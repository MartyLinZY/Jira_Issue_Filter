Summary,Issue key,Issue id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Component/s,Component/s,Component/s,Due Date,Votes,Labels,Labels,Labels,Labels,Labels,Description,Environment,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Original Estimate,Remaining Estimate,Time Spent,Work Ratio,Σ Original Estimate,Σ Remaining Estimate,Σ Time Spent,Security Level,Inward issue link (Blocked),Inward issue link (Blocker),Inward issue link (Blocker),Outward issue link (Blocker),Outward issue link (Blocker),Inward issue link (Cloners),Outward issue link (Cloners),Inward issue link (Container),Outward issue link (Container),Inward issue link (Duplicate),Inward issue link (Duplicate),Outward issue link (Duplicate),Outward issue link (Duplicate),Inward issue link (Incorporates),Inward issue link (Incorporates),Outward issue link (Incorporates),Outward issue link (Incorporates),Inward issue link (Reference),Inward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Inward issue link (Regression),Outward issue link (Regression),Outward issue link (Supercedes),Inward issue link (dependent),Outward issue link (dependent),Outward issue link (dependent),Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Custom field (Affects version (Component)),Custom field (Attachment count),Custom field (Blog - New Blog Administrators),Custom field (Blog - New Blog PMC),Custom field (Blog - Write access),Custom field (Blog Administrator?),Custom field (Blogs - Admin for blog),Custom field (Blogs - Email Address),Custom field (Blogs - Existing Blog Access Level),Custom field (Blogs - Existing Blog Name),Custom field (Blogs - New Blog Write Access),Custom field (Blogs - Username),Custom field (Bug Category),Custom field (Bugzilla - Email Notification Address),Custom field (Bugzilla - List of usernames),Custom field (Bugzilla - PMC Name),Custom field (Bugzilla - Project Name),Custom field (Bugzilla Id),Custom field (Bugzilla Id),Custom field (Change Category),Custom field (Complexity),Custom field (Discovered By),Custom field (Docs Text),Custom field (Enable Automatic Patch Review),Custom field (Epic Link),Custom field (Estimated Complexity),Custom field (Evidence Of Open Source Adoption),Custom field (Evidence Of Registration),Custom field (Evidence Of Use On World Wide Web),Custom field (Existing GitBox Approval),Custom field (External issue URL),Custom field (Fix version (Component)),Custom field (Flags),Custom field (Flags),Custom field (Git Notification Mailing List),Custom field (Git Repository Import Path),Custom field (Git Repository Name),Custom field (Git Repository Type),Custom field (GitHub Options),Custom field (Github Integration),Custom field (Github Integrations - Other),Custom field (Global Rank),Custom field (INFRA - Subversion Repository Path),Custom field (Initial Confluence Contributors),Custom field (Last public comment date),Custom field (Level of effort),Custom field (Machine Readable Info),Custom field (Mentor),Custom field (New-TLP-TLPName),Custom field (Original story points),Custom field (Parent Link),Custom field (Priority),Custom field (Project),Custom field (Protected Branch),Custom field (Rank),Custom field (Rank (Obsolete)),Custom field (Review Date),Custom field (Reviewer),Custom field (Reviewer),Custom field (Severity),Custom field (Severity),Custom field (Skill Level),Custom field (Source Control Link),Custom field (Space Description),Custom field (Space Key),Custom field (Space Name),Custom field (Start Date),Custom field (Tags),Custom field (Target end),Custom field (Target start),Custom field (Team),Custom field (Test and Documentation Plan),Custom field (Testcase included),Custom field (Tester),Custom field (Workaround),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment
Bump up commons-collections version to 3.2.2 to address a security flaw,KAFKA-2866,12914678,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,granthenke,granthenke,20/Nov/15 08:04,31/Mar/16 17:11,22/Mar/23 15:10,31/Mar/16 17:11,0.9.0.0,,,,,,,,,,,,,,,,,0,,,,,,"Update commons-collections from 3.2.1 to 3.2.2 because of a major security vulnerability. There are many other open source projects use commons-collections and are also affected.

Please see http://foxglovesecurity.com/2015/11/06/what-do-weblogic-websphere-jboss-jenkins-opennms-and-your-application-have-in-common-this-vulnerability/ for the discovery of the vulnerability.

https://issues.apache.org/jira/browse/COLLECTIONS-580 has the discussion thread of the fix.

https://blogs.apache.org/foundation/entry/apache_commons_statement_to_widespread The ASF response to the security vulnerability.",,githubbot,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Mar 31 09:11:50 UTC 2016,,,,,,,,,,"0|i2oobr:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"20/Nov/15 08:11;granthenke;This dependency is only in Kafka test code, so the fix is not critical.;;;","20/Nov/15 08:24;githubbot;GitHub user granthenke opened a pull request:

    https://github.com/apache/kafka/pull/564

    KAFKA-2866: Bump up commons-collections version to 3.2.2 to address a…

    … security flaw

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka commons

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/564.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #564
    
----
commit a5d803788da051c44ae9e298e4e68fe2862294a3
Author: Grant Henke <granthenke@gmail.com>
Date:   2015-11-20T00:22:40Z

    KAFKA-2866: Bump up commons-collections version to 3.2.2 to address a security flaw

----
;;;","11/Feb/16 22:56;githubbot;Github user granthenke closed the pull request at:

    https://github.com/apache/kafka/pull/564
;;;","31/Mar/16 17:11;ijuma;Fixed as part of KAFKA-3475.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in ZKClient may cause failure to start brokers,KAFKA-2739,12910209,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,gwenshap,gwenshap,04/Nov/15 08:57,05/Nov/15 02:43,22/Mar/23 15:10,05/Nov/15 02:43,,,,,,,,,,,,,,,,,,0,,,,,,"Described by [~fpj] here:
https://github.com/sgroschupf/zkclient/issues/38

This is an ZKClient issue. I'm opening this JIRA so we can track the error and upgrade to the new ZKClient when this is resolved.",,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2736,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,2015-11-04 00:57:18.0,,,,,,,,,,"0|i2nwzz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fault tolerance broken with replication factor 1,KAFKA-691,12626789,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,brugidou,jkreps,jkreps,10/Jan/13 00:18,18/Jan/13 01:12,22/Mar/23 15:10,11/Jan/13 03:09,0.8.0,,,,,,0.8.0,,,,,,,,,,,2,,,,,,"In 0.7 if a partition was down we would just send the message elsewhere. This meant that the partitioning was really more of a ""stickiness"" then a hard guarantee. This made it impossible to depend on it for partitioned, stateful processing.

In 0.8 when running with replication this should not be a problem generally as the partitions are now highly available and fail over to other replicas. However in the case of replication factor = 1 no longer really works for most cases as now a dead broker will give errors for that broker.

I am not sure of the best fix. Intuitively I think this is something that should be handled by the Partitioner interface. However currently the partitioner has no knowledge of which nodes are available. So you could use a random partitioner, but that would keep going back to the down node.

",,brugidou,jkreps,junrao,kamaradclimber,rangadi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-693,,,,,,,,,,"10/Jan/13 22:37;brugidou;KAFKA-691-v1.patch;https://issues.apache.org/jira/secure/attachment/12564173/KAFKA-691-v1.patch","11/Jan/13 02:38;brugidou;KAFKA-691-v2.patch;https://issues.apache.org/jira/secure/attachment/12564212/KAFKA-691-v2.patch","17/Jan/13 08:00;junrao;kafka-691_extra.patch;https://issues.apache.org/jira/secure/attachment/12565216/kafka-691_extra.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,303407,,,Thu Jan 17 17:12:46 UTC 2013,,,,,,,,,,"0|i17azj:",250748,,,,,,,,,,,,,,,,,,,,"10/Jan/13 00:44;brugidou;I think the work-around is not really acceptable for me since it will consume 3x the resources (because replication of 3 is the minimum acceptable) and it will still make the cluster less available anyway (unless i have only 3 brokers).

The thing is that 0.7 was making the cluster 100% available (for my use case, accepting data loss) as long a single broker was alive.

A way to handle this would be to:
1. Have a lot of partitions per topic (more than the # of brokers)
2. Have something that rebalances the partitions and make sure a broker has a at least a partition for each topic (to make every topic ""available"")
3. Have a setting in the consumer/producer that say ""I don't care about partitioning, just produce/consume wherever you can"";;;","10/Jan/13 03:14;junrao;One thing we can do is to change the partitioner api so that it takes # of partitions and for each partition, an indicator whether a partition is available or not. The we can change the default partitioner to only route a message to the available partitions, if a key is not provided.;;;","10/Jan/13 06:27;brugidou;I agree with Jun solution, this would solve 3 (1 and 2 can be done manualy already -- just send a ReassignPartition command when you add a broker)

I could probably implement this very quickly, I'm just not sure of how you get the availability of a partition, but i'll try to figure it out and submit a first patch tomorrow.;;;","10/Jan/13 09:37;jkreps;That would be awesome. If you don't mind just give the proposed set of changes on the JIRA first and lets get everyone on board with how it should work since it is a reasonably important change (or, if you don't mind revising your patch we can start with that).;;;","10/Jan/13 13:44;junrao;DefaultEventHander.getPartitionListForTopic() returns Seq[PartitionAndLeader]. If PartitionAndLeader.leaderBrokerIdOpt is none, the partition is not available. 

There is another tricky issue. If a partition is not available, when do we refresh the metadata to check if the partition becomes available again? Currently, we refresh the metadata if we fail to send the data. However, if we always route the messages to available partitions, we may never fail to send. One possible solution is that if there is at least one partition not available in Seq[PartitionAndLeader], we refresh the metadata if a configurable amount of time has passed (e.g., 10 mins).;;;","10/Jan/13 22:37;brugidou;Here is a first draft (v1) patch.

1. Added the consumer property ""producer.metadata.refresh.interval.ms"" defaults to 600000 (10min)

2. The metadata is refreshed every 10min (only if a message is sent), and the set of topics to refresh is tracked in the topicMetadataToRefresh Set (cleared after every refresh) - I think the added value of refreshing regardless of partition availability is to detect new partitions

3. The good news is that I didn't touch the Partitioner API, I only changed the code to use available partitions if the key is null (as suggested by Jun), it will also throw a UnknownTopicOrPartitionException(""No leader for any partition"") if no partition is available at all

Let me know what you think about this patch. I ran a producer with that code successfully and tested with a broker down.

I now have some concerns about the consumer: the refresh.leader.backoff.ms config could help me (if i increase it to say, 10min) BUT the rebalance fails in any case since there is no leader for some partitions

I don't have a good workaround yet for that, any help/suggestion appreciated.;;;","11/Jan/13 01:59;junrao;Thanks for the patch. Overall, the patch is pretty good and is well thought out. Some comments:

1. DefaultEventHandler:
1.1 In handle(), I don't think we need to add the if test in the following statement. The reason is that a message could fail to be sent because the leader changes immediately after the previous metadata refresh. Normally, leaders are elected very quickly. So, it makes sense to refresh the metadata again.
          if (topicMetadataToRefresh.nonEmpty)
              Utils.swallowError(brokerPartitionInfo.updateInfo(outstandingProduceRequests.map(_.topic).toSet))
1.2 In handle(), it seems that it's better to call the following code before dispatchSerializedData().
        if (topicMetadataRefreshInterval >= 0 &&
            SystemTime.milliseconds - lastTopicMetadataRefresh > topicMetadataRefreshInterval) {
          Utils.swallowError(brokerPartitionInfo.updateInfo(topicMetadataToRefresh.toSet))
          topicMetadataToRefresh.clear
          lastTopicMetadataRefresh = SystemTime.milliseconds
        }
1.3 getPartition(): If none of the partitions is available, we should throw LeaderNotAvailableException, instead of UnknownTopicOrPartitionException.

2. DefaultPartitioner: Since key is not expected to be null, we should remove the code that deals with null key. 

3. The consumer side logic is fine. The consumer rebalance is only triggered when there are changes in partitions, not when there are changes in the availability of the partition. The rebalance logic doesn't depend on a partition being available. If a partition is not available, ConsumerFetcherManager will keep refreshing metadata. If you have a replication factor of 1, you will need to set a larger refresh.leader.backoff.ms, if a broker is expected to go down for a long time. ;;;","11/Jan/13 02:38;brugidou;Thanks for your feedback, I updated it (v2) according to your notes (1. and 2.).

for 3. I believe you are right, except that:
3.1 It seems (correct me if i'm wrong) that a rebalance happen at the consumer initialization, so that means a consumer can't start if a broker is down
3.2 Can a rebalance be triggered when a partition is added or moved? Having a broker down shouldn't prevent me from reassigning partitions or adding partitions.
;;;","11/Jan/13 03:09;junrao;Thanks for patch v2. Committed to 0.8 by renaming lastTopicMetadataRefresh to lastTopicMetadataRefreshTime and removing an unused comment.

3.1 Rebalance happens during consumer initialization. It only needs the partition data to be in ZK and doesn't require all brokers to be up. Of course, if a broker is not up, the consumer may not be able to consume data from it. ConsumerFetcherManager is responsible for checking if a partition becomes available again.

3.2 If the partition path changes in ZK, a rebalance will be triggered.;;;","11/Jan/13 03:57;brugidou;Thanks for committing the patch.

3.1 Are you sure that the rebalance doesn't require all partitions to have a leader? My experience earlier today was that the rebalance would fail and throw ConsumerRebalanceFailedException after having stopped all fetchers and cleared all queues. If you are sure then i'll try to reproduce the behavior I encountered, and maybe open a separate JIRA?;;;","11/Jan/13 05:31;junrao;3.1 It shouldn't. However, if you can reproduce this problem, please file a new jira.;;;","13/Jan/13 00:58;junrao;Another potential issue is that for producers that produce many topics (like migrationTool and mirrorMaker), the time-based refreshing may need to get the metadata for many topics. This means that the metadata request is likely to timeout. One solution is to break topics into batches in BrokerPartitionInfo.updateInfo() and issue a metadata request per batch. ;;;","13/Jan/13 02:02;brugidou;Should i make another patch? I'll try on Monday.

1. It would probably require yet another config variable like ""producer.metadata.request.batch.size"" or something like that.
2. Should it be batched for every updateInfo() or just during the metadata refresh? It could help if we do the former because failing messages from many different topics could probably never go through if the metadata request timeouts.
3. Isn'it getting a little convoluted? Maybe i am missing something but the producer side is getting trickier.
4. Please note that I also opened KAFKA-693 about the consumer side. And I'd love to submit a patch but the rebalance logic seems complex so I'd prefer to have some insights first before going in the wrong direction.;;;","14/Jan/13 06:11;junrao;It would be great if you can provide a patch.

1,2,3. Yes, we will need a new config. We should do batching in updateinfo(). This does make the producer side logic a bit more complicated. We have been thinking about making getMetadata faster. When we get there, we can revisit the batching logic.;;;","14/Jan/13 08:34;jkreps;Does batching make sense versus just having people increase the timeout?;;;","14/Jan/13 09:00;junrao;That's a good point. Increasing the timeout will work for most cases. If a broker goes down, the client request will get a socket exception immediately, independent of the timeout. So setting a large timeout doesn't hurt. When the broker host goes down and the client is waiting for a response from the server, I think the client will have to wait until the timeout. If we set a larger timeout, it means that the client has to wait longer before realizing the broker is down. However, since this is a rarer case, I think setting a larger timeout for now is probably good enough.;;;","14/Jan/13 22:53;brugidou;So I wait for your feedback first, but I guess that increasing the time out is good enough, although it's 1500ms by default which is very short.;;;","17/Jan/13 06:53;junrao;The last patch introduced a bug. DefaultEventHander.getPartition() is expected to return the index of the partitionList, instead of the actual partition id. Attach a patch that fixes the issue.;;;","17/Jan/13 08:00;junrao;Attach the right patch (kafka-691_extra.patch).;;;","18/Jan/13 01:12;junrao;Actually, the current code works since partitionId is always btw 0 and num.partition-1 and therefore it happens to also be the index of the partitionList. This patch just makes the code a bit better to understand.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Inappropriate logging level for SSL Problem,KAFKA-3131,12933366,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Duplicate,sriharsha,jakerobb,jakerobb,22/Jan/16 23:25,20/Sep/17 17:04,22/Mar/23 15:10,20/Sep/17 17:03,,,,,,,,,,,,,,clients,,,,1,,,,,,"I didn't have my truststore set up correctly. The Kafka producer waited until the connection timed out (60 seconds in my case) and then threw this exception:

{code}
Exception in thread ""main"" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
	at org.apache.kafka.clients.producer.KafkaProducer$FutureFailure.<init>(KafkaProducer.java:706)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:453)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:339)
{code}

I changed my log level to DEBUG and found this, less than two seconds after startup:
{code}
[DEBUG] @ 2016-01-22 10:10:34,095 
[User: ; Server: ; Client: ; URL: ; ChangeGroup: ]
 org.apache.kafka.common.network.Selector  - Connection with kafka02/10.0.0.2 disconnected 

javax.net.ssl.SSLHandshakeException: General SSLEngine problem
	at sun.security.ssl.Handshaker.checkThrown(Handshaker.java:1364)
	at sun.security.ssl.SSLEngineImpl.checkTaskThrown(SSLEngineImpl.java:529)
	at sun.security.ssl.SSLEngineImpl.writeAppRecord(SSLEngineImpl.java:1194)
	at sun.security.ssl.SSLEngineImpl.wrap(SSLEngineImpl.java:1166)
	at javax.net.ssl.SSLEngine.wrap(SSLEngine.java:469)
	at org.apache.kafka.common.network.SslTransportLayer.handshakeWrap(SslTransportLayer.java:377)
	at org.apache.kafka.common.network.SslTransportLayer.handshake(SslTransportLayer.java:242)
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:68)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:281)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:270)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:216)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:128)
	at java.lang.Thread.run(Thread.java:745)
Caused by: javax.net.ssl.SSLHandshakeException: General SSLEngine problem
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:192)
	at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1708)
	at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:303)
	at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:295)
	at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1369)
	at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:156)
	at sun.security.ssl.Handshaker.processLoop(Handshaker.java:925)
	at sun.security.ssl.Handshaker$1.run(Handshaker.java:865)
	at sun.security.ssl.Handshaker$1.run(Handshaker.java:862)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.security.ssl.Handshaker$DelegatedTask.run(Handshaker.java:1302)
	at org.apache.kafka.common.network.SslTransportLayer.runDelegatedTasks(SslTransportLayer.java:335)
	at org.apache.kafka.common.network.SslTransportLayer.handshakeUnwrap(SslTransportLayer.java:413)
	at org.apache.kafka.common.network.SslTransportLayer.handshake(SslTransportLayer.java:269)
	... 6 more
Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
	at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:387)
	at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292)
	at sun.security.validator.Validator.validate(Validator.java:260)
	at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:324)
	at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:281)
	at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:136)
	at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1356)
	... 15 more
Caused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
	at sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:145)
	at sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:131)
	at java.security.cert.CertPathBuilder.build(CertPathBuilder.java:280)
	at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:382)
	... 21 more
{code}

There are two problems here:
1. The log level should be ERROR if the Kafka producer cannot connect because of an SSL handshake problem, as this error is not likely to be intermittent or recoverable without intervention, and the thrown exception completely obscures the real problem.
2. Ideally, I would think that the producer's call to {{send}} should throw an exception immediately rather than waiting for the full timeout.

I'm not sure if it will help, but the full DEBUG output of my Kafka producer's session is attached.",,githubbot,jakerobb,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-5920,,,,,,,,,,,,,,,,,,"22/Jan/16 23:27;jakerobb;kafka-ssl-error-debug-log.txt;https://issues.apache.org/jira/secure/attachment/12783840/kafka-ssl-error-debug-log.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Sep 20 09:04:23 UTC 2017,,,,,,,,,,"0|i2rukf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"30/Aug/17 20:00;githubbot;GitHub user omkreddy opened a pull request:

    https://github.com/apache/kafka/pull/3758

    KAFKA-3131: enable error level for SSLException logs

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/omkreddy/kafka KAFKA-3131

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/3758.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #3758
    
----
commit e471714320b2303388dfa5d14d8202788d5c8fc9
Author: Manikumar Reddy <manikumar.reddy@gmail.com>
Date:   2017-08-30T11:22:38Z

    KAFKA-3131: enable error level for SSLException logs

----
;;;","20/Sep/17 17:03;omkreddy;Handling of SSL authentication failures is being worked in KAFKA-5920. Resolving this as duplicate of KAFKA-5920;;;","20/Sep/17 17:04;githubbot;Github user omkreddy closed the pull request at:

    https://github.com/apache/kafka/pull/3758
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in serialize and collate logic in the DefaultEventHandler,KAFKA-107,12519065,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,nehanarkhede,nehanarkhede,17/Aug/11 11:02,13/Sep/11 09:27,22/Mar/23 15:10,13/Sep/11 09:27,0.7,,,,,,0.7,,,,,,,,,,,0,,,,,,"There is a bug in the serialize and collate in the DefaultEventHandler, that uses the map() API on a hashmap to convert a sequence of messages to a ByteBufferMessageSet, based on the compression configs. The usage of the zip() API after the map() API on a hashmap, has the side effect of reordering the mapping between the keys and the values. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/11 03:46;nehanarkhede;KAFKA-107-unit-test.patch;https://issues.apache.org/jira/secure/attachment/12490842/KAFKA-107-unit-test.patch","17/Aug/11 11:05;nehanarkhede;KAFKA-107.patch;https://issues.apache.org/jira/secure/attachment/12490597/KAFKA-107.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,60819,,,Thu Aug 18 21:40:06 UTC 2011,,,,,,,,,,"0|i15yy7:",242962,,,,,,,,,,,,,,,,,,,,"17/Aug/11 11:04;nehanarkhede;This patch refactors the code in the DefaultEventHandler serialize API to fix the reordering bug;;;","18/Aug/11 00:05;junrao;Ok, so the problem was that the code was trying to zip a map (topicsAndPartitions) and a list (messages). Even though they are derived from the same map, there is no guarantee that the map is going to be iterated in the same order as the list. So, in the future, we need to be careful about using zip. We need to make sure that the two collections to be zipped have well defined ordering (e.g., list) for iteration and the ordering is what we want. Could you double check other usage of zip introduced in the compression patch?

The patch looks fine. However, could you also add a unit test (probably just at the serialize() level) that exposes this problem?;;;","18/Aug/11 02:45;junrao;Another thing, please remove unreferenced package imports.;;;","18/Aug/11 03:08;nehanarkhede;Jun, the code is not  zipping a map with a list. That won't even compile. The code is just zipping a sequence of tuples with a sequence of ByteBufferMessageSet. The problem is that one sequence is generated using the map API on the original HashMap and another sequence is generated using the map API on another HashMap. So ordering of data across those sequences is not guaranteed. Hence, a zip on those sequences will not associate the keys with the correct values.

I will add a unit test to cover this, and remove the unreferenced package imports.;;;","19/Aug/11 03:46;nehanarkhede;Adding a unit test to the test suite for AsyncProducer that catches the reordering bug in serialize() API of DefaultEventHandler;;;","19/Aug/11 05:40;junrao;+1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Problem running Kafka using -daemon switch,KAFKA-2889,12915989,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,ing.dave@gmail.com,ing.dave@gmail.com,25/Nov/15 08:52,25/Nov/15 09:27,22/Mar/23 15:10,25/Nov/15 09:27,0.8.2.2,0.9.0.0,,,,,0.8.2.2,,,,,,,core,,,,0,newbie,,,,,"I am seeing an error ""USAGE: java [options] KafkaServer server.properties"" when I try to start Kafka using the shell scripts that are provided inside kafka_2.10-0.8.2.2.tgz or kafka_2.11-0.8.2.2.tgz.  Specifically I see this error when I use the ""-daemon"" flag as follows:

kafka-server-start.sh -daemon /opt/companyName/kafka/config/server.properties

This script then calls another script as follows:

/opt/companyName/kafka/bin/kafka-run-class.sh -name kafkaServer -loggc kafka.Kafka -daemon /opt/companyName/kafka/config/server.properties

This ultimately results in the call to java as follows:
java -Xmx1G -Xms1G -server -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC -Djava.awt.headless=true -Xloggc:/opt/companyName/kafka/bin/../logs/kafkaServer-gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/opt/companyName/kafka/bin/../logs -Dlog4j.configuration=file:/opt/companyName/kafka/bin/../config/log4j.properties -cp :/opt/companyName/kafka/bin/../core/build/dependant-libs-2.10.4*/*.jar:/opt/companyName/kafka/bin/../examples/build/libs//kafka-examples*.jar:/opt/companyName/kafka/bin/../contrib/hadoop-consumer/build/libs//kafka-hadoop-consumer*.jar:/opt/companyName/kafka/bin/../contrib/hadoop-producer/build/libs//kafka-hadoop-producer*.jar:/opt/companyName/kafka/bin/../clients/build/libs/kafka-clients*.jar:/opt/companyName/kafka/bin/../libs/jopt-simple-3.2.jar:/opt/companyName/kafka/bin/../libs/kafka_2.10-0.8.2.2.jar:/opt/companyName/kafka/bin/../libs/kafka_2.10-0.8.2.2-javadoc.jar:/opt/companyName/kafka/bin/../libs/kafka_2.10-0.8.2.2-scaladoc.jar:/opt/companyName/kafka/bin/../libs/kafka_2.10-0.8.2.2-sources.jar:/opt/companyName/kafka/bin/../libs/kafka_2.10-0.8.2.2-test.jar:/opt/companyName/kafka/bin/../libs/kafka-clients-0.8.2.2.jar:/opt/companyName/kafka/bin/../libs/log4j-1.2.16.jar:/opt/companyName/kafka/bin/../libs/lz4-1.2.0.jar:/opt/companyName/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/companyName/kafka/bin/../libs/scala-library-2.10.4.jar:/opt/companyName/kafka/bin/../libs/slf4j-api-1.7.6.jar:/opt/companyName/kafka/bin/../libs/slf4j-log4j12-1.6.1.jar:/opt/companyName/kafka/bin/../libs/snappy-java-1.1.1.7.jar:/opt/companyName/kafka/bin/../libs/zkclient-0.3.jar:/opt/companyName/kafka/bin/../libs/zookeeper-3.4.6.jar:/opt/companyName/kafka/bin/../core/build/libs/kafka_2.10*.jar kafka.Kafka -daemon /opt/companyName/kafka/config/server.properties

Finally it generates the error:

USAGE: java [options] KafkaServer server.properties

This error prevents me from calling Kafka in -daemon mode unless I write my own shell script.",Ubuntu 14.04 TLS,ing.dave@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10800,10800,,0%,10800,10800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,Patch,,,,,,,,,9223372036854775807,,,Wed Nov 25 01:27:25 UTC 2015,,,,,,,,,,"0|i2owev:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"25/Nov/15 09:27;ing.dave@gmail.com;I should not have reported this issue.  Your shell scripts are working fine and there is nothing for you to fix.

The problem was based on an outer layer of shell script which I did not even describe in this bug report.  Basically, the arguments ""-daemon server.properties"" were being passed as a single string rather than 2 separate arguments.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in the consumer rebalancing logic leads to the consumer not pulling data from some partitions,KAFKA-256,12539814,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,26/Jan/12 03:32,03/Feb/12 09:13,22/Mar/23 15:10,03/Feb/12 03:08,0.7,,,,,,0.7.1,,,,,,,core,,,,0,,,,,,"There is a bug in the consumer rebalancing logic that makes a consumer not pull data from some partitions for a topic. It recovers only after the consumer group is restarted and doesn't hit this bug again.

Here is the observed behavior of the consumer when it hits the bug -

1. Consumer is consuming 2 topics with 1 partition each on 2 brokers
2. Broker 2 is bounced
3. Rebalancing operation triggers for topic_2, where the consumer decides to now consume data only from Broker 1 for topic_2
4. During the rebalancing operation, ZK has not yet deleted the /brokers/topics/topic_1/broker_2, so the consumer still decides to consumer from both brokers for topic_1
5. While restarting the fetchers, it tries to restart fetcher for broker 2 and throws a RuntimeException. Before this, it has successfully started fetcher for broker 1 and is consuming data from broker_1
6. This exception trickles all the way upto syncedRebalance API and the oldPartitionsPerTopicMap does not get updated to reflect that for topic_2, the consumer has now seen only broker_1. It still points to topic_2 -> broker_1, broker_2
7. Next rebalancing attempt gets triggered
8. By now, broker 2 is restarted and registered in zookeeper
9. For topic_2, the consumer tries to see if rebalancing needs to be done. Since it doesn't see a change in the cached topic partition map, it decides there is no need to rebalance.
10. It continues fetching only from broker_1
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jan/12 09:03;nehanarkhede;kafka-256-v2.patch;https://issues.apache.org/jira/secure/attachment/12512061/kafka-256-v2.patch","28/Jan/12 09:27;nehanarkhede;kafka-256-v3.patch;https://issues.apache.org/jira/secure/attachment/12512267/kafka-256-v3.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,225317,,,Fri Feb 03 01:13:36 UTC 2012,,,,,,,,,,"0|i0l5pz:",121577,,,,,,,,,,,,,,,,,,,,"27/Jan/12 06:26;nehanarkhede;Changes include -

1. The bug was caused due to a stale cache problem

2. This patch fixes the bug by clearing the cache on every single unsuccessful rebalancing attempt. This includes exception during rebalancing OR failure to own one or more partitions 

3. A tool to verify if a consumer group successfully completed a rebalancing operation. 

4. To facilitate such a tool, partition ownership is split into 3 steps -

4.1 the consumer records its decision to own partitions that it has selected
4.2 the fetchers are started to start pulling data from the selected partitions
4.3 the above partition ownership decision is written to zookeeper

5. Cleanup to remove unrequired imports;;;","27/Jan/12 09:03;nehanarkhede;This patch applies cleanly to trunk;;;","28/Jan/12 09:27;nehanarkhede;A slight change here -

The fetchers are updated only after the partition ownership is reflected in zookeeper. This will reduce the possibility of duplicate data;;;","28/Jan/12 10:42;jjkoshy;+1 for v3. 

I like the idea of having a tool to check if a consumer is correctly balanced.
A more general comment/question on the kafka.tools package: I thought the tools
package is meant for stand-alone tools that people can run on the command-line,
whose output can be piped for further processing if desired.  If so, it would
be better not to use logging for the tool's output and simply println. 
;;;","30/Jan/12 02:33;nehanarkhede;You have a good point about the tools package. This tool is meant for use in running system tests (KAFKA-227) in verifying the correctness of Kafka. This means at the very least the output about whether the rebalancing attempt was successful or not, can be println and maybe the other info useful for debugging can be log4j ? If that makes sense, I'll make that change before committing this patch.

Thanks for reviewing this patch and catching the possible duplication issue in v2. ;;;","03/Feb/12 03:08;nehanarkhede;Committed this patch to trunk. Will fix KAFKA-262 separately.;;;","03/Feb/12 08:32;nehanarkhede;I found a bug in the v3 patch. The reflectPartitionOwnershipDecision API has a bug that doesn't set the value of partitionOwnershipSuccessful correctly. Will fix this as part of KAFKA-262.;;;","03/Feb/12 09:05;junrao;Some comments:
1. ZookeeperConsumerConnector.reflectPartitionOwnershipDecision, the following code seems incorrect.
      val success = partitionOwnershipSuccessful.foldLeft(0)((sum, decision) => if(decision) 0 else 1)
  The function in foldLeft should check both sum and decision. Also, the local variable success should be named to something like hasFailure.
2. ZookeeperConsumerConnector.syncedRebalance
  done = false in the catch clause is not necessary. If we hit an exception, done will be left with the initial value, which is false.
  The else after the following
         if (done) {
            return
          }
  is not necessary.
  Also, it seems there is no need to call commitOffset before closeFetchersFprQuues since the latter commits offsets already.
3. It seems that we don't need to check ownership registry in ZK in processPartition. The same check will be done later in reflectPartitionOwnershipDecision.
;;;","03/Feb/12 09:13;nehanarkhede;1. That is the bug I was referring to in my previous comment. 

2. done =false in the catch clause is to prevent a bug, in case the code elsewhere in the rebalance API changes in the future. These bugs are very hard to spot and time consuming to debug. This one-liner seems harmless since it could potentially save a lot of time.
Though, commitOffsets() can be skipped before closing the fetchers. 

3. This is also a good point, and seems like an over optimization. Will get rid of it as part of KAFKA-262.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix bug preventing Mirror Maker from successful rebalance.,KAFKA-1890,12769433,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,becket_qin,becket_qin,becket_qin,23/Jan/15 04:49,24/Jan/15 01:08,22/Mar/23 15:10,24/Jan/15 01:08,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,Follow-up patch for KAFKA-1650,,becket_qin,gwenshap,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jan/15 07:25;becket_qin;KAFKA-1890.patch;https://issues.apache.org/jira/secure/attachment/12694034/KAFKA-1890.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jan 23 17:08:11 UTC 2015,,,,,,,,,,"0|i24oun:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"23/Jan/15 07:00;gwenshap;[~becket_qin], I'm getting the following error when running MirrorMaker with KAFKA-1650:

{code}
[2015-01-22 14:45:54,338] FATAL Unable to create stream - shutting down mirror maker: (kafka.tools.MirrorMaker$)
kafka.common.ConsumerRebalanceFailedException: g1_kafkaf-2.ent.cloudera.com-1421966744998-a84db773 can't rebalance after 4 retries
	at kafka.consumer.ZookeeperConsumerConnector$ZKRebalancerListener.syncedRebalance(ZookeeperConsumerConnector.scala:650)
	at kafka.consumer.ZookeeperConsumerConnector.kafka$consumer$ZookeeperConsumerConnector$$reinitializeConsumer(ZookeeperConsumerConnector.scala:932)
	at kafka.consumer.ZookeeperConsumerConnector$WildcardStreamsHandler.<init>(ZookeeperConsumerConnector.scala:966)
	at kafka.consumer.ZookeeperConsumerConnector.createMessageStreamsByFilter(ZookeeperConsumerConnector.scala:163)
	at kafka.tools.MirrorMaker$.main(MirrorMaker.scala:271)
	at kafka.tools.MirrorMaker.main(MirrorMaker.scala)
{code}

Is this the error you are fixing in this JIRA, or is this a separate issue?
;;;","23/Jan/15 07:04;becket_qin;Yes, this is the one I'm fixing.;;;","23/Jan/15 07:25;becket_qin;Created reviewboard https://reviews.apache.org/r/30199/diff/
 against branch origin/trunk;;;","23/Jan/15 09:02;gwenshap;+1 - Solved my problem :)

Thanks, [~becket_qin];;;","24/Jan/15 01:08;nehanarkhede;Thanks for the patch, Becket. Pushed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka server mirror shutdown bug,KAFKA-145,12525599,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,04/Oct/11 07:25,06/Oct/11 07:03,22/Mar/23 15:10,06/Oct/11 07:03,,,,,,,0.7,,,,,,,core,,,,0,,,,,,"When a machine that is mirroring data off of another Kafka broker is shutdown, it runs into the following exception, effectively dropping data. The shutdown API needs to be fixed to first shutdown the consumer threads, drain all the data to the producer, and only then shutdown the producer. 

FATAL kafka.server.EmbeddedConsumer  - kafka.producer.async.QueueClosedException: Attempt to add event to a closed queue.kafka.producer.async.QueueClosedException: Attempt to add event to a closed queue.
        at kafka.producer.async.AsyncProducer.send(AsyncProducer.scala:87)
        at kafka.producer.ProducerPool$$anonfun$send$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$2.apply(ProducerPool.scala:131)
        at kafka.producer.ProducerPool$$anonfun$send$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$2.apply(ProducerPool.scala:131)
        at scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:61)
        at scala.collection.immutable.List.foreach(List.scala:45)
        at kafka.producer.ProducerPool$$anonfun$send$1$$anonfun$apply$mcVI$sp$1.apply(ProducerPool.scala:131)
        at kafka.producer.ProducerPool$$anonfun$send$1$$anonfun$apply$mcVI$sp$1.apply(ProducerPool.scala:130)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:130)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:102)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:102)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:102)
        at kafka.producer.Producer.zkSend(Producer.scala:144)
        at kafka.producer.Producer.send(Producer.scala:106)
        at kafka.server.EmbeddedConsumer$$anonfun$startNewConsumerThreads$1$$anonfun$apply$1$$anon$1$$anonfun$run$1.apply(KafkaServerStartable.scala:136)
        at kafka.server.EmbeddedConsumer$$anonfun$startNewConsumerThreads$1$$anonfun$apply$1$$anon$1$$anonfun$run$1.apply(KafkaServerStartable.scala:134)
        at scala.collection.Iterator$class.foreach(Iterator.scala:631)
        at kafka.utils.IteratorTemplate.foreach(IteratorTemplate.scala:30)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Oct/11 06:27;nehanarkhede;KAFKA-145.patch;https://issues.apache.org/jira/secure/attachment/12497912/KAFKA-145.patch","06/Oct/11 05:09;nehanarkhede;KAFKA-145.patch;https://issues.apache.org/jira/secure/attachment/12497895/KAFKA-145.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,43962,,,Wed Oct 05 23:03:16 UTC 2011,,,,,,,,,,"0|i15z5j:",242995,,,,,,,,,,,,,,,,,,,,"06/Oct/11 05:09;nehanarkhede;This patch corrects the shutdown behavior of Kafka mirroring, i.e. EmbeddedConsumer. It first shuts down the new topic watcher, then the zookeeper consumer connector. After this, it stops the mirroring threads. At this point, all mirroring threads have finished mirroring all data that they've ever consumed. Only then, it shuts down the producer. 

This ensures that the producer is not shutdown, before the mirroring threads have finished their work, thereby avoiding data loss caused due to QueueClosedException.;;;","06/Oct/11 06:14;junrao;In MirroringThread.run, it's probably better to do the countdown even when we hit an exception.;;;","06/Oct/11 06:27;nehanarkhede;Uploading an updated patch, in which the shutdown latch is decremented in a finally block, to make sure the mirroring threads will shutdown even when they run into an error/exception.;;;","06/Oct/11 06:40;junrao;+1 on the new patch.;;;","06/Oct/11 07:03;nehanarkhede;Thanks. Just committed the patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in the queue timeout logic of the async producer,KAFKA-138,12524582,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,nehanarkhede,nehanarkhede,26/Sep/11 06:59,28/Sep/11 08:52,22/Mar/23 15:10,28/Sep/11 08:52,0.7,,,,,,0.7,,,,,,,core,,,,0,,,,,,There is a bug in the queue timeout logic of the async producer. This bug shows up when the producer is very low throughput. The behavior observed by such very low throughput producers is delayed dispatching of the events. There is no observed data loss though.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Sep/11 07:34;nehanarkhede;KAFKA-138.patch;https://issues.apache.org/jira/secure/attachment/12496420/KAFKA-138.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,3227,,,Wed Sep 28 00:52:18 UTC 2011,,,,,,,,,,"0|i15z47:",242989,,,,,,,,,,,,,,,,,,,,"26/Sep/11 07:33;nehanarkhede;This patch corrects the queue.poll logic to respect the queue timeout. Before this, under very low traffic, the producer ended up waiting for a timeout proportional to number of events added to the queue, the upper bound being the batch size. ;;;","27/Sep/11 00:55;junrao;+1;;;","28/Sep/11 08:52;junrao;Thanks, Neha. Just committed this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in async producer DefaultEventHandler retry logic,KAFKA-295,12545382,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,prashanth.menon,prashanth.menon,prashanth.menon,07/Mar/12 02:00,02/Apr/12 09:50,22/Mar/23 15:10,02/Apr/12 09:49,0.8.0,,,,,,0.8.0,,,,,,,core,,,,0,,,,,,"In the DefaultEventHandler's retry loop, the logic should not return after a successful retry.  Rather, it should set a boolean flag indicating that the retry was successful and exit or break the while loop.  In the end it should throw an exception only the flag is false.  Otherwise, it should continue the outer for loop and send remaining data to remaning brokers.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-305,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,230568,,,Mon Apr 02 01:49:15 UTC 2012,,,,,,,,,,"0|i09m93:",54038,,,,,,,,,,,,,,,,,,,,"13/Mar/12 09:04;prashanth.menon;This is a small but important bug.  I can drop a patch since I've been touching that code anyways.  It will probably come in after KAFKA-49.;;;","02/Apr/12 09:49;prashanth.menon;Incorporated as part of KAFKA-300 and KAFKA-305.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Brokers are having a problem shutting down correctly,KAFKA-2351,12846432,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,mgharat,mgharat,mgharat,21/Jul/15 11:41,26/Aug/15 08:51,22/Mar/23 15:10,26/Aug/15 08:51,,,,,,,,,,,,,,,,,,0,,,,,,The run() in Acceptor during shutdown might throw an exception that is not caught and it never reaches shutdownComplete due to which the latch is not counted down and the broker will not be able to shutdown.,,guozhang,ijuma,jjkoshy,junrao,mgharat,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jul/15 04:11;mgharat;KAFKA-2351.patch;https://issues.apache.org/jira/secure/attachment/12746410/KAFKA-2351.patch","22/Jul/15 05:58;mgharat;KAFKA-2351_2015-07-21_14:58:13.patch;https://issues.apache.org/jira/secure/attachment/12746427/KAFKA-2351_2015-07-21_14%3A58%3A13.patch","24/Jul/15 12:36;mgharat;KAFKA-2351_2015-07-23_21:36:52.patch;https://issues.apache.org/jira/secure/attachment/12746947/KAFKA-2351_2015-07-23_21%3A36%3A52.patch","14/Aug/15 04:10;mgharat;KAFKA-2351_2015-08-13_13:10:05.patch;https://issues.apache.org/jira/secure/attachment/12750368/KAFKA-2351_2015-08-13_13%3A10%3A05.patch","25/Aug/15 06:50;mgharat;KAFKA-2351_2015-08-24_15:50:41.patch;https://issues.apache.org/jira/secure/attachment/12752099/KAFKA-2351_2015-08-24_15%3A50%3A41.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Aug 26 00:51:45 UTC 2015,,,,,,,,,,"0|i2hh7j:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"22/Jul/15 04:11;mgharat;Created reviewboard https://reviews.apache.org/r/36652/diff/
 against branch origin/trunk;;;","22/Jul/15 05:58;mgharat;Updated reviewboard https://reviews.apache.org/r/36652/diff/
 against branch origin/trunk;;;","23/Jul/15 10:26;mgharat;[~junrao], [~guozhang] can you take a look at this? ;;;","23/Jul/15 23:30;ijuma;[~mgharat], did you see the discussion around exceptions in the review for https://issues.apache.org/jira/browse/KAFKA-2353 ?;;;","24/Jul/15 00:32;mgharat;Hi [~ijuma], thanks a lot for pointing me towards this. I will think more on this and upload a new patch.;;;","24/Jul/15 12:36;mgharat;Updated reviewboard https://reviews.apache.org/r/36652/diff/
 against branch origin/trunk;;;","25/Jul/15 04:09;mgharat;Hi [~junrao],
Thanks for the comments on the patch. 
I have replied to your concerns on the RB. Would you mind taking another look? I will upload a new patch accordingly.

;;;","29/Jul/15 03:50;guozhang;[~mgharat] Could you change the status to ""Patch Available"" if you think it is ready for review again? [~junrao] will help reviewing it.;;;","05/Aug/15 10:14;mgharat;[~junrao] would you mind taking another look at this. I have replied to your comments on the RB. ;;;","05/Aug/15 15:15;sslavic;Running single instance of Kafka broker from latest trunk I experienced this not so successful controlled shutdown:
{noformat}
[2015-08-05 00:19:09,998] INFO [Offset Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.server.OffsetManager)
^C[2015-08-05 00:23:09,144] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2015-08-05 00:23:09,146] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2015-08-05 00:23:09,155] ERROR [KafkaApi-0] error when handling request Name: ControlledShutdownRequest; Version: 0; CorrelationId: 0; BrokerId: 0 (kafka.server.KafkaApis)
kafka.common.ControllerMovedException: Controller moved to another broker. Aborting controlled shutdown
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:231)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:146)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:63)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-05 00:23:09,156] INFO [Kafka Server 0], Remaining partitions to move:  (kafka.server.KafkaServer)
[2015-08-05 00:23:09,156] INFO [Kafka Server 0], Error code from controller: -1 (kafka.server.KafkaServer)
[2015-08-05 00:23:14,160] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2015-08-05 00:23:14,166] ERROR [KafkaApi-0] error when handling request Name: ControlledShutdownRequest; Version: 0; CorrelationId: 1; BrokerId: 0 (kafka.server.KafkaApis)
kafka.common.ControllerMovedException: Controller moved to another broker. Aborting controlled shutdown
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:231)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:146)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:63)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-05 00:23:14,167] INFO [Kafka Server 0], Remaining partitions to move:  (kafka.server.KafkaServer)
[2015-08-05 00:23:14,167] INFO [Kafka Server 0], Error code from controller: -1 (kafka.server.KafkaServer)
[2015-08-05 00:23:19,169] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2015-08-05 00:23:19,172] ERROR [KafkaApi-0] error when handling request Name: ControlledShutdownRequest; Version: 0; CorrelationId: 2; BrokerId: 0 (kafka.server.KafkaApis)
kafka.common.ControllerMovedException: Controller moved to another broker. Aborting controlled shutdown
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:231)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:146)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:63)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2015-08-05 00:23:19,173] INFO [Kafka Server 0], Remaining partitions to move:  (kafka.server.KafkaServer)
[2015-08-05 00:23:19,173] INFO [Kafka Server 0], Error code from controller: -1 (kafka.server.KafkaServer)
[2015-08-05 00:23:24,176] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2015-08-05 00:23:24,177] WARN [Kafka Server 0], Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2015-08-05 00:23:24,180] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2015-08-05 00:23:24,189] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2015-08-05 00:23:24,190] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2015-08-05 00:23:24,193] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2015-08-05 00:23:24,196] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[2015-08-05 00:23:24,196] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2015-08-05 00:23:24,197] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2015-08-05 00:23:24,197] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,310] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,310] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,310] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,413] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,413] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,420] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2015-08-05 00:23:24,421] INFO Shutting down. (kafka.log.LogManager)
[2015-08-05 00:23:24,451] INFO Shutdown complete. (kafka.log.LogManager)
[2015-08-05 00:23:24,452] INFO [ConsumerCoordinator 0]: Shutting down. (kafka.coordinator.ConsumerCoordinator)
[2015-08-05 00:23:24,453] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,494] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,494] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,494] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,513] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,513] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-08-05 00:23:24,514] INFO [ConsumerCoordinator 0]: Shutdown complete. (kafka.coordinator.ConsumerCoordinator)
[2015-08-05 00:23:24,517] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2015-08-05 00:23:24,602] INFO Session: 0x14ef8883c9e0008 closed (org.apache.zookeeper.ZooKeeper)
[2015-08-05 00:23:24,602] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[2015-08-05 00:23:24,602] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
{noformat}

Is that unwanted behavior (going to be) handled by this ticket?;;;","06/Aug/15 03:47;mgharat;[~sslavic] I think this is different. Thanks for reporting this. Let me see if I can address this in the current patch. ;;;","06/Aug/15 08:06;junrao;[~mgharat], sorry the delay. Just replied on RB.;;;","07/Aug/15 01:11;mgharat;Thanks [~junrao]. I will see if I can address the issue reported by [~sslavic] quickly. If I can, I will upload a new patch else will do it in another ticket.;;;","14/Aug/15 04:10;mgharat;Updated reviewboard https://reviews.apache.org/r/36652/diff/
 against branch origin/trunk;;;","25/Aug/15 06:50;mgharat;Updated reviewboard https://reviews.apache.org/r/36652/diff/
 against branch origin/trunk;;;","26/Aug/15 08:51;jjkoshy;Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable message replication in the presence of controlled failures,KAFKA-350,12558226,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,26/May/12 10:22,25/Jul/12 02:13,22/Mar/23 15:10,25/Jul/12 02:13,0.8.0,,,,,,,,,,,,,,,,,0,,,,,,KAFKA-46 introduced message replication feature in the absence of server failures. This JIRA will improve the log recovery logic and fix other bugs to enable message replication to happen in the presence of controlled server failures,,guozhang,jkreps,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jul/12 07:33;nehanarkhede;kafka-350-v1.patch;https://issues.apache.org/jira/secure/attachment/12536746/kafka-350-v1.patch","21/Jul/12 08:26;nehanarkhede;kafka-350-v2.patch;https://issues.apache.org/jira/secure/attachment/12537430/kafka-350-v2.patch","24/Jul/12 10:29;nehanarkhede;kafka-350-v3.patch;https://issues.apache.org/jira/secure/attachment/12537640/kafka-350-v3.patch","25/Jul/12 00:31;nehanarkhede;kafka-350-v4.patch;https://issues.apache.org/jira/secure/attachment/12537706/kafka-350-v4.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,248182,,,Tue Jul 24 18:12:37 UTC 2012,,,,,,,,,,"0|i09m2f:",54008,,,,,,,,,,,,,,,,,,,,"01/Jun/12 06:28;nehanarkhede;Handle the logic of deleting segments that have start offset > highwatermark during log recovery. ;;;","17/Jul/12 05:16;nehanarkhede;This patch contains fixes to bugs in various components to make message replication work in the presence of controlled server failures. The system test under system_test/single_host_multiple_brokers passes with server failures enabled. 

This patch contains the following changes -

1. Topic metadata request bug

1.1. While responding to a topic metadata request bug, the server uses the AdminUtils to query ZK for the host-port info for the leader and other replicas. However, it can happen that one of the brokers in the replica is offline and hence its broker registration in ZK is unavailable. Since the system test simulates exactly this scenario, the server's request handler thread was exiting due to a NoNodeException while reading the /brokers/ids/[id] path. The general problem seems to be handling error codes correctly in the request handlers and sending them to the client. I think once KAFKA-402 is resolved, all error codes will be handled cleanly by the server. For now, I've modified topic metadata response to have an error code per topic as well as per partition. So, if the leader is not available for some partitions, it will set the LeaderNotAvailable error code at the partition level. If some other replica is not available, it will set the ReplicaNotAvailable error code in the response instead of throwing an exception and exiting.
1.2. On the producer side, it fails the produce request retry if the leader for that partition is not available. It logs all other kinds of errors and ignores them. 
1.3. Changed some unit tests in AdminTest to elect a leader before making topic metadata requests, so that the test passes.
1.4. Fixed another bug in the deserialization of the topic metadata response that read the versionId and errorCode in incorrect order.
1.5. In DefaultEventHandler, during a retry, it relied on the topic cache inside BrokerPartitionInfo for refreshing topic metadata. However, if the topic cache is empty (when no previous send request has succeeded), it doesn't end up refreshing the metadata for the required topics in the produce request. Fixed this by passing the list of topics explicitly in the call to updateInfo()
1.6. In general, it seems like a good idea to have a global error code for the entire response (to handle global errors like illegal request format), then a per topic error code (to handle error codes like UnknownTopic), a per-partition error code (to handle partition-level error codes like LeaderNotAvailable) and also a per-replica error code (to handle ReplicaNotAvailable). Jun had a good suggestion about the format of TopicMetadata response. I would like to file another JIRA to improve the format of topic metadata request.

2. Bug in TestUtils waitUntilLeaderIsElected was signalling a condition object without acquiring the corresponding lock. This error message was probably getting masked since we had turned off ERROR log4j level for unit tests. Fixed this.

3. Log recovery
3.1. Removed the highWatermark() API in Log.scala, since we used “highwatermark” to indicate the offset of the latest message flushed to disk. This was causing the server to prevent the replicas from fetching unflushed data on the leader. With replication, we use highwatermark to denote the offset of the latest committed message. I removed all references to the older API (highWatermark). To remain consistent with setHW, I added an API called getHW. As I understand it, these APIs will be refactored/renamed to match conventions, when KAFKA354 is resolved
3.2. To handle truncating a log segment, I added a truncateUpto API that takes in the checkpointed highwatermark value for that partition,  computes the correct end offset for that log segment and truncates data after the computed end offset
3.3. Improved log recovery to delete segments that have start offset > highwatermark
3.4. Fixed logEndOffset to return the absolute offset of the last message in the log for that partition.
3.5. To limit the changes in this patch, it does not move the highwatermarks for all partitions to a single file. This will be done as part of KAFKA-405
3.6. Added a LogRecoveryTest to test recovery of log segments with and without failures

4. Config options
4.1. We might want to revisit the defaults for all config options. For example, the isr.keep.in.sync.time.ms defaulted to 30s which seems way too optimistic.  While running the system tests, most messages timed out since the isr.keep.in.sync.time.ms and the frequency of bouncing the replicas was also roughly 30s. The socket timeout for the producer also defaults to 30s which seems very long to block a producer for.
4.2.  The socket.timeout.ms should probably be set to producer.request.ack.timeout.ms, if it is a non-negative value. If producer.request.ack.timeout.ms  = -1, socket.timeout.ms should probably default to a meaningful value. While running the system test, I observed that the socket timeout was 30s and the producer.request.ack.timeout.ms was -1, which means that the producer would always block for 30s if the server failed to send back an ACK. Since the frequency of bouncing the brokers was also 30s, most produce requests were timing out.

5. Socket server bugs
5.1. A bug in processNewResponses() causes the SocketServer to process responses inspite of it going through a shutdown. It probably makes sense to let outstanding requests timeout and shutdown immediately
5.2. Another bug in processNewResponses() causes it to go in an infinite loop when the selection key processing throws an exception. It failed to move to the next key in this case. I fixed it by moving the next key processing in the finally block.

6. Moved the zookeeper client connection from startup() API in KafkaZookeeper to startup() API  in KafkaServer.scala. This is because the ReplicaManager is instantiated right after KafkaZookeeper and was passed in the zkclient object created by KafkaZookeeper. Since KafkaZookeeper started the zkclient only in startup() API, ReplicaManager's API's got NPE while trying to access the passed-in zkclient. With the fix, we can create the zookeeper client connection once in the KafkaServer startup, pass it around and tear it down in the shutdown API of KafkaServer. 

7. System testing
7.1. Hacked ProducerPerformance to turn off forceful use of the async producer. I guess ProducerPerformance has grown over time into a complex blob of if-else statements. Will file another JIRA to refactor it and fix it so that all config options work well with both sync and async producer.
7.2. Added producer ACK config options to ProducerPerformance. Right now, they are hardcoded. I'm hoping this can be fixed with the above JIRA. 
7.3. The single_host_multiple_brokers system test needs to be changed after KAFKA-353. Basically, it needs to count the successfully sent messages correctly. Right now, there is no good way to do this in the script. One way is to have the system test script grep the logs to find the successfully ACKed producer requests. To get it working for now, hacked it to use sync producer. Hence, before these issues are fixed it will be pretty slow.
7.4. Improved the system test to start the console consumer at the very end of the test for verification

8. Another thing that can be fixed in KAFKA-402 is the following -
8.1. When a broker gets a request for a partition for which it is not the leader, it should sent back a response with an error code immediately. Right now, I see a produce request timing out in LogRecoveryTest since the producer never gets a response. It doesn't break the test since the producer retries, but it is adding unnecessary delay.
8.2. In quite a few places, we log an error and then retry, or log an error which is actually meant to be a warning. Due to this, it is hard to spot real errors during testing. We can probably fix this too as part of KAFKA-402. 

8. Found a NPE while running ReplicaFetchTest. Would like to file a bug for it

9. Controller bugs 
9.1. Unit tests fail intermittently due to NoSuchElementException thrown by testZKSendWithDeadBroker() in KafkaController. Due to this, the zookeeper server doesn't shut down and rest of the unit tests fail. The root cause is absence of a broker id as a key in the java map. I think Scala maps should be used as it forces the user to handle invalid values cleanly through Option variables.
9.2. ControllerBasicTest tests throw tons of zookeeper warnings that complain a client not cleanly closing a zookeeper session. The sessions are forcefully closed only when the zookeeper server is shutdown. These warnings should be paid attention to and fixed. LogTest is also throwing similar zk warnings.
9.3. Since controller bugs were not in the critical path to getting replication-with-failures to work, I'd like to file another JIRA to fix it.

If the above future work sounds good, I will go ahead and file the JIRAs;;;","19/Jul/12 13:03;jkreps;This is a pretty hard to review due to the large number of changes and also because I don't know some of this code well.

A lot of things like bad logging/naming that I think you could probably catch just perusing the diff.

Log:
- Log should not know about hw right? We seem to be adding more hw stuff there?
- This adds a getHW() that just returns a private val, why not make the val public? Please fix these. Regardless of cleanup being done get/set methods have been against the style guide for a long time, lets not add more. Ditto getEndOffset() which in addition to being a getter is inconsistent with Log.logEndOffset
- There is debug statement in a for loop in Log.scala that needs to be removed
- I don't understand the difference between nextAppendOffset and logEndOffset. Can you make it clear in the javadoc and explain on why we need both of these. Our public interface to Log is getting incredibly complex, which is really sad so I think we should really think through deeply what is added here and why.
- The javadoc on line 138 of Log.scala doesn't match the style of javadoc for the preceeding 5 variables.

- Does making isr.keep.in.sync.time.ms more stringent actually make sense? 10 seconds is pretty tight. I think what you are saying is that every server bounce will introduce 30 seconds of latency. But I think that is kind of a weakness of our design. If we lower that timeout we may just get spurious dropped replicas, no?
- Can we change the name of isr.keep.in.sync.time.ms to replica.max.lag.time.ms?
- Good point about the socket timeouts. We can't set socket timeout equal to request timeout, though, as there may be a large network latency. I recommend we just default the socket timeout to something large (like 10x the request timeout), and throw an exception if it is less than the request timeout (since that is certainly wrong). I don't think we should be using the socket timeout except as an emergency escape for a totally hung broker now that we have the nice per-request timeout.
- Can we change producer.request.ack.timeout.ms to producer.request.timeout.ms so it is more intuitive? I don't think the word ""ack"" is going to be self-explanatory to users.

SocketServer.scala
- Please remove: info(""Shut down acceptor completed"")
- Is there a reason to add the port into the thread name? That seems extremely odd...is it to simplify testing where there are multiple servers on a machine?
- Why is it a bug for processNewResponses() to happen while a shutdown is occuring. I don't think that is a bug. That is called in the event loop. It is the loop that should stop, no? Is there any ill effect of this?
- Good catch on the infinite loop

System testing
- I think we should fix the performance test hacks. The performance tool is critical. I have watched this play out before. No one ever budgets time for making the performance test stuff usable and then it just gets re-written umpteen times and never does what is needed. Most of these are just a matter of some basic cleanup and adding options. Let's work clean.

AdminUtils
- I don't understand the change in getTopicMetaDataFromZK

Replica.scala
- Can you remove trace(""Returning leader replica for leader "" + leaderReplicaId) unless you think it is of value going forward

ErrorMapping.scala
- getMaxErrorCodeValue - seems to be recomputed for each TopicMetadata. Let's get rid of this, I don't think we need it. We already have an unknown entry in the mapping, we should use that and get rid of the Utils.getShortInRange
- If we do want to keep it, fix the name
- We should really give a base class KafkaException to all exceptions so the client can handle them more easily
- Instead of having the client get an IllegalArgumentException we should just throw new KafkaException(""Unknown server error (error code "" + code + "")"")
- The file NoLeaderForPartitionException seems to be empty now, I think you meant to delete it

ConsoleConsumer
- What does moving those things into a finally block do? We just caught all exceptions...

FileMessageSet
- You added more log spam. Please format it so it is intelligible to someone not working on the code or remove: debug(""flush size:"" + sizeInBytes())
- Ditto info(""recover upto size:"" + sizeInBytes())

BrokerPartitionInfos is a really weird class

DefaultEventHandler
- This seems to have grown into a big glump of proceedural logic.
- Inconsistent spacing of parens should be cleaned up
- partitionAndCollate is extemely complex
- Option[Map[Int, Map[(String, Int), Seq[ProducerData[K,Message]]]]]

ZkUtils
- LeaderExists class needs a name that is a noun
- Also we have a class with the same name in TopicMetadata

I really like TestUtils.waitUntilLeaderIsElected. God bless you for not adding sleeps. We should consider repeating this pattern for other cases like this.

ZooKeeperTestHarness.scala
- Can we replace the thread.sleep with a waitUntilZkIsUp call?

;;;","20/Jul/12 23:51;guozhang;Would it be better to have a general read/write formatting for boolean, like writeBoolean/readBoolean just like writeShortString/readShortString? Then we do not need to specify, for example, in TopicMetadata:

sealed trait LeaderRequest { def requestId: Byte }
case object LeaderExists extends LeaderRequest { val requestId: Byte = 1 }
case object LeaderDoesNotExist extends LeaderRequest { val requestId: Byte = 0 }


which would need to be done for every request/response that has a boolean.;;;","21/Jul/12 04:34;nehanarkhede;Thanks for the review, Jay ! Here is another patch fixing almost all review comments -

1. Log
1. Refactoring of the hw logic is part of KAFKA-405. It is moved to a new file HighwaterMarkCheckpoint and is controlled by the ReplicaManager. The Log does not and should not know about high watermarks.
2. Getter/setter for hw is removed as part of KAFKA-405 anyways.
3. Agree with you on the weak public interface, especially Log needs a cleanup. I think you attempted that as part of KAFKA-371. I've cleaned up quite a few things as part of KAFKA-405 and this patch. Nevertheless, fixed the nextAppendOffset as part of this patch. It is not required when we have logEndOffset. Also, removed the getEndOffset from FileMessageSet. Added endOffset() API to the LogSegment in addition to a size() API. This is useful during truncation of the log based on high watermark.
4. Fixed the javadoc and removed the debug statement.

2. Config options
1. The isr.keep.in.sync.time.ms set to 10 seconds is also very lax. A healthy follower should be able to catch up in 100s of milliseconds even with a lot of topics, with a worst case of maybe 4-5 seconds. We will know the latency better when we run some large scale tests. But yeah, the issue with the system test is independent of what the right value should be. I was just explaining how I discovered this issue. :)
2. Good point about renaming it to replica.max.lag.time.ms. Also changed isr.keep.in.sync.bytes to replica.max.lag.bytes.
3. Since the producer does a blocking read on the socket, the socket timeout cannot be greater than the request timeout. If it is, then the request timeout guarantee would be violated, no ?

3. SocketServer.scala
1. Removed info log statement
2. Yes, wanted to simplify testing/debugging (thread dumps) when there are multiple servers on one machine. Not sure if this is the best way to do that.
3. processNewResponses() doesn't have to process outstanding requests during shutdown. It can shutdown by ignoring them and those requests will timeout anyways. But yes, good point about the event loop doing it instead. Fixed it.

4. System testing
1. Fixed the hacky change. I still need ProducerPerformance needs a complete redo. Filed bug KAFKA-408 to do that.

5. AdminUtils
1. Need this change to return appropriate error codes for topic metadata request. Without this, all produce requests are timing out while fetching metadata, since in the system test, at any point of time, one replica is always down.

6. Partition.scala
1. Removed the trace statement.

7. ErrorMapping
1. Removed getMaxErrorCode and its usage from ErrorMapping
2. Good point. Introduced a new class KafkaException and converted IllegalStateException and IllegalArgumentException to it.
3. NoLeaderForPartitionException is in fact marked as deleted in the patch

8. ConsoleConsumer
1. Good point. The finally block there didn't really make any sense.

9. FileMessageSet
1. I haven't added the log statements in this patch, we always had it. 
2. The purpose of adding that was help with debugging producer side queue full exceptions. We turned on DEBUG to see what the server side flush sizes and latencies were. I think these statements were added when we didn't have an ability to monitor these. However, whoever added the log flush monitoring maybe forgot to remove these statements. I removed it in this patch.
3. Removed the “recover upto” log statement too

10. DefaultEventHandler
1. Agree with the unwieldly procedural code. Filed bug KAFKA-409 to clean this up. 

11. ZkUtils
1. Renamed LeaderExists -> LeaderExistsListener

12. ZookeeperTestHarness
1. The sleep is actually not required. The EmbeddedZookeeper constructor returns only after the zk server is completely started.;;;","24/Jul/12 00:03;junrao;Thanks for patch v2. Some comments:

20. PartitionMetadata: Could we make getLeaderRequest() private?

21. DefaultEventHandler.partitionAndCollate(): Is it necessary for this method to return an Option? It seems that if this method hits any exception, it's simpler to just pass on the exception and let the caller deal with it. 

22. LogSegment: Ideally this class should only deal with offsets local to the segment. Global offsets are only used at the Log level. So it's probably better to use local offset in the input of truncateUpto(). Similarly, we probably don't need endOffset since it returns global offset. If we do want to keep it, it probably should be named globalEndOffset.

23. Log: Since we removed the HW check in FileMessageSet.read. We will need to add a guard in Log.read() so that we only expose messages up to HW to the consumer.

24. LogManager: remove unused import

25. ControllerChannelManager.removeBroker: the error message is not correct since this method is called in places other than shutdown too.

26. system_test/single_host_multi_brokers/bin/run-test.sh: We should remove comments saying ""If KAFKA-350 is fixed"".

27. Unit tests pass on my desktop but fail on my laptop at the following test consistently. Without the patch, unit tests pass on my laptop too. This seems to be due to the change in ZooKeeperTestHarness.
[info] Test Starting: testFetcher(kafka.consumer.FetcherTest)
[error] Test Failed: testFetcher(kafka.consumer.FetcherTest)
org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 2000
	at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:876)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:98)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:84)
	at kafka.zk.ZooKeeperTestHarness$class.setUp(ZooKeeperTestHarness.scala:31)
	at kafka.consumer.FetcherTest.kafka$integration$KafkaServerTestHarness$$super$setUp(FetcherTest.scala:35)
	at kafka.integration.KafkaServerTestHarness$class.setUp(KafkaServerTestHarness.scala:35)
	at kafka.consumer.FetcherTest.setUp(FetcherTest.scala:57)
;;;","24/Jul/12 00:31;jkreps;1.1, 1.2, 2.1, 2.2 Awesome!

2.3 Hmm, well so but that doesn't make sense because we would always pop the socket timeout and fully close out the connection, which is not good. Basically the socket timeout would ALWAYS go off before the server-side request processing timeout due to the network latency both ways. I think that timeout should just be for ""emergencies"". I agree it is a bit of a muddle now that we have two.

7.2 Hmm, but that changed ALL IllegalStateExceptions to KafkaException. IllegalStateException is used to say ""this should not be possible"". For example in SocketServer those checks are in the form of assertions. I like the idea of KafkaException, and I think we should make all the other exceptions extend it to ease error handling on the client, but I don't think we should get rid of IllegalStateException or IllegalArgumentException, they are informative.
;;;","24/Jul/12 10:29;nehanarkhede;Thanks for the review !

Jun's comments -

20. Made getLeaderRequest and getLogSegmentMetadataRequest private
21. partitionAndCollate() is used by dispatchSerializedData() API. The contract of dispatchSerializedData() is to return the list of messages that were not sent successfully so that they can be used on the next retry. Now, if partitionAndCollate() fails, we need dispatchSerializedData to return the entire input list of messages. If something else fails after partitionAndCollate, we need to return a filtered list of messages back. To handle this, partitionAndCollate returns an Option. I agree that this class has very complex code that needs a cleanup. Have filed KAFKA-409 for that.
22. We need to know the absolute end offset of the segment for truncation during make follower state change. Have changed the name of the API to absoluteEndOffset. 
23. We have KAFKA-376 filed to ensure that the consumer sees data only after the HW. This patch exposes data upto log end offset to replicas as well as consumers. So FileMessageSet.read() exposes all data upto log end offset.
24. Removed unused import.
25. Hmm, fixed the error message
26. Removed the TODOs related to KAFKA-350
27. Introduced the connection timeout and session timeout variables in the test harness and set it to 6s. 

Jay's comments -

2.3 So we talked about this offline, stating it here so that others can follow. There are 2 choices here -
2.3.1. One is to keep request timeout = socket timeout. This would make us fully dependent on the socket for the timeout. So, any requests that took longer than that on the server for some reason (GC, bugs etc), would throw SocketTimeoutException on the producer client. The only downside to this is that the producer client wouldn't know why it failed or whether it got written to 0 or 1 or n replicas. Al though, this should be very rare and in the normal case, the server process the request and be able to send the response within the timeout. This is assuming the timeout value was set counting the network delay as well. So if the request is travelling cross-colo, it is expected that you set the timeout keeping in mind the cross-colo network latency. 
2.3.2. The second choice is to set the socket timeout >> request timeout. This would ensure that in some rare failure cases on the server, the producer client would still be able to get back a response (most of the times) with a descriptive error message explaining the cause of the failure. However, it would also mean that under some failures like (server side kernel bug crashing the server etc), the timeout would actually be the socket timeout, which is usually set to a much higher value. This can confuse users who might expect the timeout to be the request timeout. Also, having two different timeouts also seems to complicate the guarantees provided by Kafka 
2.3.3. I personally think option 1 is simpler and provides no worse guarantees than option 2. This patch just sets the socket timeout to be the request timeout. 

2.4 Yeah, I think differentiating between “this should not be possible” and “this should not be possible in Kafka” is a little tricky. On one hand, it seems nicer to know that any exception thrown by Kafka will either be KafkaException or some exception that extends KafkaException. On the other hand, some states are just impossible and must be treated like assertions, for example, a socketchannel key that is not readable or writable or even valid. And in such cases, it might be slightly more convenient to have IllegalStateException. And I'm not sure I know the right answer here. I took a pass over all the IllegalStateException usages and converted the ones I think should be KafkaException, but I might not have done it in the best way possible.
;;;","24/Jul/12 15:27;junrao;Thanks for patch v3. 

For 21, my point is that the exceptions that can be thrown in partitionAndCollate() are non-recoverable and therefore retries won't help. partitionAndCollate() won't throw NoBrokersForPartitionException since only BrokerPartitionInfo.updateInfo can throw such an exception and updateInfo is not called here. partitionAndCollate() throws InvalidPartitionException that indicates a wrong partition of a topic. If we just retry, we will hit the same exception and fail again. It's simpler to just throw an exception and treat it as a failed case. Ditto for other exceptions that partitionAndCollate() may throw.

A few new comments:
30. SyncProducerConfig.requestTimeoutMs: We should make sure that the value is a positive integer and change the comment accordingly.

31. IteraterTemplate: The two KafkaExceptions are better reverted to IllegalStateException.

32. ProducerPerformance: We should remove socketTimeoutMsOpt.

33. SocketServer: no need to import illegalStateException

34. I got the following exception when running system_test/single_host_multi_brokers/bin/run-test.sh

2012-07-24 00:22:51 cleaning up kafka server log/data dir
2012-07-24 00:22:53 starting zookeeper
2012-07-24 00:22:55 starting cluster
2012-07-24 00:22:55 starting kafka server
2012-07-24 00:22:55   -> kafka_pids[1]: 75282
2012-07-24 00:22:55 starting kafka server
2012-07-24 00:22:55   -> kafka_pids[2]: 75286
2012-07-24 00:22:55 starting kafka server
2012-07-24 00:22:55   -> kafka_pids[3]: 75291
2012-07-24 00:22:57 creating topic [mytest] on [localhost:2181]
creation failed because of org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /brokers/ids
org.I0Itec.zkclient.exception.ZkNoNodeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /brokers/ids
	at org.I0Itec.zkclient.exception.ZkException.create(ZkException.java:47)
	at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:685)
	at org.I0Itec.zkclient.ZkClient.getChildren(ZkClient.java:413)
	at org.I0Itec.zkclient.ZkClient.getChildren(ZkClient.java:409)
	at kafka.utils.ZkUtils$.getChildren(ZkUtils.scala:363)
	at kafka.utils.ZkUtils$.getSortedBrokerList(ZkUtils.scala:80)
	at kafka.admin.CreateTopicCommand$.createTopic(CreateTopicCommand.scala:86)
	at kafka.admin.CreateTopicCommand$.main(CreateTopicCommand.scala:73)
	at kafka.admin.CreateTopicCommand.main(CreateTopicCommand.scala)
Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /brokers/ids
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:102)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:42)
	at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1249)
	at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1277)
	at org.I0Itec.zkclient.ZkConnection.getChildren(ZkConnection.java:99)
	at org.I0Itec.zkclient.ZkClient$2.call(ZkClient.java:416)
	at org.I0Itec.zkclient.ZkClient$2.call(ZkClient.java:413)
	at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
	... 7 more
;;;","25/Jul/12 00:31;nehanarkhede;
21. Not really. updateInfo() is not the only API that throws NoBrokersForPartitionException. partitionAndCollate can encounter that exception while calling the getPartitionListForTopic() API.  But you raised a good point here. What partitionAndCollate() should do (given its current design) is to log a retry warning for recoverable exceptions and return None, so that they are included in the retry. For non-recoverable exceptions, it should just throw the exception to the handle API and mark it failed.

30. Added an error message for non-positive values for request timeout. Al though a value of zero means infinite timeout
31. I guess so. Changed it back to IllegalStateException
32. Removed socket timeout related stuff from ProducerPerformance
33. Removed the import.
34. Hmm, that can happen if you try to create a topic when the brokers haven't yet registered in zookeeper. The system tests waits for 2 seconds, which should be enough for couple of brokers to startup in the normal case. I haven't been able to reproduce this. Its possible that this is something that can be fixed in the system test. File a bug if you see it.;;;","25/Jul/12 01:59;junrao;Thanks for patch v4. We are almost there.

21. In partitionAndCollate(), UnknownTopicException doesn't seem to recoverable.

30. It doesn't look like the broker handles requestTimeoutMs of 0 through RequestPurgatory. It's probably simpler if we just require timeout to be positive. If someone wants infinite timeout, MAX_INT can be used instead.

If those issues are addressed, the patch can be committed without another round of review.

34. This seems to only happen on my laptop. Will file another jira. ;;;","25/Jul/12 02:12;nehanarkhede;21. It is recoverable when there is auto create topic enabled on the server. Until we get rid of auto create, I think we can keep this. 
30. Changed it to be non-negative and non-zero

Committing it with these changes.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A bug in the iterator of the ByteBufferMessageSet returns incorrect offsets when it encounters a compressed empty message set,KAFKA-111,12519279,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,nehanarkhede,nehanarkhede,18/Aug/11 18:56,13/Sep/11 09:28,22/Mar/23 15:10,13/Sep/11 09:28,0.7,,,,,,0.7,,,,,,,,,,,0,,,,,,"The deep iterator logic in the ByteBufferMessageSet returns incorrect offsets when it encounters empty compressed data. Ideally, it should be able to decompress the data, figure out that it is somehow empty, skip it and proceed to decoding rest of the data. To make this possible, the manner in which we update the offset to be returned by the iterator, needs to be tweaked.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/11 19:04;nehanarkhede;KAFKA-111.patch;https://issues.apache.org/jira/secure/attachment/12490784/KAFKA-111.patch","19/Aug/11 02:11;junrao;kafka-111.patch.v2;https://issues.apache.org/jira/secure/attachment/12490832/kafka-111.patch.v2","19/Aug/11 03:51;junrao;kafka-111.patch.v3;https://issues.apache.org/jira/secure/attachment/12490843/kafka-111.patch.v3",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,60816,,,Thu Aug 18 19:51:46 UTC 2011,,,,,,,,,,"0|i15yz3:",242966,,,,,,,,,,,,,,,,,,,,"18/Aug/11 19:04;nehanarkhede;This patch corrects the offset management in the deep iterator of the ByteBufferMessageSet, to handle the case of compressed empty message sets.;;;","19/Aug/11 00:01;junrao;1. Please remove unreferenced imports before checking in.
2. The following unit test now hangs.
Test Starting: testCompression(kafka.consumer.ZookeeperConsumerConnectorTest);;;","19/Aug/11 00:29;junrao;The patch in kafka-108 also identifies this problem. The problem is that we need to set the new offset in 2 cases: (1) if the compressed unit is empty; (2) otherwise, the last message of the compressed unit is being iterated. This patches covers (1), but not (2). One solution is probably to use the code that we had before, but treat case (1) specially, i.e., we won't even create an inner iterator and just advance the offset.;;;","19/Aug/11 02:11;junrao;How about patch v2? It currently breaks PrimitiveApiTest. However, the test probably should be fixed since it includes an empty message set.;;;","19/Aug/11 03:24;nehanarkhede;Yes, looks like patch v2 is a better way of handling the above 2 cases. We should check what breaks with PrimitiveApiTest though, maybe just a test bug.;;;","19/Aug/11 03:51;junrao;Patch v3. Fix test in kafka.javaapi.message.ByteBufferMessageSetTest.

PrimitiveApiTest for javaapi still fails. However, it should pass after kafka-109 is fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
new producer performance and bug improvements,KAFKA-1498,12722599,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,junrao,junrao,20/Jun/14 05:31,03/Sep/14 07:05,22/Mar/23 15:10,03/Sep/14 07:05,,,,,,,,,,,,,,core,,,,0,,,,,,"We have seen the following issues with the new producer.

1. The producer request can be significantly larger than the configured batch size.
2. The bottleneck in mirrormaker when there are keyed messages and compression is turned on.
3. The selector is woken up on every message in the new producer.
",,guozhang,junrao,kbanker,ross.black,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jul/14 05:40;guozhang;KAFKA-1498.patch;https://issues.apache.org/jira/secure/attachment/12653474/KAFKA-1498.patch","24/Jun/14 01:54;guozhang;KAFKA-1498.patch;https://issues.apache.org/jira/secure/attachment/12652011/KAFKA-1498.patch","26/Jun/14 07:45;guozhang;KAFKA-1498_2014-06-25_16:44:51.patch;https://issues.apache.org/jira/secure/attachment/12652522/KAFKA-1498_2014-06-25_16%3A44%3A51.patch","01/Jul/14 01:47;guozhang;KAFKA-1498_2014-06-30_10:47:17.patch;https://issues.apache.org/jira/secure/attachment/12653189/KAFKA-1498_2014-06-30_10%3A47%3A17.patch","01/Jul/14 06:48;guozhang;KAFKA-1498_2014-06-30_15:47:56.patch;https://issues.apache.org/jira/secure/attachment/12653257/KAFKA-1498_2014-06-30_15%3A47%3A56.patch","02/Jul/14 02:12;guozhang;KAFKA-1498_2014-07-01_11:12:41.patch;https://issues.apache.org/jira/secure/attachment/12653432/KAFKA-1498_2014-07-01_11%3A12%3A41.patch","20/Jun/14 05:34;junrao;kafka-1498.patch;https://issues.apache.org/jira/secure/attachment/12651500/kafka-1498.patch",,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,400790,,,Tue Jul 01 21:40:38 UTC 2014,,,,,,,,,,"0|i1wzon:",400880,,,,,,,,,,,,,,,,,,,,"20/Jun/14 05:34;junrao;Attach a draft patch of revision dcc88408c98a07cb9a816ab55cd81e55f1d2217d on Jun. 10.

Included in the patch:
1. Address the issue that a batch in the producer request can be significantly larger than the configured batch size.
This is done by patching MemoryRecords.hasRoom() and MemoryRecords.isFull().
2. Address the bottleneck in mirrormaker when there are keyed messages and compression is turned on.
Use a data channel per producer thread.
3. Address the issue that the selector is woken up on every message in the new producer. This is the trickiest part. The fix is the following.
(a) In KafkaProducer.send(), only wake up the selector if the batch becomes full during append.
(b) In Metadata.fetch(), force the selector to wake up if metadata is not available.
(c) In sender, calculate the select time dynamically in each iteration of the selector.poll() call. The select time is the minimal of the remaining linger time of all partitions and the metadata request. The select time is bounded by linger time. This is to handle the case that the selector is doing a long poll, a new messages is produced and no new messages come afterwards. We need to make sure that the message can be processed within the linger time.

This cover the following cases well.
3.1. If linger time is larger and there are lots of messages, the selector won't be woke up too frequently.
3.2. If linger time is small and there are lots of messages, the selector will be busy. However, this is expected.

This doesn't deal with the following case well.
3.3 If linger time is small and there are very few messages, the selector will still wake up every linger time. Not sure what's the best way to deal with this. One thing that I was thinking is to have a min_linger threshold. The selector will use a select time at least of min_linger, say 5ms, if there is nothing to do. In KafkaProducer.send(), if linger is configured to be larger than min_linger, wake up the selector on every message. This way, the selector will only be busy if there are lots of messages.

Not sure that I have thought through other potential timing issues.

4. Added a few missing ingraphs.

Other todos:
1. Metadata.needsUpdate should be renamed properly.
2. Methods with new parameters need new comments accordingly.
3. Metrics
3.1 In addition to record-size-max, add record-size-avg.
3.2 Rename incoming-bytes-rate and outgoing-bytes-rate to network-in-bytes-rate and network-out-bytes-rate
;;;","24/Jun/14 01:54;guozhang;Created reviewboard https://reviews.apache.org/r/22874/
 against branch origin/trunk;;;","26/Jun/14 07:45;guozhang;Updated reviewboard https://reviews.apache.org/r/22874/
 against branch origin/trunk;;;","01/Jul/14 01:47;guozhang;Updated reviewboard https://reviews.apache.org/r/22874/
 against branch origin/trunk;;;","01/Jul/14 06:48;guozhang;Updated reviewboard https://reviews.apache.org/r/22874/
 against branch origin/trunk;;;","02/Jul/14 02:12;guozhang;Updated reviewboard https://reviews.apache.org/r/22874/
 against branch origin/trunk;;;","02/Jul/14 05:40;guozhang;Created reviewboard https://reviews.apache.org/r/23215/
 against branch origin/trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka-topics.sh exits with 0 status on failures,KAFKA-2198,12830716,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,omkreddy,rthalley,rthalley,18/May/15 23:24,11/Jan/16 23:17,22/Mar/23 15:10,14/Jul/15 14:04,0.8.2.1,,,,,,0.9.0.0,,,,,,,admin,,,,0,,,,,,"In the two failure cases below, kafka-topics.sh exits with status 0.  You shouldn't need to parse output from the command to know if it failed or not.

Case 1: Forgetting to add Kafka zookeeper chroot path to zookeeper spec

$ kafka-topics.sh --alter --topic foo --config min.insync.replicas=2 --zookeeper 10.0.0.1 && echo succeeded
succeeded

Case 2: Bad config option.  (Also, do we really need the java backtrace?  It's a lot of noise most of the time.)

$ kafka-topics.sh --alter --topic foo --config min.insync.replicasTYPO=2 --zookeeper 10.0.0.1/kafka && echo succeeded
Error while executing topic command requirement failed: Unknown configuration ""min.insync.replicasTYPO"".
java.lang.IllegalArgumentException: requirement failed: Unknown configuration ""min.insync.replicasTYPO"".
    at scala.Predef$.require(Predef.scala:233)
    at kafka.log.LogConfig$$anonfun$validateNames$1.apply(LogConfig.scala:183)
    at kafka.log.LogConfig$$anonfun$validateNames$1.apply(LogConfig.scala:182)
    at scala.collection.Iterator$class.foreach(Iterator.scala:727)
    at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
    at kafka.log.LogConfig$.validateNames(LogConfig.scala:182)
    at kafka.log.LogConfig$.validate(LogConfig.scala:190)
    at kafka.admin.TopicCommand$.parseTopicConfigsToBeAdded(TopicCommand.scala:205)
    at kafka.admin.TopicCommand$$anonfun$alterTopic$1.apply(TopicCommand.scala:103)
    at kafka.admin.TopicCommand$$anonfun$alterTopic$1.apply(TopicCommand.scala:100)
    at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
    at kafka.admin.TopicCommand$.alterTopic(TopicCommand.scala:100)
    at kafka.admin.TopicCommand$.main(TopicCommand.scala:57)
    at kafka.admin.TopicCommand.main(TopicCommand.scala)

succeeded",,gwenshap,omkreddy,rthalley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2685,,,,,,,,,,,,,,,,,,"19/May/15 17:19;omkreddy;KAFKA-2198.patch;https://issues.apache.org/jira/secure/attachment/12733761/KAFKA-2198.patch","19/May/15 20:59;omkreddy;KAFKA-2198_2015-05-19_18:27:01.patch;https://issues.apache.org/jira/secure/attachment/12733807/KAFKA-2198_2015-05-19_18%3A27%3A01.patch","19/May/15 21:14;omkreddy;KAFKA-2198_2015-05-19_18:41:25.patch;https://issues.apache.org/jira/secure/attachment/12733810/KAFKA-2198_2015-05-19_18%3A41%3A25.patch","11/Jul/15 00:35;omkreddy;KAFKA-2198_2015-07-10_22:02:02.patch;https://issues.apache.org/jira/secure/attachment/12744741/KAFKA-2198_2015-07-10_22%3A02%3A02.patch","11/Jul/15 01:44;omkreddy;KAFKA-2198_2015-07-10_23:11:23.patch;https://issues.apache.org/jira/secure/attachment/12744752/KAFKA-2198_2015-07-10_23%3A11%3A23.patch","13/Jul/15 21:57;omkreddy;KAFKA-2198_2015-07-13_19:24:46.patch;https://issues.apache.org/jira/secure/attachment/12745038/KAFKA-2198_2015-07-13_19%3A24%3A46.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jul 14 05:09:36 UTC 2015,,,,,,,,,,"0|i2evk7:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"19/May/15 17:19;omkreddy;Created reviewboard https://reviews.apache.org/r/34403/diff/
 against branch origin/trunk;;;","19/May/15 17:28;omkreddy;Case 1: Zookeeper chroot path is optional.  Currently --zookeeper options accepts 10.0.0.1, 10.0.0.1:2181, 10.0.0.1:2181/kafka, 10.0.0.1/kafka formats

Case 2: Uploaded a simple patch which returns non-zero status on failures. I am not sure about the printing stacktrace. let the commiter can decide about it.;;;","19/May/15 20:30;rthalley;I realize that the chroot path is optional, but it's still a bug that the command does nothing.  The request is to alter an existing topic, but there is no such topic.  It makes no changes to zookeeper and exits with status 0.  A better error would be ""no Kafka configuration in directory /"" or ""topic 'foo' not found in '/config/topics'"".
;;;","19/May/15 21:00;omkreddy;Updated reviewboard https://reviews.apache.org/r/34403/diff/
 against branch origin/trunk;;;","19/May/15 21:14;omkreddy;Updated reviewboard https://reviews.apache.org/r/34403/diff/
 against branch origin/trunk;;;","19/May/15 21:16;omkreddy;Agreed. This has been fixed on trunk (KAFKA-1668). ;;;","11/Jul/15 00:35;omkreddy;Updated reviewboard https://reviews.apache.org/r/34403/diff/
 against branch origin/trunk;;;","11/Jul/15 00:36;omkreddy;[~junrao] pinging for review;;;","11/Jul/15 00:47;gwenshap;Hope its ok if I review this, [~omkreddy].;;;","11/Jul/15 00:47;gwenshap;Also, [~omkreddy], since the complaint is about usability, can you post sample output of the cases shown above? so we can show the improvement?;;;","11/Jul/15 01:40;omkreddy;[~gwenshap] Thanks for the review.  Sample output is given below.

{code}
sh kafka-topics.sh --alter --topic UNKNOWN -config min.insync.replicas=2 --zookeeper localhost && echo succeeded
Error while executing topic command : Topic UNKNOWN does not exist on ZK path localhost
[2015-07-10 22:59:01,808] ERROR java.lang.IllegalArgumentException: Topic UNKNOWN does not exist on ZK path localhost
	at kafka.admin.TopicCommand$.alterTopic(TopicCommand.scala:104)
	at kafka.admin.TopicCommand$.main(TopicCommand.scala:56)
	at kafka.admin.TopicCommand.main(TopicCommand.scala)
 (kafka.admin.TopicCommand$)
{code}
{code}
$ sh kafka-topics.sh --alter --topic EVENT --config min.insync.replicasTYPO=2 --zookeeper localhost && echo succeeded
Error while executing topic command : requirement failed: Unknown configuration ""min.insync.replicasTYPO"".
[2015-07-10 23:02:04,273] ERROR java.lang.IllegalArgumentException: requirement failed: Unknown configuration ""min.insync.replicasTYPO"".
	at scala.Predef$.require(Predef.scala:233)
	at kafka.log.LogConfig$$anonfun$validateNames$1.apply(LogConfig.scala:185)
	at kafka.log.LogConfig$$anonfun$validateNames$1.apply(LogConfig.scala:184)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at kafka.log.LogConfig$.validateNames(LogConfig.scala:184)
	at kafka.log.LogConfig$.validate(LogConfig.scala:192)
	at kafka.admin.TopicCommand$.parseTopicConfigsToBeAdded(TopicCommand.scala:217)
	at kafka.admin.TopicCommand$$anonfun$alterTopic$1.apply(TopicCommand.scala:110)
	at kafka.admin.TopicCommand$$anonfun$alterTopic$1.apply(TopicCommand.scala:107)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at kafka.admin.TopicCommand$.alterTopic(TopicCommand.scala:107)
	at kafka.admin.TopicCommand$.main(TopicCommand.scala:56)
	at kafka.admin.TopicCommand.main(TopicCommand.scala)
 (kafka.admin.TopicCommand$)
{code};;;","11/Jul/15 01:44;omkreddy;Updated reviewboard https://reviews.apache.org/r/34403/diff/
 against branch origin/trunk;;;","13/Jul/15 21:57;omkreddy;Updated reviewboard https://reviews.apache.org/r/34403/diff/
 against branch origin/trunk;;;","14/Jul/15 13:09;gwenshap;Thanks for the patch! pushed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in FileMessageSet's append API can corrupt on disk log,KAFKA-309,12546933,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,18/Mar/12 09:14,23/Mar/12 00:59,22/Mar/23 15:10,23/Mar/12 00:59,0.7,,,,,,,,,,,,,core,,,,0,,,,,,"In FileMessageSet's append API, we write a ByteBufferMessageSet to a log in the following manner -

    while(written < messages.sizeInBytes)
      written += messages.writeTo(channel, 0, messages.sizeInBytes)

In ByteBufferMessageSet, the writeTo API uses buffer.duplicate() to append to a channel -

  def writeTo(channel: GatheringByteChannel, offset: Long, size: Long): Long =
    channel.write(buffer.duplicate)

If the channel doesn't write the ByteBuffer in one call, then we call it again until sizeInBytes bytes are written. But the next call will use buffer.duplicate() to write to the FileChannel, which will write the entire ByteBufferMessageSet again to the file. 

Effectively, we have a corrupted set of messages on disk. 

Thinking about it, FileChannel is a blocking channel, so ideally, the entire ByteBuffer should be written to the FileChannel in one call. I wrote a test (attached here) and saw that it does. But I'm not aware if there are some corner cases when it doesn't do so. In those cases, Kafka will end up corrupting on disk log segment.
",,kzadorozhny,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-308,,,,,"18/Mar/12 09:18;nehanarkhede;kafka-309-test.patch;https://issues.apache.org/jira/secure/attachment/12518815/kafka-309-test.patch","22/Mar/12 08:03;nehanarkhede;kafka-309.patch;https://issues.apache.org/jira/secure/attachment/12519384/kafka-309.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,232091,,,Thu Mar 22 16:08:31 UTC 2012,,,,,,,,,,"0|i0rsav:",160229,,,,,,,,,,,,,,,,,,,,"18/Mar/12 09:18;nehanarkhede;The test includes a FileChannelTest that writes byte buffer of varying lengths to a file channel in a single call and checks if the buffer was completely written.;;;","20/Mar/12 05:34;nehanarkhede;This can potentially cause the log corruption described in KAFKA-308;;;","22/Mar/12 08:03;nehanarkhede;This patch changes the writeTo API of the ByteBufferMessageSet to use the message set's buffer to write to the FileChannel. The writeTo API does *not* change the underlying buffer's position marker. 

The right fix might be to not call ByteBufferMessageSet's writeTo in a loop in FileMessageSet's append API, since the guarantee of a blocking channel would not allow it to return without writing the entire message set or throwing an error. But that fix is arguably higher risk, so punting it for now, until we fully understand the guarantees of FileChannel;;;","23/Mar/12 00:08;junrao;+1 on the patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in LogOffsetTest,KAFKA-1377,12707499,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,10/Apr/14 01:10,24/Nov/16 03:25,22/Mar/23 15:10,24/Nov/16 03:25,,,,,,,,,,,,,,core,,,,0,newbie,,,,,"Saw the following transient unit test failure.

kafka.server.LogOffsetTest > testGetOffsetsBeforeEarliestTime FAILED
    junit.framework.AssertionFailedError: expected:<List(0)> but was:<Vector()>
        at junit.framework.Assert.fail(Assert.java:47)
        at junit.framework.Assert.failNotEquals(Assert.java:277)
        at junit.framework.Assert.assertEquals(Assert.java:64)
        at junit.framework.Assert.assertEquals(Assert.java:71)
        at kafka.server.LogOffsetTest.testGetOffsetsBeforeEarliestTime(LogOffsetTest.scala:198)
",,guozhang,ijuma,junrao,nehanarkhede,omkreddy,pyritschard,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Apr/14 09:22;junrao;KAFKA-1377.patch;https://issues.apache.org/jira/secure/attachment/12639504/KAFKA-1377.patch","12/Apr/14 08:42;junrao;KAFKA-1377_2014-04-11_17:42:13.patch;https://issues.apache.org/jira/secure/attachment/12639899/KAFKA-1377_2014-04-11_17%3A42%3A13.patch","12/Apr/14 09:14;junrao;KAFKA-1377_2014-04-11_18:14:45.patch;https://issues.apache.org/jira/secure/attachment/12639903/KAFKA-1377_2014-04-11_18%3A14%3A45.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,385822,,,Wed Nov 23 19:25:38 UTC 2016,,,,,,,,,,"0|i1ugsf:",386086,,,,,,,,,,,,,,,,,,,,"10/Apr/14 01:12;junrao;Not sure the exact cause. One potential issue that I saw is the following. We call
    waitUntilTrue(() => isLeaderLocalOnBroker(topic, part, server), 1000)
before the assertion. However, if waitUntilTrue returns false. We proceed. We should add the assertion on waitUntilTrue and probably increase the wait time.;;;","10/Apr/14 09:22;junrao;Created reviewboard https://reviews.apache.org/r/20186/
 against branch origin/trunk;;;","12/Apr/14 08:42;junrao;Updated reviewboard https://reviews.apache.org/r/20186/
 against branch origin/trunk;;;","12/Apr/14 09:14;junrao;Updated reviewboard https://reviews.apache.org/r/20186/
 against branch origin/trunk;;;","13/Apr/14 04:47;junrao;Thanks for the review. Committed to trunk.;;;","12/Jul/14 18:09;omkreddy;LogOffsetTests are consistently failing on my machine.

kafka.server.LogOffsetTest > testGetOffsetsBeforeLatestTime FAILED
junit.framework.AssertionFailedError: Log for partition [topic,0] should be created
at junit.framework.Assert.fail(Assert.java:47)
at kafka.utils.TestUtils$.waitUntilTrue(TestUtils.scala:589)
at kafka.server.LogOffsetTest.testGetOffsetsBeforeLatestTime(LogOffsetTest.scala:85)

kafka.server.LogOffsetTest > testGetOffsetsBeforeEarliestTime FAILED
    junit.framework.AssertionFailedError: Leader should be elected
        at junit.framework.Assert.fail(Assert.java:47)
        at kafka.utils.TestUtils$.waitUntilTrue(TestUtils.scala:589)
        at kafka.server.LogOffsetTest.testGetOffsetsBeforeEarliestTime(LogOffsetTest.scala:188)

kafka.server.LogOffsetTest > testEmptyLogsGetOffsets FAILED
    junit.framework.AssertionFailedError: Partition [kafka,0] metadata not propagated after 5000 ms
        at junit.framework.Assert.fail(Assert.java:47)
        at kafka.utils.TestUtils$.waitUntilTrue(TestUtils.scala:589)
        at kafka.utils.TestUtils$.waitUntilMetadataIsPropagated(TestUtils.scala:629)
        at kafka.utils.TestUtils$$anonfun$createTopic$1.apply(TestUtils.scala:174)
        at kafka.utils.TestUtils$$anonfun$createTopic$1.apply(TestUtils.scala:173)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.immutable.Range$ByOne$class.foreach(Range.scala:285)
        at scala.collection.immutable.Range$$anon$2.foreach(Range.scala:265)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)
        at scala.collection.immutable.Range.map(Range.scala:39)
        at kafka.utils.TestUtils$.createTopic(TestUtils.scala:173)
        at kafka.server.LogOffsetTest.testEmptyLogsGetOffsets(LogOffsetTest.scala:122)

kafka.server.LogOffsetTest > testGetOffsetsBeforeNow FAILED
    junit.framework.AssertionFailedError: Leader should be elected
        at junit.framework.Assert.fail(Assert.java:47)
        at kafka.utils.TestUtils$.waitUntilTrue(TestUtils.scala:589)
        at kafka.server.LogOffsetTest.testGetOffsetsBeforeNow(LogOffsetTest.scala:160)
;;;","14/Jul/14 22:58;junrao;Is this on trunk? Thanks,;;;","14/Jul/14 23:25;omkreddy;Yes. I am observing these failures on trunk.;;;","18/Jul/14 02:37;nehanarkhede;[~junrao], reopening this as per [~omkreddy]'s observation;;;","05/Sep/14 05:40;guozhang;Pushing to 0.9 as for now, [~omkreddy] is it still a consistently reproducible issue on your side?;;;","05/Sep/14 23:25;omkreddy;Yes, these failures are consistent on my machine.

My machine configuration: 32 bit Ubuntu OS, i5 processor, 4GB
;;;","11/Feb/15 16:41;omkreddy;now i am not getting this exception..so closing the issue.;;;","21/Dec/15 18:14;pyritschard;I am getting these errors consistently.
This is against trunk on Linux. 64 bit, i7 processor 16G. JDK version:

java version ""1.8.0_60""
Java(TM) SE Runtime Environment (build 1.8.0_60-b27)
Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode)
;;;","21/Dec/15 19:26;pyritschard;FWIW, bumping the waitTime parameter in TestUtils.scala does not change the behavior, so this is not timing related (waiting for 15s instead of 5s still exhibits the same behavior).;;;","22/Dec/15 02:55;guozhang;[~pyritschard] Which Kafka version are you running for these tests?;;;","22/Dec/15 04:59;pyritschard;[~guozhang] I'm testing against trunk.
The failure to propagater results is confined to the Sasl tests.;;;","22/Dec/15 05:35;ijuma;[~pyritschard], this JIRA is about LogOffsetTest, if you are seeing other failures (ie Sasl related), please file a separate issue (in case it hasn't been filed already).;;;","22/Dec/15 06:00;pyritschard;[~ijuma] will do. it looked to me as a generalization of the previous problem.;;;","24/Nov/16 03:20;guozhang;[~ijuma] Is this still an issue? I cannot remember seeing this failure in recent Jenkins builds.;;;","24/Nov/16 03:25;ijuma;I haven't seen it, so closing it since the original reporter said it was fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in mirroring code causes mirroring to halt,KAFKA-225,12534563,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,nehanarkhede,nehanarkhede,10/Dec/11 08:09,14/Dec/11 08:09,22/Mar/23 15:10,14/Dec/11 08:09,0.7,,,,,,0.7.1,,,,,,,core,,,,0,,,,,,"The mirroring code has an API that restarts the consumer connector when a new topic watcher fires. This triggers a rebalancing operation in the consumer connector. But if this rebalancing operation fails, the mirroring code simply throws an exception and never recovers. Ideally, if the rebalancing operation fails due to n retries, we should shut down the mirror",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Dec/11 01:49;junrao;KAFKA-225.patch;https://issues.apache.org/jira/secure/attachment/12507211/KAFKA-225.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,220285,,,Wed Dec 14 00:09:28 UTC 2011,,,,,,,,,,"0|i15zdj:",243031,,,,,,,,,,,,,,,,,,,,"14/Dec/11 01:49;junrao;Patch attached.;;;","14/Dec/11 02:36;nehanarkhede;+1;;;","14/Dec/11 08:09;junrao;just committed this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sending to a new topic (with auto.create.topics.enable) returns ERROR,KAFKA-1124,12677835,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,jbrosenberg@gmail.com,jbrosenberg@gmail.com,07/Nov/13 02:32,20/Jan/15 18:51,22/Mar/23 15:10,20/Jan/15 18:51,0.8.0,0.8.1,,,,,0.8.2.0,,,,,,,,,,,2,usability,,,,,"I had thought this was reported issue, but can't seem to find a previous report for it.

If auto.create.topics.enable is true, a producer still gets an ERROR logged on the first attempt to send a message to a new topic, e.g.:

2013-11-06 03:00:08,638 ERROR [Thread-1] async.DefaultEventHandler - Failed to collate messages by topic, partition due to: Failed to fetch topic metadata for topic: mynewtopic
2013-11-06 03:00:08,638  INFO [Thread-1] async.DefaultEventHandler - Back off for 100 ms before retrying send. Remaining retries = 3

This usually clears itself up immediately on retry (after 100 ms), as handled by the the kafka.producer.async.DefaultEventHandler (with retries enabled).

However, this is logged to the client as an ERROR, and looks scary, when in fact it should have been a normal operation (since we have auto.create.topics.enable=true).

There should be a better interaction here between the producer client and the server.

Perhaps the server can create the topic in flight before returning the metadata request.

Or, if it needs to be asynchronous, it could return a code which indicates something like: ""The topic doesn't exist yet, it is being created, try again shortly"".....and have the client automatically retry (even if retries not enabled, since it's not an ERROR condition, really).

The ERROR log level is a problem since apps often have alert systems set up to notify when any ERROR happens, etc.....
",,anujmehta,chelseaz,guozhang,hanish.bansal.agarwal,hasrobin,jbrosenberg@gmail.com,jeffwidman,jjkoshy,jpotter,omkreddy,wangbo23,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,357210,,,Tue Jan 20 10:51:39 UTC 2015,,,,,,,,,,"0|i1pkvr:",357500,,,,,,,,,,,,,,,,,,,,"14/Nov/13 13:26;anujmehta;Hi

I tried reproducing this issue but I am getting a WARN message instead of an ERROR

[2013-11-13 18:24:59,310] WARN Error while fetching metadata [{TopicMetadata for topic newTopic -> 
No partition metadata for topic newTopic due to kafka.common.LeaderNotAvailableException}] for topic [newTopic]: class kafka.common.LeaderNotAvailableException  (kafka.producer.BrokerPartitionInfo);;;","14/Nov/13 22:47;jbrosenberg@gmail.com;[~anujmehta] are you looking in the logs for the producer, or the server?  The ERROR I see is in the producer.  It does go on to complain aobut LeaderNotAvailable, etc., but it also gives me the ERROR message.

I'm using 0.8, sha: cd3b79699341afb8d52c51d9ac7317d93c32eeb6  (dated Oct 16).  Which version are you using?

Jason;;;","19/Nov/13 20:00;anujmehta;Hi Jason Rosenberg 

Just checked again. Yes there is an ERROR message in producer logs. Let me check if I can fix this;;;","14/Jan/14 17:59;jbrosenberg@gmail.com;status?;;;","28/Mar/14 02:13;hasrobin;I'm running 0.8.1. and only run into this issue with auto created topic when replication-factor is greater than 1.  When topics are manually created, no errors.

[root@h-kafka01-1b.use01.ho.priv kafka]# ./bin/kafka-console-producer.sh --broker-list h-kafka01:9092,h-kafka02:9092,h-kafka03:9092 --topic RobinTest4
Test Message One, testing auto topic creation
[2014-03-26 23:25:24,253] WARN Error while fetching metadata [{TopicMetadata for topic RobinTest4 -> 
No partition metadata for topic RobinTest4 due to kafka.common.LeaderNotAvailableException}] for topic [RobinTest4]: class kafka.common.LeaderNotAvailableException  (kafka.producer.BrokerPartitionInfo)
[2014-03-26 23:25:24,289] WARN Error while fetching metadata [{TopicMetadata for topic RobinTest4 -> 
No partition metadata for topic RobinTest4 due to kafka.common.LeaderNotAvailableException}] for topic [RobinTest4]: class kafka.common.LeaderNotAvailableException  (kafka.producer.BrokerPartitionInfo)
[2014-03-26 23:25:24,290] ERROR Failed to collate messages by topic, partition due to: Failed to fetch topic metadata for topic: RobinTest4 (kafka.producer.async.DefaultEventHandler)
[2014-03-26 23:25:24,406] WARN Error while fetching metadata [{TopicMetadata for topic RobinTest4 -> 
No partition metadata for topic RobinTest4 due to kafka.common.LeaderNotAvailableException}] for topic [RobinTest4]: class kafka.common.LeaderNotAvailableException  (kafka.producer.BrokerPartitionInfo)
[2014-03-26 23:25:24,434] WARN Error while fetching metadata [{TopicMetadata for topic RobinTest4 -> 
No partition metadata for topic RobinTest4 due to kafka.common.LeaderNotAvailableException}] for topic [RobinTest4]: class kafka.common.LeaderNotAvailableException  (kafka.producer.BrokerPartitionInfo)
[2014-03-26 23:25:24,434] ERROR Failed to collate messages by topic, partition due to: Failed to fetch topic metadata for topic: RobinTest4 (kafka.producer.async.DefaultEventHandler)
[2014-03-26 23:25:24,545] WARN Error while fetching metadata [{TopicMetadata for topic RobinTest4 -> 
No partition metadata for topic RobinTest4 due to kafka.common.LeaderNotAvailableException}] for topic [RobinTest4]: class kafka.common.LeaderNotAvailableException  (kafka.producer.BrokerPartitionInfo)
[2014-03-26 23:25:24,561] WARN Error while fetching metadata [{TopicMetadata for topic RobinTest4 -> 
No partition metadata for topic RobinTest4 due to kafka.common.LeaderNotAvailableException}] for topic [RobinTest4]: class kafka.common.LeaderNotAvailableException  (kafka.producer.BrokerPartitionInfo)
[2014-03-26 23:25:24,561] ERROR Failed to collate messages by topic, partition due to: Failed to fetch topic metadata for topic: RobinTest4 (kafka.producer.async.DefaultEventHandler)
[2014-03-26 23:25:24,669] WARN Error while fetching metadata [{TopicMetadata for topic RobinTest4 -> 
No partition metadata for topic RobinTest4 due to kafka.common.LeaderNotAvailableException}] for topic [RobinTest4]: class kafka.common.LeaderNotAvailableException  (kafka.producer.BrokerPartitionInfo)
[2014-03-26 23:25:24,683] WARN Error while fetching metadata [{TopicMetadata for topic RobinTest4 -> 
No partition metadata for topic RobinTest4 due to kafka.common.LeaderNotAvailableException}] for topic [RobinTest4]: class kafka.common.LeaderNotAvailableException  (kafka.producer.BrokerPartitionInfo)
[2014-03-26 23:25:24,683] ERROR Failed to collate messages by topic, partition due to: Failed to fetch topic metadata for topic: RobinTest4 (kafka.producer.async.DefaultEventHandler)
[2014-03-26 23:25:24,817] ERROR Failed to send requests for topics RobinTest4 with correlation ids in [0,8] (kafka.producer.async.DefaultEventHandler)
[2014-03-26 23:25:24,819] ERROR Error in handling batch of 1 events (kafka.producer.async.ProducerSendThread)
kafka.common.FailedToSendMessageException: Failed to send messages after 3 tries.
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:90)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:104)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:87)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:67)
	at scala.collection.immutable.Stream.foreach(Stream.scala:526)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:66)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)

;;;","10/Apr/14 15:06;hanish.bansal.agarwal;Could it be handled by just changing the message level from Error to INFO and presenting some informative message?

If that so this issue can be released in 0.8.1.1 .;;;","10/Apr/14 23:04;jbrosenberg@gmail.com;Well, not sure if that will do the right thing when there really is an ERROR when a producer gets an error sending to a broker.  However, I think would would make sense, is to only log ERROR if we've run out of retry attempts and have truly given up on sending the message.  So, if it's a failure that will be retried, it could be logged as WARN or even INFO.  But I'm guessing that change is not specific to the initial auto-topic-creation case, it affects logging for all cases.  But yeah, I think that sounds good to me.;;;","10/Apr/14 23:18;guozhang;Hi Jason, in the new producer the retry would not log as an error, and only when all retries have exhausted it will report an error. While at the same time both retry rate and error rate will be reported in DMX. Would this resolve your problem?;;;","11/Apr/14 03:12;jbrosenberg@gmail.com;Yes, I think it sounds like it would......when is the 'new producer' going to be available?;;;","11/Apr/14 03:56;guozhang;The new producer is already available now in the clients package in trunk.;;;","11/Apr/14 05:32;jbrosenberg@gmail.com;when will it be part of the 'released' version of kafka?  Or it already there?  We're currently using 0.8.0 still....;;;","11/Apr/14 05:44;guozhang;It will be in the 0.9 release, whose timeline has not been finalized yet. But we are shooting for this fall.;;;","11/Apr/14 08:54;jjkoshy;We should have an 0.8.2 release before that which has the new producer.;;;","20/Jan/15 18:51;omkreddy;This got fixed in new producer.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in controlled shutdown logic in controller leads to controller not sending out some state change request ,KAFKA-911,12648505,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,21/May/13 05:16,04/Jul/13 06:00,22/Mar/23 15:10,04/Jul/13 06:00,0.8.0,,,,,,,,,,,,,controller,,,,0,kafka-0.8,p1,,,,"The controlled shutdown logic in the controller first tries to move the leaders from the broker being shutdown. Then it tries to remove the broker from the isr list. During that operation, it does not synchronize on the controllerLock. This causes a race condition while dispatching data using the controller's channel manager.",,jjkoshy,junrao,nehanarkhede,sriramsub,swapnilghike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/May/13 01:18;nehanarkhede;kafka-911-v1.patch;https://issues.apache.org/jira/secure/attachment/12584342/kafka-911-v1.patch","29/May/13 01:14;nehanarkhede;kafka-911-v2.patch;https://issues.apache.org/jira/secure/attachment/12585046/kafka-911-v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,328860,,,Wed Jul 03 21:59:58 UTC 2013,,,,,,,,,,"0|i1kqmn:",329202,,,,,,,,,,,,,,,,,,,,"23/May/13 01:18;nehanarkhede;The root cause of this bug was a race condition while using the ControllerBrokerRequestBatch that assumes synchronization at the caller. This patch synchronizes access to the ControllerBrokerRequestBatch while sending out the StopReplicaRequest. 

While working on this and testing the patch, I noticed some inefficiency with the controller shutdown API. When we move the leader for a partition one at a time, we also remove the broker being shutdown from the ISR. This involves at least one read and one write per partition to zookeeper, sometimes more. Besides being slow, this operation is not effective. This is because the broker being shutdown still has alive fetchers to the new leader before it receives and acts on the StopReplicaRequest. So the new leader adds it back to the ISR anyways. 

Then I thought I could move it to the end of the controlled shutdown API where we check if all partitions are successfully moved, then send StopReplicaRequest to the broker being shut down. Right after this, we could move the replica to Offline and remove it from ISR as part of that operation. Even if we can invoke this operation as a batch, it will still be slow since the zookeeper reads/writes will happen serially. Also, I realized this is not required as well for 2 reasons -

1. Since the shutting broker is sent the StopReplicaRequest, it will stop the fetcher and fall out of ISR. Until then, as long as the controller doesn't failover, it will not be elected as the leader, even if it is in the ISR, since it is one of the shuttingDownBrokers.

2. Even if the controller fails over, by the time the new controller has initialized and is ready to serve, the StopReplicaRequest would've ensured that the shutdown broker is no longer in the ISR. And until the controller fails over, there cannot be any leader election anyway.

I've tested this patch on a 7 node cluster that continuously gets rolling bounced and has ~100 producers sending production data to it with ~1000 consumers consuming data from it. ;;;","23/May/13 01:21;nehanarkhede;testShutdownBroker() testcase in AdminTest will fail with this patch since it assumes that the controlled shutdown logic will shrink the ISR proactively. I will fix the test if the changes in this patch of not shrinking the ISR are acceptable.;;;","23/May/13 23:16;junrao;If we just stop the replica to be shut down without sending a reduced ISR to the leader, it will take replicaLagTimeMaxMs (defaults to 10s) before the leader realize that the follower is gone. Before that, no new messages can be committed. The idea of letting the controller send a reduced ISR to the leader is to allow the leader to commit new messages sooner. Not very sure if the existing logic does this effectively though. It seems to me that it's better if we stop the shutdown replica one at a time after the leader is moved. Maybe Joel can comment?;;;","25/May/13 00:43;nehanarkhede;You are right that we can send the reduced ISR request to the leader, but that is independent of removing the shutting down broker from the ISR in zookeeper. I'm arguing that the zookeeper write is unnecessary. To handle the issue you described, we can send a leader and isr request just to the leader with the reduced isr.;;;","25/May/13 02:41;jjkoshy;I had to revisit the notes from KAFKA-340. I think this was touched upon. i.e., the fact that the current implementation's attempt to shrink ISR may be ineffective for partitions whose leadership has been moved from the current broker - https://issues.apache.org/jira/browse/KAFKA-340?focusedCommentId=13483478&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13483478

<quote>
> 3.4 What is the point of sending leader and isr request at the end of shutdownBroker, since the OfflineReplica state 
> change would've taken care of that anyway. It seems like you just need to send the stop replica request with the delete 
> partitions flag turned off, no ? 

I still need (as an optimization) to send the leader and isr request to the leaders of all partitions that are present 
on the shutting down broker so it can remove the shutting down broker from its inSyncReplicas cache 
(in Partition.scala) so it no longer waits for acks from the shutting down broker if a producer request's num-acks is 
set to -1. Otherwise, we have to wait for the leader to ""organically"" shrink the ISR. 

This also applies to partitions which are moved (i.e., partitions for which the shutting down broker was the leader): 
the ControlledShutdownLeaderSelector needs to send the updated leaderAndIsr request to the shutting down broker as well 
(to tell it that it is no longer the leader) at which point it will start up a replica fetcher and re-enter the ISR. 
So in fact, there is actually not much point in removing the ""current leader"" from the ISR in the 
ControlledShutdownLeaderSelector.selectLeader. 
</quote>

and 

https://issues.apache.org/jira/browse/KAFKA-340?focusedCommentId=13484727&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13484727
(I don't think I actually filed that jira though.)
;;;","29/May/13 01:14;nehanarkhede;I agree with Joel's suggestion. Removing the shutting down brokers from the ISR is better. This patch sends the LeaderAndIsrRequest with the reduced isr to the new leader for the partitions on the shutting down brokers. This ensures the leader will remove the shutting down broker from the isr in zookeeper. This also makes it unnecessary for the shrunk isr zookeeper write to happen during the controlled shutdown on the controller. ;;;","29/May/13 01:22;sriramsub;I suggest we wait for my patch. My patch changes quite a bit of this logic and it just adds to the merge problem.;;;","04/Jul/13 05:59;sriramsub;This has been fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Large number of system test failures,KAFKA-3256,12940826,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,granders,granders,21/Feb/16 05:19,23/Feb/16 07:58,22/Mar/23 15:10,23/Feb/16 07:58,,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"Confluent's nightly run of the kafka system tests reported a large number of failures beginning 2/20/2016

Test run: 2016-02-19--001.1455897182--apache--trunk--eee9522/
Link: http://confluent-kafka-system-test-results.s3-us-west-2.amazonaws.com/2016-02-19--001.1455897182--apache--trunk--eee9522/report.html
Pass: 136
Fail: 0

Test run: 2016-02-20--001.1455979842--apache--trunk--5caa800/
Link: http://confluent-kafka-system-test-results.s3-us-west-2.amazonaws.com/2016-02-20--001.1455979842--apache--trunk--5caa800/report.html
Pass: 72
Fail: 64

I.e. trunk@eee9522 was the last passing run, and trunk@5caa800 had a large number of failures.

Given its complexity, the most likely culprit is 45c8195fa, and I confirmed this is the first commit with failures on a small number of tests.
[~becket_qin] do you mind investigating?

{code}
commit 5caa800e217c6b83f62ee3e6b5f02f56e331b309
Author: Jun Rao <junrao@gmail.com>
Date:   Fri Feb 19 09:40:59 2016 -0800

    trivial fix to authorization CLI table

commit 45c8195fa14c766b200c720f316836dbb84e9d8b
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   Fri Feb 19 07:56:40 2016 -0800

    KAFKA-3025; Added timetamp to Message and use relative offset.

commit eee95228fabe1643baa016a2d49fb0a9fe2c66bd
Author: Yasuhiro Matsuda <yasuhiro@confluent.io>
Date:   Thu Feb 18 09:39:30 2016 +0800

    MINOR: remove streams config params from producer/consumer configs
{code}",,apovzner,becket_qin,githubbot,granders,ijuma,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Feb 22 23:58:21 UTC 2016,,,,,,,,,,"0|i2t49j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Feb/16 06:52;becket_qin;[~hachikuji] Sure, I'm investigating.;;;","21/Feb/16 06:56;becket_qin;[~hachikuji] It seems I am not able to access the test report on AWS S3. Do you mind uploading it in this ticket?;;;","21/Feb/16 07:56;granders;[~becket_qin] Are you not able to navigate directly to this link and view the report?

http://confluent-kafka-system-test-results.s3-us-west-2.amazonaws.com/2016-02-20--001.1455979842--apache--trunk--5caa800/report.html

;;;","21/Feb/16 08:20;granders;[~becket_qin] The bucket is publicly readable as far as I can tell:

If you have awscli installed (see http://docs.aws.amazon.com/cli/latest/userguide/installing.html), you can try

{code}
aws s3 cp --recursive s3://confluent-kafka-system-test-results/2016-02-20--001.1455979842--apache--trunk--5caa800 ./2016-02-20--001.1455979842--apache--trunk—5caa800
{code}

Note that directories corresponding to individual tests are actually tarballed, and can be unpacked with:
tar xzf INDIVIDUAL_TEST_DIRECTORY



;;;","21/Feb/16 08:21;becket_qin;Ah, interesting. It seems chrome is not able to render the page so it is always blank. FireFox seems working fine.;;;","21/Feb/16 08:33;apovzner;[~becket_qin] Most of these tests are reproducible locally, so should be easier to debug.

I found the issue with some of the connect tests, which produce output like this:
 Expected [""foo"", ""bar"", ""baz"", ""razz"", ""ma"", ""tazz""] but saw [""CreateTime:1455962742782\tfoo"", ""CreateTime:1455962742789\tbar"", ""CreateTime:1455962742789\tbaz"", ""CreateTime:1455962758003\trazz"", ""CreateTime:1455962758009\tma"", ""CreateTime:1455962758009\ttazz""] in Kafka
Traceback (most recent call last):
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.10-py2.7.egg/ducktape/tests/runner.py"", line 102, in run_all_tests
    result.data = self.run_single_test()
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.10-py2.7.egg/ducktape/tests/runner.py"", line 154, in run_single_test
    return self.current_test_context.function(self.current_test)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.10-py2.7.egg/ducktape/mark/_mark.py"", line 331, in wrapper
    return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/tests/connect_test.py"", line 86, in test_file_source_and_sink
    assert expected == actual, ""Expected %s but saw %s in Kafka"" % (expected, actual)
AssertionError: Expected [""foo"", ""bar"", ""baz"", ""razz"", ""ma"", ""tazz""] but saw [""CreateTime:1455962742782\tfoo"", ""CreateTime:1455962742789\tbar"", ""CreateTime:1455962742789\tbaz"", ""CreateTime:1455962758003\trazz"", ""CreateTime:1455962758009\tma"", ""CreateTime:1455962758009\ttazz""] in Kafka

ConsoleConsumer was changed to also output timestamp type and timestamp value in addition to key/value. However, it looks connect tests expect output with just key and value. See test_file_source_and_sink in connect_test.py for example.

;;;","21/Feb/16 08:49;becket_qin;Yes, fix to those tests are obvious. I am looking at the other two types of failure.
{noformat}
No JSON object could be decoded
Traceback (most recent call last):
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.10-py2.7.egg/ducktape/tests/runner.py"", line 102, in run_all_tests
    result.data = self.run_single_test()
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.10-py2.7.egg/ducktape/tests/runner.py"", line 154, in run_single_test
    return self.current_test_context.function(self.current_test)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.10-py2.7.egg/ducktape/mark/_mark.py"", line 331, in wrapper
    return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/tests/connect_test.py"", line 85, in test_file_source_and_sink
    actual = json.dumps([decoder(x) for x in self.consumer_validator.messages_consumed[1]])
  File ""/usr/lib/python2.7/json/__init__.py"", line 338, in loads
    return _default_decoder.decode(s)
  File ""/usr/lib/python2.7/json/decoder.py"", line 366, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File ""/usr/lib/python2.7/json/decoder.py"", line 384, in raw_decode
    raise ValueError(""No JSON object could be decoded"")
{noformat}
And
{noformat}
Consumer failed to start in a reasonable amount of time.
Traceback (most recent call last):
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.10-py2.7.egg/ducktape/tests/runner.py"", line 102, in run_all_tests
    result.data = self.run_single_test()
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.10-py2.7.egg/ducktape/tests/runner.py"", line 154, in run_single_test
    return self.current_test_context.function(self.current_test)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.10-py2.7.egg/ducktape/mark/_mark.py"", line 331, in wrapper
    return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/tests/mirror_maker_test.py"", line 139, in test_simple_end_to_end
    self.run_produce_consume_validate(core_test_action=self.wait_for_n_messages)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/tests/produce_consume_validate.py"", line 79, in run_produce_consume_validate
    raise e
{noformat}

I am not super familiar with those tests, so might it might take me some time to check. It looks we have problem when starting validating consumer.;;;","21/Feb/16 09:40;apovzner;[~becket_qin] The ""No JSON object could be decoded"" failure is also caused by ConsoleConsumer outputting timestamp type and timestamp. If I remove that output from ConsoleConsumer, I stop getting this failure. 

Also, once I did that, reassign_partitions_test also started passing.

So, it leads me to believe that there is some common test tool which expects a particular *format* of an output, rather than a test expecting a specific output.

What was the reason for outputting timestamp type and timestamp in ConsoleConsumer? If it does not bring much value, I propose to just got back to the original format of outputting key and value in ConsoleConsumer. I think  that would fix most of the tests.  
;;;","21/Feb/16 09:52;becket_qin;Hmm, the reason we are printing the timestamp is because that is a user-specified field, just like key and value. ConsoleConsumer is supposed to print that if applicable. 

If fixing the integration tests format is time consuming, we can temporarily change the output format for ConsoleConsumer back to print only key and value. And we can have a follow-up patch for this ticket that updates both the ConsumerConsumer output format and integration test message format.;;;","21/Feb/16 09:54;ijuma;We may also consider outputting those fields only when a flag is set for compatibility reasons.;;;","21/Feb/16 09:57;ijuma;Whatever we decide, it would be good to do it in two steps (revert the output format change so that the system tests pass again and then discuss the best way to handle adding it back) as per Becket's suggestion.;;;","21/Feb/16 10:04;becket_qin;I like this idea. We already have ""print.key"" as an option for console consumer. We can have a ""print.timestamp"" as well and disable it by default.;;;","21/Feb/16 10:06;becket_qin;[~ijuma] If we add a ""print.timestamp"" to console consumer and disable it by default then we only need one patch, right?;;;","21/Feb/16 10:12;ijuma;Yes, one patch would be enough for that option.;;;","21/Feb/16 14:17;apovzner;I looked more into system tests to find where the format is expected, and there are several places actually:
1) Connect tests expect the output to be in JSON format. The value is published in JSON format, and since before the test was expecting the value only, the test was written to expect the console consumer output in JSON format.
2) Other tests such as reassign_partition, compatibility tests that are using ConsoleConsumer are setting message_validator=is_int when constructing it (because they were expecting only value of type integer in the console consumer output). This means that produce_consume_validate.py will be expecting consumer output to be an integer.

I actually think unless we want a system test that specifically verifies a timestamp, we shouldn't modify existing tests to work with a console consumer output containing timestamp type and timestamp. So I agree with your decision to not output timestamp type and timestamp by default. If we want to write/extend system tests that specifically checks for timestamps (type or validates timestamp range), then we will use an output with a timestamp.;;;","21/Feb/16 14:29;apovzner;Also for completeness, the remaining system tests:
mirror_maker_test.py, zookeeper_security_upgrade_test.py, and upgrade_test.py all use console consumer and set message_validator=is_int. So, they all expect  console consumer to output values that are integers, and additional ""CreateTime:NNNN> breaks that.
;;;","22/Feb/16 03:37;junrao;[~becket_qin], could you try the fix in ConsoleConsumer and run all system tests again? Geoff has given you permission to Confluence jenkins and you can run the tests on your branch.;;;","22/Feb/16 06:50;becket_qin;[~junrao] Yes, I was trying to run the integration test with the patch. 

Not sure if I did something wrong, but the jenkins test seems not quite stable. Yesterday night the build failed because some ssh issue. I kicked off a new build this morning but somehow it seems stuck at the 21st test. I just started a new build and see if that works.;;;","22/Feb/16 08:40;granders;[~becket_qin] It appears your first attempt failed while building kafka for some reason.

I cleared the workspace and kicked off another run here: https://jenkins.confluent.io/job/kafka_system_tests_branch_builder/356/console ;;;","22/Feb/16 09:06;becket_qin;Thanks for the help, Geoff.;;;","23/Feb/16 03:53;becket_qin;[~geoffra] It seems that yesterday's build had two tests failure. [~ijuma] kicked a off a new build with better logging. It shows many broker tear down failures. I'll take a looks at the log to see  what happened.;;;","23/Feb/16 04:04;apovzner;[~becket_qin], [~ijuma], [~geoffra] The remaining system tests are compatibility test and rolling upgrade tests. The issue is that both tests assume trunk to be 0.9. Since we are testing 0.8 to 0.9 upgrade tests (and similarly compatibility tests) in 0.9 branch, we don't need to port the tests to get 0.9 version vs. trunk. We have separate JIRAs (KAFKA-3201 and KAFKA-3188) to add 0.8 to 0.10 and 0.9 to 0.10 upgrade tests, and test compatibility of mix of 0.9 and 0.10 clients with 0.10 brokers. My proposal to have a patch with current fixes, and address compatibility and upgrade test failures as part of KAFKA-3201 and KAFKA-3188, which are currently assigned to me.;;;","23/Feb/16 05:23;becket_qin;Thanks for the investigation [~apovzner]. It looks upgrade test failed because the default message.format.version is higher than inter.broker.version. And producer compatibility test failed because the producer was not able to parse timestamp field in the produce response.

It is not clear to me that why we see tear down timeout failures in other tests. Those failures did not affect the test results but from the logs it seems all the servers have successfully shutdown.

I agree that we can check in this patch first and fix upgrade test and producer compatibility test in the other two separate patches.;;;","23/Feb/16 05:28;apovzner;FYI: The upgrade test fails with this error:
java.lang.IllegalArgumentException: requirement failed: message.format.version 0.10.0-IV0 cannot be used when inter.broker.protocol.version is set to 0.8.2

I think this is expected, right? We need to use 0.9.0 (or 0.8) message format in the first pass of upgrade in 0.8 to 0.10 upgrade test (which is what current upgrade test is testing), is that correct?;;;","23/Feb/16 05:30;apovzner;[~becket_qin] I wrote my comment without seeing yours. Yes, I think tear down timeout failures are unrelated and I don't think hey actually cause any issues ([~geoffra] ?). 

I'll take on upgrade and compatibility system tests if you don't mind. ;;;","23/Feb/16 05:57;githubbot;GitHub user becketqin opened a pull request:

    https://github.com/apache/kafka/pull/949

    KAFKA-3256: Add print.timestamp option to console consumer.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/becketqin/kafka KAFKA-3256

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/949.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #949
    
----
commit f4a2ebd5feb75cde8b44b3cb1512152805259383
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2016-02-21T06:03:27Z

    KAFKA-3256: Add print.timestamp option to console consumer. It is disabled by default

----
;;;","23/Feb/16 07:58;junrao;Issue resolved by pull request 949
[https://github.com/apache/kafka/pull/949];;;","23/Feb/16 07:58;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/949
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve error handling in log cleaner,KAFKA-1755,12753080,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jjkoshy,jjkoshy,jjkoshy,06/Nov/14 00:15,22/Dec/15 03:22,22/Mar/23 15:10,22/Dec/15 03:22,,,,,,,0.9.0.0,,,,,,,,,,,0,newbie++,,,,,"The log cleaner is a critical process when using compacted topics.
However, if there is any error in any topic (notably if a key is missing) then the cleaner exits and all other compacted topics will also be adversely affected - i.e., compaction stops across the board.

This can be improved by just aborting compaction for a topic on any error and keep the thread from exiting.

Another improvement would be to reject messages without keys that are sent to compacted topics although this is not enough by itself.
",,criccomini,guozhang,gwenshap,jjkoshy,jkreps,jonbringhurst,vanyatka,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1581,,,,,,,,"23/Feb/15 22:43;jjkoshy;KAFKA-1755.patch;https://issues.apache.org/jira/secure/attachment/12700201/KAFKA-1755.patch","24/Feb/15 06:30;jjkoshy;KAFKA-1755_2015-02-23_14:29:54.patch;https://issues.apache.org/jira/secure/attachment/12700276/KAFKA-1755_2015-02-23_14%3A29%3A54.patch","27/Feb/15 02:54;jjkoshy;KAFKA-1755_2015-02-26_10:54:50.patch;https://issues.apache.org/jira/secure/attachment/12701143/KAFKA-1755_2015-02-26_10%3A54%3A50.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Dec 21 19:22:47 UTC 2015,,,,,,,,,,"0|i22067:",9223372036854775807,,jkreps,,,,,,,,,,,,,,,,,,"06/Nov/14 00:20;criccomini;It might also be desirable to allow the log compaction to continue on the topic in question, and simply keep all messages without keys without doing any compaction on them.;;;","19/Nov/14 01:42;jjkoshy;There are a couple of issues that I was thinking of in scope for this jira:
* Log cleaner threads quitting on errors (which may be a non-issue as discussed further below).
* Dealing with cleaner failures due to unkeyed messages.
* Other cleaner failures are possible as well (for e.g., compressed message sets until KAFKA-1374 is reviewed and checked-in)

The reason this jira was filed is because the log cleaner compacts all compacted topics so one topic should (ideally) not affect another. Any practical deployment would need to set up alerts on the cleaner thread dying. Right now, I think the most reliable way to alert (with the currently available metrics) would be to monitor the max-dirty-ratio. If we set up this alert, then allowing the cleaner to continue would in practice only delay an alert. So one can argue that it is better to fail fast - i.e., let the log cleaner die because a problematic topic is something that needs to be looked into immediately. However, I think there are further improvements with alternatives that can be made. It would be helpful if others can share their thoughts/preferences on these:
* Introduce a new LogCleaningState: LogCleaningPausedDueToError
* Introduce a metric for the number of live cleaner threads
* If the log cleaner encounters any uncaught error, there are a couple of options:
** Don't let the thread die, but move the partition to LogCleaningPausedDueToError. Other topics-partitions can still be compacted. Alerts can be set up on the number of partitions in state LogCleaningPausedDueToError.
** Let the cleaner die and decrement live cleaner count. Alerts can be set up on the number of live cleaner threads.
* If the cleaner encounters un-keyed messages:
** Delete those messages, and do nothing. i.e., ignore (or just log the count in log cleaner stats)
** Keep the messages, move the partition to LogCleaningPausedDueToError.  The motivation for this is accidental misconfiguration. i.e., it may be important to not lose those messages. The error log cleaning state can be cleared only by deleting and then recreating the topic.
* Additionally, I think we should reject producer requests containing un-keyed messages to compacted topics.
* With all of the above, a backup alert can also be set up on the max-dirty-ratio.;;;","05/Dec/14 07:23;guozhang;Here are my two cents:

1. At the end of the day, Kafka will have two types of topics, one type only accepts keyed messages and log compaction is used; the other one accepts any message and log cleaning is used. Those two types of topics never exchange, i.e. once a topic is created with one of the two types, it will never change its type until deletion.

2. Compressed message will be supported with log compaction, which will de-serialize the message set and re-serialize.

3. With these two points in mind, I would suggest for now:
  a. Broker reject non-keyed messages for compacted topics.
  b. Broker reject compressed messages for compacted topics (this will be lifted after KAFKA-1374 is checked in).
  c. With this, it should never happen that compactor thread encountering a non-keyed / compressed (this will be lifted after KAFKA-1374); if it happens, this would be a FATAL error and we should throw an exception and halt the server. It indicates some operations are needed and there are some code fixes before it can be restarted.;;;","23/Dec/14 19:41;jjkoshy;Thanks for the comments. The issue with 3a is that once we do have compression support for compacted topics it will be very ugly to implement that check on message arrival. This is because we need to do a deep iteration on incoming messages to look at the key field. The only time we do that currently on the broker is when assigning offsets. However, this code is in ByteBufferMessageSet which is fairly low-level and has no log-config information associated with it. We would have to ""leak"" some flag indicating whether non-keyed messages are allowed or not which is ugly. That is why I prefer not doing that check on message arrival and just have the log cleaner drop/ignore non-keyed messages with a warning. Ultimately, the effect is the same. However, the benefit of rejecting is that the producer is made aware of it. So I guess I changed my mind with regard to my earlier comment - i.e., I would recommend against doing this unless we can think of an elegant implementation. 3b is easy to do and we can implement that until KAFKA-1374 is in place.;;;","24/Dec/14 01:52;jkreps;Rejecting messages without a key doesn't actually solve the problem, I think as you can change the retention setting of a topic to compaction later at which point there may already be null keys.

Perhaps the most consistent thing to do would actually be to treat null as a key value. So the cleaner would retain a single null value and remove the others. ;;;","23/Feb/15 22:43;jjkoshy;Created reviewboard https://reviews.apache.org/r/31306/
 against branch origin/trunk;;;","23/Feb/15 23:23;jjkoshy;I thought a bit more about this and here is a patch that summarizes my thoughts.

This patch does message validation on arrival, and drops unkeyed messages during log compaction.

I actually think it is better to reject invalid messages (unkeyed and for now compressed) up front as opposed to accepting those messages and only dropping/warning during compaction. This way the producer is given early indication via a client-side error that it is doing something wrong which is better than just a broker-side warning/invalid metric. We still need to deal with unkeyed messages that may already be in the log but that is orthogonal I think - this includes the case when you change a non-compacted topic to be compacted. That  is perhaps an invalid operation - i.e., you should ideally delete the topic before doing that, but in any event this patch handles that case by deleting invalid messages during log compaction.

Case in point: at LinkedIn we use Kafka-based offset management for some of our consumers. We recently discovered compressed messages in the offsets topic which caused the log cleaner to quit. We saw this issue in the past with Samza checkpoint topics and suspected that  Samza was doing something wrong. However, after seeing it in the __consumer_offsets topic it is more likely to be an actual bug in the broker - either in the log cleaner itself, or even at the lower level byte-buffer message set API level. We currently do not know. If we at least reject invalid messages on arrival we can rule out clients as being the issue.;;;","23/Feb/15 23:25;jjkoshy;Also, I have an incremental patch that prevents the log cleaner from quitting due to uncaught errors while cleaning a specific partition. It basically moves that partition to a permanent failed state and allows the cleaner to continue compacting other partitions. It      continues to include the failed partition when computing the max dirty ratio so you can still accurately alert on that metric. We can discuss whether we want to add that or not.;;;","24/Feb/15 06:30;jjkoshy;Updated reviewboard https://reviews.apache.org/r/31306/diff/
 against branch origin/trunk;;;","27/Feb/15 02:54;jjkoshy;Updated reviewboard https://reviews.apache.org/r/31306/diff/
 against branch origin/trunk;;;","22/Dec/15 03:22;gwenshap;This was in fact committed to trunk and is in 0.9.0.0:

commit 1cd6ed9e2c07a63474ed80a8224bd431d5d4243c  Joel Koshy committed on Mar 3
https://github.com/apache/kafka/commit/1cd6ed9e2c07a63474ed80a8224bd431d5d4243c#diff-d7330411812d23e8a34889bee42fedfe
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Controller unable to shutdown after a soft failure,KAFKA-1663,12745270,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,sriharsha,sriharsha,sriharsha,01/Oct/14 22:52,10/Oct/14 05:39,22/Mar/23 15:10,10/Oct/14 05:39,,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"As part of testing KAFKA-1558 I came across a case where inducing soft failure in the current controller elects a new controller  but the old controller doesn't shutdown properly.
steps to reproduce
1) 5 broker cluster
2) high number of topics(I tested it with 1000 topics)
3) on the current controller do kill -SIGSTOP  pid( broker's process id)
4) wait for bit over zookeeper timeout (server.properties)
5) kill -SIGCONT pid
6) There will be a new controller elected. check old controller's
log 
[2014-09-30 15:59:53,398] INFO [SessionExpirationListener on 1], ZK expired; shut down all controller components and try to re-elect (kafka.controller.KafkaController$SessionExpirationListener)
[2014-09-30 15:59:53,400] INFO [delete-topics-thread-1], Shutting down (kafka.controller.TopicDeletionManager$DeleteTopicsThread)

If it stops there and the broker  logs keeps printing 
Cached zkVersion [0] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
than the controller shutdown never completes.",,junrao,nehanarkhede,sriharsha,yuanjiali,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1600,,,,,,,,,,,,,,,,KAFKA-1558,KAFKA-1681,"03/Oct/14 09:31;sriharsha;KAFKA-1663.patch;https://issues.apache.org/jira/secure/attachment/12672716/KAFKA-1663.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Oct 09 21:39:15 UTC 2014,,,,,,,,,,"0|i20osv:",9223372036854775807,,nehanarkhede,,,,,,,,,,,,,,,,,,"03/Oct/14 01:54;sriharsha;bit more info KafkaController.shutdown never coming out of  deleteTopicsThread.awaitShutdown() after a soft failure causing the above issue. This is not very consistent behavior but I am able to reproduce kafka cluster running  on ec2 m3.xlarge .;;;","03/Oct/14 05:30;nehanarkhede;[~sriharsha] Thanks for reproducing this. Could you please attach the thread dump that shows where the delete topics thread hangs?;;;","03/Oct/14 08:23;sriharsha;[~nehanarkhede] testing out few possible fixes will upload the thread dump soon. Thanks.;;;","03/Oct/14 08:35;sriharsha;[~nehanarkhede] I've a question on TopicDeletionManager code
I think the idea is to start the DeleteTopicsThread and wait for the events like topics are added to delete set and trigger the doWork() method. 
right now doWork() method calls awaitTopicDeletionNotifictation

  private def awaitTopicDeletionNotification() {
    inLock(deleteLock) {
      while(!deleteTopicsThread.isRunning.get() && !deleteTopicStateChanged.compareAndSet(true, false)) {
                       deleteTopicsCond.await()
}
This condition seems to be wrong and it doesn't block DeleteTopicThread once the TopicDeletionManager starts the deleteTopicsThread.doWork() continues to execute.

The above condition should state
 while(deleteTopicsThread.isRunning.get() && deleteTopicStateChanged.compareAndSet(true, false)) {
        deleteTopicsCond.await()
}
whenever there is topic is added we are callign resumeTopicDeletionThread() which sets deleteTopicStateChanged to true and sends deleteTopicCond.signal() which should wake up doWork() and continue with deletion of the topic.
I am testing with this change, will update with the results. 
;;;","03/Oct/14 09:31;sriharsha;Created reviewboard https://reviews.apache.org/r/26306/diff/
 against branch origin/trunk;;;","03/Oct/14 09:32;sriharsha;[~nehanarkhede] I tested the attached patch for recovering from soft failure and also few delete topic cases. but I haven't gone though the entire KAFKA-1558 test cases. I am going to run them now , meanwhile can you please review the patch. Thanks.;;;","04/Oct/14 01:35;sriharsha;[~nehanarkhede] I ran all the tests in KAFKA-1558 they all pass with the above patch and didn't see any issues with soft failure case.;;;","04/Oct/14 08:53;nehanarkhede;[~sriharsha] Awesome. I'll review this tomorrow.;;;","05/Oct/14 09:10;nehanarkhede;Thanks for the patch! Pushed to trunk;;;","06/Oct/14 07:49;junrao;Neha,

Since this is a blocker for 0.8.2, could you push this to the 0.8.2 branch too? Thanks,;;;","07/Oct/14 22:04;nehanarkhede;[~sriharsha], while talking to Jun, realized that there may have been a regression introduced by the patch by removing the deleteTopicStateChanged.set(true) from startup(). The purpose of that is to let the delete topic thread resume topic deletion on startup for topics for which deletion was initiated on the previous controller. During the review, I assumed that the controller is signaling the delete topic thread separately after startup, but that is not the case. 

However, while reading through the code, I think there is a bug in the above case where the controller needs to resume topic deletion on startup. Basically the way for the controller to notify the TopicDeletionManager of resuming the thread is via the callers of resumeTopicDeletionThread(). Each of those caller APIs are protected via the controllerLock in KafkaController. However, awaitTopicDeletionNotification is not. So there is a window when the controller might signal a thread that is not waiting on the same monitor. I think the main problem is with having 2 locks - deleteLock and controllerLock. We might have to revisit that decision and see if we consolidate on a single lock (controllerLock). Since this is a different bug, can you file it and link it back to this issue? ;;;","07/Oct/14 22:35;sriharsha;[~nehanarkhede] Both TopicDeletionManager.resumeTopicDeletionThread() and awaitTopicDeletionNoification uses deleteLock and DeleteTopicThread.doWork() waits on awaitTopicDeletionNotification before it tries to acquire controllerLock.
so simple fix would be to check if there are any topics in topicsToBeDeleted set and call resumeTopicDeletionThread() from 
start(). 
I agree that it is best to consolidate on a single lock.;;;","10/Oct/14 05:39;junrao;Committed the original patch in the jira and the patch in kafka-1681 to 0.8.2. Both changes are in trunk too.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
broker failure system test broken on replication branch,KAFKA-306,12546609,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jfung,nehanarkhede,nehanarkhede,16/Mar/12 00:33,11/Jul/12 02:06,22/Mar/23 15:10,11/Jul/12 02:06,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,replication,,,,,"The system test in system_test/broker_failure is broken on the replication branch. This test is a pretty useful failure injection test that exercises the consumer rebalancing feature, various replication features like leader election. It will be good to have this test fixed as well as run on every checkin to the replication branch",,jfung,jjkoshy,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-45,,,,,,,,,,,,,,,,,,,,,,,,"31/May/12 00:15;jfung;kafka-306-v1.patch;https://issues.apache.org/jira/secure/attachment/12530225/kafka-306-v1.patch","21/Jun/12 00:18;jfung;kafka-306-v2.patch;https://issues.apache.org/jira/secure/attachment/12532716/kafka-306-v2.patch","21/Jun/12 04:41;jfung;kafka-306-v3.patch;https://issues.apache.org/jira/secure/attachment/12532759/kafka-306-v3.patch","22/Jun/12 01:53;jfung;kafka-306-v4.patch;https://issues.apache.org/jira/secure/attachment/12532912/kafka-306-v4.patch","28/Jun/12 05:28;jfung;kafka-306-v5.patch;https://issues.apache.org/jira/secure/attachment/12533709/kafka-306-v5.patch","04/Jul/12 05:31;jfung;kafka-306-v6.patch;https://issues.apache.org/jira/secure/attachment/12534985/kafka-306-v6.patch","06/Jul/12 07:00;jfung;kafka-306-v7.patch;https://issues.apache.org/jira/secure/attachment/12535280/kafka-306-v7.patch","07/Jul/12 03:56;jfung;kafka-306-v8.patch;https://issues.apache.org/jira/secure/attachment/12535410/kafka-306-v8.patch","11/Jul/12 00:54;jfung;kafka-306-v9.patch;https://issues.apache.org/jira/secure/attachment/12535871/kafka-306-v9.patch",,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,231767,,,Tue Jul 10 18:06:45 UTC 2012,,,,,,,,,,"0|i029n3:",11163,,,,,,,,,,,,,,,,,,,,"17/Mar/12 01:23;nehanarkhede;KAFKA-45 marks the start of server side replication related code changes. I think this test is a pretty good sanity check, if not a complete system testing suite. I would prefer having this fixed before accepting more patches on 0.8 branch. ;;;","31/May/12 00:15;jfung;Broker Failure Test is broken in Kafka 0.8 branch. This patch is fixing the issues and contains the following changes:
1. All server_*.properties are updated such that the first brokerid is starting from '0'
2. All mirror_producer*.properties are updated to use zk.connect (and not broker.list)
3. After the source brokers cluster is started, call kafka.admin.CreateTopicCommand to create topic.

Currently this patch is working with branch 0.8 (rev. 1342841 patched with KAFKA-46) with the following workarounds:

1. Before starting the target brokers cluster, start and stop one target broker to eliminate the following error:
       org.I0Itec.zkclient.exception.ZkNoNodeException: 
       org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /brokers/ids

2. The argument ""--consumer-timeout-ms"" doesn't seem to work properly. The consumer processes will be terminated manually

3. Consumer Lag info is not available from Zookeeper. Therefore, extra sleep time is added to the test to wait for the complete consumption of messages

The above issues are being investigated.;;;","13/Jun/12 00:37;junrao;Sorry, just got to review this. Trunk has moved, could you rebase? 

For 1, do you know the cause of this? Is this a bug? If so, please create a jira.

For 2,3, we just merged some changes from trunk to 0.8. Could you retry and see if this works now?
;;;","21/Jun/12 00:18;jfung;Uploaded kafka-306-v2.patch for branch 0.8 with the following changes:

1. Removed the worked around code and comments for NoNodeException (which is not reproducible with the latest 0.8 code).
2. The script can take a command line argument to bounce any combination of source broker, target broker and mirror maker in a round-robin fashion.
3. Use ""info"", ""kill_child_processes"" methods from a common script ""system_test/common/util.sh"".
4. Updated README.;;;","21/Jun/12 01:55;junrao;Thanks for patch v2. Some comments:

21. run_test.sh
21.1 Does the following check in start_test() need to be repeated for source, mirror and target, or can we just use 1 check for all 3 cases?
            if [[ $num_iterations -ge $iter && $svr_idx -gt 0 ]]; then
                echo
                info ""==========================================""
                info ""Iteration $iter of ${num_iterations}""
                info ""==========================================""
21.2 Do we need to sleep for 30s at the end start_test()? Isn't calling wait_for_zero_consumer_lags enough? Also, the comment says sleep for 10s.
21.3 In the header, we should add that mirror make can be terminated too.
21.4 If the test fails, could we generate a list of missing messages in a file? Ideally, messages can just be strings with sequential numbers in them.

22. The following test seems to fail sometimes.
bin/run-test.sh 2 23

23. README: We should add that one needs to do ./sbt package at the root level first.


;;;","21/Jun/12 04:41;jfung;Uploaded kafka-306-v3.patch with the following changes:

1. Set the server_source*.properties - log file size to approx 10MB:
log.file.size=10000000

2. Set the server_target*.properties - log file size to approx 10MB:
log.file.size=10000000;;;","22/Jun/12 01:53;jfung;Hi Jun,

Thanks for reviewing kafka-306-v2.patch.

kafka-306-v4.patch is uploaded with the following changes suggested by you:

21.1 The following check is required for each of the source, target and mirror maker. It is because the following 2 lines are needed for:
    Line 1: find out if the $bounce_source_id is a char in the string $svr_to_bounce
    Line 2: check to see if $num_iterations is already reached and if $svr_idx > 0 (meaning this server needs to be bounced)

    Line 1:        svr_idx=`expr index $svr_to_bounce $bounce_source_id`
    Line 2:        if [[ $num_iterations -ge $iter && $svr_idx -gt 0 ]]; then

21.2 ConsumerOffsetChecker needs to be enhanced for 0.8 and it depends on KAFKA-313. ""sleep"" is temporarily used for kafka to catch up with the offset lags.

21.3 The header is now updated to ""#### Starting Kafka Broker / Mirror Maker Failure Test ####""

21.4 There is a file ""checksum.log"" generated at the end of the test which will give the checksums found in producer, source consumer, target consumer logs

22. You may see inconsistent failure in this test due to the issue specified in KAFKA-370

23. README is updated with the steps for ./sbt package

Thanks,
John
;;;","23/Jun/12 00:58;junrao;Thanks for patch v4. A few more comments:

21.2 KAFA-313 adds 2 more options, which option does this jira depends on?

21.3 I meant that we should add mirror maker in the following line in the header:
# 5. One of the Kafka SOURCE or TARGET brokers in the cluster will
#    be randomly terminated and waiting for the consumer to catch up.

21.4 Instead of using checksum, can we use the message string itself? This makes it a bit easier to figure out the missing messages, if any.

22. Just attached a patch to kafka-370. Could you give it a try?
;;;","28/Jun/12 05:28;jfung;** In replying to Jun's question about KAFKA-313: in this script, the function ""wait_for_zero_consumer_lag"" is calling ConsumerOffsetChecker to get the Consumer lag value. However, the topic-partition info is changed in 0.8 and it's not returned correctly in ConsumerOffsetChecker. Please refer to this comment: https://issues.apache.org/jira/browse/KAFKA-313?focusedCommentId=13397990&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13397990

** Uploaded kafka-306-v5.patch. Changes made in kafka-306-v5.patch:

1. In ""initialize"" function, added code to find the location of the zk & kafka log4j log files.

2. In ""cleanup"" function, added code to remove the zk & kafka log4j log files

3. The header of the script is now removed and the description are in README

4. Use getopt to process command line arguments

5. Consolidated the following functions:

    * start_console_consumer_for_source_producer
    * start_console_consumer_for_mirror_producer
    * wait_for_zero_source_console_consumer_lags
    * wait_for_zero_mirror_console_consumer_lags

6. The file to notify producer to stop:
The producer is sent to the background to run in a while-loop. If a file is used to notify the producer process in the background, the producer will exit properly inside the while loop.

7. The following check is required for each of the source, target and mirror maker. It is because the following 2 lines are needed for:

    * Line 1: find out if the $bounce_source_id is a char in the string $svr_to_bounce
    * Line 2: check to see if $num_iterations is already reached and if $svr_idx > 0 (meaning this server needs to be bounced)

    * Line 1: svr_idx=`expr index $svr_to_bounce $bounce_source_id`
    * Line 2: if [[ $num_iterations -ge $iter && $svr_idx -gt 0 ]]; then;;;","04/Jul/12 05:31;jfung;Uploaded kafka-306-v6.patch and made further changes in ProducerPerformance and ConsoleConsumer to support producing sequential message IDs such that it would be easier to troubleshoot data loss.

ProducerPerformance.scala

    * Added command line option ""--seq-id-starting-from"". This option enable ""seqIdMode"" with the following changes:

    * Every message will be tagged with a sequential message ID such that all IDs are unique
    * Every message will be sent by its own producer thread sequentially
    * Each producer thread will use a unique range of numbers to give sequential message IDs
    * All message IDs are leftpadded with 0s for easier troubleshooting
    * Extra characters are added to the message to make up the required message size

ConsoleConsumer.scala

    * Added DecodedMessageFormatter class to display message contents

run-test.sh

    * Modified to use the enhanced ProducerPerformance and ConsoleConsumer
    * Validate ""MessageID"" instead of ""checksum"" for data matching between source and target consumers

;;;","04/Jul/12 09:45;jjkoshy;John, thanks for the patch. The test script itself looks good - as we
discussed on the other jira we can do further cleanup separately. Here are
some comments on the new changes:

ProducerPerformance:
- seqIdStartFromopt -> startId or initialId would be more
  convenient/intuitive.
- May be better not to describe the message format in detail in the help
  message. I think the template: ""Message:000..1:xxx..."" is good enough.
- On line 136, 137 I think you mean if (options.has) and not
  if(!options.has) - something odd there. Can you double-check?
- Try to avoid using vars if possible. vals are generally clearer and safer
  - for example,
  val isFixSize = options.has(seqIdStartFromOpt) || !options.has(varyMessageSizeOpt)
  val numThreads = if (options.has(seqIdStartFromOpt)) 1 else options.valueOf(numThreadsOpt).intValue()
  etc.
- For user-specified options that you override can you log a warning?
- Instead of the complicated padding logic I think you can get it for free
  with Java format strings - i.e., specify the width/justification of each
  column in the format string. That would be much easier I think.
- numThreads override to 1 -> did it work to prefix the id with thread-id
  and allow > 1 thread?

Server property files:
- send/receive.buffer.size don't seem to be valid config options - may be
  deprecated by the socket buffer size settings, but not sure.

Util functions:

- Small suggestion: would be better to echo the result than return. So you
  can have: idx=$(get_random_range ...) which is clearer than
  get_random_range; idx=$? . Also, non-zero bash returns typically indicate
  an error.
;;;","06/Jul/12 07:00;jfung;Hi Joel,

Thanks for reviewing. I just uploaded kafka-306-v7.patch with the changes you suggested:

ProducerPerformance
===================
* seqIdStartFromopt -> startId or initialId would be more convenient/intuitive.
- Changed

* May be better not to describe the message format in detail in the help message. I think the template: ""Message:000..1:xxx..."" is good enough.
- Changed

* On line 136, 137 I think you mean if (options.has) and not if(!options.has) - something odd there. Can you double-check?
- In ""seqIdMode"", if ""numThreadsOpt"" is not specified, numThreads default to 1. Otherwise, it will take the user specified value

* Try to avoid using vars if possible. vals are generally clearer and safer, for example,
  val isFixSize = options.has(seqIdStartFromOpt) || !options.has(varyMessageSizeOpt)
  val numThreads = if (options.has(seqIdStartFromOpt)) 1 else options.valueOf(numThreadsOpt).intValue()
- This is because the values may be overridden later by user specified values. Therefore, some of the val is changed to var

* For user-specified options that you override can you log a warning?
- Changed

* Instead of the complicated padding logic I think you can get it for free with Java format strings - i.e., specify the width/justification of each column in the format string. That would be much easier I think.
- Changed

* numThreads override to 1 -> did it work to prefix the id with thread-id and allow > 1 thread?
- numThreads will be overridden if ""--threads"" is specified in command line arg


Server property files
=====================
* send/receive.buffer.size don't seem to be valid config options - may be deprecated by the socket buffer size settings, but not sure.
- Changed

Util functions
==============
* Small suggestion: would be better to echo the result than return.
So you can have: idx=$(get_random_range ...) which is clearer than get_random_range; idx=$? .
Also, non-zero bash returns typically indicate an error.
- Changed
;;;","07/Jul/12 03:56;jfung;Uploaded kafka-306-v8.patch.

The changes made in the previous patch (kafka-306-v7.patch) will break single_host_multi_brokers/bin/run-test.sh due to the fact that ProducerPerformance will no longer print the message checksum.

The changes made in this patch supports single_host_multi_brokers/bin/run-test.sh to make use of the sequential message ID for test results validation.;;;","07/Jul/12 04:08;jjkoshy;Thanks for making the changes - looks better.

> - This is because the values may be overridden later by user specified
> values. Therefore, some of the val is changed to var 

I meant even with overrides I don't think you need these vars and they can 
be handled better with vals. However, it's a minor issue and looking at
ProducerPerformance it seems it needs an overhaul - the main loop is pretty hard to 
read. We should probably do that in a separate jira as it isn't directly
related to this one.

BTW, it seems bytesSent is not updated in seqIdMode.
;;;","10/Jul/12 08:43;junrao;Patch v8 looks good overall. Some minor comments on ProducerPerformance:

81. Could we default numThreadsOpt to 1? Then we can get rid of the following override.

      if (!options.has(numThreadsOpt)) { 
        numThreads = 1 
        warn(""seqIdMode - numThreads is overridden to: "" + numThreads)
      }

82. Could we replace the following code
            if (config.seqIdMode) {
              producer.send(new ProducerData[Message,Message](config.topic, null, message))
            }
            else if(!config.isFixSize) {
     with
            if(!config.isFixSize || !config.seqIdMode) {;;;","11/Jul/12 00:54;jfung;Thanks Jun for reviewing. Your suggestion are made in kafka-306-v9.patch.

The changes are:
91. numThreadsOpt is defaulted to 1 and the 'if' block is removed

92. The following block is actually not necessary and it's now removed:
          if (config.seqIdMode) { 
              producer.send(new ProducerData[Message,Message](config.topic, null, message)) 
            } ;;;","11/Jul/12 02:06;junrao;John, thanks for patch v9. Removed the commented out code in ProducerPerformance and committed to 0.8.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in ProducerFailureHandlingTest,KAFKA-1533,12726624,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,junrao,junrao,11/Jul/14 00:35,10/Sep/14 08:43,22/Mar/23 15:10,10/Sep/14 08:43,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Occasionally, saw the test hang on tear down. The following is the stack trace.

""Test worker"" prio=5 tid=7f9246956000 nid=0x10e078000 in Object.wait() [10e075000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        - waiting on <7f4e69578> (a org.apache.zookeeper.ClientCnxn$Packet)
        at java.lang.Object.wait(Object.java:485)
        at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1344)
        - locked <7f4e69578> (a org.apache.zookeeper.ClientCnxn$Packet)
        at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:732)
        at org.I0Itec.zkclient.ZkConnection.delete(ZkConnection.java:91)
        at org.I0Itec.zkclient.ZkClient$8.call(ZkClient.java:720)
        at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
        at org.I0Itec.zkclient.ZkClient.delete(ZkClient.java:716)
        at kafka.utils.ZkUtils$.deletePath(ZkUtils.scala:416)
        at kafka.utils.ZkUtils$.deregisterBrokerInZk(ZkUtils.scala:184)
        at kafka.server.KafkaHealthcheck.shutdown(KafkaHealthcheck.scala:50)
        at kafka.server.KafkaServer$$anonfun$shutdown$2.apply$mcV$sp(KafkaServer.scala:243)
        at kafka.utils.Utils$.swallow(Utils.scala:172)
        at kafka.utils.Logging$class.swallowWarn(Logging.scala:92)
        at kafka.utils.Utils$.swallowWarn(Utils.scala:45)
        at kafka.utils.Logging$class.swallow(Logging.scala:94)
        at kafka.utils.Utils$.swallow(Utils.scala:45)
        at kafka.server.KafkaServer.shutdown(KafkaServer.scala:243)
        at kafka.api.ProducerFailureHandlingTest.tearDown(ProducerFailureHandlingTest.scala:90)
",,copester,guozhang,heavydawson,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jul/14 06:45;guozhang;KAFKA-1533.patch;https://issues.apache.org/jira/secure/attachment/12656600/KAFKA-1533.patch","17/Jul/14 07:38;guozhang;KAFKA-1533.patch;https://issues.apache.org/jira/secure/attachment/12656179/KAFKA-1533.patch","16/Jul/14 04:40;guozhang;KAFKA-1533.patch;https://issues.apache.org/jira/secure/attachment/12655857/KAFKA-1533.patch","22/Jul/14 06:46;guozhang;KAFKA-1533_2014-07-21_15:45:58.patch;https://issues.apache.org/jira/secure/attachment/12656981/KAFKA-1533_2014-07-21_15%3A45%3A58.patch","28/Jul/14 16:35;heavydawson;kafka.threads;https://issues.apache.org/jira/secure/attachment/12658107/kafka.threads","28/Jul/14 01:48;junrao;stack.out;https://issues.apache.org/jira/secure/attachment/12658029/stack.out",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,404731,,,Wed Sep 10 00:43:00 UTC 2014,,,,,,,,,,"0|i1xnkv:",404769,,,,,,,,,,,,,,,,,,,,"11/Jul/14 01:38;guozhang;This error seems not specific to this test case, since it is blocked on submitting the write/delete request to ZK upon shutting down the server, which we do in all test cases.;;;","11/Jul/14 22:53;junrao;Yes, I am not sure what the issue is. Occasionally, I do see the test ran out of memory and this could be the effect of that.;;;","12/Jul/14 01:13;guozhang;Maybe memory usage can be reduced, which test case caused this failure, or all of them in the ProducerFailureHandlingTest has the potential?;;;","12/Jul/14 02:28;junrao;Not sure. The test itself is done and all left is the teardown part.;;;","12/Jul/14 02:33;guozhang;I think at least one thing we can do to improve this test class is to use the KafkaServerHarness instead of writing the setup/teardown code separately as [~jkreps] suggested, and probably further reduce the process length of the testBrokerFailure case. Will try to upload a patch for that.

Guozhang;;;","16/Jul/14 04:40;guozhang;Created reviewboard https://reviews.apache.org/r/23521/
 against branch origin/trunk;;;","17/Jul/14 07:38;guozhang;Created reviewboard https://reviews.apache.org/r/23593/
 against branch origin/trunk;;;","19/Jul/14 06:45;guozhang;Created reviewboard https://reviews.apache.org/r/23697/
 against branch origin/trunk;;;","22/Jul/14 06:46;guozhang;Updated reviewboard https://reviews.apache.org/r/23697/
 against branch origin/trunk;;;","23/Jul/14 05:15;junrao;Thanks for the patch. +1 and committed to trunk.;;;","28/Jul/14 01:48;junrao;I saw this test hang again. Attached is the stacktrace. ""daemon-producer"" seems to hang during shutdown. Not sure why though.;;;","28/Jul/14 16:35;heavydawson;Seeing the same issue. Jun, not sure if you attached your own thread dump or a copy of mine from the mailing list, but attaching here again per your request.;;;","29/Jul/14 02:01;junrao;This seems to be introduced by a bug in KAFKA-1542. I just committed a fix. After that, I don't see the unit test hanging issue any more.

David,

Could you try the test again?
;;;","29/Jul/14 16:17;heavydawson;Hey Jun, I can confirm the test is now passing. However your patch isn't converting the InetAddress to a string representation of the IP. It just needs to be updated to use:
{{getInetAddress().getHostAddress()}}
;;;","05/Sep/14 05:36;guozhang;Hi [~junrao] do you have time to fix this minor thing before 0.8.2 release?;;;","10/Sep/14 08:43;junrao;Yes, logging the InetAddress is fine. To get the remoteAddress, we will have to check if the InetAddress is not null, which makes the code a bit more complicated. So, we can resolve this issue now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Documentation bug: the default value for the ""rebalance.backoff.ms"" property is not specified correctly",KAFKA-2589,12901043,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,bbdimitriu,bbdimitriu,28/Sep/15 23:37,06/Feb/16 05:25,22/Mar/23 15:10,06/Feb/16 05:25,0.8.2.1,,,,,,0.10.0.0,0.9.0.1,,,,,,config,,,,0,,,,,,"The documentation for 0.8.2.1 consumer properties specifies:
| rebalance.backoff.ms | 2000 | Backoff time between retries during rebalance |
According to the source code though the default value is obtained this way:
{code}
val rebalanceBackoffMs = props.getInt(""rebalance.backoff.ms"", zkSyncTimeMs)
{code}
which is referenced from here:
{code}
val zkSyncTimeMs = props.getInt(""zookeeper.sync.time.ms"", 2000)
{code}
So by default it is 2000 as specified in the documentation, UNLESS the {{zookeeper.sync.time.ms}} is manually set to be different

This may create confusion with recommendations such:
{quote}
In the case, make sure that rebalance.max.retries * rebalance.backoff.ms > zookeeper.session.timeout.ms
{quote}
from here: https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Whyaretheremanyrebalancesinmyconsumerlog?",any,bbdimitriu,ewencp,githubbot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Feb 05 21:25:51 UTC 2016,,,,,,,,,,"0|i2mczj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"05/Feb/16 13:09;githubbot;GitHub user granthenke opened a pull request:

    https://github.com/apache/kafka/pull/876

    KAFKA-2589: the default value for the ""rebalance.backoff.ms"" property…

    … is not specified correctly

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka rebalance-doc

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/876.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #876
    
----
commit 746a3cc88b05cc26e727b66ae808148066a07f1f
Author: Grant Henke <granthenke@gmail.com>
Date:   2016-02-05T05:09:09Z

    KAFKA-2589: the default value for the ""rebalance.backoff.ms"" property is not specified correctly

----
;;;","06/Feb/16 05:25;ewencp;Issue resolved by pull request 876
[https://github.com/apache/kafka/pull/876];;;","06/Feb/16 05:25;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/876
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in the collate logic of the DefaultEventHandler dispatches empty list of messages using the producer,KAFKA-110,12519275,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,nehanarkhede,nehanarkhede,18/Aug/11 18:39,13/Sep/11 09:27,22/Mar/23 15:10,13/Sep/11 09:27,0.7,,,,,,0.7,,,,,,,,,,,0,,,,,,"The collate logic in the DefaultEventHandler is designed to batch together requests for a single topic and partition in order to send it to the server in a single request. In this collate logic, the use of the partition API might give back an empty sequence of data for a particular topic,partition pair. It is useless to add it to the list of data to be sent, and it should avoid making network requests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/11 18:50;nehanarkhede;KAFKA-110.patch;https://issues.apache.org/jira/secure/attachment/12490783/KAFKA-110.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,60817,,,Thu Aug 18 16:04:06 UTC 2011,,,,,,,,,,"0|i15yyv:",242965,,,,,,,,,,,,,,,,,,,,"18/Aug/11 18:50;nehanarkhede;This patch corrects the behavior of the collate API to avoid adding empty sequences of data to the list of events to be sent using the producer.

Also, it modifies the ProducerSendThread so that it never dispatches an empty list of events to the event handler.;;;","19/Aug/11 00:04;junrao;+1 (please remove unreferenced imports before checking in);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Documentation bug: Add information for key.serializer and value.serializer to New Producer Config sections,KAFKA-2412,12852438,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,gchao,jfields,jfields,06/Aug/15 08:25,17/Oct/15 06:09,22/Mar/23 15:10,17/Oct/15 06:09,,,,,,,0.9.0.0,,,,,,,,,,,0,newbie,,,,,"As key.serializer and value.serializer are required options when using the new producer, they should be mentioned in the documentation ( here and svn http://kafka.apache.org/documentation.html#newproducerconfigs )

Appropriate values for these options exist in javadoc and producer.java examples; however, not everyone is reading those, as is the case for anyone setting up a producer.config file for mirrormaker.

A sensible default should be suggested, such as
org.apache.kafka.common.serialization.StringSerializer
Or at least a mention of the key.serializer and value.serializer options along with a link to javadoc

Thanks",,darshankumar89,elephish,gchao,gwenshap,jfields,junrao,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/15 03:12;gchao;KAFKA-2412-r1.diff;https://issues.apache.org/jira/secure/attachment/12752070/KAFKA-2412-r1.diff","22/Aug/15 02:04;gchao;KAFKA-2412.diff;https://issues.apache.org/jira/secure/attachment/12751763/KAFKA-2412.diff",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Oct 16 22:09:46 UTC 2015,,,,,,,,,,"0|i2ieav:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"09/Aug/15 11:50;gwenshap;Also missing in action: max.in.flight.requests.per.connection;;;","09/Aug/15 13:32;darshankumar89;Hello all,

I am interested to work on this card and please let me know which repository and branch to work on and also a brief explanation of this issue. I want to learn and contribute to this project. 
I request you to please let me know to work on this. 
Please let me know your availability to connect.

Thank you;;;","09/Aug/15 15:13;gwenshap;Thank you.

Please take a look at our contributor guide: http://kafka.apache.org/contributing.html
Especially the section of ""Contributing A Change To The Website"" which is how you contribute improvements to the documentation.;;;","09/Aug/15 15:29;darshankumar89;Thank you. I have been following the same process as mentioned ""Contributing A Change To The Website"" in Atlas and falcon.
;;;","09/Aug/15 20:55;darshankumar89;I see key.serializer.class in the document http://kafka.apache.org/documentation.html#newproducerconfigs.

Please let me know what has to be done and also looking forwards for a brief explanation on your availability.

Thank you;;;","10/Aug/15 18:03;darshankumar89;Hi,

I have cloned the repository, git clone https://git-wip-us.apache.org/repos/asf/kafka.git kafka.

I will find the options  in javadoc and producer.java examples for key.serializer and value.serializer.

Thank you.;;;","22/Aug/15 02:00;gchao;I based the documentation for max.in.flight.requests.per.connection on Jay's answer at http://grokbase.com/t/kafka/users/14cj8np158/in-flight-requests and the documentation for  key/value.serializer on my own reading of the code + Manikumar's answer at https://groups.google.com/forum/#!topic/kafka-clients/Psh1tmVbktY.;;;","22/Aug/15 02:09;gchao;Also, this info https://cwiki.apache.org/confluence/display/KAFKA/Kafka+patch+review+tool doesn't seem to be written to work with the documentation/site which are stored in SVN and not Git. I can work on submitting an RB for this patch if that's preferred for documentation updates.;;;","22/Aug/15 02:48;gwenshap;Thank you for contributing! Documenting our configuration and producer behavior is super important, so I appreciate you taking this on.

I have two content related comments:

1. I'm not sure your recommendations for ""commonly used"" are actually common... Perhaps just pointing to the default implementations will be clear enough? Especially regarding String for value... I feel like we are pointing people toward an implementation we don't necessarily recommend.

2. Your explanation for ""in-flight"" uses the term ""in-flight"", perhaps it can be made more clear? I'm not sure how common this term is.
I don't really see where increasing this number can cause suboptimal batching. The ""waiting for batches"" behavior is controlled in linger.ms.
 Also, some warning that high in-flight value will increase throughput but can cause out-of-order arrivals?
;;;","25/Aug/15 03:09;gchao;1. Good point. I agree that pointing toward the default implementations is clear enough, since serialization is likely to be familiar to anybody who's using Kafka anyway.

2. Rephrased the explanation of ""in-flight requests"" to make it more clear what term is being defined. I can see why that was ambiguous before.

Regarding controlling batching behavior with linger.ms, it seems like increasing the number could cause suboptimal batching unless the user specifically sets linger.ms. If the max number of inflight requests is very high or unlimited, then the batch size is basically (number of enqueued requests per ms * linger.ms). Since linger.ms defaults to 0, batch size will end up being very small. I've added a pointer to linger.ms in the explanation for max.in.flight to address that.

I've also added the warning you mentioned about out-of-order arrivals, though I don't understand why that happens. Is there an issue I can read so that I can give a more detailed explanation (or is a more detailed explanation even appropriate?)

If the explanation of the out-of-order arrivals is not necessary, I've got a new diff ready that addresses all of your comments, otherwise I will add a more detailed explanation and then submit it.

Thanks for your feedback! It's very much appreciated.
Grayson;;;","25/Aug/15 04:10;wushujames;[~gchao], here are some slides that describe how out-of-order arrival is possible: http://www.slideshare.net/JiangjieQin/no-data-loss-pipeline-with-apache-kafka-49753844;;;","25/Aug/15 04:11;gchao;Thanks [~wushujames]!;;;","02/Sep/15 07:08;junrao;Those docs are auto generated. Perhaps we should fix ConfigDef.toHtmlTable() to add a ""required"" column.;;;","17/Oct/15 06:09;gwenshap;In 0.9.0.0 we plan to auto-generate the configuration docs from code, so all the necessary docs will be there automatically.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in ProducerFailureHandlingTest.testNotEnoughReplicasAfterBrokerShutdown,KAFKA-1976,12776764,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,junrao,junrao,23/Feb/15 12:37,21/Aug/15 15:20,22/Mar/23 15:10,04/Mar/15 08:57,0.9.0.0,,,,,,,,,,,,,core,,,,0,,,,,,"Saw the following failure a few times.

kafka.api.test.ProducerFailureHandlingTest > testNotEnoughReplicasAfterBrokerShutdown FAILED
    org.scalatest.junit.JUnitTestFailedError: Expected NotEnoughReplicasException when producing to topic with fewer brokers than min.insync.replicas
        at org.scalatest.junit.AssertionsForJUnit$class.newAssertionFailedException(AssertionsForJUnit.scala:101)
        at org.scalatest.junit.JUnit3Suite.newAssertionFailedException(JUnit3Suite.scala:149)
        at org.scalatest.Assertions$class.fail(Assertions.scala:711)
        at org.scalatest.junit.JUnit3Suite.fail(JUnit3Suite.scala:149)
        at kafka.api.test.ProducerFailureHandlingTest.testNotEnoughReplicasAfterBrokerShutdown(ProducerFailureHandlingTest.scala:352)
",,gwenshap,junrao,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Mar 04 00:57:01 UTC 2015,,,,,,,,,,"0|i25wtr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"23/Feb/15 12:39;junrao;I suspect the issue is the following: Since broker failure is handled asynchronously, we can get either NotEnoughReplicasException or NotEnoughReplicasAfterAppendException.;;;","23/Feb/15 12:41;sriharsha;[~junrao] I covered this issue as part of this JIRA https://issues.apache.org/jira/browse/KAFKA-1887;;;","23/Feb/15 12:43;gwenshap;Thanks [~harsha_ch].

As I mentioned in KAFKA-1887, both are legitimate exceptions for the test, since they are result of slightly different timings.;;;","04/Mar/15 08:57;junrao;Duplicate of KAFKA-1999.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Path length must be > 0"" error during startup",KAFKA-294,12545274,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,tomdz,tomdz,06/Mar/12 11:47,20/Jul/15 22:41,22/Mar/23 15:10,02/Oct/14 06:12,,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"When starting Kafka 0.7.0 using zkclient-0.1.jar, I get this error:

INFO 2012-03-06 02:39:04,072  main kafka.server.KafkaZooKeeper Registering broker /brokers/ids/1
FATAL 2012-03-06 02:39:04,111  main kafka.server.KafkaServer Fatal error during startup.
java.lang.IllegalArgumentException: Path length must be > 0
        at org.apache.zookeeper.common.PathUtils.validatePath(PathUtils.java:48)
        at org.apache.zookeeper.common.PathUtils.validatePath(PathUtils.java:35)
        at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:620)
        at org.I0Itec.zkclient.ZkConnection.create(ZkConnection.java:87)
        at org.I0Itec.zkclient.ZkClient$1.call(ZkClient.java:308)
        at org.I0Itec.zkclient.ZkClient$1.call(ZkClient.java:304)
        at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
        at org.I0Itec.zkclient.ZkClient.create(ZkClient.java:304)
        at org.I0Itec.zkclient.ZkClient.createPersistent(ZkClient.java:213)
        at org.I0Itec.zkclient.ZkClient.createPersistent(ZkClient.java:223)
        at org.I0Itec.zkclient.ZkClient.createPersistent(ZkClient.java:223)
        at kafka.utils.ZkUtils$.createParentPath(ZkUtils.scala:48)
        at kafka.utils.ZkUtils$.createEphemeralPath(ZkUtils.scala:60)
        at kafka.utils.ZkUtils$.createEphemeralPathExpectConflict(ZkUtils.scala:72)
        at kafka.server.KafkaZooKeeper.registerBrokerInZk(KafkaZooKeeper.scala:57)
        at kafka.log.LogManager.startup(LogManager.scala:124)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:80)
        at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:47)
        at kafka.Kafka$.main(Kafka.scala:60)
        at kafka.Kafka.main(Kafka.scala)

The problem seems to be this code in ZkClient's createPersistent method:

String parentDir = path.substring(0, path.lastIndexOf('/'));
createPersistent(parentDir, createParents);
createPersistent(path, createParents);

which doesn't check for whether parentDir is an empty string, which it will become for /brokers/ids/1 after two recursions.
",,anandnalya,githubbot,gwenshap,jbrosenberg,jbrosenberg@gmail.com,jkreps,junrao,lanzaa,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,230460,,,Mon Jul 20 14:41:27 UTC 2015,,,,,,,,,,"0|i029uf:",11196,,,,,,,,,,,,,,,,,,,,"06/Mar/12 23:33;junrao;Are you using namespace in ZK connection string? If so, the typical problem is that the namespace is not present. You have to manually create the namespace in ZK.;;;","07/Mar/12 00:55;tomdz;Ah I see, this is very non-descriptive error then. Maybe you could add this to the documentation/FAQ (or make the error more descriptive) ?;;;","09/Jun/12 03:33;jkreps;I think we can fix this so it gives a more intuitive error message that explains the problem. No one will be able to figure this out otherwise.;;;","09/May/13 13:05;jbrosenberg;This issue happens also in 0.8.0
It would be even better, if the chroot is not present in zk, that it be automatically created, thus avoiding this issue altogether.;;;","10/May/13 00:29;junrao;We can auto-create it, but then we can't prevent config mistakes. We can probably start by just providing a more meaningful error. One way is to just catch IllegalArgumentException with that message and covert it to a more meaningful exception (and message). Jason, you want to give this a shot?;;;","02/Oct/14 06:12;gwenshap;With KAFKA-404 committed, this is resolved too.;;;","20/Jul/15 22:41;githubbot;Github user fsaintjacques closed the pull request at:

    https://github.com/apache/kafka/pull/2
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
System Test Transient Failure on testcase_0122,KAFKA-772,12633953,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriramsub,jfung,jfung,26/Feb/13 01:34,06/Mar/13 00:26,22/Mar/23 15:10,05/Mar/13 14:41,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,kafka-0.8,p1,,,,"* This test case is failing randomly in the past few weeks. Please note there is a small % data loss allowance for the test case with Ack = 1. But the failure in this case is the mismatch of log segment checksum across the replicas.

* Test description:
3 brokers cluster
Replication factor = 3
No. topic = 2
No. partitions = 3
Controlled failure (kill -15)
Ack = 1

* Test case output
_test_case_name  :  testcase_0122
_test_class_name  :  ReplicaBasicTest
arg : auto_create_topic  :  true
arg : bounce_broker  :  true
arg : broker_type  :  leader
arg : message_producing_free_time_sec  :  15
arg : num_iteration  :  3
arg : num_partition  :  3
arg : replica_factor  :  3
arg : sleep_seconds_between_producer_calls  :  1
validation_status  : 
     Leader Election Latency - iter 1 brokerid 3  :  377.00 ms
     Leader Election Latency - iter 2 brokerid 1  :  374.00 ms
     Leader Election Latency - iter 3 brokerid 2  :  384.00 ms
     Leader Election Latency MAX  :  384.00
     Leader Election Latency MIN  :  374.00
     Unique messages from consumer on [test_1] at simple_consumer_test_1-0_r1.log  :  1750
     Unique messages from consumer on [test_1] at simple_consumer_test_1-0_r2.log  :  1750
     Unique messages from consumer on [test_1] at simple_consumer_test_1-0_r3.log  :  1750
     Unique messages from consumer on [test_1] at simple_consumer_test_1-1_r1.log  :  1750
     Unique messages from consumer on [test_1] at simple_consumer_test_1-1_r2.log  :  1750
     Unique messages from consumer on [test_1] at simple_consumer_test_1-1_r3.log  :  1750
     Unique messages from consumer on [test_1] at simple_consumer_test_1-2_r1.log  :  1500
     Unique messages from consumer on [test_1] at simple_consumer_test_1-2_r2.log  :  1500
     Unique messages from consumer on [test_1] at simple_consumer_test_1-2_r3.log  :  1500
     Unique messages from consumer on [test_2]  :  5000
     Unique messages from consumer on [test_2] at simple_consumer_test_2-0_r1.log  :  1714
     Unique messages from consumer on [test_2] at simple_consumer_test_2-0_r2.log  :  1714
     Unique messages from consumer on [test_2] at simple_consumer_test_2-0_r3.log  :  1680
     Unique messages from consumer on [test_2] at simple_consumer_test_2-1_r1.log  :  1708
     Unique messages from consumer on [test_2] at simple_consumer_test_2-1_r2.log  :  1708
     Unique messages from consumer on [test_2] at simple_consumer_test_2-1_r3.log  :  1708
     Unique messages from consumer on [test_2] at simple_consumer_test_2-2_r1.log  :  1469
     Unique messages from consumer on [test_2] at simple_consumer_test_2-2_r2.log  :  1469
     Unique messages from consumer on [test_2] at simple_consumer_test_2-2_r3.log  :  1469
     Unique messages from producer on [test_2]  :  4900
     Validate for data matched on topic [test_1] across replicas  :  PASSED
     Validate for data matched on topic [test_2]  :  FAILED
     Validate for data matched on topic [test_2] across replicas  :  FAILED
     Validate for merged log segment checksum in cluster [source]  :  FAILED
     Validate leader election successful  :  PASSED
",,jfung,junrao,nehanarkhede,sriramsub,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/13 06:44;sriramsub;KAFKA-772.patch;https://issues.apache.org/jira/secure/attachment/12571974/KAFKA-772.patch","26/Feb/13 01:35;jfung;testcase_0122.tar.gz;https://issues.apache.org/jira/secure/attachment/12570815/testcase_0122.tar.gz","02/Mar/13 02:03;jfung;testcase_0125.tar.gz;https://issues.apache.org/jira/secure/attachment/12571621/testcase_0125.tar.gz",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,314447,,,Tue Mar 05 16:26:48 UTC 2013,,,,,,,,,,"0|i1i9gf:",314791,,,,,,,,,,,,,,,,,,,,"26/Feb/13 01:35;jfung;Attached a tar file for all log4j messages and data log files;;;","01/Mar/13 05:59;sriramsub;There are two issues with the given logs. Both the issues are for topic 2 - partition 0 on broker 3.

1. Segment 1 starting with logical offset 0 on broker 3 does not have continuous logical offsets. Logical offset 699 is followed by 734. 
2. Segment 2 starting with logical offset 974 on broker 3 is 0 bytes while that in broker 2 has values from 974 to 1713. Broker 3 has segment 3 starting with logical offset 1012 to 1713. Broker 2 does not have any third segment.

We have run the test in a loop multiple times for a day but have not been able to repro this on the local box. I am still investigating how the logs could end up in this state during continuous restarts with ack = 0 and replication factor = 3 ;;;","02/Mar/13 01:54;jfung;There is a similar failure in testcase_0125 yesterday in our distributed environment. Attached the log4j messages and data log segment files for reference.

The failure is as follows (similar to testcase_0122):

     Unique messages from consumer on [test_1] at simple_consumer_test_1-0_r1.log  :  1715
     Unique messages from consumer on [test_1] at simple_consumer_test_1-0_r2.log  :  1715
     Unique messages from consumer on [test_1] at simple_consumer_test_1-0_r3.log  :  1715
     Unique messages from consumer on [test_1] at simple_consumer_test_1-1_r1.log  :  1711
     Unique messages from consumer on [test_1] at simple_consumer_test_1-1_r2.log  :  1711
     Unique messages from consumer on [test_1] at simple_consumer_test_1-1_r3.log  :  1711
     Unique messages from consumer on [test_1] at simple_consumer_test_1-2_r1.log  :  1469
     Unique messages from consumer on [test_1] at simple_consumer_test_1-2_r2.log  :  1469
     Unique messages from consumer on [test_1] at simple_consumer_test_1-2_r3.log  :  1469
     Unique messages from consumer on [test_2]  :  4895
     Unique messages from consumer on [test_2] at simple_consumer_test_2-0_r1.log  :  1715
     Unique messages from consumer on [test_2] at simple_consumer_test_2-0_r2.log  :  1715
     Unique messages from consumer on [test_2] at simple_consumer_test_2-0_r3.log  :  1682
     Unique messages from consumer on [test_2] at simple_consumer_test_2-1_r1.log  :  1708
     Unique messages from consumer on [test_2] at simple_consumer_test_2-1_r2.log  :  1708
     Unique messages from consumer on [test_2] at simple_consumer_test_2-1_r3.log  :  1708
     Unique messages from consumer on [test_2] at simple_consumer_test_2-2_r1.log  :  1467
     Unique messages from consumer on [test_2] at simple_consumer_test_2-2_r2.log  :  1467
     Unique messages from consumer on [test_2] at simple_consumer_test_2-2_r3.log  :  1467
     Unique messages from producer on [test_2]  :  4900
     Validate for data matched on topic [test_1] across replicas  :  PASSED
     Validate for data matched on topic [test_2]  :  PASSED
     Validate for data matched on topic [test_2] across replicas  :  FAILED
     Validate for merged log segment checksum in cluster [source]  :  FAILED
     Validate leader election successful  :  PASSED
;;;","05/Mar/13 08:03;nehanarkhede;It would be useful to maybe add a WARN message and log the topic, partition, replica id, current offset, fetch offset when this happens. Other than that, this fix looks good.;;;","05/Mar/13 08:14;sriramsub;I would like WARN to be actionable. Do you think it would be useful in this case? I am thinking what we would do if we saw this message in the log now that we know this is a valid case.;;;","05/Mar/13 08:29;sriramsub;The test failed on Monday and then again failed on Friday. It was clear that the issue was timing related. We tried to reproduce the failure on the local box (repeatedly running the test) but could not reproduce it. I did some code browsing but did not have much luck. So I decided to setup tracing and run the test repeatedly in a distributed environment over the weekend and was hoping that it would fail. Luckily, it did and the trace logs proved to be useful in identifying the issue. Thanks to John for setting this up.

What you see below are excerpts from the trace log which pertain to this failure at different points in time. In this particular failure, topic_2 / partitions 2 had missing logical offsets from 570 to 582 on broker 3 (3 brokers in total).

current fetch offset = 582 
current HW = 570
Leader for topic_2/partition 2 = broker 2

1. The lines below show the Fetch request that was issued by broker 3 to broker 2 just before broker 1 was shutdown. The requested offset is 582 for [test_2,2].

[2013-03-02 12:37:56,034] TRACE [ReplicaFetcherThread-0-2], issuing to broker 2 of fetch request Name: FetchRequest; Version: 0; CorrelationId: 121; ClientId: ReplicaFetcherThread-0-2; ReplicaId: 3; MaxWait: 500 ms; MinBytes: 4096 bytes; RequestInfo: [test_1,0] -> PartitionFetchInfo(700,1048576),[test_2,1] -> PartitionFetchInfo(677,1048576),[test_2,2] -> PartitionFetchInfo(582,1048576),[test_2,0] -> PartitionFetchInfo(679,1048576),[test_1,2] -> PartitionFetchInfo(600,1048576),[test_1,1] -> PartitionFetchInfo(699,1048576) (kafka.server.ReplicaFetcherThread)

2. Broker 1 is shutdown and broker 3 handles leader and isr request. Note that [test_2,2] still follows broker 2 but we still issue a makefollower call for it.

[2013-03-02 12:37:56,086] INFO Replica Manager on Broker 3: Handling leader and isr request Name: LeaderAndIsrRequest; Version: 0; CorrelationId: 2; ClientId: ; AckTimeoutMs: 1000 ms; ControllerEpoch: 2; PartitionStateInfo: (test_1,0) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,1,3"", ""leader"":""2"", ""leaderEpoch"":""1"" },1),3),(test_2,1) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,3"", ""leader"":""2"", ""leaderEpoch"":""2"" },2),3),(test_2,2) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,1,3"", ""leader"":""2"", ""leaderEpoch"":""1"" },1),3),(test_2,0) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,3"", ""leader"":""2"", ""leaderEpoch"":""2"" },2),3),(test_1,2) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,3"", ""leader"":""2"", ""leaderEpoch"":""2"" },2),3),(test_1,1) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,1,3"", ""leader"":""2"", ""leaderEpoch"":""1"" },1),3); Leaders: id:2,host:xxxx(kafka.server.ReplicaManager)

3. The leader and isr request results in removing the fetcher to broker 2 for [test_2,2], truncating the log to high watermark (570) and then adding back the fetcher to the same broker.

[2013-03-02 12:37:56,088] INFO [ReplicaFetcherManager on broker 3] removing fetcher on topic test_2, partition 2 (kafka.server.ReplicaFetcherManager)
[2013-03-02 12:37:56,088] INFO [Kafka Log on Broker 3], Truncated log segment /tmp/kafka_server_3_logs/test_2-2/00000000000000000000.log to target offset 570 (kafka.log.Log)
[2013-03-02 12:37:56,088] INFO [ReplicaFetcherManager on broker 3] adding fetcher on topic test_2, partion 2, initOffset 570 to broker 2 with fetcherId 0 (kafka.server.ReplicaFetcherManager)

4. The leader and isr request is completed at this point of time.

[2013-03-02 12:37:56,090] INFO Replica Manager on Broker 3: Completed leader and isr request Name: LeaderAndIsrRequest; Version: 0; CorrelationId: 2; ClientId: ; AckTimeoutMs: 1000 ms; ControllerEpoch: 2; PartitionStateInfo: (test_1,0) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,1,3"", ""leader"":""2"", ""leaderEpoch"":""1"" },1),3),(test_2,1) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,3"", ""leader"":""2"", ""leaderEpoch"":""2"" },2),3),(test_2,2) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,1,3"", ""leader"":""2"", ""leaderEpoch"":""1"" },1),3),(test_2,0) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,3"", ""leader"":""2"", ""leaderEpoch"":""2"" },2),3),(test_1,2) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,3"", ""leader"":""2"", ""leaderEpoch"":""2"" },2),3),(test_1,1) -> PartitionStateInfo(LeaderIsrAndControllerEpoch({ ""ISR"":""2,1,3"", ""leader"":""2"", ""leaderEpoch"":""1"" },1),3); Leaders: id:2,host:xxxx (kafka.server.ReplicaManager)


5.  A log append happens at offset 582 though the nextOffset for the log is at 570. This append actually pertains to the fetch request at step 1. This explains the gap in the log.

[2013-03-02 12:37:56,098] TRACE [Kafka Log on Broker 3], Appending message set to test_2-2 offset: 582 nextOffset: 570 messageSet: ByteBufferMessageSet(MessageAndOffset(Message(magic = 0, attributes = 0, crc = 1408289663, key = null, payload = java.nio.HeapByteBuffer[pos=0 lim=500 cap=500]),582), MessageAndOffset(Message(magic = 0, attributes = 0, crc = 3696400058, key = null, payload = java.nio.HeapByteBuffer[pos=0 lim=500 cap=500]),583), MessageAndOffset(Message(magic = 0, attributes = 0, crc = 2403920749, key = null, payload = java.nio.HeapByteBuffer[pos=0 lim=500 cap=500]),584), ) (kafka.log.Log)

From the set of steps above, it is clear that some thing is causing the fetch request at step 1 to complete even though step 2 and 3 removed the fetcher for that topic,partition.

Looking at the code now it becomes obvious. The race condition is between the thread that removes the fetcher, truncates the log and adds the fetcher back and the thread that fetches bytes from the leader. Follow the steps below to understand what is happening.

Partition.Scala

          replicaFetcherManager.removeFetcher(topic, partitionId)           --> step 2 : Removes the topic,partition – offset mapping from partitionMap in AbstractFetcherThread
          // make sure local replica exists
          val localReplica = getOrCreateReplica()
          localReplica.log.get.truncateTo(localReplica.highWatermark)    --> step 3 : Truncates to offset 570
          inSyncReplicas = Set.empty[Replica]
          leaderEpoch = leaderAndIsr.leaderEpoch
          zkVersion = leaderAndIsr.zkVersion
          leaderReplicaIdOpt = Some(newLeaderBrokerId)
          // start fetcher thread to current leader
          replicaFetcherManager.addFetcher(topic, partitionId, localReplica.logEndOffset, leaderBroker)    --> step 4: Sets the new fetcher to fetch from the log end offset which is at 570 at this point

AbstractFetcherThread.Scala

private def processFetchRequest(fetchRequest: FetchRequest) {
    val partitionsWithError = new mutable.HashSet[TopicAndPartition]
    var response: FetchResponse = null
    try {
      trace(""issuing to broker %d of fetch request %s"".format(sourceBroker.id, fetchRequest))
      response = simpleConsumer.fetch(fetchRequest)
    } catch {
      case t =>
        debug(""error in fetch %s"".format(fetchRequest), t)
        if (isRunning.get) {
          partitionMapLock synchronized {
            partitionsWithError ++= partitionMap.keys
          }
        }
    }
    fetcherStats.requestRate.mark()   -->  step 1 : Fetch completes. Fetch request is from offset 582.

    if (response != null) {
      // process fetched data 
      partitionMapLock.lock()     ---> step 5: This is where the fetch request is waiting when the addFetcher in Partition.Scala is executing above
      try {
        response.data.foreach {
          case(topicAndPartition, partitionData) =>
            val (topic, partitionId) = topicAndPartition.asTuple
            val currentOffset = partitionMap.get(topicAndPartition)
            if (currentOffset.isDefined) {
              partitionData.error match {
                case ErrorMapping.NoError =>
                  val messages = partitionData.messages.asInstanceOf[ByteBufferMessageSet]
                  val validBytes = messages.validBytes
                  val newOffset = messages.lastOption match {          -->  step 6: The newOffset is set to 587 and partitionMap is updated
                    case Some(m: MessageAndOffset) => m.nextOffset
                    case None => currentOffset.get
                  }
                  partitionMap.put(topicAndPartition, newOffset)
                  fetcherLagStats.getFetcherLagStats(topic, partitionId).lag = partitionData.hw - newOffset
                  fetcherStats.byteRate.mark(validBytes)
                  // Once we hand off the partition data to the subclass, we can't mess with it any more in this thread
                  processPartitionData(topicAndPartition, currentOffset.get, partitionData)    --> step 7: This appends data to the log with logical offsets from 582 – 587. Note that the offset passed to this method is 570 (currentOffset). Hence all offset validation checks in processPartitionData passes.
                case ErrorMapping.OffsetOutOfRangeCode =>
                  try {
                    val newOffset = handleOffsetOutOfRange(topicAndPartition)
                    partitionMap.put(topicAndPartition, newOffset)
                    warn(""current offset %d for topic %s partition %d out of range; reset offset to %d""
                      .format(currentOffset.get, topic, partitionId, newOffset))
                  } catch {
                    case e =>
                      warn(""error getting offset for %s %d to broker %d"".format(topic, partitionId, sourceBroker.id), e)
                      partitionsWithError += topicAndPartition
                  }
                case _ =>
                  warn(""error for %s %d to broker %d"".format(topic, partitionId, sourceBroker.id),
                    ErrorMapping.exceptionFor(partitionData.error))
                  partitionsWithError += topicAndPartition
              }
            }
        }
      } finally {
        partitionMapLock.unlock()
      }
    };;;","05/Mar/13 14:41;junrao;Thanks for the patch. Committed to 0.8.;;;","06/Mar/13 00:26;nehanarkhede;Yeah, probably ok to skip the message;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Partition reassignment failure for brokers freshly added to cluster,KAFKA-3228,12938533,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,nehanarkhede,noslowerdna,noslowerdna,11/Feb/16 23:03,05/Dec/16 22:11,22/Mar/23 15:10,05/Dec/16 20:16,0.8.2.1,,,,,,,,,,,,,controller,,,,0,,,,,,"After adding about new 20 brokers to double the size of an existing production Kafka deployment, when attempting to rebalance partitions we were initially unable to reassign any partitions to 5 of the 20. There was no problem with the other 15. The controller broker logged error messages like:

{noformat}
ERROR kafka.controller.KafkaController: [Controller 19]: Error completing reassignment of partition [TOPIC-NAME,2]
kafka.common.KafkaException: Only 4,33 replicas out of the new set of replicas 4,34,33 for partition [TOPIC-NAME,2]
to be reassigned are alive. Failing partition reassignment
	at kafka.controller.KafkaController.initiateReassignReplicasForTopicPartition(KafkaController.scala:611)
	at kafka.controller.PartitionsReassignedListener$$anonfun$handleDataChange$4$$anonfun$apply$6.apply$mcV$sp(KafkaController.scala:1203)
	at kafka.controller.PartitionsReassignedListener$$anonfun$handleDataChange$4$$anonfun$apply$6.apply(KafkaController.scala:1197)
	at kafka.controller.PartitionsReassignedListener$$anonfun$handleDataChange$4$$anonfun$apply$6.apply(KafkaController.scala:1197)
	at kafka.utils.Utils$.inLock(Utils.scala:535)
	at kafka.controller.PartitionsReassignedListener$$anonfun$handleDataChange$4.apply(KafkaController.scala:1196)
	at kafka.controller.PartitionsReassignedListener$$anonfun$handleDataChange$4.apply(KafkaController.scala:1195)
	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:224)
	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:403)
	at kafka.controller.PartitionsReassignedListener.handleDataChange(KafkaController.scala:1195)
	at org.I0Itec.zkclient.ZkClient$7.run(ZkClient.java:751)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
{noformat}

We reattempted the reassignment to one of these new brokers, with the same result.

We also saw these messages in the controller's log. There was a ""Broken pipe"" error for each of the new brokers.

{noformat}
2016-02-09 12:13:22,082 WARN kafka.controller.RequestSendThread: [Controller-19-to-broker-34-send-thread],
Controller 19 epoch 28 fails to send request Name:UpdateMetadataRequest...
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.writev0(Native Method)
	at sun.nio.ch.SocketDispatcher.writev(SocketDispatcher.java:51)
	at sun.nio.ch.IOUtil.write(IOUtil.java:148)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:504)
	at java.nio.channels.SocketChannel.write(SocketChannel.java:502)
	at kafka.network.BoundedByteBufferSend.writeTo(BoundedByteBufferSend.scala:56)
	at kafka.network.Send$class.writeCompletely(Transmission.scala:75)
	at kafka.network.BoundedByteBufferSend.writeCompletely(BoundedByteBufferSend.scala:26)
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:103)
	at kafka.controller.RequestSendThread.liftedTree1$1(ControllerChannelManager.scala:132)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:131)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)
{noformat}

{noformat}
WARN kafka.controller.RequestSendThread: [Controller-19-to-broker-34-send-thread],
Controller 19 epoch 28 fails to send request Name:UpdateMetadataRequest... to broker id:34...
Reconnecting to broker.
java.io.EOFException: Received -1 when reading from channel, socket has likely been closed.
	at kafka.utils.Utils$.read(Utils.scala:381)
	at kafka.network.BoundedByteBufferReceive.readFrom(BoundedByteBufferReceive.scala:54)
	at kafka.network.Receive$class.readCompletely(Transmission.scala:56)
	at kafka.network.BoundedByteBufferReceive.readCompletely(BoundedByteBufferReceive.scala:29)
	at kafka.network.BlockingChannel.receive(BlockingChannel.scala:111)
	at kafka.controller.RequestSendThread.liftedTree1$1(ControllerChannelManager.scala:133)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:131)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)
{noformat}

{noformat}
INFO kafka.controller.RequestSendThread: [Controller-19-to-broker-34-send-thread], Controller 19 connected
to id:34... for sending state change requests
{noformat}

There were no error messages in the new broker log files, just the normal startup logs. A jstack did not reveal anything unusual with the threads, and using netstat the network connections looked normal.

We're running version 0.8.2.1. The new brokers were simultaneously started  using a broadcast-style command. However we also had the same issue with a different Kafka cluster after starting up the new brokers individually about 30 seconds apart.

After stopping and restarting the 5 problematic new brokers, the reassignment was then successful, and they are now functioning normally.",,ijuma,noslowerdna,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-4214,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Dec 05 14:11:55 UTC 2016,,,,,,,,,,"0|i2sq5r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"05/Dec/16 20:16;ijuma;I think this is the same as KAFKA-4214. Please reopen if you disagree.;;;","05/Dec/16 22:03;noslowerdna;Since the exception message that we saw has been removed from the code, I agree that this should be marked resolved. The bug description for KAFKA-4214 makes sense for applicability to this scenario as well.;;;","05/Dec/16 22:04;noslowerdna;Added fix version and duplicate link.;;;","05/Dec/16 22:11;ijuma;Thanks for confirming. I removed the fix version to avoid having duplicates in the release notes, it's enough to have the issue that has the ""Fixed"" resolution.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in SocketServerTest,KAFKA-1400,12708817,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,17/Apr/14 00:09,22/May/18 07:21,22/Mar/23 15:10,28/Feb/15 03:54,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Saw the following transient failure.
kafka.network.SocketServerTest > testSocketsCloseOnShutdown FAILED java.lang.AssertionError: Expected exception: java.net.SocketException 
",,githubbot,gwenshap,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/14 06:27;nehanarkhede;KAFKA-1400.patch;https://issues.apache.org/jira/secure/attachment/12641131/KAFKA-1400.patch","27/Feb/15 08:15;junrao;kafka-1400.patch;https://issues.apache.org/jira/secure/attachment/12701217/kafka-1400.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,387140,,,Mon May 21 23:21:26 UTC 2018,,,,,,,,,,"0|i1uowf:",387403,,,,,,,,,,,,,,,,,,,,"17/Apr/14 00:09;junrao;Perhaps we should expect IOException instead of SocketException.;;;","22/Apr/14 06:27;nehanarkhede;Created reviewboard https://reviews.apache.org/r/20537/
 against branch trunk;;;","29/Apr/14 08:03;junrao;Thanks for the patch. Committed to trunk.;;;","19/Aug/14 09:12;gwenshap;Still seeing the same issue (occasionally).  Except now the Expected Exception is IOException. (no pun intended...)

I'm wondering if this is a race condition. Perhaps the server doesn't complete shutdown before we are sending the request? 

Should we re-open this jira? or open a new one?;;;","19/Aug/14 12:23;junrao;Gwen,

Not sure what the problem is. We can reopen this one. Do you know what exception is thrown, if it's not IOException?;;;","20/Aug/14 01:07;gwenshap;No exception is thrown. Thats the problem :)

I believe that server.shutdown() returns before shutdown is complete, and the next send() command (the one that should fail with an IOException) actually succeeds. 

I hate adding ""sleep"" to unit tests, but I'm not sure how else to avoid the send() succeeding and the test failing.;;;","20/Aug/14 02:18;nehanarkhede;[~gwenshap], to see if you are observing the same problem, it will be helpful to have the log4j output from the failed test. Could you paste it here?;;;","20/Aug/14 10:41;gwenshap;Good idea. Will do that next time the issue reproduces.;;;","26/Feb/15 07:26;gwenshap;.... and here are the logs :

{code}
[2015-02-25 15:11:10,002] INFO Awaiting socket connections on 0.0.0.0:52503. (kafka.network.Acceptor:68)
[2015-02-25 15:11:10,007] INFO [Socket Server on Broker 0], Started (kafka.network.SocketServer:68)
[2015-02-25 15:11:10,096] INFO Awaiting socket connections on 0.0.0.0:52504. (kafka.network.Acceptor:68)
[2015-02-25 15:11:10,096] INFO [Socket Server on Broker 0], Started (kafka.network.SocketServer:68)
wrote data to socket Socket[addr=localhost/127.0.0.1,port=52504,localport=52505]
[2015-02-25 15:11:10,111] DEBUG Accepted connection from /127.0.0.1 on /127.0.0.1:52504. sendBufferSize [actual|requested]: [300000|300000] recvBufferSize [actual|requested]: [310308|300000] (kafka.network.Acceptor:52)
[2015-02-25 15:11:10,114] TRACE Processor id 0 selection time = 17218000 ns (kafka.network.Processor:36)
[2015-02-25 15:11:10,115] DEBUG Processor 0 listening to new connection from /127.0.0.1:52505 (kafka.network.Processor:52)
[2015-02-25 15:11:10,115] TRACE Processor id 0 selection time = 36000 ns (kafka.network.Processor:36)
[2015-02-25 15:11:10,121] TRACE 42 bytes read from /127.0.0.1:52505 (kafka.network.Processor:36)
[2015-02-25 15:11:10,160] TRACE Processor 1 received request : Name: ProducerRequest; Version: 0; CorrelationId: 0; ClientId: ; RequiredAcks: 0; AckTimeoutMs: 0 ms; TopicAndPartition:  (kafka.network.RequestChannel$:36)
[2015-02-25 15:11:10,161] TRACE Processor 0 received request : Name: ProducerRequest; Version: 0; CorrelationId: 0; ClientId: ; RequiredAcks: 0; AckTimeoutMs: 0 ms; TopicAndPartition:  (kafka.network.RequestChannel$:36)
[2015-02-25 15:11:10,165] TRACE Processor id 0 selection time = 3599000 ns (kafka.network.Processor:36)
[2015-02-25 15:11:10,165] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer:68)
[2015-02-25 15:11:10,166] DEBUG Closing server socket and selector. (kafka.network.Acceptor:52)
[2015-02-25 15:11:10,166] TRACE Socket server received response to send, registering for write: Response(0,Request(0,sun.nio.ch.SelectionKeyImpl@4328493c,null,1424905870123,/127.0.0.1:52505),kafka.network.BoundedByteBufferSend@318b1420,SendAction) (kafka.network.Processor:36)
[2015-02-25 15:11:10,167] TRACE Processor id 0 selection time = 26000 ns (kafka.network.Processor:36)
[2015-02-25 15:11:10,170] TRACE 22 bytes written to /127.0.0.1:52505 using key sun.nio.ch.SelectionKeyImpl@4328493c (kafka.network.Processor:36)
[2015-02-25 15:11:10,170] DEBUG is socket ServerSocket[addr=/0:0:0:0:0:0:0:0,localport=52504] closed? true (kafka.network.Acceptor:52)
[2015-02-25 15:11:10,171] DEBUG Done shutting down acceptor. (kafka.network.Acceptor:52)
[2015-02-25 15:11:10,231] TRACE Completed request:Name: ProducerRequest; Version: 0; CorrelationId: 0; ClientId: ; RequiredAcks: 0; AckTimeoutMs: 0 ms; TopicAndPartition:  from client /127.0.0.1:52505;totalTime:47,requestQueueTime:0,localTime:1424905870165,remoteTime:0,responseQueueTime:1,sendTime:5 (kafka.request.logger:85)
[2015-02-25 15:11:10,232] TRACE Finished writing, registering for read on connection /127.0.0.1:52505 (kafka.network.Processor:36)
[2015-02-25 15:11:10,232] DEBUG Closing selector. (kafka.network.Processor:52)
[2015-02-25 15:11:10,233] DEBUG Closing connection from /127.0.0.1:52505 (kafka.network.Processor:52)
[2015-02-25 15:11:10,237] DEBUG done shutting down processor (kafka.network.Processor:52)
[2015-02-25 15:11:10,237] INFO [Socket Server on Broker 0], SocketServer: Shutdown completed (kafka.network.SocketServer:68)
wrote data to socket Socket[addr=localhost/127.0.0.1,port=52504,localport=52505]
- testSocketsCloseOnShutdown
{code}

Note that we successfully wrote to the socket (... the ""wrote data"" line is logged after calling flush() and sending the request). This is with trunk code (I added few extra log lines for clarity).

Are we sure that writing a single packet (we are not sending a lot of data) to a server that did socket.close() is actually expected to fail?

Because it looks like this may not be the case:
http://stackoverflow.com/questions/11436013/writing-to-a-closed-local-tcp-socket-not-failing
;;;","26/Feb/15 09:00;gwenshap;Kinda strange, the TCPDUMP looks the same whether I get an exception or not:

{code}
16:52:17.249207 IP localhost.55538 > localhost.9095: Flags [S], seq 3746193634, win 65535, options [mss 16344,nop,wscale 5,nop,nop,TS val 1314712608 ecr 0,sackOK,eol], length 0
16:52:17.249257 IP localhost.9095 > localhost.55538: Flags [S.], seq 999508519, ack 3746193635, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1314712608 ecr 1314712608,sackOK,eol], length 0
16:52:17.249264 IP localhost.55538 > localhost.9095: Flags [.], ack 1, win 12759, options [nop,nop,TS val 1314712608 ecr 1314712608], length 0
16:52:17.249270 IP localhost.9095 > localhost.55538: Flags [.], ack 1, win 38788, options [nop,nop,TS val 1314712608 ecr 1314712608], length 0
16:52:22.436127 IP localhost.55538 > localhost.9095: Flags [P.], seq 1:2, ack 1, win 12759, options [nop,nop,TS val 1314717768 ecr 1314712608], length 1
16:52:22.436162 IP localhost.9095 > localhost.55538: Flags [.], ack 2, win 38788, options [nop,nop,TS val 1314717768 ecr 1314717768], length 0
16:52:22.436169 IP localhost.55538 > localhost.9095: Flags [P.], seq 2:7, ack 1, win 12759, options [nop,nop,TS val 1314717768 ecr 1314717768], length 5
16:52:22.436173 IP localhost.9095 > localhost.55538: Flags [.], ack 7, win 38787, options [nop,nop,TS val 1314717768 ecr 1314717768], length 0
16:52:22.436177 IP localhost.55538 > localhost.9095: Flags [P.], seq 7:47, ack 1, win 12759, options [nop,nop,TS val 1314717768 ecr 1314717768], length 40
16:52:22.436180 IP localhost.9095 > localhost.55538: Flags [.], ack 47, win 38782, options [nop,nop,TS val 1314717768 ecr 1314717768], length 0
16:52:22.484320 IP localhost.9095 > localhost.55538: Flags [P.], seq 1:23, ack 47, win 38782, options [nop,nop,TS val 1314717808 ecr 1314717768], length 22
16:52:22.484353 IP localhost.55538 > localhost.9095: Flags [.], ack 23, win 12758, options [nop,nop,TS val 1314717808 ecr 1314717808], length 0
16:52:22.552365 IP localhost.9095 > localhost.55538: Flags [F.], seq 23, ack 47, win 38782, options [nop,nop,TS val 1314717872 ecr 1314717808], length 0
16:52:22.552372 IP localhost.55538 > localhost.9095: Flags [.], ack 24, win 12758, options [nop,nop,TS val 1314717872 ecr 1314717872], length 0
16:52:22.552376 IP localhost.9095 > localhost.55538: Flags [.], ack 47, win 38782, options [nop,nop,TS val 1314717872 ecr 1314717872], length 0
16:52:28.632196 IP localhost.55538 > localhost.9095: Flags [P.], seq 47:48, ack 24, win 12758, options [nop,nop,TS val 1314723916 ecr 1314717872], length 1
16:52:28.632235 IP localhost.9095 > localhost.55538: Flags [R], seq 999508543, win 0, length 0
{code}

I get a FIN, I ack it. I send one extra packet and I get a RST. Pretty much as expected.

Whether I get an exception or not, OTOH is completely random. I'm guessing this is because the .write() and .flush() methods are async.

As documented for output stream: The <code>flush</code> method of <code>OutputStream</code> does nothing.

I *think* that if I force a sleep after some bytes were written, I'll always get an exception. I'm not too happy with this approach.

Any thoughts?

;;;","26/Feb/15 09:27;gwenshap;On second thought, why do we even try to detect from the client whether the server closed the connection? 

We have the server right there... we can just:
Assert(server.acceptor.socket.isClosed)

Any reason not to do this?;;;","27/Feb/15 08:15;junrao;Created reviewboard https://reviews.apache.org/r/31510/diff/
 against branch origin/trunk;;;","27/Feb/15 08:16;junrao;Provide a simple fix to send enough bytes to trigger a socket flush. Without the patch, the unit test failed 3 times on 10 tries. With the patch, it didn't fail in 20 tries.;;;","27/Feb/15 09:30;gwenshap;Any reason you prefer to try and detect a closed socket from the client side, rather than check the state of the socket on the server?;;;","27/Feb/15 09:35;junrao;Well, this test is supposed to test the client behavior. On the server side, we know the socket will be closed on shutdown.;;;","27/Feb/15 10:01;gwenshap;I was under the impression that this was there to validate that the SocketServer actually closes the sockets as intended.

Isn't the client behavior when writing to a closed socket part of Java's NIO implementation (and the OS socket implementation, and TCP specs...) and largely outside our control?

Your fix is obviously valid, so I'm not really arguing against your patch. Just trying to clarify my own understanding.;;;","28/Feb/15 03:47;junrao;Yes, that's probably the goal of this test. The checking on the socket server may be a bit involved though since in addition to checking the socket for the acceptor, we probably need to check the sockets in each of the processors. Testing from the client seems simpler to me.

How about this: let me check in my patch. I will resolve this jira, but not close it. If you have a better patch, feel free to reopen the jira.;;;","28/Feb/15 03:54;junrao;Thanks for the review. Committed to trunk.;;;","28/Feb/15 04:48;gwenshap;Awesome. I'm just happy to see this fixed :)

It drove me mad, especially since I wasn't sure if its just my multi-port work, or a more general problem...;;;","22/May/18 07:15;githubbot;JimGalasyn opened a new pull request #5056: KAFKA-1400: Fix link in num.standby.replicas section
URL: https://github.com/apache/kafka/pull/5056
 
 
   Replace broken link with link to [State restoration during workload rebalance](https://docs.confluent.io/current/streams/developer-guide/running-app.html#state-restoration-during-workload-rebalance). Fixes [KSTREAMS-1400: AK docs: broken link in section on num.standby.replicas](https://confluentinc.atlassian.net/browse/KSTREAMS-1400).

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;","22/May/18 07:21;githubbot;JimGalasyn opened a new pull request #142: KAFKA-1400: Fix link in num.standby.replicas section
URL: https://github.com/apache/kafka-site/pull/142
 
 
   Replace broken link with link to [State restoration during workload rebalance](https://docs.confluent.io/current/streams/developer-guide/running-app.html#state-restoration-during-workload-rebalance). Fixes [KSTREAMS-1400: AK docs: broken link in section on num.standby.replicas](https://confluentinc.atlassian.net/browse/KSTREAMS-1400).

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in SocketServerTest,KAFKA-1383,12707620,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,10/Apr/14 09:55,29/Apr/14 06:03,22/Mar/23 15:10,29/Apr/14 06:03,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Saw the following transient unit test failure.

kafka.network.SocketServerTest > testNullResponse FAILED
    java.lang.AssertionError: null
        at org.junit.Assert.fail(Assert.java:69)
        at org.junit.Assert.assertTrue(Assert.java:32)
        at org.junit.Assert.assertFalse(Assert.java:51)
        at org.junit.Assert.assertFalse(Assert.java:60)
        at kafka.network.SocketServerTest.testNullResponse(SocketServerTest.scala:117)
",,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1422,,,,,,,,,,,,,,,,,,"29/Apr/14 01:44;junrao;KAFKA-1383.patch;https://issues.apache.org/jira/secure/attachment/12642287/KAFKA-1383.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,385943,,,Mon Apr 28 22:03:56 UTC 2014,,,,,,,,,,"0|i1uhjb:",386207,,,,,,,,,,,,,,,,,,,,"23/Apr/14 05:23;guozhang;[~junrao] Is this fixed by KAFKA-1400 or a different issue?;;;","23/Apr/14 05:28;junrao;This seems to be a different issue. Not sure what the cause is.;;;","29/Apr/14 01:43;junrao;The problem is the following. The interestOps is updated by the processor thread after the request is put in the request queue. There is no guarantee that after a request is dequeued, the read bit in interestOps is turned off. So need to wait a bit.;;;","29/Apr/14 01:44;junrao;Created reviewboard https://reviews.apache.org/r/20787/
 against branch origin/trunk;;;","29/Apr/14 06:03;junrao;Thanks for the reviews. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
normal IOException in the new producer is logged as ERROR,KAFKA-1542,12727781,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,heavydawson,junrao,junrao,17/Jul/14 05:38,29/Jul/14 22:53,22/Mar/23 15:10,28/Jul/14 01:56,0.8.2.0,,,,,,0.8.2.0,,,,,,,,,,,0,newbie,,,,,"Saw the following error in the log. It seems this can happen if the broker is down. So, this probably should be logged as WARN, instead ERROR.

2014/07/16 00:12:51.799 [Selector] Error in I/O: 
java.io.IOException: Connection timed out
        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
        at sun.nio.ch.IOUtil.read(IOUtil.java:197)
        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
        at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:60)
        at org.apache.kafka.common.network.Selector.poll(Selector.java:241)
        at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:171)
        at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:174)
        at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:114)
        at java.lang.Thread.run(Thread.java:744)",,guozhang,heavydawson,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jul/14 15:06;heavydawson;KAFKA-1542.patch;https://issues.apache.org/jira/secure/attachment/12657788/KAFKA-1542.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,405886,,,Tue Jul 29 14:53:49 UTC 2014,,,,,,,,,,"0|i1xuj3:",405906,,,,,,,,,,,,,,,,,,,,"17/Jul/14 06:24;junrao;Also, it would be useful to log the remote ip that caused the IOException.;;;","25/Jul/14 15:06;heavydawson;Attaching patch;;;","25/Jul/14 23:26;guozhang;Thanks for the patch. LGTM.;;;","26/Jul/14 01:00;junrao;Thanks for the patch. Perhaps we can just log the inetaddress. Getting the hostname on the client may not always be possible.;;;","26/Jul/14 01:01;heavydawson;Hey Jun, the current patch returns the IP address. getHostAddress() returns the address as a string, whereas getHostName() would be used if we wanted the hostname;;;","28/Jul/14 01:56;junrao;Thanks for the patch. Committed to trunk.;;;","29/Jul/14 01:59;junrao;This change introduced a bug. Saw the following when running ProducerFailureHandlingTest. The problem is that the remote InetAdress may not always be available (e.g., in connecting mode). Committed a followup patch.

    java.lang.NullPointerException
    	at org.apache.kafka.common.network.Selector.poll(Selector.java:265)
    	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:178)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:175)
    	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:115)
    	at java.lang.Thread.run(Thread.java:695);;;","29/Jul/14 16:19;heavydawson;Hey Jun, the patch looks fine except it's missing the call to {{getHostAddress()}} in the logger. That's need to convert the address object to a string representation for output.;;;","29/Jul/14 22:08;junrao;I think InetAddress.toString gives what we want.;;;","29/Jul/14 22:13;heavydawson;Strictly speaking, toString can return either the hostname and the ipaddress [http://docs.oracle.com/javase/1.5.0/docs/api/java/net/InetAddress.html#toString()], whereas getHostAddress will always be just the IP address. That said, I defer to you guys on this. It was you who request the host info, so happy to run with your suggestion.

;;;","29/Jul/14 22:53;junrao;Yes, I realized that the InetAddress can be null. So, instead of doing another null check, it's simpler to just print out itself.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Error updating metrics in RequestChannel,KAFKA-2115,12820427,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,gwenshap,gwenshap,gwenshap,13/Apr/15 05:42,13/Apr/15 22:22,22/Mar/23 15:10,13/Apr/15 22:22,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Reported by [~jkreps] on the mailing list:

{code}
    kafka.common.KafkaException: Wrong request type 12
    
    at kafka.api.RequestKeys$.nameForKey(RequestKeys.scala:55)
    
    at
    kafka.network.RequestChannel$Request.updateRequestMetrics(RequestChannel.scala:85)
    
    at kafka.network.Processor.write(SocketServer.scala:514)
    
    at kafka.network.Processor.run(SocketServer.scala:379)
    
    at java.lang.Thread.run(Thread.java:744)
    
    [2015-04-12 12:54:52,077] INFO [Kafka Coordinator 0]: Registered consumer
my-group-24 for group my-group (kafka.coordinator.ConsumerCoordinator)
    
    [2015-04-12 12:54:52,080] INFO [Kafka Coordinator 0]: Handled join-group
    from consumer  to group my-group (kafka.coordinator.ConsumerCoordinator)

    [2015-04-12 12:54:52,081] ERROR Closing socket for /10.0.0.220 because of
    error (kafka.network.Processor)
    
    kafka.common.KafkaException: Wrong request type 11
    
    at kafka.api.RequestKeys$.nameForKey(RequestKeys.scala:55)
    
    at
    kafka.network.RequestChannel$Request.updateRequestMetrics(RequestChannel.scala:85)
    
    at kafka.network.Processor.write(SocketServer.scala:514)
    
    at kafka.network.Processor.run(SocketServer.scala:379)
    
     at java.lang.Thread.run(Thread.java:744)
{code}

This a result of KAFKA-2044 - we moved few Requests out
of RequestKeys to the newer ApiKeys, but didn't update the metrics
code.",,gwenshap,junrao,onurkaraman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Apr/15 11:39;gwenshap;KAFKA-2115.patch;https://issues.apache.org/jira/secure/attachment/12724860/KAFKA-2115.patch","13/Apr/15 12:28;gwenshap;KAFKA-2115_2015-04-12_21:28:12.patch;https://issues.apache.org/jira/secure/attachment/12724867/KAFKA-2115_2015-04-12_21%3A28%3A12.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Apr 13 14:22:37 UTC 2015,,,,,,,,,,"0|i2d5un:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"13/Apr/15 11:39;gwenshap;Created reviewboard https://reviews.apache.org/r/33118/diff/
 against branch trunk;;;","13/Apr/15 11:42;gwenshap;I created a small test that uses the new consumer API, so I can reproduce the error and validate my patch.

One thing I noticed while running my test is that while my consumer is running, it looks like a new consumer is joining the consumer group every 10 seconds:

{code}
[2015-04-12 20:34:44,743] INFO [Kafka Coordinator 0]: Registered consumer test-23 for group test (kafka.coordinator.ConsumerCoordinator)
[2015-04-12 20:34:44,746] INFO [Kafka Coordinator 0]: Handled join-group from consumer to group test (kafka.coordinator.ConsumerCoordinator)
[2015-04-12 20:34:54,649] INFO [Kafka Coordinator 0]: Handled heartbeat of consumer from group test (kafka.coordinator.ConsumerCoordinator)
[2015-04-12 20:34:54,652] INFO [Kafka Coordinator 0]: Registered consumer test-24 for group test (kafka.coordinator.ConsumerCoordinator)
[2015-04-12 20:34:54,655] INFO [Kafka Coordinator 0]: Handled join-group from consumer to group test (kafka.coordinator.ConsumerCoordinator)
[2015-04-12 20:35:04,719] INFO [Kafka Coordinator 0]: Handled heartbeat of consumer from group test (kafka.coordinator.ConsumerCoordinator)
[2015-04-12 20:35:04,722] INFO [Kafka Coordinator 0]: Registered consumer test-25 for group test (kafka.coordinator.ConsumerCoordinator)
[2015-04-12 20:35:04,725] INFO [Kafka Coordinator 0]: Handled join-group from consumer to group test (kafka.coordinator.ConsumerCoordinator)
{code}

I don't know whether this is expected behavior, bug in Kafka or bug in my consumer code... perhaps someone more familiar with the new consumer can jump in?

Here's my test:

{code}
public class NewConsumerDemo {

    public static void main(String[] args) throws Exception {
        Properties props = new Properties();
        props.put(""bootstrap.servers"", ""localhost:9092"");
        props.put(""group.id"", ""test"");
        props.put(""enable.auto.commit"", ""true"");
        props.put(""auto.commit.interval.ms"", ""1000"");
        props.put(""session.timeout.ms"", ""30000"");
        props.put(""key.deserializer"", ""org.apache.kafka.common.serialization.StringDeserializer"");
        props.put(""value.deserializer"", ""org.apache.kafka.common.serialization.StringDeserializer"");
        KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);
        consumer.subscribe(""t1"", ""topic2"");
        while (true) {
                ConsumerRecords<String, String> records = consumer.poll(100);
                for (ConsumerRecord<String, String> record : records)
                    System.out.printf(""offset = %d, key = %s, value = %s"", record.offset(), record.key(), record.value());
            }
    }
}
{code};;;","13/Apr/15 12:28;gwenshap;Updated reviewboard https://reviews.apache.org/r/33118/diff/
 against branch trunk;;;","13/Apr/15 17:10;onurkaraman;Trunk's coordinator is pretty much unimplemented. Without going into too many details, you're seeing this behavior because the coordinator never sends back the consumer id it generated for the consumer during the join group. So the consumer will just keep using the UNKNOWN_CONSUMER_ID (empty string). This will fail the heartbeat, making the consumer try to rejoin, again with UNKNOWN_CONSUMER_ID, causing the whole process to repeat. You can see in your logs the incrementing ids the coordinator made for the consumer, but the heartbeat logs show an empty consumer id. The 10 second gaps happens because heartbeats are sent at an interval of session.timeout.ms / 3.

My coordinator patch should address this: https://reviews.apache.org/r/33088;;;","13/Apr/15 22:22;junrao;Thanks for the latest patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafk broker can not stop itself normaly after problems with connection to ZK,KAFKA-1408,12709514,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,nehanarkhede,dmitrybugaychenko,dmitrybugaychenko,21/Apr/14 14:39,16/Nov/17 23:07,22/Mar/23 15:10,16/Nov/17 23:07,0.8.1,,,,,,,,,,,,,controller,,,,0,,,,,,"After getting to inconsistence state due to short netwrok failure broker can not stop itself. The last message in the log is:

{code}
INFO   | jvm 1    | 2014/04/21 08:53:07 | [2014-04-21 09:53:06,999] INFO [kafka-log-cleaner-thread-0], Stopped  (kafka.log.LogCleaner)
INFO   | jvm 1    | 2014/04/21 08:53:07 | [2014-04-21 09:53:06,999] INFO [kafka-log-cleaner-thread-0], Shutdown completed (kafka.log.LogCleaner)
{code}

There is also a preceding error:

{code}
INFO   | jvm 1    | 2014/04/21 08:52:55 | [2014-04-21 09:52:55,015] WARN Controller doesn't exist (kafka.utils.Utils$)
INFO   | jvm 1    | 2014/04/21 08:52:55 | kafka.common.KafkaException: Controller doesn't exist
INFO   | jvm 1    | 2014/04/21 08:52:55 |       at kafka.utils.ZkUtils$.getController(ZkUtils.scala:70)
INFO   | jvm 1    | 2014/04/21 08:52:55 |       at kafka.server.KafkaServer.kafka$server$KafkaServer$$controlledShutdown(KafkaServer.scala:148)
INFO   | jvm 1    | 2014/04/21 08:52:55 |       at kafka.server.KafkaServer$$anonfun$shutdown$1.apply$mcV$sp(KafkaServer.scala:220)
{code}

Here is a part of jstack (it looks like there is a deadlock between delete-topics-thread  and ZkClient-EventThread):
{code}
IWrapper-Connection id=10 state=WAITING
    - waiting on <0x15d6aa44> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
    - locked <0x15d6aa44> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
     owned by ZkClient-EventThread-37-devlnx2:2181 id=37
    at sun.misc.Unsafe.park(Native Method)
    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:867)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1197)
    at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:214)
    at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:290)
    at kafka.utils.Utils$.inLock(Utils.scala:536)
    at kafka.controller.KafkaController.shutdown(KafkaController.scala:641)
    at kafka.server.KafkaServer$$anonfun$shutdown$8.apply$mcV$sp(KafkaServer.scala:233)
    at kafka.utils.Utils$.swallow(Utils.scala:167)
    at kafka.utils.Logging$class.swallowWarn(Logging.scala:92)
    at kafka.utils.Utils$.swallowWarn(Utils.scala:46)
    at kafka.utils.Logging$class.swallow(Logging.scala:94)
    at kafka.utils.Utils$.swallow(Utils.scala:46)
    at kafka.server.KafkaServer.shutdown(KafkaServer.scala:233)
    at odkl.databus.server.Main.stop(Main.java:184)
    at org.tanukisoftware.wrapper.WrapperManager.stopInner(WrapperManager.java:1982)
    at org.tanukisoftware.wrapper.WrapperManager.handleSocket(WrapperManager.java:2391)
    at org.tanukisoftware.wrapper.WrapperManager.run(WrapperManager.java:2696)
    at java.lang.Thread.run(Thread.java:744)


ZkClient-EventThread-37-devlnx2:2181 id=37 state=WAITING
    - waiting on <0x3d5f9878> (a java.util.concurrent.CountDownLatch$Sync)
    - locked <0x3d5f9878> (a java.util.concurrent.CountDownLatch$Sync)
    at sun.misc.Unsafe.park(Native Method)
    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:994)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1303)
    at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:236)
    at kafka.utils.ShutdownableThread.shutdown(ShutdownableThread.scala:36)
    at kafka.controller.TopicDeletionManager.shutdown(TopicDeletionManager.scala:93)
    at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply$mcV$sp(KafkaController.scala:340)
    at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply(KafkaController.scala:337)
    at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply(KafkaController.scala:337)
    at kafka.utils.Utils$.inLock(Utils.scala:538)
    at kafka.controller.KafkaController.onControllerResignation(KafkaController.scala:337)
    at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1068)
    at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1067)
    at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1067)
    at kafka.utils.Utils$.inLock(Utils.scala:538)
    at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1067)
    at org.I0Itec.zkclient.ZkClient$4.run(ZkClient.java:472)
    at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)

    Locked synchronizers: count = 1
      - java.util.concurrent.locks.ReentrantLock$NonfairSync@15d6aa44

Controller-3-to-broker-3-send-thread id=2414 state=WAITING
    - waiting on <0x4044618f> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    - locked <0x4044618f> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at sun.misc.Unsafe.park(Native Method)
    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
    at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:121)
    at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)

delete-topics-thread id=2416 state=WAITING
    - waiting on <0x15d6aa44> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
    - locked <0x15d6aa44> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
     owned by ZkClient-EventThread-37-devlnx2:2181 id=37
    at sun.misc.Unsafe.park(Native Method)
    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:867)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1197)
    at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:214)
    at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:290)
    at kafka.utils.Utils$.inLock(Utils.scala:536)
    at kafka.controller.TopicDeletionManager$DeleteTopicsThread.doWork(TopicDeletionManager.scala:333)
    at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)
{code}",,dmitrybugaychenko,ijuma,jkreps,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,387836,,,Thu Nov 16 15:07:55 UTC 2017,,,,,,,,,,"0|i1ut73:",388097,,,,,,,,,,,,,,,,,,,,"21/Apr/14 22:57;junrao;The deadlock issue is fixed in the latest 0.8.1 branch as long as the delete topic feature is disabled (the default). Could you give it a try?;;;","22/Apr/14 18:06;dmitrybugaychenko;We are using artefact from maven: http://search.maven.org/#artifactdetails|org.apache.kafka|kafka_2.10|0.8.1|jar and would like to awoid building entire kafka from sources...;;;","22/Apr/14 22:57;junrao;We are in the process of preparing the 0.8.1.1 release.;;;","22/Apr/14 23:06;dmitrybugaychenko;Found this patch in the reviosion history: https://git-wip-us.apache.org/repos/asf?p=kafka.git;a=commit;h=fb92b3a2cdf571715b948f81f1f8bb4bc363d497

I'll try to apply it tomorrow. It looks like KAFKA-1407 and KAFKA-1408 are actually about the same thing (deadlock in topics deletion thread) and thus are both duplicates of KAFKA-1317.
;;;","08/Feb/15 06:41;jkreps;[~junrao], [~dmitrybugaychenko] is this still active?;;;","10/Feb/15 15:53;dmitrybugaychenko;When topic deletion is disabled the problem is not reproducable. Have not tried to enable deletion yet. And yes, I think its a duplicate of KAFKA-1317;;;","16/Nov/17 23:07;ijuma;Closing as duplicate of KAFKA-1317 based on other comments and the fact that there has been no activity on this issue for years.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cryptic serde error messages in new producer,KAFKA-1241,12693189,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,jkreps,nehanarkhede,nehanarkhede,05/Feb/14 03:11,21/Mar/14 05:56,22/Mar/23 15:10,21/Mar/14 05:56,0.10.1.0,,,,,,,,,,,,,producer ,,,,0,,,,,,"One of the motivations for the new serde format is better error reporting. I was running a test on the new mirror maker when I saw this exception -

java.nio.BufferUnderflowException
	at java.nio.Buffer.nextGetIndex(Buffer.java:480)
	at java.nio.HeapByteBuffer.getInt(HeapByteBuffer.java:336)
	at kafka.common.protocol.types.Type$3.read(Type.java:88)
	at kafka.common.protocol.types.Schema.read(Schema.java:50)
	at kafka.common.protocol.types.ArrayOf.read(ArrayOf.java:30)
	at kafka.common.protocol.types.Schema.read(Schema.java:50)
	at kafka.common.protocol.types.ArrayOf.read(ArrayOf.java:30)
	at kafka.common.protocol.types.Schema.read(Schema.java:50)
	at kafka.clients.producer.internals.Sender.handleResponses(Sender.java:273)
	at kafka.clients.producer.internals.Sender.run(Sender.java:144)
	at kafka.clients.producer.internals.Sender.run(Sender.java:84)
	at java.lang.Thread.run(Thread.java:619)


I was expecting to see a precise error message about the Request type that serde failed for. Instead it says Type$3 and no information on which field.",,jkreps,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Feb/14 12:23;jkreps;KAFKA-1241.patch;https://issues.apache.org/jira/secure/attachment/12627551/KAFKA-1241.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,371775,,,Thu Mar 20 21:56:30 UTC 2014,,,,,,,,,,"0|i1s2lb:",372074,,,,,,,,,,,,,,,,,,,,"07/Feb/14 12:23;jkreps;Created reviewboard https://reviews.apache.org/r/17836/
 against branch trunk;;;","07/Feb/14 12:29;jkreps;I improved the error for that case. I think the rationale was that we CAN have good error messages because all parsing logic is in a single place not that we DO have good errors. Once we fix all the issues like this then we will have good errors :-)

We can't give the request name as the serialization doesn't know about requests but we can give the field being read and how much it was off by which I think is an improvement.

All that said this sounds like there is a bug, no? I mean the fact that we get an error is itself an issue irrespective of how good the error message is, right?;;;","07/Feb/14 13:29;nehanarkhede;Yes, it is a bug I hit during a test with large set of topics on the mirror maker. However, due to absence of logging and the incomplete error message, it is difficult to say what happened. Here is the rest of the stack trace -

java.lang.IllegalStateException: Attempt to begin a send operation with prior send operation still in progress.
	at kafka.common.network.Selector.poll(Selector.java:171)
	at kafka.clients.producer.internals.Sender.run(Sender.java:137)
	at kafka.clients.producer.internals.Sender.run(Sender.java:84)
	at java.lang.Thread.run(Thread.java:619)
java.lang.IllegalStateException: Correlation id for response (7401215) does not match request (7401214)
	at kafka.clients.producer.internals.Sender.correlate(Sender.java:313)
	at kafka.clients.producer.internals.Sender.handleResponses(Sender.java:274)
	at kafka.clients.producer.internals.Sender.run(Sender.java:144)
	at kafka.clients.producer.internals.Sender.run(Sender.java:84)
	at java.lang.Thread.run(Thread.java:619)
java.nio.BufferUnderflowException
	at java.nio.Buffer.nextGetIndex(Buffer.java:480)
	at java.nio.HeapByteBuffer.getInt(HeapByteBuffer.java:336)
	at kafka.common.protocol.types.Type$3.read(Type.java:88)
	at kafka.common.protocol.types.Schema.read(Schema.java:50)
	at kafka.common.protocol.types.ArrayOf.read(ArrayOf.java:30)
	at kafka.common.protocol.types.Schema.read(Schema.java:50)
	at kafka.common.protocol.types.ArrayOf.read(ArrayOf.java:30)
	at kafka.common.protocol.types.Schema.read(Schema.java:50)
	at kafka.clients.producer.internals.Sender.handleResponses(Sender.java:273)
	at kafka.clients.producer.internals.Sender.run(Sender.java:144)
	at kafka.clients.producer.internals.Sender.run(Sender.java:84)
	at java.lang.Thread.run(Thread.java:619)


;;;","10/Feb/14 07:57;jkreps;Hey [~nehanarkhede] I think that is a real bug that someone pointed out in the code review, namely that when the metadata refresh happens if it goes to a broker that also gets a produce request in the same iteration it is possible to have two unsent requests at the same time (which we don't allow). The fix is fairly straight-forward but let me break it into a seperate issue from the error message bug.

In any case I think the patch I posted fixes the logging in the serialization. I'll fix up the sender logging when we do the slf4j. So can I get a +1 on this?;;;","10/Feb/14 13:48;nehanarkhede;Got it. Do you want to fix the issue of better error messages for request types in the Sender in another JIRA then? If so, I'm a +1 on this patch. ;;;","21/Mar/14 05:56;jkreps;I believe this is fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clean shutdown after startup connection failure,KAFKA-589,12613686,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,ewencp,jbrosenberg,jbrosenberg,27/Oct/12 01:24,26/Sep/14 12:24,22/Mar/23 15:10,26/Sep/14 12:23,0.7.2,0.8.0,,,,,,,,,,,,core,,,,0,bugs,newbie,,,,"Hi,

I'm embedding the kafka server (0.7.2) in an application container.   I've noticed that if I try to start the server without zookeeper being available, by default it gets a zk connection timeout after 6 seconds, and then throws an Exception out of KafkaServer.startup()....E.g., I see this stack trace:

Exception in thread ""main"" org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 6000
	at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:876)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:98)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:84)
	at kafka.server.KafkaZooKeeper.startup(KafkaZooKeeper.scala:44)
	at kafka.log.LogManager.<init>(LogManager.scala:93)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:58)
        ....
        ....

So that's ok, I can catch the exception, and then shut everything down gracefully, in this case.  However, when I do this, it seems there is a daemon thread still around, which doesn't quit, and so the server never actually exits the jvm.  Specifically, this thread seems to hang around:

""kafka-logcleaner-0"" prio=5 tid=7fd9b48b1000 nid=0x112c08000 waiting on condition [112c07000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <7f40d4be8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2025)
	at java.util.concurrent.DelayQueue.take(DelayQueue.java:164)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:609)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:602)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:947)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
	at java.lang.Thread.run(Thread.java:680)

Looking at the code in kafka.log.LogManager(), it does seem like it starts up the scheduler to clean logs, before then trying to connect to zk (and in this case fail):

  /* Schedule the cleanup task to delete old logs */
  if(scheduler != null) {
    info(""starting log cleaner every "" + logCleanupIntervalMs + "" ms"")    
    scheduler.scheduleWithRate(cleanupLogs, 60 * 1000, logCleanupIntervalMs)
  }

So this scheduler does not appear to be stopped if startup fails.  However, if I catch the above RuntimeException, and then call KafkaServer.shutdown(), then it will stop the scheduler, and all is good.

However, it seems odd that if I get an exception when calling KafkaServer.startup(), that I should still have to do a KafkaServer.shutdown().  Rather, wouldn't it be better to have it internally cleanup after itself if startup() gets an exception?  I'm not sure I can reliably call shutdown() after a failed startup()....",,ewencp,jbrosenberg,jbrosenberg@gmail.com,junrao,nehanarkhede,swapnilghike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Sep/14 07:54;ewencp;KAFKA-589-v1.patch;https://issues.apache.org/jira/secure/attachment/12671345/KAFKA-589-v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,251638,,,Fri Sep 26 04:23:45 UTC 2014,,,,,,,,,,"0|i0c2yn:",68424,,,,,,,,,,,,,,,,,,,,"29/Oct/12 10:47;junrao;This problem exists in 0.8 too. What we need to do is to add a try/catch in KafkaServer.start() and call shutdown if we hit any exceptions.;;;","30/Oct/12 05:21;swapnilghike;Hi Jason, 

Are you using the KafkaServer.startup() or KafkaServerStartable.startup()? The latter calls the former and also shuts the server down in case of an exception.;;;","06/Nov/12 04:32;jbrosenberg;I was using KafkaServerStartable.startup(), but switched to KafkaServer.startup(), because I wanted to have a bit more control of things, e.g. I want to be able know if there was a problem within the container, and retry, etc.  In KafkaServerStartable.startup(), if there's an exception, it swallows the exception, and then calls shutdown(), but the caller has no idea if the startup was successful or not.

But I don't think that's relevant here.  I think it's counter intuitive that the KafkaServer.startup() would fail to startup, and throw an exception, and then not cleanup after itself, and require a call to shutdown in the first place.;;;","26/Sep/14 07:52;ewencp;This patch makes KafkaServer clean up after itself, but still rethrow any caught exceptions. This keeps the existing interface the same, should still work if the caller does cleanup themselves by catching exceptions and calling shutdown, but also cleans up if they don't so the leftover thread won't cause a hang. Also adds a test of this behavior.;;;","26/Sep/14 12:23;nehanarkhede;Thanks for fixing a longstanding bug! +1 on the patch.;;;","26/Sep/14 12:23;nehanarkhede;Pushed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Checkstyle reporting failure in trunk due to unused imports in Selector.java,KAFKA-2549,12864042,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,parth.brahmbhatt,parth.brahmbhatt,parth.brahmbhatt,15/Sep/15 05:41,15/Sep/15 06:56,22/Mar/23 15:10,15/Sep/15 06:03,,,,,,,,,,,,,,,,,,0,,,,,,Introduced in https://github.com/apache/kafka/commit/d02ca36ca1cccdb6962191b97f54ce96b9d75abc#diff-db8f8be6ef2f1c81515d1ed83b3ab107 in which the Selector.java was modified with some unused imports so the trunk can not execute test targets as it fails in client section during checkstyle stage.,,githubbot,gwenshap,ijuma,jholoman,parth.brahmbhatt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Sep 14 22:56:32 UTC 2015,,,,,,,,,,"0|i2k5yf:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"15/Sep/15 05:44;githubbot;GitHub user Parth-Brahmbhatt opened a pull request:

    https://github.com/apache/kafka/pull/215

    KAFKA-2549: Fixing checkstyle failure resulting due to unused imports…

    … in Selector.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/Parth-Brahmbhatt/kafka KAFKA-2549

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/215.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #215
    
----
commit 510b4ec6ef327448d4825acd84d24486054bc9ca
Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>
Date:   2015-09-14T21:44:18Z

    KAFKA-2549: Fixing checkstyle failure resulting due to unused imports in Selector.

----
;;;","15/Sep/15 05:59;ijuma;Looks like we need to either fix the build config or the Jenkins jobs because this was merged weeks ago and it has gone undetected since. I've been running `gradlew test` every day without errors.

An easy workaround is to run clean as part of the Jenkins builds, but a better fix would be to make sure checkstyle works correctly without a clean. It's still a good idea to do clean builds in Jenkins, but it would be nicer for development.
;;;","15/Sep/15 06:01;ijuma;Btw, the word ""again"" in the description is a bit misleading because the compiler failure that you recently reported was due to a different commit.;;;","15/Sep/15 06:02;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/215
;;;","15/Sep/15 06:03;parth.brahmbhatt;[~ijuma] You are right, my bad, edited the description.;;;","15/Sep/15 06:03;gwenshap;Thanks for the quick fix!;;;","15/Sep/15 06:29;ijuma;[~parth.brahmbhatt], the right commit where this problem was introduced is:

https://github.com/apache/kafka/commit/d88b5bdfde0b6d020e687f6d59ad88d577910ae9

Not the one you mentioned. And that commit was merged today, not weeks ago. OK, I feel less bad about checkstyle and incremental builds.;;;","15/Sep/15 06:43;jholoman;Yeah sorry about that, I inadvertently cmd-z'd the import deletion. Thanks for fixing. ;;;","15/Sep/15 06:56;ijuma;No problem Jeff. I just mentioned it because the original description led me to an incorrect conclusion regarding checkstyle. Thank both for the PRs.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in ProducerSendTest.testAutoCreateTopic,KAFKA-1412,12709808,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,23/Apr/14 00:47,02/May/14 07:36,22/Mar/23 15:10,02/May/14 07:36,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Saw the following transient failure. 

kafka.api.test.ProducerSendTest > testAutoCreateTopic FAILED
    java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:56)
        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:43)
        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:25)
        at kafka.api.test.ProducerSendTest.testAutoCreateTopic(ProducerSendTest.scala:254)

        Caused by:
        org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
",,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,86400,86400,,0%,86400,86400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/May/14 00:53;junrao;KAFKA-1412.patch;https://issues.apache.org/jira/secure/attachment/12642868/KAFKA-1412.patch","02/May/14 00:52;junrao;KAFKA-1412.patch;https://issues.apache.org/jira/secure/attachment/12642867/KAFKA-1412.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,388130,,,Thu May 01 23:36:08 UTC 2014,,,,,,,,,,"0|i1uuzb:",388388,,,,,,,,,,,,,,,,,,,,"23/Apr/14 00:49;junrao;The issue seems to be there is no resend in the test. We should configure enough retries (default to 0) and retry backoff time to allow metadata to be propagated to the broker after auto topic creation.;;;","23/Apr/14 01:26;guozhang;I think this is a duplicate of KAFKA-1395. My proposal is to unify createProducer to ensure acks = -1 and type = sync, in which after the send call if no exception is thrown for failed message sending we are assured that the topic is created, hence no need to check waitUntilMetadataIsPropagated either.;;;","02/May/14 00:52;junrao;Created reviewboard  against branch origin/trunk;;;","02/May/14 00:53;junrao;Created reviewboard https://reviews.apache.org/r/20954/
 against branch origin/trunk;;;","02/May/14 07:36;junrao;Thanks for the reviews. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add error code 4 (InvalidFetchSize) to Errors.java,KAFKA-2912,12917069,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,granthenke,granthenke,01/Dec/15 04:57,19/Apr/16 14:47,22/Mar/23 15:10,19/Apr/16 14:47,0.9.0.0,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"org.apache.kafka.common.protocol.Errors.java has:
{quote}
// TODO: errorCode 4 for InvalidFetchSize
{quote}",,granthenke,jinxing6042@126.com,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2929,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Apr 19 06:47:14 UTC 2016,,,,,,,,,,"0|i2p32n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"01/Dec/15 04:59;granthenke;See Errors.java in trunk [here|https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/protocol/Errors.java#L42].;;;","02/Dec/15 22:26;jinxing6042@126.com;I believe the validation for fetch size should be done inside of KafkaApis : handleFetchRequets(request: RequestChannel.Request) ;
The question is how to define a fetch request is invalid?
Maybe we can judge by parameters: buffer size, fetchRequest.maxWait, fetchRequest.minBytes, quotas of throughput, request.timeout.ms...;
Is this point of view right?;;;","19/Apr/16 14:47;omkreddy;Fixed in KAFKA-2929;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client Error doesn't preserve or display original server error code when it is an unknown code,KAFKA-2100,12819041,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,dajac,gwenshap,gwenshap,08/Apr/15 03:50,30/Jul/15 01:40,22/Mar/23 15:10,30/Jul/15 01:40,,,,,,,,,,,,,,clients,,,,0,newbie,,,,,"When the java client receives an unfamiliar error code, it translates it into 

UNKNOWN(-1, new UnknownServerException(""The server experienced an unexpected error when processing the request""))

This completely loses the original code, which makes troubleshooting from the client impossible. 

Will be better to preserve the original code and write it to the log when logging the error.",,dajac,ewencp,guozhang,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jul/15 21:26;dajac;KAFKA-2100-1.patch;https://issues.apache.org/jira/secure/attachment/12747024/KAFKA-2100-1.patch","27/Jul/15 13:39;dajac;KAFKA-2100-2.patch;https://issues.apache.org/jira/secure/attachment/12747283/KAFKA-2100-2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jul 29 17:36:01 UTC 2015,,,,,,,,,,"0|i2cxf3:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"20/Jul/15 13:17;dajac;[~gwenshap] Are you working on this one? I'd like to take it to familiarize myself with the contributing process.;;;","21/Jul/15 10:36;gwenshap;Go ahead, all yours :);;;","24/Jul/15 21:26;dajac;I have looked at how Errors are used in the java client and I see mainly two options for preserving original error code:

1. We could modify Errors to not default to UNKNOWN and returns an error which preserves the original error code.
2. We could log a warning message when a lookup is made with an unknown error code.

Option 1 requires a refactoring of the Errors enum as it is not possible to create an new entry at runtime. One way would be to replace the enum by a class which defines static constants for each error. I think that it is quite clean approach but it is a bit less readable. Also, I'm wondering if not defaulting to UNKNOWN could impact logic of the client, for instance, if a retry is done based on an UNKNOWN error. I have attached a rough patch which show this. All tests pass with it.

Option 2 doesn't require any changes in the code base and will warn the end user.

I'm wondering how often this happens? Error codes are defined in the protocol so mapping between the client and the server (assuming they use the same version) should be one to one.

I would be happy to have any feedback/advice on how to move forward with this. [~gwenshap] Is it what you had in mind?

While reading the code of the client, I have noticed that few different ways are used to handle error codes. Mainly, the are keep as numerical values, and sometimes, they are converted to Errors. Would it be better to stay consistent and stick to one way or the other?;;;","25/Jul/15 00:01;gwenshap;Regarding how often it happens: I believe its mostly an upgrade concern (i.e. we added new error codes to the server, but didn't upgrade the client so it can't translate them properly). However, its just very frustrating to troubleshoot because you see the UNKNOWN and simply have no clue as to what went wrong.

I like option #2 since its short, simple and solves what I see as the main issue with UNKNOWN (that you have no clues at all). 

I agree that option #1 could impact client logic (although UNKNOWN is not retriable). I didn't dig deep into the code yet, but do you think it makes sense to keep the UNKNOWN code in the Error class, and just add the code to the message in the Exception? Will this get to the error log eventually?

Since option #1 can have other implications on client-side, it will be awesome if others take a look too: [~guozhang], [~jkreps], [~ewencp], [~junrao]?

Regarding the inconsistent ways errors are handled, can you point out few examples?;;;","25/Jul/15 03:05;dajac;I think that UNKNOWN must be kept in the Errors because UNKNOWN (-1) is part of the protocol and used in the code for checking its error code. Yes, exception will get to the log or get to the user.

Thinking a bit more about it, would it be better to ensure that same errors are used in both the server and the client by sharing them? It might be already the objective of the common package, isn't it? Then, a warning in the log when a lookup is done might be enough to warn the user that he should check or update his client.

Regarding the inconsistent ways, it is not a big deal but I have seen above ways. The first one is used almost everywhere except in the Sender class.

{code:title=Coordinator.java|borderStyle=solid}
short error = heartbeatResponse.errorCode();
if (error == Errors.NONE.code()) {
...
} else {
  future.raise(new KafkaException(""Unexpected error in heartbeat response: ""
                        + Errors.forCode(error).exception().getMessage()));
}
{code}

{code:title=Sender.java|borderStyle=solid}
Errors error = Errors.forCode(partResp.errorCode);
...
if (error != Errors.NONE && canRetry(batch, error))
{code}

;;;","25/Jul/15 03:22;gwenshap;We have KAFKA-1929 for re-using the Errors package in the server side.;;;","25/Jul/15 05:47;guozhang;I like option #2 as well, I think it is sufficient to bring user's attention with the preserved original error code.

Regarding the inconsistency usage, it is mainly because they are written by two people (namely me and Jay :P) who did not really sync-up on the usage style. I do not have a strong preference either way, but Sender's way may be less characters?;;;","27/Jul/15 10:33;ewencp;Option #2 looks good to me as well.

As for when this can happen, the upgrade situation Gwen described is the one case I'm aware of as well. Error code changes and changes in semantics of various protocol fields are the two ways I can think of where I don't think we can provide complete compatibility without introducing extra protocol versions that are only semantically (and not structurally) different. There was a discussion about this awhile ago (though I can't recall the context now) and I think the conclusion was that adding an error code despite it technically being incompatible is ok (especially if its a non-retriable error that ultimately has the same effect as UNKNOWN). Since that's the case, it's definitely valuable to have this information logged.;;;","27/Jul/15 13:42;dajac;Thank you for your feedback. I just uploaded a patch which implements option #2.

Regarding the inconsistency usage, I don't have a preference neither. Should we align them? Any way, I think that it must be handled in a separate JIRA.;;;","27/Jul/15 15:38;ewencp;LGTM.

wrt inconsistency: the example shown, canRetry, checks RetriableException. This info isn't available directly via the error code. It's true we could make the error checking consistent and convert to Error as needed to check the exception type, but this doesn't strike me as particularly egregious. I wouldn't worry about it.;;;","29/Jul/15 01:29;dajac;[~gwenshap] Could you review this one when you have time? Thanks!;;;","30/Jul/15 01:36;gwenshap;+1 and pushed to trunk.

Thank you for your contribution [~dajac], hope to see more :);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in testDeleteTopicDuringAddPartition,KAFKA-1439,12713091,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,sriharsha,junrao,junrao,08/May/14 22:16,05/Sep/14 06:22,22/Mar/23 15:10,05/Sep/14 06:21,,,,,,,0.8.2.0,,,,,,,,,,,0,newbie++,,,,,"Saw the following transient unit test failure.

kafka.admin.DeleteTopicTest > testDeleteTopicDuringAddPartition FAILED
    junit.framework.AssertionFailedError: Admin path /admin/delete_topic/test path not deleted even after a replica is restarted
        at junit.framework.Assert.fail(Assert.java:47)
        at kafka.utils.TestUtils$.waitUntilTrue(TestUtils.scala:578)
        at kafka.admin.DeleteTopicTest.verifyTopicDeletion(DeleteTopicTest.scala:333)
        at kafka.admin.DeleteTopicTest.testDeleteTopicDuringAddPartition(DeleteTopicTest.scala:216)
",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1482,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,391407,,,2014-05-08 14:16:35.0,,,,,,,,,,"0|i1vetz:",391622,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in PartitionAssignorTest,KAFKA-1759,12753836,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,junrao,junrao,08/Nov/14 06:31,27/Mar/15 01:23,22/Mar/23 15:10,27/Mar/15 01:23,0.9.0.0,,,,,,0.9.0.0,,,,,,,core,,,,0,,,,,,"Saw the following transient failure.

unit.kafka.consumer.PartitionAssignorTest > testRoundRobinPartitionAssignor FAILED
    java.lang.UnsupportedOperationException: empty.max
        at scala.collection.TraversableOnce$class.max(TraversableOnce.scala:216)
        at scala.collection.AbstractIterator.max(Iterator.scala:1157)
        at unit.kafka.consumer.PartitionAssignorTest$.unit$kafka$consumer$PartitionAssignorTest$$assignAndVerify(PartitionAssignorTest.scala:190)
        at unit.kafka.consumer.PartitionAssignorTest$$anonfun$testRoundRobinPartitionAssignor$1.apply$mcVI$sp(PartitionAssignorTest.scala:54)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at unit.kafka.consumer.PartitionAssignorTest.testRoundRobinPartitionAssignor(PartitionAssignorTest.scala:39)",,airbots,junrao,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Mar 18 12:37:22 UTC 2015,,,,,,,,,,"0|i224p3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"18/Mar/15 20:37;rsivaram;This has been fixed under [KAFKA-1823];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Transient test failure in OffsetCheckpointTest.testReadWrite,KAFKA-3195,12936183,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,ewencp,ewencp,03/Feb/16 07:47,22/Feb/17 09:06,22/Mar/23 15:10,03/Feb/16 10:29,0.10.0.0,,,,,,0.10.0.0,,,,,,,streams,,,,0,,,,,,"It looks like its probably an issue with parallel tests trying to access the same fixed path, where one test deletes the file. Saw this on 86a9036a7b03c8ae07d014c25a5eedc315544139.

{quote}
org.apache.kafka.streams.state.internals.OffsetCheckpointTest > testReadWrite FAILED
    java.io.FileNotFoundException: /tmp/kafka-streams/offset_checkpoint.test.tmp (No such file or directory)
        at java.io.FileOutputStream.open(Native Method)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:171)
        at org.apache.kafka.streams.state.internals.OffsetCheckpoint.write(OffsetCheckpoint.java:68)
        at org.apache.kafka.streams.state.internals.OffsetCheckpointTest.testReadWrite(OffsetCheckpointTest.java:48)
{quote}",,ewencp,githubbot,guozhang,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Feb 03 02:29:56 UTC 2016,,,,,,,,,,"0|i2sbwn:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"03/Feb/16 08:00;ijuma;There is:

File f = new File(""/tmp/kafka-streams/offset_checkpoint.test"");

The test should probably use `TestUtils.tempFile`.;;;","03/Feb/16 08:16;guozhang;Thanks [~ewencp]. [~ijuma] Do you want to provide a PR? Then I can help merging it otherwise I need to ping Ewen again :);;;","03/Feb/16 08:24;ijuma;Sure.;;;","03/Feb/16 09:29;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/855

    KAFKA-3195; Transient test failure in OffsetCheckpointTest.testReadWrite

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-3195-offset-checkpoint-test-transient-failure

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/855.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #855
    
----
commit 4db54d599de7461aa15d717714747bc03d9857bc
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-02-03T01:28:43Z

    Use temp file in `OffsetCheckpointTest`

----
;;;","03/Feb/16 10:29;ewencp;Issue resolved by pull request 855
[https://github.com/apache/kafka/pull/855];;;","03/Feb/16 10:29;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/855
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
unit test failure in org.apache.kafka.streams.processor.internals.KafkaStreamingPartitionAssignorTest,KAFKA-2815,12912383,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,junrao,junrao,12/Nov/15 10:55,13/Nov/15 01:53,22/Mar/23 15:10,13/Nov/15 01:53,0.10.0.0,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"See the following failure on trunk.

org.apache.kafka.streams.processor.internals.KafkaStreamingPartitionAssignorTest > testSubscription FAILED
    java.lang.AssertionError: expected:<[topic1, topic2]> but was:<[topic2, topic1]>
        at org.junit.Assert.fail(Assert.java:88)
        at org.junit.Assert.failNotEquals(Assert.java:743)
        at org.junit.Assert.assertEquals(Assert.java:118)
        at org.junit.Assert.assertEquals(Assert.java:144)
        at org.apache.kafka.streams.processor.internals.KafkaStreamingPartitionAssignorTest.testSubscription(KafkaStreamingPartitionAssignorTest.java:174)
",,githubbot,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 12 17:53:59 UTC 2015,,,,,,,,,,"0|i2oa93:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"13/Nov/15 01:44;githubbot;Github user granthenke closed the pull request at:

    https://github.com/apache/kafka/pull/510
;;;","13/Nov/15 01:44;githubbot;GitHub user granthenke reopened a pull request:

    https://github.com/apache/kafka/pull/510

    KAFKA-2815: Fix KafkaStreamingPartitionAssignorTest.testSubscription

    Fails when order of elements is incorrect

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka streams-test

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/510.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #510
    
----
commit f6f76ffd622d80e12f753e7175fdf4c08ca2069d
Author: Grant Henke <granthenke@gmail.com>
Date:   2015-11-12T16:27:44Z

    MINOR: Fix KafkaStreamingPartitionAssignorTest.testSubscription
    
    Fails when order of elements is incorrect

----
;;;","13/Nov/15 01:53;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/510
;;;","13/Nov/15 01:53;guozhang;Issue resolved by pull request 510
[https://github.com/apache/kafka/pull/510];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Errors enum should be a 1 to 1 mapping of error codes and exceptions,KAFKA-2999,12922465,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,granthenke,granthenke,17/Dec/15 03:15,19/Jan/16 02:09,22/Mar/23 15:10,19/Jan/16 02:09,0.9.0.0,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"Errors has functionality to map from code to exception and from exception to code. This requires the mapping to be 1 to 1 or else unexpected behavior may occur.

In the current code (below), a generic ApiException will result in an INVALID_COMMIT_OFFSET_SIZE error, because that is the last occurrence in the Enum.

{code:title=Error.java|borderStyle=solid}
...
for (Errors error : Errors.values()) {
   codeToError.put(error.code(), error);
   if (error.exception != null)
      classToError.put(error.exception.getClass(), error);
}
...
{code}


This should be fixed and some tests should be written to validate it's not broken. ",,githubbot,granthenke,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jan 18 18:09:36 UTC 2016,,,,,,,,,,"0|i2pztb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"14/Jan/16 02:18;githubbot;GitHub user granthenke opened a pull request:

    https://github.com/apache/kafka/pull/766

    KAFKA-2999: Errors enum should be a 1 to 1 mapping of error codes and…

    … exceptions

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka errors-map

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/766.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #766
    
----
commit 86ce814a533b90147f862a2114e40d360181cd7c
Author: Grant Henke <granthenke@gmail.com>
Date:   2016-01-13T18:04:39Z

    KAFKA-2999: Errors enum should be a 1 to 1 mapping of error codes and exceptions

----
;;;","19/Jan/16 02:09;gwenshap;Issue resolved by pull request 766
[https://github.com/apache/kafka/pull/766];;;","19/Jan/16 02:09;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/766
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
can't use public release maven repo because of failure of downloaded dependency,KAFKA-974,12657567,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,charmalloc,charmalloc,13/Jul/13 13:56,28/Nov/13 17:38,22/Mar/23 15:10,20/Aug/13 22:02,,,,,,,0.8.0,,,,,,,,,,,2,,,,,,"trying to use the 0.8.0-beta1 release from public maven


name := ""Stub""

version := ""1.0.0.0""

scalaVersion := ""2.9.2""

mainClass := Some(""Stub"")

libraryDependencies ++= Seq(
	""org.apache.kafka"" % ""kafka_2.9.2"" % ""0.8.0-beta1""
)

results in

Joes-MacBook-Air:stub joestein$ ./sbt compile
[info] Set current project to default-63d5f2 (in build file:/opt/medialets/SymanticManager/scala/stub/)
[info] Updating {file:/opt/medialets/SymanticManager/scala/stub/}default-63d5f2...
[warn] 	[NOT FOUND  ] javax.jms#jms;1.1!jms.jar (50ms)
[warn] ==== public: tried
[warn]   http://repo1.maven.org/maven2/javax/jms/jms/1.1/jms-1.1.jar
[warn] 	[NOT FOUND  ] com.sun.jdmk#jmxtools;1.2.1!jmxtools.jar (12ms)
[warn] ==== public: tried
[warn]   http://repo1.maven.org/maven2/com/sun/jdmk/jmxtools/1.2.1/jmxtools-1.2.1.jar
[warn] 	[NOT FOUND  ] com.sun.jmx#jmxri;1.2.1!jmxri.jar (71ms)
[warn] ==== public: tried
[warn]   http://repo1.maven.org/maven2/com/sun/jmx/jmxri/1.2.1/jmxri-1.2.1.jar
[warn] 	::::::::::::::::::::::::::::::::::::::::::::::
[warn] 	::              FAILED DOWNLOADS            ::
[warn] 	:: ^ see resolution messages for details  ^ ::
[warn] 	::::::::::::::::::::::::::::::::::::::::::::::
[warn] 	:: javax.jms#jms;1.1!jms.jar
[warn] 	:: com.sun.jdmk#jmxtools;1.2.1!jmxtools.jar
[warn] 	:: com.sun.jmx#jmxri;1.2.1!jmxri.jar
[warn] 	::::::::::::::::::::::::::::::::::::::::::::::
[info] 
[warn] :: problems summary ::
[warn] :::: WARNINGS
[warn] 		[NOT FOUND  ] javax.jms#jms;1.1!jms.jar (50ms)
[warn] 	==== public: tried
[warn] 	  http://repo1.maven.org/maven2/javax/jms/jms/1.1/jms-1.1.jar
[warn] 		[NOT FOUND  ] com.sun.jdmk#jmxtools;1.2.1!jmxtools.jar (12ms)
[warn] 	==== public: tried
[warn] 	  http://repo1.maven.org/maven2/com/sun/jdmk/jmxtools/1.2.1/jmxtools-1.2.1.jar
[warn] 		[NOT FOUND  ] com.sun.jmx#jmxri;1.2.1!jmxri.jar (71ms)
[warn] 	==== public: tried
[warn] 	  http://repo1.maven.org/maven2/com/sun/jmx/jmxri/1.2.1/jmxri-1.2.1.jar
[warn] 		::::::::::::::::::::::::::::::::::::::::::::::
[warn] 		::              FAILED DOWNLOADS            ::
[warn] 		:: ^ see resolution messages for details  ^ ::
[warn] 		::::::::::::::::::::::::::::::::::::::::::::::
[warn] 		:: javax.jms#jms;1.1!jms.jar
[warn] 		:: com.sun.jdmk#jmxtools;1.2.1!jmxtools.jar
[warn] 		:: com.sun.jmx#jmxri;1.2.1!jmxri.jar
[warn] 		::::::::::::::::::::::::::::::::::::::::::::::
[info] 
[info] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS
[error] {file:/opt/medialets/SymanticManager/scala/stub/}default-63d5f2/*:update: sbt.ResolveException: download failed: javax.jms#jms;1.1!jms.jar
[error] download failed: com.sun.jdmk#jmxtools;1.2.1!jmxtools.jar
[error] download failed: com.sun.jmx#jmxri;1.2.1!jmxri.jar
[error] Total time: 3 s, completed Jul 13, 2013 1:55:36 AM
",,charmalloc,craigwblake,criccomini,jkreps,miguno,otis,scruffy323,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/13 14:14;charmalloc;KAFKA-974.patch;https://issues.apache.org/jira/secure/attachment/12592127/KAFKA-974.patch","15/Jul/13 09:19;charmalloc;KAFKA-974.v2.patch;https://issues.apache.org/jira/secure/attachment/12592225/KAFKA-974.v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,337788,,,Thu Nov 28 09:38:14 UTC 2013,,,,,,,,,,"0|i1m9hj:",338110,,,,,,,,,,,,,,,,,,,,"13/Jul/13 14:38;charmalloc;first patch that didn't work;;;","13/Jul/13 17:01;charmalloc;tried this, same error

diff --git a/project/Build.scala b/project/Build.scala
index bad93db..c758178 100644
--- a/project/Build.scala
+++ b/project/Build.scala
@@ -39,7 +39,21 @@ object KafkaBuild extends Build {
     <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>
     <distribution>repo</distribution>
   </license>
-</licenses>,
+</licenses>
+<dependencies>
+  <exclusion>
+    <groupId>com.sun.jmx</groupId>
+    <artifactId>jmxri</artifactId>
+  </exclusion>
+  <exclusion>
+    <groupId>com.sun.jdmk</groupId>
+    <artifactId>jmxtools</artifactId>
+  </exclusion>
+  <exclusion>
+    <groupId>javax.jms</groupId>
+    <artifactId>jms</artifactId>
+  </exclusion>
+</dependencies>,
     scalacOptions ++= Seq(""-deprecation"", ""-unchecked"", ""-g:none""),
     crossScalaVersions := Seq(""2.8.0"",""2.8.2"", ""2.9.1"", ""2.9.2""),
     scalaVersion := ""2.8.0"",
;;;","15/Jul/13 08:44;charmalloc;tried this with no luck, same error

diff --git a/project/Build.scala b/project/Build.scala
index bad93db..219d7e0 100644
--- a/project/Build.scala
+++ b/project/Build.scala
@@ -52,7 +52,11 @@ object KafkaBuild extends Build {
     javacOptions ++= Seq(""-Xlint:unchecked"", ""-source"", ""1.5""),
     parallelExecution in Test := false, // Prevent tests from overrunning each other
     libraryDependencies ++= Seq(
-      ""log4j""                 % ""log4j""        % ""1.2.15"",
+      ""log4j""                 % ""log4j""        % ""1.2.15"" excludeAll(
+    ExclusionRule(organization = ""com.sun.jdmk""),
+    ExclusionRule(organization = ""com.sun.jmx""),
+    ExclusionRule(organization = ""javax.jms"")
+    ),
       ""net.sf.jopt-simple""    % ""jopt-simple""  % ""3.2"",
       ""org.slf4j""             % ""slf4j-simple"" % ""1.6.4""
     ),
;;;","15/Jul/13 09:08;charmalloc;well, as far as SBT goes http://www.scala-sbt.org/release/docs/Detailed-Topics/Library-Management#exclude-transitive-dependencies it looks like exclude is the right command to use not excludeAll 

diff --git a/project/Build.scala b/project/Build.scala
index bad93db..b3858f3 100644
--- a/project/Build.scala
+++ b/project/Build.scala
@@ -52,7 +52,7 @@ object KafkaBuild extends Build {
     javacOptions ++= Seq(""-Xlint:unchecked"", ""-source"", ""1.5""),
     parallelExecution in Test := false, // Prevent tests from overrunning each other
     libraryDependencies ++= Seq(
-      ""log4j""                 % ""log4j""        % ""1.2.15"",
+      ""log4j""                 % ""log4j""        % ""1.2.15"" exclude(""javax.jms"", ""jms""),
       ""net.sf.jopt-simple""    % ""jopt-simple""  % ""3.2"",
       ""org.slf4j""             % ""slf4j-simple"" % ""1.6.4""
     ),


however, still same error though 

[error] {file:/opt/medialets/SymanticManager/scala/stub/}default-63d5f2/*:update: sbt.ResolveException: download failed: javax.jms#jms;1.1!jms.jar

the pom does look better with the exclusion in the place I expected 

<dependency>
<groupId>log4j</groupId>
<artifactId>log4j</artifactId>
<version>1.2.15</version>
<exclusions>
<exclusion>
<groupId>javax.jms</groupId>
<artifactId>jms</artifactId>
</exclusion>
</exclusions>
</dependency>

still not working;;;","15/Jul/13 09:19;charmalloc;That last fix did work and attached patch

to use public maven

""org.apache.kafka"" % ""kafka_2.9.2"" % ""0.8.0-beta1"" intransitive()

the key in this last patch was to include intransitive() so that SBT knows to not fetch the dependencies we specified in the pom http://www.scala-sbt.org/release/docs/Detailed-Topics/Library-Management#disable-transitivity;;;","16/Jul/13 00:33;jkreps;w00t!;;;","16/Jul/13 02:55;criccomini;Hey Joe,

This looks really good. Per our discussion on the mailing list, I'm updating with some issues I've found:

1. Maven central can't resolve it properly (POM is different from Apache release). Have to use Apache release repo directly to get things to work.
2. Exclusions must be manually applied even though they exist in Kafka's POM already. I think Maven can handle this automatically, if the POM is done right.
3. Weird parent block in Kafka POMs that points to org.apache.
4. Would be nice to publish kafka-test jars as well.
5. Would be nice to have SNAPSHOT releases off of trunk using a Hudson job.

Our hypothesis regarding the first issue is that it was caused by duplicate publishing during testing, and it should go away in the future.

Regarding number 2, I have to explicitly exclude the following when depending on Kafka:

      exclude module: 'jms'
      exclude module: 'jmxtools'
      exclude module: 'jmxri'

I believe these just need to be excluded from the appropriate jars in the actual SBT build file, to fix this issue. I see JMS is excluded from ZK, but it's probably being pulled in from somewhere else, anyway.

Regarding number 3, it is indeed listed as something to do on the Apache publication page (http://www.apache.org/dev/publishing-maven-artifacts.html). I can't find an example of anyone using it, but it doesn't seem to be doing any harm.

Also, regarding your intransitive() call, that is disabling ALL dependencies not just the exclusions, I believe. I think that the ""proper"" way to do that would be to do what I've done: exclude(""jms"", ""jmxtools"", ""jmxri""). Regardless, fixing number 2, above, should mean that intransitive()/exclude() are not required.;;;","20/Aug/13 22:02;charmalloc;resolving because we need another release to take the patch and publish it since it is working in the apache repository fine;;;","28/Nov/13 17:38;miguno;FWIW here is an sbt snippet that resolves this problem.  Chris' last comment was pointing me in the right direction but I still had to figure out the correct sbt syntax -- literally using exclude(""jms"", ""jmxtools"", ""jmxri"") did not work.

{code}
libraryDependencies ++= Seq(
  ""org.apache.kafka"" % ""kafka_2.10"" % ""0.8.0""
    exclude(""javax.jms"", ""jms"")
    exclude(""com.sun.jdmk"", ""jmxtools"")
    exclude(""com.sun.jmx"", ""jmxri""),
  // Alternatively, this apparently also works but it will exclude ALL deps of the excluded organizations:
  //""org.apache.kafka"" % ""kafka_2.10"" % ""0.8.0"" excludeAll(
  //  ExclusionRule(organization = ""com.sun.jdmk""),
  //  ExclusionRule(organization = ""com.sun.jmx""),
  //  ExclusionRule(organization = ""javax.jms"")
  //),
  ...other dependencies...
)
{code}

Versions:
- sbt 0.13.0
- Scala 2.10.3;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LICENSE and NOTICE problems in Kafka 0.7,KAFKA-221,12533519,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jghoman,kevan,kevan,02/Dec/11 05:54,16/Dec/11 02:35,22/Mar/23 15:10,16/Dec/11 02:35,,,,,,,0.7,,,,,,,,,,,0,,,,,,"The source LICENSE file for Kafka is incomplete. The LICENSE file needs to accurately reflect the Kafka source and included artifacts.

Similarly, the NOTICE file is likely to be missing information. I'll attach a file with some information that I created. It's incomplete and will need additional work...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-222,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Dec/11 05:39;jghoman;KAFKA-221-2.patch;https://issues.apache.org/jira/secure/attachment/12506795/KAFKA-221-2.patch","10/Dec/11 05:44;jghoman;KAFKA-221-3.patch;https://issues.apache.org/jira/secure/attachment/12506797/KAFKA-221-3.patch","06/Dec/11 05:50;jghoman;KAFKA-221.patch;https://issues.apache.org/jira/secure/attachment/12506171/KAFKA-221.patch","16/Dec/11 02:28;nehanarkhede;kafka-221-4.patch;https://issues.apache.org/jira/secure/attachment/12507562/kafka-221-4.patch","02/Dec/11 06:00;kevan;kafka-license-info.txt;https://issues.apache.org/jira/secure/attachment/12505817/kafka-license-info.txt",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,219247,,,Thu Dec 15 18:35:02 UTC 2011,,,,,,,,,,"0|i15zcv:",243028,,,,,,,,,,,,,,,,,,,,"02/Dec/11 06:00;kevan;This is a partial analysis of Kafka LICENSE/NOTICE requirements. I use emacs to look inside jars for license/notice files. if you don't find one, then you need to search for a license for the artifact.

Once you have this information pulled together, it's not too hard to pull it all into a LICENSE/NOTICE file.

Unfortunately, there's just not a good automated way to generate this information. If it's any comfort, Geronimo has *way* more embedded jar files than Kafka... ;-);;;","06/Dec/11 05:50;jghoman;Patch that re-does the LICENSE and NOTICE file assuming KAFKA-222 goes in.  NOTICE now just has entries for LinkedIn's contribution, zkclient and sbt.  The other remaining jars are from Apache projects and so don't need to be included here (per my understanding).  The License file has Scala, sbt's license (copied from its LICENSE file in the release we use). zkclient is Apache licensed and as far as I can tell, it therefore doesn't need to be included here.  Is this correct?;;;","06/Dec/11 17:41;aelder;I've tried to have a look but i don't have git and can't work out what SVN revision that patch is against so its hard for me to tell what the resultant files will look like, would you be able to attach the complete license and notice files here?

What is the reasoning behind keeping the NOTICE file entries for LinkedIn, zkclient and sbt? For example, looking at the sbt license at https://github.com/harrah/xsbt/blob/0.11/LICENSE if you include that complete license text in the Kafka LICENSE file then I don't think there is a need to mention sbt in the Kafka NOTICE.

;;;","10/Dec/11 05:39;jghoman;OK, updated based on comments from Ant and the other thread.  NOTICE (new version: http://dl.dropbox.com/u/565949/NOTICE ) only contains the Apache notice based on:
* as Ant mentioned, the sbt license is included in full in LICENSE so not necessary in NOTICE
* zkclient is Apache 2.0 licensed (category A), so no need to mention it in LICENSE
New LICENSE (new version: http://dl.dropbox.com/u/565949/LICENSE ):
* Removed Scala license, since we're not distributing the Scala runtime (it's pulled in via sbt)
* Has sbt license since it is being included and requires inclusion (although I still don't understand why including it in its jar isn't enough to satisfy this condition)
* Doesn't include anything for zkclient since it's ASL2.0
* Doesn't include anything for the pig stuff since they're sister ASF projects.

I think this is enough for a source release.
;;;","10/Dec/11 05:40;jghoman;re-submitting patch.;;;","10/Dec/11 05:44;jghoman;here's a new version without the final line of dashes in LICENSE.;;;","10/Dec/11 08:14;nehanarkhede;+1 on the latest patch.;;;","16/Dec/11 02:28;nehanarkhede;I think we missed the nunit entry in the LICENSE and the NOTICE files. We have the nunit.dll checked into the source repository under clients/csharp;;;","16/Dec/11 02:35;nehanarkhede;Thanks a bunch for helping out on this patch, Jakob ! 
Just committed this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unit test failure in 0.8.1 related to LogCleaner,KAFKA-1098,12675058,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,nehanarkhede,nehanarkhede,23/Oct/13 00:43,25/Oct/13 12:35,22/Mar/23 15:10,25/Oct/13 12:35,0.8.1,,,,,,,,,,,,,log,,,,0,,,,,,"Floor = 0, To = -1
[2013-10-22 09:39:25,001] ERROR Error in cleaner thread 0: (kafka.log.LogCleaner:103)
java.lang.IllegalArgumentException: inconsistent range
	at java.util.concurrent.ConcurrentSkipListMap$SubMap.<init>(ConcurrentSkipListMap.java:2506)
	at java.util.concurrent.ConcurrentSkipListMap.subMap(ConcurrentSkipListMap.java:1984)
	at kafka.log.Log.logSegments(Log.scala:605)
	at kafka.log.LogToClean.<init>(LogCleaner.scala:596)
	at kafka.log.LogCleaner$$anonfun$5.apply(LogCleaner.scala:137)
	at kafka.log.LogCleaner$$anonfun$5.apply(LogCleaner.scala:137)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
	at scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:61)
	at scala.collection.immutable.List.foreach(List.scala:45)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)
	at scala.collection.immutable.List.map(List.scala:45)
	at kafka.log.LogCleaner.kafka$log$LogCleaner$$grabFilthiestLog(LogCleaner.scala:137)
	at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:203)
	at kafka.log.LogCleaner$CleanerThread.run(LogCleaner.scala:189)
",,jjkoshy,jkreps,junrao,jvanremoortere,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/13 12:52;jkreps;KAFKA-1098-v2.patch;https://issues.apache.org/jira/secure/attachment/12609802/KAFKA-1098-v2.patch","25/Oct/13 11:44;jkreps;KAFKA-1098-v3.patch;https://issues.apache.org/jira/secure/attachment/12610260/KAFKA-1098-v3.patch","23/Oct/13 02:46;jvanremoortere;kafka_1098-v1.patch;https://issues.apache.org/jira/secure/attachment/12609702/kafka_1098-v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,354680,,,Fri Oct 25 04:29:09 UTC 2013,,,,,,,,,,"0|i1p5an:",354969,,,,,,,,,,,,,,,,,,,,"23/Oct/13 02:46;jvanremoortere;logSegments can currently be called with to = -1. This can trigger submap to be called with invalid arguments (i.e. from > to). We catch this case and return an empty iterable of logSegments.;;;","23/Oct/13 08:53;jjkoshy;Thanks for the patch - this is interesting/weird.

The real issue seems to be that since the map is defined as {{[Long, LogSegment]}} the null return of floorKey is getting converted to a 0 Long value and failing the eq null check.

i.e., the actual from value is also -1. floorKey should return null (and it does) but it is implicitly converted to 0, so it does not enter the {{floor eq null}} block but we want it to.

I'm wondering if we should just switch the map to use java.lang.Long instead of scala Long to avoid these implicit conversions.

{code}
scala> val m = new ConcurrentSkipListMap[Long, Any]
m: java.util.concurrent.ConcurrentSkipListMap[Long,Any] = {}

scala> m.floorKey(0)
res10: Long = 0

scala> val m = new ConcurrentSkipListMap[java.lang.Long, Any]
m: java.util.concurrent.ConcurrentSkipListMap[java.lang.Long,Any] = {}

scala> m.floorKey(0)
res11: java.lang.Long = null
{code};;;","23/Oct/13 09:03;jvanremoortere;I think the behavior is dependent on the version of Scala used. When I first wrote the patch for Kafka-1042 I was using 2.9.2. This error seems to arise when using 2.8.0.
Your suggestion makes sense, I'm not sure what the plan is for supporting older versions of Scala.;;;","23/Oct/13 12:01;nehanarkhede;+1 on [~jjkoshy]'s suggestion. [~jvanremoortere] Would you like to take a stab at that?;;;","23/Oct/13 12:20;jkreps;Joel, I think you're right. I can grab this.;;;","23/Oct/13 12:52;jkreps;Here is a patch that seems to fix the issue. ;;;","23/Oct/13 12:53;jkreps;Sorry about the churn btw I was only compiling for 2.9 which obviously isn't enough.;;;","23/Oct/13 23:30;junrao;Thanks for the patch. It doesn't compile with scala 2.10.1 though since asIterable no longer exists there. I guess we have to import all JavaConversions._ to get around the cross compilation issue.
[error] /Users/jrao/Intellij/kafka_git/core/src/main/scala/kafka/log/Log.scala:589: value asIterable is not a member of object scala.collection.JavaConversions
[error]     import JavaConversions.asIterable
[error]            ^

Also, in the following places, should we use eq to test null for the returned entry from the skipListMap?

In read(),
    if(startOffset > next || entry == null)

In roll(),
      segments.lastEntry() match {
        case null => 
        case entry => entry.getValue.index.trimToValidSize()
      }
;;;","24/Oct/13 00:36;jvanremoortere;Is the list of Scala versions in the README file (2.8.0, 2.8.2, 2.9.1, 2.9.2 or 2.10.1) a full and  accurate representation of the versions we intend to support? I can be more thorough in running the test suite under each one, but am not sure which versions I need to test.;;;","25/Oct/13 08:59;nehanarkhede;[~jvanremoortere] That list of Scala versions is correct.;;;","25/Oct/13 11:44;jkreps;Ack, fixed 2.10 issue. Frustrating. Do we have a single sbt command that can compile for all?

Jun--the other two null comparisons are for entries not offsets so == should be valid there.;;;","25/Oct/13 12:29;junrao;+1 for v3. 

To compile in all versions of scala, do the following. It's included in README.md
 ./sbt +package;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Error incrementing leader high watermark,KAFKA-862,12641931,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,11/Apr/13 05:40,12/Apr/13 02:55,22/Mar/23 15:10,12/Apr/13 02:55,0.8.0,,,,,,,,,,,,,replication,,,,0,kafka-0.8,p1,,,,"2013/04/10 20:04:31.529 ERROR [KafkaApis] [kafka-request-handler-6] [kafka] [] [KafkaApi-270] Error processing ProducerRequest with correlation id 242757885 from client null-13 on foo:3
java.lang.UnsupportedOperationException: empty.min
        at scala.collection.TraversableOnce$class.min(TraversableOnce.scala:317)
        at scala.collection.immutable.Set$EmptySet$.min(Set.scala:47)
        at kafka.cluster.Partition.maybeIncrementLeaderHW(Partition.scala:263)
        at kafka.server.KafkaApis$$anonfun$appendToLocalLog$2.apply(KafkaApis.scala:195)
        at kafka.server.KafkaApis$$anonfun$appendToLocalLog$2.apply(KafkaApis.scala:186)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)
        at scala.collection.Iterator$class.foreach(Iterator.scala:631)
        at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:161)
        at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:194)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:80)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)
        at scala.collection.mutable.HashMap.map(HashMap.scala:39)
        at kafka.server.KafkaApis.appendToLocalLog(KafkaApis.scala:186)
        at kafka.server.KafkaApis.handleProducerRequest(KafkaApis.scala:120)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:60)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:41)
        at java.lang.Thread.run(Thread.java:619)
",,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-860,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,322346,,,Thu Apr 11 18:55:11 UTC 2013,,,,,,,,,,"0|i1jm73:",322691,,,,,,,,,,,,,,,,,,,,"11/Apr/13 06:32;nehanarkhede;This is caused by a race condition while updating inSyncReplicaSet. Root cause is Partition.maybeIncrementLeaderHW() does not synchronize on the leaderAndIsrUpdateLock causing it to read an empty in sync replica set. Now, the in sync replica set is empty because the broker is becoming a follower for the same partition at that time. The fix should include two things -

1. synchronize access to inSyncReplicaSet
2. fix the behavior of Partition.maybeIncrementLeaderHW() if the inSyncReplicaSet is empty. This should never happen since at least the leader should be in the set at all times.;;;","11/Apr/13 07:53;nehanarkhede;The fix for KAFKA-860 will probably fix this one as well;;;","12/Apr/13 02:55;nehanarkhede;Fix for KAFKA-860 fixes this bug;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient test failure in UncleanLeaderElectionTest,KAFKA-1376,12707493,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,10/Apr/14 01:00,10/Apr/14 05:53,22/Mar/23 15:10,10/Apr/14 05:53,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"We have the following transient unit test failure in trunk.

kafka.integration.UncleanLeaderElectionTest > testUncleanLeaderElectionEnabled FAILED
    org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 400
        at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:880)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:98)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:84)
        at kafka.consumer.ZookeeperConsumerConnector.connectZk(ZookeeperConsumerConnector.scala:169)
        at kafka.consumer.ZookeeperConsumerConnector.<init>(ZookeeperConsumerConnector.scala:125)
        at kafka.consumer.ZookeeperConsumerConnector.<init>(ZookeeperConsumerConnector.scala:141)
        at kafka.consumer.Consumer$.create(ConsumerConnector.scala:89)
        at kafka.integration.UncleanLeaderElectionTest.consumeAllMessages(UncleanLeaderElectionTest.scala:273)
        at kafka.integration.UncleanLeaderElectionTest.verifyUncleanLeaderElectionEnabled(UncleanLeaderElectionTest.scala:197)
        at kafka.integration.UncleanLeaderElectionTest.testUncleanLeaderElectionEnabled(UncleanLeaderElectionTest.scala:106)

kafka.integration.UncleanLeaderElectionTest > testUncleanLeaderElectionDisabled PASSED

kafka.integration.UncleanLeaderElectionTest > testUncleanLeaderElectionEnabledByTopicOverride PASSED

kafka.integration.UncleanLeaderElectionTest > testCleanLeaderElectionDisabledByTopicOverride FAILED
    org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 400
        at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:880)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:98)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:84)
        at kafka.consumer.ZookeeperConsumerConnector.connectZk(ZookeeperConsumerConnector.scala:169)
        at kafka.consumer.ZookeeperConsumerConnector.<init>(ZookeeperConsumerConnector.scala:125)
        at kafka.consumer.ZookeeperConsumerConnector.<init>(ZookeeperConsumerConnector.scala:141)
        at kafka.consumer.Consumer$.create(ConsumerConnector.scala:89)
        at kafka.integration.UncleanLeaderElectionTest.consumeAllMessages(UncleanLeaderElectionTest.scala:273)
        at kafka.integration.UncleanLeaderElectionTest.verifyUncleanLeaderElectionDisabled(UncleanLeaderElectionTest.scala:214)
        at kafka.integration.UncleanLeaderElectionTest.testCleanLeaderElectionDisabledByTopicOverride(UncleanLeaderElectionTest.scala:148)
",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Apr/14 05:44;junrao;KAFKA-1376.patch;https://issues.apache.org/jira/secure/attachment/12639471/KAFKA-1376.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,385816,,,Wed Apr 09 21:53:49 UTC 2014,,,,,,,,,,"0|i1ugr3:",386080,,,,,,,,,,,,,,,,,,,,"10/Apr/14 01:02;junrao;The issue seems to be the zk connection/sessesion timeout are too small (400ms) as configured in TestUtils.createConsumerProperties.;;;","10/Apr/14 05:44;junrao;Created reviewboard https://reviews.apache.org/r/20181/
 against branch origin/trunk;;;","10/Apr/14 05:53;junrao;Thanks for the review. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Error in controller log when broker tries to rejoin cluster,KAFKA-2300,12840252,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,fpj,jbrownrally,jbrownrally,25/Jun/15 00:43,30/Jan/16 08:36,22/Mar/23 15:10,22/Sep/15 02:58,0.8.2.1,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Hello Kafka folks,

We are having an issue where a broker attempts to join the cluster after being restarted, but is never added to the ISR for its assigned partitions. This is a three-node cluster, and the controller is broker 2.

When broker 1 starts, we see the following message in broker 2's controller.log.

{{
[2015-06-23 13:57:16,535] ERROR [BrokerChangeListener on Controller 2]: Error while handling broker changes (kafka.controller.ReplicaStateMachine$BrokerChangeListener)
java.lang.IllegalStateException: Controller to broker state change requests batch is not empty while creating a new one. Some UpdateMetadata state changes Map(2 -> Map([prod-sver-end,1] -> (LeaderAndIsrInfo:(Leader:-2,ISR:1,LeaderEpoch:0,ControllerEpoch:165),ReplicationFactor:1),AllReplicas:1)), 1 -> Map([prod-sver-end,1] -> (LeaderAndIsrInfo:(Leader:-2,ISR:1,LeaderEpoch:0,ControllerEpoch:165),ReplicationFactor:1),AllReplicas:1)), 3 -> Map([prod-sver-end,1] -> (LeaderAndIsrInfo:(Leader:-2,ISR:1,LeaderEpoch:0,ControllerEpoch:165),ReplicationFactor:1),AllReplicas:1))) might be lost 
  at kafka.controller.ControllerBrokerRequestBatch.newBatch(ControllerChannelManager.scala:202)
  at kafka.controller.KafkaController.sendUpdateMetadataRequest(KafkaController.scala:974)
  at kafka.controller.KafkaController.onBrokerStartup(KafkaController.scala:399)
  at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ReplicaStateMachine.scala:371)
  at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$apply$mcV$sp$1.apply(ReplicaStateMachine.scala:359)
  at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$apply$mcV$sp$1.apply(ReplicaStateMachine.scala:359)
  at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
  at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply$mcV$sp(ReplicaStateMachine.scala:358)
  at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply(ReplicaStateMachine.scala:357)
  at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply(ReplicaStateMachine.scala:357)
  at kafka.utils.Utils$.inLock(Utils.scala:535)
  at kafka.controller.ReplicaStateMachine$BrokerChangeListener.handleChildChange(ReplicaStateMachine.scala:356)
  at org.I0Itec.zkclient.ZkClient$7.run(ZkClient.java:568)
  at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
}}

{{prod-sver-end}} is a topic we previously deleted. It seems some remnant of it persists in the controller's memory, causing an exception which interrupts the state change triggered by the broker startup.

Has anyone seen something like this? Any idea what's happening here? Any information would be greatly appreciated.

Thanks,
Johnny",,bob.cotton@gmail.com,drcrallen,fpj,githubbot,guozhang,jbrownrally,jthakrar,kharriger,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3173,,,,,,,,"15/Jul/15 03:40;bob.cotton@gmail.com;KAFKA-2300-controller-logs.tar.gz;https://issues.apache.org/jira/secure/attachment/12745314/KAFKA-2300-controller-logs.tar.gz","16/Jul/15 23:47;fpj;KAFKA-2300-repro.patch;https://issues.apache.org/jira/secure/attachment/12745642/KAFKA-2300-repro.patch","30/Jul/15 02:01;fpj;KAFKA-2300.patch;https://issues.apache.org/jira/secure/attachment/12747826/KAFKA-2300.patch","14/Jul/15 19:54;fpj;KAFKA-2300.patch;https://issues.apache.org/jira/secure/attachment/12745241/KAFKA-2300.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Sep 21 18:56:47 UTC 2015,,,,,,,,,,"0|i2gfyn:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"25/Jun/15 02:37;kharriger;Looking at the code it appears once the controller has this invalid state new brokers are unable to join the cluster and this state cannot be cleared until the current controller is restarted.  The only code path that is calls clear on the updateMetadataRequestMap follows a call to newBatch and thus is unreachable.  If newBatch fails it probably needs to clear the invalid state.  

The only way it seems to clear the new invalid state is to restart the current controller node.  Its a bit scary to restart an otherwise working node when you have another node sitting idle and currently unable to join the cluster.
;;;","25/Jun/15 23:59;kharriger;We eventually resolved the problem after hours with much less success than desired. 

Reviewing the code it appeared that the controller would not be able to send state to any brokers and would need to be restarted.  

We were hesitant to bring this node down entirely as it was the only ISR for many partitions and since the controller was unable to send messages to other brokers we were unable to reassign any partitions.  

We determined it would be possible to force a controller re-election without fully shutting down the broker by deleting the /controller node in zookeeper.  Our hope was that once a new controller was elected broker 1 would be able to rejoin the cluster and we would then be able to restart broker 2 after replication was up to date.

Once we deleted the /controller node from zookeeper, election did occur as expected and broker 3 became the new leader and broker 1 was able to join the cluster.  However we started lots of unknown errors in the logs from broker 2. 
...
[2015-06-24 18:14:23,274] ERROR [ReplicaFetcherThread-0-2], Error for partition [prod-eclipselinkchannel,5] to broker 2:class kafka.common.UnknownException (kafka.server.ReplicaFetcherThread)
[2015-06-24 18:14:23,274] ERROR [ReplicaFetcherThread-0-2], Error for partition [birdseed-metadata-stream,18] to broker 2:class kafka.common.UnknownException (kafka.server.ReplicaFetcherThread)
[2015-06-24 18:14:23,274] ERROR [ReplicaFetcherThread-0-2], Error for partition [trial-server-start,7] to broker 2:class kafka.common.UnknownException (kafka.server.ReplicaFetcherThread)
... 
We looked through the code a bit but were not easily able to identify the root cause of this exception.  More logging may have been helpful here.  We knew that broker 2 was needed to be restarted so we did that now.  Once node 2 came back online the error messages changed and the logs seemed to indicate data was lost: 
...
[2015-06-24 18:43:51,136] ERROR [Replica Manager on Broker 3]: Error when processing fetch request for partition [feedback-events,10] offset 1757 from follower with correlation id 10539. Possible cause: Request for offset 1757 but we only have log segments in the range 0 to 0. (kafka.server.ReplicaManager)
[2015-06-24 18:43:51,136] ERROR [Replica Manager on Broker 3]: Error when processing fetch request for partition [prod-beacon,10] offset 70616524 from follower with correlation id 10539. Possible cause: Request for offset 70616524 but we only have log segments in the range 0 to 1246. (kafka.server.ReplicaManager)
...
The logs were still noisy and replication did not appear to be working so we decided to restart broker 3.  Following this we saw large number of files being deleted. 
[2015-06-24 19:34:11,237] INFO Deleting index /home/kafka/shared/logs/alm-start-spans-2/00000000000420766992.index.deleted (kafka.log.OffsetIndex)
[2015-06-24 19:34:11,248] INFO Deleting index /home/kafka/shared/logs/alm-spans-2/00000000000420150674.index.deleted (kafka.log.OffsetIndex)
[2015-06-24 19:34:11,269] INFO Deleting index /home/kafka/shared/logs/alm-start-spans-2/00000000000426783743.index.deleted (kafka.log.OffsetIndex)
[2015-06-24 19:34:11,270] INFO Deleting index /home/kafka/shared/logs/beacon-spans-11/00000000000389662179.index.deleted (kafka.log.OffsetIndex)
[2015-06-24 19:34:11,275] INFO Deleting index /home/kafka/shared/logs/prod-server-start-11/00000000000415746006.index.deleted (kafka.log.OffsetIndex)

After this the logs settled down and the cluster began replicating and was otherwise healthy.  We know we lost some partitions that were on broker 1. I'm not entirely sure if the above indicated errors indicated that topics were partitions were lost entirely or just replicas of said partitions, but we definitely lost some partitions.  

We also mirror the data into another data center where we do the actual data analytics, so I was able to compare message counts by dumping all the data and grouping by date to see that about 2/3rds of the data on at least one topic was lost.  This topic had 2 of 12 located on broker 1 which went unavailable after broker 2 (the controller) entered a bad state since it was the only ISR.  We expected we would probably lose these partitions, but this ratio suggests that much more data was lost.  Given that we mirror the data we aren't particularly concerned with historical data loss, but I thought I would mention it.  

;;;","09/Jul/15 23:25;fpj;My assessment so far focused on the original problem that has been reported in this issue, the one that the controller is stuck because of some spurious state. From the description and the comments, ControllerBrokerRequestBatch.updateMetadataRequestMap isn't empty at the time a broker tries to re-join, which causes the processing of KafkaController.onBrokerStartup to fail because a call to ControllerBrokerRequestBatch.newBatch   (verifies that three data structures are empty, including updateMetadataRequestMap) throws an exception.

From the description, the update metadata requests have -2 for the leader, which is LeaderDuringDelete. Such requests are put in the update metadata map via a call from onTopicDeletion to controller.sendUpdateMetadataRequest. Interestingly, the call to sendUpdateMetadataRequest adds to the update metadata map by calling brokerRequestBatch.addUpdateMetadataRequestForBrokers and right after invokes brokerRequestBatch.sendRequestsToBrokers. The latter is supposed to clear the update metadata map, which makes me think that there could have been an exception that interrupted the flow, causing the updateMetadataRequestMap to not be cleared. 

I wanted to ask if anyone has anything to add or correct in the analysis so far, and I also if [~kharriger] would be able to post the whole log so that I can have a look. Ultimately, it'd be great to avoid having the controller unable to make progress because of some bad state.;;;","10/Jul/15 05:44;bob.cotton@gmail.com;Which logs would you like? server, controller, state-change?;;;","10/Jul/15 05:48;fpj;controller logs, please.;;;","14/Jul/15 19:54;fpj;Attaching a preliminary patch in the case anyone is willing to give a hand. As I described before, one problem is that calls like sendRequest can throw an exception and if one is thrown, then the state of the ControllerBrokerRequestBatch object can be left broken (requests are not sent and newBatch calls keep throwing exceptions).

The attached patch catches exceptions that calls like sendRequest might throw, cleans the state, and throws an IllegalStateException. Cleaning the state can be problematic if we don't handle the IllegalStateException appropriately. For now, at least in the call path of the topic deletion, I'm suggesting that we make the controller resign, but this could be overkill. If anyone is willing to chime in, I'd appreciate suggestions around the best way of dealing with such a controller in an illegal state.;;;","15/Jul/15 03:40;bob.cotton@gmail.com;Controller logs ;;;","15/Jul/15 16:45;fpj;thank you, [~bob.cotton@gmail.com]. however, these log files do not seem to correspond to the period in the description of the jira. the error reported above isn't in the logs and the latest timestamp in the controller log of broker 2 is [2015-06-04 07:38:08,066]. ;;;","16/Jul/15 23:47;fpj;I'm attaching a patch to trigger the problem as I described. It essentially throw an exception before clearing the update metadata when processing a topic delete. The sequence of steps I used to trigger the problem with the repro patch are:

# Start a broker
# Create a topic
# Delete topic (exception thrown)
# Start another broker

When the second broker starts, I get an exception in the controller during the execution of newBatch. The controller isn't able to recover from the illegal state without the patch I proposed previously.;;;","30/Jul/15 02:01;githubbot;GitHub user fpj opened a pull request:

    https://github.com/apache/kafka/pull/102

    KAFKA-2300: Error in controller log when broker tries to rejoin cluster

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/fpj/kafka 2300

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/102.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #102
    
----
commit dbd1bf3a91c3e15ed2d14bf941c41c87b8116608
Author: flavio junqueira <fpj@apache.org>
Date:   2015-07-29T17:07:51Z

    KAFKA-2300: Error in controller log when broker tries to rejoin cluster

----
;;;","30/Jul/15 02:01;fpj;Uploading a patch for trunk.;;;","30/Jul/15 02:06;fpj;It turns out that the scenario that the scenario the test case implements is less relevant after KAFKA-2122 got in because the message queues in the controller are large enough. The patch might still be relevant to make sure that exceptions won´t bring the controller to a useless state. ;;;","30/Jul/15 05:34;guozhang;[~junrao] would you like to take a look?;;;","13/Aug/15 05:30;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/102
;;;","13/Aug/15 05:30;guozhang;Issue resolved by pull request 102
[https://github.com/apache/kafka/pull/102];;;","12/Sep/15 00:39;fpj;I'm observing sometimes that the same controller gets elected, but it is not restarting with a clean state, which causes the test case committed in this patch to fail. We need to make sure that the controller starts with a clean state for brokerRequestBatch to fix this problem.;;;","14/Sep/15 21:52;githubbot;GitHub user fpj opened a pull request:

    https://github.com/apache/kafka/pull/212

    KAFKA-2300: Error in controller log when broker tries to rejoin cluster

    I have reopened this issue because the controller isn't cleaning up the state upon an exception and the test case was legitimately failing for me every now and then. I'm proposing a change to fix this.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/fpj/kafka 2300

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/212.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #212
    
----
commit dbd1bf3a91c3e15ed2d14bf941c41c87b8116608
Author: flavio junqueira <fpj@apache.org>
Date:   2015-07-29T17:07:51Z

    KAFKA-2300: Error in controller log when broker tries to rejoin cluster

commit 9b6390ae1c474b90689ff53036120b4be44a3f8f
Author: flavio junqueira <fpj@apache.org>
Date:   2015-07-29T22:36:16Z

    Updated package name and removed unnecessary imports.

commit f1261b15b007d08e87d0ed56f7ec3fecbeddc276
Author: flavio junqueira <fpj@apache.org>
Date:   2015-07-30T09:57:34Z

    Fixed some style issues.

commit aa6ec90b15ac6d0e0f9e5a58d4fed7b1909d50c2
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-12T16:37:07Z

    KAFKA-2300: Wrapped all occurences of sendRequestToBrokers with try/catch
    and fixed string typo.

commit 7bd2edb83054a9be72dda3425930a68ea3ad494b
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-12T16:40:13Z

    KAFKA-2300: Removed unnecessary s"" occurrences.

commit d5cfba343dac5967733c9415d4574256efdd764a
Author: fpj <fpj@apache.org>
Date:   2015-09-14T13:00:15Z

    Merge remote-tracking branch 'upstream/trunk' into 2300

commit 742519349463c879d8413aee2b3f12b2ae8888a8
Author: fpj <fpj@apache.org>
Date:   2015-09-14T13:47:50Z

    KAFKA-2300: Cleaning the state of broker request batch upon an exception.

----
;;;","22/Sep/15 02:56;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/212
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
broker fetch request uses old leader offset which is higher than current leader offset causes error,KAFKA-1806,12759528,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,nehanarkhede,lokeshbirla,lokeshbirla,05/Dec/14 06:16,24/Dec/14 09:06,22/Mar/23 15:10,24/Dec/14 09:06,0.8.1.1,,,,,,0.8.2.0,,,,,,,consumer,,,,0,,,,,,"Although following issue: https://issues.apache.org/jira/browse/KAFKA-727
is marked fixed but I still see this issue in 0.8.1.1. I am able to reproducer the issue consistently. 

[2014-08-18 06:43:58,356] ERROR [KafkaApi-1] Error when processing fetch request for partition [mmetopic4,2] offset 1940029 from consumer with correlation id 21 (kafka.server.Kaf
kaApis)
java.lang.IllegalArgumentException: Attempt to read with a maximum offset (1818353) less than the start offset (1940029).
        at kafka.log.LogSegment.read(LogSegment.scala:136)
        at kafka.log.Log.read(Log.scala:386)
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$readMessageSet(KafkaApis.scala:530)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$readMessageSets$1.apply(KafkaApis.scala:476)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$readMessageSets$1.apply(KafkaApis.scala:471)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:233)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:233)
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:119)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:233)
        at scala.collection.immutable.Map$Map1.map(Map.scala:107)
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$readMessageSets(KafkaApis.scala:471)
        at kafka.server.KafkaApis$FetchRequestPurgatory.expire(KafkaApis.scala:783)
        at kafka.server.KafkaApis$FetchRequestPurgatory.expire(KafkaApis.scala:765)
        at kafka.server.RequestPurgatory$ExpiredRequestReaper.run(RequestPurgatory.scala:216)
        at java.lang.Thread.run(Thread.java:745)

",,eapache,joestein,kzadorozhny,lokeshbirla,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Dec 24 01:04:53 UTC 2014,,,,,,,,,,"0|i232nj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"05/Dec/14 06:19;lokeshbirla;I have 3 node cluster kafka broker running one broker on each blade. I have one zookeeper running on another blade. 
I created 4 partitions with replication factor 3 each and producer is sending messages from one blade and consumer is getting from another blade. I see above issue consistently. 

However this issue did not exist when I use same configuaration with upto 3 topics. I increase the heap size from 4GB to 16GB however same issue. ;;;","09/Dec/14 01:48;lokeshbirla;is there any update on this?;;;","09/Dec/14 12:59;nehanarkhede;[~lokeshbirla] Please can you provide the steps to reproduce this issue?;;;","11/Dec/14 06:32;lokeshbirla;ok. I'll create the steps to reproducer this. Basically I am using sarama client for kafka which is go client. ;;;","12/Dec/14 02:42;nehanarkhede;[~lokeshbirla] We don't support that client. You may have to loop in the maintainer of that library. Let us know if you see this behavior with the java/scala client.;;;","16/Dec/14 10:06;lokeshbirla;Neha,

I can see this problem quite often. 


[2014-08-29 11:37:34,980] ERROR [ReplicaFetcherThread-2-2], Current offset 11396282 for partition [mmetopic1,1] out of range; reset offset to 3006843 (kafka.server.ReplicaFetcherThread)

kafka.common.OffsetOutOfRangeException: Request for offset 7602056 but we only have log segments in the range 0 to 7471002.

I'll send you steps for this. 
;;;","17/Dec/14 03:37;eapache;Sarama client maintainer here (via https://github.com/Shopify/sarama/issues/226); this looks like a kafka bug to me since the error in the log message is from a ReplicaFetcherThread, but I'm happy to provide extra information on the behaviour of the client if you think it's relevant.;;;","17/Dec/14 05:34;lokeshbirla;This problem occurs multiple times in server.log. 
Currently I am using:

 #added replica fetchers
num.replica.fetchers=4


[2014-08-30 04:00:58,419] ERROR [ReplicaFetcherThread-1-2], Current offset 7343326909 for partition [mmetopic1,0] out of range; reset offset to 7351079341 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:01:58,351] ERROR [ReplicaFetcherThread-1-2], Current offset 7352830699 for partition [mmetopic1,0] out of range; reset offset to 7360600212 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:01:58,398] ERROR [ReplicaFetcherThread-2-2], Current offset 7362122784 for partition [mmetopic1,1] out of range; reset offset to 7369788902 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:01:58,428] ERROR [ReplicaFetcherThread-3-2], Current offset 7349217662 for partition [mmetopic1,2] out of range; reset offset to 7356979468 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:02:58,380] ERROR [ReplicaFetcherThread-3-2], Current offset 7358748697 for partition [mmetopic1,2] out of range; reset offset to 7366511359 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:02:58,431] ERROR [ReplicaFetcherThread-2-2], Current offset 7371546217 for partition [mmetopic1,1] out of range; reset offset to 7379322019 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:02:58,491] ERROR [ReplicaFetcherThread-1-2], Current offset 7362381355 for partition [mmetopic1,0] out of range; reset offset to 7370131818 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:03:58,553] ERROR [ReplicaFetcherThread-3-2], Current offset 7368280588 for partition [mmetopic1,2] out of range; reset offset to 7376042337 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:03:58,606] ERROR [ReplicaFetcherThread-1-2], Current offset 7371895090 for partition [mmetopic1,0] out of range; reset offset to 7379659373 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:03:58,745] ERROR [ReplicaFetcherThread-2-2], Current offset 7381073377 for partition [mmetopic1,1] out of range; reset offset to 7388856060 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:04:58,377] ERROR [ReplicaFetcherThread-2-2], Current offset 7390601461 for partition [mmetopic1,1] out of range; reset offset to 7398383811 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:04:58,378] ERROR [ReplicaFetcherThread-1-2], Current offset 7381410731 for partition [mmetopic1,0] out of range; reset offset to 7389193402 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:04:58,462] ERROR [ReplicaFetcherThread-3-2], Current offset 7377936663 for partition [mmetopic1,2] out of range; reset offset to 7385573885 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:05:58,440] ERROR [ReplicaFetcherThread-2-2], Current offset 7400170911 for partition [mmetopic1,1] out of range; reset offset to 7407915357 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:05:58,441] ERROR [ReplicaFetcherThread-1-2], Current offset 7390968588 for partition [mmetopic1,0] out of range; reset offset to 7398725995 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:05:58,442] ERROR [ReplicaFetcherThread-3-2], Current offset 7387325243 for partition [mmetopic1,2] out of range; reset offset to 7395096361 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:06:58,326] ERROR [ReplicaFetcherThread-1-2], Current offset 7400572665 for partition [mmetopic1,0] out of range; reset offset to 7411422730 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:06:58,346] ERROR [ReplicaFetcherThread-2-2], Current offset 7409827554 for partition [mmetopic1,1] out of range; reset offset to 7417436416 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:06:58,511] ERROR [ReplicaFetcherThread-3-2], Current offset 7396889418 for partition [mmetopic1,2] out of range; reset offset to 7404620618 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:07:58,328] ERROR [ReplicaFetcherThread-2-2], Current offset 7419467753 for partition [mmetopic1,1] out of range; reset offset to 7420615385 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:07:58,362] ERROR [ReplicaFetcherThread-3-2], Current offset 7406461331 for partition [mmetopic1,2] out of range; reset offset to 7410977640 (kafka.server.ReplicaFetcherThread)
[2014-08-30 04:07:58,588] ERROR [ReplicaFetcherThread-1-2], Current offset 7413376626 for partition [mmetopic1,0] out of range; reset offset to 7414599975 (kafka.server.ReplicaFetcherThread)

;;;","19/Dec/14 01:48;lokeshbirla;Hi Neha,

What is the status of fixing this issue? This issue happens on every run. I have seen, if I use: num.replica.fetchers=1, then sometimes this issue goes away however I see other problem of leadership changes very often even when all brokers are running. 

If I set: num.replica.fetchers=4, then I can reproduce this issue on every run. 

Please let me or Evan (from sarama) know if you need any help to fix this. ;;;","19/Dec/14 10:24;nehanarkhede;[~lokeshbirla] I was looking for steps to reproduce this. So if I download 0.8.2-beta and go through your steps, I should be able to see the same error you see.;;;","20/Dec/14 02:53;joestein;I am not sure if this is directly related but perhaps in some way possibly so I wanted to bring it up. I just created https://issues.apache.org/jira/browse/KAFKA-1825 which is a case where the Sarama client is putting Kafka in a bad state.  I suspect this might be the same type of scenario too.

[~lokeshbirla] is there some chance of getting code to reproduce your issue succinctly (please see my KAFKA-1825 sample code to reproduce and even a binary for folks to try out). 

<< sometimes this issue goes away however I see other problem of leadership changes very often even when all brokers are running.
This is a another issue I see in production with the Sarama client. I am working on hunting down the root cause but right now the thinking is that it is related to https://issues.apache.org/jira/browse/KAFKA-766 and https://github.com/Shopify/sarama/issues/236 with https://github.com/Shopify/sarama/commit/03ad601663634fd75eb357fee6782653f5a9a5ed being a fix for it.  ;;;","20/Dec/14 14:14;lokeshbirla;Hi Joe,

Your problem described in  https://issues.apache.org/jira/browse/KAFKA-1825 is very similar. I get leadership changes quite often even with 3 partitions itself. I also found that using sarma fix where I am restricting batch size to 1000, DOES not resolve the problem. I tried to slow down the producer speed by using batchsize=1000. Even with 72k message/sec (msg size 150 bytes), I still see leadership change issue and broker offset error. 

I only filed sarama issue:  https://github.com/Shopify/sarama/issues/236. 

--Lokesh;;;","20/Dec/14 14:53;lokeshbirla;Hello Neha,

I did further debugging on this by turning trace on and found the following. 

1. Broker 1 and broker 3 have different offset for partition 0 for topic mmetopic1.  Broker 1 has higher offset than Broker 3.  
2. Due to kafka leadership changed, Broker 3 became the leader which has lower offset and when Broker 1 send fetch request with higher offset, error comes from broker 3 since it does NOT have that higher offset. 

Here is important trace information. 

Broker 1 (log)

[2014-09-02 06:53:55,466] DEBUG Partition [mmetopic1,0] on broker 1: Old hw for partition [mmetopic1,0] is 1330329. New hw is 1330329. All leo's are 1371212,1330329,1331850 (kafka.cluster.Partition)[2014-09-02 06:53:55,537] INFO Truncating log mmetopic1-0 to offset 1329827. (kafka.log.Log)
[2014-09-02 06:53:55,477] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions ArrayBuffer, [[mmetopic1,0], initOffset 1330329 to broker id:3,host:10.1.130.1,port:9092] ) (kafka.server.ReplicaFetcherManager
[2014-09-02 06:53:55,479] TRACE [KafkaApi-1] Handling request: Name:UpdateMetadataRequest;Version:0;Controller:2;ControllerEpoch:2;CorrelationId:5;ClientId:id_2-host_null-port_9092;AliveBrokers:id:3,host:10.1.130.1,port:9092,id:2,host:10.1.129.1,port:9092,id:1,host:10.1.128.1,port:9092;PartitionState:[mmetopic1,0] -> (LeaderAndIsrInfo:(Leader:3,ISR:3,2,LeaderEpoch:2,ControllerEpoch:2),ReplicationFactor:3),AllReplicas:1,2,3) from client: /10.1.128.1:59805 (kafka.server.KafkaApis)
[2014-09-02 06:53:55,490] TRACE [ReplicaFetcherThread-0-3], issuing to broker 3 of fetch request Name: FetchRequest; Version: 0; CorrelationId: 3687; ClientId: ReplicaFetcherThread-0-3; ReplicaId: 1; MaxWait: 500 ms; MinBytes: 1 bytes; RequestInfo: [mmetopic1,0] -> PartitionFetchInfo(1330329,2097152) (kafka.server.ReplicaFetcherThread)
[2014-09-02 06:53:55,543] WARN [ReplicaFetcherThread-0-3], Replica 1 for partition [mmetopic1,0] reset its fetch offset to current leader 3's latest offset 1329827 (kafka.server.ReplicaFetcherThread)
[2014-09-02 06:53:55,543] ERROR [ReplicaFetcherThread-0-3], Current offset 1330329 for partition [mmetopic1,0] out of range; reset offset to 1329827 (kafka.server.ReplicaFetcherThread)

Broker 3 (log)
[2014-09-02 06:53:06,525] TRACE Setting log end offset for replica 2 for partition [mmetopic1,0] to 1330329 (kafka.cluster.Replica)
[2014-09-02 06:53:06,526] DEBUG Partition [mmetopic1,0] on broker 3: Old hw for partition [mmetopic1,0] is 1329827. New hw is 1329827. All leo's are 1329827,1330329 (kafka.cluster.Partition)




=========================================================================================================

[2014-09-02 06:53:06,530] ERROR [KafkaApi-3] Error when processing fetch request for partition [mmetopic1,0] offset 1330329 from follower with correlation id 3686 (kafka.server.KafkaApis)
kafka.common.OffsetOutOfRangeException: Request for offset 1330329 but we only have log segments in the range 0 to 1329827.
        at kafka.log.Log.read(Log.scala:380)
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$readMessageSet(KafkaApis.scala:530)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$readMessageSets$1.apply(KafkaApis.scala:476)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$readMessageSets$1.apply(KafkaApis.scala:471)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:233)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:233)
        at scala.collection.immutable.Map$Map3.foreach(Map.scala:164)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:233)
        at scala.collection.immutable.Map$Map3.map(Map.scala:144)
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$readMessageSets(KafkaApis.scala:471)
        at kafka.server.KafkaApis.handleFetchRequest(KafkaApis.scala:437)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:186)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:42)
        at java.lang.Thread.run(Thread.java:745)

==========================================================================================

;;;","23/Dec/14 03:46;lokeshbirla;Neha,

Could you please update on this? With my recent comment and title change for the problem you should now know the detail information about the problem. Please let me know if you need further information. 

Lokesh;;;","24/Dec/14 01:54;nehanarkhede;Pasting my comment above 

[~lokeshbirla] I was looking for steps to reproduce this. So if I download 0.8.2-beta and go through your steps, I should be able to see the same error you see. 

If you can provide this, someone can help out.;;;","24/Dec/14 09:04;lokeshbirla;Neha,

I used 0.8.2-beta and it works great. I did not see any problem so far. I think this issue can be closed now. I found multiple issues with 0.8.1.1 however I see NO issue with 0.8.2-beta. 

Thanks,
Lokesh;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Confusing Error mesage from producer when no kafka brokers are available,KAFKA-4,12514641,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,,,,20/Jul/11 05:32,16/Nov/17 17:11,22/Mar/23 15:10,16/Nov/17 17:11,0.6,,,,,,0.11.0.0,,,,,,,,,,,0,,,,,,"If no kafka brokers are available the producer gives the following error: 

Exception in thread ""main"" kafka.common.InvalidPartitionException: Invalid number of partitions: 0 
Valid values are > 0 
at kafka.producer.Producer.kafka$producer$Producer$$getPartition(Producer.scala:144) 
at kafka.producer.Producer$$anonfun$3.apply(Producer.scala:112) 
at kafka.producer.Producer$$anonfun$3.apply(Producer.scala:102) 
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206) 
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206) 
at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34) 
at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:32) 
at scala.collection.TraversableLike$class.map(TraversableLike.scala:206) 
at scala.collection.mutable.WrappedArray.map(WrappedArray.scala:32) 
at kafka.producer.Producer.send(Producer.scala:102) 
at kafka.javaapi.producer.Producer.send(Producer.scala:101) 
at com.linkedin.nusviewer.PublishTestMessage.main(PublishTestMessage.java:45) 

This is confusing. The problem is that no brokers are available, we should make this more clear.",,sliebau,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-5179,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,67512,,,Thu Nov 16 09:05:14 UTC 2017,,,,,,,,,,"0|i15ygn:",242883,,,,,,,,,,,,,,,,,,,,"16/Nov/17 17:05;sliebau;Current error message when no broker is available is:

{code}
WARN Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
{code}

This message was introduced by KAFKA-5179, so I think it is save to say that we can close this ticket as well with the same fix version. Before that there were other error messages that also improved upon this message, but I don't think we need to provide the entire history here..
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SSL: Received fatal alert: handshake_failure occurs sporadically ,KAFKA-2564,12895247,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,benstopford,benstopford,benstopford,22/Sep/15 04:30,13/Oct/15 17:42,22/Mar/23 15:10,13/Oct/15 17:42,,,,,,,0.9.0.0,,,,,,,security,,,,0,,,,,,"We sporadically get this error when SSL is enabled. It might be better if we retried this rather than failing immediately on the error. 

[2015-09-21 17:22:09,446] WARN Error in I/O with connection to ip-172-31-34-157.eu-west-1.compute.internal/172.31.34.157 (org.apache.kafka.common.network.Selector)
javax.net.ssl.SSLException: Received fatal alert: handshake_failure
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208)
	at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1639)
	at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1607)
	at sun.security.ssl.SSLEngineImpl.recvAlert(SSLEngineImpl.java:1776)
	at sun.security.ssl.SSLEngineImpl.readRecord(SSLEngineImpl.java:1068)
	at sun.security.ssl.SSLEngineImpl.readNetRecord(SSLEngineImpl.java:890)
	at sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:764)
	at javax.net.ssl.SSLEngine.unwrap(SSLEngine.java:624)
	at org.apache.kafka.common.network.SSLTransportLayer.handshakeUnwrap(SSLTransportLayer.java:377)
	at org.apache.kafka.common.network.SSLTransportLayer.handshake(SSLTransportLayer.java:247)
	at org.apache.kafka.common.network.KafkaChannel.prepare(KafkaChannel.java:69)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:293)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:250)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:274)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:182)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:172)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:125)
	at org.apache.kafka.clients.consumer.internals.Coordinator.ensureCoordinatorKnown(Coordinator.java:214)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:804)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:776)
	at kafka.tools.ConsumerPerformance$.consume(ConsumerPerformance.scala:122)
	at kafka.tools.ConsumerPerformance$.main(ConsumerPerformance.scala:66)
	at kafka.tools.ConsumerPerformance.main(ConsumerPerformance.scala)",,benstopford,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Oct 13 09:42:19 UTC 2015,,,,,,,,,,"0|i2ld7z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"13/Oct/15 17:42;benstopford;Duplicate of https://issues.apache.org/jira/browse/KAFKA-2504 which is resolved;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in AddPartitionsTest,KAFKA-1381,12707601,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,10/Apr/14 07:43,13/Apr/14 04:51,22/Mar/23 15:10,13/Apr/14 04:51,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Saw the following transient unit test failure.

kafka.admin.AddPartitionsTest > testReplicaPlacement FAILED
    java.util.NoSuchElementException: None.get
        at scala.None$.get(Option.scala:313)
        at scala.None$.get(Option.scala:311)
        at kafka.admin.AddPartitionsTest.testReplicaPlacement(AddPartitionsTest.scala:189)
",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Apr/14 09:16;junrao;KAFKA-1381.patch;https://issues.apache.org/jira/secure/attachment/12639500/KAFKA-1381.patch","12/Apr/14 09:39;junrao;KAFKA-1381_2014-04-11_18:39:42.patch;https://issues.apache.org/jira/secure/attachment/12639908/KAFKA-1381_2014-04-11_18%3A39%3A42.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,385924,,,Sat Apr 12 20:51:54 UTC 2014,,,,,,,,,,"0|i1uhf3:",386188,,,,,,,,,,,,,,,,,,,,"10/Apr/14 09:16;junrao;Created reviewboard https://reviews.apache.org/r/20185/
 against branch origin/trunk;;;","12/Apr/14 09:39;junrao;Updated reviewboard https://reviews.apache.org/r/20185/
 against branch origin/trunk;;;","13/Apr/14 04:51;junrao;Thanks for the review. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in testSendWithDeadBroker,KAFKA-1424,12710562,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,25/Apr/14 22:51,29/Apr/14 06:00,22/Mar/23 15:10,29/Apr/14 06:00,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Saw the following transient unit test failure.

kafka.producer.ProducerTest > testSendWithDeadBroker FAILED
    java.lang.AssertionError: Message set should have 1 message
        at org.junit.Assert.fail(Assert.java:69)
        at org.junit.Assert.assertTrue(Assert.java:32)
        at kafka.producer.ProducerTest.testSendWithDeadBroker(ProducerTest.scala:245)
",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Apr/14 01:16;junrao;KAFKA-1424.patch;https://issues.apache.org/jira/secure/attachment/12642277/KAFKA-1424.patch","25/Apr/14 22:54;junrao;KAFKA-1424.patch;https://issues.apache.org/jira/secure/attachment/12641929/KAFKA-1424.patch","29/Apr/14 01:24;junrao;KAFKA-1424_2014-04-28_10:24:23.patch;https://issues.apache.org/jira/secure/attachment/12642281/KAFKA-1424_2014-04-28_10%3A24%3A23.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,388883,,,Mon Apr 28 22:00:05 UTC 2014,,,,,,,,,,"0|i1uzj3:",389129,,,,,,,,,,,,,,,,,,,,"25/Apr/14 22:54;junrao;Created reviewboard https://reviews.apache.org/r/20713/
 against branch origin/trunk;;;","25/Apr/14 23:23;junrao;Thanks for the review. Committed to trunk.;;;","29/Apr/14 01:15;junrao;The fix is not complete. If there is only a single broker in the cluster, on broker restart, the controller sends the following metadata requests to the broker. The first few requests will have leader as -1. We need to wait until a valid leader is propagated in the metadata cache in the test. 

    [2014-04-25 14:06:26,712] TRACE Controller 0 epoch 2 sending UpdateMetadata request (Leader:-1,ISR:,LeaderEpoch:1,ControllerEpoch:1) with correlationId 3 to broker 0 for partition [test,0] (state.change.logger:36)
    [2014-04-25 14:06:26,714] TRACE Controller 0 epoch 2 sending become-follower LeaderAndIsr request (Leader:-1,ISR:,LeaderEpoch:1,ControllerEpoch:1) with correlationId 4 to broker 0 for partition [test,0] (state.change.logger:36)
    [2014-04-25 14:06:26,714] TRACE Controller 0 epoch 2 sending UpdateMetadata request (Leader:-1,ISR:,LeaderEpoch:1,ControllerEpoch:1) with correlationId 4 to broker 0 for partition [test,0] (state.change.logger:36)
    [2014-04-25 14:06:26,745] TRACE Controller 0 epoch 2 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:2) with correlationId 5 to broker 0 for partition [test,0] (state.change.logger:36)
    [2014-04-25 14:06:26,745] TRACE Controller 0 epoch 2 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:2) with correlationId 5 to broker 0 for partition [test,0] (state.change.logger:36)
;;;","29/Apr/14 01:16;junrao;Created reviewboard https://reviews.apache.org/r/20783/
 against branch origin/trunk;;;","29/Apr/14 01:24;junrao;Updated reviewboard https://reviews.apache.org/r/20783/
 against branch origin/trunk;;;","29/Apr/14 06:00;junrao;Thanks for the reviews. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in LogRecoveryTest,KAFKA-1378,12707502,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,10/Apr/14 01:14,13/Apr/14 04:49,22/Mar/23 15:10,13/Apr/14 04:49,,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Saw the following transient unit test failure.

kafka.server.LogRecoveryTest > testHWCheckpointNoFailuresMultipleLogSegments FAILED
    java.lang.AssertionError: Failed to update highwatermark for follower after 1000 ms
        at org.junit.Assert.fail(Assert.java:69)
        at org.junit.Assert.assertTrue(Assert.java:32)
        at kafka.server.LogRecoveryTest.testHWCheckpointNoFailuresMultipleLogSegments(LogRecoveryTest.scala:182)
",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Apr/14 09:29;junrao;KAFKA-1378.patch;https://issues.apache.org/jira/secure/attachment/12639507/KAFKA-1378.patch","12/Apr/14 09:21;junrao;KAFKA-1378_2014-04-11_18:21:34.patch;https://issues.apache.org/jira/secure/attachment/12639905/KAFKA-1378_2014-04-11_18%3A21%3A34.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,385825,,,Sat Apr 12 20:49:24 UTC 2014,,,,,,,,,,"0|i1ugt3:",386089,,,,,,,,,,,,,,,,,,,,"10/Apr/14 09:29;junrao;Created reviewboard https://reviews.apache.org/r/20189/
 against branch origin/trunk;;;","12/Apr/14 09:21;junrao;Updated reviewboard https://reviews.apache.org/r/20189/
 against branch origin/trunk;;;","13/Apr/14 04:49;junrao;Thanks for the review. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in ZookeeperConsumerConnectorTest,KAFKA-1433,12711641,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,01/May/14 08:13,01/May/14 23:54,22/Mar/23 15:10,01/May/14 23:54,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Saw the following transient unit test failure.

kafka.consumer.ZookeeperConsumerConnectorTest > testBasic FAILED
    kafka.common.FailedToSendMessageException: Failed to send messages after 3 tries.
        at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:90)
        at kafka.producer.Producer.send(Producer.scala:76)
        at kafka.consumer.ZookeeperConsumerConnectorTest.sendMessagesToBrokerPartition(ZookeeperConsumerConnectorTest.scala:353)
        at kafka.consumer.ZookeeperConsumerConnectorTest.testBasic(ZookeeperConsumerConnectorTest.scala:92)
",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/May/14 08:17;junrao;KAFKA-1433.patch;https://issues.apache.org/jira/secure/attachment/12642774/KAFKA-1433.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,389962,,,Thu May 01 15:54:26 UTC 2014,,,,,,,,,,"0|i1v653:",390203,,,,,,,,,,,,,,,,,,,,"01/May/14 08:17;junrao;Created reviewboard https://reviews.apache.org/r/20930/
 against branch origin/trunk;;;","01/May/14 23:54;junrao;Thanks for the review. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in testAutoCreateAfterDeleteTopic,KAFKA-1529,12725639,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,07/Jul/14 02:35,16/Jul/14 05:53,22/Mar/23 15:10,16/Jul/14 05:53,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Saw the following transient failure.

kafka.admin.DeleteTopicTest > testAutoCreateAfterDeleteTopic FAILED
    org.scalatest.junit.JUnitTestFailedError: Topic should have been auto created
        at org.scalatest.junit.AssertionsForJUnit$class.newAssertionFailedException(AssertionsForJUnit.scala:101)
        at org.scalatest.junit.JUnit3Suite.newAssertionFailedException(JUnit3Suite.scala:149)
        at org.scalatest.Assertions$class.fail(Assertions.scala:711)
        at org.scalatest.junit.JUnit3Suite.fail(JUnit3Suite.scala:149)
        at kafka.admin.DeleteTopicTest.testAutoCreateAfterDeleteTopic(DeleteTopicTest.scala:222)
",,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/14 02:40;junrao;KAFKA-1529.patch;https://issues.apache.org/jira/secure/attachment/12654221/KAFKA-1529.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,403797,,,Tue Jul 15 21:53:48 UTC 2014,,,,,,,,,,"0|i1xhw7:",403840,,,,,,,,,,,,,,,,,,,,"07/Jul/14 02:38;junrao;The issue is probably due to not enough retries in the producer. However, testAutoCreateAfterDeleteTopic seems redundant since it should be covered by testRecreateTopicAfterDeletion already.;;;","07/Jul/14 02:40;junrao;Created reviewboard https://reviews.apache.org/r/23294/
 against branch origin/trunk;;;","16/Jul/14 00:31;nehanarkhede;[~junrao], would you like to check this in?;;;","16/Jul/14 05:53;junrao;Thanks for the reviews. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in testRequestHandlingDuringDeleteTopic,KAFKA-1473,12717083,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,junrao,junrao,29/May/14 00:31,05/Jun/14 04:34,22/Mar/23 15:10,05/Jun/14 04:34,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"kafka.admin.DeleteTopicTest > testRequestHandlingDuringDeleteTopic FAILED
    org.scalatest.junit.JUnitTestFailedError: fails with exception
        at org.scalatest.junit.AssertionsForJUnit$class.newAssertionFailedException(AssertionsForJUnit.scala:102)
        at org.scalatest.junit.JUnit3Suite.newAssertionFailedException(JUnit3Suite.scala:149)
        at org.scalatest.Assertions$class.fail(Assertions.scala:731)
        at org.scalatest.junit.JUnit3Suite.fail(JUnit3Suite.scala:149)
        at kafka.admin.DeleteTopicTest.testRequestHandlingDuringDeleteTopic(DeleteTopicTest.scala:118)

        Caused by:
        org.scalatest.junit.JUnitTestFailedError: Test should fail because the topic is being deleted
            at org.scalatest.junit.AssertionsForJUnit$class.newAssertionFailedException(AssertionsForJUnit.scala:101)
            at org.scalatest.junit.JUnit3Suite.newAssertionFailedException(JUnit3Suite.scala:149)
            at org.scalatest.Assertions$class.fail(Assertions.scala:711)
            at org.scalatest.junit.JUnit3Suite.fail(JUnit3Suite.scala:149)
            at kafka.admin.DeleteTopicTest.testRequestHandlingDuringDeleteTopic(DeleteTopicTest.scala:120)
",,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jun/14 05:38;guozhang;KAFKA-1473.patch;https://issues.apache.org/jira/secure/attachment/12648237/KAFKA-1473.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,395291,,,Wed Jun 04 20:34:09 UTC 2014,,,,,,,,,,"0|i1w247:",395422,,,,,,,,,,,,,,,,,,,,"29/May/14 00:33;junrao;I think we probably need to make sure the metadata cache in the broker no longer has the deleted partitions before testing the failure of the producer requests.;;;","04/Jun/14 05:38;guozhang;Created reviewboard https://reviews.apache.org/r/22220/
 against branch origin/trunk;;;","05/Jun/14 04:34;junrao;Thanks for the patch. +1. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in ProducerFailureHandlingTest,KAFKA-1389,12708155,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,14/Apr/14 04:09,25/Apr/14 02:50,22/Mar/23 15:10,24/Apr/14 08:30,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Saw the following transient unit test failure.

kafka.api.ProducerFailureHandlingTest > testTooLargeRecordWithAckZero FAILED
    junit.framework.AssertionFailedError: Partition [topic-1,0] metadata not propagated after timeout
        at junit.framework.Assert.fail(Assert.java:47)
        at junit.framework.Assert.assertTrue(Assert.java:20)
        at kafka.utils.TestUtils$.waitUntilMetadataIsPropagated(TestUtils.scala:532)
        at kafka.utils.TestUtils$$anonfun$createTopic$1.apply(TestUtils.scala:151)
        at kafka.utils.TestUtils$$anonfun$createTopic$1.apply(TestUtils.scala:150)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.immutable.Range.foreach(Range.scala:141)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at kafka.utils.TestUtils$.createTopic(TestUtils.scala:150)
        at kafka.api.ProducerFailureHandlingTest.testTooLargeRecordWithAckZero(ProducerFailureHandlingTest.scala:115)
",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1420,,,,,,,,"14/Apr/14 04:22;junrao;KAFKA-1389.patch;https://issues.apache.org/jira/secure/attachment/12639992/KAFKA-1389.patch","24/Apr/14 01:41;junrao;KAFKA-1389_2014-04-23_10:41:08.patch;https://issues.apache.org/jira/secure/attachment/12641519/KAFKA-1389_2014-04-23_10%3A41%3A08.patch","24/Apr/14 05:36;junrao;KAFKA-1389_2014-04-23_14:36:00.patch;https://issues.apache.org/jira/secure/attachment/12641584/KAFKA-1389_2014-04-23_14%3A36%3A00.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,386478,,,Thu Apr 24 00:30:54 UTC 2014,,,,,,,,,,"0|i1uktr:",386742,,,,,,,,,,,,,,,,,,,,"14/Apr/14 04:22;junrao;Created reviewboard https://reviews.apache.org/r/20290/
 against branch origin/trunk;;;","17/Apr/14 00:07;junrao;We can use this opportunity to standardize the timeout in TestUtils.waitUntilMetadataIsPropagated() to sth like 5 secs.;;;","24/Apr/14 01:41;junrao;Updated reviewboard https://reviews.apache.org/r/20290/
 against branch origin/trunk;;;","24/Apr/14 05:36;junrao;Updated reviewboard https://reviews.apache.org/r/20290/
 against branch origin/trunk;;;","24/Apr/14 08:30;junrao;Thanks for the review. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Shutting down Kafka should be FATAL, not ERROR",KAFKA-102,12518896,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,,bmatheny,bmatheny,16/Aug/11 00:45,16/Aug/11 01:32,22/Mar/23 15:10,16/Aug/11 01:32,,,,,,,,,,,,,,core,,,,0,,,,,,"When Kafka encounters an unrecoverable error it generates an error level log record and then calls Runtime.getRuntime.halt(1). This should really be fatal, not an error.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Aug/11 01:14;bmatheny;kafka-log-2.patch;https://issues.apache.org/jira/secure/attachment/12490450/kafka-log-2.patch","16/Aug/11 00:47;bmatheny;kafka-log.patch;https://issues.apache.org/jira/secure/attachment/12490445/kafka-log.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,64995,,,Mon Aug 15 17:32:04 UTC 2011,,,,,,,,,,"0|i15yxr:",242960,,,,,,,,,,,,,,,,,,,,"16/Aug/11 00:56;jkreps;Thanks for catching this! While we are cleaning up we should fix the error messages. The capitalization is wrong and they reference internal method names, which makes them sysadmin unfriendly.;;;","16/Aug/11 01:14;bmatheny;Updated the patch to at least cleanup the error/fatal logging in those two methods according to the kafka style guide.;;;","16/Aug/11 01:21;jkreps;+1;;;","16/Aug/11 01:32;jkreps;Applied.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Separate RebalanceInProgress from IllegalGeneration Error Code,KAFKA-2557,12888626,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,onurkaraman,becket_qin,becket_qin,19/Sep/15 02:02,23/Sep/15 05:30,22/Mar/23 15:10,23/Sep/15 05:30,,,,,,,0.9.0.0,,,,,,,clients,consumer,,,0,,,,,,"The ILLEGAL_GENERATION error is a bit confusing today. When a consumer receives an ILLEGAL_GENERATION from hearbeat response, it should still use that generation id to commit offset. i.e. the generation id was not really illegal.

The current code was written earlier when we still bump up the generation id when the coordinator enters PrepareRebalance state. Since now the generation id is bumped up after PreareRebalance state ends, we should not overload ILLEGAL_GENERATION to notify a rebalance but create a new error code such as REBALANCE_IN_PROGRESS.",,becket_qin,githubbot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Sep 22 21:29:14 UTC 2015,,,,,,,,,,"0|i2l4qv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Sep/15 07:14;githubbot;GitHub user onurkaraman opened a pull request:

    https://github.com/apache/kafka/pull/222

    KAFKA-2557: separate REBALANCE_IN_PROGRESS and ILLEGAL_GENERATION error codes

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/onurkaraman/kafka KAFKA-2557

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/222.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #222
    
----
commit f92a9f73b5bb8e7b69c682e49bf58ea45bc27154
Author: Onur Karaman <okaraman@linkedin.com>
Date:   2015-09-18T22:35:10Z

    separate REBALANCE_IN_PROGRESS and ILLEGAL_GENERATION error codes

----
;;;","23/Sep/15 05:29;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/222
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fatal error during KafkaServer startup because of Map failed error.,KAFKA-2560,12895076,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,wangbo23,wangbo23,21/Sep/15 17:16,24/Aug/17 23:53,22/Mar/23 15:10,24/Aug/17 23:53,0.8.2.1,,,,,,,,,,,,,log,,,,0,,,,,,"I have 3 kafka nodes,  
create 30 topics ,every topic has 100 pations, and replica factor is 2.

Kafka server start failed,
2015-09-21 10:28:35,668 | INFO  | pool-2-thread-1 | Recovering unflushed segment 0 in log testTopic_14-34. | kafka.utils.Logging$class.info(Logging.scala:68)
2015-09-21 10:28:35,942 | ERROR | main | There was an error in one of the threads during logs loading: java.io.IOException: Map failed | kafka.utils.Logging$class.error(Logging.scala:97)
2015-09-21 10:28:35,943 | INFO  | pool-2-thread-5 | Recovering unflushed segment 0 in log testTopic_17-23. | kafka.utils.Logging$class.info(Logging.scala:68)
2015-09-21 10:28:35,944 | INFO  | pool-2-thread-5 | Completed load of log testTopic_17-23 with log end offset 0 | kafka.utils.Logging$class.info(Logging.scala:68)
2015-09-21 10:28:35,945 | FATAL | main | [Kafka Server 54], Fatal error during KafkaServer startup. Prepare to shutdown | kafka.utils.Logging$class.fatal(Logging.scala:116)
java.io.IOException: Map failed
        at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:907)
        at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:286)
        at kafka.log.OffsetIndex$$anonfun$resize$1.apply(OffsetIndex.scala:276)
        at kafka.utils.Utils$.inLock(Utils.scala:535)
        at kafka.log.OffsetIndex.resize(OffsetIndex.scala:276)
        at kafka.log.Log.loadSegments(Log.scala:179)
        at kafka.log.Log.<init>(Log.scala:67)
        at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$7$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:142)
        at kafka.utils.Utils$$anon$1.run(Utils.scala:54)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.OutOfMemoryError: Map failed
        at sun.nio.ch.FileChannelImpl.map0(Native Method)
        at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:904)
        ... 13 more
2015-09-21 10:28:35,946 | INFO  | pool-2-thread-5 | Recovering unflushed segment 0 in log testTopic_25-77. | kafka.utils.Logging$class.info(Logging.scala:68)
2015-09-21 10:28:35,949 | INFO  | main | [Kafka Server 54], shutting down | kafka.utils.Logging$class.info(Logging.scala:68)

Kafka server host's top infomation below:
top - 17:16:23 up 53 min,  6 users,  load average: 0.42, 0.99, 1.19
Tasks: 215 total,   1 running, 214 sleeping,   0 stopped,   0 zombie
Cpu(s):  4.5%us,  2.4%sy,  0.0%ni, 92.9%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:     40169M total,     6118M used,    34050M free,        9M buffers
Swap:        0M total,        0M used,        0M free,      431M cached

",Linux ,AjItator,omkreddy,wangbo23,zhiwei,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,604800,604800,,0%,604800,604800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Aug 24 15:53:54 UTC 2017,,,,,,,,,,"0|i2lc6f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"16/Oct/15 04:01;AjItator;What ""bitness"" of JVM are you using?

I ran into this with using a 32-bit JVM on Linux.  Switching to a 64-bit JVM remedied this issue.

It seems it's related to the JVM's ability to address large mapped files.  The 32-bit JVM has a limit, which in my experience seems kinda small.  Here's a page online that anecdotally has some suggestions that lead from the cause: http://javarevisited.blogspot.com/2014/11/javaioioexception-map-failed-javalangoutofmemoryerror.html

Basically, it seems this is a JVM limitation.  Not something that Kafka can correct.

The key part of the stack trace is:

{panel:bgColor=#FFFF00}Caused by: java.lang.OutOfMemoryError: Map failed
at sun.nio.ch.FileChannelImpl.map0(Native Method)
{panel};;;","24/Aug/17 23:53;omkreddy;This is due to java.lang.OutOfMemoryError.  Pl reopen if you think the issue still exists
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Document on possible error codes for each response type,KAFKA-1985,12777632,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,guozhang,guozhang,26/Feb/15 02:53,16/May/20 23:13,22/Mar/23 15:10,16/May/20 23:13,,,,,,,,,,,,,,clients,,,,0,,,,,,"When coding the clients logic we tend to forget one or more possible error codes that needs special handling because it is not summarized and documented anywhere. It would better to at least add comments in

{code}
org.apache.kafka.common.requests.XXResponse
{code}

about all possible error codes so that people can check and handle them appropriately.",,guozhang,gwenshap,jkreps,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Feb 25 21:11:32 UTC 2015,,,,,,,,,,"0|i261vb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"26/Feb/15 05:04;gwenshap;Awesome awesome idea.

However, we should also document that this is not a guarantee - new error codes may appear in new releases with or without a protocol bump and clients must be able to handle unknown error codes gracefully.;;;","26/Feb/15 05:11;jkreps;Totally agree. The documentation for this should really go with the protocol description, though. All the other clients have the same issue we do only much worse because they may be less fluent in Java.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Give better error message when trying to run shell scripts without having built/downloaded the jars yet,KAFKA-259,12540545,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,,rossc,rossc,31/Jan/12 20:40,30/May/13 11:27,22/Mar/23 15:10,30/May/13 11:27,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,newbie,,,,,"Hi there, I've cloned from the kafka github repo and tried to run the start server script:

 ./bin/kafka-server-start.sh config/server.properties 

Which results in:

Exception in thread ""main"" java.lang.NoClassDefFoundError: kafka/Kafka
Caused by: java.lang.ClassNotFoundException: kafka.Kafka
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)

It seems that Im missing a build step? what have I forgotten to do?

Thanks in advance and I look forward to using kafka.

regards
rcdh",Mac OSX Lion,ashwanthfernando@gmail.com,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/May/13 06:44;ashwanthfernando@gmail.com;KAFKA-259-v1.patch;https://issues.apache.org/jira/secure/attachment/12583908/KAFKA-259-v1.patch","30/May/13 07:10;ashwanthfernando@gmail.com;KAFKA-259-v2.patch;https://issues.apache.org/jira/secure/attachment/12585326/KAFKA-259-v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,225958,,,Thu May 30 03:27:37 UTC 2013,,,,,,,,,,"0|i15zev:",243037,,,,,,,,,,,,,,,,,,,,"31/Jan/12 22:23;charmalloc;cd kafka
./sbt update
./sbt package

this will make the jars for you to be able to run the server as you are attempting to-do;;;","01/Feb/12 06:47;jkreps;This is covered in the README and the releases come with packaged jars. The only thing I think we could do better is error out if there are no jars in dist, let's change this bug to be about doing that.;;;","01/Feb/12 15:11;rossc;as a noob to java/scala I can honestly say that it may be covered in the readme but there is allot of forest in there and not many trees to be seen ;) its just the basics (and probably only form my point of view) :) thanks for your time and effort guys and keep up the great work! ;;;","02/Feb/12 01:23;jkreps;Yeah, I didn't mean that in a snotty way, just that if we version control the jars the java people get all sulky and complain that we aren't using maven to download them, but if we do that then the non-maven people are unhappy because nothing works.;;;","02/Feb/12 04:05;rossc;@jay, absolutely no problem mate, sorry if I sounded snooty ;) was not meant as such. As far as I can see maven +- sbt are really good tools. But for a rank noob with java its a case of figuring out the nomenclature and processes that is the java world lol ;) ;;;","19/May/13 15:42;ashwanthfernando@gmail.com;Hi, I have a patch for this, I am going through legal to get it approved. Will upload it here asap.;;;","21/May/13 06:45;ashwanthfernando@gmail.com;I have submitted a patch for this. Basically the patch checks whether the java process returns with an exit code of 1 (abnormal), and if it does checks the output of the java process to see whether there are NoClassDefFoundError or ""Could not find or load main class"" messages and then if it does, displays this message:

""Please build the project using sbt. Documentation is available at http://kafka.apache.org/""

Please let me know if you have any concerns with this approach.;;;","30/May/13 00:49;junrao;Thanks for the patch. It doesn't apply to 0.8 though. Could you provide another patch?

git apply ~/Downloads/KAFKA-259-v1.patch 
/Users/jrao/Downloads/KAFKA-259-v1.patch:21: trailing whitespace.
if [ $exitval -eq ""1"" ] ; then 
/Users/jrao/Downloads/KAFKA-259-v1.patch:27: trailing whitespace.
	if [[ -n ""$match"" ]]; then 
error: patch failed: bin/kafka-run-class.sh:81
error: bin/kafka-run-class.sh: patch does not apply
error: patch failed: bin/kafka-run-class.sh:93
error: bin/kafka-run-class.sh: patch does not apply
;;;","30/May/13 07:10;ashwanthfernando@gmail.com;[~junrao] - I executed the simple contributor workflow in this page (https://cwiki.apache.org/confluence/display/KAFKA/Git+Workflow) again. Attached the patch. Can you please try again?;;;","30/May/13 11:27;junrao;Thanks for patch v2. +1. Committed to 0.8.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Error starting KafkaStream caused by sink not being connected to parent source/processor nodes,KAFKA-2872,12915056,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,bbejeck,bbejeck,bbejeck,21/Nov/15 10:51,22/Feb/17 09:07,22/Mar/23 15:10,22/Nov/15 10:46,0.10.0.0,,,,,,0.10.0.0,,,,,,,streams,,,,0,,,,,,"When starting the KafkaStream I get the following Exception:

Exception in thread ""main"" java.util.NoSuchElementException: id: SINK
	at org.apache.kafka.streams.processor.internals.QuickUnion.root(QuickUnion.java:40)
	at org.apache.kafka.streams.processor.TopologyBuilder.makeNodeGroups(TopologyBuilder.java:387)
	at org.apache.kafka.streams.processor.TopologyBuilder.topicGroups(TopologyBuilder.java:339)
	at org.apache.kafka.streams.processor.internals.StreamThread.<init>(StreamThread.java:139)
	at org.apache.kafka.streams.processor.internals.StreamThread.<init>(StreamThread.java:120)
	at org.apache.kafka.streams.KafkaStreaming.<init>(KafkaStreaming.java:110)
	at bbejeck.ProcessorDriver.main(ProcessorDriver.java:35)

The TopologyBuilder is being built like so:
topologyBuilder.addSource(""SOURCE"", new StringDeserializer(), new StringDeserializer(), ""src-topic"")
                .addProcessor(""PROCESS"", new GenericProcessorClient(replaceVowels), ""SOURCE"")
                .addSink(""SINK"", ""dest-topic"", new StringSerializer(), new StringSerializer(), ""PROCESS"");

Looks to me the cause of the error is that in  TopologyBuilder.addSink method the sink  is never connected with it's parent.  ",,bbejeck,githubbot,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Nov 22 02:46:33 UTC 2015,,,,,,,,,,"0|i2oqnr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Nov/15 22:43;githubbot;GitHub user bbejeck opened a pull request:

    https://github.com/apache/kafka/pull/572

    KAFKA-2872 Fixed addSink method connecting sink with parent source(s)…

    Starting a KafkaStream was getting an error due to the fact that the TopologyBuilder.addSink method was not connecting the sink with it parent(s) processor/sources.  Just needed to wire up the sink with it parent(s) in TopologyBuilder.addSink .

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/bbejeck/kafka KAFKA-2872_kafka_stream_sink_not_connected_to_parent

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/572.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #572
    
----
commit 514796557b904ed77441cc61393b7180eb046e86
Author: bbejeck <bbejeck@gmail.com>
Date:   2015-11-21T04:12:18Z

    KAFKA-2872 Fixed addSink method connecting sink with parent source(s) or parent processor(s)

----
;;;","22/Nov/15 06:56;bbejeck;Updated the ToplogyBuilder.addSink method to connect sink with parent processor/source;;;","22/Nov/15 06:58;bbejeck;There appears to be a test failure (kafka.api.SslConsumerTest.testSimpleConsumption) that is unrelated to this patch.  Should I close and re-open the PR as described in the code contribution guidlines?;;;","22/Nov/15 10:30;guozhang;[~bbejeck] Yeah I think that is unrelated, has left a comment in the PR.;;;","22/Nov/15 10:46;guozhang;Issue resolved by pull request 572
[https://github.com/apache/kafka/pull/572];;;","22/Nov/15 10:46;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/572
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Non-failure System Test Log Segment File Checksums mismatched,KAFKA-562,12611078,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,jfung,jfung,10/Oct/12 06:09,23/Nov/12 05:56,22/Mar/23 15:10,23/Nov/12 05:56,,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"To reproduce this issue
1. Download 0.8 branch (reproduced in r1396343)
2. Apply the patch attached
3. Build Kafka under <kafka_home> by running ""./sbt update package""
4. In the directory <kafka_home>/system_test, run ""python -B system_test_runner.py"" and it will run the case ""testcase_0002"" which will reproduce this issue.
5. The log segment files will be located in /tmp",,jfung,jkreps,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/12 06:10;jfung;kafka-562-reproduce-issue.patch;https://issues.apache.org/jira/secure/attachment/12548475/kafka-562-reproduce-issue.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,246538,,,Thu Nov 22 21:56:51 UTC 2012,,,,,,,,,,"0|i07r2n:",43152,,,,,,,,,,,,,,,,,,,,"10/Oct/12 06:24;jfung;In this testcase, the observations are as follows:

1. By comparing the messages produced and consumed, there is no data loss.

2. There are unequal no. of log segment files

[/tmp] find kafka_server_* -name '*.log' -ls
20189793   12 -rw-r--r--   1 jfung    eng         10322 Oct  9 14:44 kafka_server_1_logs/test_1-0/00000000000000000000.log
20189809    4 -rw-r--r--   1 jfung    eng          1537 Oct  9 14:44 kafka_server_1_logs/test_1-0/00000000000000000261.log

20189797   12 -rw-r--r--   1 jfung    eng         10271 Oct  9 14:44 kafka_server_2_logs/test_1-0/00000000000000000000.log
20189807   12 -rw-r--r--   1 jfung    eng         10189 Oct  9 14:44 kafka_server_2_logs/test_1-0/00000000000000000201.log
20189803   12 -rw-r--r--   1 jfung    eng         10293 Oct  9 14:44 kafka_server_2_logs/test_1-0/00000000000000000101.log

20189798   12 -rw-r--r--   1 jfung    eng         10322 Oct  9 14:44 kafka_server_3_logs/test_1-0/00000000000000000000.log
20189819    4 -rw-r--r--   1 jfung    eng          1537 Oct  9 14:44 kafka_server_3_logs/test_1-0/00000000000000000261.log

3. If the corresponding files for broker 1, broker 2, ... are merged together in sequence, their checksum would not match either.

4. Running the tool DumpLogSegments on each individual file as shown below.

Broker 1
========
bin/kafka-run-class.sh kafka.tools.DumpLogSegments kafka_server_1_logs/test_1-0/00000000000000000000.log

Dumping kafka_server_1_logs/test_1-0/00000000000000000000.log

Starting offset: 0

offset: 4 isvalid: true payloadsize: 167 magic: 2 compresscodec: GZIPCompressionCodec crc: 2048048444
offset: 9 isvalid: true payloadsize: 171 magic: 2 compresscodec: GZIPCompressionCodec crc: 594807606
offset: 14 isvalid: true payloadsize: 172 magic: 2 compresscodec: GZIPCompressionCodec crc: 1696552621
offset: 19 isvalid: true payloadsize: 172 magic: 2 compresscodec: GZIPCompressionCodec crc: 3794535639
offset: 24 isvalid: true payloadsize: 172 magic: 2 compresscodec: GZIPCompressionCodec crc: 4167930995
. . .
offset: 245 isvalid: true payloadsize: 174 magic: 2 compresscodec: GZIPCompressionCodec crc: 3337681338
offset: 250 isvalid: true payloadsize: 174 magic: 2 compresscodec: GZIPCompressionCodec crc: 2655434756
offset: 255 isvalid: true payloadsize: 174 magic: 2 compresscodec: GZIPCompressionCodec crc: 5551624
offset: 260 isvalid: true payloadsize: 171 magic: 2 compresscodec: GZIPCompressionCodec crc: 53200305

bin/kafka-run-class.sh kafka.tools.DumpLogSegments kafka_server_1_logs/test_1-0/00000000000000000261.log 

Dumping kafka_server_1_logs/test_1-0/00000000000000000261.log

Starting offset: 261

offset: 265 isvalid: true payloadsize: 173 magic: 2 compresscodec: GZIPCompressionCodec crc: 1224901688
offset: 270 isvalid: true payloadsize: 173 magic: 2 compresscodec: GZIPCompressionCodec crc: 2027726868
offset: 275 isvalid: true payloadsize: 173 magic: 2 compresscodec: GZIPCompressionCodec crc: 559159044
offset: 280 isvalid: true payloadsize: 173 magic: 2 compresscodec: GZIPCompressionCodec crc: 157990978
offset: 285 isvalid: true payloadsize: 173 magic: 2 compresscodec: GZIPCompressionCodec crc: 2995943272
offset: 290 isvalid: true payloadsize: 173 magic: 2 compresscodec: GZIPCompressionCodec crc: 3964443281
offset: 295 isvalid: true payloadsize: 173 magic: 2 compresscodec: GZIPCompressionCodec crc: 140848011
offset: 299 isvalid: true payloadsize: 150 magic: 2 compresscodec: GZIPCompressionCodec crc: 657039729



Broker 2
=========

bin/kafka-run-class.sh kafka.tools.DumpLogSegments kafka_server_2_logs/test_1-0/00000000000000000000.log 

Dumping kafka_server_2_logs/test_1-0/00000000000000000000.log

Starting offset: 0

offset: 0 isvalid: true payloadsize: 77 magic: 2 compresscodec: GZIPCompressionCodec crc: 2305854709
offset: 1 isvalid: true payloadsize: 79 magic: 2 compresscodec: GZIPCompressionCodec crc: 1768470661
offset: 2 isvalid: true payloadsize: 80 magic: 2 compresscodec: GZIPCompressionCodec crc: 657973900
offset: 3 isvalid: true payloadsize: 80 magic: 2 compresscodec: GZIPCompressionCodec crc: 3672345982
offset: 4 isvalid: true payloadsize: 77 magic: 2 compresscodec: GZIPCompressionCodec crc: 3431890374
. . .
offset: 98 isvalid: true payloadsize: 80 magic: 2 compresscodec: GZIPCompressionCodec crc: 2479186795
offset: 99 isvalid: true payloadsize: 79 magic: 2 compresscodec: GZIPCompressionCodec crc: 2127679297
offset: 100 isvalid: true payloadsize: 81 magic: 2 compresscodec: GZIPCompressionCodec crc: 3367058812


/bin/kafka-run-class.sh kafka.tools.DumpLogSegments kafka_server_2_logs/test_1-0/00000000000000000101.log 

Dumping kafka_server_2_logs/test_1-0/00000000000000000101.log

Starting offset: 101

offset: 101 isvalid: true payloadsize: 81 magic: 2 compresscodec: GZIPCompressionCodec crc: 2061836440
offset: 102 isvalid: true payloadsize: 81 magic: 2 compresscodec: GZIPCompressionCodec crc: 1118186556
offset: 103 isvalid: true payloadsize: 81 magic: 2 compresscodec: GZIPCompressionCodec crc: 374092732
offset: 104 isvalid: true payloadsize: 80 magic: 2 compresscodec: GZIPCompressionCodec crc: 1013512453
. . .
offset: 198 isvalid: true payloadsize: 81 magic: 2 compresscodec: GZIPCompressionCodec crc: 1754585683
offset: 199 isvalid: true payloadsize: 80 magic: 2 compresscodec: GZIPCompressionCodec crc: 3604597143
offset: 200 isvalid: true payloadsize: 81 magic: 2 compresscodec: GZIPCompressionCodec crc: 1508187619


bin/kafka-run-class.sh kafka.tools.DumpLogSegments kafka_server_2_logs/test_1-0/00000000000000000201.log

Dumping kafka_server_2_logs/test_1-0/00000000000000000201.log

Starting offset: 201

offset: 201 isvalid: true payloadsize: 81 magic: 2 compresscodec: GZIPCompressionCodec crc: 782997024
offset: 202 isvalid: true payloadsize: 81 magic: 2 compresscodec: GZIPCompressionCodec crc: 1935012961
offset: 203 isvalid: true payloadsize: 80 magic: 2 compresscodec: GZIPCompressionCodec crc: 554951891
offset: 204 isvalid: true payloadsize: 81 magic: 2 compresscodec: GZIPCompressionCodec crc: 14519573
. . .
offset: 297 isvalid: true payloadsize: 80 magic: 2 compresscodec: GZIPCompressionCodec crc: 1204716196
offset: 298 isvalid: true payloadsize: 81 magic: 2 compresscodec: GZIPCompressionCodec crc: 2682999595
offset: 299 isvalid: true payloadsize: 81 magic: 2 compresscodec: GZIPCompressionCodec crc: 4284106376
;;;","11/Oct/12 02:10;jkreps;Yeah, this is definitely a real problem that is leading to not all messages being replicated. With the new logical offsets the followers should have messages with offset 0, 1, 2, 3, 4... as the leader does. But instead the followers have offsets 4,9,14,19,24... I.e. only every fifth message. Not sure of the cause, looking into it.;;;","11/Oct/12 02:46;jkreps;Okay, this is not a bug exactly, I was mistaken. Here is what is happening:

The leader receives one message at a time, gzip'd. The follower fetches chunks of multiple gzip'd messages.

The current logic is that when appending a message set we check if there are any compressed messages. If there are we need to uncompress all messages and re-compress with new offsets assigned. Because the follower is getting chunks of five messages at a time, it is compressing these together. The reason the follower logs are so much smaller is because they are batch compressed.

Not sure what the best thing to do here is. On one hand it is much nicer if the follower has byte-for-byte identical logs. On the other hand batch compression is a good thing.;;;","11/Oct/12 08:00;jkreps;So the proposed fix for this is to special case appends that come from replication and not do any offset assignment, re-compression, or anything else during these. This had already been proposed as a performance improvement. It also ensures that the offset assignment on the leader and followers will match. A patch is attached to KAFKA-557, and I verified that it fixes this system test issue.;;;","23/Nov/12 05:56;jkreps;This was addressed a while back.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
system tests: error copying keytab file,KAFKA-2851,12913815,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,apovzner,granders,granders,18/Nov/15 02:36,03/Dec/15 05:56,22/Mar/23 15:10,03/Dec/15 05:56,,,,,,,,,,,,,,,,,,0,,,,,,"It is best to use unique paths for temporary files on the test driver machine so that multiple test jobs don't conflict. 

If the test driver machine is running multiple ducktape jobs concurrently, as is the case with Confluent nightly test runs, conflicts can occur if the same canonical path is always used.

In this case, security_config.py copies a file to /tmp/keytab on the test driver machine, while other jobs may remove this from the driver machine. Then you can get errors like this:

{code}
====================================================================================================
test_id:    2015-11-17--001.kafkatest.tests.replication_test.ReplicationTest.test_replication_with_broker_failure.security_protocol=SASL_PLAINTEXT.failure_mode=clean_bounce
status:     FAIL
run time:   1 minute 33.395 seconds


    
Traceback (most recent call last):
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.8-py2.7.egg/ducktape/tests/runner.py"", line 101, in run_all_tests
    result.data = self.run_single_test()
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.8-py2.7.egg/ducktape/tests/runner.py"", line 151, in run_single_test
    return self.current_test_context.function(self.current_test)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.8-py2.7.egg/ducktape/mark/_mark.py"", line 331, in wrapper
    return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/tests/replication_test.py"", line 132, in test_replication_with_broker_failure
    self.run_produce_consume_validate(core_test_action=lambda: failures[failure_mode](self))
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/tests/produce_consume_validate.py"", line 66, in run_produce_consume_validate
    core_test_action()
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/tests/replication_test.py"", line 132, in <lambda>
    self.run_produce_consume_validate(core_test_action=lambda: failures[failure_mode](self))
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/tests/replication_test.py"", line 43, in clean_bounce
    test.kafka.restart_node(prev_leader_node, clean_shutdown=True)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/services/kafka/kafka.py"", line 275, in restart_node
    self.start_node(node)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/services/kafka/kafka.py"", line 123, in start_node
    self.security_config.setup_node(node)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/services/security/security_config.py"", line 130, in setup_node
    node.account.scp_to(MiniKdc.LOCAL_KEYTAB_FILE, SecurityConfig.KEYTAB_PATH)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.8-py2.7.egg/ducktape/cluster/remoteaccount.py"", line 174, in scp_to
    return self._ssh_quiet(self.scp_to_command(src, dest, recursive))
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.8-py2.7.egg/ducktape/cluster/remoteaccount.py"", line 219, in _ssh_quiet
    raise e
CalledProcessError: Command 'scp -o 'HostName 52.33.250.202' -o 'Port 22' -o 'UserKnownHostsFile /dev/null' -o 'StrictHostKeyChecking no' -o 'PasswordAuthentication no' -o 'IdentityFile /var/lib/jenkins/muckrake.pem' -o 'IdentitiesOnly yes' -o 'LogLevel FATAL'  /tmp/keytab ubuntu@worker2:/mnt/security/keytab' returned non-zero exit status 1
{code}",,apovzner,githubbot,granders,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Dec 02 19:17:45 UTC 2015,,,,,,,,,,"0|i2oj0v:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"18/Nov/15 12:54;apovzner;Pull request: https://github.com/apache/kafka/pull/610

;;;","03/Dec/15 02:19;githubbot;Github user apovzner closed the pull request at:

    https://github.com/apache/kafka/pull/609
;;;","03/Dec/15 03:17;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/610
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a soft failure in controller may leave a topic partition in an inconsistent state,KAFKA-3083,12928676,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,onurkaraman,junrao,junrao,09/Jan/16 00:01,16/Mar/19 02:27,22/Mar/23 15:10,19/Oct/17 06:28,0.9.0.0,,,,,,1.1.0,,,,,,,core,,,,8,reliability,,,,,"The following sequence can happen.

1. Broker A is the controller and is in the middle of processing a broker change event. As part of this process, let's say it's about to shrink the isr of a partition.

2. Then broker A's session expires and broker B takes over as the new controller. Broker B sends the initial leaderAndIsr request to all brokers.

3. Broker A continues by shrinking the isr of the partition in ZK and sends the new leaderAndIsr request to the broker (say C) that leads the partition. Broker C will reject this leaderAndIsr since the request comes from a controller with an older epoch. Now we could be in a situation that Broker C thinks the isr has all replicas, but the isr stored in ZK is different.
",,aozeritsky,astubbs,cwright,dibbhatt,Federico Giraud,fpj,guozhang,hightea,jalaziz,jeffwidman,josh.cummings,jthakrar,junrao,kzadorozhny-tubemogul,mdaxini,mgharat,prasincs,rehevkor5,shaharmor,sini,stephane.maarek@gmail.com,stevenz3wu,travees,umesh9794@gmail.com,w466397352,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3210,,,,KAFKA-2729,KAFKA-5027,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Mar 15 18:27:32 UTC 2019,,,,,,,,,,"0|i2r1nj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"09/Jan/16 00:06;junrao;[~fpj] suggested that reason that this could happen is the misuse of ZK in Kafka controller.;;;","09/Jan/16 01:43;mgharat;[~fpj] can you shed some light on what you meant by misuse?
[~junrao] if this is actually an issue, I would like to give a shot at it.;;;","13/Jan/16 10:34;junrao;This can potentially lead to more serious issues. For example, after step 3, if the current leader fails, we may not be able to select the new leader since the other replica (which is actually in sync) is not in ISR in Zookeeper (e.g., when unclean leader election is turned off).;;;","13/Jan/16 18:03;fpj;[~mgharat] the fact that A kept going with a session expired makes me think that A ignored the connection loss event and kept doing controller work. What we recommend for mastership with ZooKeeper is that the master stops doing master work upon receiving a connection loss event, and either resumes if it reconnects or drops mastership altogether if the session expires. Talking to [~junrao] about this, it sounds like the controller isn't processing the event that ZkClient is passing up.

Let me give you some more context on session semantics. At 2/3 of the session expiration, if the client hasn't heard from the current server it is connected to, then it will start looking for another server and will notify the application via connection loss events. At that point, the recommendation is that the client (broker in this case) stops doing any master work until it learns more about the session.

I also need to add that I haven't verified this in the code, so it is possible that it is something else causing the problem, but it sounds wrong that a controller with a session expired keeps going.;;;","14/Jan/16 01:32;guozhang;In this case, the truth should be that the other replica is no longer in ISR, so ZK's data is correct while C's cache is not, right?;;;","14/Jan/16 07:47;fpj;It sounds like this comment from [~junrao] is extending the description of the jira. It assumes that the replica that was removed from the ISR in step 1 eventually came back, but it coming back isn't reflected in the state of ZK. However, the replica would be in the cache of the controller B, so would it be elected in this case? Would it be an actual problem if the B is demoted and another controller comes up? ;;;","14/Jan/16 08:11;fpj;One clarification, if broker A shrinks the partition ISR in ZK before step 2 but notifies C after step 2 as in the description, does C eventually learn the ISR stored in ZK? If it doesn't, then the observation about connection loss might not be sufficient to fix it or even matter at all in this case.   ;;;","15/Jan/16 02:34;mgharat;That's a very good point, I will verify if this can happen. 
Moreover, I think the behavior should be :
1) Broker A was the controller.
2) Broker A faces a session expiration, invokes the controllerResignation and clears all its caches and also stops all the ongoing controller work.
3) Broker B becomes the controller and proceeds. 

what do you think?;;;","16/Jan/16 00:20;fpj;Hey [~mgharat], Best practice with ZK is to put the master (controller in this case) on hold upon a connection loss event and wait until the next event, which can be flagging a reconnection or that the session has expired. It should call {{controllerResignation}} upon a session expiration, and resume if it reconnects.

But, we have to be careful because we can't really control the speed of messages, and even if A stops before B takes over in your example, we can't guarantee that some message from A will hit some broker somewhere late. The description of this jira says that C correctly discards an old message, and it should be like that, so this part looks fine this far. It is about the change in ZK happening at the wrong time.;;;","16/Jan/16 02:33;mgharat;For your question regarding  :
If broker A shrinks the partition ISR in ZK before step 2 but notifies C after step 2 as in the description, does C eventually learn the ISR stored in ZK?

C will not know about ISR stored in ZK until next LeaderAndISR from the new controller.;;;","16/Jan/16 06:27;junrao;[~fpj], thanks for the clarification. If broker A shrinks the partition ISR in ZK before step 2, then broker A's ZK session expires, then, broker sends the shrunk ISR to broker C, two things can happen. (1) C has already received requests from the new controller B. In this case, A's request will be rejected. However, since the new controller B is re-elected after broker A shrinks the ISR in ZK and the new controller read the latest ISR from ZK on initialization, B will send the latest ISR to broker C. (2) C hasn't received any request from the new controller B. In this case, A's request will be accepted. The new controller B will later send the same ISR to broker B, but that's fine. So, in either case, we are covered.

The problem in the description is really caused by broker A changing ZK after its session expires. So, it seems the fix would be the following. If the controller (say A) hits a ZK ConnectionLoss event while reading/writing to ZK, it will pause the operation. Two possibilities can follow. In the case when the controller A's ZK session expires, it will just ignore all the outstanding ZK events. This guarantees that controller A can't touch ZK any more after a new controller is elected (which has to happen after controller A's SessionExpiration event). So, the new controller is guaranteed to read the latest ZK data, act on this, and send the latest info to the broker. This would avoid the issue in the description. 

In the second case, controller A will get a SyncConnected event. In this case, does controller A just resume from where it's left off? Or does it ignore all outstanding events and re-read all subscribed ZK paths (since there could be missing events between the connection loss event and the SyncConnected event)?

Finally, ZkClient actually hides the ZK ConnectionLoss event and only informs the application when the ZK session expires. To pursue this, we will have to access ZK directly.;;;","16/Jan/16 08:39;mgharat;[~junrao], [~fpj] that makes it more clear. I was just thinking if we can modify the controller code to always check if it is the controller before it makes such changes to zookeeper. 
Again there is a race condition, wherein Broker A's session timesOut at time T. Broker B becomes the controller at T+2. Broker A can still proceed with the changes to ZK between T and T+2.

I had some questions on the zookeeper session expiry:

1) If suppose a broker establishes a connection with zookeeper and  has a ZookeeperSessionTimeout set to 10 min.The broker goes down/or is stuck and comes back up and connects to zookeeper after 5 min, will it connect on the same session?

2) The session Expiry is only invoked on SessionTimeout and nothing else. Am I right?

;;;","16/Jan/16 08:44;mgharat;on a side note, I noticed a new issue in controlled shutdown that is kind of similar. I will open a new Jira for that. ;;;","16/Jan/16 08:50;junrao;[~mgharat], in general, the approach of checking if still controller and then writing to ZK won't work since the controller can change immediately after the check.;;;","16/Jan/16 09:32;mgharat;That's right. 
I am thinking if there is a way to check the ConnectionLoss using handleStateChanged() api on the SessionExpirationListener which can be use to drop all the current zk task that controller A was about to do.;;;","16/Jan/16 09:45;junrao;That api doesn't exist in SessionExpirationListener. Even if it exists, it has the same problem--the session can expire after the check. So, you pretty much have to rely on the raw ZK client api that handles ConnectionLossException while reading/writing to ZK.;;;","16/Jan/16 09:57;mgharat;Hi Jun,

I was talking about the SessionExpirationListener that implements the IZkStateListener in KafkaController that has the handleStateChanged() api. I was thinking if we can handle the statechange to Disconnected in that callback, to do the cleanup.;;;","16/Jan/16 14:00;junrao;We will have a take closer look at the ZKClient implementation, but handleStateChanged() doesn't seem enough. When receiving a state change event, ZKClient just puts the event into a queue. A separate thread takes each item off the queue and then calls handleStateChanged(). So, between the time that a connection is lost and the time handleStateChanged() is called, a write may already be done in ZK on a newly created session.;;;","19/Jan/16 01:55;fpj;[~junrao]
bq. does controller A just resume from where it's left off? Or does it ignore all outstanding events and re-read all subscribed ZK paths (since there could be missing events between the connection loss event and the SyncConnected event)?

I don't see a reason for ignoring outstanding events and re-reading zk state. If the session hasn't expired, then the broker is still the controller and I'd say it is safe to assume the no other controller work happened in parallel.

bq. ZkClient actually hides the ZK ConnectionLoss event and only informs the application when the ZK session expires. To pursue this, we will have to access ZK directly.

I think further down you noted that ZkClient actually exposes the connection loss event, but does put a thread in the middle.;;;","19/Jan/16 02:01;fpj;[~junrao]

bq. Even if it exists, it has the same problem--the session can expire after the check. So, you pretty much have to rely on the raw ZK client api that handles ConnectionLossException while reading/writing to ZK.

Perhaps you meant to say this, but you can also learn about a connection loss via the watcher you pass when creating a zookeeper object.

;;;","19/Jan/16 02:12;fpj;[~mgharat]

bq. I was just thinking if we can modify the controller code to always check if it is the controller before it makes such changes to zookeeper.

In principle, there is the race that [~junrao] mentioned, but I was thinking that one possibility would be use a multi-op that combines the update to the ISR and a znode check. The znode check verifies that the version of the controller leadership znode is still the same and if it passes, then the ISR data is updated. Using the scenario in the description to illustrate, when broker A tries to update the ISR state in ZK in step 3, the operation fails because the version of the controller leadership znode has changed.

The solution of handling the connection loss event is typical, but we could consider adding a multi-op to be extra safe against these spurious writes. ;;;","19/Jan/16 04:04;fpj;Another thing to mention is that if ZkClient didn't create a new session transparently, then the update of broker A in step 3 would fail because the session has expired and the ZK ensemble wouldn't take a request from an expired session.;;;","20/Jan/16 04:55;mgharat;Hi [~fpj],

Correct me if I am wrong :
1) We need to use a multi-op that combines the update to the ISR and a znode check. The znode check verifies that the version of the controller leadership znode is still the same and if it passes, then the ISR data is updated. 
2) The race condition that [~junrao] mentioned still exist above in 1).
3) To overcome this we somehow need to detect that the broker A who was the controller got a session expiration and should drop all the zk work its doing immediately. 
4) To do step 3), as [~junrao] suggested we have to detect the connection loss event. Now 2 things might happen :
     i) Broker A has connection loss and connects immediately in which case it gets a SyncConnected event. Now the session MIGHT NOT have expired since the connection happened immediately. Broker A is expected to continue since it is still the controller and the session has not expired.
    ii) Broker A has connection loss and connects back in which case it gets a SyncConnected event. Now the session MIGHT have expired. Broker A is expected to stop all the zk operations.
The only difference between i) and ii) is SessionExpiration check.













;;;","20/Jan/16 09:02;mgharat; However, the replica would be in the cache of the controller B, so would it be elected in this case? Would it be an actual problem if the B is demoted and another controller comes up? 

---> That seems right, it should be in the cache of controller B and should be elected as leader. If however B goes down before this and a new controller is elected, it will read the data from zookeeper and might not be able to elect a new leader if uncleanLeaderElection is turned OFF.;;;","21/Jan/16 08:57;junrao;[~mgharat], in step 4) ii), if the session expires, you won't get SyncConnected event. Also, we probably should consider fixing this jira and KAFKA-3038 in a unified way.

[~fpj], do you think that you can outline the approach of addressing both issues together by potentially moving to the raw ZK async api?;;;","21/Jan/16 22:42;fpj;bq. 1) We need to use a multi-op that combines the update to the ISR and a znode check. The znode check verifies that the version of the controller leadership znode is still the same and if it passes, then the ISR data is updated.

I was really just thinking out loud, the multiop is just a hack to get around the fact that controller broker doesn't know if the underlying session has been recreated or not. The comment about using multiop was simply pointing that you can check and update atomically with this multiop recipe. If we do this the right way, then we don't need to use a multiop call.

bq. 2) The race condition that Jun Rao mentioned still exist above in 1).

It still exists but the multiop would fail to perform the update on ZK if you're checking a version.

bq. 4) To do step 3), as Jun Rao suggested we have to detect the connection loss event.

There are two parts. Detecting connection loss is one of them. If the controller isn't sure about its session when it receives connection loss, then it should stop. The second part is not to create a new session if the previous one expired. If the session of A has expired, which must happen by step 2) otherwise B can't be elected, then A isn't able to get requests completed on the expired session. Once B is elected, the session of A must have expired and no update coming from A will be executed. Of course, we want to bring broker A back up and to do it, we need to start a new session. However, before starting a new session, we need to make sure to stop any controller work in A.

bq. i) Broker A has connection loss and connects immediately in which case it gets a SyncConnected event. Now the session MIGHT NOT have expired since the connection happened immediately. Broker A is expected to continue since it is still the controller and the session has not expired. ii) Broker A has connection loss and connects back in which case it gets a SyncConnected event. Now the session MIGHT have expired. Broker A is expected to stop all the zk operations.

The broker will only get SyncConnected if it connects and it is able to validate the session. If the session is invalid, then it gets an Expired notification. Note that if we are using SASL to authenticate, then we could be also getting an authenticated event.;;;","21/Jan/16 23:22;fpj;Sure, we need to transform all operations to look like what we currently have in ZKCheckedEphemeral. That particular class is a bit special because it performs checks and such, but essentially we need to change the current calls in ZkUtils to use asynchronous calls using the ZK handle directly and have a callback class that pairs up with the call.

Related to this present issue, we will also need to implement session management, but this time it can't try to be transparent like ZkClient does. It is good to have a central point to get the current zk handle from, but we need to give the broker the ability to signal when to create a new session. As part of this signaling, we will need to implement some kind of listener to propagate events. Another option is to let the broker implement directly a Watcher to process event notifications.

One simple way to start is to replace gradually the calls in ZkUtils with asynchronous calls, still using the handle ZkUtils provide. The calls would block to maintain the current behavior outside ZkUtils. Once that's done, we can make the calls non-blocking and do the necessary changes across broker/controller. Finally, we can replace the session management with our own last.

If you guys want to do this, then we should probably create an umbrella jira.   ;;;","24/Aug/16 06:33;junrao;Someone encountered another issue related to this. After a broker's ZK session expires and it resigns as the controller, there is the following error in the controller log.

2016-08-13 17:34:23,721 ERROR org.I0Itec.zkclient.ZkEventThread:77 [ZkClient-EventThread-87- [run] Error handling event ZkEvent[Children of /isr_change_notification changed sent to kafka.controller.IsrChangeNotificationListener@3c60b0b1] 
java.lang.IllegalStateException: java.lang.NullPointerException 
at kafka.controller.ControllerBrokerRequestBatch.sendRequestsToBrokers(ControllerChannelManager.scala:435) 
at kafka.controller.KafkaController.sendUpdateMetadataRequest(KafkaController.scala:1029) 
at kafka.controller.IsrChangeNotificationListener.kafka$controller$IsrChangeNotificationListener$$processUpdateNotifications(KafkaController.scala:1372) 
at kafka.controller.IsrChangeNotificationListener$$anonfun$handleChildChange$1.apply$mcV$sp(KafkaController.scala:1359) 
at kafka.controller.IsrChangeNotificationListener$$anonfun$handleChildChange$1.apply(KafkaController.scala:1352) 
at kafka.controller.IsrChangeNotificationListener$$anonfun$handleChildChange$1.apply(KafkaController.scala:1352) 
at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262) 
at kafka.controller.IsrChangeNotificationListener.handleChildChange(KafkaController.scala:1352) 
at org.I0Itec.zkclient.ZkClient$10.run(ZkClient.java:842) 
at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71) 
Caused by: java.lang.NullPointerException 
at kafka.controller.KafkaController.sendRequest(KafkaController.scala:699) 
at kafka.controller.ControllerBrokerRequestBatch$$anonfun$sendRequestsToBrokers$2.apply(ControllerChannelManager.scala:404) 
at kafka.controller.ControllerBrokerRequestBatch$$anonfun$sendRequestsToBrokers$2.apply(ControllerChannelManager.scala:370) 
at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99) 
at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99) 
at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230) 
at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) 
at scala.collection.mutable.HashMap.foreach(HashMap.scala:99) 
at kafka.controller.ControllerBrokerRequestBatch.sendRequestsToBrokers(ControllerChannelManager.scala:370) 
... 9 more

The broker fails to send an UpdateMetadataRequest in react to an ISR change event since controllerChannelManager is null after the broker resigns as the controller. When this happen, the broker calls the logic to force a controller to resign. This could accidentally delete the controller path created by another broker.

2016-08-13 17:34:23,639 ERROR kafka.utils.Logging$class:97 [ZkClient-EventThread-87-] [error] [Controller 43]: Forcing the controller to resign

;;;","26/Aug/16 01:29;mgharat;[~fpj] do we have an umbrella jira where this issue is been tracked with the changes required to be made that are mentioned in this patch?;;;","29/Mar/17 09:41;stephane.maarek@gmail.com;Just hit this issue in prod with Kafka 0.10.2.0, and the only solution was to reboot the broker that got put in an inconsistent state;;;","19/Apr/17 16:55;dibbhatt;Hi [~junrao] We also had this issue in Kafka 0.9.x. Any idea when this can be fixed. ;;;","07/Sep/17 08:34;guozhang;[~dibbhatt] KAFKA-5027 is being actively worked on and expected to be released in the next release (mid Oct.), which would resolve this issue.;;;","19/Oct/17 06:28;junrao;This is now fixed in KAFKA-5642.;;;","16/Mar/19 02:27;rehevkor5;Is there a way to make this less likely to occur in versions before the fix? Would using a larger value for zookeeper.session.timeout.ms make any difference? I assume that ""broker A's session expires"" refers to the broker's Zookeeper session?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DumpLogSegments tool should return error on non-existing files,KAFKA-1009,12663687,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,guozhang,junrao,junrao,15/Aug/13 00:41,20/Aug/13 00:46,22/Mar/23 15:10,20/Aug/13 00:46,0.8.0,,,,,,0.8.1,,,,,,,log,,,,0,,,,,,"If we run the tool on an non-existing file, we get the following

bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files 00.log
Dumping 00.log
Starting offset: 0

The tool should return an error message instead.",,guozhang,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Aug/13 08:29;guozhang;KAFKA-1009.v1.patch;https://issues.apache.org/jira/secure/attachment/12598114/KAFKA-1009.v1.patch","20/Aug/13 00:04;guozhang;KAFKA-1009.v2.patch;https://issues.apache.org/jira/secure/attachment/12598777/KAFKA-1009.v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,343688,,,Mon Aug 19 16:46:13 UTC 2013,,,,,,,,,,"0|i1n9qv:",343992,,,,,,,,,,,,,,,,,,,,"15/Aug/13 08:11;guozhang;This is due to the fact that in dumpLog, it create a FileMessageSet(file) for the filename, which use ""rw"" in creating the RandomAccessFile. When under ""rw"" mode if the file does not exist it will create one.

Proposed fix: instead of call FileMessageSet(file), call a new function FileMessageSet(file, mutable), and set mutable to false to specify it is read-only.

;;;","18/Aug/13 23:56;nehanarkhede;Thanks for the patch, Guozhang. Two comments -

1. We should default mutable=true in FileMessageSet
2. I think we should take this patch on trunk. Could you provide another patch for trunk since this one fails?;;;","20/Aug/13 00:04;guozhang;Thanks for the comments Neha.

1. We do set default mutable to true, what I said is that we add another function that do accept the mutable parameter and pass it instead of always using the default.

2. Rebased on trunk for v2.;;;","20/Aug/13 00:44;nehanarkhede;1. I see what you are saying. 

The patch looks good. Thanks for fixing the bug. +1;;;","20/Aug/13 00:46;nehanarkhede;Committed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Connection reset by peer"" IOExceptions should not be logged as ERROR",KAFKA-2251,12835513,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,jbrosenberg@gmail.com,jbrosenberg@gmail.com,05/Jun/15 04:04,16/Jun/15 01:42,22/Mar/23 15:10,15/Jun/15 15:08,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"It's normal to see lots of these exceptions logged in the broker logs:

{code}
2015-06-04 16:49:30,146 ERROR [kafka-network-thread-27330-1] network.Processor - Closing socket for /1.2.3.4 because of error
java.io.IOException: Connection reset by peer
        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
        at sun.nio.ch.IOUtil.read(IOUtil.java:197)
        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
        at kafka.utils.Utils$.read(Utils.scala:380)
        at kafka.network.BoundedByteBufferReceive.readFrom(BoundedByteBufferReceive.scala:54)
        at kafka.network.Processor.read(SocketServer.scala:444)
        at kafka.network.Processor.run(SocketServer.scala:340)
        at java.lang.Thread.run(Thread.java:745)
{code}

These are routine exceptions, that occur regularly in response to clients going away, etc.  The server should not log these as 'ERROR' level, instead they should be probably just 'WARN', and should not log the full stack trace (maybe just the exception message).

The problem is that if we want to alert on actual errors, innocuous errors such as this make it difficult to alert properly, etc.

We are using 0.8.2.1, fwiw",,gwenshap,jbrosenberg@gmail.com,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jun 15 17:42:53 UTC 2015,,,,,,,,,,"0|i2fni7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"15/Jun/15 15:08;omkreddy;This got fixed in KAFKA-1928. Log level changed to WARN.;;;","16/Jun/15 01:42;gwenshap;Haha, I accidentally fixed Kafka's most annoying issue :);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Print metadata response errors,KAFKA-1884,12768617,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,omkreddy,omkreddy,omkreddy,20/Jan/15 15:21,08/May/15 06:49,22/Mar/23 15:10,08/May/15 06:49,0.8.2.0,,,,,,0.9.0.0,,,,,,,producer ,,,,0,,,,,,"Print metadata response errors.

producer logs:

DEBUG [2015-01-20 12:46:13,406] NetworkClient: maybeUpdateMetadata(): Trying to send metadata request to node -1
DEBUG [2015-01-20 12:46:13,406] NetworkClient: maybeUpdateMetadata(): Sending metadata request ClientRequest(expectResponse=true, payload=null, request=RequestSend(header={api_key=3,api_version=0,correlation_id=50845,client_id=my-producer}, body={topics=[TOPIC=]})) to node -1
TRACE [2015-01-20 12:46:13,416] NetworkClient: handleMetadataResponse(): Ignoring empty metadata response with correlation id 50845.
DEBUG [2015-01-20 12:46:13,417] NetworkClient: maybeUpdateMetadata(): Trying to send metadata request to node -1
DEBUG [2015-01-20 12:46:13,417] NetworkClient: maybeUpdateMetadata(): Sending metadata request ClientRequest(expectResponse=true, payload=null, request=RequestSend(header={api_key=3,api_version=0,correlation_id=50846,client_id=my-producer}, body={topics=[TOPIC=]})) to node -1
TRACE [2015-01-20 12:46:13,417] NetworkClient: handleMetadataResponse(): Ignoring empty metadata response with correlation id 50846.
DEBUG [2015-01-20 12:46:13,417] NetworkClient: maybeUpdateMetadata(): Trying to send metadata request to node -1
DEBUG [2015-01-20 12:46:13,418] NetworkClient: maybeUpdateMetadata(): Sending metadata request ClientRequest(expectResponse=true, payload=null, request=RequestSend(header={api_key=3,api_version=0,correlation_id=50847,client_id=my-producer}, body={topics=[TOPIC=]})) to node -1
TRACE [2015-01-20 12:46:13,418] NetworkClient: handleMetadataResponse(): Ignoring empty metadata response with correlation id 50847.

Broker logs:

[2015-01-20 12:46:14,074] ERROR [KafkaApi-0] error when handling request Name: TopicMetadataRequest; Version: 0; CorrelationId: 51020; ClientId: my-producer; Topics: TOPIC= (kafka.server.KafkaApis)
kafka.common.InvalidTopicException: topic name TOPIC= is illegal, contains a character other than ASCII alphanumerics, '.', '_' and '-'
	at kafka.common.Topic$.validate(Topic.scala:42)
	at kafka.admin.AdminUtils$.createOrUpdateTopicPartitionAssignmentPathInZK(AdminUtils.scala:186)
	at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:177)
	at kafka.server.KafkaApis$$anonfun$5.apply(KafkaApis.scala:367)
	at kafka.server.KafkaApis$$anonfun$5.apply(KafkaApis.scala:350)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractSet.scala$collection$SetLike$$super$map(Set.scala:47)
	at scala.collection.SetLike$class.map(SetLike.scala:93)
	at scala.collection.AbstractSet.map(Set.scala:47)
	at kafka.server.KafkaApis.getTopicMetadata(KafkaApis.scala:350)
	at kafka.server.KafkaApis.handleTopicMetadataRequest(KafkaApis.scala:389)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:57)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
	at java.lang.Thread.run(Thread.java:722)
",,guozhang,nehanarkhede,omkreddy,pradeepg26,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Mar/15 23:57;omkreddy;KAFKA-1884.patch;https://issues.apache.org/jira/secure/attachment/12701885/KAFKA-1884.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu May 07 22:49:29 UTC 2015,,,,,,,,,,"0|i24jwf:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"06/Feb/15 11:22;pradeepg26;I'd like to work on this. Please assign to me.

I've been able to reproduce the issue. I also noticed another oddity about this though.

1. The server side error above is being repeated 100's of times a second (each repeat increments the CorrelationId). This seems to indicate some type of retry logic.
2. If I kill the server, kill the client and start the server. The error continues to repeat. This seems to indicate that this request may be persisted somewhere.

I have a good grasp of where to start looking for the problem, though I have no idea why the above two are occurring.;;;","06/Feb/15 14:00;pradeepg26;What makes the behavior in #2 earlier even more odd is, I stopped the server, deleted the znodes, deleted the kafka log dir and restarted the server and the same behavior is seen.

O.o;;;","07/Feb/15 03:09;guozhang;I think the behavior that producer's sender thread will keep retrying refreshing metadata for invalid topic names is expected, and it does not actually ""block"" the producer as it is a background thread; but the other issue is valid: it should back off between refreshing instead of bombarding the server. This issue is being addressed in KAFKA-1919.;;;","07/Feb/15 08:03;pradeepg26;[~guozhang] That's what I figured at first. But the odd behavior is that the exception storm is happening on server even after the producer has been shut down (and the broker restarted). Not sure why that would be the case.;;;","07/Feb/15 08:22;guozhang;That is a bit weird, the metadata requests should not persist... did you make a thread dump and check if the underlying sender thread is already gone after producer shut down? I guess it is because the background thread is not shut down when you hard kill the producer.;;;","07/Feb/15 12:47;pradeepg26;I guess that makes sense... I'll confirm.;;;","08/Feb/15 17:55;omkreddy;[~guozhang] [~jkreps] 
KAFKA-1919 solves the retry problem.  Currently we will get continuous empty metadata response for invalid topics.  I was thinking,  Can clients get the InvalidTopicException/Error code?  or Can we add topic validation at client side itself? How non-java clients will handle it?;;;","09/Feb/15 08:14;guozhang;[~omkreddy] I think this is a valid point, we should handle this exception better at the server side to return corresponding error code.;;;","11/Feb/15 01:45;omkreddy;looks like we are already returning error code from server. It just that we are not logging any error info in new client logs. Will add some logs.;;;","02/Mar/15 23:57;omkreddy;Created reviewboard https://reviews.apache.org/r/31627/diff/
 against branch origin/trunk;;;","09/Mar/15 05:11;nehanarkhede;[~guozhang] It seems you were helping out earlier. ;;;","18/Apr/15 13:22;omkreddy;[~guozhang] can you review this trivial patch?;;;","08/May/15 06:49;guozhang;[~omkreddy] Sorry for the late reply, committed to trunk with some minor changes.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KafkaOffsetBackingStoreTest.testGetSet transient test failure,KAFKA-2628,12903838,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,ewencp,ewencp,10/Oct/15 01:32,20/Oct/15 16:01,22/Mar/23 15:10,20/Oct/15 16:01,,,,,,,0.9.0.0,,,,,,,KafkaConnect,,,,0,,,,,,"{quote}
org.apache.kafka.copycat.storage.KafkaOffsetBackingStoreTest > testGetSet FAILED
    java.lang.AssertionError
        at org.junit.Assert.fail(Assert.java:86)
        at org.junit.Assert.assertTrue(Assert.java:41)
        at org.junit.Assert.assertTrue(Assert.java:52)
        at org.apache.kafka.copycat.storage.KafkaOffsetBackingStoreTest.testGetSet(KafkaOffsetBackingStoreTest.java:308)
{quote}

Haven't noticed this on Apache's Jenkins yet, but have seen it on Confluent's. May be due to limited resources under some conditions, although the timeout is already quite generous at 10s.",,ewencp,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Oct 20 08:01:40 UTC 2015,,,,,,,,,,"0|i2mtu7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"20/Oct/15 16:01;ewencp;Closing because this test has completely changed as of KAFKA-2372 because much of this code has been refactored into KafkaBasedLog and KafkaOffsetBackingStoreTest can be implemented more simply with plain mocks. Further, it appears to be a duplicate of KAFKA-2667 which now has a patch and I haven't seen it since KAFKA-2372.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Scala match error in javaapi.Implicits,KAFKA-940,12652533,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jjkoshy,jjkoshy,jjkoshy,13/Jun/13 08:19,13/Jun/13 11:43,22/Mar/23 15:10,13/Jun/13 11:43,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"This would affect javaapi users who (correctly) test for null on API calls (e.g., if (partitionMetadata.leader == null))

Right now, we actually get a match error:
scala.MatchError: null
	at kafka.javaapi.Implicits$.optionToJavaRef(Implicits.scala:38)
	at kafka.javaapi.Implicits$.optionToJavaRef(Implicits.scala:40)
	at kafka.javaapi.PartitionMetadata.leader(TopicMetadata.scala:51)
<truncated>
",,jjkoshy,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jun/13 08:21;jjkoshy;KAFKA-940-v1.patch;https://issues.apache.org/jira/secure/attachment/12587531/KAFKA-940-v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,332857,,,Thu Jun 13 03:43:55 UTC 2013,,,,,,,,,,"0|i1lf5j:",333185,,,,,,,,,,,,,,,,,,,,"13/Jun/13 08:21;jjkoshy;Simple fix.;;;","13/Jun/13 11:43;junrao;Thanks for the patch. +1. Committed to 0.8.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix intermittent test failures and remove unnecessary sleeps,KAFKA-384,12596466,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,jjkoshy,jjkoshy,30/Jun/12 06:29,01/Aug/12 07:28,22/Mar/23 15:10,01/Aug/12 07:28,0.8.0,,,,,,,,,,,,,,,,,0,,,,,,"Seeing intermittent failures in 0.8 unit tests. Also, many sleeps can be removed (with producer acks in place) and I think MockTime isn't used in some places where it should.
",,jjkoshy,jkreps,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jul/12 03:24;nehanarkhede;kafka-384-v1.patch;https://issues.apache.org/jira/secure/attachment/12538287/kafka-384-v1.patch","31/Jul/12 04:39;nehanarkhede;kafka-384-v2.patch;https://issues.apache.org/jira/secure/attachment/12538408/kafka-384-v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,248177,,,Tue Jul 31 23:28:30 UTC 2012,,,,,,,,,,"0|i09m1b:",54003,,,,,,,,,,,,,,,,,,,,"30/Jul/12 03:24;nehanarkhede;This patch removes sleep statements from the unit tests. Changes include -

1. All sleep statements except those related to a scheduler are removed. So 2-3 sleep statements that exercise the producer side queue expiration logic have not been removed
2. For the Log tests, passed in a Time parameter to the Log. Kafka server already takes in an optional Time parameter that defaults to SystemTime. However, it wasn't passed around in LogManager. Fixed it so KafkaServer passes its Time
 variable to LogManager which passes it to Log.
This is useful in removing all sleep statements from unit tests for the log manager and logs;;;","31/Jul/12 04:12;junrao;Thanks for the patch. It looks good. Just 1 comment:

1. AsyncProducerTest.testQueueTimeExpired(): This is an existing issue, but probably can be fixed in this patch too. It seems that we should do     producerSendThread.shutdown after EasyMock.verify(mockHandler). Shutdown always sends all remaining messages in the buffer. If we call shutdown before verify, it's not clear if the send was triggered by timeout or shutdown.;;;","31/Jul/12 04:39;nehanarkhede;Thanks for the review, Jun. That is a good point. I fixed that and also removed the reference to mockTime since that is not useful here.;;;","31/Jul/12 04:44;jjkoshy;+1 for v2.;;;","31/Jul/12 05:42;jkreps;You are my hero...;;;","31/Jul/12 05:57;junrao;+1 on v2 too.;;;","01/Aug/12 02:19;nehanarkhede;KAFKA-343 checkin broke some unit tests and cause others to hang. I think I might have to hold off on the checkin until that is either fixed or reverted. ;;;","01/Aug/12 07:28;nehanarkhede;Thanks all for the review! Committed the v2 patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Error when trying to shut down auto balancing scheduler of controller,KAFKA-3107,12930190,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,fpj,fpj,15/Jan/16 00:58,12/May/17 12:20,22/Mar/23 15:10,12/May/17 12:20,0.8.2.1,,,,,,,,,,,,,,,,,1,,,,,,"We observed the following exception when a controller was shutting down:

{noformat}
[run] Error handling event ZkEvent[New session event sent to kafka.controller.KafkaController$SessionExpirationListener@3278c211]
java.lang.IllegalStateException: Kafka scheduler has not been started
    at kafka.utils.KafkaScheduler.ensureStarted(KafkaScheduler.scala:114)
    at kafka.utils.KafkaScheduler.shutdown(KafkaScheduler.scala:86)
    at kafka.controller.KafkaController.onControllerResignation(KafkaController.scala:350)
    at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1108)
    at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1107)
    at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1107)
    at kafka.utils.Utils$.inLock(Utils.scala:535)
    at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1107)
    at org.I0Itec.zkclient.ZkClient$4.run(ZkClient.java:472)
    at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
{noformat}

The scheduler should have been started.",,fpj,onurkaraman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri May 12 04:20:07 UTC 2017,,,,,,,,,,"0|i2razb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"12/May/17 12:20;onurkaraman;This problem should no longer exist after KAFKA-5028.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Merged log segment checksums mismatched in Leader failure System Test case,KAFKA-572,12611665,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,jfung,jfung,13/Oct/12 13:12,14/Oct/12 06:22,22/Mar/23 15:10,14/Oct/12 06:22,,,,,,,,,,,,,,,,,,0,,,,,,,,jfung,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Oct/12 13:26;jfung;kafka-572-reproduce-issue.patch;https://issues.apache.org/jira/secure/attachment/12549004/kafka-572-reproduce-issue.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,248201,,,Sat Oct 13 22:22:38 UTC 2012,,,,,,,,,,"0|i09phz:",54564,,,,,,,,,,,,,,,,,,,,"13/Oct/12 13:32;jfung;* Test Description:

1. Start a 3-broker cluster as source
2. Send messages to source cluster
3. Find leader and terminate it (kill -15)
4. Start the broker shortly
5. Start a consumer to consume data
6. Compare the MessageID in the data between producer log and consumer log.

* To reproduce this issue, please do the followings:

1. Download the latest 0.8 branch
2. Apply the patch attached to this JIRA
3. Build kafka by running ""./sbt update package""
4. Execute the test in directory ""system_test"" : ""python -B system_test_runner.py""

* Output from the test - No data loss but merged log segment checksums mismatched

2012-10-12 22:27:35,760 - INFO - ======================================================
2012-10-12 22:27:35,760 - INFO - validating data matched
2012-10-12 22:27:35,760 - INFO - ======================================================
2012-10-12 22:27:35,771 - INFO - no. of unique messages on topic [test_1] sent from publisher  : 500 (kafka_system_test_utils)
2012-10-12 22:27:35,771 - INFO - no. of unique messages on topic [test_1] received by consumer : 500 (kafka_system_test_utils)
2012-10-12 22:27:35,771 - INFO - ================================================
2012-10-12 22:27:35,771 - INFO - validating merged broker log segment checksums
2012-10-12 22:27:35,771 - INFO - ================================================
{u'kafka_server_1_logs:test_1-0': 'd70c8d37634b0b08cd407eb042e77ef8',
 u'kafka_server_2_logs:test_1-0': 'd70c8d37634b0b08cd407eb042e77ef8',
 u'kafka_server_3_logs:test_1-0': '924d30d5f0d2a8ba9ef45f7cba88e192'}
2012-10-12 22:27:35,774 - ERROR - merged log segment checksum in test_1-0 mismatched (kafka_system_test_utils)

;;;","13/Oct/12 13:37;jfung;* Data Log Segment files sizes:

system_test/replication_testsuite/testcase_0102/logs $ find broker-* -name '00*.log' -ls

9702225   12 -rw-r--r--   1 jfung    eng         10279 Oct 12 22:27 broker-1/kafka_server_1_logs/test_1-0/00000000000000000301.log
9702226   12 -rw-r--r--   1 jfung    eng         10271 Oct 12 22:27 broker-1/kafka_server_1_logs/test_1-0/00000000000000000000.log
9702227   12 -rw-r--r--   1 jfung    eng         10293 Oct 12 22:27 broker-1/kafka_server_1_logs/test_1-0/00000000000000000201.log
9702228   12 -rw-r--r--   1 jfung    eng         10292 Oct 12 22:27 broker-1/kafka_server_1_logs/test_1-0/00000000000000000101.log
9702230   12 -rw-r--r--   1 jfung    eng         10178 Oct 12 22:27 broker-1/kafka_server_1_logs/test_1-0/00000000000000000401.log

9702239   12 -rw-r--r--   1 jfung    eng         10279 Oct 12 22:27 broker-2/kafka_server_2_logs/test_1-0/00000000000000000301.log
9702240   12 -rw-r--r--   1 jfung    eng         10271 Oct 12 22:27 broker-2/kafka_server_2_logs/test_1-0/00000000000000000000.log
9702241   12 -rw-r--r--   1 jfung    eng         10293 Oct 12 22:27 broker-2/kafka_server_2_logs/test_1-0/00000000000000000201.log
9702242   12 -rw-r--r--   1 jfung    eng         10292 Oct 12 22:27 broker-2/kafka_server_2_logs/test_1-0/00000000000000000101.log
9702244   12 -rw-r--r--   1 jfung    eng         10178 Oct 12 22:27 broker-2/kafka_server_2_logs/test_1-0/00000000000000000401.log

9702252   12 -rw-r--r--   1 jfung    eng         10279 Oct 12 22:27 broker-3/kafka_server_3_logs/test_1-0/00000000000000000361.log
9702255    4 -rw-r--r--   1 jfung    eng          4010 Oct 12 22:27 broker-3/kafka_server_3_logs/test_1-0/00000000000000000461.log
9702256   12 -rw-r--r--   1 jfung    eng         10271 Oct 12 22:27 broker-3/kafka_server_3_logs/test_1-0/00000000000000000000.log
9702257    8 -rw-r--r--   1 jfung    eng          5657 Oct 12 22:27 broker-3/kafka_server_3_logs/test_1-0/00000000000000000101.log
9702259   12 -rw-r--r--   1 jfung    eng         10280 Oct 12 22:27 broker-3/kafka_server_3_logs/test_1-0/00000000000000000261.log
9702262   12 -rw-r--r--   1 jfung    eng         10816 Oct 12 22:27 broker-3/kafka_server_3_logs/test_1-0/00000000000000000156.log
;;;","14/Oct/12 06:22;jfung;This issue is due to a bug in the System Test script (log segment files were not sorted before merging). So mark this Fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
system tests: failures in version-related sanity checks,KAFKA-2928,12917447,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granders,granders,granders,02/Dec/15 10:35,11/Dec/15 07:28,22/Mar/23 15:10,11/Dec/15 07:28,,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"There have been a few consecutive failures of version-related sanity checks in nightly system test runs:
kafkatest.sanity_checks.test_verifiable_producer
kafkatest.sanity_checks.test_kafka_version

assert is_version(...) is failing
utils.util.is_version is a fairly rough heuristic, so most likely this needs to be updated.

E.g., see
http://testing.confluent.io/kafka/2015-12-01--001/
(if this is broken, use http://testing.confluent.io/kafka/2015-12-01--001.tar.gz)",,ewencp,githubbot,granders,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Dec 10 23:28:11 UTC 2015,,,,,,,,,,"0|i2p5en:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"10/Dec/15 09:45;githubbot;GitHub user granders opened a pull request:

    https://github.com/apache/kafka/pull/656

    KAFKA-2928: system test: fix version sanity checks

    Fixed version sanity checks by updated kafkatest version to match kafka version

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/confluentinc/kafka KAFKA-2928-fix-version-sanity-checks

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/656.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #656
    
----
commit 1196d5aefa32e338881e7b3b50682e082733c625
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-12-10T01:43:04Z

    Fixed version sanity checks by updated kafkatest version to match kafka version

----
;;;","11/Dec/15 07:28;ewencp;Issue resolved by pull request 656
[https://github.com/apache/kafka/pull/656];;;","11/Dec/15 07:28;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/656
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Occassional GZIP errors on the server while writing compressed data to disk,KAFKA-273,12542954,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,17/Feb/12 06:22,17/Aug/17 20:00,22/Mar/23 15:10,17/Aug/17 20:00,0.7,,,,,,,,,,,,,core,,,,1,,,,,,"Occasionally, we see the following errors on the Kafka server -

2012/02/08 14:58:21.832 ERROR [KafkaRequestHandlers] [kafka-processor-6] [kafka] Error processing MultiProducerRequest on NusImpressionSetEvent:0
java.io.EOFException: Unexpected end of ZLIB input stream
        at java.util.zip.InflaterInputStream.fill(InflaterInputStream.java:223)
        at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:141)
        at java.util.zip.GZIPInputStream.read(GZIPInputStream.java:92)
        at java.io.FilterInputStream.read(FilterInputStream.java:90)
        at kafka.message.GZIPCompression.read(CompressionUtils.scala:52)
        at kafka.message.CompressionUtils$$anonfun$decompress$1.apply$mcI$sp(CompressionUtils.scala:143)
        at kafka.message.CompressionUtils$$anonfun$decompress$1.apply(CompressionUtils.scala:143)
        at kafka.message.CompressionUtils$$anonfun$decompress$1.apply(CompressionUtils.scala:143)
        at scala.collection.immutable.Stream$$anonfun$continually$1.apply(Stream.scala:598)
        at scala.collection.immutable.Stream$$anonfun$continually$1.apply(Stream.scala:598)
        at scala.collection.immutable.Stream$Cons.tail(Stream.scala:555)
        at scala.collection.immutable.Stream$Cons.tail(Stream.scala:549)
        at scala.collection.immutable.Stream$$anonfun$takeWhile$1.apply(Stream.scala:394)
        at scala.collection.immutable.Stream$$anonfun$takeWhile$1.apply(Stream.scala:394)
        at scala.collection.immutable.Stream$Cons.tail(Stream.scala:555)
        at scala.collection.immutable.Stream$Cons.tail(Stream.scala:549)
        at scala.collection.immutable.Stream.foreach(Stream.scala:255)
        at kafka.message.CompressionUtils$.decompress(CompressionUtils.scala:143)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNextOuter(ByteBufferMessageSet.scala:119)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:132)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:81)
        at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:59)
        at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:51)
        at scala.collection.Iterator$class.foreach(Iterator.scala:631)
        at kafka.utils.IteratorTemplate.foreach(IteratorTemplate.scala:30)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
        at kafka.message.MessageSet.foreach(MessageSet.scala:87)
        at kafka.log.Log.append(Log.scala:204)
        at kafka.server.KafkaRequestHandlers.kafka$server$KafkaRequestHandlers$$handleProducerRequest(KafkaRequestHandlers.scala:70)
        at kafka.server.KafkaRequestHandlers$$anonfun$handleMultiProducerRequest$1.apply(KafkaRequestHandlers.scala:63)
        at kafka.server.KafkaRequestHandlers$$anonfun$handleMultiProducerRequest$1.apply(KafkaRequestHandlers.scala:63)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)
        at scala.collection.mutable.ArrayOps.foreach(ArrayOps.scala:34)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)
        at scala.collection.mutable.ArrayOps.map(ArrayOps.scala:34)
        at kafka.server.KafkaRequestHandlers.handleMultiProducerRequest(KafkaRequestHandlers.scala:63)
        at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$4.apply(KafkaRequestHandlers.scala:42)
        at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$4.apply(KafkaRequestHandlers.scala:42)
        at kafka.network.Processor.handle(SocketServer.scala:297)
        at kafka.network.Processor.read(SocketServer.scala:320)
        at kafka.network.Processor.run(SocketServer.scala:215)
        at java.lang.Thread.run(Thread.java:619)
",,jkreps,omkreddy,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-274,KAFKA-275,,,,,,,,,,,"07/Mar/12 03:09;nehanarkhede;kafka-273.patch;https://issues.apache.org/jira/secure/attachment/12517289/kafka-273.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,228240,,,Thu Aug 17 12:00:09 UTC 2017,,,,,,,,,,"0|i15zfr:",243041,,,,,,,,,,,,,,,,,,,,"07/Mar/12 01:56;nehanarkhede;We've seen this error very occasionally, but in our deployments the Deflator uses jdk-1.6.0.21 and zlib-1.2.3 on Linux and jdk-1.6.0_16 and zlib-1.2.3 on Solaris. And the Inflator uses jdk-1.6.0.21 and zlib-1.2.3 on Linux.

According to this Java bug - http://bugs.sun.com/bugdatabase/view_bug.do;jsessionid=e8f7802ea035813254fc6aba9bf0?bug_id=6519463, the bug is fixed by using a combination of zlib1.23 and jdk7-b72

Here is the code snippet from InflatorInputStream.java - 
  157                   if (inf.needsInput()) {
  158                       fill();
  159                   }

This bug occurs when the native Inflator on the platform indicates there are more bytes to decompress, when there aren't any. So, the InflatorInputStream.read() calls fill() based on that, where it throws EOFException(). 

The workaround seems to be catching the EOFException in CompressionUtils.decompress and do nothing.
;;;","07/Mar/12 02:39;junrao;We have also seem the following gzip issue. Is that the same issue since it's not triggered by EOF?

 ERROR [CompressionUtils$] [kafka-processor-0] [kafka] Error while reading from the GZIP input stream
java.io.IOException: Corrupt GZIP trailer
        at java.util.zip.GZIPInputStream.readTrailer(GZIPInputStream.java:182)
        at java.util.zip.GZIPInputStream.read(GZIPInputStream.java:94)
        at java.io.FilterInputStream.read(FilterInputStream.java:90)
        at kafka.message.GZIPCompression.read(CompressionUtils.scala:52)
        at kafka.message.CompressionUtils$$anonfun$decompress$1.apply$mcI$sp(CompressionUtils.scala:143)
        at kafka.message.CompressionUtils$$anonfun$decompress$1.apply(CompressionUtils.scala:143)
        at kafka.message.CompressionUtils$$anonfun$decompress$1.apply(CompressionUtils.scala:143)
        at scala.collection.immutable.Stream$$anonfun$continually$1.apply(Stream.scala:598)
        at scala.collection.immutable.Stream$$anonfun$continually$1.apply(Stream.scala:598)
        at scala.collection.immutable.Stream$Cons.tail(Stream.scala:555)
        at scala.collection.immutable.Stream$Cons.tail(Stream.scala:549)
        at scala.collection.immutable.Stream$$anonfun$takeWhile$1.apply(Stream.scala:394)
        at scala.collection.immutable.Stream$$anonfun$takeWhile$1.apply(Stream.scala:394)
        at scala.collection.immutable.Stream$Cons.tail(Stream.scala:555)
        at scala.collection.immutable.Stream$Cons.tail(Stream.scala:549)
        at scala.collection.immutable.Stream.foreach(Stream.scala:255)
        at kafka.message.CompressionUtils$.decompress(CompressionUtils.scala:143)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNextOuter(ByteBufferMessageSet.scala:119)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:132)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:81)
        at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:59)
        at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:51)
        at scala.collection.Iterator$class.foreach(Iterator.scala:631)
        at kafka.utils.IteratorTemplate.foreach(IteratorTemplate.scala:30)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
        at kafka.message.MessageSet.foreach(MessageSet.scala:87)
        at kafka.log.Log.append(Log.scala:204)
        at kafka.server.KafkaRequestHandlers.kafka$server$KafkaRequestHandlers$$handleProducerRequest(KafkaRequestHandlers.scala:70)
        at kafka.server.KafkaRequestHandlers$$anonfun$handleMultiProducerRequest$1.apply(KafkaRequestHandlers.scala:63)
        at kafka.server.KafkaRequestHandlers$$anonfun$handleMultiProducerRequest$1.apply(KafkaRequestHandlers.scala:63)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)
        at scala.collection.mutable.ArrayOps.foreach(ArrayOps.scala:34)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)
        at scala.collection.mutable.ArrayOps.map(ArrayOps.scala:34)
        at kafka.server.KafkaRequestHandlers.handleMultiProducerRequest(KafkaRequestHandlers.scala:63)
        at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$4.apply(KafkaRequestHandlers.scala:42)
        at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$4.apply(KafkaRequestHandlers.scala:42)
        at kafka.network.Processor.handle(SocketServer.scala:297)
        at kafka.network.Processor.read(SocketServer.scala:320)
        at kafka.network.Processor.run(SocketServer.scala:215)
        at java.lang.Thread.run(Thread.java:619)
;;;","07/Mar/12 03:09;nehanarkhede;Changed CompressionUtils.decompress to handle EOFException and return -1 from the read API;;;","07/Mar/12 07:33;nehanarkhede;Jun, I am not sure its the same issue. See this - http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4262583

The Java bugs mention that it happens due to very large compressed or uncompressed data (larger than 2GB). Not sure how Kafka server can get into that situation, since the request size is 100 MB. ;;;","08/Mar/12 01:42;junrao;The patch for EOF looks fine. We probably need to do some system test to make sure this doesn't introduce new problems, especially when the compressed size is relatively large. Once that test is done. We can commit the patch.;;;","13/Mar/12 04:07;nehanarkhede;Have run the system test with message size = 100K, batch size = 200 and compression turned on. It passed.;;;","12/Jul/13 06:43;jkreps;Is this still happening?;;;","17/Aug/17 20:00;omkreddy; We have seen this issues recently. Pl reopen if you think the issue still exists 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in testDeleteTopicWithCleaner due to OOME,KAFKA-1881,12768517,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,junrao,junrao,20/Jan/15 03:34,27/Feb/15 07:04,22/Mar/23 15:10,27/Feb/15 07:04,0.9.0.0,,,,,,0.9.0.0,,,,,,,core,,,,0,,,,,,"kafka.admin.DeleteTopicTest > testDeleteTopicWithCleaner FAILED
    java.lang.OutOfMemoryError: Java heap space
        at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:39)
        at java.nio.ByteBuffer.allocate(ByteBuffer.java:312)
        at kafka.log.SkimpyOffsetMap.<init>(OffsetMap.scala:42)
        at kafka.log.LogCleaner$CleanerThread.<init>(LogCleaner.scala:177)
        at kafka.log.LogCleaner$$anonfun$1.apply(LogCleaner.scala:86)
        at kafka.log.LogCleaner$$anonfun$1.apply(LogCleaner.scala:86)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.immutable.Range.foreach(Range.scala:141)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at kafka.log.LogCleaner.<init>(LogCleaner.scala:86)
        at kafka.log.LogManager.<init>(LogManager.scala:64)
        at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:337)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:85)
        at kafka.utils.TestUtils$.createServer(TestUtils.scala:134)
        at kafka.admin.DeleteTopicTest$$anonfun$10.apply(DeleteTopicTest.scala:272)
        at kafka.admin.DeleteTopicTest$$anonfun$10.apply(DeleteTopicTest.scala:272)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.immutable.List.foreach(List.scala:318)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at kafka.admin.DeleteTopicTest.createTestTopicAndCluster(DeleteTopicTest.scala:272)
        at kafka.admin.DeleteTopicTest.testDeleteTopicWithCleaner(DeleteTopicTest.scala:241)
",,ewencp,gwenshap,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Feb/15 07:27;ewencp;KAFKA-1881.patch;https://issues.apache.org/jira/secure/attachment/12700898/KAFKA-1881.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Feb 26 23:04:00 UTC 2015,,,,,,,,,,"0|i24jb3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"20/Jan/15 03:35;junrao;Perhaps we can just reduce the amount of data written in writeDups().
;;;","20/Jan/15 06:22;gwenshap;We can (although we are looking at around 2K of memory here... 100 records * 3 dupes * ~6 bytes each).

But it looks like we are running out of memory before writeDups is even called - the error is in createTestTopicAndCluster:
at kafka.admin.DeleteTopicTest.createTestTopicAndCluster(DeleteTopicTest.scala:272)
at kafka.admin.DeleteTopicTest.testDeleteTopicWithCleaner(DeleteTopicTest.scala:241)

What makes you suspect writeDups in this issue? Does the OOM only happens when running the test in a loop?;;;","20/Jan/15 13:32;junrao;Not sure id writeDups is causing the issue. I just ran gradlew test. It seems this starts to happen after KAFKA-1819 is committed.;;;","26/Feb/15 07:27;ewencp;Created reviewboard https://reviews.apache.org/r/31447/diff/
 against branch origin/trunk;;;","27/Feb/15 07:04;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
transient unit test failure in DeleteTopicTest.testPreferredReplicaElectionDuringDeleteTopic,KAFKA-1391,12708165,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,junrao,junrao,14/Apr/14 06:11,16/Apr/14 23:55,22/Mar/23 15:10,16/Apr/14 23:55,0.8.2.0,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"The test hang due to the following deadlock.

""Test worker"" prio=5 tid=7fd40c0b2800 nid=0x114ebd000 waiting on condition [114eb9000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <7f40b2aa0> (a java.util.concurrent.CountDownLatch$Sync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:811)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:969)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1281)
        at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:207)
        at kafka.utils.ShutdownableThread.shutdown(ShutdownableThread.scala:36)
        at kafka.controller.TopicDeletionManager.shutdown(TopicDeletionManager.scala:105)
        at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply$mcV$sp(KafkaController.scala:344)
        at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply(KafkaController.scala:340)
        at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply(KafkaController.scala:340)
        at kafka.utils.Utils$.inLock(Utils.scala:537)
        at kafka.controller.KafkaController.onControllerResignation(KafkaController.scala:340)
        at kafka.controller.KafkaController$$anonfun$shutdown$1.apply$mcV$sp(KafkaController.scala:647)
        at kafka.controller.KafkaController$$anonfun$shutdown$1.apply(KafkaController.scala:645)
        at kafka.controller.KafkaController$$anonfun$shutdown$1.apply(KafkaController.scala:645)
        at kafka.utils.Utils$.inLock(Utils.scala:537)
        at kafka.controller.KafkaController.shutdown(KafkaController.scala:645)
        at kafka.server.KafkaServer$$anonfun$shutdown$9.apply$mcV$sp(KafkaServer.scala:242)
        at kafka.utils.Utils$.swallow(Utils.scala:166)
        at kafka.utils.Logging$class.swallowWarn(Logging.scala:92)
        at kafka.utils.Utils$.swallowWarn(Utils.scala:45)
        at kafka.utils.Logging$class.swallow(Logging.scala:94)
        at kafka.utils.Utils$.swallow(Utils.scala:45)
        at kafka.server.KafkaServer.shutdown(KafkaServer.scala:242)
        at kafka.admin.DeleteTopicTest.testPreferredReplicaElectionDuringDeleteTopic(DeleteTopicTest.scala:163)

""delete-topics-thread"" prio=5 tid=7fd409ad2000 nid=0x11b0c2000 waiting on condition [11b0c1000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <7f40a7048> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:811)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:842)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1178)
        at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:186)
        at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:262)
        at kafka.utils.Utils$.inLock(Utils.scala:535)
        at kafka.controller.TopicDeletionManager$DeleteTopicsThread.doWork(TopicDeletionManager.scala:376)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)

",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,386488,,,Wed Apr 16 15:55:54 UTC 2014,,,,,,,,,,"0|i1ukvz:",386752,,,,,,,,,,,,,,,,,,,,"14/Apr/14 06:15;junrao;KAFKA-1363 doesn't quite fix the hanging issue when shutting down deleteTopicsThread.  This thread does the following. During the shutdown, if the shutdown logic will first unblock awaitTopicDeletionNotification() and then mark isRunning as false. However, if the marking happens after the checking of isRunning in the deleteTopicsThread, it will block forever. 

    override def doWork() {
      awaitTopicDeletionNotification()

      if(!isRunning.get)
        return

      inLock(controllerContext.controllerLock) {
;;;","14/Apr/14 06:17;junrao;At this moment, I am not if it's worth keeping patching the unit tests in DeleteTopicTest. We know that we have to make another pass of them when we actually fix the delete topic logic itself. We probably can just comment out all tests in DeleteTopicTest for now and fix them when we actual fix delete topic.;;;","16/Apr/14 23:55;junrao;The relevant unit tests are commented out for now in KAFKA-1390. The real fix will be done in KAFKA-1397.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Concurrency issue in getCluster() causes rebalance failure and dead consumer,KAFKA-1010,12663814,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,smeder,smeder,smeder,15/Aug/13 16:39,17/Aug/13 01:09,22/Mar/23 15:10,17/Aug/13 01:09,0.8.0,,,,,,0.8.0,,,,,,,consumer,,,,0,,,,,,"We're seeing the following stack trace on the consumer when brokers are (forcefully) removed from the cluster:

Thu Aug 15 05:10:06 GMT 2013 Exception in thread ""main"" org.I0Itec.zkclient.exception.ZkNoNodeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /brokers/ids/4
at org.I0Itec.zkclient.exception.ZkException.create(ZkException.java:47)
at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:685)
at org.I0Itec.zkclient.ZkClient.readData(ZkClient.java:766)
at org.I0Itec.zkclient.ZkClient.readData(ZkClient.java:761)
at kafka.utils.ZkUtils$.readData(ZkUtils.scala:407)
at kafka.utils.ZkUtils$$anonfun$getCluster$1.apply(ZkUtils.scala:453)
at kafka.utils.ZkUtils$$anonfun$getCluster$1.apply(ZkUtils.scala:452)
at scala.collection.Iterator$class.foreach(Iterator.scala:631)
at scala.collection.JavaConversions$JIteratorWrapper.foreach(JavaConversions.scala:549)
at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
at scala.collection.JavaConversions$JListWrapper.foreach(JavaConversions.scala:596)
at kafka.utils.ZkUtils$.getCluster(ZkUtils.scala:452)
at kafka.consumer.ZookeeperConsumerConnector$ZKRebalancerListener$$anonfun$syncedRebalance$1.apply$mcVI$sp(ZookeeperConsumerConnector.scala:394)
at scala.collection.immutable.Range$ByOne$class.foreach$mVc$sp(Range.scala:282)
at scala.collection.immutable.Range$$anon$2.foreach$mVc$sp(Range.scala:265)
at kafka.consumer.ZookeeperConsumerConnector$ZKRebalancerListener.syncedRebalance(ZookeeperConsumerConnector.scala:391)
at kafka.consumer.ZookeeperConsumerConnector.kafka$consumer$ZookeeperConsumerConnector$$reinitializeConsumer(ZookeeperConsumerConnector.scala:722)
at kafka.consumer.ZookeeperConsumerConnector.consume(ZookeeperConsumerConnector.scala:206)
at kafka.javaapi.consumer.ZookeeperConsumerConnector.createMessageStreams(ZookeeperConsumerConnector.scala:77)
at kafka.javaapi.consumer.ZookeeperConsumerConnector.createMessageStreams(ZookeeperConsumerConnector.scala:89)

I'm pretty sure this is due to the following logic in getCluster():

    val nodes = getChildrenParentMayNotExist(zkClient, BrokerIdsPath)
    for (node <- nodes) {
      val brokerZKString = readData(zkClient, BrokerIdsPath + ""/"" + node)._1
      cluster.add(Broker.createBroker(node.toInt, brokerZKString))
    }

which is obviously not safe since the nodes retrieved in the first call may have disappeared by the time we iterate to get the values.

getCluster() seems to only be used in ZookeeperConsumerConnector.syncedRebalance and in ImportZkOffsets.updateZkOffsets (which doesn't actually look like it is using the values), so the simplest solution may be to just move the getCluster() call into the try block in syncedRebalance and kill the usage in the other call.",,guozhang,junrao,smeder,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/13 00:30;smeder;get_cluster_0_8_git.patch;https://issues.apache.org/jira/secure/attachment/12598488/get_cluster_0_8_git.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,343815,,,Fri Aug 16 17:09:43 UTC 2013,,,,,,,,,,"0|i1nain:",344117,,,,,,,,,,,,,,,,,,,,"15/Aug/13 17:08;smeder;Simply move getCluster() call intro retry loop and eliminate second call. Also would be happy to provide a retry inside of getCluster based patch.;;;","16/Aug/13 00:28;guozhang;This looks good to me. If the broker ephemeral node disappears after the first Zk Call, another rebalance should be triggered so it is safe to fail-fast this trial.

+1;;;","17/Aug/13 00:15;junrao;Thanks for the patch. It doesn't seem to apply to 0.8 though. Could you rebase?

 git apply ~/Downloads/get_cluster_0_8.patch 
error: patch failed: core/src/main/scala/kafka/tools/ImportZkOffsets.scala:96
error: core/src/main/scala/kafka/tools/ImportZkOffsets.scala: patch does not apply
;;;","17/Aug/13 00:24;smeder;weird, patch -p1 -i get_cluster_0_8.patch worked, but git apply didn't. Let me see if I can get something that git apply likes.;;;","17/Aug/13 00:31;smeder;Git formatted patch is now attached.;;;","17/Aug/13 01:09;junrao;Thanks for the patch. Committed to 0.8.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka-preferred-replica-election.sh will fail without clear error message if /brokers/topics/[topic]/partitions does not exist,KAFKA-1019,12665069,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,sriharsha,guozhang,guozhang,23/Aug/13 00:41,13/Jun/17 20:31,22/Mar/23 15:10,13/Jun/17 20:31,0.8.1,,,,,,,,,,,,,,,,,1,newbie,,,,,"From Libo Yu:

I tried to run kafka-preferred-replica-election.sh on our kafka cluster.
But I got this expection:
Failed to start preferred replica election
org.I0Itec.zkclient.exception.ZkNoNodeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /brokers/topics/uattoqaaa.default/partitions

I checked zookeeper and there is no /brokers/topics/uattoqaaa.default/partitions. All I found is
/brokers/topics/uattoqaaa.default.
",,baluchicken,draiwn,guozhang,hongyu.bi,ijuma,jozi-k,junrao,nehanarkhede,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,345010,,,Tue Jun 13 12:31:31 UTC 2017,,,,,,,,,,"0|i1nhvb:",345311,,nehanarkhede,,,,,,,,,,,,,,,,,,"09/Jul/14 01:23;draiwn;Hi,

We faced the same issue with the latest Kafka version 0.8.1.
Is there any known workaround ?

Thanks;;;","09/Jul/14 12:18;junrao;In general, /brokers/topics/[topic]/partitions should be immediately available after a topic is created. Not sure how you get to this state. One possibility is that the controller somehow lost its registered ZK watcher and therefore didn't act on newly created topics. Could you verify that the topic watcher is still registered by the controller? If not, could you make sure that you are using ZK 3.3.4?;;;","10/Jul/14 00:48;draiwn;Hi Jun,

We use ZK 3.4.6, can it cause this issue?
How can we check that the topic watcher is registered by the controller?

Thanks;;;","10/Jul/14 01:06;junrao;I am not sure how reliable ZK 3.4.6 is. If you check the ZK admin page, it shows you the command of listing all watchers registered. You want to check if there is a child watcher on /brokers/topics.

Another thing is to avoid ZK session expiration, since it may expose some corner case bugs.;;;","16/Jul/14 01:03;nehanarkhede;[~draiwn] were you able to confirm the issue with zookeeper 3.4.6? In any case, we can at least fix the error message when the path doesn't exist.;;;","04/Aug/14 21:23;draiwn;I tried with zookeeper 3.3.6 and we have the same issue.
To reproduce:

Create a topic named testid
{code}bin/kafka-topics.sh --topic testid --replication-factor 3 --partition 3 --zookeeper 127.0.0.1:2181/kafka --create
Created topic ""testid"".{code}

{code}./bin/kafka-topics.sh --topic testid --zookeeper 127.0.0.1:2181/kafka --describe
Topic:testid	PartitionCount:3	ReplicationFactor:3	Configs:
	Topic: testid	Partition: 0	Leader: 31985	Replicas: 31985,9920,4580	Isr: 31985,9920,4580
	Topic: testid	Partition: 1	Leader: 4580	Replicas: 4580,31985,9920	Isr: 4580,31985,9920
	Topic: testid	Partition: 2	Leader: 9920	Replicas: 9920,4580,31985	Isr: 9920,4580,31985
{code}
Ok great, we have leaders and  /brokers/topics/testid/partitions in zookeeper

Delete testid topic
{code}bin/kafka-run-class.sh kafka.admin.DeleteTopicCommand --topic testid --zookeeper 127.0.0.1:2181/kafka
deletion succeeded!
{code}

Create again a topic named testid
{code}bin/kafka-topics.sh --topic testid --replication-factor 3 --partition 3 --zookeeper 127.0.0.1:2181/kafka --create
Created topic ""testid"".{code}

Now check:
{code}./bin/kafka-topics.sh --topic testid --zookeeper 127.0.0.1:2181/kafka --describe
Topic:testid	PartitionCount:3	ReplicationFactor:3	Configs:
	Topic: testid	Partition: 0	Leader: none	Replicas: 31985,4580,9920	Isr: 
	Topic: testid	Partition: 1	Leader: none	Replicas: 4580,9920,31985	Isr: 
	Topic: testid	Partition: 2	Leader: none	Replicas: 9920,31985,4580	Isr:{code}

As you can see we have no leader when we create the topic after a deletion. And there is no /brokers/topics/testid/partitions in zookeeper
It works again with a different topic name, so it seems that something is not properly deleted with DeleteTopicCommand command.

We reproduced it on 3 differents zookeeper chroot: 127.0.0.1:2181/kafka, 127.0.0.1:2181/kafka2 and 127.0.0.1:2181/kafka3

Thanks;;;","05/Sep/14 06:16;guozhang;Moving to 0.9 now.;;;","19/Sep/14 17:45;hongyu.bi;@Mickael Hemri  we face the same issue on zookeeper 3.4.5/kafka 0.8.1.1
;;;","20/Sep/14 03:41;guozhang;Hongyu, did you follow the same pattern as Mickael to re-produce this issue? From Mickael's pattern it seems to be related to the delete-topic tool (KAFKA-1558).;;;","23/Sep/14 15:35;hongyu.bi;Thanks @Guozhang.
After diving into source code i got it.;;;","24/Sep/14 09:23;sriharsha;[~guozhang] [~nehanarkhede]  I don't think this issues exists in the trunk
I ran the above steps specified by [~draiwn] with zookeeper 3.4.6

 bin/kafka-topics.sh --describe --topic testid  --zookeeper zookeeper1:2181,zookeeper2:2181,zookeeper3:2181       
Topic:testid    PartitionCount:3        ReplicationFactor:3     Configs:
        Topic: testid   Partition: 0    Leader: 3       Replicas: 3,2,1 Isr: 3,2,1
        Topic: testid   Partition: 1    Leader: 1       Replicas: 1,3,2 Isr: 1,3,2
        Topic: testid   Partition: 2    Leader: 2       Replicas: 2,1,3 Isr: 2,1,3
[kafka@zookeeper1 kafka]$ bin/kafka-topics.sh --delete --topic testid  --zookeeper zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
Topic testid is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
[kafka@zookeeper1 kafka]$ bin/kafka-topics.sh --describe --topic testid  --zookeeper zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
[kafka@zookeeper1 kafka]$ bin/kafka-topics.sh --create --topic testid --replication-factor 3 --partition 3 --zookeeper zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
Created topic ""testid"".
[kafka@zookeeper1 kafka]$ bin/kafka-topics.sh --describe --topic testid  --zookeeper zookeeper1:2181,zookeeper2:2181,zookeeper3:2181
Topic:testid    PartitionCount:3        ReplicationFactor:3     Configs:
        Topic: testid   Partition: 0    Leader: 3       Replicas: 3,1,2 Isr: 3,1,2
        Topic: testid   Partition: 1    Leader: 1       Replicas: 1,2,3 Isr: 1,2,3
        Topic: testid   Partition: 2    Leader: 2       Replicas: 2,3,1 Isr: 2,3,1
;;;","25/Sep/14 09:52;nehanarkhede;Thanks for checking, [~sriharsha]. I wonder if the original issue reported in the JIRA also doesn't exist anymore? The need for a clear error message when preferred replica election is attempted on a topic that doesn't exist.;;;","08/Apr/17 03:23;jozi-k;Is it still an issue [~draiwn]? Or can we close the issue now?;;;","13/Jun/17 20:31;ijuma;The underlying reason could be the same as KAFKA-5418. Closing as a duplicate.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ByteBufferMessageSet logs error about fetch size,KAFKA-59,12514696,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,,,20/Jul/11 05:32,20/Jul/11 05:32,22/Mar/23 15:10,20/Jul/11 05:32,,,,,,,0.6,,,,,,,,,,,0,,,,,,"Not sure how this happened, but someone added an error message about fetch size being too small in ByteBufferMessageSet. This obviously makes no sense since this class is used in the producer and broker as well as in the consumer, neither of which have a fetch size. This error needs to be properly handled (say by throwing an error), and each user needs to be modified to handle it appropriately.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,67470,,,2011-07-19 21:32:25.0,,,,,,,,,,"0|i15yqf:",242927,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New producer + Snappy face un-compression errors after broker restart,KAFKA-2308,12842442,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,gwenshap,gwenshap,gwenshap,03/Jul/15 05:02,03/Dec/15 12:07,22/Mar/23 15:10,09/Jul/15 00:58,,,,,,,0.8.2.2,0.9.0.0,,,,,,,,,,0,,,,,,"Looks like the new producer, when used with Snappy, following a broker restart is sending messages the brokers can't decompress. This issue was discussed at few mailing lists thread, but I don't think we ever resolved it.

I can reproduce with trunk and Snappy 1.1.1.7. 

To reproduce:
1. Start 3 brokers
2. Create a topic with 3 partitions and 3 replicas each.
2. Start performance producer with --new-producer --compression-codec 2 (and set the number of messages to fairly high, to give you time. I went with 10M)
3. Bounce one of the brokers
4. The log of one of the surviving nodes should contain errors like:

{code}
2015-07-02 13:45:59,300 ERROR kafka.server.ReplicaManager: [Replica Manager on Broker 66]: Error processing append operation on partition [t3,0]
kafka.common.KafkaException:
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:94)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:64)
        at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)
        at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)
        at kafka.message.ByteBufferMessageSet$$anon$2.innerDone(ByteBufferMessageSet.scala:177)
        at kafka.message.ByteBufferMessageSet$$anon$2.makeNext(ByteBufferMessageSet.scala:218)
        at kafka.message.ByteBufferMessageSet$$anon$2.makeNext(ByteBufferMessageSet.scala:173)
        at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)
        at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)
        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
        at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
        at scala.collection.AbstractIterator.to(Iterator.scala:1157)
        at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
        at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
        at kafka.message.ByteBufferMessageSet.validateMessagesAndAssignOffsets(ByteBufferMessageSet.scala:267)
        at kafka.log.Log.liftedTree1$1(Log.scala:327)
        at kafka.log.Log.append(Log.scala:326)
        at kafka.cluster.Partition$$anonfun$appendMessagesToLeader$1.apply(Partition.scala:423)
        at kafka.cluster.Partition$$anonfun$appendMessagesToLeader$1.apply(Partition.scala:409)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
        at kafka.utils.CoreUtils$.inReadLock(CoreUtils.scala:268)
        at kafka.cluster.Partition.appendMessagesToLeader(Partition.scala:409)
        at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:365)
        at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:350)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:350)
        at kafka.server.ReplicaManager.appendMessages(ReplicaManager.scala:286)
        at kafka.server.KafkaApis.handleProducerRequest(KafkaApis.scala:270)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:57)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: PARSING_ERROR(2)
        at org.xerial.snappy.SnappyNative.throw_error(SnappyNative.java:84)
        at org.xerial.snappy.SnappyNative.uncompressedLength(Native Method)
        at org.xerial.snappy.Snappy.uncompressedLength(Snappy.java:594)
        at org.xerial.snappy.SnappyInputStream.hasNextChunk(SnappyInputStream.java:358)
        at org.xerial.snappy.SnappyInputStream.rawRead(SnappyInputStream.java:167)
        at org.xerial.snappy.SnappyInputStream.read(SnappyInputStream.java:150)
        at java.io.DataInputStream.readFully(DataInputStream.java:195)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:82)
        ... 43 more
{code}

The client has the following messages:
{code}
[2015-07-02 13:46:00,478] ERROR Error when sending message to topic t3 with key: 4 bytes, value: 100 bytes with error: The server experienced an unexpected error when processing the request (org.apache.kafka.clients.producer.internals.ErrorLoggingCallback)
java: target/snappy-1.1.1/snappy.cc:423: char* snappy::internal::CompressFragment(const char*, size_t, char*, snappy::uint16*, int): Assertion `0 == memcmp(base, candidate, matched)' failed.
{code}",,allenxwang,ewencp,githubbot,guozhang,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jul/15 10:47;gwenshap;KAFKA-2308.patch;https://issues.apache.org/jira/secure/attachment/12744120/KAFKA-2308.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Dec 03 04:07:03 UTC 2015,,,,,,,,,,"0|i2gt9b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"08/Jul/15 02:03;gwenshap;I kinda know why it happens, a patch will take a bit of time since I can't reproduce the error in a unit test (although it reproduces nicely in a test environment). I'll put a preliminary patch without unit tests up in a sec, so people suffering from this issue can validate. Here's what I found:

When we get a retriable error in the producer (NETWORK_EXCEPTION for instance), the current record batch gets put first in its topic-partition message batch queue by completeBatch().
Next time Sender runs, it drains the queue and one of the things it does is to take the first batch from the queue and close() it. But if a batch was re-queued, it was already closed. Calling close() twice should be safe, and for un-compressed messages, it is. However, for compressed messages the logic in close() is rather complex, and I believe closing a batch twice messes up the record. I can't tell exactly where the close() logic becomes unsafe, but there's really no need to close a batch twice. MemoryRecords.close() can check if it is writable before closing, and only close() the record if it is writable. This guarantees closing will happen just once. 

Fixing this resolved the problem on my system.

;;;","08/Jul/15 03:10;guozhang;Hi [~gwenshap] thanks for the findings. Yes for compressed message set the close call will trigger Compressor.close() which:

1. close the compression input stream, which will likely write the left-over cached bytes to the underlying buffer.
2. set the wrapper message header accordingly, such as offset (as the number of compressed messages - 1), length, and crc.

For the second step I think it should be OK to execute twice, plus if not then gzip should also have the similar issue; but it seems for the first step calling stream.close() multiple times on snappy may be problematic. To verify that we can write some simple test code:

{code}
stream = new org.xerial.snappy.SnappyOutputStream(buffer-size);
// write some bytes to stream
stream.close();
stream.close(); // again
{code};;;","08/Jul/15 10:43;gwenshap;Thanks for your comments, [~guozhang].

Closing multiple times on Snappy is not an issue. Actually, even draining, requeueing and draining again is not an issue by itself.
That is, I'm still unable to create a test that replicates this error, even though it reproduces nicely in a real cluster with the performance producer.

I have a patch that I'm fairly certain fixes the problem (although I cannot say why). I'll attach it here, because someone may need it, and continue digging into when and why does double-close corrupt messages.

Here's a link to a test that should have caused an issue, but doesn't:
https://gist.github.com/gwenshap/1ec9cb55d704a82477d8;;;","08/Jul/15 10:47;gwenshap;Created reviewboard https://reviews.apache.org/r/36290/diff/
 against branch trunk;;;","08/Jul/15 12:26;gwenshap;Actually, looks likely that it is Snappy (even though I can't reproduce):
https://github.com/xerial/snappy-java/pull/108

Note that this is not in 1.1.1.7 (which we are using).

I suggest pushing our simple work-around (since its simple and nothing bad can happen from only closing once).;;;","09/Jul/15 00:25;ewencp;[~gwenshap] The test case you gave doesn't quite do enough to trigger the bug. It releases the same buffer twice, but doesn't reuse it. I think you'd need to get the test to do something more like:

* Fill first record batch (batch 1) with records and drain (causing buffer to be released).
* At least start creating another batch (batch 2). This allocates the buffer to that batch.
* Reenqueue batch 1 and drain (causing buffer to be released second time).
* Continue enqueuing until it creates *another* batch (batch 3), which allocates the buffer yet again.
* Drain batches 2 and 3 and validate their contents.;;;","09/Jul/15 00:29;gwenshap;yes, I saw the Snappy test case too :)

Since its a confirmed Snappy bug, I don't think we need a Kafka test-case. We can just protect that call, right?;;;","09/Jul/15 00:38;guozhang;Agree, we do not need a test case inside Kafka code.;;;","09/Jul/15 00:43;gwenshap;Was that a ""ship it"", [~guozhang]? :);;;","09/Jul/15 00:55;guozhang;I was unit testing the patch while writing the last comment :) Just shipped it and committed to trunk.;;;","09/Jul/15 01:25;gwenshap;Thanks :);;;","02/Dec/15 03:39;allenxwang;[~gwenshap] [~guozhang] Is the fix in producer only? If I take 0.8.2.2 producer, do I also need to have broker/consumer upgraded to 0.8.2.2 or a later snappy version in order to avoid this bug? Currently our broker is on 0.8.2.1 and snappy 1.1.1.6. ;;;","02/Dec/15 04:14;guozhang;[~allenxwang] This bug should be only in the producer due to its use patterns of snappy.;;;","03/Dec/15 12:07;githubbot;Github user darionyaphet commented on the pull request:

    https://github.com/apache/storm/pull/801#issuecomment-161509467
  
    Hi @knusbaum @revans2 I read `Kafka Release Notes Version 0.8.2.2`  and found a bug fixed ([KAFKA-2308](https://issues.apache.org/jira/browse/KAFKA-2308)) about New producer and Snappy un-compression errors when Kafka Broker restart . So I think this is maybe useful .
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SimpleConsumer.fetchOffset returns wrong error code when no offset exists for topic/partition/consumer group,KAFKA-1637,12742012,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,amir.malekpour,amir.malekpour,17/Sep/14 08:59,15/Nov/14 03:16,22/Mar/23 15:10,17/Oct/14 01:39,0.8.1,0.8.1.1,,,,,0.8.2.0,,,,,,,consumer,core,,,0,newbie,,,,,"This concerns Kafka's Offset  Fetch API:

According to Kafka's current documentation, ""if there is no offset associated with a topic-partition under that consumer group the broker does not set an error code (since it is not really an error), but returns empty metadata and sets the offset field to -1.""  (Link below)

However, in Kafka 08.1.1 Error code '3' is returned, which effectively makes it impossible for the client to decide if there was an error, or if there is no offset associated with a topic-partition under that consumer group.


https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-MetadataAPI
",Linux,amir.malekpour,ewencp,jjkoshy,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Oct/14 06:04;ewencp;KAFKA-1637.patch;https://issues.apache.org/jira/secure/attachment/12674862/KAFKA-1637.patch","16/Oct/14 00:08;ewencp;KAFKA-1637_2014-10-15_09:08:12.patch;https://issues.apache.org/jira/secure/attachment/12675023/KAFKA-1637_2014-10-15_09%3A08%3A12.patch","16/Oct/14 05:47;ewencp;KAFKA-1637_2014-10-15_14:47:21.patch;https://issues.apache.org/jira/secure/attachment/12675127/KAFKA-1637_2014-10-15_14%3A47%3A21.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Oct 16 17:39:14 UTC 2014,,,,,,,,,,"0|i204wv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"15/Oct/14 06:04;ewencp;Created reviewboard https://reviews.apache.org/r/26710/diff/
 against branch origin/trunk;;;","15/Oct/14 06:11;ewencp;The error code is for ""UnkownTopicOrPartition"", which may have been correct if the request was for a non-existent topic or partition. Previously the code seemed to be doing the correct thing, reporting this error and returning invalid offset when the consumer hadn't started reading from that group. But KAFKA-1012 (a670537aa337) actually changed that behavior. The provided patch tries to cover the different possible scenarios (missing topic, invalid partition, and valid TopicAndPartition but a consumer with no offset for it).

One potential caveat is auto topic creation since it could be reasonable to not return UnkownTopicOrPartition for a missing topic in that case. I'm not sure we really want different behavior in that case though.;;;","15/Oct/14 12:50;nehanarkhede;Thanks for the patch. Pushed to trunk and 0.8.2;;;","15/Oct/14 13:34;jjkoshy;-1 on this patch per the comment in the RB. Reverted it for now.;;;","15/Oct/14 21:51;nehanarkhede;Wups. Didn't mean to push the patch for this JIRA. Sorry! 
Had a suggestion myself for not using the replica manager which didn't get published by reviewboard.;;;","16/Oct/14 00:08;ewencp;Updated reviewboard https://reviews.apache.org/r/26710/diff/
 against branch origin/trunk;;;","16/Oct/14 05:24;nehanarkhede;[~ewencp] Your latest patch looks good. Once you've addressed [~jjkoshy]'s latest comment, I'll push it to trunk and 0.8.2;;;","16/Oct/14 05:47;ewencp;Updated reviewboard https://reviews.apache.org/r/26710/diff/
 against branch origin/trunk;;;","17/Oct/14 01:39;nehanarkhede;Pushed updated patch to trunk and 0.8.2;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
shutdown kafka when there is any disk IO error,KAFKA-55,12514692,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,,,20/Jul/11 05:32,20/Jul/11 05:32,22/Mar/23 15:10,20/Jul/11 05:32,,,,,,,0.6,,,,,,,,,,,0,,,,,,"Currently, if we encounter any IO error while writing to a kafka log, we simply log the error and continue. However, this kind of errors could leave the log in a corrupted state (e.g., only part of a message is added to the log). When this happens, we should stop accepting new requests and force kafka to shutdown. Once kafka is restarted, log recovery can clean up any corrupted log.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,67473,,,2011-07-19 21:32:24.0,,,,,,,,,,"0|i15ypz:",242925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Write duplicate messages during broker failure,KAFKA-908,12647977,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,nehanarkhede,tscurtu,tscurtu,16/May/13 23:43,01/Sep/17 02:34,22/Mar/23 15:10,01/Sep/17 02:34,0.8.0,,,,,,,,,,,,,replication,,,,0,,,,,,"Reproduction steps:
1. Start a multi-broker quorum (e.g. 3 brokers)
2. Create a multi-replica topic (e.g. 3 replicas)
3. Start an async performance producer with a fixed number of messages to produce
4. Force kill a partition leader broker using SIGKILL (no clean shutdown) - make sure you kill it during actual writes
5. Wait for the producer to stop
6. Read from the topic from the beginning - there will a small amount of duplicate messages

Reproduction rate: sometimes
",,chaitanyap,omkreddy,tscurtu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,328333,,,Thu Aug 31 18:34:04 UTC 2017,,,,,,,,,,"0|i1kndz:",328677,,,,,,,,,,,,,,,,,,,,"01/Sep/17 02:34;omkreddy;Closing inactive issue. Pl reopen if you think the issue still exists;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multiple Unit Test failures with new producer,KAFKA-1366,12707029,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,guozhang,guozhang,08/Apr/14 05:18,09/Apr/14 01:15,22/Mar/23 15:10,09/Apr/14 01:15,,,,,,,,,,,,,,,,,,0,,,,,,"Current known failed tests include

1. Log4jAppenderTest
2. ProducerFailureHandlingTest

These tests failed mainly due to the config changes in KAFKA-1337, some others due to the async mode of the new producer.",,guozhang,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Apr/14 07:00;guozhang;KAFKA-1366.patch;https://issues.apache.org/jira/secure/attachment/12639087/KAFKA-1366.patch","08/Apr/14 07:12;guozhang;KAFKA-1366_2014-04-07_16:12:00.patch;https://issues.apache.org/jira/secure/attachment/12639089/KAFKA-1366_2014-04-07_16%3A12%3A00.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,385352,,,Tue Apr 08 17:15:33 UTC 2014,,,,,,,,,,"0|i1udwv:",385619,,,,,,,,,,,,,,,,,,,,"08/Apr/14 07:00;guozhang;Created reviewboard https://reviews.apache.org/r/20109/
 against branch origin/trunk;;;","08/Apr/14 07:12;guozhang;Updated reviewboard https://reviews.apache.org/r/20109/
 against branch origin/trunk;;;","09/Apr/14 01:15;nehanarkhede;Committed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
switching to gzip compression no error message for missing snappy jar on classpath,KAFKA-1037,12666353,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,charmalloc,charmalloc,31/Aug/13 00:55,08/Sep/17 17:25,22/Mar/23 15:10,08/Sep/17 17:25,,,,,,,,,,,,,,,,,,2,noob,,,,,seems to be swallowed by not setting the log4j.properties but shows up when this and setting to DEBUG ,,AndrewStein,charmalloc,MrCarlosRendon,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1039,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,346292,,,Fri Sep 08 09:25:27 UTC 2017,,,,,,,,,,"0|i1nprb:",346593,,,,,,,,,,,,,,,,,,,,"03/Mar/16 07:10;AndrewStein;This is a severe issue AFAIK. It took three of us three days to track down why our kafka messages were disappearing. At a minimum, if one cannot revert easily to ""gzip"" or ""none"" for compression, this should be logged as an ERROR.;;;","08/Sep/17 17:25;omkreddy;This has been fixed in newer versions.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix for KAFKA-2235 LogCleaner offset map overflow causes another compaction failures,KAFKA-2303,12841039,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,guozhang,alexdemthk,alexdemthk,27/Jun/15 09:37,05/Dec/16 20:40,22/Mar/23 15:10,05/Dec/16 20:40,0.8.2.1,,,,,,,,,,,,,core,log,,,0,,,,,,"We have rolled out the patch for KAFKA-2235 to our kafka cluster, and recently instead of 
{code}
""kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Error due to
java.lang.IllegalArgumentException: requirement failed: Attempt to add a new entry to a full offset map."" 
{code}
we started to see 
{code}
kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Error due to
java.lang.IllegalArgumentException: requirement failed: 131390902 messages in segment <topic-name>-cgstate-8/00000000000079840768.log but offset map can fit only 80530612. You can increase log.cleaner.dedupe.buffer.size or decrease log.cleaner.threads
{code}
So, we had to roll it back to avoid disk depletion although I'm not sure if it needs to be rolled back in trunk. This patch applies more strict checks than were in place before: even if there is only one unique key for a segment, cleanup will fail if this segment is too big. 


Does it make sense to eliminate a limit for the offset map slots count, for example to use an offset map backed by a memory mapped file?

The limit of 80530612 slots comes from memory / bytesPerEntry, where memory is Int.MaxValue (we use only one cleaner thread) and bytesPerEntry is 8 + digest hash size. Might be wrong, but it seems if the overall number of unique keys per partition is more than 80M slots in an OffsetMap, compaction will always fail and cleaner thread will die. 
",,alexdemthk,becket_qin,ijuma,ivan.simonenko,mrlabbe,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3587,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Dec 05 12:40:09 UTC 2016,,,,,,,,,,"0|i2gkq7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"11/Jul/15 03:05;becket_qin;Would the following help solve the issue?
1. Make log.cleaner.min.cleanable.ratio to be smaller
2. Make log.cleaner.backoff.ms smaller
It is supposedly make each cleaning scan over less records but do the cleaning more frequently. That should help a little bit.;;;","28/Jul/15 02:08;alexdemthk;I think in our case we had too many unique keys per partition, so making compactions to happen more frequently will not ultimately solve the issue.
Increasing partitions number should help, but it requires more careful planning about the compacted topic overall data volumes.;;;","05/Dec/16 20:40;ijuma;I think this is a duplicate of KAFKA-3894. Please reopen if you disagree.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""alter topic"" on non-existent topic exits without error",KAFKA-2685,12907119,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,gwenshap,gwenshap,22/Oct/15 23:40,11/Jan/16 23:17,22/Mar/23 15:10,11/Jan/16 23:17,,,,,,,,,,,,,,,,,,0,,,,,,"When running:
kafka-topics --zookeeper localhost:2181 --alter --topic test --config unclean.leader.election.enable=false

and topic ""test"" does not exist, the command simply return with no error message.

We expect to see an error when trying to modify non-existing topics, so user will have a chance to catch and correct typos.",,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2198,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,2015-10-22 15:40:49.0,,,,,,,,,,"0|i2ndxj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Windows: Error: Could not find or load main class org.apache.zookeeper.server.quorum.QuorumPeerMain,KAFKA-1608,12735821,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,,rakesh.komulwad,rakesh.komulwad,22/Aug/14 00:19,09/Sep/17 00:14,22/Mar/23 15:10,09/Sep/17 00:14,0.8.1.1,,,,,,,,,,,,,core,,,,0,windows,,,,,"When trying to start zookeeper getting the following error in Windows

Error: Could not find or load main class org.apache.zookeeper.server.quorum.QuorumPeerMain

Fix for this is to edit windows\kafka-run-class.bat

Change
set BASE_DIR=%CD%\..
to
set BASE_DIR=%CD%\..\..

Change
for %%i in (%BASE_DIR%\core\lib\*.jar)
to
for %%i in (%BASE_DIR%\libs\*.jar)
",Windows,omkreddy,rakesh.komulwad,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Sep 08 16:14:17 UTC 2017,,,,,,,,,,"0|i1z6vb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"09/Sep/17 00:14;omkreddy; This was fixed in newer versions. Pl reopen if you think the issue still exists
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
partition-reassignment tool stops working due to error in registerMetric,KAFKA-2730,12910012,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,guozhang,junrao,junrao,03/Nov/15 23:03,06/Nov/15 07:43,22/Mar/23 15:10,05/Nov/15 02:24,,,,,,,0.9.0.0,,,,,,,core,,,,0,,,,,,"I updated our test system to use Kafka from latest revision 7c33475274cb6e65a8e8d907e7fef6e56bc8c8e6 and now I'm seeing:

[2015-11-03 14:07:01,554] ERROR [KafkaApi-2] error when handling request Name:LeaderAndIsrRequest;Version:0;Controller:3;ControllerEpoch:1;CorrelationId:5;ClientId:3;Leaders:BrokerEndPoint(3,192.168.60.168,21769);PartitionState:(5c700e33-9230-4219-a3e1-42574c175d62-logs,0) -> (LeaderAndIsrInfo:(Leader:3,ISR:3,LeaderEpoch:1,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:2,3,1) (kafka.server.KafkaApis)
java.lang.IllegalArgumentException: A metric named 'MetricName [name=connection-close-rate, group=replica-fetcher-metrics, description=Connections closed per second in the window., tags={broker-id=3}]' already exists, can't register another one.
at org.apache.kafka.common.metrics.Metrics.registerMetric(Metrics.java:285)
at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:177)
at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:162)
at org.apache.kafka.common.network.Selector$SelectorMetrics.<init>(Selector.java:578)
at org.apache.kafka.common.network.Selector.<init>(Selector.java:112)
at kafka.server.ReplicaFetcherThread.<init>(ReplicaFetcherThread.scala:69)
at kafka.server.ReplicaFetcherManager.createFetcherThread(ReplicaFetcherManager.scala:35)
at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:83)
at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:78)
at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
at scala.collection.immutable.Map$Map1.foreach(Map.scala:109)
at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
at kafka.server.AbstractFetcherManager.addFetcherForPartitions(AbstractFetcherManager.scala:78)
at kafka.server.ReplicaManager.makeFollowers(ReplicaManager.scala:791)
at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:628)
at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:114)
at kafka.server.KafkaApis.handle(KafkaApis.scala:71)
at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
at java.lang.Thread.run(Thread.java:745)

This happens when I'm running kafka-reassign-partitions.sh. As a result in the verify command one of the partition reassignments says ""is still in progress"" forever.
",,githubbot,guozhang,gwenshap,junrao,Ormod,ScottReynolds,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 05 23:43:59 UTC 2015,,,,,,,,,,"0|i2nvrz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"04/Nov/15 02:53;gwenshap;[~guozhang] - I assigned this to you since you mentioned working on it. Feel free to reassign if you are not.;;;","04/Nov/15 03:11;guozhang;Thanks [~gwenshap], yes I am working on this now.;;;","04/Nov/15 04:53;Ormod;Answering Guozhang Wang's question on the mailing list here: 

Yes the servers all have the same version. (and were just raised up with that version from scratch)
 
As for the request logs logged by the server i.e. on INFO)? I'm afraid the VM with the logs was deleted already. I can reproduce it tomorrow when I'm at the office again if needed. (it reproduced consistently for us)

As background the test cluster is a two node cluster with a replication factor of 2 which is being grown to add a third node. The reassign partitions is called on the third node pretty much immediately after Kafka starts up and starts responding.

;;;","04/Nov/15 07:20;guozhang;Thanks [~Ormod], did you use enable any security features in your system tests? Also could you share the Kafka server config values, particularly ""num.replica.fetchers""?;;;","04/Nov/15 15:48;Ormod;No security features were in use in this particular setup. Here are the config settings:

            ""default.replication.factor"": 2,
            ""log.cleaner.enable"": ""true"",
            ""log.retention.bytes"": 4 * units.Gi,
            ""log.retention.check.interval.ms"": 300000,
            ""log.retention.hours"": 168,
            ""log.segment.bytes"": 200 * units.Mi,
            ""num.io.threads"": 8,
            ""num.network.threads"": 8,
            ""num.partitions"": 1,
            ""num.replica.fetchers"": 4,
            ""num.recovery.threads.per.data.dir"": 1,
            ""zookeeper.connection.timeout.ms"": 6000

As an unrelated sidenote on security features I tried setting up SSL a while back but somehow when more than one broker was added the interbroker communication collapsed for whatever reason.  The idea was to actually try to get that working now but then I ran into this. :) Once this one gets sorted I'll give that another spin and open issues if I find any.

I'll try to reproduce this today and attach some logs. ;;;","04/Nov/15 15:58;guozhang;Thanks [~Ormod], could you try the following in your experiment:

1) set ""num.replica.fetchers"" to 1 and re-run your settings.
2) still keep ""num.replica.fetchers"" as 4 and apply the patch below and re-run your settings:

https://github.com/apache/kafka/pull/416;;;","04/Nov/15 16:00;Ormod;Sure, will do. I'll report back in a couple of hours.;;;","04/Nov/15 19:49;Ormod;Both the workaround (solution 1) and the actual patch (2) seem to work fine when testing by hand or against our automated tests. 

Thanks for the quick solution.;;;","05/Nov/15 01:42;guozhang;Great to hear that, will merge the patch to trunk to be include in the 0.9.0 release.

Thanks for reporting.;;;","05/Nov/15 02:24;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/416
;;;","05/Nov/15 02:24;gwenshap;Issue resolved by pull request 416
[https://github.com/apache/kafka/pull/416];;;","06/Nov/15 04:22;githubbot;GitHub user guozhangwang opened a pull request:

    https://github.com/apache/kafka/pull/434

    MINOR: follow-up KAFKA-2730 to use two tags for broker id and fetcher id combination

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/guozhangwang/kafka K2730-hotfix

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/434.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #434
    
----
commit d502b30fbc375774c41ad95efab8cb32e071f6d1
Author: Guozhang Wang <wangguoz@gmail.com>
Date:   2015-11-05T20:26:37Z

    v1

----
;;;","06/Nov/15 07:43;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/434
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka broker throws OutOfMemory error with invalid SASL packet,KAFKA-3169,12935093,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,rsivaram,rsivaram,rsivaram,29/Jan/16 20:09,02/Feb/16 23:43,22/Mar/23 15:10,02/Feb/16 23:43,0.9.0.0,,,,,,0.9.0.1,,,,,,,security,,,,0,,,,,,"Receive buffer used in Kafka servers to process SASL packets is unbounded. This can results in brokers crashing with OutOfMemory error when an invalid SASL packet is received. 

There is a standard SASL property in Java _javax.security.sasl.maxbuffer_ that can be used to specify buffer size. When properties are added to the Sasl implementation in KAFKA-3149, we can use the standard property to limit receive buffer size. 

But since this is a potential DoS issue, we should set a reasonable limit in 0.9.0.1. ",,githubbot,ijuma,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Feb 02 15:43:34 UTC 2016,,,,,,,,,,"0|i2s56v:",9223372036854775807,,harsha_ch,,,,,,,,,,,,,,,,,,"29/Jan/16 21:14;githubbot;GitHub user rajinisivaram opened a pull request:

    https://github.com/apache/kafka/pull/831

    KAFKA-3169: Limit receive buffer size for SASL packets in broker

    Limit receive buffer size to avoid OOM in broker with invalid SASL packets

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/rajinisivaram/kafka KAFKA-3169

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/831.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #831
    
----
commit add436b8d3ad03f1189547bb4bfac824295d7e63
Author: Rajini Sivaram <rajinisivaram@googlemail.com>
Date:   2016-01-29T13:02:08Z

    KAFKA-3169: Limit receive buffer size for SASL packets to avoid broker OOM with invalid packets

----
;;;","30/Jan/16 19:35;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/831
;;;","02/Feb/16 23:43;ijuma;This was merged to both trunk and 0.9.0.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"javadoc compile error due to illegal <p/> , build failing (jdk 8)",KAFKA-2294,12839621,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jeff.maxwell,jfields,jfields,23/Jun/15 02:00,17/May/16 22:16,22/Mar/23 15:10,24/Jun/15 01:57,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Quick one,

kafka/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java:525: error: self-closing element not allowed
     * <p/>

This is causing build to fail under java 8 due to strict html checking.

Replace that <p/> with <p>

Regards,",,jeff.maxwell,jfields,jghoman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2203,,,,,,,,,,"24/Jun/15 00:25;jeff.maxwell;KAFKA-2294-1.patch;https://issues.apache.org/jira/secure/attachment/12741312/KAFKA-2294-1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jun 23 17:57:23 UTC 2015,,,,,,,,,,"0|i2gckv:",9223372036854775807,,jghoman,,,,,,,,,,,,,,,,,,"24/Jun/15 00:25;jeff.maxwell;Fixed close() javadoc;;;","24/Jun/15 01:53;jghoman;+1.;;;","24/Jun/15 01:57;jghoman;I've committed this to trunk.  Resolving.  Thanks for the patch, Jeff!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Logs can have same offsets causing recovery failure,KAFKA-905,12647785,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriramsub,sriramsub,sriramsub,16/May/13 01:17,11/Jun/13 01:20,22/Mar/23 15:10,04/Jun/13 08:05,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"Consider the following scenario - 

L                       F
1  m1,m2        1 m1,m2
3  m3,m4        3 m3,m4
5  m5,m6        5 m5,m6

HW = 6           HW = 4

Follower goes down and comes back up. Truncates its log to HW

L                             F
1  m1,m2               1 m1,m2
3  m3,m4               3 m3,m4
5  m5,m6

HW = 6            HW = 4

Before follower catches up with the leader, leader goes down and follower becomes the leader. It then gets new messages

F                       L
1  m1,m2        1  m1,m2
3  m3,m4        3  m3,m4
5  m5,m6      10 m5-m10

HW=6              HW=4

follower fetches from offset 7. Since offset 7 is within the compressed message 10 in the leader, the whole message chunk is sent to the follower

F                        L      
1   m1,m2         1  m1,m2
3   m3,m4         3  m3,m4  
5   m5,m6       10  m5-m10
10 m5-m10

HW=4               HW=10

The follower logs now contain the same offsets. On recovery, re-indexing will fail due to repeated offsets.

Possible ways to fix this - 
1. The fetcher thread can do deep iteration instead of shallow iteration and drop the offsets that are less than the log end offset. This would however incur performance hit.
2. To optimize step 1, we could do the deep iteration till the logical offset of the fetched message set is greater than the log end offset of the follower log and then switch to shallow iteration.
3. On recovery we just truncate the active segment and refetch the data.

All the above 3 steps are hacky. The right fix is to ensure we never corrupt the logs. We can incur data loss but should not compromise consistency. For 0.8, the easiest and simplest fix would be 3. ",,jkreps,junrao,lucasrxly,nehanarkhede,sriramsub,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jun/13 08:24;sriramsub;KAFKA-905-trunk.patch;https://issues.apache.org/jira/secure/attachment/12586003/KAFKA-905-trunk.patch","04/Jun/13 07:44;sriramsub;KAFKA-905-v2.patch;https://issues.apache.org/jira/secure/attachment/12585994/KAFKA-905-v2.patch","31/May/13 06:35;sriramsub;KAFKA-905.patch;https://issues.apache.org/jira/secure/attachment/12585495/KAFKA-905.patch","16/May/13 01:24;sriramsub;KAFKA-905.rtf;https://issues.apache.org/jira/secure/attachment/12583339/KAFKA-905.rtf",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,328141,,,Mon Jun 10 17:20:34 UTC 2013,,,,,,,,,,"0|i1km7b:",328485,,,,,,,,,,,,,,,,,,,,"16/May/13 01:24;sriramsub;Attached a file that has the right formatting. JIRA seems to swallow the spaces.;;;","31/May/13 06:35;sriramsub;We have decided to fix this using step 3 above. We just truncate the active segment to the start offset and re-fetch the data.;;;","31/May/13 23:12;junrao;Thanks for the patch. Looks good. Some minor comments:

1. Log: 
1.1 logSegments.get(logSegments.size - 1) is used twice when handling InvalidOffsetExcetpion. Could we just call it once and reuse the result?
1.2 The info logging should probably be warning. Also, it would be useful to log the dir name so that we know the topic/partition.

2. OffsetIndex: It would be useful to include the full file name in the message of the exception so that we know the topic/partition.

3. The patch doesn't compile since it's missing the new file InvalidOffsetExcetpion.;;;","01/Jun/13 01:33;nehanarkhede;Great catch, patch looks good except the new exception file is missing.;;;","01/Jun/13 02:56;jkreps;This patch looks good. One thing worth pointing out is that any corruption will result in deleting the corrupt file which will potentially make it hard to debug.

I am +1 if we have also a patch for trunk.;;;","04/Jun/13 07:44;sriramsub;- made the logging changes
- added the missing file;;;","04/Jun/13 08:05;nehanarkhede;Thanks for v2, committed it to 0.8;;;","04/Jun/13 08:24;sriramsub;changes for trunk;;;","11/Jun/13 01:07;sriramsub;Ping...Take a look at the patch for trunk.;;;","11/Jun/13 01:20;junrao;I have a pending merge from trunk (kafka-896). I'd like to get that in before this patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Configuration example errors,KAFKA-1551,12728368,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,aozeritsky,aozeritsky,aozeritsky,19/Jul/14 18:39,21/Jul/14 02:07,22/Mar/23 15:10,21/Jul/14 02:07,,,,,,,,,,,,,,website,,,,1,,,,,,"A Production Server Config (http://kafka.apache.org/documentation.html#prodconfig) contains error:
{code}
# ZK configuration
zk.connection.timeout.ms=6000
zk.sync.time.ms=2000
{code}
Should be
{code}
# ZK configuration
zookeeper.connection.timeout.ms=6000
zookeeper.sync.time.ms=2000
{code}
",,aozeritsky,jkreps,ovgolovin,suninside,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,406444,,,Sun Jul 20 18:07:06 UTC 2014,,,,,,,,,,"0|i1xxxr:",406464,,,,,,,,,,,,,,,,,,,,"21/Jul/14 02:07;jkreps;Fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Errors after reboot in single node setup,KAFKA-1724,12749836,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriharsha,hakman,hakman,23/Oct/14 02:03,25/Feb/15 06:23,22/Mar/23 15:10,25/Feb/15 06:23,0.8.2.0,,,,,,0.9.0.0,,,,,,,,,,,1,newbie,,,,,"In a single node setup, after reboot, Kafka logs show the following:
{code}
[2014-10-22 16:37:22,206] INFO [Controller 0]: Controller starting up (kafka.controller.KafkaController)
[2014-10-22 16:37:22,419] INFO [Controller 0]: Controller startup complete (kafka.controller.KafkaController)
[2014-10-22 16:37:22,554] INFO conflict in /brokers/ids/0 data: {""jmx_port"":-1,""timestamp"":""1413995842465"",""host"":""ip-10-91-142-54.eu-west-1.compute.internal"",""version"":1,""port"":9092} stored data: {""jmx_port"":-1,""timestamp"":""1413994171579"",""host"":""ip-10-91-142-54.eu-west-1.compute.internal"",""version"":1,""port"":9092} (kafka.utils.ZkUtils$)
[2014-10-22 16:37:22,736] INFO I wrote this conflicted ephemeral node [{""jmx_port"":-1,""timestamp"":""1413995842465"",""host"":""ip-10-91-142-54.eu-west-1.compute.internal"",""version"":1,""port"":9092}] at /brokers/ids/0 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2014-10-22 16:37:25,010] ERROR Error handling event ZkEvent[Data of /controller changed sent to kafka.server.ZookeeperLeaderElector$LeaderChangeListener@a6af882] (org.I0Itec.zkclient.ZkEventThread)
java.lang.IllegalStateException: Kafka scheduler has not been started
        at kafka.utils.KafkaScheduler.ensureStarted(KafkaScheduler.scala:114)
        at kafka.utils.KafkaScheduler.shutdown(KafkaScheduler.scala:86)
        at kafka.controller.KafkaController.onControllerResignation(KafkaController.scala:350)
        at kafka.controller.KafkaController$$anonfun$2.apply$mcV$sp(KafkaController.scala:162)
        at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:138)
        at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:134)
        at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:134)
        at kafka.utils.Utils$.inLock(Utils.scala:535)
        at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:134)
        at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:549)
        at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2014-10-22 16:37:28,757] INFO Registered broker 0 at path /brokers/ids/0 with address ip-10-91-142-54.eu-west-1.compute.internal:9092. (kafka.utils.ZkUtils$)
[2014-10-22 16:37:28,849] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2014-10-22 16:38:56,718] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2014-10-22 16:38:56,850] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2014-10-22 16:38:56,985] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
{code}
The last log line repeats forever and is correlated with errors on the app side.
Restarting Kafka fixes the errors.

Steps to reproduce (with help from the mailing list):
# start zookeeper
# start kafka-broker
# create topic or start a producer writing to a topic
# stop zookeeper
# stop kafka-broker( kafka broker shutdown goes into  WARN Session
0x14938d9dc010001 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn) java.net.ConnectException: Connection refused)
# kill -9 kafka-broker
# restart zookeeper and than kafka-broker leads into the the error above
",,diederik,hakman,junrao,mazhar.shaikh.in,otis,spsusbilla,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1596,,,,,,,,,,,,,,,,"14/Nov/14 09:34;sriharsha;KAFKA-1724.patch;https://issues.apache.org/jira/secure/attachment/12681465/KAFKA-1724.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Feb 24 00:20:56 UTC 2015,,,,,,,,,,"0|i21ghz:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"05/Nov/14 01:31;otis;[~harsha_ch] - I noticed you assigned yourself to this.  Are you working on this by any chance?;;;","05/Nov/14 01:39;sriharsha;[~otis] I started working on this. Will send a patch soon.;;;","05/Nov/14 02:07;otis;Great, thanks!  Still aiming for 0.8.2?;;;","14/Nov/14 09:34;sriharsha;Created reviewboard https://reviews.apache.org/r/28027/diff/
 against branch origin/trunk;;;","14/Nov/14 09:39;sriharsha;[~junrao] [~nehanarkhede]
This issue happens in a single node setup as per above steps. When the user brings up zookeeper and immediately starts a kafka broker 
ZookeeperLeaderElector will be able to read /controller data from zookeeper which will gets deleted as its a ephemeral node triggering
ZookeeperLeaderElector.handleDataDeleted calling KafkaController.onControllerResignation
as it tries shutdown KafkaScheduler which isn't started yet causing it throw up IllegalStateException. Please check the patch. Thanks.
;;;","03/Dec/14 01:18;sriharsha;[~junrao] can you please look at the reply to your review. Please let me know if this approach makes sense or not. I do see the kafka scheduler error in multi broker env too. ;;;","19/Jan/15 01:50;sriharsha;[~junrao] Can you please take a look at my reply to the review. Thanks.;;;","24/Feb/15 07:38;sriharsha;[~junrao] Thanks for the comments on the patch. So it looks like this is already fixed in the trunk.  We can close this JIRA.;;;","24/Feb/15 08:09;junrao;[~sriharsha], so, this is fixed as part of KAFKA-1760?;;;","24/Feb/15 08:20;sriharsha;[~junrao] Yes. We've isStarted in KafkaScheduler which gets set after its started and in shutdown we check isStarted and go through shutdown process.
Tested it  in a cluster to reproduce don't see any errors.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
java.lang.IllegalMonitorStateException thrown in AbstractFetcherThread when handling error returned from simpleConsumer,KAFKA-2048,12785382,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,xiaotao183,xiaotao183,25/Mar/15 09:31,25/Mar/15 11:57,22/Mar/23 15:10,25/Mar/15 11:57,0.8.2.1,,,,,,,,,,,,,consumer,,,,0,,,,,,AbstractFetcherThread will throw java.lang.IllegalMonitorStateException in the catch block of processFetchRequest method. This is because partitionMapLock is not acquired before calling partitionMapCond.await(),,guozhang,xiaotao183,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Mar/15 10:43;xiaotao183;KAFKA-2048.patch;https://issues.apache.org/jira/secure/attachment/12707120/KAFKA-2048.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Mar 25 03:57:20 UTC 2015,,,,,,,,,,"0|i27bav:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"25/Mar/15 10:40;xiaotao183;Patch submitted. Acquire partitionMapLock explicitly before calling partitionMapCond.await();;;","25/Mar/15 11:57;guozhang;Thanks for the patch [~xiaotao183], +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New producer metadata response handling should only exclude a PartitionInfo when its error is LEADER_NOT_AVAILABLE,KAFKA-1609,12736149,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,lindong,lindong,lindong,23/Aug/14 03:56,23/Aug/14 08:06,22/Mar/23 15:10,23/Aug/14 08:06,,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"The new producer is not able to produce data when it sees ReplicaNotAvailable error, even when the leader of the replica is still available. 

This behavior is different from old producer, which says ""any other error code (e.g. ReplicaNotAvailable) can be ignored since the producer does not need to access the replica and isr metadata"".

To reproduce the error:
1) Start 4 brokers
2) Create a topic of 1 partition using a replication factor of 3.
3) Start producerPerformance with new producer
4) Kill the leader of the topic/partition
5) Kill the new leader of the topic/partition
6) Observe that the producerPerformance stops producing data.




",,junrao,lindong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Aug/14 03:58;lindong;KAFKA-1609.patch;https://issues.apache.org/jira/secure/attachment/12663727/KAFKA-1609.patch","23/Aug/14 04:04;lindong;KAFKA-1609_2014-08-22_13:04:10.patch;https://issues.apache.org/jira/secure/attachment/12663728/KAFKA-1609_2014-08-22_13%3A04%3A10.patch","23/Aug/14 07:22;lindong;KAFKA-1609_2014-08-22_16:22:00.patch;https://issues.apache.org/jira/secure/attachment/12663791/KAFKA-1609_2014-08-22_16%3A22%3A00.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Aug 23 00:06:20 UTC 2014,,,,,,,,,,"0|i1z8tz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"23/Aug/14 03:58;lindong;Created reviewboard https://reviews.apache.org/r/24992/diff/
 against branch origin/trunk;;;","23/Aug/14 04:04;lindong;Updated reviewboard https://reviews.apache.org/r/24992/diff/
 against branch origin/trunk;;;","23/Aug/14 07:22;lindong;Updated reviewboard https://reviews.apache.org/r/24992/diff/
 against branch origin/trunk;;;","23/Aug/14 08:06;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OffsetRequest handler does not handle errors,KAFKA-523,12608661,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,,mumrah,mumrah,22/Sep/12 00:18,22/Apr/17 06:55,22/Mar/23 15:10,22/Apr/17 06:55,0.7.1,,,,,,,,,,,,,core,,,,0,,,,,,"There is not error handling in the KafkaRequestHandlers#handleOffsetRequest, as a result invalid requests get no data back since they raise an Exception in the server.

",,guozhang,jjkoshy,mumrah,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,299156,,,Fri Apr 21 22:55:10 UTC 2017,,,,,,,,,,"0|i15zxz:",243123,,,,,,,,,,,,,,,,,,,,"22/Sep/12 00:20;mumrah;E.g., I make an OffsetRequest for an invalid partition I get no response on the client side, and I see the following exception in Kafka server logs:

{code}
    kafka.common.InvalidPartitionException: wrong partition 10
      at kafka.log.LogManager.getOrCreateLog(LogManager.scala:169)
      at kafka.server.KafkaRequestHandlers.handleOffsetRequest(KafkaRequestHandlers.scala:130)
      at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$5.apply(KafkaRequestHandlers.scala:47)
      at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$5.apply(KafkaRequestHandlers.scala:47)
      at kafka.network.Processor.handle(SocketServer.scala:289)
      at kafka.network.Processor.read(SocketServer.scala:312)
      at kafka.network.Processor.run(SocketServer.scala:207)
      at java.lang.Thread.run(Thread.java:680)
{code}
;;;","22/Sep/12 01:13;jjkoshy;This will be addressed as part of KAFKA-501. It requires a wire-format change though so it will be in 0.8.;;;","21/Apr/17 03:21;jozi-k;The specified method does not exist anymore. Does it mean this issue can be closed?;;;","22/Apr/17 06:55;guozhang;I think this issue has already been fixed in {{handleListOffsetRequest}}. Closing for now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Class CommitThread overwrite group of Thread class causing compile errors,KAFKA-1959,12775394,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,tongli,tongli,tongli,16/Feb/15 23:57,12/Mar/15 12:04,22/Mar/23 15:10,18/Feb/15 15:54,,,,,,,0.9.0.0,,,,,,,core,,,,0,newbie,,,,,"class CommitThread(id: Int, partitionCount: Int, commitIntervalMs: Long, zkClient: ZkClient)
        extends ShutdownableThread(""commit-thread"")
        with KafkaMetricsGroup {

    private val group = ""group-"" + id

group overwrite class Thread group member, causing the following compile error:

overriding variable group in class Thread of type ThreadGroup;  value group has weaker access privileges; it should not be private",scala 2.10.4,jjkoshy,tongli,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Feb/15 00:37;tongli;KAFKA-1959.patch;https://issues.apache.org/jira/secure/attachment/12699130/KAFKA-1959.patch","17/Feb/15 03:24;tongli;compileError.png;https://issues.apache.org/jira/secure/attachment/12699149/compileError.png",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Feb 18 07:54:36 UTC 2015,,,,,,,,,,"0|i25omn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"17/Feb/15 00:11;tongli;Though  I saw the error by using scala 2.10.4,  I think it will be the same error in other scala versions. ;;;","17/Feb/15 00:37;tongli;Created reviewboard https://reviews.apache.org/r/31088/diff/
 against branch origin/trunk;;;","18/Feb/15 15:54;jjkoshy;Thanks for the patch - committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Typographical Errors in Output,KAFKA-968,12657135,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Trivial,Fixed,nehanarkhede,rsealfon,rsealfon,11/Jul/13 03:23,15/Jul/13 05:24,22/Mar/23 15:10,15/Jul/13 05:24,0.8.0,,,,,,0.8.0,,,,,,,core,replication,,,0,partition,typo,,,,"The word ""partition"" is referred to as ""partion"" in system_test/replication_testsuite/testcase_0106/testcase_0106_properties.json line 2 and core/src/main/scala/kafka/server/AbstractFetcherManager.scala line 49.  This typo may interfere with text-based searching of output.",Kafka was run on GNU/Linux x86_64 but this is relevant to all environments,rsealfon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,300,300,,0%,300,300,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,337358,,,Sun Jul 14 21:24:20 UTC 2013,,,,,,,,,,"0|i1m6u7:",337681,,,,,,,,,,,,,,,,,,,,"15/Jul/13 05:24;rsealfon;I checked the repository and this seems to have been fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
System tests don't handle errors well,KAFKA-1746,12752503,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,ewencp,ewencp,04/Nov/14 03:43,07/Nov/14 10:16,22/Mar/23 15:10,07/Nov/14 10:16,0.8.1.1,,,,,,0.9.0.0,,,,,,,system tests,,,,0,,,,,,"The system test scripts don't handle errors well. A couple of key issues:

* Unexpected exceptions during tests are just ignored and the tests appear to be successful in the reports.
* The scripts exit code is always 0, even if tests fail.
* Almost no subprocess calls are checked. In a lot of cases this is ok, and sometimes it's not possible (e.g. after starting a long-running remote process), but in some cases such as calls to DumpLogSegments, the tests can miss that the tools is exiting with an exception and the test appears to be successful even though no data was verified.
",,ewencp,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Nov/14 03:46;ewencp;KAFKA-1746.patch;https://issues.apache.org/jira/secure/attachment/12679007/KAFKA-1746.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 07 02:16:33 UTC 2014,,,,,,,,,,"0|i21wnz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"04/Nov/14 03:46;ewencp;Created reviewboard https://reviews.apache.org/r/27534/diff/
 against branch origin/trunk;;;","07/Nov/14 10:16;nehanarkhede;Thanks for the patch! Pushed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
File system errors are not detected unless Kafka tries to write,KAFKA-1860,12767215,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,mgharat,guozhang,guozhang,14/Jan/15 02:52,02/Feb/16 06:42,22/Mar/23 15:10,02/Feb/16 06:42,,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"When the disk (raid with caches dir) dies on a Kafka broker, typically the filesystem gets mounted into read-only mode, and hence when Kafka tries to read the disk, they'll get a FileNotFoundException with the read-only errno set (EROFS).

However, as long as there is no produce request received, hence no writes attempted on the disks, Kafka will not exit on such FATAL error (when the disk starts working again, Kafka might think some files are gone while they will reappear later as raid comes back online). Instead it keeps spilling exceptions like:

{code}
2015/01/07 09:47:41.543 ERROR [KafkaScheduler] [kafka-scheduler-1] [kafka-server] [] Uncaught exception in scheduled task 'kafka-recovery-point-checkpoint'
java.io.FileNotFoundException: /export/content/kafka/i001_caches/recovery-point-offset-checkpoint.tmp (Read-only file system)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:206)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:156)
	at kafka.server.OffsetCheckpoint.write(OffsetCheckpoint.scala:37)
{code}",,githubbot,guozhang,ijuma,jonbringhurst,mgharat,mitake,ozawa,suda,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Mar/15 04:56;mgharat;KAFKA-1860.patch;https://issues.apache.org/jira/secure/attachment/12705187/KAFKA-1860.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Feb 01 22:41:44 UTC 2016,,,,,,,,,,"0|i24bof:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"18/Mar/15 04:56;mgharat;Created reviewboard https://reviews.apache.org/r/32172/diff/
 against branch origin/trunk;;;","04/Aug/15 00:29;mgharat;[~guozhang] ping.;;;","18/Dec/15 01:26;ijuma;Maybe worth filing a PR with this change.;;;","18/Dec/15 01:41;mgharat;Cool.;;;","19/Dec/15 07:04;githubbot;GitHub user MayureshGharat opened a pull request:

    https://github.com/apache/kafka/pull/697

    KAFKA-1860

    The JVM should stop if the underlying file system goes in to Read only mode

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/MayureshGharat/kafka kafka-1860

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/697.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #697
    
----
commit 5c7f2e749fd8674bae66b6698319181a0f3e9251
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2015-12-18T18:28:32Z

    Added topic-partition information to the exception message on batch expiry in RecordAccumulator

commit 140d89f33171d665ec27839e8589f2055dc2a34b
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2015-12-18T19:02:49Z

    Made the exception message more clear explaining why the batches expired

----
;;;","19/Dec/15 07:16;githubbot;Github user MayureshGharat closed the pull request at:

    https://github.com/apache/kafka/pull/697
;;;","19/Dec/15 07:22;githubbot;GitHub user MayureshGharat opened a pull request:

    https://github.com/apache/kafka/pull/698

    KAFKA-1860

    The JVM should stop if the underlying file system goes in to Read only mode

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/MayureshGharat/kafka KAFKA-1860

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/698.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #698
    
----
commit 4ba2186fbeeeef422395387254d3201f53bc6707
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2015-12-18T23:21:01Z

    The JVM should stop if the underlying file system goes in to Read only mode

----
;;;","23/Jan/16 05:33;mgharat;[~guozhang] can you take another look at the PR? I have included most of the comments on the PR. ;;;","02/Feb/16 06:41;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/698
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replica fetcher thread need to back off upon getting errors on partitions,KAFKA-1629,12740687,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,guozhang,guozhang,11/Sep/14 13:38,08/Oct/16 01:03,22/Mar/23 15:10,17/Sep/14 23:41,,,,,,,,,,,,,,,,,,0,newbie++,,,,,"ReplicaFetcherThread's handlePartitionsWithErrors() function needs to be implemented (currently it is an empty function) such that upon getting errors on these partitions, the fetcher thread will back off the corresponding simple consumer to retry fetching that partition.

This can happen when there is leader migration, the replica may get a bit delayed receiving the leader ISR update request before keeping retry fetching the old leader.",,abhioncbr,guozhang,vanyatka,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,2014-09-11 05:38:34.0,,,,,,,,,,"0|i1zwuf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gaps in messages delivered by new consumer after Kafka restart,KAFKA-2891,12916172,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,,rsivaram,rsivaram,25/Nov/15 23:04,04/Dec/15 05:15,22/Mar/23 15:10,04/Dec/15 05:15,0.9.0.0,,,,,,,,,,,,,consumer,,,,0,,,,,,"Replication tests when run with the new consumer with SSL/SASL were failing very often because messages were not being consumed from some topics after a Kafka restart. The fix in KAFKA-2877 has made this a lot better. But I am still seeing some failures (less often now) because a small set of messages are not received after Kafka restart. This failure looks slightly different from the one before the fix for KAFKA-2877 was applied, hence the new defect. The test fails because not all acked messages are received by the consumer, and the number of messages missing are quite small.

[~benstopford] Are the upgrade tests working reliably with KAFKA-2877 now?

Not sure if any of these log entries are important:
{quote}
[2015-11-25 14:41:12,342] INFO SyncGroup for group test-consumer-group failed due to NOT_COORDINATOR_FOR_GROUP, will find new coordinator and rejoin (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[2015-11-25 14:41:12,342] INFO Marking the coordinator 2147483644 dead. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[2015-11-25 14:41:12,958] INFO Attempt to join group test-consumer-group failed due to unknown member id, resetting and retrying. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[2015-11-25 14:41:42,437] INFO Fetch offset null is out of range, resetting offset (org.apache.kafka.clients.consumer.internals.Fetcher)
{quote}",,benstopford,hachikuji,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Dec 03 21:15:33 UTC 2015,,,,,,,,,,"0|i2oxjj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"25/Nov/15 23:09;benstopford;Yes. I get something similar. Worked fine for about six runs then got a run with:

At least one acked message did not appear in the consumed messages. acked_minus_consumed: set([29073, 29067, 29076, 29070, 29079])

Which i have not seen before (i.e. just a few messages missing). 

The five messages were produced at 11:29:19. Interestingly this time corresponds to the consumer's first notifications that the coordinator is dead (below). These come a few secs after the second node (of 3) is shutdown.

{quote}
[2015-11-25 11:28:55,958] INFO Kafka version : 0.9.1.0-SNAPSHOT (org.apache.kafka.common.utils.AppInfoParser)
[2015-11-25 11:28:55,958] INFO Kafka commitId : 6f3c8e2c5079f00e (org.apache.kafka.common.utils.AppInfoParser)
[2015-11-25 11:29:02,628] INFO Attempt to heart beat failed since member id is not valid, reset it and try to re-join group. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[2015-11-25 11:29:02,649] ERROR Error ILLEGAL_GENERATION occurred while committing offsets for group unique-test-group-0.206159604113 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2015-11-25 11:29:02,649] WARN Auto offset commit failed:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2015-11-25 11:29:19,376] INFO Marking the coordinator 2147483644 dead. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[2015-11-25 11:29:19,383] INFO Marking the coordinator 2147483644 dead. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[2015-11-25 11:29:19,386] INFO Marking the coordinator 2147483644 dead. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
{quote};;;","26/Nov/15 02:07;benstopford;So I'm starting to think the problem may be related to https://issues.apache.org/jira/browse/KAFKA-2827 (in my case at least). There are periods where the ISR drops to 1 which it shouldn't do during a clean bounce. Adding artificial pauses between node restarts also appears to remove the problem. Not definitive yet. Just a heads up.  ;;;","26/Nov/15 21:23;rsivaram;[~benstopford] Thank you, it looks like the same problem as KAFKA-2827 in my test logs too. Will rerun the tests when that is fixed.;;;","28/Nov/15 01:35;benstopford;Retracting this comment as it's confusing. ;;;","28/Nov/15 09:09;hachikuji;[~benstopford] To be clear, are you saying that the message gap is on the server side? In other words, the messages were successfully acked by the producer, but were then lost? ;;;","28/Nov/15 18:33;benstopford;Sorry [~hachikuji] - that wasn't clear or well evidenced - I have created a subtask with one investigation in. This suggests an issue although the logging is slightly different. I'll add to it as I discover more. 
https://issues.apache.org/jira/browse/KAFKA-2908;;;","01/Dec/15 19:56;benstopford;[~rsivaram] That sounds reasonable to me. I'm also surprised it works reliably with hard bounce currently like that. Although doesn't it set the min.insync.replicas to 2 in the test constructor?

Note also that there are a couple of examples (in subtasks) of intermittent failures which look consumer related (as data makes it to kafka). Jason kindly took a look at this yesterday with one related fix [KAFKA-2913|https://issues.apache.org/jira/browse/KAFKA-2913]. 


;;;","01/Dec/15 21:43;rsivaram;[~benstopford] Yes, you are right, replication test does set min.insync.replicas, ignore my previous comment. Have deleted the comment to avoid confusion.;;;","01/Dec/15 22:06;benstopford;[~rsivaram] so - in my investigations, even with min.insync.replicas = 2 + clean_shutdown additional pauses are needed between bounces to get long term stability on Ec2. My theory is this is a problem consumer-side because I don't see evidence of data loss in Kafka. Maybe by waiting for the ISR to hit 2 you are getting similar behaviour. Your test is a little more extreme though due to the hard_bounce.   ;;;","01/Dec/15 23:19;rsivaram;[~benstopford] I dont see errors in my local replication test runs when run with PLAINTEXT with either new consumer or old consumer. But it could just be hiding timing issues because the consumer is faster. I will run the tests again tonight with the fix from KAFKA-2913. I am hopeful that once your the issues you are seeing are fixed, the replication tests would just work :-);;;","02/Dec/15 01:18;benstopford;[~rsivaram] The one thing we know for sure is that putting time between bounces solves the problem. Checking for the ISR to have two entries is a good option. You may even need to pad with pauses. It'd be great to get this test merged though, even if we have to go back to refactor it later. ;;;","02/Dec/15 02:04;benstopford;[~rsivaram] I found an error in my analysis of KAFKA-2909 meaning that jira refers to actual data loss. KAFKA-2908 remains a client-side issue. This puts more evidence behind your theory that nodes are being killed before data is replicated. I'll be interested to see if this change is stable on Ec2.;;;","02/Dec/15 07:49;rsivaram;[~benstopford]  The logs from my failing test runs all show the same pattern - min.insync.replicas set to one and messages acked when leader is the only ISR. When the leader gets killed by the test, messages are lost, as you would expect. The test was intended to run with min.insync.replicas set to 2, but due to a bug in the way min.insync.replicas was being set for topics, it was being left as default of one. All tests which currently set min.insync.replicas have copied the same config with the result that the config is never set. I have updated the PR for KAFKA-2642 with a fix for the min.insync.replicas setting in all the tests which set this. Have scheduled a build with the fix and will check the results in the morning.;;;","04/Dec/15 05:15;rsivaram;This was fixed by setting min.insync.replicas=2 correctly in the tests. Closing this since the subtasks have been closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Long topic names mess up broker topic state,KAFKA-3219,12937470,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,vahid,edenhill,edenhill,08/Feb/16 19:20,11/Mar/17 07:01,22/Mar/23 15:10,21/May/16 11:57,0.9.0.0,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"Seems like the broker doesn't like topic names of 254 chars or more when creating using kafka-topics.sh --create.
The problem does not seem to arise when topic is created through automatic topic creation.

How to reproduce:

{code}
TOPIC=$(printf 'd%.0s' {1..254} ) ; bin/kafka-topics.sh --zookeeper 0 --create --topic $TOPIC --partitions 1 --replication-factor 1
{code}

{code}
[2016-02-06 22:00:01,943] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions [dddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd,0] (kafka.server.ReplicaFetcherManager)
[2016-02-06 22:00:01,944] ERROR [KafkaApi-3] Error when handling request {controller_id=3,controller_epoch=12,partition_states=[{topic=dddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd,partition=0,controller_epoch=12,leader=3,leader_epoch=0,isr=[3],zk_version=0,replicas=[3]}],live_leaders=[{id=3,host=eden,port=9093}]} (kafka.server.KafkaApis)
java.lang.NullPointerException
        at scala.collection.mutable.ArrayOps$ofRef$.length$extension(ArrayOps.scala:114)
        at scala.collection.mutable.ArrayOps$ofRef.length(ArrayOps.scala:114)
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:32)
        at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
        at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
        at kafka.log.Log.loadSegments(Log.scala:138)
        at kafka.log.Log.<init>(Log.scala:92)
        at kafka.log.LogManager.createLog(LogManager.scala:357)
        at kafka.cluster.Partition.getOrCreateReplica(Partition.scala:96)
        at kafka.cluster.Partition$$anonfun$4$$anonfun$apply$2.apply(Partition.scala:176)
        at kafka.cluster.Partition$$anonfun$4$$anonfun$apply$2.apply(Partition.scala:176)
        at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
        at kafka.cluster.Partition$$anonfun$4.apply(Partition.scala:176)
        at kafka.cluster.Partition$$anonfun$4.apply(Partition.scala:170)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:259)
        at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:267)
        at kafka.cluster.Partition.makeLeader(Partition.scala:170)
        at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:696)
        at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:695)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
        at kafka.server.ReplicaManager.makeLeaders(ReplicaManager.scala:695)
        at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:641)
        at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:142)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:79)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
        at java.lang.Thread.run(Thread.java:745)
{code}",,edenhill,githubbot,gwenshap,ijuma,vahid,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-4858,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Mar 22 20:10:34 UTC 2016,,,,,,,,,,"0|i2sjtr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"09/Feb/16 03:27;vahid;[~edenhill] I tried the same command above on 0.9.0.0 release and could reproduce the problem. However, when I tried it on the trunk branch it worked fine. It seems it is fixed (perhaps along with some other defect). Could you please double check?;;;","09/Feb/16 05:08;vahid;My apologies. I tried again, and noticed the null pointer exception in server.log. The topic is created though. This is the case for lengths 254 and 255.;;;","09/Feb/16 07:21;vahid;This seems to be somehow related to folder name length limit which is 255.
When creating a topic a folder is created for each of its partitions under the {{kafka-logs}} folder. The name of these folders is the topic name appended by a dash {{-}}, appended by partition id (a number starting from 0). For a given topic name of 254, these folder names will be at least 256 characters long. Even though the topic is created no folder is created for partitions whose folder name length goes above 255. With a topic name of 253 characters long and 11 partitions the same issue occurs because for partition id 10 the folder would not be created.

A potential fix would be to check for the combination of topic name and partition count and disallow combinations that lead to one or more partition folder names of 256 or more characters.

Suggestions are welcome.;;;","09/Feb/16 07:31;ijuma;Seems sensible to fail with a reasonable error if someone attempts to create a topic with a name that is too long. The original description says that this works fine with automatic topic creation. Is that really true?;;;","09/Feb/16 08:04;vahid;I see similar behavior when producing a new topic of length 254. As soon as I send the first message to the topic I see the same exception in the log. Again the topic is there when I try a {{--list}} option, but no partition folder is created for it. Consuming from the topic will also lead to errors.;;;","09/Feb/16 08:05;ijuma;Makes sense, thanks.;;;","11/Feb/16 00:41;githubbot;GitHub user vahidhashemian opened a pull request:

    https://github.com/apache/kafka/pull/898

    KAFKA-3219: Fix long topic name validation

    This fixes an issue with long topic names by considering, during topic
    validation, the '-' and the partition id that is appended to the log
    folder created for each topic partition.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/vahidhashemian/kafka KAFKA-3219

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/898.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #898
    
----
commit 413f1f657b810032c94c8d59908e4bc5e39c26fe
Author: Vahid Hashemian <vahidhashemian@us.ibm.com>
Date:   2016-02-10T16:37:35Z

    KAFKA-3219: Fix long topic name validation
    
    This fixes an issue with long topic names by considering, during topic
    validation, the '-' and the partition id that is appended to the log
    folder created for each topic partition.

----
;;;","23/Mar/16 04:10;gwenshap;Issue resolved by pull request 898
[https://github.com/apache/kafka/pull/898];;;","23/Mar/16 04:10;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/898
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka network thread lacks top exception handler,KAFKA-1804,12758900,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,,ovgolovin,ovgolovin,02/Dec/14 22:41,08/Sep/17 03:32,22/Mar/23 15:10,14/Oct/15 02:21,0.8.2.0,,,,,,0.9.0.0,,,,,,,core,,,,3,,,,,,"We have faced the problem that some kafka network threads may fail, so that jstack attached to Kafka process showed fewer threads than we had defined in our Kafka configuration. This leads to API requests processed by this thread getting stuck unresponed.

There were no error messages in the log regarding thread failure.

We have examined Kafka code to find out there is no top try-catch block in the network thread code, which could at least log possible errors.

Could you add top-level try-catch block for the network thread, which should recover network thread in case of exception?",,aozeritsky,ataraxer,ijuma,jkreps,olindaspider,ovgolovin,sekikn,sriharsha,suninside,vladap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2595,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Oct 13 18:21:50 UTC 2015,,,,,,,,,,"0|i22yrz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"15/Dec/14 20:10;ovgolovin;`kafka-socket-acceptor` has the same problem.;;;","16/Jan/15 06:24;aozeritsky;We've written the simple patch for kafka-network-thread:
{code:java}
  override def run(): Unit = {
    try {
      iteration() // = the original run()
    } catch {
      case e: Throwable => 
        error(""ERROR IN NETWORK THREAD: %s"".format(e), e)
        Runtime.getRuntime.halt(1)
    }
  }
{code}
and got the following trace:
{code}
[2015-01-15 23:04:08,537] ERROR ERROR IN NETWORK THREAD: java.util.NoSuchElementException: None.get (kafka.network.Processor)
java.util.NoSuchElementException: None.get
        at scala.None$.get(Option.scala:313)
        at scala.None$.get(Option.scala:311)
        at kafka.network.ConnectionQuotas.dec(SocketServer.scala:544)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:165)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:157)
        at kafka.network.Processor.close(SocketServer.scala:394)
        at kafka.network.Processor.processNewResponses(SocketServer.scala:426)
        at kafka.network.Processor.iteration(SocketServer.scala:328)
        at kafka.network.Processor.run(SocketServer.scala:381)
        at java.lang.Thread.run(Thread.java:745)
{code};;;","22/Jan/15 03:55;sriharsha;[~jjkoshy] [~aozeritsky] this looks to be similar in nature to KAFKA-1577.  Do you have any steps to reproduce this.;;;","23/Jan/15 00:52;aozeritsky;The last time we saw the bug during restart the network switch on a cluster of 20 machines. kafka-network-threads fell down on more than half machines. As a result, the cluster became unavailable. We are trying to find the specific steps that reproduce the problem.
;;;","08/Feb/15 06:40;jkreps;The remaining issue is the lack of logging. However we actually do set an uncaught exception handler that should log any uncaught exception.  [~aozeritsky] is there any chance this was just showing up in a different log?;;;","28/Sep/15 08:11;olindaspider;I ran into a similar issue where that same ""java.util.NoSuchElementException: None.get"" exception was being thrown in the ConnectionQuotas.dec method. I was able to reproduce it, and I believe I have found the root cause of all cases of these.

The call to ""close(key)"" on this line https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/network/SocketServer.scala#L406 is the culprit. This call should not be done there because, as the debug log on the line just above says, the socket is already closed. In other words, a ""close(key)"" using that key has already occurred. This causes an extra call on ConnectionQuotas.dec against that InetAddress. This sets up the situation where later on during the closing of an actually open key that there is now a None value in ConnectionQuotas count for that InetAddress.

I have a log files if needed.;;;","29/Sep/15 06:09;sriharsha;[~olindaspider] that sounds right to me. Are you planning on sending a patch.;;;","29/Sep/15 06:29;olindaspider;I was not planning on sending a patch. I have it working on my servers, so I am all set. ;;;","12/Oct/15 19:53;vladap;Hello, I just would like to report that this error was thrown after 4 days run on Kafka version: kafka-0.8.2.2-2.11. We were not attempting to shutdown. Unfortunately we were not able to reproduce the error yet. I just want to increase the attention to this issue.

{code}
[2015-10-08 14:40:47,176] ERROR Uncaught exception in thread 'kafka-network-thread-9092-1': (kafka.utils.Utils$)
java.util.NoSuchElementException: None.get
        at scala.None$.get(Option.scala:347)
        at scala.None$.get(Option.scala:345)
        at kafka.network.ConnectionQuotas.dec(SocketServer.scala:524)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:165)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:157)
        at kafka.network.Processor.close(SocketServer.scala:374)
        at kafka.network.Processor.processNewResponses(SocketServer.scala:406)
        at kafka.network.Processor.run(SocketServer.scala:318)
        at java.lang.Thread.run(Thread.java:745)
[2015-10-08 14:40:47,177] INFO Closing socket connection to /10.33.167.154. (kafka.network.Processor)
[2015-10-08 14:40:47,177] INFO Closing socket connection to /10.33.167.154. (kafka.network.Processor)
[2015-10-08 14:40:47,177] INFO Closing socket connection to /10.33.167.154. (kafka.network.Processor)
[2015-10-08 14:40:47,177] ERROR Uncaught exception in thread 'kafka-network-thread-9092-0': (kafka.utils.Utils$)
java.util.NoSuchElementException: None.get
        at scala.None$.get(Option.scala:347)
        at scala.None$.get(Option.scala:345)
        at kafka.network.ConnectionQuotas.dec(SocketServer.scala:524)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:165)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:157)
        at kafka.network.Processor.close(SocketServer.scala:374)
        at kafka.network.Processor.run(SocketServer.scala:350)
        at java.lang.Thread.run(Thread.java:745)
{code};;;","12/Oct/15 20:34;ijuma;Note that the code in trunk looks different and the following code was removed:

{code}
 catch {
        case e: CancelledKeyException => {
          debug(""Ignoring response for closed socket."")
          close(key)
        }
      } 
{code}

There were also some fixes as part of KAFKA-2614.

Furthermore, `Processor.run` and `Acceptor.run` also have try/catch blocks in trunk. All of this code is in `SocketServer.scala`:

https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/network/SocketServer.scala

So, this looks fixed to me. Could one of the people that have pointed out the issue in the code verify that my assessment is correct?;;;","13/Oct/15 01:02;olindaspider;It looks likely fixed in the trunk, but remains an issue in the 0.8.x line.

What is the intention with the trunk changes? Is that an entirely new major version? Is there a road map somewhere explaining what is going on in the trunk development that I missed?;;;","13/Oct/15 01:08;ijuma;trunk will be released as 0.9.0.0, see http://search-hadoop.com/m/uyzND1LUUpN1qRojN1 for the discussion thread where the decision was made to name the next release 0.9.0 instead of 0.8.3.;;;","14/Oct/15 02:21;ijuma;Resolving this as it has been fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Memory records is not writable in MirrorMaker,KAFKA-3147,12933930,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,mgharat,megnarasimhan,megnarasimhan,26/Jan/16 04:27,04/May/16 17:38,22/Mar/23 15:10,04/May/16 17:38,0.9.0.0,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"Hi,
We are running a 3 node cluster (kafka version 0.9) and Node 0 also has a few mirror makers running. 
When we do a rolling restart of the cluster, the mirror maker shuts down with the following errors.

[2016-01-11 20:16:00,348] WARN Got error produce response with correlation id 12491674 on topic-partition test-99, retrying (2147483646 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender)
[2016-01-11 20:16:00,853] FATAL [mirrormaker-thread-0] Mirror maker thread failure due to  (kafka.tools.MirrorMaker$MirrorMakerThread)
java.lang.IllegalStateException: Memory records is not writable
        at org.apache.kafka.common.record.MemoryRecords.append(MemoryRecords.java:93)
        at org.apache.kafka.clients.producer.internals.RecordBatch.tryAppend(RecordBatch.java:69)
        at org.apache.kafka.clients.producer.internals.RecordAccumulator.append(RecordAccumulator.java:168)
        at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:435)
        at kafka.tools.MirrorMaker$MirrorMakerProducer.send(MirrorMaker.scala:593)
        at kafka.tools.MirrorMaker$MirrorMakerThread$$anonfun$run$3.apply(MirrorMaker.scala:398)
        at kafka.tools.MirrorMaker$MirrorMakerThread$$anonfun$run$3.apply(MirrorMaker.scala:398)
        at scala.collection.Iterator$class.foreach(Iterator.scala:742)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1194)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
        at kafka.tools.MirrorMaker$MirrorMakerThread.run(MirrorMaker.scala:398)
[2016-01-11 20:16:01,072] WARN Got error produce response with correlation id 12491679 on topic-partition test-75, retrying (2147483646 attempts left). Error: NETWORK_EXCEPTION (org.apache.kafka.clients.producer.internals.Sender)
[2016-01-11 20:16:01,073] WARN Got error produce response with correlation id 12491679 on topic-partition test-93, retrying (2147483646 attempts left). Error: NETWORK_EXCEPTION (org.apache.kafka.clients.producer.internals.Sender)
[2016-01-11 20:16:01,073] WARN Got error produce response with correlation id 12491679 on topic-partition test-24, retrying (2147483646 attempts left). Error: NETWORK_EXCEPTION (org.apache.kafka.clients.producer.internals.Sender)

[2016-01-11 20:16:20,479] FATAL [mirrormaker-thread-0] Mirror maker thread exited abnormally, stopping the whole mirror maker. (kafka.tools.MirrorMaker$MirrorMakerThread)

Curious if the NOT_LEADER_FOR_PARTITION is because of a potential bug hinted at in the thread , http://mail-archives.apache.org/mod_mbox/kafka-users/201505.mbox/%3CCAJS3ho_u8s1Xou_kudNfjAMyPJtMrjLW10QVkNGn2YQkdan0+A@mail.gmail.com%3E   

And I think the mirror maker shuts down because of the ""abort.on.send.failure"" which is set to true in our case. ",,becket_qin,githubbot,guozhang,ijuma,junrao,kdkavanagh,m1racoli,megnarasimhan,mgharat,omkreddy,piaoyu zhang,stevenschlansker,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed May 04 09:38:56 UTC 2016,,,,,,,,,,"0|i2ry0n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"27/Jan/16 08:47;junrao;I think the issue could be related to ""abort.on.send.failure"". There is a code path where the above error can be hit.

In MirrorMaker, if abortOnSendFailure is enabled, we will call producer.close(0) on send failure. This will call sender.forceClose(), which first sets this.forceClose = true, followed by accumulator.close(). Suppose that the sender wakes up after this.forceClose = true but before accumulator.close(). The sender will call this.accumulator.abortIncompleteBatches(), which eventually closes all batch records in the queue w/o actually dequeuing them. At this moment, if the client sends another record to the producer, it can hit the exception described in the jira.

[~mgharat], this may be introduced in the request timeout patch. Could you take a look and see if the above scenario is possible? Thanks.

;;;","27/Jan/16 10:20;mgharat;[~junrao] I think abortIncompleteBatches was not a part of KIP-19 patch. I will surely like to look in to this though.  ;;;","28/Jan/16 03:23;becket_qin;[~junrao] [~mgharat] I think the issue is what Jun pointed out. I think a simple solution is to put the first close status check in append() into the synchronized(dq) block. This will guarantee either the message append goes through first or it will see the producer is closed.;;;","28/Jan/16 03:28;mgharat;[~becket_qin] sure. I will take a look and upload a PR.;;;","28/Jan/16 09:49;junrao;It also seems that in RecordAccumulator.abortBatches(), if we close a RecordBatch, we should always take it off DQ for consistency.;;;","28/Jan/16 10:16;becket_qin;Yes, we should do that as well.;;;","29/Jan/16 02:49;githubbot;GitHub user MayureshGharat opened a pull request:

    https://github.com/apache/kafka/pull/825

    KAFKA-3147 : Memory records is not writable in MirrorMaker

    Remove the batch from the RecordAccumulator once its closed while aborting batches. Make sure we don't accept new batch appends to RecordAccumulator while the producer is being closed.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/MayureshGharat/kafka KAFKA-3147

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/825.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #825
    
----
commit 088c4666fcd5a5d67e038fef8a0b237c056fe98a
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2016-01-28T18:45:19Z

    Remove the batch from the RecordAccumulator once its closed while aborting batches. Make sure we don't accept new batch appends to RecordAccumulator while the producer is being closed.

----
;;;","12/Feb/16 17:16;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/825
;;;","12/Feb/16 17:16;guozhang;Issue resolved by pull request 825
[https://github.com/apache/kafka/pull/825];;;","02/Mar/16 04:37;kdkavanagh;Any possibility this makes it into a 0.9.x build rather than 0.10?;;;","02/Mar/16 05:40;becket_qin;[~kdkavanagh] The next Kafka release will be 0.10.0. :)  So this fix will be in the next release.;;;","19/Apr/16 22:24;m1racoli;It would be very much appreciated to get fixes for those bugs without relying on a new major version. while 0.10.0.0 comes out there will be high interest in a 0.9.0.2 version for production systems.;;;","04/May/16 17:20;ijuma;Not clear if this has been completely fixed given the following comment in the PR:

{quote}
We patched 0.9.0.0 branch with this pull request. And tested patched version in our load test environment, after ~7 hours we have got same error:

java.lang.IllegalStateException: Memory records is not writable
at org.apache.kafka.common.record.MemoryRecords.append(MemoryRecords.java:93)
at org.apache.kafka.clients.producer.internals.RecordBatch.tryAppend(RecordBatch.java:69)
at org.apache.kafka.clients.producer.internals.RecordAccumulator.append(RecordAccumulator.java:168)

This always happens after next exceptions:
[kafka-producer-network-thread | audiLoadTest] WARN org.apache.kafka.clients.producer.internals.Sender - Got error produce response with correlation id 2274005 on topic-partition mct-3, retrying (1 attempts left). Error: NETWORK_EXCEPTION
{quote}

[~mgharat], thoughts?;;;","04/May/16 17:34;omkreddy;Similar exception scenario is fixed in KAFKA-3594. Above logs indicates, this is due to KAFKA-3594.;;;","04/May/16 17:38;ijuma;Thanks [~omkreddy], closing again.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NetworkClient may connect to a different Kafka cluster than originally configured,KAFKA-3068,12927639,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,enothereska,junrao,junrao,06/Jan/16 08:57,18/Jan/23 19:52,22/Mar/23 15:10,03/Feb/16 01:36,0.9.0.0,,,,,,0.10.0.0,0.9.0.1,,,,,,clients,,,,0,,,,,,"In https://github.com/apache/kafka/pull/290, we added the logic to cache all brokers (id and ip) that the client has ever seen. If we can't find an available broker from the current Metadata, we will pick a broker that we have ever seen (in NetworkClient.leastLoadedNode()).

One potential problem this logic can introduce is the following. Suppose that we have a broker with id 1 in a Kafka cluster. A producer client remembers this broker in nodesEverSeen. At some point, we bring down this broker and use the host in a different Kafka cluster. Then, the producer client uses this broker from nodesEverSeen to refresh metadata. It will find the metadata in a different Kafka cluster and start producing data there.",,enothereska,ewencp,githubbot,guozhang,hachikuji,ijuma,junrao,stevenz3wu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-13653,,,,,,KAFKA-14548,,KAFKA-12480,KAFKA-13467,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Feb 02 17:36:56 UTC 2016,,,,,,,,,,"0|i2qv9b:",9223372036854775807,,ewencp,,,,,,,,,,,,,,,,,,"06/Jan/16 09:02;junrao;[~enothereska], [~ijuma], [~guozhang], [~ewencp], [~hachikuji], since you all worked on that pull request, do you think this is an issue?;;;","06/Jan/16 09:08;guozhang;Even without this caching, we can still potentially hit this issue if Kafka nodes are migrating to a different cluster but with the same host, right?;;;","06/Jan/16 09:09;hachikuji;[~junrao] It does seem like an issue to me (can't believe we all missed it). From memory, I think the problem that the nodesEverSeen collection was trying to solve was what to do when the last node in the cluster becomes unreachable. In this case, the only thing the client can do is keep trying to reconnect to the one node indefinitely (since we have no other ways to discover other nodes in the cluster). By keeping track of the history of nodes, we have an out in this case and we can retry against one of the other nodes that we connected to before. But, as you say, this can lead to other problems. It seems like what we should do in this case is maybe revert to the bootstrap brokers in configuration.;;;","06/Jan/16 09:33;junrao;Yes, without this caching, in theory, this is still possible. However, the window won't be long since the migrated broker will be removed on the next metadata refresh, which will either happen periodically, or when one of the existing connections is lost.;;;","06/Jan/16 09:43;guozhang;That is right... maybe we should just use bootstrap servers as [~hachikuji] suggested.;;;","06/Jan/16 11:09;ijuma;Reverting to the bootstrap brokers in the config seems like a sensible and less surprising option (it is not unreasonable to expect users to have to update the config if they want to move one of the brokers in the config to a different cluster).

This kind of thing does raise the question of whether clusters should be have an identity to prevent accidental usage (this is easily achieved in a secured cluster so that may be enough).;;;","06/Jan/16 23:00;enothereska;[~ijuma], [~hachikuji]: I think a proper solution would make use of a cluster identity in addition to broker id+host. The problems with using bootstrap brokers is that 1) users might not specify enough bootstrap brokers and 2) bootstrap brokers can also move to a different cluster as [~ijuma] points out. While the windows of vulnerability will be small as [~junrao] points out, it will still be a problem. One option would have been to query zookeeper (which is the cluster identity in a way) and get the latest brokers from it instead of caching them in the client. With the new clients that is not an option anymore though.;;;","06/Jan/16 23:23;ijuma;[~enothereska], I agree that a better solution would involve cluster identity, but that seems like a bigger change. The reason is that the new clients should not access ZK directly, only via the Kafka brokers (security being a major reason). With regards to your point (1), I also thought of that, but failed brokers are also an issue when a client is started, so there is a good reason to include a reasonable number of brokers in the bootstrap brokers config.

It seems like if we favour safety and there is no easy way to make use of cluster identity, then we should do the bootstrap brokers config change now and explore the better solution in a subsequent JIRA. Thoughts?;;;","06/Jan/16 23:29;enothereska;[~ijuma]: a slightly different solution would be to keep just the latest N seen nodes (e.g., N = 3). That has the advantage of freshness over keeping the (potentially old) bootstrap brokers. Currently we have N = inf, which means we keep all seen brokers.  ;;;","06/Jan/16 23:36;ijuma;Yeah. Or expire brokers based on time. Let's see what others think. :);;;","07/Jan/16 08:17;hachikuji;[~ijuma],[~enothereska] Introducing a notion of cluster identity seems like a good idea to solve this problem more generally. I'm not sure I understand the point about not having enough bootstrap brokers though. The cached metadata always contains the full list of brokers in the cluster (i.e. those registered in Zookeeper). The only time we might need to dip into an additional set is when all of the known brokers simultaneously become unreachable. When that happens, it seems to make more sense to revert to the list of bootstrap brokers rather than attempting to reach a broker which we discovered previously but had itself became unreachable at some point (if it was still reachable on the last metadata refresh, then it would be contained in the metadata). And yes, the bootstrap brokers can also move to another cluster, but I would consider this a user configuration error rather than an application error. You can hardly fault an application for trying to connect to the endpoints that had been explicitly configured, but you might if it connects to a broker it previously discovered which had been shutdown and moved to another cluster. Does that make sense?;;;","07/Jan/16 08:39;ijuma;It does to me.;;;","07/Jan/16 11:01;junrao;There are 2 possible ways of configuring bootstrap servers: (1) Using a VIP on a load balancer. In the case, we can expect the VIP to map to the current live brokers. (2) Using a list of broker hosts. In this case, it's the user's responsibility to make sure the list is up to date and contains at least one live broker. When we hit a case that none of the current brokers (from last metadata response) is connectable (e.g., the cluster is shrunk to 1 node, then that node dies and other brokers are restarted), falling back to the bootstrap servers will help if option (1) is used since the VIP will allow us to connect to a live broker. If option (2) is used, falling back to the bootstrap servers may not help if none of the bootstrap servers is reachable. However, in this case, it's really the user's responsibility to re-configure bootstrap servers and restart the producer. So, overall, it seems that falling back to bootstrap servers when all existing connections are gone will help.

Now, on caching old brokers long than the metadata refresh interval. Currently, we can say if you ever want to reuse a server in a different Kafka cluster, wait for at least the metadata refresh interval after taking the broker down. If we cache the old brokers longer, this reasoning will be more complicated. Also, from the above, I am not sure if old brokers are more useful than the configured bootstrap servers.

Finally, we discussed to fall back to the bootstrap servers in KAFKA-1303 for a different scenario early on, but didn't pursue that in the end.;;;","07/Jan/16 20:47;enothereska;[~junrao], [~hachikuji] I understand the concerns. What I don't like about using the bootstrap servers is that the problem is punted to the user (to provide enough bootstrap servers, to keep track of whether they have moved and to restart producers when they do so. For a long running cluster of 100+ machines that is hard to do.). [~junrao]: between these two non-ideal solutions do we have a sense which one is the least worst? I can change the code to use the bootstrap brokers but I am worried an equal number of users may be dissatisfied from that. 

So it's between caching the latest N seen brokers or caching the N bootstrap servers. ;;;","07/Jan/16 20:51;enothereska;[~hachikuji]: it boils down to whether the network client wants to cache the latest N brokers seen or cache the N bootstrap brokers. For a long running cluster my intuition is that caching the latest N brokers is best. Currently we cache too many (all) the seen brokers. I think caching the latest N is better than caching the N bootstrap servers.;;;","08/Jan/16 01:41;junrao;[~enothereska], yes, your concerns are valid. When running in the Cloud (say EC2), since broker hosts can change often, some of the users build their own discovery service. On startup, the producer will grab the current broker list from the discovery service and use those to build the bootstrap servers. The expectation is that this list will only be used once when the producer starts up. If we change that behavior by falling back to the bootstrap servers, weird things may happen since the bootstrap servers may not be valid, or worse reused in a different Kafka cluster. Like you said, falling back to old brokers may not be ideal either.

Give that in a common setup, it should be rare to have all brokers returned in metadata response be unreachable, in this jira, we can probably just remove the caching of old brokers and just wait when all brokers are not connectable.

We can do a KIP discussion on improving this (whether to cache old brokers or use bootstrap servers) if we think this is still a significant enough issue. ;;;","08/Jan/16 03:29;hachikuji;We retain in the metadata cache the full list of currently known brokers, so an additional cache wouldn't be helpful unless it contains nodes that were not in the last metadata refresh (in other words, nodes that were not registered at the time of that refresh). I guess that means you'd have to set N at least as large as the maximum size of the cluster to get any benefit from this cache policy. It might be more useful to expire based on time as Ismael suggested since frees the user from tuning N and it's also more predictable. And it's probably never a good idea to try connecting to a node that hasn't been registered for more than an hour. Since this is a last-resort option, reverting to the bootstrap brokers seems simpler and less surprising for users, but as Jun pointed out, its usefulness depends on how the user has configured it.

Anyway, this is a pretty unlikely case to hit in practice since all of the registered brokers have to become unreachable at the same time. For clusters larger than a few nodes, probably the only way this happens is if the client becomes partitioned or if you lose all brokers simultaneously (e.g. from a power outage). For those cases, perhaps the best the client can do anyway is continue retrying with whatever broker list it last knew about. I do think that the bootstrap brokers should also be tried in case the user has configured a VIP.;;;","08/Jan/16 05:29;ewencp;You can get into bad states without losing everything simultaneously, and in situations that aren't unrealistic in practice: see https://issues.apache.org/jira/browse/KAFKA-1843?focusedCommentId=14517659&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14517659;;;","08/Jan/16 05:58;ewencp;[~junrao] It's definitely a real issue -- see https://issues.apache.org/jira/browse/KAFKA-1843?focusedCommentId=14517659&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14517659 where you can get into unrecoverable situations if a Kafka node is decomissioned or in the case of a failure. This doesn't necessarily seem like it would be that rare to me -- sure, it requires there to be failures, but any app that produces to a single topic could encounter a case like this since it'll have a very limited set of brokers to work with. Multiple people reported encountering this issue, although as far as I've seen it may only have been in testing environments: http://mail-archives.apache.org/mod_mbox/kafka-users/201505.mbox/%3CCAJ7fV7qbfQZrD0EoDJmTRq725Q+ZiirnctwJHyhQLdm+5CwR0Q@mail.gmail.com%3E

It sounds like KAFKA-1843 is messy enough that it needs a more complete discussion to resolve and maybe a KIP. Just waiting on the old list doesn't help in the situation described above if there's an actual hardware failure that takes the node out entirely -- eventually you need to try something else. If we're going to change anything now, I'd suggest either making the entries in nodesEverSeen expire but at a longer interval than the metadata refresh or falling back to bootstrap nodes. I think the former is probably the better solution, though the latter may be easier for people to reason about until we work out a more complete solution. The former seems nicer because it decouples the expiration from other failures. Currently a broker failure that triggers a metadata refresh can force that broker out of the set of nodes to try immediately, which is why you can get into situations like the one linked above (and in much less time than the metadata refresh interval since these events force a metadata refresh).

Ultimately, the problem boils down to the fact that we're not getting the information we want from these metadata updates -- we get the info we need about topic leaders, but we're also using this metadata for basic connectivity to the cluster. That breaks down if you're only working with one or a small number of topics and they end up with too few or crashed replicas. I think caching old entries is not the ideal solution here, but it's a way to work around the current situation. It would probably be better if metadata responses could include a random subset of the current set of brokers so that rather than relying on the original bootstrap servers we could get new, definitely valid bootstrap brokers with each metadata refresh. (It might even be possible to implement this just by having the broker return extra brokers in the metadata response even if there aren't entries in the topic metadata section of the response referencing those brokers; but I'm not sure if that'd break anything, either in our clients or in third party clients. It also doesn't fully fix the problem since the linked issue can still occur, but should only ever happen in the case of their tiny test case, not in practice.);;;","08/Jan/16 06:06;hachikuji;[~ewencp] Is it not correct that the topic metadata response always includes all alive brokers?;;;","08/Jan/16 06:11;ewencp;[~hachikuji] Sorry, yeah, that's right. But you still have the same issues in any smaller cluster or in the case of a partition. So actually, even having the extra brokers returned doesn't work out great since as soon as you lose too many from the active set you can get into that same situation where you're not longer able to connect to any of the nodes from the last metadata refresh.;;;","22/Jan/16 23:56;enothereska;We'll go with keeping the original bootstrap brokers.;;;","23/Jan/16 01:55;ewencp;I'm thinking more about this in combination with KAFKA-3112. In 3112, you may get unresolvable nodes over time if your app is running for a long time and your bootstrap servers become stale.

The more I think about this, most of these issues seem to ultimately be due to the fact that you have to specify a fixed list of bootstrap servers which should be valid indefinitely. Assuming you have the right setup, you can work around this by, e.g., a VIP/loadbalancer/round robin DNS. But I'm wondering for how many people this requires extra work because they are already using some other service discovery mechanism? Today, if you want to pull bootstrap data from somewhere else, you need to do it at app startup and commit to using that fixed set of servers. I'm hesitant to suggest adding more points for extension, but wouldn't this be addressed more generally if there was a hook to get a list of bootstrap servers and we invoked it at startup, any time we run out of options, or fail to connect for too long? The default can just be to use the bootstrap servers list, but if you want to grab your list of servers from ZK, DNS, Consul, or whatever your system of choice is, you could easily hook those in instead and avoid this entire problem.;;;","23/Jan/16 02:15;ijuma;[~ewencp], that sounds like a worthwhile improvement, I agree. It's a bigger change and requires a KIP though so maybe we can file a separate JIRA for it? Jun expressed concerns that the problem in this JIRA could be a security issue and a fix for 0.9.0.1 would be desireable. As such, it would be great if we could find a simple fix for now and explore a more sophisticated one in the future.;;;","23/Jan/16 02:15;enothereska;[~ewencp]: sounds like a KIP? In the old Kafka we could have connected to ZK, but we don't have that option anymore. I wonder if ZK can still be used as a proxy for a directory service of sorts? We basically need a directory service to find other services in the cluster.;;;","23/Jan/16 02:57;ewencp;[~enothereska] [~ijuma] Agreed, likely a KIP and separate JIRA. I was raising it here to get some feedback about whether it makes sense and see if anybody had any ideas for less intrusive solutions (i.e. do we really need that level of pluggability or could we get away with something less?). I agree that a larger change like this shouldn't block fixing this JIRA.;;;","23/Jan/16 04:37;githubbot;GitHub user enothereska opened a pull request:

    https://github.com/apache/kafka/pull/804

    KAFKA-3068: Keep track of bootstrap nodes instead of all nodes ever seen

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/enothereska/kafka kafka-3068

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/804.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #804
    
----
commit 32f3bffb2281a03fa6449627c144478a0ce666ad
Author: Eno Thereska <eno.thereska@gmail.com>
Date:   2016-01-22T20:36:27Z

    Keep track of bootstrap nodes instead of all nodes ever seen

----
;;;","26/Jan/16 02:23;junrao;[~ewencp], having a pluggable discovery service may be reasonable. However, one will need some kind of entry points to connect to the external discovery service. Then one has to answer the same question: how to keep the entry points to external services valid all the time. If one has to rely upon things like VIP or DNS mapping there, we probably should just recommend people to use those on the bootstrap servers in the first place.

Also, for the fix, my feeling is that falling back to bootstrap servers is a subtle change of behavior from 0.8.2 producer and probably should go through a KIP discussion too, since it can have implication on people who generate bootstrap servers from an external service.

Alternatively, we can just revert the behavior in 0.9.0.1 to 0.8.2 (i.e., just wait when all brokers are not connectable). This may affect people who are using a small cluster and when there is a significant number of broker failures. However, this should be relatively rare. Then, we can start a separate KIP discussion in 0.9.1 to see what's the best way to fix this completely.;;;","26/Jan/16 09:27;ewencp;[~junrao] Right, for people using VIP or DNS, using it as the bootstrap works fine. If you're using other discovery mechanisms that don't expose info via DNS are stuck using a fixed setting by looking it up once and setting the bootstrap servers. (Note also that even DNS only works if you're using some fixed, default port. I faced this issue trying to work with Kafka on Mesos because I could discover the node the service was running on with mesos-dns, but it was using a randomly assigned port. At the time the only way I could figure to make this work without opting out of their port management was to use their REST API to discover host + port.)

In any case, that is really a much larger KIP discussion, as I said I just wanted to gauge level of interest on it. On the solution proposed here, maybe go through the quick KIP and see if people agree it makes sense in 0.9.0.1 too -- it's true this is a behavioral change, but also for behavior that I'm not sure we ever specified or made promises about. [~enothereska] do you want to draft up a KIP? Should be a small one.;;;","26/Jan/16 19:19;enothereska;Ok, I'll revert to using the 0.8.2 solution (by updating the PR) and draft a KIP for moving forward. Thanks.;;;","28/Jan/16 23:19;githubbot;Github user enothereska closed the pull request at:

    https://github.com/apache/kafka/pull/804
;;;","29/Jan/16 00:00;githubbot;GitHub user enothereska opened a pull request:

    https://github.com/apache/kafka/pull/823

    KAFKA-3068: Remove retry with nodesEverSeen

    @ewencp @ijuma if this looks good please merge when you can. Thanks.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/enothereska/kafka kafka-3068-alt

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/823.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #823
    
----
commit 820be2808bd7e399d1ecf1b26fb9388783cb3029
Author: Eno Thereska <eno.thereska@gmail.com>
Date:   2016-01-28T15:58:31Z

    Remove retry with nodesEverSeen

----
;;;","03/Feb/16 01:36;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/823
;;;","03/Feb/16 01:36;ewencp;Issue resolved by pull request 823
[https://github.com/apache/kafka/pull/823];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Data Loss for Incremented Replica Factor and Leader Election,KAFKA-1561,12730349,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,guozhang,guozhang,29/Jul/14 07:14,12/Dec/17 03:01,22/Mar/23 15:10,12/Dec/17 03:01,,,,,,,0.11.0.0,,,,,,,,,,,0,,,,,,"This is reported on the mailing list (thanks to Jad).

{quote}
Hi,

I have a test that continuously sends messages to one broker, brings up
another broker, and adds it as a replica for all partitions, with it being
the preferred replica for some. I have auto.leader.rebalance.enable=true,
so replica election gets triggered. Data is being pumped to the old broker
all the while. It seems that some data gets lost while switching over to
the new leader. Is this a bug, or do I have something misconfigured? I also
have request.required.acks=-1 on the producer.

Here's what I think is happening:

1. Producer writes message to broker 0, [EventServiceUpsertTopic,13], w/
broker 0 currently leader, with ISR=(0), so write returns successfully,
even when acks = -1. Correlation id 35836

Producer log:

[2014-07-24 14:44:26,991]  [DEBUG]  [dw-97 - PATCH
/v1/events/type_for_test_bringupNewBroker_shouldRebalance_shouldNotLoseData/event?_idPath=idField&_mergeFields=field1]
[kafka.producer.BrokerPartitionInfo]  Partition
[EventServiceUpsertTopic,13] has leader 0

[2014-07-24 14:44:26,993]  [DEBUG]  [dw-97 - PATCH
/v1/events/type_for_test_bringupNewBroker_shouldRebalance_shouldNotLoseData/event?_idPath=idField&_mergeFields=field1]
[k.producer.async.DefaultEventHandler]  Producer sent messages with
correlation id 35836 for topics [EventServiceUpsertTopic,13] to broker 0 on
localhost:56821
2. Broker 1 is still catching up

Broker 0 Log:

[2014-07-24 14:44:26,992]  [DEBUG]  [kafka-request-handler-3]
[kafka.cluster.Partition]  Partition [EventServiceUpsertTopic,13] on broker
0: Old hw for partition [EventServiceUpsertTopic,13] is 971. New hw is 971.
All leo's are 975,971

[2014-07-24 14:44:26,992]  [DEBUG]  [kafka-request-handler-3]
[kafka.server.KafkaApis]  [KafkaApi-0] Produce to local log in 0 ms

[2014-07-24 14:44:26,992]  [DEBUG]  [kafka-processor-56821-0]
[kafka.request.logger]  Completed request:Name: ProducerRequest; Version:
0; CorrelationId: 35836; ClientId: ; RequiredAcks: -1; AckTimeoutMs: 10000
ms from client /127.0.0.1:57086
;totalTime:0,requestQueueTime:0,localTime:0,remoteTime:0,responseQueueTime:0,sendTime:0
3. Leader election is triggered by the scheduler:

Broker 0 Log:

[2014-07-24 14:44:26,991]  [INFO ]  [kafka-scheduler-0]
[k.c.PreferredReplicaPartitionLeaderSelector]
[PreferredReplicaPartitionLeaderSelector]: Current leader 0 for partition [
EventServiceUpsertTopic,13] is not the preferred replica. Trigerring
preferred replica leader election

[2014-07-24 14:44:26,993]  [DEBUG]  [kafka-scheduler-0]
[kafka.utils.ZkUtils$]  Conditional update of path
/brokers/topics/EventServiceUpsertTopic/partitions/13/state with value
{""controller_epoch"":1,""leader"":1,""version"":1,""leader_epoch"":3,""isr"":[0,1]}
and expected version 3 succeeded, returning the new version: 4

[2014-07-24 14:44:26,994]  [DEBUG]  [kafka-scheduler-0]
[k.controller.PartitionStateMachine]  [Partition state machine on
Controller 0]: After leader election, leader cache is updated to
Map(<Snipped>(Leader:1,ISR:0,1,LeaderEpoch:3,ControllerEpoch:1),<EndSnip>)

[2014-07-24 14:44:26,994]  [INFO ]  [kafka-scheduler-0]
[kafka.controller.KafkaController]  [Controller 0]: Partition [
EventServiceUpsertTopic,13] completed preferred replica leader election.
New leader is 1
4. Broker 1 is still behind, but it sets the high water mark to 971!!!

Broker 1 Log:

[2014-07-24 14:44:26,999]  [INFO ]  [kafka-request-handler-6]
[kafka.server.ReplicaFetcherManager]  [ReplicaFetcherManager on broker 1]
Removed fetcher for partitions [EventServiceUpsertTopic,13]

[2014-07-24 14:44:27,000]  [DEBUG]  [kafka-request-handler-6]
[kafka.cluster.Partition]  Partition [EventServiceUpsertTopic,13] on broker
1: Old hw for partition [EventServiceUpsertTopic,13] is 970. New hw is -1.
All leo's are -1,971

[2014-07-24 14:44:27,098]  [DEBUG]  [kafka-request-handler-3]
[kafka.server.KafkaApis]  [KafkaApi-1] Maybe update partition HW due to
fetch request: Name: FetchRequest; Version: 0; CorrelationId: 1; ClientId:
ReplicaFetcherThread-0-1; ReplicaId: 0; MaxWait: 500 ms; MinBytes: 1 bytes;
RequestInfo: [EventServiceUpsertTopic,13] ->
PartitionFetchInfo(971,1048576), <Snipped>

[2014-07-24 14:44:27,098]  [DEBUG]  [kafka-request-handler-3]
[kafka.cluster.Partition]  Partition [EventServiceUpsertTopic,13] on broker
1: Recording follower 0 position 971 for partition [
EventServiceUpsertTopic,13].

[2014-07-24 14:44:27,100]  [DEBUG]  [kafka-request-handler-3]
[kafka.cluster.Partition]  Partition [EventServiceUpsertTopic,13] on broker
1: Highwatermark for partition [EventServiceUpsertTopic,13] updated to 971
5. Consumer is none the wiser. All data that was in offsets 972-975 doesn't
show up!

I tried this with 2 initial replicas, and adding a 3rd which is supposed to
be the leader for some new partitions, and this problem also happens there.
The log on the old leader gets truncated to the offset on the new leader.
What's the solution? Can I make a new broker leader for partitions that are
currently active without losing data?

Thanks,
Jad.
{quote}",,guozhang,jnaous,junrao,panih2o,vinayak10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jul/14 07:20;jnaous;broker0.log;https://issues.apache.org/jira/secure/attachment/12658294/broker0.log","29/Jul/14 07:20;jnaous;broker2.log;https://issues.apache.org/jira/secure/attachment/12658295/broker2.log","29/Jul/14 07:20;jnaous;consumer.log;https://issues.apache.org/jira/secure/attachment/12658296/consumer.log","29/Jul/14 07:20;jnaous;producer.log;https://issues.apache.org/jira/secure/attachment/12658297/producer.log",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,408422,,,Wed Jun 21 07:32:32 UTC 2017,,,,,,,,,,"0|i1y9yn:",408421,,,,,,,,,,,,,,,,,,,,"29/Jul/14 07:22;jnaous;Here's some more detailed info on what the latest test does (from which these logs are obtained):

0) Start two brokers, one producer, one consumer. Topic has 20 partitions, using default partitioning scheme (which seems to send data to only a couple of partitions when the keys are null, but that doesn't matter for this test).
1) Start a data generator sending data through Kafka continuously
2) Start a new broker
3) Reassign partitions:
{code}
{""version"": 1, ""partitions"":[
    {""topic"":""EventServiceUpsertTopic"",""partition"":0,        ""replicas"": [0, 1, 2]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":1,        ""replicas"": [1, 2, 0]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":2,        ""replicas"": [2, 0, 1]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":3,        ""replicas"": [0, 1, 2]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":4,        ""replicas"": [1, 2, 0]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":5,        ""replicas"": [2, 0, 1]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":6,        ""replicas"": [0, 1, 2]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":7,        ""replicas"": [1, 2, 0]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":8,        ""replicas"": [2, 0, 1]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":9,        ""replicas"": [0, 1, 2]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":10,        ""replicas"": [1, 2, 0]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":11,        ""replicas"": [2, 0, 1]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":12,        ""replicas"": [0, 1, 2]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":13,        ""replicas"": [1, 2, 0]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":14,        ""replicas"": [2, 0, 1]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":15,        ""replicas"": [0, 1, 2]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":16,        ""replicas"": [1, 2, 0]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":17,        ""replicas"": [2, 0, 1]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":18,        ""replicas"": [0, 1, 2]},
    {""topic"":""EventServiceUpsertTopic"",""partition"":19,        ""replicas"": [1, 2, 0]}]}
{code}
4) Wait until reassignment is complete (i.e. until ZkUtils.getPartitionsBeingReassigned() returns empty map)
5) Wait until all replicas are caught up (i.e. until ZkUtils.getLeaderAndIsrForPartition() returns all brokers in the ISR for each partition)
6) Trigger leader re-election by calling the PreferredReplicaLeaderElectionCommand
7) Wait until all the leaders are the preferred leaders for partitions according to the replica reassignment from step 3
8) Stop the data generator
9) Check that all the data was consumed

You can see from the producer.log that the data: {{ {""field1"": [""10""], ""idField"": ""id-5-59""} }} was sent to broker0 successfully, but the consumer never sees it.;;;","27/May/17 00:10;junrao;Hmm, interesting. From the description, when the LEOs on the leader are 574 and 571, the HW on broker 0 is still at 571. This suggests that messages between 572 and 574 haven't been committed and the producer shouldn't have received a successful ack with acks=-1.;;;","07/Jun/17 00:42;vinayak10;Hi,
[~junrao]
I have Cluster consisting of 3 Zookeeper nodes and 2 Brokers running on AWS instances. When I am trying to scale Brokers from 2 to 3 while simultaneously producing and consuming from topic I am experiencing loss of messages.

Topic :
Partitions - 40
Replication Factor - 2

I am using console producer to produce 1000 messages at a time to the topic. I do this for 200 secs and then print total no of messages produced, while simultaneously I run a script to consume from the same topic.While these scripts are running I reassign the partitions of the same topic from 2 brokers(0,1) to 3 brokers(0,1,2 ). While these reassignment of partitions is running I see producer throwing the following logs:
[2017-05-31 13:31:13,311] WARN Got error produce response with correlation id 4 on topic-partition Topic6-39, retrying (2 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender)
[2017-05-31 13:31:13,338] WARN Got error produce response with correlation id 4 on topic-partition Topic6-27, retrying (2 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender)
[2017-05-31 13:31:13,338] WARN Got error produce response with correlation id 4 on topic-partition Topic6-21, retrying (2 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender)
[2017-05-31 13:31:13,338] WARN Got error produce response with correlation id 4 on topic-partition Topic6-15, retrying (2 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender)
[2017-05-31 13:31:13,339] WARN Got error produce response with correlation id 6 on topic-partition Topic6-36, retrying (2 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender)
[2017-05-31 13:31:13,339] WARN Got error produce response with correlation id 6 on topic-partition Topic6-6, retrying (2 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender)
[2017-05-31 13:31:13,339] WARN Got error produce response with correlation id 6 on topic-partition Topic6-0, retrying (2 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender)
[2017-05-31 13:31:13,342] WARN Got error produce response with correlation id 6 on topic-partition Topic6-18, retrying (2 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender)
[2017-05-31 13:31:13,343] WARN Got error produce response with correlation id 6 on topic-partition Topic6-24, retrying (2 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender)
[2017-05-31 13:31:13,401] WARN Got error produce response with correlation id 11 on topic-partition Topic6-3, retrying (2 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender)


After 200 secs I see that producer says the total number of messages produced are 61000 while consumed messages are 60974.

Just to make sure whether it is consumer's fault or producer's fault, I run another console consumer on the same topic from the beginning and observer that there were actually 60974 messages in that topic. So that proves that the messages were lost at the producer end.

I also tried the same test with adding the following property to the topic being used:
unclean.leader.election.enable = false

And I also changed the ""leader.imbalance.check.interval.seconds"" in server.properties from 30 secs to 1 sec.

Still the loss of messages persist.

I have posted these issue on confluent-platform(Thread name = Loss of data while Scaling Kafka Brokers) also but have not got any reply yet.
Please tell me how can I completely avoid this loss of messages.
Thanks.;;;","08/Jun/17 08:48;junrao;[~vinayak10], did you set acks=all in the producer?;;;","20/Jun/17 20:01;vinayak10;[~junrao] I tried with acks=all, there is no loss of messages now.

But, what I see now is some messages are produced more than once now.

this is what I did:
I produced using the following command:
bin/kafka-console-producer.sh --broker-list 172.31.15.135:9092,172.31.17.243:9092 --topic Topic --message-send-max-retries 1000 --request-timeout-ms 60000 --request-required-acks ""all"" --max-block-ms 9223372036854775807

I also set min.insync.replicas = 2 in topic and broker configurations.

While reassigning the partitions I found out that number of messages produced were 730000 while consumed were 730012.

Can you tell me where did I go wrong?

Thanks.

;;;","20/Jun/17 22:29;junrao;[~vinayak10], currently, duplicates can be introduced during producer retry on transient failure such as leader changes. In the 0.11.0.0 release, we are introducing an idempotent producer that can avoid duplicates during retry.;;;","21/Jun/17 15:32;vinayak10;[~junrao] I will look forward to the release.
Thanks alot for your replies. It really helped.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SyncProducer does not correctly timeout,KAFKA-305,12546581,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,prashanth.menon,prashanth.menon,prashanth.menon,15/Mar/12 21:11,02/Apr/12 09:48,22/Mar/23 15:10,27/Mar/12 01:19,0.7,0.8.0,,,,,0.8.0,,,,,,,core,,,,0,,,,,,So it turns out that using the channel in SyncProducer like we are to perform blocking reads will not trigger socket timeouts (though we set it) and will block forever which is bad.  This bug identifies the issue: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4614802 and this article presents a potential work-around: http://stackoverflow.com/questions/2866557/timeout-for-socketchannel for workaround. The work-around is a simple solution that involves creating a separate ReadableByteChannel instance for timeout-enabled reads.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-49,,KAFKA-295,,,,,,,,,,,,"26/Mar/12 09:45;prashanth.menon;BlockingChannel2.scala;https://issues.apache.org/jira/secure/attachment/12519889/BlockingChannel2.scala","20/Mar/12 10:04;prashanth.menon;KAFKA-305-v1.patch;https://issues.apache.org/jira/secure/attachment/12519005/KAFKA-305-v1.patch","23/Mar/12 21:57;prashanth.menon;KAFKA-305-v2.patch;https://issues.apache.org/jira/secure/attachment/12519623/KAFKA-305-v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,231739,,,Mon Apr 02 01:48:37 UTC 2012,,,,,,,,,,"0|i09m9b:",54039,,,,,,,,,,,,,,,,,,,,"17/Mar/12 01:16;nehanarkhede;Produce ACK should not be blocking. It probably makes sense to fix this before closing KAFKA-49.;;;","19/Mar/12 10:15;prashanth.menon;I, unfortunately, didn't get a chance to work on this over the weekend.  From my point of view, creating a new ReadableByteChannel that wraps the socket channel InputStream seems like the simplest solution.  Then the SyncProudcer will have a writeChannel (the SocketChannel) and a readChannel (the wrapped version).  All writes and reads go through the respective channels with the additional of timeout functionality.  

Another step we can take it is to move all that logic into some class BlockingChannel which can be reused on the consumer side in SimpleConsumer.  Such a class would have, perhaps, four methods: connect, disconnect, send and receive.  Connect and disconnect would be synchronized, send would take a Request object and receive would return a Tuple2[Receive, Int] like usual.  Send and receive will need to be synchronized externally, meaning the class can be effectively treated like a regular Channel otherwise ...

Thoughts?;;;","20/Mar/12 10:00;prashanth.menon;Hi all, I've attached a patch.  Some notes:

- New class called BlockingChannel that has timeouts enabled.
- SyncProducer uses BlockingChannel instead of creating its own SocketChannel
- Re-introducsed testZKSendWithDeadBroker which passes now.

I'd like to get feedback on this.  It's simple and may be reused on the consumer side.  When I think about it, it would be nice to combine SimpleConsumer and SyncProducer into one generic ""SimpleClient"" since the functionality is effectively the same.

I'd also like to benchmark this against a pure NIO implementation where we can use selectors to enabled timeout functionality.  It'll be more complex and will require minor adjustment to BoundedByteBuffer and BoundedByteBufferSend but it may be worth it.;;;","21/Mar/12 08:12;junrao;Prashanth,

Thanks for the patch. This is very useful. Some comments:

1. I think it makes sense for SimpleConsumer to use BlockingChannel as well. Could you change that in this patch too?
2. ProducerTest.testZKSendWithDeadBroker: This test doesn't really test the timeout on getting a response. We probably need to create a mock kafkaserver (that don't send a response) to test this out.
3. BlockingChannel: 
3.1 We probably should rename timeoutMs to readTimeoutMs since only reads are subject to the timeout.
3.2 We should pass in a socketSendBufferSize and a socketReceiveBufferSize.
3.3 Should host and port be part of the constructor? It seems to me it's cleaner if each instance of BlockingChannel is tied to 1 host and 1 port.

I'd also be interested in your findings on the comparison with NIO with selectors.
;;;","22/Mar/12 10:18;prashanth.menon;Thanks for review, Jun.

1. Will do.
2. So that test actually exposed the issue to begin with - the initial send would fail and then hang forever when attempting to refresh the topic metadata.  Regardless, I'll create a separate more direct test for timeouts.  On my local machine, this test seems to be unpredictable around 30% of the time.  In these cases, it seems like the ephemeral broker nodes aren't removed from ZK and bringing back up a broker after shutdown throws a ""Broker already exists"" exception.  Is anyone else experiencing it or just me?  Increasing the wait time after shutdown helps but not 100%.
3. 1,2,3 Sounds fair.

I should be able to get a patch in for this by Friday.  Then continue on KAFKA-49 over the weekend and get it in on Saturday or Sunday should the review go okay.  Apologies for the delays :(;;;","22/Mar/12 23:01;junrao;Prashant,

2. If you want to make sure that a broker is shut down, you need to call kafkaServer.awaitShutdown after calling kafkaServer.shutdown. Overall, I don't quite understand how the new test works. It only brought down 1 broker and yet the comment says all brokers are down. If it is indeed that all brokers are down, any RPC call to the broker should get a broken pipe or socket closed exception immediately, not a sockettimeout exception. So, to really test that the timeout works, we need to keep the broker alive and somehow delay the response from the server. This can probably be done with a mock request handler.;;;","22/Mar/12 23:32;nehanarkhede;Prashanth,

Thanks for the patch. A couple of suggestions -

1. Since you are adding a new abstraction, BlockingChannel, would it make sense to change SimpleConsumer to use it ? Its your call if you'd rather fix it in another JIRA.
2. In BlockingChannel, since you are synchronizing on a lock, any reason the connected boolean be a volatile ? Also, you can avoid resetting the read and write channels to null values in disconnect.
3. Lets add some more tests for this, since it is unclear if the workaround of wrapping input stream in a channel actually works or not. I like Jun's suggestion of mocking out the request handler to achieve this. Tests would include SyncProducer as well as async producer (DefaultEventHandler);;;","23/Mar/12 10:54;prashanth.menon;I've uploaded a new patch with the suggestions, but it's not ready for commit, just another review.  A few notes:

1. BlockingChannel modified to meet suggestions.
2. SimpleConsumer uses BlockingChannel.
3. To test the BlockingChannel (in SyncProducer and async producer), I bring up a regular server but shutdown the requesthandler.  So the socket remains open, accepts requests and queues them in the request channel, but there are no handlers processing requests.
4. The original testZKSendWithDeadBroker wasn't commented entirely correctly.  I've modified to actually test what the name suggests.
5. Though I wait for the broker to do down, testZKSendWithDeadBroker still unpredictably throws the ""Broker already registered"" exception.  Are you experiencing this locally?

I think there might be an issue with the BrokerPartitionInfo and ProduerPool classes.  ProducerPool never removes producers even if one is connected to a downed broker, so calls to getAnyProducer (used by BrokerPartitioninfo.updateInfo to update cached topic metadata information) could return the same ""bad"" producer on consecutive calls when attempting to refresh the cache.  This could potentially cause an entire send to fail though there may exist a broker that is able to service the topic metadata request.  We need to somehow, remove ""bad"" producers, or refresh the ProducerPool when brokers go down, or have BrokerPartitionInfo retry its updateInfo call a certain number of times.  Thoughts?;;;","24/Mar/12 00:57;junrao;Prashanth,

v2 patch looks good. 

As for 5, I do see transient failures of testZKSendWithDeadBroker. This is a bit weird. During broker shutdown, we close the ZK client, which should cause all ephemeral nodes to be deleted in ZK. Could you verify if this is indeed the behavior of ZK?

As for BrokerPartitionInfo and ProducerPool, we should clean up dead brokers. Could you open a separate jira to track that?;;;","24/Mar/12 02:58;nehanarkhede;v2 looks good. 

Regarding the test failure, I debugged it and see a probable bug with either Zookeeper or ZkClient. See below - 

[info] Test Starting: testZKSendWithDeadBroker(kafka.producer.ProducerTest)
Shutting down broker 0
[2012-03-23 11:50:36,870] DEBUG Deleting ephemeral node /brokers/ids/0 for session 0x13640e55f240013 (org.apache.zookeeper.server.DataTree:831)
[2012-03-23 11:50:36,873] DEBUG Deleting ephemeral node /brokers/topics/new-topic/partitions/3/leader for session 0x13640e55f240013 (org.apache.zookeeper.server.DataTree:831)
[2012-03-23 11:50:36,873] DEBUG Deleting ephemeral node /brokers/topics/new-topic/partitions/1/leader for session 0x13640e55f240013 (org.apache.zookeeper.server.DataTree:831)
[2012-03-23 11:50:36,873] DEBUG Deleting ephemeral node /brokers/topics/new-topic/partitions/2/leader for session 0x13640e55f240013 (org.apache.zookeeper.server.DataTree:831)
[2012-03-23 11:50:36,873] DEBUG Deleting ephemeral node /brokers/topics/new-topic/partitions/0/leader for session 0x13640e55f240013 (org.apache.zookeeper.server.DataTree:831)
Shut down broker 0
Restarting broker 0
[2012-03-23 11:50:45,194] DEBUG Deleting ephemeral node /brokers/ids/1 for session 0x13640e55f24001b (org.apache.zookeeper.server.DataTree:831)
[error] Test Failed: testZKSendWithDeadBroker(kafka.producer.ProducerTest)
java.lang.RuntimeException: A broker is already registered on the path /brokers/ids/0. This probably indicates that you either have configured a brokerid that is already in use, or else you have shutdown this broker and restarted it faster than the zookeeper timeout so it appears to be re-registering.
	at kafka.utils.ZkUtils$.registerBrokerInZk(ZkUtils.scala:109)
	at kafka.server.KafkaZooKeeper.kafka$server$KafkaZooKeeper$$registerBrokerInZk(KafkaZooKeeper.scala:60)
	at kafka.server.KafkaZooKeeper.startup(KafkaZooKeeper.scala:52)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:84)
	at kafka.producer.ProducerTest.testZKSendWithDeadBroker(ProducerTest.scala:173)

Notice that after shutting down broker 0, the ephemeral node was deleted from its in memory data tree. That happens part of the close session workflow. Still, when we try to create the ephemeral node again, it complains that it already exists. 

I'll come back to this zookeeper bug later. I'd say lets checkin this test since it helps reproduce this zk bug. 

I think your patch looks good. ;;;","24/Mar/12 03:32;prashanth.menon;Thanks for the input everyone.  Regarding the ZK failure, that is effectively the trace I'm seeing on my end as well - the log makes it clear that the ephemeral nodes get deleted but the test still fails when creating them afterwards.  

I would like to delay commiting this patch, atleast for the weekend, as I'd like to perform a little benchmark against a pure NIO implementation.  The benefits there would be having timeouts for both read and write operations and a potential performance boost.;;;","24/Mar/12 04:22;junrao;If this is indeed a ZK issue, we can probably check/wait that the ephemeral node is gone before restarting the broker.;;;","26/Mar/12 09:45;prashanth.menon;I've attached another non-blocking implementation that uses selectors, but I'm not seeing any significant performance boost on my machine.  I tested it on the producer side using the ProducerPerformance class by varying the number of messages, the message sizes and the number of threads.  Each test scenario was run four times and the average result was used.  Find the results here: https://gist.github.com/2202142.  

For what it's worth, I think we should go ahead with the simple solution attached in the v2 path - if everyone is okay with it, please commit.  Regarding the test error, it could potentially be a valid ZK or ZKClient bug.  I can investigate a little by digging into ZKClient and asking around the mailing list and channels.  Keeping the test in breaks the test unpredictably.  Thought I'm not entirely okay with it keeping the bug in, waiting for the node to go down doesn't seem to be the right solution either.  ;;;","27/Mar/12 01:19;junrao;Prashanth,

Thanks for the patch. I agree that v2 is less risky than the selector approach. So, we can revisit the selector approach later. Thanks for the patch though and it will probably be useful in the future. Committed v2 patch to 0.8 branch with the following minor changes in DefaultEventHandler:
* log all unsent messages
* maintain outstandingRequests properly on both successful and unsuccessful sends.

Could you file 2 jiras, one for taking out dead brokers in ProducerPool and another for transient failures due to ZK ephemeral node not deleted in time?;;;","27/Mar/12 05:36;nehanarkhede;I found the zookeeper related problem, filed KAFKA-320 and also included a patch.;;;","27/Mar/12 08:22;prashanth.menon;Awesome!;;;","02/Apr/12 09:48;prashanth.menon;KAFKA-300 and KAFKA-305 ticket together resolve KAFKA-295.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
prevent potential resource leak in KafkaProducer and KafkaConsumer,KAFKA-2121,12820878,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,stevenz3wu,stevenz3wu,stevenz3wu,15/Apr/15 01:15,08/May/15 12:04,22/Mar/23 15:10,08/May/15 12:04,0.8.2.0,,,,,,0.9.0.0,,,,,,,producer ,,,,0,,,,,,"On Mon, Apr 13, 2015 at 7:17 PM, Guozhang Wang <wangguoz@gmail.com> wrote:
It is a valid problem and we should correct it as soon as possible, I'm
with Ewen regarding the solution.

On Mon, Apr 13, 2015 at 5:05 PM, Ewen Cheslack-Postava <ewen@confluent.io>
wrote:

> Steven,
>
> Looks like there is even more that could potentially be leaked -- since key
> and value serializers are created and configured at the end, even the IO
> thread allocated by the producer could leak. Given that, I think 1 isn't a
> great option since, as you said, it doesn't really address the underlying
> issue.
>
> 3 strikes me as bad from a user experience perspective. It's true we might
> want to introduce additional constructors to make testing easier, but the
> more components I need to allocate myself and inject into the producer's
> constructor, the worse the default experience is. And since you would have
> to inject the dependencies to get correct, non-leaking behavior, it will
> always be more code than previously (and a backwards incompatible change).
> Additionally, the code creating a the producer would have be more
> complicated since it would have to deal with the cleanup carefully whereas
> it previously just had to deal with the exception. Besides, for testing
> specifically, you can avoid exposing more constructors just for testing by
> using something like PowerMock that let you mock private methods. That
> requires a bit of code reorganization, but doesn't affect the public
> interface at all.
>
> So my take is that a variant of 2 is probably best. I'd probably do two
> things. First, make close() safe to call even if some fields haven't been
> initialized, which presumably just means checking for null fields. (You
> might also want to figure out if all the methods close() calls are
> idempotent and decide whether some fields should be marked non-final and
> cleared to null when close() is called). Second, add the try/catch as you
> suggested, but just use close().
>
> -Ewen
>
>
> On Mon, Apr 13, 2015 at 3:53 PM, Steven Wu <stevenz3wu@gmail.com> wrote:
>
> > Here is the resource leak problem that we have encountered when 0.8.2
> java
> > KafkaProducer failed in constructor. here is the code snippet of
> > KafkaProducer to illustrate the problem.
> >
> > -------------------------------
> > public KafkaProducer(ProducerConfig config, Serializer<K> keySerializer,
> > Serializer<V> valueSerializer) {
> >
> >     // create metrcis reporter via reflection
> >     List<MetricsReporter> reporters =
> >
> >
> config.getConfiguredInstances(ProducerConfig.METRIC_REPORTER_CLASSES_CONFIG,
> > MetricsReporter.class);
> >
> >     // validate bootstrap servers
> >     List<InetSocketAddress> addresses =
> >
> >
> ClientUtils.parseAndValidateAddresses(config.getList(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG));
> >
> > }
> > -------------------------------
> >
> > let's say MyMetricsReporter creates a thread in constructor. if hostname
> > validation threw an exception, constructor won't call the close method of
> > MyMetricsReporter to clean up the resource. as a result, we created
> thread
> > leak issue. this becomes worse when we try to auto recovery (i.e. keep
> > creating KafkaProducer again -> failing again -> more thread leaks).
> >
> > there are multiple options of fixing this.
> >
> > 1) just move the hostname validation to the beginning. but this is only
> fix
> > one symtom. it didn't fix the fundamental problem. what if some other
> lines
> > throw an exception.
> >
> > 2) use try-catch. in the catch section, try to call close methods for any
> > non-null objects constructed so far.
> >
> > 3) explicitly declare the dependency in the constructor. this way, when
> > KafkaProducer threw an exception, I can call close method of metrics
> > reporters for releasing resources.
> >     KafkaProducer(..., List<MetricsReporter> reporters)
> > we don't have to dependency injection framework. but generally hiding
> > dependency is a bad coding practice. it is also hard to plug in mocks for
> > dependencies. this is probably the most intrusive change.
> >
> > I am willing to submit a patch. but like to hear your opinions on how we
> > should fix the issue.
> >
> > Thanks,
> > Steven
> >
>
>
>
> --
> Thanks,
> Ewen
>



--
-- Guozhang",,ewencp,guozhang,slydon,stevenz3wu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2126,,,,"02/May/15 02:00;stevenz3wu;KAFKA-2121.patch;https://issues.apache.org/jira/secure/attachment/12729795/KAFKA-2121.patch","29/Apr/15 09:37;stevenz3wu;KAFKA-2121.patch;https://issues.apache.org/jira/secure/attachment/12729017/KAFKA-2121.patch","16/Apr/15 05:31;stevenz3wu;KAFKA-2121.patch;https://issues.apache.org/jira/secure/attachment/12725694/KAFKA-2121.patch","17/Apr/15 00:55;stevenz3wu;KAFKA-2121_2015-04-16_09:55:14.patch;https://issues.apache.org/jira/secure/attachment/12725914/KAFKA-2121_2015-04-16_09%3A55%3A14.patch","17/Apr/15 01:43;stevenz3wu;KAFKA-2121_2015-04-16_10:43:55.patch;https://issues.apache.org/jira/secure/attachment/12725927/KAFKA-2121_2015-04-16_10%3A43%3A55.patch","19/Apr/15 11:09;stevenz3wu;KAFKA-2121_2015-04-18_20:09:20.patch;https://issues.apache.org/jira/secure/attachment/12726416/KAFKA-2121_2015-04-18_20%3A09%3A20.patch","20/Apr/15 11:08;stevenz3wu;KAFKA-2121_2015-04-19_20:08:45.patch;https://issues.apache.org/jira/secure/attachment/12726504/KAFKA-2121_2015-04-19_20%3A08%3A45.patch","20/Apr/15 11:30;stevenz3wu;KAFKA-2121_2015-04-19_20:30:18.patch;https://issues.apache.org/jira/secure/attachment/12726506/KAFKA-2121_2015-04-19_20%3A30%3A18.patch","21/Apr/15 00:06;stevenz3wu;KAFKA-2121_2015-04-20_09:06:09.patch;https://issues.apache.org/jira/secure/attachment/12726594/KAFKA-2121_2015-04-20_09%3A06%3A09.patch","21/Apr/15 00:51;stevenz3wu;KAFKA-2121_2015-04-20_09:51:51.patch;https://issues.apache.org/jira/secure/attachment/12726601/KAFKA-2121_2015-04-20_09%3A51%3A51.patch","21/Apr/15 00:52;stevenz3wu;KAFKA-2121_2015-04-20_09:52:46.patch;https://issues.apache.org/jira/secure/attachment/12726602/KAFKA-2121_2015-04-20_09%3A52%3A46.patch","21/Apr/15 00:57;stevenz3wu;KAFKA-2121_2015-04-20_09:57:49.patch;https://issues.apache.org/jira/secure/attachment/12726604/KAFKA-2121_2015-04-20_09%3A57%3A49.patch","21/Apr/15 13:48;stevenz3wu;KAFKA-2121_2015-04-20_22:48:31.patch;https://issues.apache.org/jira/secure/attachment/12726799/KAFKA-2121_2015-04-20_22%3A48%3A31.patch","02/May/15 06:42;stevenz3wu;KAFKA-2121_2015-05-01_15:42:30.patch;https://issues.apache.org/jira/secure/attachment/12729884/KAFKA-2121_2015-05-01_15%3A42%3A30.patch",,,,,,,,,,,,,,14.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri May 08 04:04:04 UTC 2015,,,,,,,,,,"0|i2d8lj:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"15/Apr/15 05:31;stevenz3wu;add a unit test file;;;","15/Apr/15 08:09;ewencp;[~stevenz3wu] looks like a good start. I'll leave some comments here, but it's usually easier to do reviews if you submit the to reviewboard. The patch submission tool makes this process pretty painless once you've got it setup: https://cwiki.apache.org/confluence/display/KAFKA/Patch+submission+and+review#Patchsubmissionandreview-Kafkapatchreviewtool

* I'm getting a bunch of checkstyle complaints when I try to test. These should all be easy to fix (and should be causing tests to fail before even running). The only rule that might not be obvious from the error message is that the static final field in MockMetricsReporter is expected to be all-caps since it looks like a constant to checkstyle.
* In the constructor, could we throw some subclass of KafkaException instead? The new clients try to stick to that exception hierarchy except in a few special cases. Alternatively, maybe if we caught Error and RuntimeException instead of Throwable then we could just rethrow the same exception?
* The new version of close() will swallow exceptions when called normally (i.e. not from the constructor). They'll be logged, but the caller won't see the exception anymore. Maybe we should save the first exception and rethrow it?
* Exception messages should be capitalized.
* In the test, we should probably have an assert outside the catch. And is there any reason the closeCount is being reset to 0?
;;;","15/Apr/15 08:29;stevenz3wu;[~ewencp]
I will create a item on reviewboard. will try to address your comments there.

I  wished that apache/kafka just used github. then it will be really painless from the beginning. ;;;","16/Apr/15 05:31;stevenz3wu;Created reviewboard https://reviews.apache.org/r/33242/diff/
 against branch apache/trunk;;;","16/Apr/15 05:37;stevenz3wu;finally, I was able to post to review board. had some issues with my python installation. finally used virtualenv to make it work. I haven't yet addressed [~ewencp] comments yet. will update the reviewboard.;;;","17/Apr/15 00:55;stevenz3wu;Updated reviewboard https://reviews.apache.org/r/33242/diff/
 against branch apache/trunk;;;","17/Apr/15 01:44;stevenz3wu;Updated reviewboard https://reviews.apache.org/r/33242/diff/
 against branch apache/trunk;;;","19/Apr/15 11:09;stevenz3wu;Updated reviewboard https://reviews.apache.org/r/33242/diff/
 against branch apache/trunk;;;","20/Apr/15 11:08;stevenz3wu;Updated reviewboard https://reviews.apache.org/r/33242/diff/
 against branch apache/trunk;;;","20/Apr/15 11:30;stevenz3wu;Updated reviewboard https://reviews.apache.org/r/33242/diff/
 against branch apache/trunk;;;","20/Apr/15 11:32;stevenz3wu;[~ewencp] I have applied same fix to KafkaConsumer. 

I also made one change to KafkaProducer. I think it should be safe. basically, I moved the close of NetworkClient in Sender to KafkaProducer.;;;","20/Apr/15 11:42;stevenz3wu;BTW, when I ran ""./gradlew clients:test"" on cmd-line, there are a few test failures. But when I ran them in IDE, they are fine.

SenderTest
RecordAccumulatorTest
PartitionerTest
BufferPoolTest
;;;","20/Apr/15 12:27;ewencp;Odd, I don't see those, but I do see some like this now:

kafka.api.ProducerFailureHandlingTest > testSendAfterClosed FAILED
    org.apache.kafka.common.KafkaException: Failed to close kafka producer
        at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:555)
        at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:526)
        at kafka.api.ProducerFailureHandlingTest.tearDown(ProducerFailureHandlingTest.scala:73)

        Caused by:
        java.nio.channels.ClosedSelectorException
            at sun.nio.ch.SelectorImpl.keys(SelectorImpl.java:51)
            at org.apache.kafka.common.network.Selector.close(Selector.java:175)
            at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:319)
            at org.apache.kafka.clients.ClientUtils.closeQuietly(ClientUtils.java:57)
            at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:549)
            ... 2 more

Note that this is in core:tests. A bunch of client behavior isn't thoroughly tested until integration tests with the server.

The problem is that NetworkClient doesn't seem to handle close() being called twice. Since this is already available public interface, we'd have to consider that a regression -- we can't really change that behavior at this point just by cleaning up the tests. I think this is related to the change you made to pull that call out of Sender because it used to be called from Sender.run() and that wouldn't have been invoked twice. Another solution might be to null out the fields of KafkaProducer and KafkaConsumer as you close() them, but this probably means we need to think through that change or revert it.;;;","21/Apr/15 00:06;stevenz3wu;Updated reviewboard https://reviews.apache.org/r/33242/diff/
 against branch apache/trunk;;;","21/Apr/15 00:51;stevenz3wu;Updated reviewboard https://reviews.apache.org/r/33242/diff/
 against branch apache/trunk;;;","21/Apr/15 00:52;stevenz3wu;Updated reviewboard https://reviews.apache.org/r/33242/diff/
 against branch apache/trunk;;;","21/Apr/15 00:57;stevenz3wu;Updated reviewboard https://reviews.apache.org/r/33242/diff/
 against branch apache/trunk;;;","21/Apr/15 01:41;stevenz3wu;[~ewencp] I made two more changes in latest commit
1) moved close of NetworkClient back in Sender for the reason you outlined above
2) close deserializers in KafkaConsumer similar to what KafkaProducer does with serializers;;;","21/Apr/15 01:41;stevenz3wu;[~ewencp] I made two more changes in latest commit
1) moved close of NetworkClient back in Sender for the reason you outlined above
2) close deserializers in KafkaConsumer similar to what KafkaProducer does with serializers;;;","21/Apr/15 02:25;ewencp;Latest patch LGTM, maybe [~junrao] could review when he has a chance? This patch also ends up fixing KAFKA-2126 since it needed to in order to close the deserializers properly, so I closed that one in favor of this patch.;;;","21/Apr/15 13:48;stevenz3wu;Updated reviewboard https://reviews.apache.org/r/33242/diff/
 against branch apache/trunk;;;","23/Apr/15 01:15;guozhang;Thanks for the patch Steven, committed to trunk.;;;","23/Apr/15 01:39;stevenz3wu;[~guozhang] thanks. would it go in next 0.8.3 release?;;;","23/Apr/15 01:41;ewencp;[~stevenz3wu] Yes, it'll be released with 0.8.3.;;;","24/Apr/15 08:10;slydon;While this does resolve https://issues.apache.org/jira/browse/KAFKA-2126, there is a slight bug with the 'isKey' parameter which would be solved by the following patch.  This is so minor it seems silly to open a new branch+ticket+reviewboard just to change a boolean value.

{noformat}
--- a/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java
@@ -495,7 +495,7 @@ public class KafkaConsumer<K, V> implements Consumer<K, V> {
             if (keyDeserializer == null) {
                 this.keyDeserializer = config.getConfiguredInstance(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,
                         Deserializer.class);
-                this.keyDeserializer.configure(config.originals(), false);
+                this.keyDeserializer.configure(config.originals(), true);
             } else {
                 this.keyDeserializer = keyDeserializer;
             }
{noformat};;;","28/Apr/15 02:43;ewencp;Reopening since there's a trivial follow up patch that still needs to be applied. [~guozhang] since you committed the original patch, can you follow up on this?;;;","28/Apr/15 08:21;stevenz3wu;[~ewencp] [~guozhang]

I would like to hear your opinion about a source incompatibility scenario that my colleague [~allenxwang] pointed out.

Serializer<T> keySerializer = ...
Serializer<T> valueSerializer = ...
KafkaProducer producer = new KafkaProducer(config, keySerializer, valueSerializer)
// ...
keySerializer.close()
valueSerializer.close()

with this change, Serializer#close now throws an checked IOException that requires catch. it will cause compiling error.  are you concerned with the above problem?

Obviously, this won't be an issue if user rely on KafkaProducer to close the serializers and don't explicitly close serializers. 
For the long term, I think it is beneficial to converge on the java.io.Closeable interface. this may be a very small price to pay for short term.;;;","28/Apr/15 08:39;guozhang;Thanks [~slydon] for pointing out the bug, will make a follow-up commit.

Regarding IOException in close(): hmm, I overlooked this is actually an API change, but I also agree it is beneficial to move to Closeable for the long term. Will bring it up to the dev mailing list for discussion.;;;","28/Apr/15 08:44;ewencp;[~stevenz3wu] Interesting. Looks like this wasn't obvious for a couple of reasons:

1. Removing throws clauses is fine when overriding, so the implementations didn't cause the compiler to complain.
2. There's no testing of the implementation classes directly, so nothing was exercising their close() methods. Even if we tested them directly, we'd have to make sure to test them using a Serializer variable instead of their more specific type in order to force handling of the exception.
3. I wasn't expecting user code to be calling close() on those objects :) Apparently that was an incorrect assumption on my part.

So yeah, I think this unfortunately requires us to revert those changes. I think the other changes to Closeable should be fine since they are internal classes -- they may be marked public, but we don't consider them as such (they are filtered out of the javadocs).

Not sure what that means for being able to avoid all that duplicated code for the close() calls, it may just have to be messy. We could potentially introduce an interface for non-IOException-throwing closeables, but I'm not sure that's worth the trouble?
;;;","29/Apr/15 02:26;stevenz3wu;[~ewencp] I am ok to reverse the change on Serializer. 

what about Deserializer? I assume nobody is using it because consumer is not feature completed yet. so we can keep the change.

should we wait more feedbacks on the DISCUSS email thread that [~guozhang] started?

should I include the revert as part of KAFKA-2151? or a new jira for reverting? what's the common practice here?;;;","29/Apr/15 02:50;ewencp;I'd give people some more time to comment, it's tough to keep up with the volume of that list and it hasn't been a full day yet.

If we revert it, I'd personally revert both just for consistency, but if it generates any more discussion on the mailing list you should probably just ask people there what they think.

On where to submit the patch, I don't know that there is a common practice for this. I'd just submit it here. That way it will get tagged with this JIRA in the commit log message which makes it easy for people to track down the origin of the changes.;;;","29/Apr/15 09:37;stevenz3wu;Created reviewboard https://reviews.apache.org/r/33654/diff/
 against branch apache/trunk;;;","02/May/15 02:00;stevenz3wu;Created reviewboard https://reviews.apache.org/r/33760/diff/
 against branch apache/trunk;;;","02/May/15 06:42;stevenz3wu;Updated reviewboard https://reviews.apache.org/r/33760/diff/
 against branch apache/trunk;;;","08/May/15 12:04;guozhang;Committed the followup patch to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
adding partition did not find the correct startIndex ,KAFKA-2146,12823728,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,chenshangan521@163.com,chenshangan521@163.com,chenshangan521@163.com,24/Apr/15 19:48,22/Jan/16 08:18,22/Mar/23 15:10,22/Jan/16 08:18,0.8.2.0,,,,,,0.10.0.0,,,,,,,admin,,,,0,,,,,,"TopicCommand provide a tool to add partitions for existing topics. It try to find the startIndex from existing partitions. There's a minor flaw in this process, it try to use the first partition fetched from zookeeper as the start partition, and use the first replica id in this partition as the startIndex.

One thing, the first partition fetched from zookeeper is not necessary to be the start partition. As partition id begin from zero, we should use partition with id zero as the start partition.

The other, broker id does not necessary begin from 0, so the startIndex is not necessary to be the first replica id in the start partition. 

  ",,chenshangan521@163.com,githubbot,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Sep/15 00:32;chenshangan521@163.com;KAFKA-2146.2.patch;https://issues.apache.org/jira/secure/attachment/12761672/KAFKA-2146.2.patch","27/Apr/15 14:58;chenshangan521@163.com;KAFKA-2146.patch;https://issues.apache.org/jira/secure/attachment/12728329/KAFKA-2146.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jan 22 00:18:36 UTC 2016,,,,,,,,,,"0|i2dppb:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"24/Apr/15 19:48;chenshangan521@163.com;I'd like to provide a patch soon.;;;","27/Apr/15 14:58;chenshangan521@163.com;use partition 0 as head partition;
find the index of first replica of head partition in sortedBrokerList and use it as startIndex
;;;","12/May/15 10:45;guozhang;[~chenshangan521@163.com] Thanks for the patch, and sorry for the late review.

I agree with you on #1, but for #2 there is a case when some brokers are temporarily not available, while the existing replica list is set statically. So 

<code>
brokerList.indexOf(existingReplicaList.head)
<code>

may return -1 in this case, causing a random pick of the starting index. In this case, we should probably pick the next available broker as the starting broker, i.e. if now the available broker list is (1,2,5) and the replica list of partition 0 is 3, we should pick broker-5 as starting broker.

Also for #1, I think for better replica distribution we should pick the starting index as the first replica of the LAST partition's list plus one. That is, if we already have three partitions with replica list:

1, 2, 3
2, 3, 4
3, 4, 5

Then if we add another partition, its starting broker should be 4 given if all (1,2,3,4,5) brokers are available; or should be 5 if only (1,2,3,5) are available

Another minor comment: not introduced in this patch, but the name of ""existingReplicaList"" was originally misleading, we could rename it to ""existingReplicaListForLastPartition"" or ""existingReplicaListForPartitionZero"" with your current patch.

2. ;;;","12/May/15 16:03;chenshangan521@163.com;[~guozhang] It's ok.

For #2 I totally agree, it's better to pick the next available broker than pick a random one.

But for #1, I think we do not need to process as function #assignReplicasToBrokers will help us to deal with it as following

{code}
val firstReplicaIndex = (currentPartitionId + startIndex) % brokerList.size
{code}

And starting index has its own definition in function #assignReplicasToBrokers, if you use the LAST partition, you need to change the logic of this function, and this modification will gain nothing.

If we get agreed, I will update the patch.

I have another task KAFKA-2106, I think it's a big headache for users of kafka. My current solution is a workaround, but not well distributed , hope for some comment on that.  



;;;","22/Sep/15 03:27;guozhang;Yeah I agree, could you update the patch?;;;","23/Sep/15 00:30;chenshangan521@163.com;updated patch.;;;","15/Oct/15 08:05;guozhang;[~chenshangan521@163.com] your updated patch seems not apply cleanly on trunk, could you rebase?;;;","19/Oct/15 22:59;githubbot;GitHub user shangan opened a pull request:

    https://github.com/apache/kafka/pull/329

    KAFKA-2146. adding partition did not find the correct startIndex

    TopicCommand provide a tool to add partitions for existing topics. It try to find the startIndex from existing partitions. There's a minor flaw in this process, it try to use the first partition fetched from zookeeper as the start partition, and use the first replica id in this partition as the startIndex.
    One thing, the first partition fetched from zookeeper is not necessary to be the start partition. As partition id begin from zero, we should use partition with id zero as the start partition.
    The other, broker id does not necessary begin from 0, so the startIndex is not necessary to be the first replica id in the start partition.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/shangan/kafka trunk-KAFKA-2146

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/329.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #329
    
----
commit 8937cf75240bf48c1b70c1c2be461c5577dba3ac
Author: chenshangan <chenshangan@meituan.com>
Date:   2015-10-19T13:06:24Z

    KAFKA-2146. adding partition did not find the correct startIndex

----
;;;","22/Jan/16 08:18;guozhang;Issue resolved by pull request 329
[https://github.com/apache/kafka/pull/329];;;","22/Jan/16 08:18;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/329
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka-0.9.0.0 does not work as OSGi module,KAFKA-3218,12937466,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,rsivaram,joconnor,joconnor,08/Feb/16 18:58,09/Nov/17 18:58,22/Mar/23 15:10,23/Aug/16 20:02,0.9.0.0,,,,,,0.10.1.0,,,,,,,clients,,,,2,,,,,,"KAFKA-2295 changed all Class.forName() calls to use currentThread().getContextClassLoader() instead of the default ""classloader that loaded the current class"". 

OSGi loads each module's classes using a separate classloader so this is now broken.

Steps to reproduce: 
# install the kafka-clients servicemix OSGi module 0.9.0.0_1
# attempt to initialize the Kafka producer client from Java code 

Expected results: 
- call to ""new KafkaProducer()"" succeeds

Actual results: 
- ""new KafkaProducer()"" throws ConfigException:
{quote}        Suppressed: java.lang.Exception: Error starting bundle54: Activator start error in bundle com.openet.testcase.ContextClassLoaderBug [54].
                at org.apache.karaf.bundle.command.BundlesCommand.doExecute(BundlesCommand.java:66)
                ... 12 more
        Caused by: org.osgi.framework.BundleException: Activator start error in bundle com.openet.testcase.ContextClassLoaderBug [54].
                at org.apache.felix.framework.Felix.activateBundle(Felix.java:2276)
                at org.apache.felix.framework.Felix.startBundle(Felix.java:2144)
                at org.apache.felix.framework.BundleImpl.start(BundleImpl.java:998)
                at org.apache.karaf.bundle.command.Start.executeOnBundle(Start.java:38)
                at org.apache.karaf.bundle.command.BundlesCommand.doExecute(BundlesCommand.java:64)
                ... 12 more
        Caused by: java.lang.ExceptionInInitializerError
                at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:156)
                at com.openet.testcase.Activator.start(Activator.java:16)
                at org.apache.felix.framework.util.SecureAction.startActivator(SecureAction.java:697)
                at org.apache.felix.framework.Felix.activateBundle(Felix.java:2226)
                ... 16 more
        *Caused by: org.apache.kafka.common.config.ConfigException: Invalid value org.apache.kafka.clients.producer.internals.DefaultPartitioner for configuration partitioner.class: Class* *org.apache.kafka.clients.producer.internals.DefaultPartitioner could not be found.*
                at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:255)
                at org.apache.kafka.common.config.ConfigDef.define(ConfigDef.java:78)
                at org.apache.kafka.common.config.ConfigDef.define(ConfigDef.java:94)
                at org.apache.kafka.clients.producer.ProducerConfig.<clinit>(ProducerConfig.java:206)
{quote}


Workaround is to call ""currentThread().setContextClassLoader(null)"" before initializing the kafka producer.

Possible fix is to catch ClassNotFoundException at ConfigDef.java:247 and retry the Class.forName() call with the default classloader. However with this fix there is still a problem at AbstractConfig.java:206,  where the newInstance() call succeeds but ""instanceof"" is false because the classes were loaded by different classloaders.

Testcase attached, see README.txt for instructions.

See also SM-2743","Apache Felix OSGi container
jdk_1.8.0_60",githubbot,hlavki,joconnor,lidel,lowerobert,niallc,omkreddy,rituparno.paul@gmail.com,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2295,SM-2743,,,,,,,"08/Feb/16 18:59;joconnor;ContextClassLoaderBug.tar.gz;https://issues.apache.org/jira/secure/attachment/12786787/ContextClassLoaderBug.tar.gz",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 09 10:58:24 UTC 2017,,,,,,,,,,"0|i2sjsv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"08/Feb/16 18:59;joconnor;Testcase attached in ContextClassLoaderBug.tar.gz , README.txt included;;;","09/Feb/16 00:41;omkreddy;Thanks for reporting this. Can we add a new configuration option to decide ""current class loader vs context class loader"" ?
;;;","09/Feb/16 04:06;rsivaram;Not sure if a configuration option to choose between current classloader and the context classloader is the right approach to support OSGi. While that may work in this particular case where the class being loaded is the default partitioner which is included in Kafka, in the general case, you might want to load your own partitioner class contained in another bundle. Perhaps, it makes sense to fix the default case in this JIRA without adding additional config and raise a KIP to support OSGi properly?;;;","09/Feb/16 16:13;githubbot;GitHub user rajinisivaram opened a pull request:

    https://github.com/apache/kafka/pull/888

    KAFKA-3218: Use static classloading for default config classes

    Static classloading is better for default classes used in config to ensure that the classes can be loaded in any environment (OSGi, JEE etc. which rely on different classloading strategies).

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/rajinisivaram/kafka KAFKA-3218

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/888.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #888
    
----
commit c6fd1857fe085f95e9042745e24f762b8b4c550c
Author: Rajini Sivaram <rajinisivaram@googlemail.com>
Date:   2016-02-09T08:05:06Z

    KAFKA-3218: Use static classloading for default config classes

----
;;;","09/Feb/16 16:30;rsivaram;The PR addresses the loading of default classes for configuration properties by switching to static classloading to enable Kafka classes to be loaded in different environments like JEE, OSGi etc. which use different classloading strategies. Most properties supplied by the application (eg. key.serializer) can already be specified as classes to avoid relying on the current classloading strategy in Kafka:
{quote}
properties.put(""key.serializer"", org.apache.kafka.common.serialization.StringSerializer.class)
{quote}

Joe, can you check if this solution works for you?

To enable all features of Kafka to work well in OSGi, all uses of dynamic classloading need to be fixed. This needs more work and it would be better to do this with a KIP.
;;;","09/Feb/16 23:00;joconnor;Hi Rajini,
Thanks for the suggested workaround, we will try that out and let you know if it works.
Regards
Joe ;;;","15/Feb/16 22:44;lowerobert;Suggested workaround throws error on bundle:start
{code}
org.apache.karaf.shell.support.MultiException: Error executing command on bundles:
        Error starting bundle66: Activator start error in bundle com.openet.testcase.ContextClassLoaderBug [66].
        at org.apache.karaf.shell.support.MultiException.throwIf(MultiException.java:61)
        at org.apache.karaf.bundle.command.BundlesCommand.doExecute(BundlesCommand.java:69)
        at org.apache.karaf.bundle.command.BundlesCommand.execute(BundlesCommand.java:54)
        at org.apache.karaf.shell.impl.action.command.ActionCommand.execute(ActionCommand.java:83)
        at org.apache.karaf.shell.impl.console.osgi.secured.SecuredCommand.execute(SecuredCommand.java:67)
        at org.apache.karaf.shell.impl.console.osgi.secured.SecuredCommand.execute(SecuredCommand.java:87)
        at org.apache.felix.gogo.runtime.Closure.executeCmd(Closure.java:480)
        at org.apache.felix.gogo.runtime.Closure.executeStatement(Closure.java:406)
        at org.apache.felix.gogo.runtime.Pipe.run(Pipe.java:108)
        at org.apache.felix.gogo.runtime.Closure.execute(Closure.java:182)
        at org.apache.felix.gogo.runtime.Closure.execute(Closure.java:119)
        at org.apache.felix.gogo.runtime.CommandSessionImpl.execute(CommandSessionImpl.java:94)
        at org.apache.karaf.shell.impl.console.ConsoleSessionImpl.run(ConsoleSessionImpl.java:270)
        at java.lang.Thread.run(Thread.java:745)
        Suppressed: java.lang.Exception: Error starting bundle66: Activator start error in bundle com.openet.testcase.ContextClassLoaderBug [66].
                at org.apache.karaf.bundle.command.BundlesCommand.doExecute(BundlesCommand.java:66)
                ... 12 more
        Caused by: org.osgi.framework.BundleException: Activator start error in bundle com.openet.testcase.ContextClassLoaderBug [66].
                at org.apache.felix.framework.Felix.activateBundle(Felix.java:2270)
                at org.apache.felix.framework.Felix.startBundle(Felix.java:2138)
                at org.apache.felix.framework.BundleImpl.start(BundleImpl.java:977)
                at org.apache.karaf.bundle.command.Start.executeOnBundle(Start.java:38)
                at org.apache.karaf.bundle.command.BundlesCommand.doExecute(BundlesCommand.java:64)
                ... 12 more
        Caused by: java.lang.NoClassDefFoundError: Could not initialize class org.apache.kafka.clients.producer.ProducerConfig
                at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:156)
                at com.openet.testcase.Activator.start(Activator.java:18)
                at org.apache.felix.framework.util.SecureAction.startActivator(SecureAction.java:697)
                at org.apache.felix.framework.Felix.activateBundle(Felix.java:2220)
                ... 16 more

{code};;;","16/Feb/16 00:13;joconnor;The problem with the workaround seems to be that the ""partitioner.class"" config value has its default value specified as a string (as opposed to a class):{code}//ProducerConfig.java:278
                                .define(PARTITIONER_CLASS_CONFIG,
                                        Type.CLASS,
                                        DefaultPartitioner.class.getName(),
                                        Importance.MEDIUM, PARTITIONER_CLASS_DOC)
{code}
ConfigDef.java is then calling Class.forName() on the ""DefaultPartitioner.class.getName()"" string, which is triggering the bug

{code}Caused by: org.apache.kafka.common.config.ConfigException: Invalid value org.apache.kafka.clients.producer.internals.DefaultPartitioner for configuration partitioner.class: Class org.apache.kafka.clients.producer.internals.DefaultPartitioner could not be found.^M
        at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:255)^M
        at org.apache.kafka.common.config.ConfigDef.define(ConfigDef.java:78)^M
        at org.apache.kafka.common.config.ConfigDef.define(ConfigDef.java:94)^M
        at org.apache.kafka.clients.producer.ProducerConfig.<clinit>(ProducerConfig.java:206)^M
        ... 35 more^M
{code};;;","16/Feb/16 00:44;rsivaram;[~lowerobert] [~joconnor] Have you tried with the PR in https://github.com/apache/kafka/pull/888 which loads default config using static classloading to overcome this issue?;;;","29/Feb/16 19:57;lowerobert;Using the PR https://github.com/apache/kafka/pull/888 works in the Karaf container with Activator.java code updated to include 
{code:java}
properties.put(""key.serializer"", ""org.apache.kafka.common.serialization.StringSerializer"");
properties.put(""value.serializer"", ""org.apache.kafka.common.serialization.StringSerializer"");
properties.put(""partitioner.class"", ""org.apache.kafka.clients.producer.internals.DefaultPartitioner"");
properties.put(""bootstrap.servers"",""localhost:12345"");
KafkaProducer kafkaProducer = new KafkaProducer<String, byte[]>(properties);
{code};;;","09/May/16 20:40;rsivaram;Created [KIP-60|https://cwiki.apache.org/confluence/display/KAFKA/KIP-60+-+Make+Java+client+classloading+more+flexible] to fix default classloading described in this JIRA as well as loading of custom classes.;;;","24/May/16 18:31;githubbot;Github user rajinisivaram closed the pull request at:

    https://github.com/apache/kafka/pull/888
;;;","23/Aug/16 19:55;omkreddy;[~ rajinisivaram]    KAFKA-3680 fixes this issue right? ;;;","23/Aug/16 20:02;rsivaram;[~omkreddy] Yes, this has been fixed under KAFKA-3680, marking as resolved.;;;","09/Nov/17 18:58;hlavki;I have same problem when using Streams API 1.0.0 in karaf 4.1.13

{code}
Caused by: org.apache.kafka.common.KafkaException: org.apache.kafka.streams.processor.internals.StreamPartitionAssignor ClassNotFoundException exception occurred
 at org.apache.kafka.common.config.AbstractConfig.getConfiguredInstances(AbstractConfig.java:288) ~[?:?]
 at org.apache.kafka.common.config.AbstractConfig.getConfiguredInstances(AbstractConfig.java:263) ~[?:?]
 at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:732) ~[?:?]
 ... 51 more
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.streams.processor.internals.StreamPartitionAssignor
 at java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[?:?]
 at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[?:?]
 at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335) ~[?:?]
 at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[?:?]
 at java.lang.Class.forName0(Native Method) ~[?:?]
 at java.lang.Class.forName(Class.java:348) ~[?:?]
 at org.apache.kafka.common.utils.Utils.newInstance(Utils.java:308) ~[?:?]
 at org.apache.kafka.common.config.AbstractConfig.getConfiguredInstances(AbstractConfig.java:286) ~[?:?]
 at org.apache.kafka.common.config.AbstractConfig.getConfiguredInstances(AbstractConfig.java:263) ~[?:?]
 at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:732) ~[?:?]
 ... 51 more
{code}

Workaround is to wrap code:
{code:java}
ClassLoader cl = Thread.currentThread().getContextClassLoader();
try {
    Thread.currentThread().setContextClassLoader(KStream.class.getClassLoader());
    // original code of init streams
} finally {
    Thread.currentThread().setContextClassLoader(cl);
}
{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
java.lang.IllegalArgumentException Buffer.limit on FetchResponse.scala + 33,KAFKA-1196,12686852,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,ewencp,gerritjvv,gerritjvv,01/Jan/14 00:15,26/Sep/16 11:48,22/Mar/23 15:10,26/Sep/16 11:48,0.8.0,,,,,,0.10.1.0,,,,,,,consumer,,,,1,newbie,,,,,"I have 6 topics each with 8 partitions spread over 4 kafka servers.
the servers are 24 core 72 gig ram.

While consuming from the topics I get an IlegalArgumentException and all consumption stops, the error keeps on throwing.

I've tracked it down to FectchResponse.scala line 33

The error happens when the FetchResponsePartitionData object's readFrom method calls:
messageSetBuffer.limit(messageSetSize)

I put in some debug code the the messageSetSize is 671758648, while the buffer.capacity() gives 155733313, for some reason the buffer is smaller than the required message size.

I don't know the consumer code enough to debug this. It doesn't matter if compression is used or not.




","running java 1.7, linux and kafka compiled against scala 2.9.2",antonymayi,becket_qin,dashengju,donnchadh,ewencp,gerritjvv,ijuma,junrao,kbanker,kostassoid,milieu,nehanarkhede,solon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2063,,,,,,,,,,"17/Oct/14 00:55;ewencp;KAFKA-1196.patch;https://issues.apache.org/jira/secure/attachment/12675308/KAFKA-1196.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,365845,,,Mon Sep 26 03:48:21 UTC 2016,,,,,,,,,,"0|i1r293:",366152,,,,,,,,,,,,,,,,,,,,"07/Jan/14 02:27;nehanarkhede;As suggested by Jun -

If a broker is the leader of multiple partitions of a topic, the high level
consumer will fetch all those partitions in a single fetch request. Then
the aggregate of the fetched data from multiple partitions could be more
than 2GB.

You can try using more consumers in the same consumer group to reduce #
partitions fetched per consumer.

Thanks,

Jun;;;","07/Jan/14 02:39;gerritjvv;Hi, thanks for the response, but this is not really a solution.

Its obvious that how the api does the call is then flawed that or the broker should take care of it. I cannot add more consumers just for this issue because my data will grow maybe it doubles in a year, then I'd run again into the same problem, which is in the end an integer overflow problem and not a resource problem.

i.e. beyond a certain amount of data the api fails and I should add more consumers? I've opted for writing my own api that does calls on a topic,partition basis to each broker, so far its working.


 
;;;","13/Jan/14 12:44;junrao;To really support fetching more than 2GB of data in a single fetch response requires wire protocol change. One simple thing that we can do immediately is to sanity check the response size. If it's more than 2GB, just throw an error to the client.;;;","13/Jan/14 17:33;gerritjvv;If I throw an error then what? How can I consume the data in the first place? I'm using all the defaults and the provided stock consumer/producer.

The problem here is that I've not setup anywhere in the configuration to consume more than 2GB, its the way that the consumer does its fetch that causes the data to go over 2GB.

So it means that: If you use the broker and consumer and for some reason the consumer does a fetch over 2GB at any time, I'll be unable to consume the data ever, even though no single message is even over the 100-200 mb. The only solution left to me is then either write my own client, or delete the topic data every time I see this, which is about 5 seconds after I removed and recreated the topic.

;;;","15/Jan/14 23:54;junrao;Yes, I wasn't thinking of fixing the issue since I can't think of an easy way. I was just thinking of giving the client the right error message so that the client is not confused  btw this case and an actual log corruption.;;;","15/Jan/14 23:59;gerritjvv;:) , it doesn't seem like there is an easy fix, 
 I'm trying to write my own consumer that would try and work around this error, i.e. ignore the initial message length, and still read the message sets, even though the actual topic/partition/messageset sequences might go over the initial 4 byte int message size. will comment on how this goes.;;;","16/Jan/14 01:08;gerritjvv;I've written a consumer https://github.com/gerritjvv/kafka-fast, its running on the same dataset implemented what I said in the previous comment, I do not see any errors yet.
;;;","02/Jul/14 17:09;dashengju;I have encounter this problem.

I have many topics and partitions, every topic have 2 replicas. Then one broker needs to consumer data from another broker. It seems the broker to fetch many replication,  and the sync was failed, because of the error above. So the ISR list is always just the ""preferred replica"". 

I think this is a big problem.

============= below is the error log ====================================
[2014-06-28 10:00:03,434] ERROR [ReplicaFetcherThread-0-1], Error in fetch Name: FetchRequest; Version: 0; CorrelationId: 710; ClientId: ReplicaFetcherThread-0-1; ReplicaId: 5; MaxWait: 3000 ms; MinBytes: 1 bytes; RequestInfo: [org.wasp_card_log,12] -> PartitionFetchInfo(0,67108864),[org.mobile_push_netevent,1] -> PartitionFetchInfo(492788,67108864),[org.mobile,8] -> PartitionFetchInfo(59767,67108864),[app.newbuyer,7] -> PartitionFetchInfo(42,67108864),[binlog.wwwdeal,6] -> PartitionFetchInfo(1718,67108864),[org.b,6] -> PartitionFetchInfo(150548,67108864),[org.filestorage,14] -> PartitionFetchInfo(11,67108864),[org.feedbackchange,6] -> PartitionFetchInfo(277,67108864),[org.eventlog,6] -> PartitionFetchInfo(101049,67108864),[org.bizappapi,10] -> PartitionFetchInfo(0,67108864),[org.data_resys_routerres,5] -> PartitionFetchInfo(606925,67108864),[log.mobile,5] -> PartitionFetchInfo(0,67108864),[org.mtrace,0] -> PartitionFetchInfo(75581,67108864),[org.mobile,3] -> PartitionFetchInfo(2062782,67108864),[org.data_resys_geo,10] -> PartitionFetchInfo(678,67108864),[org.data_asyncquerier_tablecolumn,12] -> PartitionFetchInfo(1,67108864),[org.mobile_push_applist,10] -> PartitionFetchInfo(2438334,67108864),[org.mobile_hotellog,12] -> PartitionFetchInfo(623,67108864),[org.mobile,15] -> PartitionFetchInfo(2376788,67108864),[org.stormlog,0] -> PartitionFetchInfo(0,67108864),[org.mtcrm,14] -> PartitionFetchInfo(250,67108864),[binlog.coupon,4] -> PartitionFetchInfo(149681,67108864),[org.mtrace,1] -> PartitionFetchInfo(1025277,67108864),[org.cos_sso,15] -> PartitionFetchInfo(3301,67108864),[org.data_resys_router,6] -> PartitionFetchInfo(1031,67108864),[log.mobile,3] -> PartitionFetchInfo(17453,67108864),[log.loginlog,7] -> PartitionFetchInfo(5932,67108864),[org.data_search_queryserver,13] -> PartitionFetchInfo(891,67108864),[org.mobile_push_applist,5] -> PartitionFetchInfo(180204,67108864),[org.data_resys_hotquery,4] -> PartitionFetchInfo(1153,67108864),[org.wasp_device,0] -> PartitionFetchInfo(10,67108864),[org.mobilerpc,9] -> PartitionFetchInfo(42137,67108864),[org.mtrace,9] -> PartitionFetchInfo(1783580,67108864),[org.mobile_push_applist,8] -> PartitionFetchInfo(2471375,67108864),[org.mobile_eventlog,1] -> PartitionFetchInfo(311414,67108864),[org.extendapply,15] -> PartitionFetchInfo(0,67108864),[app.newbuyer,14] -> PartitionFetchInfo(0,67108864),[org.mobile_push_record,13] -> PartitionFetchInfo(11,67108864),[org.mtrace,3] -> PartitionFetchInfo(1578588,67108864),[log.orderlog,8] -> PartitionFetchInfo(0,67108864),[org.mtrace,4] -> PartitionFetchInfo(122482,67108864),[org.tmplog,13] -> PartitionFetchInfo(0,67108864),[org.ecomlogin,0] -> PartitionFetchInfo(2,67108864),[org.payrequest,6] -> PartitionFetchInfo(6207,67108864),[org.dealrank,14] -> PartitionFetchInfo(3699,67108864),[org.wm_submitorder,15] -> PartitionFetchInfo(0,67108864),[org.web_seckill_ticketlog,2] -> PartitionFetchInfo(0,67108864),[org.nginx,4] -> PartitionFetchInfo(3122673,67108864),[org.mobile_group_push,11] -> PartitionFetchInfo(0,67108864),[org.data_resys_routerreq,11] -> PartitionFetchInfo(162226,67108864),[binlog.coupon,10] -> PartitionFetchInfo(32224,67108864),[log.eventlog,10] -> PartitionFetchInfo(31378,67108864),[log.intranet_nginx,2] -> PartitionFetchInfo(0,67108864),[org.extendapply,13] -> PartitionFetchInfo(1,67108864),[log.accesslog,0] -> PartitionFetchInfo(149156,67108864),[org.mobile,4] -> PartitionFetchInfo(51119,67108864),[org.ecomlogin,14] -> PartitionFetchInfo(655,67108864),[org.mobileapp,4] -> PartitionFetchInfo(150715,67108864),[org.mobile_push_netevent,14] -> PartitionFetchInfo(12863099,67108864),[org.wasp_card_log,4] -> PartitionFetchInfo(11,67108864),[org.data_resys_router,4] -> PartitionFetchInfo(35192,67108864),[org.nginx,15] -> PartitionFetchInfo(92880,67108864),[org.mobile_groupapi_search,6] -> PartitionFetchInfo(408,67108864),[org.wasp_page_visit_record,0] -> PartitionFetchInfo(0,67108864),
[log.couponverify,4] -> PartitionFetchInfo(0,67108864),[org.nginx,9] -> PartitionFetchInfo(100270,67108864),[org.mtcrm,7] -> PartitionFetchInfo(5078,67108864),[org.data_resys_hotquery,6] -> PartitionFetchInfo(83107,67108864),[org.mobile_nginx,6] -> PartitionFetchInfo(157869,67108864),[org.mobile,9] -> PartitionFetchInfo(1831700,67108864),[org.intranet_nginx,9] -> PartitionFetchInfo(132779,67108864),[org.mobile_push_applist,4] -> PartitionFetchInfo(2279570,67108864),[org.dealrank,0] -> PartitionFetchInfo(103,67108864),[org.mobile_networklog,3] -> PartitionFetchInfo(1723358,67108864),[org.mobile_movie_statistics,5] -> PartitionFetchInfo(6309,67108864),[org.mtrace,2] -> PartitionFetchInfo(94002,67108864),[org.data_asyncquerier_sql,7] -> PartitionFetchInfo(1,67108864),[org.spamlogin,12] -> PartitionFetchInfo(2480,67108864),[org.search_dealrank,8] -> PartitionFetchInfo(24118,67108864),[log.orderlog,1] -> PartitionFetchInfo(7231,67108864),[log.b,12] -> PartitionFetchInfo(0,67108864),[org.mobile_push_netevent,11] -> PartitionFetchInfo(659425,67108864),[org.mobile_networklog,9] -> PartitionFetchInfo(1251021,67108864),[org.data_resys_combinerec,11] -> PartitionFetchInfo(21870,67108864),[org.paytobiznotify,9] -> PartitionFetchInfo(0,67108864),[org.mobile_push_applist,12] -> PartitionFetchInfo(3099746,67108864),[org.mtrace,7] -> PartitionFetchInfo(1190072,67108864),[org.mobile_nginx,0] -> PartitionFetchInfo(174905,67108864),[org.web_user_message_op,8] -> PartitionFetchInfo(4529,67108864),[binlog.coupon,12] -> PartitionFetchInfo(23996,67108864),[org.tmplog,15] -> PartitionFetchInfo(0,67108864),[org.paylog,1] -> PartitionFetchInfo(489,67108864),[org.data_resys_routerres,7] -> PartitionFetchInfo(10502,67108864),[binlog.coupon,0] -> PartitionFetchInfo(25215,67108864),[org.nginxerrorlog,9] -> PartitionFetchInfo(29483,67108864),[org.mobile_push_applist,11] -> PartitionFetchInfo(103347,67108864),[org.basync,7] -> PartitionFetchInfo(299174,67108864),[org.mobile_push_netevent,0] -> PartitionFetchInfo(12720799,67108864),[org.basync,5] -> PartitionFetchInfo(4184,67108864),[org.mobile_nginx,12] -> PartitionFetchInfo(181939,67108864),[org.cos_errorlog,0] -> PartitionFetchInfo(189,67108864),[org.nginxerrorlog,15] -> PartitionFetchInfo(27555,67108864),[org.captcha,4] -> PartitionFetchInfo(14233,67108864),[org.data_search_smartbox,11] -> PartitionFetchInfo(0,67108864),[org.mobile_push_applist,2] -> PartitionFetchInfo(2371719,67108864),[org.mobile,5] -> PartitionFetchInfo(1906756,67108864),[org.mobile_movielog,3] -> PartitionFetchInfo(126780,67108864),[org.mobile_push_netevent,8] -> PartitionFetchInfo(10731244,67108864),[org.nginxerrorlog,14] -> PartitionFetchInfo(1525,67108864),[org.bdecomaction,2] -> PartitionFetchInfo(0,67108864),[org.cos_errorlog,12] -> PartitionFetchInfo(123,67108864),[org.mobile_networklog,2] -> PartitionFetchInfo(62332,67108864),[org.mobile_xmlog,8] -> PartitionFetchInfo(478,67108864),[org.mobile_eventlog,15] -> PartitionFetchInfo(8429,67108864),[org.cos_errorlog,10] -> PartitionFetchInfo(2569,67108864),[org.eventlog,4] -> PartitionFetchInfo(935,67108864),[org.data_asyncquerier_sql,14] -> PartitionFetchInfo(0,67108864),[org.dealrank,12] -> PartitionFetchInfo(93,67108864),[org.search_queryserver,1] -> PartitionFetchInfo(0,67108864),[binlog.user,5] -> PartitionFetchInfo(5950,67108864),[org.mobile_group_push,9] -> PartitionFetchInfo(25002,67108864),[org.mobile,13] -> PartitionFetchInfo(2117661,67108864),[org.nginx,11] -> PartitionFetchInfo(140093,67108864),[org.mobile_push_applist,7] -> PartitionFetchInfo(171384,67108864),[org.mobile_push_netevent,13] -> PartitionFetchInfo(531815,67108864),[org.mobile_eventlog,3] -> PartitionFetchInfo(14430,67108864),[org.captcha,6] -> PartitionFetchInfo(88,67108864),[org.mobile_push_netevent,5] -> PartitionFetchInfo(460960,67108864),[org.mobile_order_nomsg,4] -> PartitionFetchInfo(3,67108864),[org.data_xmltableview_access,2] -> PartitionFetchInfo(7,67108864),[org.payrequest,13] -> PartitionFetchInfo(101,67108864),[org.mtrace,8] -> Partiti
...
4),[org.mobile_mars_report,10] -> PartitionFetchInfo(2926,67108864),[org.mobile,12] -> PartitionFetchInfo(55550,67108864),[org.mobile_movielog,2] -> PartitionFetchInfo(1519,67108864),[org.commonsubscribe,3] -> PartitionFetchInfo(0,67108864),[org.apacheerrorlog,14] -> PartitionFetchInfo(1366,67108864),[org.wm_submitorder,13] -> PartitionFetchInfo(3,67108864),[org.data_resys_routerreq,9] -> PartitionFetchInfo(1582,67108864),[org.mobile_push_applist,1] -> PartitionFetchInfo(228829,67108864),[org.mtrace,11] -> PartitionFetchInfo(1232471,67108864),[org.404log,12] -> PartitionFetchInfo(0,67108864),[org.mtsg,4] -> PartitionFetchInfo(4,67108864),[org.applog,4] -> PartitionFetchInfo(607,67108864),[org.mobile_movielog,8] -> PartitionFetchInfo(3223,67108864),[org.mobile_push_netevent,6] -> PartitionFetchInfo(13081128,67108864),[org.cmsdealapi,11] -> PartitionFetchInfo(0,67108864),[org.mobile,2] -> PartitionFetchInfo(53029,67108864),[org.mobilerebindinfo,6] -> PartitionFetchInfo(32,67108864),[org.nginx,3] -> PartitionFetchInfo(105261,67108864),[org.mobile_push_applist,3] -> PartitionFetchInfo(162462,67108864),[org.mobile_xmlog,10] -> PartitionFetchInfo(21754,67108864),[org.mobile,6] -> PartitionFetchInfo(65015,67108864),[org.mobile_movielog,9] -> PartitionFetchInfo(132672,67108864),[org.intranet_nginx,11] -> PartitionFetchInfo(4738,67108864),[binlog.user,0] -> PartitionFetchInfo(225872,67108864) (kafka.server.ReplicaFetcherThread)
java.lang.IllegalArgumentException
at java.nio.Buffer.limit(Buffer.java:267)
at kafka.api.FetchResponsePartitionData$.readFrom(FetchResponse.scala:33)
at kafka.api.TopicData$$anonfun$1.apply(FetchResponse.scala:83)
at kafka.api.TopicData$$anonfun$1.apply(FetchResponse.scala:81)
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
at scala.collection.immutable.Range.foreach(Range.scala:141)
at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
at scala.collection.AbstractTraversable.map(Traversable.scala:105)
at kafka.api.TopicData$.readFrom(FetchResponse.scala:81)
at kafka.api.FetchResponse$$anonfun$3.apply(FetchResponse.scala:142)
at kafka.api.FetchResponse$$anonfun$3.apply(FetchResponse.scala:141)
at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:251)
at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:251)
at scala.collection.immutable.Range.foreach(Range.scala:141)
at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:251)
at scala.collection.AbstractTraversable.flatMap(Traversable.scala:105)
at kafka.api.FetchResponse$.readFrom(FetchResponse.scala:141)
at kafka.consumer.SimpleConsumer.fetch(SimpleConsumer.scala:112)
at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:96)
at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:88)
at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51);;;","02/Jul/14 23:44;junrao;You can do one or more of the following to get around this.

1. Increase num.replica.fetchers (http://kafka.apache.org/documentation.html#brokerconfigs)
2. Reduce replica.fetch.max.bytes, but make sure it's still >= message.max.bytes.;;;","03/Jul/14 10:24;dashengju;Thanks for your reply. 
I will try to increase num.replica.fetchers in our production environment.
do you have any plan to fixing the issue?;;;","17/Oct/14 00:55;ewencp;Created reviewboard https://reviews.apache.org/r/26811/diff/
 against branch origin/trunk;;;","17/Oct/14 00:57;ewencp;This is a wip patch to fix this issue, which previous discussion suggests was due to the FetchResponse exceeding 2GB. My approach to triggering the issue, however, doesn't exhibit exactly the same issue but does cause an unrecoverable error that causes the consumer connection to terminate. (For reference, it causes the server to fail when FetchResponseSend.writeTo calls expectIncomplete and sendSize is negative due to overflow. This confuses the server since it looks like the message is already done sending and the server forcibly closes the consumer's connection.)

The patch addresses the core issue by ensuring the returned message doesn't exceed 2GB by dropping parts of it in a way that otherwise shouldn't affect the consumer. But there are a lot of points that still need to be addressed:

* I started by building an integration test to trigger the issue, included in PrimitiveApiTest. However, since we necessarily need to have > 2GB data to trigger the issue, it's probably too expensive to include in this way. Offline discussion suggests maybe a system test would be a better place to include this. It's still included here for completeness.
* The implementation filters to a subset of the data in FetchResponse. The main reason for this is that this process needs to know the exact (or at least conservative estimate) size of serialized data, which only FetchResponse knows. But it's also a bit weird compared to other message classes, which are case classes and don't modify those inputs.
* Algorithm for choosing subset to return: initial approach is to remove random elements until we get below the limit. This is simple to understand and avoids starvation of specific TopicAndPartitions. Any concerns with this basic approach?
* I'm pretty sure I've managed to keep the < 2GB case to effectively the same computational cost (computing the serialized size, grouped data, etc. exactly once as before). However, for the > 2GB case I've only ensured correctness. In particular, the progressive removal and reevaluation of serialized size could potentially be very bad for very large data sets (e.g. starting a mirror maker against a large data set with large # of partitions from scratch).
* Note that the algorithm never deals with the actual message data, only metadata about what messages are available. This is relevant since this is what suggested the approach in the patch could still be performant -- ReplicaManager.readMessageSets processes the entire FetchRequest and filters it down because the metadata involved is relatively small.
* Based on the previous two points, this really needs some more realistic large scale system tests to make sure this approach is not only correct, but provides reasonable performance (or indicates we need to revise the algorithm for selecting a subset of the data).
* Testing isn't really complete -- I triggered the issue with 4 topics * 600 MB/topic, which is > 2GB. Another obvious case to check is when some partitions contain > 2GB on their own.
* I'd like someone to help sanity check the exact maximum FetchResponse serialized size we limit messages to. It's not Int.MaxValue because the FetchResponseSend class adds 4 + FetchResponse.sizeInBytes for it's own size. I'd like a sanity check that the extra 4 bytes is enough -- is there any additional wrapping we might need to account for? Getting a test to hit exactly that narrow range could be tricky.
* The tests include both immediate-response and purgatory paths, but the purgatory version requires a timeout in the test, which could end up being flaky + wasting time, but it doesn't look like there's a great way to mock that right now. Maybe this doesn't matter if it moves to a system test?
* One case this doesn't handle yet is when the data reaches > 2GB after it's in the purgatory. The result is correct, but the response is not sent as soon as that condition is satisfied. This is because it looks like evaluating this exactly would require calling readMessageSets and evaluating the size of the message for every DelayedFetch.isSatisifed call. This sounds like it could end up being pretty expensive. Maybe there's a better way, perhaps an approximate scheme?
* The test requires some extra bytes in the fetchSize for each partition, presumably for overhead in encoding. I haven't tracked down exactly how big that should be, but I'm guessing it could end up affecting the results of more comprehensive tests.;;;","24/Feb/16 13:39;ijuma;[~ewencp], this is marked as ""Blocker"" with a ""Fix Version"" of 0.10.0. Is that really the case?;;;","24/Feb/16 13:55;ewencp;[~ijuma] Pretty sure I didn't set the fix version on this (it's a throwback, and I doubt I would have known what fix version to set back then anyway). Probably was set incorrectly w/ the initial report and can be changed.;;;","26/Sep/16 11:48;becket_qin;This issue should have been resolved by KIP-74 (KAFKA-2063).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Partitions for topic not created after restart from forced shutdown,KAFKA-1738,12751679,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,junrao,pradeepbadiger,pradeepbadiger,30/Oct/14 21:37,08/Nov/14 02:47,22/Mar/23 15:10,08/Nov/14 02:47,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"We are using Kafka Topic APIs to create the topic. But in some cases, the topic gets created but we don't see the partition specific files and when producer/consumer tries to get the topic metadata and it fails with exception. Same happens if one tries to create using the command line.

k.p.BrokerPartitionInfo - Error while fetching metadata [{TopicMetadata for topic tloader1 -> No partition metadata for topic tloader1 due to kafka.common.UnknownTopicOrPartitionException}] for topic [tloader1]: class kafka.common.UnknownTopicOrPartitionException

Steps to reproduce - 

1.      Stop kafka using kill  -9 <PID of Kafka>
2.      Start Kafka
3.      Create Topic with partition and replication factor of 1.
4.      Check the response “Created topic <topic_name>”
5.      Run the list command to verify if its created.
6.      Now check the data directory of kakfa. There would not be any for the newly created topic.


We see issues when we are creating new topics. This happens randomly and we dont know the exact reasons. We see the below logs in controller during the time of creation of topics which doesnt have the partition files.

2014-11-03 13:12:50,625] INFO [Controller 0]: New topic creation callback for [JobJTopic,0] (kafka.controller.KafkaController)
[2014-11-03 13:12:50,626] INFO [Controller 0]: New partition creation callback for [JobJTopic,0] (kafka.controller.KafkaController)
[2014-11-03 13:12:50,626] INFO [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [JobJTopic,0] (kafka.controller.PartitionStateMachine)
[2014-11-03 13:12:50,653] INFO [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=JobJTopic,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[2014-11-03 13:12:50,654] INFO [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [JobJTopic,0] (kafka.controller.PartitionStateMachine)
[2014-11-03 13:12:50,654] DEBUG [Partition state machine on Controller 0]: Live assigned replicas for partition [JobJTopic,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[2014-11-03 13:12:50,654] DEBUG [Partition state machine on Controller 0]: Initializing leader and isr for partition [JobJTopic,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:2) (kafka.controller.PartitionStateMachine)
[2014-11-03 13:12:50,667] INFO [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=JobJTopic,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[2014-11-03 13:12:50,794] WARN [Controller-0-to-broker-0-send-thread], Controller 0 fails to send a request to broker id:0,host:DMIPVM,port:9092 (kafka.controller.RequestSendThread)
java.io.EOFException: Received -1 when reading from channel, socket has likely been closed.
	at kafka.utils.Utils$.read(Utils.scala:381)
	at kafka.network.BoundedByteBufferReceive.readFrom(BoundedByteBufferReceive.scala:54)
	at kafka.network.Receive$class.readCompletely(Transmission.scala:56)
	at kafka.network.BoundedByteBufferReceive.readCompletely(BoundedByteBufferReceive.scala:29)
	at kafka.network.BlockingChannel.receive(BlockingChannel.scala:108)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:146)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)
[2014-11-03 13:12:50,965] ERROR [Controller-0-to-broker-0-send-thread], Controller 0 epoch 2 failed to send request Name:UpdateMetadataRequest;Version:0;Controller:0;ControllerEpoch:2;CorrelationId:43;ClientId:id_0-host_null-port_9092;AliveBrokers:id:0,host:DMIPVM,port:9092;PartitionState:[JobJTopic,0] -> (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:2),ReplicationFactor:1),AllReplicas:0) to broker id:0,host:DMIPVM,port:9092. Reconnecting to broker. (kafka.controller.RequestSendThread)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:97)
	at kafka.controller.RequestSendThread.liftedTree1$1(ControllerChannelManager.scala:132)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:131)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)


","Linux, 2GB RAM, 2 Core CPU",junrao,nehanarkhede,pradeepbadiger,schandr,thathineni.srihari@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1713,,,,,,,,,,,,,,,,,,,,,"05/Nov/14 10:42;pradeepbadiger;1738.zip;https://issues.apache.org/jira/secure/attachment/12679461/1738.zip","06/Nov/14 03:21;schandr;ServerLogForFailedTopicCreation.txt;https://issues.apache.org/jira/secure/attachment/12679604/ServerLogForFailedTopicCreation.txt","06/Nov/14 03:16;schandr;ServerLogForFailedTopicCreation.txt;https://issues.apache.org/jira/secure/attachment/12679598/ServerLogForFailedTopicCreation.txt","06/Nov/14 03:16;schandr;ServerLogForSuccessfulTopicCreation.txt;https://issues.apache.org/jira/secure/attachment/12679599/ServerLogForSuccessfulTopicCreation.txt","07/Nov/14 01:34;junrao;kafka-1738.patch;https://issues.apache.org/jira/secure/attachment/12679889/kafka-1738.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 07 18:47:32 UTC 2014,,,,,,,,,,"0|i21rpz:",9223372036854775807,,nehanarkhede,,,,,,,,,,,,,,,,,,"31/Oct/14 00:58;nehanarkhede;[~pradeepbadiger] Do you also try to send data to the topic you are hoping to see the logs for?;;;","31/Oct/14 10:51;pradeepbadiger;Yes. We tried sending data but it gave the exception.

k.p.BrokerPartitionInfo - Error while fetching metadata [{TopicMetadata for topic JobCTopic -> No partition metadata for topic JobCTopic due to kafka.common.UnknownTopicOrPartitionException}] for topic [JobCTopic]: class kafka.common.UnknownTopicOrPartitionException;;;","04/Nov/14 10:13;junrao;I can't reproduce this issue by following the steps in the description. Does this happen every time?
;;;","05/Nov/14 00:41;pradeepbadiger;yes.. This is happening in 8.2.0-beta version which we are currently on. I had two topic in kakfa before killing the service and i added three more topics (ATopic, BTopic and CTopic) and all of them got created successfully as you can see below. When i list it i can see the topics in kakfa. But if i see the data folder in kafka, i dont see the partition folders/files for them. Let me know if you need more details.

[root@dmipvm temp]# service kafka status
Kafka is running as 19396.
    LISTEN on tcp port=9999
    LISTEN on tcp port=53536
    LISTEN on tcp port=9092
    LISTEN on tcp port=48330
[root@dmipvm temp]# kill -9 19396
[root@dmipvm temp]# service kafka start
Starting kafka ... STARTED.
[root@dmipvm temp]# /apps/kafka/bin/kafka-topics.sh --create --topic ATopic --partitions 1 --replication-factor 1 --zookeeper localhost:2181
Created topic ""ATopic"".
[root@dmipvm temp]# /apps/kafka/bin/kafka-topics.sh --create --topic BTopic --partitions 1 --replication-factor 1 --zookeeper localhost:2181
Created topic ""BTopic"".
[root@dmipvm temp]# /apps/kafka/bin/kafka-topics.sh --create --topic CTopic --partitions 1 --replication-factor 1 --zookeeper localhost:2181
Created topic ""CTopic"".
[root@dmipvm temp]#


[root@DMIPVM kafka]# ls -lrt
total 16
drwxr-xr-x 2 root root 4096 Nov  4 11:32 topic_1-0
drwxr-xr-x 2 root root 4096 Nov  4 11:34 topic_2-0
-rw-r--r-- 1 root root   28 Nov  4 11:35 replication-offset-checkpoint
-rw-r--r-- 1 root root   28 Nov  4 11:36 recovery-point-offset-checkpoint


[root@DMIPVM kafka]# /apps/kafka/bin/kafka-topics.sh --list --zookeeper localhost:2181
ATopic
BTopic
CTopic
topic_1
topic_2
;;;","05/Nov/14 10:42;pradeepbadiger;Attachment 1738.zip contains logs and a script which creates a topic every 10 mins.;;;","06/Nov/14 00:28;junrao;The log shows that the log dir was created for topic_A. Were you looking at the right directory?

[2014-11-04 21:36:30,724] INFO Created log for partition [topic_A,0] in /tmp/kafka-logs with properties;;;","06/Nov/14 01:01;pradeepbadiger;I suggest you to run the script once on a working setup of kafka. The only error that we see on kafka controller.log is 

[2014-11-05 11:42:53,088] DEBUG [Partition state machine on Controller 0]: Live assigned replicas for partition [topic_13,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[2014-11-05 11:42:53,088] DEBUG [Partition state machine on Controller 0]: Initializing leader and isr for partition [topic_13,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:5) (kafka.controller.PartitionStateMachine)
[2014-11-05 11:42:53,097] WARN [Controller-0-to-broker-0-send-thread], Controller 0 fails to send a request to broker id:0,host:DMIPVM,port:9092 (kafka.controller.RequestSendThread)
java.io.EOFException: Received -1 when reading from channel, socket has likely been closed.
	at kafka.utils.Utils$.read(Utils.scala:381)
	at kafka.network.BoundedByteBufferReceive.readFrom(BoundedByteBufferReceive.scala:54)
	at kafka.network.Receive$class.readCompletely(Transmission.scala:56)
	at kafka.network.BoundedByteBufferReceive.readCompletely(BoundedByteBufferReceive.scala:29)
	at kafka.network.BlockingChannel.receive(BlockingChannel.scala:108)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:146)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)
[2014-11-05 11:42:53,097] INFO [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=topic_13,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[2014-11-05 11:42:53,097] ERROR [Controller-0-to-broker-0-send-thread], Controller 0 epoch 5 failed to send request Name:UpdateMetadataRequest;Version:0;Controller:0;ControllerEpoch:5;CorrelationId:16;ClientId:id_0-host_null-port_9092;AliveBrokers:id:0,host:DMIPVM,port:9092;PartitionState:[topic_13,0] -> (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:5),ReplicationFactor:1),AllReplicas:0) to broker id:0,host:DMIPVM,port:9092. Reconnecting to broker. (kafka.controller.RequestSendThread)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:97)
	at kafka.controller.RequestSendThread.liftedTree1$1(ControllerChannelManager.scala:132)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:131)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)
[2014-11-05 11:42:53,099] INFO [Controller-0-to-broker-0-send-thread], Controller 0 connected to id:0,host:DMIPVM,port:9092 for sending state change requests (kafka.controller.RequestSendThread)
[2014-11-05 11:45:34,605] TRACE [Controller 0]: checking need to trigger partition rebalance (kafka.controller.KafkaController)
[2014-11-05 11:45:34,607] DEBUG [Controller 0]: preferred replicas by broker Map(0 -> Map([topic_8,0] -> List(0), [topic_13,0] -> List(0), [topic_6,0] -> List(0), [topic_1,0] -> List(0), [topic_9,0] -> List(0), [topic_2,0] -> List(0), [topic_11,0] -> List(0), [topic_4,0] -> List(0), [topic_12,0] -> List(0), [topic_7,0] -> List(0), [topic_3,0] -> List(0), [topic_10,0] -> List(0))) (kafka.controller.KafkaController)
[2014-11-05 11:45:34,608] DEBUG [Controller 0]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[2014-11;;;","06/Nov/14 01:19;junrao;Yes, I started a kafka broker and ran your script. I was able to see local logs created.

ls /tmp/kafka-logs/
juntopic-0				test-0					topic3-0				topic_3-0
recovery-point-offset-checkpoint	topic1-0				topic_1-0				topic_4-0
replication-offset-checkpoint		topic2-0				topic_2-0				topic_5-0

The error you saw typically happens when a broker is down. Can you telnet to host DMIPVM on port 9092 when the broker is up?
;;;","06/Nov/14 01:24;pradeepbadiger;Can you provide the configuration files? We are using the default configurations and the script tries to create a topic every 10 mins. Also, i tried telnet and the broker is up.;;;","06/Nov/14 01:37;schandr;Here are the additional logs for the same issue

Controller.log
[2014-11-05 10:31:12,441] WARN [Controller-0-to-broker-0-send-thread], Controller 0 fails to send a request to broker id:0,host:localhost.localdomain,port:9092 (kafka.controller.RequestSendThread)
java.io.EOFException: Received -1 when reading from channel, socket has likely been closed.
	at kafka.utils.Utils$.read(Utils.scala:381)
	at kafka.network.BoundedByteBufferReceive.readFrom(BoundedByteBufferReceive.scala:54)
	at kafka.network.Receive$class.readCompletely(Transmission.scala:56)
	at kafka.network.BoundedByteBufferReceive.readCompletely(BoundedByteBufferReceive.scala:29)
	at kafka.network.BlockingChannel.receive(BlockingChannel.scala:108)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:146)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)
[2014-11-05 10:31:12,445] ERROR [Controller-0-to-broker-0-send-thread], Controller 0 epoch 7 failed to send request Name:UpdateMetadataRequest;Version:0;Controller:0;ControllerEpoch:7;CorrelationId:8;ClientId:id_0-host_null-port_9092;AliveBrokers:id:0,host:localhost.localdomain,port:9092;PartitionState:[topic_30,0] -> (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0),[topic_5,0] -> (LeaderAndIsrInfo:(Leader:-2,ISR:0,LeaderEpoch:0,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0) to broker id:0,host:localhost.localdomain,port:9092. Reconnecting to broker. (kafka.controller.RequestSendThread)
java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:97)
	at kafka.controller.RequestSendThread.liftedTree1$1(ControllerChannelManager.scala:132)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:131)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)
[2014-11-05 10:31:12,448] INFO [Controller-0-to-broker-0-send-thread], Controller 0 connected to id:0,host:localhost.localdomain,port:9092 for sending state change requests (kafka.controller.RequestSendThread)

Server.log

[2014-11-05 10:31:12,414] DEBUG Got notification sessionid:0x14980b08c110003 (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,415] DEBUG Got WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/brokers/topics for sessionid 0x14980b08c110003 (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,415] DEBUG Received event: WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/brokers/topics (org.I0Itec.zkclient.ZkClient)
[2014-11-05 10:31:12,415] DEBUG New event: ZkEvent[Children of /brokers/topics changed sent to kafka.controller.PartitionStateMachine$TopicChangeListener@1fc5681] (org.I0Itec.zkclient.ZkEventThread)
[2014-11-05 10:31:12,415] DEBUG Leaving process event (org.I0Itec.zkclient.ZkClient)
[2014-11-05 10:31:12,415] DEBUG Delivering event #3 ZkEvent[Children of /brokers/topics changed sent to kafka.controller.PartitionStateMachine$TopicChangeListener@1fc5681] (org.I0Itec.zkclient.ZkEventThread)
[2014-11-05 10:31:12,415] DEBUG Got ping response for sessionid: 0x14980b08c110003 after 0ms (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,416] DEBUG Reading reply sessionid:0x14980b08c110003, packet:: clientPath:null serverPath:null finished:false header:: 257,3  replyHeader:: 257,13610,0  request:: '/brokers/topics,T  response:: s{6,6,1415130748279,1415130748279,0,23,0,0,0,23,13610}  (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,417] DEBUG Reading reply sessionid:0x14980b08c110003, packet:: clientPath:null serverPath:null finished:false header:: 258,8  replyHeader:: 258,13610,0  request:: '/brokers/topics,T  response:: v{'topic_23,'topic_18,'topic_22,'topic_17,'topic_25,'topic_16,'topic_24,'topic_15,'topic_14,'topic_13,'topic_12,'topic_11,'topic_19,'topic_5,'topic_7,'topic_6,'Test1,'topic_10,'topic_9,'topic_8,'topic_20,'topic_30,'topic_21}  (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,420] DEBUG Reading reply sessionid:0x14980b08c110003, packet:: clientPath:null serverPath:null finished:false header:: 259,4  replyHeader:: 259,13610,0  request:: '/brokers/topics/topic_30,F  response:: #7b2276657273696f6e223a312c22706172746974696f6e73223a7b2230223a5b305d7d7d,s{13610,13610,1415205072414,1415205072414,0,0,0,0,36,0,13610}  (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,422] DEBUG Replicas assigned to topic [topic_30], partition [0] are [List(0)] (kafka.utils.ZkUtils$)
[2014-11-05 10:31:12,422] DEBUG Replicas assigned to topic [topic_30], partition [0] are [List(0)] (kafka.utils.ZkUtils$)
[2014-11-05 10:31:12,425] DEBUG Reading reply sessionid:0x14980b08c110003, packet:: clientPath:null serverPath:null finished:false header:: 260,3  replyHeader:: 260,13611,0  request:: '/brokers/topics/topic_30,T  response:: s{13610,13610,1415205072414,1415205072414,0,0,0,0,36,0,13610}  (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,425] DEBUG Subscribed data changes for /brokers/topics/topic_30 (org.I0Itec.zkclient.ZkClient)
[2014-11-05 10:31:12,427] DEBUG Reading reply sessionid:0x14980b08c110003, packet:: clientPath:null serverPath:null finished:false header:: 261,4  replyHeader:: 261,13611,0  request:: '/brokers/topics/topic_30,T  response:: #7b2276657273696f6e223a312c22706172746974696f6e73223a7b2230223a5b305d7d7d,s{13610,13610,1415205072414,1415205072414,0,0,0,0,36,0,13610}  (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,430] DEBUG Reading reply sessionid:0x14980b08c110003, packet:: clientPath:null serverPath:null finished:false header:: 262,4  replyHeader:: 262,13611,-101  request:: '/brokers/topics/topic_30/partitions/0/state,F  response::   (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,434] DEBUG Reading reply sessionid:0x14980b08c110003, packet:: clientPath:null serverPath:null finished:false header:: 263,1  replyHeader:: 263,13612,-101  request:: '/brokers/topics/topic_30/partitions/0/state,#7b22636f6e74726f6c6c65725f65706f6368223a372c226c6561646572223a302c2276657273696f6e223a312c226c65616465725f65706f6368223a302c22697372223a5b305d7d,v{s{31,s{'world,'anyone}}},0  response::   (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,435] DEBUG Reading reply sessionid:0x14980b08c110003, packet:: clientPath:null serverPath:null finished:false header:: 264,1  replyHeader:: 264,13613,-101  request:: '/brokers/topics/topic_30/partitions/0,,v{s{31,s{'world,'anyone}}},0  response::   (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,437] DEBUG Reading reply sessionid:0x14980b08c110003, packet:: clientPath:null serverPath:null finished:false header:: 265,1  replyHeader:: 265,13614,0  request:: '/brokers/topics/topic_30/partitions,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/topic_30/partitions  (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,438] DEBUG Reading reply sessionid:0x14980b08c110003, packet:: clientPath:null serverPath:null finished:false header:: 266,1  replyHeader:: 266,13615,0  request:: '/brokers/topics/topic_30/partitions/0,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/topic_30/partitions/0  (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,439] DEBUG Reading reply sessionid:0x14980b08c110003, packet:: clientPath:null serverPath:null finished:false header:: 267,1  replyHeader:: 267,13616,0  request:: '/brokers/topics/topic_30/partitions/0/state,#7b22636f6e74726f6c6c65725f65706f6368223a372c226c6561646572223a302c2276657273696f6e223a312c226c65616465725f65706f6368223a302c22697372223a5b305d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/topic_30/partitions/0/state  (org.apache.zookeeper.ClientCnxn)
[2014-11-05 10:31:12,440] TRACE 131 bytes written. (kafka.network.BoundedByteBufferSend)
[2014-11-05 10:31:12,440] TRACE 131 bytes written. (kafka.network.BoundedByteBufferSend)
[2014-11-05 10:31:12,441] DEBUG Delivering event #3 done (org.I0Itec.zkclient.ZkEventThread)
[2014-11-05 10:31:12,448] DEBUG Created socket with SO_TIMEOUT = 90000 (requested 90000), SO_RCVBUF = 43690 (requested -1), SO_SNDBUF = 84580 (requested -1). (kafka.network.BlockingChannel)
[2014-11-05 10:31:12,448] DEBUG Created socket with SO_TIMEOUT = 90000 (requested 90000), SO_RCVBUF = 43690 (requested -1), SO_SNDBUF = 84580 (requested -1). (kafka.network.BlockingChannel)
[2014-11-05 10:31:12,448] DEBUG Accepted connection from /127.0.0.1 on /127.0.0.1:9092. sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [102400|102400] (kafka.network.Acceptor)
[2014-11-05 10:31:12,448] DEBUG Accepted connection from /127.0.0.1 on /127.0.0.1:9092. sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [102400|102400] (kafka.network.Acceptor)
[2014-11-05 10:31:12,449] TRACE Processor id 1 selection time = 228708013 ns (kafka.network.Processor)
[2014-11-05 10:31:12,449] TRACE Processor id 1 selection time = 228708013 ns (kafka.network.Processor)
[2014-11-05 10:31:12,449] DEBUG Processor 1 listening to new connection from /127.0.0.1:55693 (kafka.network.Processor)
[2014-11-05 10:31:12,449] DEBUG Processor 1 listening to new connection from /127.0.0.1:55693 (kafka.network.Processor)
[2014-11-05 10:31:12,550] TRACE Processor id 7 selection time = 301161349 ns (kafka.network.Processor)
[2014-11-05 10:31:12,550] TRACE Processor id 7 selection time = 301161349 ns (kafka.network.Processor)
[2014-11-05 10:31:12,596] TRACE Processor id 3 selection time = 300772884 ns (kafka.network.Processor)
[2014-11-05 10:31:12,596] TRACE Processor id 3 selection time = 300772884 ns (kafka.network.Processor)
[2014-11-05 10:31:12,640] TRACE Processor id 6 selection time = 301205873 ns (kafka.network.Processor)
[2014-11-05 10:31:12,640] TRACE Processor id 6 selection time = 301205873 ns (kafka.network.Processor)
[2014-11-05 10:31:12,660] TRACE Processor id 8 selection time = 301212710 ns (kafka.network.Processor)
[2014-11-05 10:31:12,660] TRACE Processor id 8 selection time = 301212710 ns (kafka.network.Processor)
[2014-11-05 10:31:12,660] TRACE Processor id 9 selection time = 301187091 ns (kafka.network.Processor)
[2014-11-05 10:31:12,660] TRACE Processor id 9 selection time = 301187091 ns (kafka.network.Processor)
[2014-11-05 10:31:12,673] TRACE Processor id 0 selection time = 301144174 ns (kafka.network.Processor)
[2014-11-05 10:31:12,673] TRACE Processor id 0 selection time = 301144174 ns (kafka.network.Processor)
[2014-11-05 10:31:12,674] TRACE Processor id 4 selection time = 301200540 ns (kafka.network.Processor)
[2014-11-05 10:31:12,674] TRACE Processor id 4 selection time = 301200540 ns (kafka.network.Processor)
[2014-11-05 10:31:12,675] TRACE Processor id 2 selection time = 301240208 ns (kafka.network.Processor)
[2014-11-05 10:31:12,675] TRACE Processor id 2 selection time = 301240208 ns (kafka.network.Processor)
[2014-11-05 10:31:12,679] TRACE Processor id 5 selection time = 301217390 ns (kafka.network.Processor)
[2014-11-05 10:31:12,679] TRACE Processor id 5 selection time = 301217390 ns (kafka.network.Processor)
[2014-11-05 10:31:12,750] TRACE Processor id 1 selection time = 300491401 ns (kafka.network.Processor)
[2014-11-05 10:31:12,750] TRACE Processor id 1 selection time = 300491401 ns (kafka.network.Processor)
[2014-11-05 10:31:12,750] TRACE 176 bytes written. (kafka.network.BoundedByteBufferSend)
[2014-11-05 10:31:12,750] TRACE 176 bytes written. (kafka.network.BoundedByteBufferSend)
[2014-11-05 10:31:12,750] TRACE Processor id 1 selection time = 232897 ns (kafka.network.Processor)
[2014-11-05 10:31:12,750] TRACE Processor id 1 selection time = 232897 ns (kafka.network.Processor)
[2014-11-05 10:31:12,750] TRACE 172 bytes read from /127.0.0.1:55693 (kafka.network.Processor)
[2014-11-05 10:31:12,750] TRACE 172 bytes read from /127.0.0.1:55693 (kafka.network.Processor)
[2014-11-05 10:31:12,751] TRACE [Kafka Request Handler 2 on Broker 0], Kafka request handler 2 on broker 0 handling request Request(1,sun.nio.ch.SelectionKeyImpl@3a6a2cf,null,1415205072751,/127.0.0.1:55693) (kafka.server.KafkaRequestHandler)
[2014-11-05 10:31:12,751] TRACE [Kafka Request Handler 2 on Broker 0], Kafka request handler 2 on broker 0 handling request Request(1,sun.nio.ch.SelectionKeyImpl@3a6a2cf,null,1415205072751,/127.0.0.1:55693) (kafka.server.KafkaRequestHandler)
[2014-11-05 10:31:12,751] TRACE [KafkaApi-0] Handling request: Name:UpdateMetadataRequest;Version:0;Controller:0;ControllerEpoch:7;CorrelationId:8;ClientId:id_0-host_null-port_9092;AliveBrokers:id:0,host:localhost.localdomain,port:9092;PartitionState:[topic_30,0] -> (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0),[topic_5,0] -> (LeaderAndIsrInfo:(Leader:-2,ISR:0,LeaderEpoch:0,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0) from client: /127.0.0.1:55693 (kafka.server.KafkaApis)
[2014-11-05 10:31:12,751] TRACE [KafkaApi-0] Handling request: Name:UpdateMetadataRequest;Version:0;Controller:0;ControllerEpoch:7;CorrelationId:8;ClientId:id_0-host_null-port_9092;AliveBrokers:id:0,host:localhost.localdomain,port:9092;PartitionState:[topic_30,0] -> (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0),[topic_5,0] -> (LeaderAndIsrInfo:(Leader:-2,ISR:0,LeaderEpoch:0,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0) from client: /127.0.0.1:55693 (kafka.server.KafkaApis)
[2014-11-05 10:31:12,752] TRACE Processor id 1 selection time = 660576 ns (kafka.network.Processor)
[2014-11-05 10:31:12,752] TRACE Processor id 1 selection time = 660576 ns (kafka.network.Processor)
[2014-11-05 10:31:12,753] TRACE Socket server received response to send, registering for write: Response(1,Request(1,sun.nio.ch.SelectionKeyImpl@3a6a2cf,null,1415205072751,/127.0.0.1:55693),kafka.network.BoundedByteBufferSend@6d0015b6,SendAction) (kafka.network.Processor)
[2014-11-05 10:31:12,753] TRACE Socket server received response to send, registering for write: Response(1,Request(1,sun.nio.ch.SelectionKeyImpl@3a6a2cf,null,1415205072751,/127.0.0.1:55693),kafka.network.BoundedByteBufferSend@6d0015b6,SendAction) (kafka.network.Processor)
[2014-11-05 10:31:12,753] TRACE Processor id 1 selection time = 12017 ns (kafka.network.Processor)
[2014-11-05 10:31:12,753] TRACE Processor id 1 selection time = 12017 ns (kafka.network.Processor)
[2014-11-05 10:31:12,753] TRACE 10 bytes written to /127.0.0.1:55693 using key sun.nio.ch.SelectionKeyImpl@3a6a2cf (kafka.network.Processor)
[2014-11-05 10:31:12,753] TRACE 10 bytes written to /127.0.0.1:55693 using key sun.nio.ch.SelectionKeyImpl@3a6a2cf (kafka.network.Processor)
[2014-11-05 10:31:12,753] TRACE 6 bytes read. (kafka.network.BoundedByteBufferReceive)
[2014-11-05 10:31:12,753] TRACE 6 bytes read. (kafka.network.BoundedByteBufferReceive)
[2014-11-05 10:31:12,753] TRACE Finished writing, registering for read on connection /127.0.0.1:55693 (kafka.network.Processor)
[2014-11-05 10:31:12,753] TRACE Finished writing, registering for read on connection /127.0.0.1:55693 (kafka.network.Processor)
[2014-11-05 10:31:12,851] TRACE Processor id 7 selection time = 301124890 ns (kafka.network.Processor)
[2014-11-05 10:31:12,851] TRACE Processor id 7 selection time = 301124890 ns (kafka.network.Processor)






If we look at the timestamp, when the error is thrown in the controller.log its at 10:31:12,445. But the timestamp in the server.log where the data is written to the Socket is after the exception is thrown.

Is there some kind of race condition with the acceptor and send threads within the Kafka processor?;;;","06/Nov/14 02:02;schandr;And I was able to telnet to the host:port.;;;","06/Nov/14 03:16;schandr;Please see the attached serverlog excerpts for a failed and successful topic creation. Please use the second  ServerLogForFailedTopicCreation.txt file
For a failed Topic creation the log files are not getting created under the kafka.log.dirs folder.
Looking at the successful topic creation server log, I can see the trace logs for the partition log creation, which is missing from the failed server log.
One main difference is, in the failed log, I see the Kafka handler request as UpdateMetaData request, where as in the successful log, I see both LeaderAndIsrRequest and UpdateMetaData kafka handler requests.;;;","06/Nov/14 05:30;schandr;Ok....Here is my understanding. This might probably be a bug.

1. For any requests that the controller sends to the Broker, it uses the BlockingChannel - that's initialized with the controller.socket.timeout.ms value specified in the server.properties.
2. Once the channel is established the RequestSendThread uses this channel to send any requests such as LeaderAndIsr, UpdateMetaData without checking if the channel is still open
3. Based on the value, the socket might have timed out. The following Code in the RequestSendThread calls the connectToBroker again on catching the exception, but does not send the failed request. If the request happens to be LeaderAndIsr for the new partition it results in missing log directory creation or other errors which results in producer or consumer throwing exceptions when they try to produce or consume data from the failed topic.




 var isSendSuccessful = false
        while(isRunning.get() && !isSendSuccessful) {
          // if a broker goes down for a long time, then at some point the controller's zookeeper listener will trigger a
          // removeBroker which will invoke shutdown() on this thread. At that point, we will stop retrying.
          try {
            channel.send(request)
            isSendSuccessful = true
          } catch {
            case e: Throwable => // if the send was not successful, reconnect to broker and resend the message
              error((""Controller %d epoch %d failed to send request %s to broker %s. "" +
                ""Reconnecting to broker."").format(controllerId, controllerContext.epoch,
                request.toString, toBroker.toString()), e)

              channel.disconnect()
              connectToBroker(toBroker, channel)

              isSendSuccessful = false
              // backoff before retrying the connection and send
              Utils.swallow(Thread.sleep(300))
          }
        }


In the code above, after reconnecting to the broker, it should also resend the failed request. Atleast the inline comment says so. -- // if the send was not successful, reconnect to broker and resend the message. So the code in the catch block should be

 catch {
            case e: Throwable => // if the send was not successful, reconnect to broker and resend the message
              error((""Controller %d epoch %d failed to send request %s to broker %s. "" +
                ""Reconnecting to broker."").format(controllerId, controllerContext.epoch,
                request.toString, toBroker.toString()), e)

              channel.disconnect()
              connectToBroker(toBroker, channel)

              channel.send(request)

              isSendSuccessful = false
              // backoff before retrying the connection and send
              Utils.swallow(Thread.sleep(300))
          }
;;;","06/Nov/14 10:07;junrao;Hmm, that try/catch block is in a while loop. So, the resend should happen when the logic loops back again. Also, normally when a broker goes down, the controller typically notices it immediately and will remove the corresponding BlockingChannel. When a broker comes back, a new BlockingChannel will be created.

It sounds like that you see this issue in some broker failure scenarios. Could you describe that a bit more?;;;","06/Nov/14 10:19;schandr;Thank you very much for your response.

First I think the broker is not down. Because I am able to telnet to the VM where kafka is running using the host:9092. We have tried several scenarios
1. Creating a topic through Java code using TopicCommand
2. Creating a topic in a bash script.

In either of the cases above, the topic creation fails randomly. When the bash script is modified to create the topic every 10 minutes, it fails consistently. But if the same bash script is modified to create topic every 5 minutes, then the alternate topic creation goes through. Somehow the 10 minute interval is failing consistently.
In the server log, I see the request to LeaderAndISR fails, that results in partition log file not getting created. Only zookeeper and Kafka is running in the VM where the script was ran. Let me know if you need more information like server.properties file. Also I am able to see the zk nodes for the controller and broker through an eclipse zookeeper plugin

;;;","06/Nov/14 10:33;junrao;What's your value for controller.socket.timeout.ms?;;;","06/Nov/14 10:44;schandr;controller.socket.timeout.ms=90000
controller.message.queue.size=20
auto.leader.rebalance.enable=true
queued.max.requests=20;;;","06/Nov/14 11:17;schandr;One more observance in the server log

Here is the Trace statement for the send request. This gets logged when channel.send(request) is invoked in the RequestSendThread.
The send method invokes writeCompletely method in the Send class.
0:31:12,440] TRACE 131 bytes written. (kafka.network.BoundedByteBufferSend)
[2014-11-05 10:31:12,440] TRACE 131 bytes written. (kafka.network.BoundedByteBufferSend)

If the request gets resend the same statement should be relogged in the server log based on
channel.send(request) code in the RequestSendThread which did not get logged.

And it could be a race condition between the LeaderAndIsr request resend and the UpdateMetaData request, which could lead to the channel.receive throwing a EOFException.

Once the topic creation fails, no exceptions are thrown back for us to catch and retry. Is there any workaround for this issue?;;;","07/Nov/14 01:31;junrao;You actually found a real bug, thanks! We exposed an existing problem after adding the ability to kill idle connections in KAFKA-1282. The default max idle time happens to be 10 minutes. That's why you only see the issue if the topics are created more than 10 mins apart. I will attach a patch soon.;;;","07/Nov/14 01:34;junrao;Created reviewboard https://reviews.apache.org/r/27690/diff/
 against branch origin/trunk;;;","07/Nov/14 01:37;junrao;Sri, Pradeep,

Do you think you can try the patch and see if this fixes your issue?

Also marking this as an 0.8.2 blocker.;;;","07/Nov/14 02:29;schandr;Great....And thank you for the Patch. How should we apply this patch? Are there any instructions on how to apply the patch.;;;","07/Nov/14 02:55;junrao;You can follow the instruction at https://cwiki.apache.org/confluence/display/KAFKA/Patch+submission+and+review#Patchsubmissionandreview-Reviewerworkflow: to apply the patch.;;;","07/Nov/14 03:21;nehanarkhede;Good catch. Thanks for following up on this, Jun. Reviewed the patch, looks good.;;;","07/Nov/14 03:36;schandr;Will apply the patch against the 0.8.2-beta and post the update.;;;","07/Nov/14 23:47;schandr;The patch works and thanks for the help!!!. Will this be patch be included in 0.8.2 release? If yes, do you have a date in mind?;;;","08/Nov/14 02:47;junrao;Thanks for the review. Double committed to 0.8.2 and trunk.

We expect 0.8.2 final will be released in ~3 weeks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Creating topic of empty string puts broker in a bad state,KAFKA-371,12595368,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,martinkl,martinkl,21/Jun/12 09:09,15/Aug/12 01:23,22/Mar/23 15:10,15/Aug/12 01:23,0.6,0.7,,,,,0.8.0,,,,,,,,,,,0,,,,,,"Using the Java client library, I accidentally published a message where the topic name was the empty string. This put the broker in a bad state where publishing became impossible, and the following exception was logged 10-20 times per second:

2012-06-21 00:41:30,324 [kafka-processor-3] ERROR kafka.network.Processor  - Closing socket for /127.0.0.1 because of er
ror
kafka.common.InvalidTopicException: topic name can't be empty
        at kafka.log.LogManager.getOrCreateLog(LogManager.scala:165)
        at kafka.server.KafkaRequestHandlers.kafka$server$KafkaRequestHandlers$$handleProducerRequest(KafkaRequestHandle
rs.scala:75)
        at kafka.server.KafkaRequestHandlers.handleProducerRequest(KafkaRequestHandlers.scala:58)
        at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$1.apply(KafkaRequestHandlers.scala:43)
        at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$1.apply(KafkaRequestHandlers.scala:43)
        at kafka.network.Processor.handle(SocketServer.scala:289)
        at kafka.network.Processor.read(SocketServer.scala:312)
        at kafka.network.Processor.run(SocketServer.scala:207)
        at java.lang.Thread.run(Thread.java:679)

Restarting Kafka did not help. I had to manually clear out the bad state in Zookeeper to resolve the problem.

The broker should not accept a message that would put it in such a bad state.",,jcreasy,jkreps,martinkl,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jul/12 09:27;jcreasy;KAFKA-371-0.7.1.patch;https://issues.apache.org/jira/secure/attachment/12536938/KAFKA-371-0.7.1.patch","19/Jul/12 05:30;jkreps;KAFKA-371-0.8-v2.patch;https://issues.apache.org/jira/secure/attachment/12537072/KAFKA-371-0.8-v2.patch","18/Jul/12 09:20;jcreasy;KAFKA-371-0.8.patch;https://issues.apache.org/jira/secure/attachment/12536937/KAFKA-371-0.8.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,248166,,,Thu Jul 19 22:44:41 UTC 2012,,,,,,,,,,"0|i09lxz:",53988,,,,,,,,,,,,,,,,,,,,"18/Jul/12 09:25;jcreasy;Modifed createLog() to fail if it has been asked to create a log that would fail on the getLogPool() function.

I am not sure if the partition check is correct here, it appears that the partition could be any >0 partition and be OK since the file would get created. If there is no where else that partition would need to exist that would be OK, I think that this may not be the case though as it would need to be in Zk if my current understanding is correct. 
;;;","18/Jul/12 09:27;jcreasy;Probably should set fix version to 0.7.1;;;","19/Jul/12 01:17;jkreps;Committed the 0.8 patch. Thanks.

At the moment I don't know if we are doing a 0.7.2 so I am going to hold off on the 0.7.1 patch.;;;","19/Jul/12 01:34;nehanarkhede;I think in the 0.8 patch, the changes to createLog are unnecessary. This is because the same check happens inside getLogPool, which is always called before createLog in getOrCreateLog, no ?;;;","19/Jul/12 03:10;jcreasy;Well, I didn't see any way for the bug to have occurred unless createLog was being called outside of where getLogPool gets called. So, it does appear to be unnecessary, perhaps these checks were added and the ticket was never updated? 

;;;","19/Jul/12 04:26;jkreps;Hmm, good point. This is a little odd, though, no? Why would getting a log pool check the validity of a partition? Not sure how that came about. I recommend we delete that and keep the check in create--if you can't create a bad log you don't need to check on every access. Objections?

Actually I have a bunch of clean-ups I would like to do in LogManager. Let me post a patch with all these while I am in there.;;;","19/Jul/12 04:32;nehanarkhede;Yes, that will work too. I guess the API was added so that every access to the log was guarded with the check. But if we ensure that you can't create one in the first place, we can get rid of the check in getLogPool and keep the one in createLog. ;;;","19/Jul/12 04:40;jkreps;Reopening for cleanups of LogManager;;;","19/Jul/12 05:30;jkreps;Neha can you sanity check this? Here are the changes:

- Remove some unneeded getter getServerConfig
- Rename getTopicIterator to topics()
- Simplify getLogIterator() and rename to allLogs()
- Remove awaitStartup latch and awaitStartup latch acquisition. The comment on startup() says it registers in zookeeper, but this doesn't seem to be true
- Remove getLogPool. createLog checks correctness of creation, and fails if it fails. getLog returns null if the log doesn't exist, as per the contract. getOrCreateLog will fail when createLog fails. I think this is more sensible, and elimantes the getter
- Remove the word ""Map"" from things of type Map
- MS should be Ms by our usual conventions
- Remove helper getLogRetentionMSMap

I think the latch was there because log manager was somehow doing zk registration (according to comments). But I don't see that code there at all now, and logManager shouldn't be talking to zk, so i think it got cleaned up. So now theoretically we shouldn't need that and the weird ordering where we take requests before log manager is initiatialized but then block should not be needed. 

Also, I removed the EasyMock verification on logmanager (I think all it does is check that the config was fetched), which I don't think is useful? But EasyMock is kind of a blackbox to me.;;;","20/Jul/12 03:11;nehanarkhede;+1. 

Minor comment -

Change logCleanupThresholdMS to logCleanupThresholdMs while you're in there;;;","20/Jul/12 04:15;jcreasy;Does it make sense to have a function to ""validate a log"" and call that any time you want to validate that the log you are reading/writing is valid? Potentially some of the validation would be redundant and called at times it didn't need to be, reducing capacity. 

So the balance is between consistent checking and efficient execution.;;;","20/Jul/12 06:34;jkreps;Got it, committed.;;;","20/Jul/12 06:44;jkreps;Hey Jonathan, I don't think so, but I may have misunderstood. Basically a log has two states
 OPEN
 CLOSED

Every time we create a log object we run recovery on it which validates any messages since the last know flush point and truncates any partial writes to put the log in a known state. This is done as part of log construction so there is no way to have a reference to a log until it is known to be valid and ready for writes.

Our policy is that we actually kill the instance of the broker if we see an IOException while writing to disk (STONITH, if you will), so there is effectively no invalid state. The reason for this is that an IO error is effectively the same as a broker failure in that it indicates a potentially partial or corrupt write. You cannot append to the log in this state, so continuing to accept traffic only makes thing worse, the best policy is to die and let the other brokers cover things.

Attempt to read or write to a closed log would be a programming error in the broker, and should just give an exception about the file being closed, so I don't know if we need additional checks there.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka consumer can hang when position() is called on a non-existing partition.,KAFKA-3177,12935404,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,hachikuji,becket_qin,becket_qin,31/Jan/16 09:20,01/Jun/18 22:36,22/Mar/23 15:10,01/Jun/18 22:32,0.9.0.0,,,,,,2.0.0,,,,,,,clients,,,,4,,,,,,"This can be easily reproduced as following:

{code}
{
    ...
    consumer.assign(SomeNonExsitingTopicParition);
    consumer.position();
    ...
}
{code}

It seems when position is called we will try to do the following:
1. Fetch committed offsets.
2. If there is no committed offsets, try to reset offset using reset strategy. in sendListOffsetRequest(), if the consumer does not know the TopicPartition, it will refresh its metadata and retry. In this case, because the partition does not exist, we fall in to the infinite loop of refreshing topic metadata.

Another orthogonal issue is that if the topic in the above code piece does not exist, position() call will actually create the topic due to the fact that currently topic metadata request could automatically create the topic. This is a known separate issue.",,ArnaudL,becket_qin,bryan.deng,cpennello_opentable,dana.powers,dehora,ecomar,ehelleren,githubbot,guozhang,hachikuji,hongyu.bi,jeffwidman,kdkavanagh,koeninger,omkreddy,TheMonolith,wangbo23,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3503,,,,,,KAFKA-2391,KAFKA-3727,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jun 01 14:32:09 UTC 2018,,,,,,,,,,"0|i2s73z:",9223372036854775807,,hachikuji,,,,,,,,,,,,,,,,,,"31/Jan/16 09:29;becket_qin;[~hachikuji] [~guozhang] Not sure what is the correct solution here. Should we leave the retry option to user if the topic partition they are trying to query does not exist? i.e. if the currently cached metadata does not include the topic partition we refresh only once. If the refreshed metadata does not have that topic partition, we simply throw UnknownTopicOrPartitionException to user. So it becomes user's call to retry or not.;;;","02/Feb/16 01:31;hachikuji;[~becket_qin] Nice find. Your suggestion seems reasonable to me. As a user, I would probably expect to see an exception if a partition doesn't exist.;;;","02/Feb/16 01:43;becket_qin;Thanks [~hachikuji], I'll submit patch for the ticket then.;;;","02/Feb/16 06:55;guozhang;[~hachikuji] Just checking, this infinite loop's pattern is not the same as the scenario when there is no broker up and running, which will fall in the loop of finding the coordinator and disconnected from the given socket, right?

It seems today we have a couple of patterns that could result it ""not respecting timeout in poll"" and ""unexpected blocking for unblocking functions"", it would be better to fix these two in a more generic way rather tackling them one-by-one?;;;","02/Feb/16 07:36;becket_qin;[~guozhang]  In this particular case, the issue is different from the actual no broker available scenario. Good point about verify the expected behavior of methods calls.

Also, should we make some improvements on the Exception definition, too? Currently some exception definition is a little confusing. e.g. NetworkException is a subclass of InvalidMatadataException; There is a StaleMetadataException while we already have more specific exception such as UnknownTopicOrPartitionException, NotLeaderForPartitionException, etc.;;;","02/Feb/16 13:43;dana.powers;A similar infinite loop happens when the partition exists but has no leader b/c it is under-replicated. In that case, Fetcher.listOffset infinitely retries on the leaderNotAvailableError returned by sendListOffsetRequest.;;;","03/Feb/16 07:37;hachikuji;[~guozhang] I think it's useful to separate failures into two categories: 1) ephemeral failures which should eventually resolve themselves, and 2) permanent failures. Blocking seems justifiable (even if undesirable) for ephemeral failures, but we ought to raise an exception if we don't expect the error to resolve ""soon."" I'd classify this type of failure as permanent since we can't really depend on the number of partitions being increased. And it almost certainly indicates a bug in the user's code if they're trying to assign partitions which don't exist. I think we'll have to handle cases like this individually as they come up.;;;","04/Feb/16 09:46;becket_qin;[~hachikuji] The two categories makes sense. As you said it is possible that the same exception can sometimes be ephemeral and sometimes be permanent depending on how ""ephemeral"" they are. It seems related to KAFKA-2391. Do you think it would be useful to add some timeout to the blocking calls?

BTW, in this ticket I am currently planning to only fix the position() call issue. Please let me know if you prefer a bigger operation on the exceptions.;;;","23/Mar/16 04:28;hachikuji;[~becket_qin] Were you planning to submit a patch for this? I can pick it up if you don't have time.;;;","23/Mar/16 06:29;becket_qin;[~hachikuji] It would be great if you can help. I probably won't be able to work on this in a couple of days. Thanks a lot for help.;;;","28/Mar/16 23:26;ehelleren;Is there a ticket for that ""no broker up and running"" scenario so I can upvote it?  We are running into an application hang when calling position() against a non-live kafka cluster.  I would also expect an exception in such cases after a reasonable timeout.  ;;;","29/Mar/16 01:08;hachikuji;[~becket_qin] Got sidetracked, but working on this now. I talked with [~guozhang] offline and we were thinking it may be sufficient to log a warning in this case for now. Longer term, we could add a ""max.block.ms"" like the producer to handle this problem more generally for all of the consumer's blocking APIs. I think that's what you're suggesting above. Does that sound reasonable?;;;","29/Mar/16 01:15;becket_qin;[~hachikuji] Yes, I agree that we need a general solution to solve this. Logging a warning for now sounds good to me.;;;","29/Mar/16 01:20;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/1157

    KAFKA-3177: log warning when topic/partition doesn't exist

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-3177

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1157.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1157
    
----
commit 48b1f1fef29c5150c6deeffb3cf5fde3491fe888
Author: Jason Gustafson <jason@confluent.io>
Date:   2016-03-23T03:16:32Z

    KAFKA-3177: log warning when topic/partition doesn't exist

----
;;;","26/May/16 18:55;ecomar;see also Consumer.poll() stuck in loop on non-existent topic manually assigned : https://issues.apache.org/jira/browse/KAFKA-3727;;;","24/Sep/16 06:16;hachikuji;Kicking this to 0.10.2. Improving the logging alone doesn't bring much value. We need a better long term solution for addressing unknown topics/blocking in the consumer.;;;","18/Jan/17 03:38;githubbot;Github user hachikuji closed the pull request at:

    https://github.com/apache/kafka/pull/1157
;;;","23/Sep/17 12:48;guozhang;*Reminder to the contributor / reviewer of the PR*: please note that the code deadline for 1.0.0 is less than 2 weeks away (Oct. 4th). Please re-evaluate your JIRA and see if it still makes sense to be merged into 1.0.0 or it could be pushed out to 1.1.0, or be closed directly if the JIRA itself is not valid any more, or re-assign yourself as contributor / committer if you are no longer working on the JIRA.;;;","01/Jun/18 22:32;omkreddy;This is addressed by KIP-266.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Requesting committed offsets results in inconsistent results,KAFKA-3251,12940455,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,hachikuji,dimitrij.denissenko@blacksquaremedia.com,dimitrij.denissenko@blacksquaremedia.com,19/Feb/16 18:10,27/Feb/16 19:05,22/Mar/23 15:10,27/Feb/16 19:05,0.9.0.0,,,,,,,,,,,,,offset manager,,,,0,,,,,,"Hi,

I am using github.com/Shopify/sarama to retrieve the committed offsets for a high-volume topic, but the bug seems to be actually originating in Kafka itself.

I have written a little test to query the offsets of all partitions of one topic, every second. The request looks like this:

{code}
OffsetFetchRequest{
  ConsumerGroup: ""my-group-name"", 
  Version: 1,
  TopicPartitions: []TopicPartition{
     {TopicName: ""logs"", Partitions: []int32{0,1,2,3,4,5,6,7}
  }
}
{code}

For most of the time, the responses are correct, but every 10 minutes or so, there is a little glitch. I am not familiar with the Kafka internals, but it looks like a little race. Here's my log output:

{code}
...

2016/02/19 09:48:10 topic=logs partition=00 error=0 offset=206567925
2016/02/19 09:48:10 topic=logs partition=01 error=0 offset=206671019
2016/02/19 09:48:10 topic=logs partition=02 error=0 offset=206567995
2016/02/19 09:48:10 topic=logs partition=03 error=0 offset=205785315
2016/02/19 09:48:10 topic=logs partition=04 error=0 offset=206526677
2016/02/19 09:48:10 topic=logs partition=05 error=0 offset=206713764
2016/02/19 09:48:10 topic=logs partition=06 error=0 offset=206524006
2016/02/19 09:48:10 topic=logs partition=07 error=0 offset=206629121

2016/02/19 09:48:11 topic=logs partition=00 error=0 offset=206572870
2016/02/19 09:48:11 topic=logs partition=01 error=0 offset=206675966
2016/02/19 09:48:11 topic=logs partition=02 error=0 offset=206573267
2016/02/19 09:48:11 topic=logs partition=03 error=0 offset=205790613
2016/02/19 09:48:11 topic=logs partition=04 error=0 offset=206531841
2016/02/19 09:48:11 topic=logs partition=05 error=0 offset=206718513
2016/02/19 09:48:11 topic=logs partition=06 error=0 offset=206529762
2016/02/19 09:48:11 topic=logs partition=07 error=0 offset=206634037

2016/02/19 09:48:12 topic=logs partition=00 error=0 offset=-1
2016/02/19 09:48:12 topic=logs partition=01 error=0 offset=-1
2016/02/19 09:48:12 topic=logs partition=02 error=0 offset=-1
2016/02/19 09:48:12 topic=logs partition=03 error=0 offset=-1
2016/02/19 09:48:12 topic=logs partition=04 error=0 offset=-1
2016/02/19 09:48:12 topic=logs partition=05 error=0 offset=-1
2016/02/19 09:48:12 topic=logs partition=06 error=0 offset=-1
2016/02/19 09:48:12 topic=logs partition=07 error=0 offset=-1

2016/02/19 09:48:13 topic=logs partition=00 error=0 offset=-1
2016/02/19 09:48:13 topic=logs partition=01 error=0 offset=206686020
2016/02/19 09:48:13 topic=logs partition=02 error=0 offset=206583861
2016/02/19 09:48:13 topic=logs partition=03 error=0 offset=205800480
2016/02/19 09:48:13 topic=logs partition=04 error=0 offset=206542733
2016/02/19 09:48:13 topic=logs partition=05 error=0 offset=206728251
2016/02/19 09:48:13 topic=logs partition=06 error=0 offset=206534794
2016/02/19 09:48:13 topic=logs partition=07 error=0 offset=206643853

2016/02/19 09:48:14 topic=logs partition=00 error=0 offset=206584533
2016/02/19 09:48:14 topic=logs partition=01 error=0 offset=206690275
2016/02/19 09:48:14 topic=logs partition=02 error=0 offset=206588902
2016/02/19 09:48:14 topic=logs partition=03 error=0 offset=205805413
2016/02/19 09:48:14 topic=logs partition=04 error=0 offset=206542733
2016/02/19 09:48:14 topic=logs partition=05 error=0 offset=206733144
2016/02/19 09:48:14 topic=logs partition=06 error=0 offset=206540275
2016/02/19 09:48:14 topic=logs partition=07 error=0 offset=206649392
...
{code}

As you can see, the returned error code is 0 and there is no obvious reason why the returned offsets are suddenly wrong/blank. 

I have also added some debugging to our offset committer to make absolutely sure the numbers we are sending are absolutely correct and they are. 

Any help is greatly appreciated!",,daichi.hirata,dimitrij.denissenko@blacksquaremedia.com,hachikuji,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Feb 27 11:05:54 UTC 2016,,,,,,,,,,"0|i2t1z3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Feb/16 19:19;ijuma;Thanks for the report. Does this happen with trunk or 0.9.0.1 RC1 as well?;;;","19/Feb/16 20:10;dimitrij.denissenko@blacksquaremedia.com;It's unfortunately not something I can test easily, as it only happens under production load, but will investigate.;;;","20/Feb/16 03:33;hachikuji;[~dimitrij.denissenko@blacksquaremedia.com] Thanks for the report. This sounds like it could be caused by KAFKA-2913, which we found after the 0.9.0.0 release. Is there any chance you will be able to upgrade to 0.9.0.1 and check whether the bug is still present?;;;","22/Feb/16 11:12;daichi.hirata;Hi. I was also investigating a similar problem. sarama sets 0 not -1 in RetentionTime of OffsetCommitRequest. So, I think that delete-expired-consumer-offsets always remove expired offset.;;;","22/Feb/16 20:05;dimitrij.denissenko@blacksquaremedia.com;Looks like it's fixed 0.9.0.1. Thanks;;;","27/Feb/16 19:05;ijuma;Thanks for letting us know.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Force offset commits when migrating consumer offsets from zookeeper to kafka,KAFKA-1510,12724186,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jjkoshy,jjkoshy,jjkoshy,28/Jun/14 02:27,06/Sep/14 03:21,22/Mar/23 15:10,06/Sep/14 03:21,0.8.2.0,,,,,,0.8.2.0,,,,,,,,,,,0,newbie,,,,,"When migrating consumer offsets from ZooKeeper to kafka, we have to turn on dual-commit (i.e., the consumers will commit offsets to both zookeeper and kafka) in addition to setting offsets.storage to kafka. However, when we commit offsets we only commit offsets if they have changed (since the last commit). For low-volume topics or for topics that receive data in bursts offsets may not move for a long period of time. Therefore we may want to force the commit (even if offsets have not changed) when migrating (i.e., when dual-commit is enabled) - we can add a minimum interval threshold (say force commit after every 10 auto-commits) as well as on rebalance and shutdown.

Also, I think it is safe to switch the default for offsets.storage from zookeeper to kafka and set the default to dual-commit (for people who have not migrated yet). We have deployed this to the largest consumers at linkedin and have not seen any issues so far (except for the migration caveat that this jira will resolve).
",,guozhang,jjkoshy,junrao,nmarasoi,nmarasoiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Aug/14 22:57;nmarasoiu;Patch_to_push_unfiltered_offsets_to_both_Kafka_and_potentially_Zookeeper_when_Kafka_is_con.patch;https://issues.apache.org/jira/secure/attachment/12665351/Patch_to_push_unfiltered_offsets_to_both_Kafka_and_potentially_Zookeeper_when_Kafka_is_con.patch","05/Sep/14 13:07;nmarasoi;Unfiltered_offsets_commit_to_kafka_rebased.patch;https://issues.apache.org/jira/secure/attachment/12666669/Unfiltered_offsets_commit_to_kafka_rebased.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,402371,,,Fri Sep 05 19:21:15 UTC 2014,,,,,,,,,,"0|i1x987:",402433,,jjkoshy,,,,,,,,,,,,,,,,,,"18/Jul/14 20:02;nmarasoiu;Hi, it sounds clear and simple enough, I am going to try this.
I will probably come back with some questions for the low level detail.

Why is the offset management moving from zookeeper to kafka? To ease the consumer and favor language proliferation of consumers ? Is kafka managing them through zookeeper as well, behind the scenes, or is it using its own / other cluster / consensus mechanism to store the offsets in a HA manner?;;;","19/Jul/14 01:06;guozhang;Hi Nicolae,

Thanks for taking this ticket. You can take a look at the offset management design proposal for the motivations of moving it away from ZK.

https://cwiki.apache.org/confluence/display/KAFKA/Inbuilt+Consumer+Offset+Management
;;;","19/Jul/14 03:50;jjkoshy;I think it should be sufficient to force commit only on shutdown while dual-commit is enabled. i.e., no need to force commit at intervals.;;;","24/Jul/14 05:58;jjkoshy;[~nmarasoiu] do you think you will be able to take this on in the next couple days?;;;","24/Jul/14 15:03;nmarasoiu;[~jjkoshy] Yes I am going to tackle this these days, have a first patch proposal in the weekend or sooner.;;;","27/Jul/14 02:03;nmarasoi;Hi,
isAutoCommit argument works exactly the other way around, apparently it is ""false"" from the scheduled auto commit and to ""true"" from zkConsConn.commitOffsets()?

So the migration of offsets from zk to kafka is to : set dual commit and kafka storage, restart consumers, wait for kafka to be copied on the offset commits, and take out dual commit.

So currently kafka is copied with the offsets only when data flows, and for the purpose of this task, we need to add one or 2 more cases when it is getting the offset: when shutting down, or perhaps periodically.

So this task applies only when storage==kafka and dualCommit ==true, right?

I would first ask why the write to zookeeper the new offsets, only if the write to kafka was ok? My assumption is To make sure only one write to zookeeper, even though the process of writing to kafka may involve retries. 

I would write both directions at all time, and perhaps keep 2 checkpoint structures, one kafka one zookeeper.


I create a patch now with: a forceCommit that will make that all offsets are commited to both kafka and zookeeper when shutting down in dual commit mode.

The usefulness of committing all offsets not only to kafka but to zookeeper as well comes at least from one reason: the one I mentioned above, that if kafka offset write fails completely, zookeeper is never copied on that.

Forcing all offsets to zk on shutdown too does indeed have the drawback that it will typically copy the same offsets again, and not only once but potentially several times (if kafka is retried).
However the alternative is to commit to both kafka and zookeeper unconditionally in the normal flow (right now, the commit to zk happens only after a successful commit to kafka if any). That too poses the same risk of committing multiple times to a system (zk) if the other (kafka) needs retries. So a clean way here would be a completely different OffsetDAO implementation, one on kafka , one on zookeeper, and one on dual mode, and read, as now max(both), while write goes to the 2 implementations, each of them doing retries without affecting the other!;;;","27/Jul/14 14:40;nmarasoi;attached patch as per my interpretation and tradeoffs detailed in my comments;;;","30/Jul/14 13:12;nmarasoi;[~jjkoshy] Can you please take a look at my comments+code, it will probably take one more iteration at least to make it.;;;","30/Jul/14 19:58;nmarasoi;[~jkreps] Hi, can you please help me with feedback on my comment + code, or who can I ask, so that I can go in the right direction?;;;","31/Jul/14 07:17;jjkoshy;[~nmarasoi] - sure thing. Will get back to you on this.;;;","01/Aug/14 09:12;jjkoshy;Re: isAutoCommit:
Yes you are right. Can you fix that?

Re: migration steps:
Yes that is correct. ""Wait for kafka to be copied on commits"" would essentially mean do one rolling bounce after your patch (since the shutdown guarantees that the offsets would have moved over).

Re: applies only when storage==kafka and dual-commit==true.
Yes that is correct.

Re:  why the write to zookeeper the new offsets, only if the write to kafka was ok?
As you observed, avoid redundant writes to ZooKeeper, but also for consistency between ZK and Kafka (although this does not matter too much since while transitioning they are inconsistent to start with).

Re: separate DAOs
We probably don't need that since we plan to eventually remove support for ZooKeeper-based offsets from the server-side - i.e., a consumer can choose to store offsets elsewhere (including ZooKeeper) but support for doing that via the OffsetCommitRequest channel will be removed.

Your patch looks good, but I'm unclear on why you need the ""|| forceCommit"" on line 318;;;","01/Aug/14 19:52;nmarasoi;Hi, the ""|| forceCommit"" on line 318 is meant to ensure write to zookeeper on shutdown even in the situation when kafka commits do not work.;;;","02/Aug/14 08:21;jjkoshy;I see - my thinking was since we retry indefinitely until a successful commit it only needs to be done at the end (once) after a successful commit to Kafka.

So to summarize - let me know if you have any comments/questions:

* Can you fix the issue you caught with the isAutoCommit flag?
* Probably unnecessary to have the ""|| forceCommit""
* Also, as mentioned in the summary I think it is reasonable to switch the default offsets.storage to Kafka and set dual.commit to true.
* Can you also run the unit tests and verify? It will be useful to also run the system tests (at least the mirror maker test suite). See https://cwiki.apache.org/confluence/display/KAFKA/Kafka+System+Tests#KafkaSystemTests-RunningSystemTest for more information on this - it should be sufficient to just run the mirror maker tests.
;;;","02/Aug/14 20:30;nmarasoiu;Where is the indefinite retry you mention? I don't think it is indefinite..



;;;","02/Aug/14 20:34;nmarasoiu;It is a limited retry , and I found no easy way to determine if this is the
last attempt, so that I write to zookeeper as well. This can be taken out
to a different jira task too, but I would let the zookeeper ensure-commit
here too, and regard this task as a ""make all efforts to commit all offsets
to both storages at shutdown"" and rename as such.


On Sat, Aug 2, 2014 at 3:28 PM, Nicolae Marasoiu <nicolae.marasoiu@gmail.com

;;;","02/Aug/14 20:57;nmarasoi;Hi,

I have given it more consideration, and indeed to ""||force"" on 318 it is a different concern, which can be taken to another task.
The risk which it would solve, is that when kafka is out for the limited retry count during shutdown, at least zookeeper would get the offsets, and the consumer will not rewind. However it is low probability that both systems are down, so zookeeper would likely be up to date when kafka is down, for instance. The probability that zookeeper will get flooded with all offsets multiple times kafka is retried is comparable to that low probability.

So, for this task, I take out that line 318 part of the patch, test went fine.

I will create another task for isAutoCommit issue and analyze if the meaning is truly reversed, cause I feel it is only partially and perhaps used correctly with the reversed name, and it is mostly diffent thing.

I will do the config changes, no prob - switch the default offsets.storage to Kafka and set dual.commit to true.;;;","03/Aug/14 13:54;nmarasoi;re-uploaded the patch ;;;","09/Aug/14 02:26;jjkoshy;[~nmarasoi] I realized later there is actually a flaw in how we get rid of offset commits from old (non-existent) consumers.

As of now, the offset manager does the following: it periodically goes through its entire cache (i.e., hashtable of offsets) and extracts those entries that have a timestamp earlier than some staleness threshold. It then proceeds to add tombstones for those entries in the offsets commit log.

The problem with this approach as it stands is similar to the original issue that this jira intended to address. A live consumer may be consuming a low volume topic and its offset may change infrequently. i.e., its offset may not move within the staleness threshold. If we delete the offset and a consumer rebalance occurs and fetches that offset, then depending on the auto.offset.reset configuration, it will pick up the new latest offset of the topic (in which case the consumer could lose some messages) or the earliest offset (in which case the consumer will see duplicates).

I think the fix for this is the following and I'm backtracking to what I earlier wrote and later (incorrectly) thought was unnecessary:

A consumer implementation can optionally choose to selectively commit only offsets that have changed since the last commit. HOWEVER, there should be a configurable interval at which the consumer should always commit ALL its offsets regardless of whether it has changed or not.
;;;","09/Aug/14 02:28;jjkoshy;Would you be able to update your patch to take into account the above?;;;","11/Aug/14 05:15;junrao;Thinking about this a bit more, would it be more reliable to do the expiration of an offset based on the last connect time from the client, instead of the last time the offset is modified? In the new consumer, we will be tracking the set of consumers per consumer group on the broker. We can expire an offset if the time since the last time the partition was actively owned by a consumer exceeds the threshold. Handling consumer coordinator failover can be a bit tricky. We can probably just start doing the expiration countdown from the beginning during the failover. This means that the removal of some of the offsets may be delayed. This maybe ok since the consumer coordinator failover should be rare.;;;","13/Aug/14 01:25;nmarasoi;ok, so I have not fully understood, but what I think I did, is that for the moment there is no clear decision on any modifications to the patch as it is now, the way that i understand it;;;","13/Aug/14 01:51;jjkoshy;[~junrao] yes that would make sense. However, we don't have this tracking implemented in the existing consumer and I would rather not add that feature now just to fix an existing bug. i.e., I think we should just fix the current issue by forcing commits (either periodically or always) when using Kafka-based offset storage.;;;","14/Aug/14 03:00;jjkoshy;After some discussion with [~guozhang] and [~junrao] here are some additional comments to help clarify my earlier reasoning:

In order to migrate offsets from ZooKeeper to Kafka, at minimum we need to force an unfiltered commit (regardless of whether offsets have changed or not) at some point - e.g., shut down of the consumer.

An orthogonal issue is that of a consumer that consumes a low-volume topic. i.e., if the offsets don't change within the offset retention threshold on the offset manager (defaults to one day) then those offsets will be deleted. If the consumer fails for any reason and does an offset fetch, it will reset to earliest or latest. We have a couple of options:
* One possible approach to address this is to configure the broker-side offset retention period to a large value - i.e., larger than the maximum retention period of any topic. This is not ideal because: (a) if there are short-lived (say, console-) consumers that come and go often then those offsets can sit around for a long time; (b) in general, you cannot really come up with a retention period for a compacted topics. So I would not want to do this, but I wrote this here for completeness.
* Another approach is to do UN-filtered commits if offsets.storage is set to Kafka. i.e., commit everything always.
* Yet another approach is to do unfiltered commits at a configurable interval.

Thoughts?

My preference after thinking about it is to go with the second approach.
;;;","16/Aug/14 09:11;junrao;Yes, I agree that always do unfiltered commits when offset.storage is used is the simplest and is good enough. ;;;","19/Aug/14 14:42;jjkoshy;[~nmarasoi] can you update your patch to do unfiltered commits if offsets.storage is kafka? Or if you have any other preference in approach, feel free to comment.;;;","25/Aug/14 15:39;jjkoshy;[~nmarasoi] do you think you will have time to wrap this up? If not, let me know or if you need any clarification.;;;","25/Aug/14 15:48;nmarasoiu;Hi, I will attach a patch with unfiltered commits today, or latest tomorrow;

So to clarify the requirement, my understanding is that, when storage =
kafka and dualcommit = enabled (or just one of those?), we are going to
make each and every offsets commit to kafka an unfiltered one i.e. commit
all offsets regardless of change or not; do we do this unfiltered commit
also on zookeeper?

Thanks
Nicu



;;;","26/Aug/14 02:10;jjkoshy;[~nmarasoi] that's right - whenever storage=kafka, we should to unfiltered commits to kafka. In other words, ALL offset commits sent to kafka should be unfiltered.

As for commits to zookeeper: if storage=zookeeper then we can do filtered commits. If storage=kafka and dual.commit=enabled then if the code doesn't get too complicated we should continue to do filtered commits to zookeeper (but unfiltered to kafka).;;;","29/Aug/14 03:55;nmarasoi;Hi, I will do this tomorrow, Friday, so I hope you will have a patch Friday morning your time.

So you say that the only condition to do unfiltered is kafka storage, regardless of dual commit mode or single commit mode, yes?

Thanks,
Nicu;;;","29/Aug/14 22:57;nmarasoiu;Patch to push unfiltered offsets to both Kafka and potentially Zookeeper when Kafka is configured to be the offset storage;;;","30/Aug/14 02:11;nmarasoi;Attached a patch - I am doing unfiltered commits to kafka and using offsets checkpoint Map for zookeeper incremental commits only (in both zk storage and dual commit modes) - its reads and mutations are now part of the commitToZk method exclusively in the suggested approach.

Right now, the rearrangement of topic topicRegistry into offsettsToCommit, a different reified structure with no more filtering in the process of its reification seems a bit futile, but because we got .size if, and we got usage of the structure below, and to minimize changes brought by this task (and leave them for an obvious future need of refactoring on the bigger scale this class), I let it like this.

The other optimization I could do, but not included in the patch, is to keep a state of the commit timestamp for each partition, and use that for filtering commits to kafka, based on a configurable maximum idleness of the partition offset commit for each partition.

A more primitive form of the same optimization, that would only protect from repeatedly committing to good brokers because of the broken ones, I could have such a state in a local structure for the duration of the method, just to make sure we keep retrying only the failed commits.;;;","03/Sep/14 00:06;nmarasoi;[~jjkoshy] Hi, can you check my patch + comments & provide feedback pls?;;;","05/Sep/14 09:12;jjkoshy;[~nmarasoi] Your patch looks good to me - however, it does not cleanly apply on the latest trunk. Would you mind rebasing? If you don't have time I can take care of it as well.;;;","05/Sep/14 13:07;nmarasoi;Attached rebased patch;;;","06/Sep/14 03:21;jjkoshy;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Java New Producer Kafka Trunk] CPU Usage Spike to 100% when network connection is lost,KAFKA-1642,12742642,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,ewencp,Bmis13,Bmis13,19/Sep/14 12:26,07/Jan/15 02:57,22/Mar/23 15:10,07/Jan/15 02:57,0.8.2.0,,,,,,0.8.2.0,,,,,,,producer ,,,,2,,,,,,"I see my CPU spike to 100% when network connection is lost for while.  It seems network  IO thread are very busy logging following error message.  Is this expected behavior ?
2014-09-17 14:06:16.830 [kafka-producer-network-thread] ERROR org.apache.kafka.clients.producer.internals.Sender - Uncaught error in kafka producer I/O thread: 

java.lang.IllegalStateException: No entry found for node -2

at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:110)

at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:99)

at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:394)

at org.apache.kafka.clients.NetworkClient.maybeUpdateMetadata(NetworkClient.java:380)

at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:174)

at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:175)

at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:115)

at java.lang.Thread.run(Thread.java:744)

Thanks,

Bhavesh",,becket_qin,Bmis13,donnchadh,ewencp,fdesjarl,jkreps,junrao,nehanarkhede,soumen.sarkar,stevenz3wu,vivek_arya1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Nov/14 09:52;Bmis13;0001-Initial-CPU-Hish-Usage-by-Kafka-FIX-and-Also-fix-CLO.patch;https://issues.apache.org/jira/secure/attachment/12683253/0001-Initial-CPU-Hish-Usage-by-Kafka-FIX-and-Also-fix-CLO.patch","02/Dec/14 07:49;ewencp;KAFKA-1642.patch;https://issues.apache.org/jira/secure/attachment/12684506/KAFKA-1642.patch","18/Oct/14 02:37;ewencp;KAFKA-1642.patch;https://issues.apache.org/jira/secure/attachment/12675537/KAFKA-1642.patch","21/Oct/14 08:34;ewencp;KAFKA-1642_2014-10-20_17:33:57.patch;https://issues.apache.org/jira/secure/attachment/12675989/KAFKA-1642_2014-10-20_17%3A33%3A57.patch","24/Oct/14 07:19;ewencp;KAFKA-1642_2014-10-23_16:19:41.patch;https://issues.apache.org/jira/secure/attachment/12676774/KAFKA-1642_2014-10-23_16%3A19%3A41.patch","06/Jan/15 10:56;ewencp;KAFKA-1642_2015-01-05_18:56:55.patch;https://issues.apache.org/jira/secure/attachment/12690231/KAFKA-1642_2015-01-05_18%3A56%3A55.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jan 06 18:57:19 UTC 2015,,,,,,,,,,"0|i208p3:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"20/Sep/14 00:55;jkreps;The intended behavior is that the client will periodically attempt to reconnect and update metadata until either it can reconnect or it discovers that a new node has taken over leadership for the given partition.

There are two things that could be going on here: (1) our default backoffs could be too low or (2) the network selector could be busy waiting. The backoffs are controlled by reconnect.backoff.ms and retry.backoff.ms. reconnect.backoff.ms controls the amount of time to wait after the last connection attempt (whether successful or unsuccessful) before trying to make another connection attempt--this avoids trying to connect over and over again. This seems to default to only 10ms. The retry.backoff.ms controls the amount of time we wait before attempting to update the metadata. This defaults to 100ms.

Alternatively, [~guozhang] found and fixed a bug in the network selector that lead to busy waiting previously. Maybe there is another bug like that.

Would you be willing to try setting the two backoffs to something high and see if you can reproduce the problem. The ideal would be a short piece of code that reproduces this that we could use for testing.;;;","26/Sep/14 02:42;Bmis13;HI [~jkreps],

I will work on the sample program. We are not setting reconnect.backoff.ms and retry.backoff.ms configuration so it would be default configuration.  Only thing I can tell you is that I have 4 Producer instances per JVM.  So this might amplify issue. 

Thanks,

Bhavesh ;;;","27/Sep/14 03:49;jkreps;Yeah a sample program that reproduces the issue would be excellent. That will help us take a look.;;;","13/Oct/14 23:44;Bmis13;{code}


import java.io.IOException;
import java.io.InputStream;
import java.util.Properties;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;

import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

public class TestNetworkDownProducer {
	
	static int numberTh = 200;
	static CountDownLatch latch = new CountDownLatch(200);
	public static void main(String[] args) throws IOException, InterruptedException {

		Properties prop = new Properties();
		InputStream propFile = Thread.currentThread().getContextClassLoader()
				.getResourceAsStream(""kafkaproducer.properties"");

		String topic = ""test"";
		prop.load(propFile);
		System.out.println(""Property: "" + prop.toString());
		StringBuilder builder = new StringBuilder(1024);
		int msgLenth = 256;
		for (int i = 0; i < msgLenth; i++)
			builder.append(""a"");

		int numberOfProducer = 4;
		Producer[] producer = new Producer[numberOfProducer];

		for (int i = 0; i < producer.length; i++) {
			producer[i] = new KafkaProducer(prop);
		}
		ExecutorService service =   new ThreadPoolExecutor(numberTh, numberTh,
                0L, TimeUnit.MILLISECONDS,
                new LinkedBlockingQueue<Runnable>(numberTh *2));
		
		for(int i = 0 ; i < numberTh;i++){
			service.execute(new MyProducer(producer,100000,builder.toString(), topic));
		}		
		latch.await();
		
		System.out.println(""All Producers done...!"");
		for (int i = 0; i < producer.length; i++) {
			producer[i].close();
		}		
		service.shutdownNow();
		System.out.println(""All done...!"");

	}


	
	static class MyProducer implements Runnable {
		
		Producer[] producer;
		long maxloops;
		String msg ;
		String topic;
		
		MyProducer(Producer[] list, long maxloops,String msg,String topic){
			this.producer = list;
			this.maxloops = maxloops;
			this.msg = msg;
			this.topic = topic;
		}
		public void run() {
			ProducerRecord record = new ProducerRecord(topic, msg.toString().getBytes());
			Callback  callBack = new  MyCallback();
			try{
				for(long j=0 ; j < maxloops ; j++){
					try {
						for (int i = 0; i < producer.length; i++) {
							producer[i].send(record, callBack);
						}
						Thread.sleep(10);
					} catch (Throwable th) {
						System.err.println(""FATAL "");
						th.printStackTrace();
					}
				}

			}finally {
				latch.countDown();
			}			
		}
	}	

	static class MyCallback implements Callback {
		public void onCompletion(RecordMetadata metadata, Exception exception) {
			if(exception != null){
				System.err.println(""Msg dropped..!"");
				exception.printStackTrace();
			}
			
		}
	}
	
}
{code}

This is property file used:
{code}
# THIS IS FOR NEW PRODUCERS API TRUNK Please see the configuration at https://kafka.apache.org/documentation.html#newproducerconfigs
# Broker List
bootstrap.servers= BROKERS HERE...
#Data Acks
acks=1
# 64MB of Buffer for log lines (including all messages).
buffer.memory=134217728
compression.type=snappy
retries=3
# DEFAULT FROM THE KAFKA...
# batch size =  ((buffer.memory) / (number of partitions)) (so we can have in progress batch size created for each partition.).
batch.size=1048576
#2MiB
max.request.size=1048576
send.buffer.bytes=2097152
# We do not want to block the buffer Full so application thread will not be blocked but logs lines will be dropped...
block.on.buffer.full=false
#2MiB
send.buffer.bytes=2097152
#wait...
linger.ms=5000
{code};;;","14/Oct/14 00:12;Bmis13; [~jkreps]  Let me know if you need any other help !!

Thanks,
Bhavesh ;;;","17/Oct/14 07:36;Bmis13;[~jkreps],

Did you get chance to re-produce the problem ?  Has someone else reported this issues or similar issue ?

Thanks,

Bhavesh ;;;","18/Oct/14 02:37;ewencp;Created reviewboard https://reviews.apache.org/r/26885/diff/
 against branch origin/trunk;;;","21/Oct/14 08:34;ewencp;Updated reviewboard https://reviews.apache.org/r/26885/diff/
 against branch origin/trunk;;;","21/Oct/14 08:42;ewencp;To summarize the issues fixed now:
* Fix logic issue with ""expired"" in RecordAccumulator.ready
* Don't include nodes that can send data when computing the delay until the next check for ready data. Including these doesn't make sense since their delays will change when we send data.
* To correctly account for nodes with sendable data, use a timeout of 0 if we send any. This guarantees any necessary delay is computed immediately in the next round after some current data has been removed.
* Properly account for nodes with sendable data under connection retry backoff. Since they weren't included in computing the next check delay when looking up ready nodes, we need to account for it later, but only if we conclude the node isn't ready. We need to incorporate the amount of backoff time still required before a retry will be performed (nothing else would wakeup at the right time, unlike other conditions like a full buffer which only change if data is received).

It might be possible to break this into smaller commits for each one, but the ordering of applying them needs to be careful because some by themselves result in bad behavior -- the existing client worked because it often ended up with poll timeouts that were much more aggressive (i.e., often 0).;;;","24/Oct/14 07:19;ewencp;Updated reviewboard https://reviews.apache.org/r/26885/diff/
 against branch origin/trunk;;;","15/Nov/14 02:59;ewencp;[~junrao] I think you reviewed most of this already since we discussed it offline, so I reassigned to you. I think this should be in good shape for committing.;;;","15/Nov/14 06:30;junrao;Thanks for the patch. Committed to trunk.;;;","15/Nov/14 06:55;junrao;Since this is relatively critical and the changes are only in the new java producer, double committed to 0.8.2 as well.;;;","24/Nov/14 09:29;Bmis13;The patch provided does not solve the problem.  When you have more than one or more producer instance,  the effect amplifies. 

org.apache.kafka.clients.producer.internals.Send.run() takes 100% CPU due to infinite  loop when there is no brokers (no work to be done to dump data).


Thanks,
Bhavesh ;;;","24/Nov/14 09:52;Bmis13;Please take look at experimental patch that solve this problem by capturing the correct Node state and also not so elegant by exponential backoff run() method by sleeping (many of the value is hard coded but it is just experimental).

Also, there is another problem close() method on producer does not exit and JVM does not gracefully  shutdown because io thread is spinning in  while loop during network outage.  This is also another edge case. 

I hope this will be very helpful and solve problem.

Thanks,

Bhavesh ;;;","24/Nov/14 13:31;ewencp;[~Bmis13] I've only taken a quick look at the patch, but Sender.run() is intentionally a tight loop. The body of the loop calls Sender.run(time), which in turn calls Client.poll() with a timeout that *should* keep it from actually being a tight loop. The previous patch fixed some issues in those other methods that were causing the timeout to incorrectly be 0, leading to the high CPU usage. If you're still seeing this problem, the right fix will almost definitely involve tracking down how a 0 (or very small) timeout is consistently being computed.

The way I verified the previous patch was simple -- I ran the producer against a local cluster and then just disabled the network connection. Can you describe how you produce the error now? Things like whether there are already active connections to the brokers, if it's time sensitive (e.g. takes a certain amount of time to start using CPU), exactly how you simulate the network failure, and whether the issue is consistent or only happens intermittently would all be helpful details to know.

The issue with it not shutting down is probably because the producer doesn't timeout messages when the leader it needs to send them to isn't available, but it waits to send any outstanding messages before shutting down. KAFKA-1788 is probably really the same issue since it's also caused by messages that never get sent and don't time out, although since that issue is specifically about the RecordAccumulator/buffer pool accounting, a fix for that issue may or may not fix the shutdown issue you're describing here.
;;;","25/Nov/14 01:25;Bmis13;[~ewencp],

The way to reproduce this is to simulate network instability by turning on and off network service (or turn on/off physical cable).   The connect and see if recover and disconnect and connect again etc.. you will see the behavior again and again. 

The issue is also with connection state management :

{code}
private void initiateConnect(Node node, long now) {
        try {
            log.debug(""Initiating connection to node {} at {}:{}."", node.id(), node.host(), node.port());
            // TODO FIX java.lang.IllegalStateException: No entry found for node -3 (We need put before remove it..)..
            this.connectionStates.connecting(node.id(), now);  (This line has problem because it will loose previous last attempt made get above exception and it will try to connect to that node for ever and ever with exception )
            selector.connect(node.id(), new InetSocketAddress(node.host(), node.port()), this.socketSendBuffer, this.socketReceiveBuffer);
        } catch (IOException e) {
            /* attempt failed, we'll try again after the backoff */
            connectionStates.disconnectedWhenConnectting(node.id());
            /* maybe the problem is our metadata, update it */
            metadata.requestUpdate();
            log.debug(""Error connecting to node {} at {}:{}:"", node.id(), node.host(), node.port(), e);
        }
    }
{code}

In my opinion, regardless of what node status is in run() method needs to be safe-guarded from still CPU Cycle when there is no state for Node.  (Hence I have added exponential sleep as temp solution to not to stealing CPU cycle , I think must protect it some how and must check the execution time...)

Please let me know if you need more info  and i will be more than happy to reproduce bug and we can have conference call, and I can show you the problem.

Based on code diff I have done from 0.8.1.1 tag and this.  This issue also occur in  0.8.1.1 as well I think.

Thanks,
Bhavesh 

;;;","25/Nov/14 05:20;Bmis13;[~ewencp],

Also Regarding KafkaProder.close() method hangs for ever because of following loop, and 

{code}
Sender.java

 // okay we stopped accepting requests but there may still be
// requests in the accumulator or waiting for acknowledgment,
// wait until these are completed.
while (this.accumulator.hasUnsent() || this.client.inFlightRequestCount() > 0) {
try {
run(time.milliseconds());
} catch (Exception e) {
log.error(""Uncaught error in kafka producer I/O thread: "", e);
}
}

KafkaProducer.java

 /**
* Close this producer. This method blocks until all in-flight requests complete.
*/
@Override
public void close() {
log.trace(""Closing the Kafka producer."");
this.sender.initiateClose();
try {
this.ioThread.join();  // THIS IS BLOCKED since ioThread does not give up so it is all related in my opinion.
} catch (InterruptedException e) {
throw new KafkaException(e);
}
this.metrics.close();
log.debug(""The Kafka producer has closed."");
}
{code}

The issue describe in KAFKA-1788  is likelihood, but if you look the close call stack then calling thread that initiated the close() will hang till io thread dies (which it never dies when data is there and network is down).  

Thanks,

Bhavesh
;;;","25/Nov/14 05:43;Bmis13;Here is exact steps how to reproducer it bug: (Must have demon program continuously running).

1)  Start with happy Situation where all borkers are up everything is running fine.  And verify all top -pid JAVA_PID and your kit (kafka network threads  are taking less than 4% CPU).
2)  Shutdown network (turn off network or pull the eth0 cable)  wait for while and you will see that CPU spike to 325% under top  (if you have 4 producer) and verify your kit is showing 25% CPU consumption for for each Kafka io thread.
3) Connect back the network ( Spike will still be there but CPU after while come down to 100% or so ) and remain connected for while.  
4) again simulate network failure (to simulate network instability) repeat steps again 1 to 4 but wait for 10 or so minutes in between and you will see the trends of CPU spike along with above exception. java.lang.IllegalStateException: No entry found for node -2

Also, I see that Kafka is logging excessively when network is down (your kit shows it is taking more CPU Cycle  as compare  to normal)

Thanks,
Bhavesh ;;;","25/Nov/14 06:15;Bmis13;Also, there is issue in my experimental patch.  I did not update the lastConnectAttemptMs...in connecting state method to solve the issue with illegal sate exp:
{code}
 /**
     * Enter the connecting state for the given node.
     * @param node The id of the node we are connecting to
     * @param now The current time.
     */
    public void connecting(int node, long now) {
    	NodeConnectionState nodeConn = nodeState.get(node); 
    	if(nodeConn == null){
    		nodeState.put(node, new NodeConnectionState(ConnectionState.CONNECTING, now));
    	}else{
    		nodeConn.state = ConnectionState.CONNECTING;
    		nodeConn.lastConnectAttemptMs = now;  (This will capture and update last connection attempt) 
    		
    	}
    }
{code};;;","25/Nov/14 07:25;ewencp;Ok, so as I suspected, you need to wait awhile before the issue shows up. It looks to me like this is due to a metadata refresh. This causes metadataTimeout in Client.poll() to be 0, but then maybeUpdateMetadata is unable to make any progress since it can't connect to any nodes. The previous patch fixed issues that caused the timeout parameter to that method to be 0, so this is a similar issue. However, under normal testing it won't always show up immediately -- you need to wait until the next metadata refresh, which is currently every 5 minutes.

I need to think more about the details of the fix. That timeout shouldn't consistently be 0 if we're just trying to refresh metadata, but we need to make sure we select an appropriate timeout for each case. Looking through maybeUpdateMetadata there are a few different possibilities:

1. leastLoadedNode returns null, leaving no nodes available and we don't even try to refresh
2. The selected node is connected and we can send more data - we mark metadataFetchInProgress to avoid resending requests, but should probably also use that to determine the timeout on poll()
3. The selected node is connected but we can't send more data yet
4. The selected node is not connected, but we are allowed to try to initiate a connection based on the reconnection backoff.
4a. Trying to initiate the connection may return an immediate error
4b. Or we'll need to wait for the connection event.
5. The selected node is not connected and we aren't allowed to initiate a new connection yet.

Given that all these conditions are based on the code in maybeUpdateMetadata (and initiateConnect, which it calls), it probably makes sense to have that code return an appropriate timeout to be used in poll(). But we need to make sure the selected values are also combined correctly with the timeout passed into poll() and that any wakeups before that time also subsequently produce correct values.

The logic in the Sender.run() and NetworkClient.poll() are complex and need to handle a lot of different cases, but it should be possible to fix this problem only by adjusting that code without adding retries/backoff further up the stack. The core of this problem is just that that loop is selecting too small a timeout.;;;","25/Nov/14 07:47;Bmis13;[~ewencp],

Thanks for looking into this really appreciate your response. 

Also, do you think rapid connect and disconnect is also due to incorrect Node state management ?  connecting method and initiateConnection also ?

Also, Can we also take the defensive coding and have protection in this tight infinite loop to throttle CPU cycle if it ends up with start-end duration is below some xx ms.  This will actually prevent this issues.    We had this issue on Prod so I just wanted to highlight the impact of 325% CPU and excessive logging. 

Thanks,

Bhavesh ;;;","25/Nov/14 12:23;Bmis13;Here are some more cases to reproduce this simulating network connection issue with one of brokers only and still problem persist:

Case 1:  brokers connection is down (note according to ZK leader for partition still with b1 ) 
Have tree brokers: b1, b2, b3
1)  Start your daemon program and keep sending data to all the brokers and continue sending some data 
2)  Observed that you have data  netstat -a | grep b1|b2|b3   (keep pumping data for 5 minutes and observed normal behavior using top -pid or top -p java_pid )
3) Simulate a network connection or problem establishing new TCP connection via following as java program still continues to pump data aggressively (please note TCP connection to B1 still active and connected)
a)  sudo vi /etc/hosts 2) add entry ""b1 127.0.0.1"" 
b) /etc/init.d/network restart  after while (5 to 7 minutes you will see the issue but keep pumping data, and also repeat this for b2 it will be more CPU consumption) 
 
4) Under a heavy dumping data, now producer will try to establish new TCP connection to B1 and it will get connection refused (Note that CPU spikes up again and remain in state) just because could not establish.

Case 2) Simulate Firewall rule such as you are only allowed (4 TCP connection to each brokers) 

Do step 1,2 and 3 above.
4) use Iptable rule to reject 
To start an ""enforcing fire wall"":
iptables -A OUTPUT -p tcp -m tcp -d b1 --dport 9092 -j REJECT
5) Still pump data will while iptable rejects ( you will see CPU spike to to 200% more depending on # of producer)
To ""recover"" :
iptables -D OUTPUT -p tcp -m tcp -d b1 --dport 9092 -j REJECT
;;;","25/Nov/14 12:28;Bmis13;[~ewencp],

I hope above steps will give you comprehensive steps to reproduce problems with run() method.  It would be really great if we can make the client more resilient and  robust so network and brokers instability does not cause CPU spikes and degrade application performance. Hence, I would strongly at least detect the time run(time) is taking and do some stats based on some configuration, we can do CPU Throttling (if need) just to be more defensive or at lest detect that io thread is taking CPU cycle.

By the way the experimental patch still works for steps describe above as well due to hard coded back-off. 

Any time you have patch or any thing, please let me know I will test it out ( you have my email id) .  Once again thanks for your detail analysis and looking at this at short notice.  

Please look into to ClusterConnectionStates and how it manage the state of node when disconnecting immediately . 

please look into  connecting(int node, long now) and this (I feel connecting needs to come before not after).
selector.connect(node.id(), new InetSocketAddress(node.host(), node.port()), this.socketSendBuffer, this.socketReceiveBuffer);
this.connectionStates.connecting(node.id(), now);

Also, I still feel that produce.close() is also needs to be looked at (join() method with some configuration time out so thread does not hang)

Thanks,

Bhavesh  ;;;","25/Nov/14 12:43;Bmis13;Also, Are you going to port back the patch to 0.8.1.1 version as well ?  Please let me know also.

Thanks,
Bhavesh ;;;","27/Nov/14 04:08;Bmis13;[~ewencp],

Even setting long following parameter, states of system does get impacted does not matter what reconnect.backoff.ms and retry.backoff.ms is set to.  Once Node state is removed, the time out is set to 0.  Please see the following logs.  

#15 minutes
reconnect.backoff.ms=900000
retry.backoff.ms=900000

{code}
2014-11-26 11:01:27.898 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:02:27.903 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:03:27.903 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:04:27.903 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:05:27.904 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:06:27.905 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:07:27.906 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:08:27.908 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:09:27.908 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:10:27.909 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:11:27.909 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:12:27.910 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:13:27.911 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:14:27.912 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:15:27.914 Kafka Drop message topic=.rawlog
org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms.
 2014-11-26 11:00:27.613 [kafka-producer-network-thread | heartbeat] ERROR org.apache.kafka.clients.producer.internals.Sender - Uncaught error in kafka producer I/O thread: 
 2014-11-26 11:00:27.613 [kafka-producer-network-thread | rawlog] ERROR org.apache.kafka.clients.producer.internals.Sender - Uncaught error in kafka producer I/O thread: 
java.lang.IllegalStateException: No entry found for node -1
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:131)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:120)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:407)
	at org.apache.kafka.clients.NetworkClient.maybeUpdateMetadata(NetworkClient.java:393)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:187)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:184)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:115)
	at java.lang.Thread.run(Thread.java:744)
java.lang.IllegalStateException: No entry found for node -3
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:131)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:120)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:407)
	at org.apache.kafka.clients.NetworkClient.maybeUpdateMetadata(NetworkClient.java:393)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:187)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:184)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:115)
	at java.lang.Thread.run(Thread.java:744)
 2014-11-26 11:00:27.613 [kafka-producer-network-thread | heartbeat] ERROR org.apache.kafka.clients.producer.internals.Sender - Uncaught error in kafka producer I/O thread: 
 2014-11-26 11:00:27.613 [kafka-producer-network-thread | error] ERROR org.apache.kafka.clients.producer.internals.Sender - Uncaught error in kafka producer I/O thread: 
 2014-11-26 11:00:27.613 [kafka-producer-network-thread | event] ERROR org.apache.kafka.clients.producer.internals.Sender - Uncaught error in kafka producer I/O thread: 
java.lang.IllegalStateException: No entry found for node -1
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:131)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:120)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:407)
	at org.apache.kafka.clients.NetworkClient.maybeUpdateMetadata(NetworkClient.java:393)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:187)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:184)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:115)
	at java.lang.Thread.run(Thread.java:744)
java.lang.IllegalStateException: No entry found for node -1
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:131)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:120)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:407)
	at org.apache.kafka.clients.NetworkClient.maybeUpdateMetadata(NetworkClient.java:393)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:187)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:184)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:115)
	at java.lang.Thread.run(Thread.java:744)
 2014-11-26 11:00:27.613 [kafka-producer-network-thread | error] ERROR org.apache.kafka.clients.producer.internals.Sender - Uncaught error in kafka producer I/O thread: 
java.lang.IllegalStateException: No entry found for node -1
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:131)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:120)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:407)
	at org.apache.kafka.clients.NetworkClient.maybeUpdateMetadata(NetworkClient.java:393)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:187)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:184)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:115)
	at java.lang.Thread.run(Thread.java:744)
 2014-11-26 11:00:27.613 [kafka-producer-network-thread | rawlog] ERROR org.apache.kafka.clients.producer.internals.Sender - Uncaught error in kafka producer I/O thread: 
java.lang.IllegalStateException: No entry found for node -1
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:131)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:120)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:407)
	at org.apache.kafka.clients.NetworkClient.maybeUpdateMetadata(NetworkClient.java:393)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:187)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:184)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:115)
	at java.lang.Thread.run(Thread.java:744)
 2014-11-26 11:00:27.613 [kafka-producer-network-thread | error] ERROR org.apache.kafka.clients.producer.internals.Sender - Uncaught error in kafka producer I/O thread: 
java.lang.IllegalStateException: No entry found for node -3
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:131)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:120)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:407)
	at org.apache.kafka.clients.NetworkClient.maybeUpdateMetadata(NetworkClient.java:393)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:187)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:184)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:115)
	at java.lang.Thread.run(Thread.java:744)
{code};;;","27/Nov/14 13:37;soumen.sarkar;Is it reasonable to expect that timeout should have a lower bound (say *100 ms*) instead of being 0?;;;","28/Nov/14 09:55;Bmis13;[~soumen.sarkar],

Time out is one thing, but also IO Thread needs to be safe guarded to see how aggressive it is based on network and data to be send.  So it does not consume so much CPU cycle.

Thanks,
Bhavesh ;;;","01/Dec/14 04:24;Bmis13;I just discovered yesterday that 0.8.1.1 release does not have new producer code base jar officially released jar (kafka-clients) although code is there in 0.8.1.1 branch.   That created confusion about porting to  0.8.1.1.
  
Thanks,

Bhavesh ;;;","02/Dec/14 07:49;ewencp;Created reviewboard https://reviews.apache.org/r/28582/diff/
 against branch origin/trunk;;;","02/Dec/14 07:54;ewencp;Attached a new patch that fixes all the timeout issues I'm aware of. Here's how it addresses each of the situations I listed earlier:

1. lastNoNodeAvailableMs is updated, which forces metadata timeout for each poll to be  use a backoff period

2. Added another backoff value based on metadataFetchInProgress. Since the request actually made it out, this can be arbitrarily large -- we just need to see some sort of response or failure for the request.

3. Requires some response to arrive to clear out space, so we can wait arbitrarily long. Updating lastNoNodeAvailableMs works even though it may wake up sooner than necessary. But making all cases that didn't send the data use a single approach keeps the code simpler.

4a. This can happen if, e.g., the network interface has been taken down entirely. After fixing the ordering of marking the node as connecting and issuing the request, this cleans up after that error cleanly. lastNoNodeAvailableMs is updated since there *weren't* any nodes available. This triggers a backoff period where the connection won't be retried.

4b. This can be handled in the same way - we set lastNoNodeAvailableMs whether or not we immediately saw an error from the connection request. This causes it to sleep while waiting for the connection request. This may wake up before we get connected. However, if the node is still in the connecting state, it'll be ignored during the next round and we'll either start trying to connect to another node or we'll end up in state 1 with no nodes available. Either way, we still only wake up periodically based on the this timeout.

5. Looking more carefully at how leastLoadedNode works, this case isn't actually possible.

One additional note -- apparently you can't use Long.MAX_VALUE as a timeout, it throws an exception. That's why Integer.MAX_VALUE is there instead. We could also detect the large value and convert it to a negative value instead, which the underlying API treats as having no timeout.

[~Bmis13] can you test this out for the failure modes you found?;;;","03/Dec/14 01:59;stevenz3wu;this sounds like a serious blocker issue. once this fix is confirmed and merged, is there any chance for a patch release of 0.8.2.1? ;;;","03/Dec/14 02:02;ewencp;[~stevenz3wu] this is already a blocker on 0.8.2. 0.8.2 hasn't been released yet, only a beta.;;;","03/Dec/14 02:18;stevenz3wu;[~ewencp] forgot 0.8.2 is still beta, because we are already using 0.8.2-beta now. thanks for the clarification.;;;","03/Dec/14 04:00;Bmis13;Hi  [~ewencp],

I will not have time to validate this patch till next week.  

Here is my comments:

1) Producer.close() method issue is not address with patch. In event of network connection lost or other events happens, IO thread will not be killed and close method hangs. In patch that I have provided, I had timeout for join method and interrupted IO thread.  I think we need similar solution.

2) Also, can we please add JMX monitoring for IO tread to know how quick it is running.  It will great to add this and run() method will report duration to metric in nano sec.
{code}
            try{
            	ThreadMXBean bean = ManagementFactory.getThreadMXBean( );
            	if(bean.isThreadCpuTimeSupported() && bean.isThreadCpuTimeEnabled()){
            		this.ioTheadCPUTime = metrics.sensor(""iothread-cpu"");
                    this.ioTheadCPUTime.add(""iothread-cpu-ms"", ""The Rate Of CPU Cycle used by iothead in NANOSECONDS"", new Rate(TimeUnit.NANOSECONDS) {
                        public double measure(MetricConfig config, long now) {
                            return (now - metadata.lastUpdate()) / 1000.0;
                        }
                    });	            		
            	}
            }catch(Throwable th){
            	log.warn(""Not able to set the CPU time... etc"");
            }
{code}

3)  Please check the timeout final value in *pollTimeout* if it is zero for constantly then we need to slow IO thread down.

4)  Defensive check is need for back off  in run() method when IO thread is aggressive.  

{code}

        while (running) {
        	long start = time.milliseconds();
            try {
                run(time.milliseconds());        
            } catch (Exception e) {
                log.error(""Uncaught error in kafka producer I/O thread: "", e);
            }finally{
            	long durationInMs = time.milliseconds() - start;
            	// TODO Fix ME HERE GET DO exponential back-off sleep etc to prevent still CPU CYCLE HERE ?????? How Much ...for the edge case...
            	if(durationInMs < 200){
            		if(client.isAllRegistredNodesAreDown()){
            			countinuousRetry++;
            			 /// TODO MAKE THIS CONSTANT CONFIGURATION..... when do we rest this interval ????? so we can try aggressive again...
            			sleepInMs = ((long) Math.pow(2, countinuousRetry) * 500);
            		}else{
            			sleepInMs =  500 ; 
            			countinuousRetry = 0;
            		}
            		
            		// Wait until the desired next time arrives using nanosecond
            		// accuracy timer (wait(time) isn't accurate enough on most platforms) 
            		try {
            			// TODO SLEEP IS NOT GOOD SOLUTON..
						Thread.sleep(sleepInMs);
					} catch (InterruptedException e) {
						log.error(""While sleeping some one interupted this tread probally close method on prodcuer close () "");
					}  
            	}
            }
        }
{code}

5)  When all nodes are disconnected, do you still want to spin the IO Thread ?

6)  When you have a firewall rule that says ""you can only have 2 concurrent TCP connections from Client to Brokers"" and client still have live TCP connection to same node (Broker), but new TCP connections are rejected. Node State will be marked as Disconnected in initiateConnect ?  Is this case handled gracefully  ?

By the way, thank you very much for quick reply and with new patch.  I appreciate your help.

Thanks,

Bhavesh ;;;","03/Dec/14 08:57;ewencp;[~Bmis13], responses to each item:

1. I'm specifically trying to address the CPU usage here. I realize from your perspective they are closely related since they're both can be triggered by a loss of network connectivity, but internally they're really separate issues -- the CPU usage has to do with incorrect timeouts and the join() issues is due to the lack of timeouts on produce operations. That's why I pointed you toward KAFKA-1788. If a timeout is added for data in the producer, that would resolve the close issue as well since any data waiting in the producer would eventually timeout and the IO thread could exit. I think that's the cleanest solution since it solves both problems with a single setting (the amount of time your willing to wait before discarding data). If you think a separate timeout specifically for Producer.close() is worthwhile I'd suggest filing a separate JIRA for that.

2. I think the measure() implementation you have is incorrect, it looks like the amount of time since the last metadata update. In any case, I think you'd want a sensor there so it would take care of computing the rate for you. Is the use case for this just detecting the CPU spike? I suppose providing the average iteration rate can at least tell you the source of CPU usage compared to just monitoring CPU at the system level. But (as described below) it's not necessarily bad for the rate to be quite high. And an average also doesn't tell you much except maybe in the extreme case that we're fixing with this patch. Before just adding another metric, maybe we should think through exactly what you're trying to measure/monitor and how best to reveal that information?

3. I probably should have given a better explanation earlier for why that approach is problematic. In a lot of cases, you *want* run() to use small timeouts. If you're pumping a lot of data through, saturating your network connection, then you're likely to going to need to poll very fast and end up with consistently small timeouts (e.g. if you produce to many topics and consistently have data flowing through them, you'll end up using the linger period and your timeout will generally be a fraction of that period). In other words, if we've actually given the producer a lot of work to do, then we should expect that it will use short timeouts and eat up CPU. You found that you could work around your particular issue by backing off, but it breaks another very important use case -- high throughput to the producer. I bet if you ran performance tests with it enabled you would find diminished performance. Fundamentally the bug wasn't that we were sometimes computing small timeouts consistently, it was that we were computing *incorrect* timeouts. If we get the timeouts computed correctly, then we'll properly support both cases.

4. See explanation in 3. The rate of this loop is controlled by correct computation of timeouts. I think the only case this code could be an issue is if we compute correct timeouts, but then consistently see exceptions that are only caught by this block. That shouldn't be happening consistenly, and if you find an example where it is then we should catch that exception deeper in the call stack and handle it more gracefully.

5. The thread still has to be available so that when send() is called again it can initiate a connection. What should happen now (after my patch) if there is no work to do is that we'll still run the loop, but the timeout will be very large so it basically won't be using any CPU. If we get a request to send data, a wakeup() call wakes it back up before the timeout so it can start sending data immediately.

6. It should be handled gracefully, and should have been fixed by the original patch (although maybe the fix to the ordering in initiateConnect in the second patch was also necessary). The logic in Sender.run() adjusts timeouts when it finds nodes that aren't ready to send data (i.e. are disconnected) and makes sure we backoff when connection attempts fail. This is a fixed backoff (reconnect.backoff.ms, default 10ms), but is enough to avoid high CPU usage.
;;;","05/Dec/14 00:01;Bmis13;[~ewencp],

1) I will posted toward KAFKA-1788 and perhaps link the issue.
2) True , some sort of measure would be great 5,10...25 50, 95 and 99 percentile would be great of execution time.  The point is just measure the duration report the rate of execution. 
3) Agree with what you are saying and I have observed same behavior.  But only recommendation is to add some intelligence to *timeouts* to detect if for long period and consecutive timeout is zero then there is problem. (Little more defensive) 
4) Again I agree with you point, but based in your previous comments you had mentioned that you may consider having back-off logic further up the chain. So I was just checking run() is best place to do that check.  Again, may be add intelligence here if you get consecutive “Exception” then likelihood of high CPU is high.  
 
5) Ok.  I agree what you are saying is data needs to be de-queue so more data can be en-queue even in event of network lost.  Is my understanding correct ?

6) All I am saying is network firewall rule (such as only 2 TCP connections per source host) or Brokers running out of File Descriptor so new connection to broker is not established but Client have live and active TCP connection to same broker.  But based on what I see in the method * initiateConnect* will mark the entire Broker or Node status as disconnected.  Is this expected behavior?  So question is: will client continue to send data ?

Thank you very much for entertaining my questions so far and I will test out the patch next week.

Thanks,

Bhavesh ;;;","09/Dec/14 14:52;Bmis13;[~stevenz3wu],

0.8.2 is very well tested and worked well under heavy load.  This bug is rare only happen when broker or network has issue.  We have been producing about 7 to 10 TB per day using this new producer, so 0.8.2 is very safe to use in production.  It has survived  pick traffic of the year on large e-commerce site.  So I am fairly confident that  New Java API is indeed does true round-robin and much faster than Scala Based API.

[~ewencp],  I will verify the patch by end of this Friday, but do let me know your understanding based on my last comment. The goal is to rest this issue and cover all the use case.

Thanks,

Bhavesh;;;","24/Dec/14 07:35;Bmis13;[~ewencp],

Patch indeed solve the high CPU Problem reported by this bug.  I have tested all brokers down, one broker down and two broker down (except for last use cases where one of the brokers runs out of Socket File Descriptor a rear case) :  I am sorry for last response, I got busy with other stuff so testing got delayed.

Here are some interesting Observations from YourKit:

0)  Overall, patch has also brought down  overall consumption in Normal Healthy or Happy case where every thing is up and running.  In old code (without patch), I used to see about 10% of overall CPU used by  io threads (4 in my case), it has reduce to 5% or less now with patch.   

1)	When two brokers are down, then occasionally I see IO thread blocked. ( I did not see this when one brokers is down) 

{code}
kafka-producer-network-thread | rawlog [BLOCKED] [DAEMON]
org.apache.kafka.clients.producer.internals.Metadata.fetch() Metadata.java:70
java.lang.Thread.run() Thread.java:744
{code}

2)	record-error-rate metric remain zero despite following firewall rule.  In my opinion, it should have called  org.apache.kafka.clients.producer.Callback  but I did not see that happening either in either one or two brokers down.  Should I file another issue for this ? Please confirm.

{code}

sudo ipfw add reject tcp from me to b1.ip dst-port 9092
sudo ipfw add reject tcp from me to b2.ip dst-port 9092

00100 reject tcp from me to b1.ip dst-port 9092
00200 reject tcp from me to b2.ip dst-port 9092
{code}

{code}
	class LoggingCallBaHandler implements Callback {

		/**
		 * A callback method the user can implement to provide asynchronous
		 * handling of request completion. This method will be called when the
		 * record sent to the server has been acknowledged. Exactly one of the
		 * arguments will be non-null.
		 * 
		 * @param metadata
		 *            The metadata for the record that was sent (i.e. the
		 *            partition and offset). Null if an error occurred.
		 * @param exception
		 *            The exception thrown during processing of this record.
		 *            Null if no error occurred.
		 */
		@Override
		public void onCompletion(RecordMetadata metadata, Exception exception) {
			if(exception != null){
				exception.printStackTrace();
			}
		}
	}
{code}

I do not see any exception at all on console....not sure why ?

3)	Application does NOT gracefully shutdown when there one or more brokers are down. (io Thread never exits this is know issue ) 

{code}
""SIGTERM handler"" daemon prio=5 tid=0x00007f8bd79e4000 nid=0x17907 waiting for monitor entry [0x000000011e906000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bd5159000 nid=0x1cb0b waiting for monitor entry [0x000000011e803000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bdd147800 nid=0x15d0b waiting for monitor entry [0x000000011e30a000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bdf820000 nid=0x770b waiting for monitor entry [0x000000011e207000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bdc393800 nid=0x1c30f waiting for monitor entry [0x000000011e104000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""Thread-4"" prio=5 tid=0x00007f8bdb39f000 nid=0xa107 in Object.wait() [0x000000011ea89000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.$$YJP$$wait(Native Method)
        at java.lang.Object.wait(Object.java)
        at java.lang.Thread.join(Thread.java:1280)
        - locked <0x0000000705c2f650> (a org.apache.kafka.common.utils.KafkaThread)
        at java.lang.Thread.join(Thread.java:1354)
        at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:322)
        at 

""kafka-producer-network-thread | error"" daemon prio=5 tid=0x00007f8bd814e000 nid=0x7403 runnable [0x000000011e6c0000]
   java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.KQueueArrayWrapper.$$YJP$$kevent0(Native Method)
        at sun.nio.ch.KQueueArrayWrapper.kevent0(KQueueArrayWrapper.java)
        at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:200)
        at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
        - locked <0x0000000705c109f8> (a sun.nio.ch.Util$2)
        - locked <0x0000000705c109e8> (a java.util.Collections$UnmodifiableSet)
        - locked <0x0000000705c105c8> (a sun.nio.ch.KQueueSelectorImpl)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
        at org.apache.kafka.common.network.Selector.select(Selector.java:322)
        at org.apache.kafka.common.network.Selector.poll(Selector.java:212)
        at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:192)
        at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:184)
        at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:128)
        at java.lang.Thread.run(Thread.java:744)
{code}

Thank you for the patch fix.

Thanks,
Bhavesh;;;","24/Dec/14 09:27;ewencp;1) Since this method just returns data, it probably just happens to have had to wait for the lock. Not a big deal, we would expect to see that occasionally.

2) Right now this is expected, as explained in KAFKA-1788. I saw there's patch for that one now, might help if you tested that out and see if gives the behavior you were expecting.

3) As you said, known issue so we can leave that for other JIRAs to resolve.;;;","24/Dec/14 09:40;Bmis13;[~ewencp],

Thanks for patch.  You may close this issue.   The only thing,  I have not tested the rare case where a single broker is out of File Descriptor and under heavy load on producer will request more connections to same broker.  According to code, it will mark the Node State to disconnect and I am not sure if data will be sent via already live connection.  

Another comment is that there is no WARN or ERROR message logged when connection fails. Can we please change the log level for following code to WAR, because in production environment people set LOG LEVEL to WARN or ERROR.  So there will no visibility if there is connection issue.  

{code}
   /**
     * Initiate a connection to the given node
     */
    private void initiateConnect(Node node, long now) {
        try {
            log.debug(""Initiating connection to node {} at {}:{}."", node.id(), node.host(), node.port());
            this.connectionStates.connecting(node.id(), now);
            selector.connect(node.id(), new InetSocketAddress(node.host(), node.port()), this.socketSendBuffer, this.socketReceiveBuffer);
        } catch (IOException e) {
            /* attempt failed, we'll try again after the backoff */
            connectionStates.disconnected(node.id());
            /* maybe the problem is our metadata, update it */
            metadata.requestUpdate();
            log.debug(""Error connecting to node {} at {}:{}:"", node.id(), node.host(), node.port(), e);
        }
    }
{code}

Thanks for all your help !

Thanks,

Bhavesh  ;;;","30/Dec/14 06:49;nehanarkhede;Thanks for following through on this, [~ewencp]! [~junrao], since you probably have most context on this, would you mind reviewing the follow up patch (https://reviews.apache.org/r/28582/diff/) so we can close this out?;;;","06/Jan/15 10:56;ewencp;Updated reviewboard https://reviews.apache.org/r/28582/diff/
 against branch origin/trunk;;;","07/Jan/15 02:57;junrao;Thanks for the latest followup patch. +1 and committed to both 0.8.2 and trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New consumer's subscribe(Topic...) api fails if called more than once,KAFKA-2413,12852833,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,onurkaraman,singhashish,singhashish,07/Aug/15 08:11,08/Aug/15 06:20,22/Mar/23 15:10,08/Aug/15 06:20,,,,,,,0.9.0.0,,,,,,,consumer,,,,0,,,,,,"I believe new consumer is supposed to allow adding to existing topic subscriptions. If it is then the issue is that on trying to subscribe to a topic when consumer is already subscribed to a topic, below exception is thrown.

{code}
[2015-08-06 16:06:48,591] ERROR [KafkaApi-2] error when handling request null (kafka.server.KafkaApis:103)
java.util.NoSuchElementException: key not found: topic
	at scala.collection.MapLike$class.default(MapLike.scala:228)
	at scala.collection.AbstractMap.default(Map.scala:58)
	at scala.collection.MapLike$class.apply(MapLike.scala:141)
	at scala.collection.AbstractMap.apply(Map.scala:58)
	at kafka.coordinator.RangeAssignor$$anonfun$4.apply(PartitionAssignor.scala:109)
	at kafka.coordinator.RangeAssignor$$anonfun$4.apply(PartitionAssignor.scala:108)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:251)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:251)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:251)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:105)
	at kafka.coordinator.RangeAssignor.assign(PartitionAssignor.scala:108)
	at kafka.coordinator.ConsumerCoordinator.reassignPartitions(ConsumerCoordinator.scala:378)
	at kafka.coordinator.ConsumerCoordinator.rebalance(ConsumerCoordinator.scala:360)
	at kafka.coordinator.ConsumerCoordinator.onCompleteRebalance(ConsumerCoordinator.scala:414)
	at kafka.coordinator.DelayedRebalance.onComplete(DelayedRebalance.scala:39)
	at kafka.server.DelayedOperation.forceComplete(DelayedOperation.scala:72)
	at kafka.coordinator.DelayedRebalance$$anonfun$tryComplete$1.apply$mcZ$sp(DelayedRebalance.scala:37)
	at kafka.coordinator.ConsumerCoordinator.tryCompleteRebalance(ConsumerCoordinator.scala:388)
	at kafka.coordinator.DelayedRebalance.tryComplete(DelayedRebalance.scala:37)
	at kafka.server.DelayedOperationPurgatory$Watchers.tryCompleteWatched(DelayedOperation.scala:307)
	at kafka.server.DelayedOperationPurgatory.checkAndComplete(DelayedOperation.scala:227)
	at kafka.coordinator.ConsumerCoordinator.doJoinGroup(ConsumerCoordinator.scala:186)
	at kafka.coordinator.ConsumerCoordinator.handleJoinGroup(ConsumerCoordinator.scala:131)
	at kafka.server.KafkaApis.handleJoinGroupRequest(KafkaApis.scala:578)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:67)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)

Unexpected error in join group response: The server experienced an unexpected error when processing the request
org.apache.kafka.common.KafkaException: Unexpected error in join group response: The server experienced an unexpected error when processing the request
	at org.apache.kafka.clients.consumer.internals.Coordinator$JoinGroupResponseHandler.handle(Coordinator.java:362)
	at org.apache.kafka.clients.consumer.internals.Coordinator$JoinGroupResponseHandler.handle(Coordinator.java:311)
	at org.apache.kafka.clients.consumer.internals.Coordinator$CoordinatorResponseHandler.onSuccess(Coordinator.java:703)
	at org.apache.kafka.clients.consumer.internals.Coordinator$CoordinatorResponseHandler.onSuccess(Coordinator.java:677)
	at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:163)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:129)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:105)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.onComplete(ConsumerNetworkClient.java:293)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:237)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:274)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:182)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:172)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:145)
	at org.apache.kafka.clients.consumer.internals.Coordinator.reassignPartitions(Coordinator.java:197)
	at org.apache.kafka.clients.consumer.internals.Coordinator.ensurePartitionAssignment(Coordinator.java:172)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:764)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:725)
	at kafka.api.ConsumerTest$$anonfun$testRepetitiveTopicSubscription$2.apply$mcZ$sp(ConsumerTest.scala:80)
	at kafka.utils.TestUtils$.waitUntilTrue(TestUtils.scala:616)
	at kafka.api.ConsumerTest.testRepetitiveTopicSubscription(ConsumerTest.scala:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.scalatest.junit.JUnit3Suite.run(JUnit3Suite.scala:309)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
{code}",,githubbot,gwenshap,hachikuji,onurkaraman,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1893,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Aug 07 22:20:36 UTC 2015,,,,,,,,,,"0|i2ig53:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"07/Aug/15 08:13;singhashish;[~hachikuji] thoughts?;;;","07/Aug/15 08:23;onurkaraman;Couple questions to start things off:
1. What is the git hash of kafka you're running on the brokers and consumers?
2. How can I reproduce this? What does your consumer code look like? More specifically, can you go into more detail on the ""called more than once"" part?;;;","07/Aug/15 08:52;hachikuji;[~onurkaraman] I was able to reproduce this error on trunk by subscribing to a second topic while in the consumer's poll loop. It looks like the error might be related to how the server manages group topics.;;;","07/Aug/15 09:15;singhashish;Thanks guys for quick response!

Below is a test case that can repro the issue.

{code}
  def testRepetitiveTopicSubscription() {
    val numRecords = 10000
    sendRecords(numRecords)

    this.consumers(0).subscribe(""topic"")

    TestUtils.waitUntilTrue(() => {
      this.consumers(0).poll(50)
      this.consumers(0).subscriptions.size == 2
    },
      ""Could not find expected number of subscriptions"")

    TestUtils.createTopic(this.zkClient, ""tblablac"", 2, serverCount, this.servers)
    sendRecords(1000, new TopicPartition(""tblablac"", 0))
    sendRecords(1000, new TopicPartition(""tblablac"", 1))

    this.consumers(0).subscribe(""tblablac"")

    TestUtils.waitUntilTrue(() => {
      this.consumers(0).poll(50)
      this.consumers(0).subscriptions.size == 4
    },
      ""Could not find expected number of subscriptions"")
  }
{code}

I guess another interesting problem to solve.;;;","07/Aug/15 09:19;hachikuji;I think the issue is in here (in ConsumerCoordinator):

{code}
  private def updateConsumer(group: ConsumerGroupMetadata, consumer: ConsumerMetadata, topics: Set[String]) {
    val topicsToBind = topics -- group.topics
    group.remove(consumer.consumerId)
    val topicsToUnbind = consumer.topics -- group.topics
    group.add(consumer.consumerId, consumer)
    consumer.topics = topics
    coordinatorMetadata.bindAndUnbindGroupFromTopics(group.groupId, topicsToBind, topicsToUnbind)
  }
{code}

In particular, it looks like topicsToUnbind is taking the difference in the wrong order. But I'm not sure that just reversing that is correct either since we'd only wan to unbind the topic if no other consumers in the group are subscribed.;;;","07/Aug/15 09:32;hachikuji;[~singhashish] I can attempt a patch if you want.;;;","07/Aug/15 09:48;singhashish;[~hachikuji] I was planning to play with it to get more accustomed with the new consumer's intricacies. If you have not already worked out a patch, then is it OK I try to fix it by tonight?;;;","07/Aug/15 10:49;onurkaraman;Woops! I haven't tried it out yet, but I think the fix is:
{code}
private def updateConsumer(group: ConsumerGroupMetadata, consumer: ConsumerMetadata, topics: Set[String]) {
  val topicsToBind = topics -- group.topics
  group.remove(consumer.consumerId)
  val topicsToUnbind = consumer.topics -- (group.topics ++ topics)
  group.add(consumer.consumerId, consumer)
  consumer.topics = topics
  coordinatorMetadata.bindAndUnbindGroupFromTopics(group.groupId, topicsToBind, topicsToUnbind)
}
{code}

I forgot to factor in the possibility of the consumer's previous subscriptions overlapping with its new subscriptions.;;;","07/Aug/15 11:05;onurkaraman;Okay I just tested it out. It seems to have fixed the bug.;;;","07/Aug/15 11:11;onurkaraman;I'll have the patch ready later today.;;;","07/Aug/15 12:34;singhashish;Hi [~onurkaraman], sorry for not explicitly saying this, but I am working on a patch already. Thanks for your help!;;;","07/Aug/15 12:56;githubbot;GitHub user onurkaraman opened a pull request:

    https://github.com/apache/kafka/pull/122

    KAFKA-2413: fix ConsumerCoordinator updateConsumer

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/onurkaraman/kafka KAFKA-2413

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/122.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #122
    
----
commit 073dc4b716594880de4fb58c8832f02dd3792683
Author: Onur Karaman <okaraman@linkedin.com>
Date:   2015-08-07T04:49:53Z

    fix ConsumerCoordinator updateConsumer

----
;;;","07/Aug/15 12:58;onurkaraman;Aaaaaand I just saw this. My bad.;;;","07/Aug/15 13:09;singhashish;I am not sure if posting patches to issues other person is working on is a good idea. It is discouraging, that is all I can see. There has to be a reason why ""Assignee"" field is present in JIRA. I guess it will be a moot point to discuss about it anymore as the fix is already posted. Feel free to assign yourself to the JIRA. I will review the patch posted by you as I have already spent some time to find the issue and to try to fix it. I just hope it does not happen again.;;;","08/Aug/15 06:20;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/122
;;;","08/Aug/15 06:20;gwenshap;Issue resolved by pull request 122
[https://github.com/apache/kafka/pull/122];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Warn users if they change max.message.bytes that they also need to update broker and consumer settings,KAFKA-2338,12845364,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,benstopford,ewencp,ewencp,16/Jul/15 03:16,22/Oct/15 23:34,22/Mar/23 15:10,21/Oct/15 08:22,0.8.2.1,,,,,,0.9.0.0,,,,,,,core,,,,0,,,,,,"We already have KAFKA-1756 filed to more completely address this issue, but it is waiting for some other major changes to configs to completely protect users from this problem.

This JIRA should address the low hanging fruit to at least warn users of the potential problems. Currently the only warning is in our documentation.

1. Generate a warning in the kafka-topics.sh tool when they change this setting on a topic to be larger than the default. This needs to be very obvious in the output.
2. Currently, the broker's replica fetcher isn't logging any useful error messages when replication can't succeed because a message size is too large. Logging an error here would allow users that get into a bad state to find out why it is happening more easily. (Consumers should already be logging a useful error message.)",,eribeiro,ewencp,githubbot,gwenshap,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2684,,,,,,,,"18/Jul/15 03:32;eribeiro;KAFKA-2338.patch;https://issues.apache.org/jira/secure/attachment/12745873/KAFKA-2338.patch","18/Jul/15 11:37;eribeiro;KAFKA-2338_2015-07-18_00:37:31.patch;https://issues.apache.org/jira/secure/attachment/12745929/KAFKA-2338_2015-07-18_00%3A37%3A31.patch","22/Jul/15 00:21;eribeiro;KAFKA-2338_2015-07-21_13:21:19.patch;https://issues.apache.org/jira/secure/attachment/12746379/KAFKA-2338_2015-07-21_13%3A21%3A19.patch","25/Aug/15 01:36;eribeiro;KAFKA-2338_2015-08-24_14:32:38.patch;https://issues.apache.org/jira/secure/attachment/12752040/KAFKA-2338_2015-08-24_14%3A32%3A38.patch","03/Sep/15 06:31;eribeiro;KAFKA-2338_2015-09-02_19:27:17.patch;https://issues.apache.org/jira/secure/attachment/12753868/KAFKA-2338_2015-09-02_19%3A27%3A17.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Oct 22 12:28:36 UTC 2015,,,,,,,,,,"0|i2hat3:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"18/Jul/15 03:32;eribeiro;Created reviewboard https://reviews.apache.org/r/36578/diff/
 against branch origin/trunk;;;","18/Jul/15 03:34;eribeiro;Hi [~ewencp], as this my first official Kafka patch (yay!) it should have some misunderstandings or plain errors (I was particularly in doubt about the logging of a useful message by the broker's replica fetcher). Please, whenever you have time, see if it's okay. Thanks!;;;","18/Jul/15 11:37;eribeiro;Updated reviewboard https://reviews.apache.org/r/36578/diff/
 against branch origin/trunk;;;","21/Jul/15 11:16;eribeiro;Hi [~gwenshap], whenever you have a free cycles, could you please review this puppy? :) Still getting acquainted with the code base, so I hope not far off what's required. 

Thanks!;;;","21/Jul/15 22:55;eribeiro;Oh, ignore the previous message, [~gwenshap], I will be reworking the patch to fix it.;;;","22/Jul/15 00:21;eribeiro;Updated reviewboard https://reviews.apache.org/r/36578/diff/
 against branch origin/trunk;;;","09/Aug/15 12:09;gwenshap;Moving to patch-available so we won't forget to review.;;;","23/Aug/15 10:39;gwenshap;OK, this patch doesn't even come close to fixing everything that is broken with max message sizes, but it is short, sweet and will probably be useful to some users. 

+1;;;","23/Aug/15 10:40;gwenshap;Sorry, patch doesn't apply again :(

Can you rebase?;;;","25/Aug/15 01:36;eribeiro;Updated reviewboard https://reviews.apache.org/r/36578/diff/
 against branch origin/trunk;;;","25/Aug/15 01:46;eribeiro;Hi, [~gwenshap], thanks for the kind words. :) I am sorry for not being able to give the necessary love to this patch :( (much because of my inexperience with the code base, I guess). I hope I can dig more about max message size problems soon tough. I have just rebased the patch and it compiles successfully now with latest trunk.

Oh, one thing that has caught my attention is that some chunk of code (below) was removed from TopicCommand, specifically in the alterTopic() method, in the context of KAFKA-2198 (a7e0ac):. Seems to indicate that now topic configuration cannot be altered, right?

{code}
      val configs = AdminUtils.fetchTopicConfig(zkClient, topic)
      if(opts.options.has(opts.configOpt) || opts.options.has(opts.deleteConfigOpt)) {
        val configsToBeAdded = parseTopicConfigsToBeAdded(opts)
        val configsToBeDeleted = parseTopicConfigsToBeDeleted(opts)
        // compile the final set of configs
        configs.putAll(configsToBeAdded)
        configsToBeDeleted.foreach(config => configs.remove(config))
        AdminUtils.changeTopicConfig(zkClient, topic, configs)
        println(""Updated config for topic \""%s\""."".format(topic))
      }
{code}

Sorry if my doubt is naive/stupid. And feel free to merge this patch, but take a look to see if I am doing it right. :) 

Thanks!
Edward;;;","03/Sep/15 06:31;eribeiro;Updated reviewboard https://reviews.apache.org/r/36578/diff/
 against branch origin/trunk;;;","16/Oct/15 07:59;githubbot;GitHub user benstopford opened a pull request:

    https://github.com/apache/kafka/pull/322

    KAFKA-2338: Warn on max.message.bytes change

    - Both TopicCommand and ConfigCommand warn if message.max.bytes increases
    - Log failures on the broker if replication gets stuck due to an oversized message


You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/benstopford/kafka CPKAFKA-61

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/322.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #322
    
----
commit d59110d28fe1dcd62520e2b031005a369ceb4bc7
Author: benstopford <benstopford@gmail.com>
Date:   2015-10-15T17:13:09Z

    KAFKA-2338: Warn user if they override max.message.bytes. Warn on failing replica fetches.

----
;;;","21/Oct/15 08:22;junrao;Issue resolved by pull request 322
[https://github.com/apache/kafka/pull/322];;;","21/Oct/15 08:22;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/322
;;;","22/Oct/15 20:28;githubbot;GitHub user benstopford opened a pull request:

    https://github.com/apache/kafka/pull/351

    KAFKA-2338: add force option to topic / config command so they can be called programatically

    Tiny change to add a force option to the topic and config commands so they can be called programatically without requiring user input. 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/benstopford/kafka CPKAFKA-61B

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/351.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #351
    
----
commit b29316e7174f21a91043d7a3aa451b6345324dd2
Author: Ben Stopford <benstopford@gmail.com>
Date:   2015-10-22T12:27:13Z

    KAFKA-2338: add 'force' option to avoid console prompts

----
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix kafka ssl configs to not throw warnings,KAFKA-2472,12858653,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,sriharsha,sriharsha,25/Aug/15 23:24,25/Oct/15 00:34,22/Mar/23 15:10,22/Oct/15 08:11,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"This is a follow-up fix on kafka-1690.
[2015-08-25 18:20:48,236] WARN The configuration ssl.truststore.password = striker was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[2015-08-25 18:20:48,236] WARN The configuration security.protocol = SSL was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)",,githubbot,gwenshap,ijuma,jkreps,junrao,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Oct 24 16:34:30 UTC 2015,,,,,,,,,,"0|i2jch3:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"25/Aug/15 23:53;gwenshap;I'm wondering if we still need the unknown config warnings at all - the entire system was designed to pass arguments to SSL, serializers, reporters, etc. Unknown configs are expected at this point.;;;","25/Aug/15 23:56;sriharsha;[~gwenshap]  I think we should remove the warning.;;;","02/Sep/15 06:34;junrao;The original intention is to warn people of mis-spelled config names. Also, we are only supposed to log those unused properties as warning and we do that (config.logUnused()) at the end of the instantiation of the producer. So, not sure why those warning will show up.;;;","19/Oct/15 19:52;ijuma;[~harsha_ch], do you mind if I take this?;;;","19/Oct/15 20:18;sriharsha;[~ijuma] No worries. Take it over.;;;","19/Oct/15 20:32;ijuma;Thank you.;;;","20/Oct/15 16:26;ijuma;[~junrao], the reason why we have the warnings is that we are passing a Map<String, ?> to the various `configure` methods and we do that by calling `AbstractConfig.values()`. This means that the usage of the parameters is never recorded and we also have to cast instead of using the nicer getString, getInt, etc. methods. And we also have `KafkaConfig.channelConfigs` where we must remember to add the relevant configs (which is error-prone).

Is there a reason why the `configure` methods can't accept an `AbstractConfig` instead of `Map<String, ?>`?;;;","20/Oct/15 20:46;ijuma;I did a quick spike:

* Introduced a `Config` interface with the `get*` methods
* Changed `Configurable.configure` to take the `Config` interface
* Introduced `SimpleConfig` that just wraps a `Map<String, ?>` for tests and code that doesn't use a `ConfigDef`
* Adapted all the code so that it compiles
* Ran the tests

It looks promising. There were some test failures, I investigated one and it was due to a genuine bug in trunk (there is no `define` for KafkaConfig.SSLEndpointIdentificationAlgorithmProp in the broker).

Thoughts?
;;;","21/Oct/15 00:31;jkreps;[~gwenshap] This should work with plugins too. The config helper code records which configs are requested, so even a config specific to a plugin like a serializer should still get requested by the serializer.

[~ijuma] The only thing to be careful of is that if we are changing the Configurable interface that that doesn't result in changing any public interfaces people have implemented such as Partitioner.;;;","21/Oct/15 00:46;ijuma;[~jkreps], good point regarding Partitioner and other public classes. That's a problem for the approach I suggested. Without default methods, it seems like we can't change `Configurable`.

We could introduce a new interface and use it in new classes and classes that are not public, but it's not great to have two interfaces for the same thing. An alternative is to pass to a special Map implementation to `configure` that records usage. It still means that we can't use the nicer `Config` API, but that is no worse than what we have today.;;;","21/Oct/15 22:26;ijuma;Pull request:

https://github.com/apache/kafka/pull/342;;;","22/Oct/15 08:11;junrao;Issue resolved by pull request 342
[https://github.com/apache/kafka/pull/342];;;","25/Oct/15 00:34;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/355

    KAFKA-2472; Fix capitalisation in SSL classes

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-2460-fix-capitalisation-in-ssl-classes

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/355.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #355
    
----
commit 9bbf8b701f13f0b4ea8df842b46cab29002033be
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2015-10-24T16:24:18Z

    Fix capitalisation in SSL classes

----
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Producer can send message out of order even when in flight request is set to 1.,KAFKA-3197,12936218,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,becket_qin,becket_qin,becket_qin,03/Feb/16 10:03,09/Mar/16 06:08,22/Mar/23 15:10,09/Mar/16 06:08,0.9.0.0,,,,,,0.10.0.0,,,,,,,clients,producer ,,,0,,,,,,"The issue we saw is following:

1. Producer send message 0 to topic-partition-0 on broker A. The in-flight request to broker A is 1.
2. The request is somehow lost
3. Producer refreshed its topic metadata and found leader of topic-partition-0 migrated from broker A to broker B.
4. Because there is no in-flight request to broker B. All the subsequent messages to topic-partition-0 in the record accumulator are sent to broker B.
5. Later on when the request in step (1) times out, message 0 will be retried and sent to broker B. At this point, all the later messages has already been sent, so we have re-order.",,becket_qin,bryan.deng,dana.powers,enothereska,fpj,githubbot,ijuma,jjkoshy,jkreps,miguno,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3223,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Mar 08 22:08:08 UTC 2016,,,,,,,,,,"0|i2sc47:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"03/Feb/16 17:13;githubbot;GitHub user becketqin opened a pull request:

    https://github.com/apache/kafka/pull/857

    KAFKA-3197 Fix producer sending records out of order

    This patch adds a new configuration to the producer to enforce the maximum in flight batch for each partition. The patch itself is small, but this is an interface change. Given this is a pretty important fix, may be we can run a quick KIP on it. 
    
    This patch did not remove max.in.flight.request.per.connection configuration because it might still have some value to throttle the number of requests sent to a broker. This is primarily for broker's interest.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/becketqin/kafka KAFKA-3197

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/857.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #857
    
----
commit c12c1e2044fe92954e0c8a27f63263f2020ddd3c
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2016-02-03T06:51:41Z

    KAFKA-3197 Fix producer sending records out of order

----
;;;","03/Feb/16 20:32;enothereska;[~becket_qin]: I don't think the documentation for max.in.flight.requests ever promised to send a message in order if in flight requests is set to 1. Reqs can be sent out of order if there are retries. Could the order goal be achieved without adding another parameter to the (already long) config file but by using a combination of in flight requests=1 and (retries=0 or acks=1)? Thanks.;;;","04/Feb/16 01:51;becket_qin;[~enothereska] The documentation of max.in.flight.request.per.connection did not say it explicitly, but I think followings are the guarantees we currently claim (or think) we are providing with different in.flight.request.per.connection and retries.

1. retries = 0, regardless of in.flight.request.per.connection
Producer itself does not introduce reordering in this case (all messages are only sent once), but message send will very likely fail immediately when event such as leader migration occurs. Users probably only have three choices when message failure occurs: a) let it go so the message is dropped; b) close producer if user do not tolerate message loss or re-ordering; c) resend the message and have re-ordering (this re-ordering is introduced by user)

2. in.flight.request.per.connection >1 and retries > 0 (some reasonable number)
No worry about frequent message send failure, but re-order could happen when there is retry.

3. in.flight.request.per.connection = 1 and retries > 0
No re-ordering and no frequent failure.

The bug here breaks the 3rd guarantee which we thought we are providing.
;;;","04/Feb/16 02:03;jjkoshy;[~enothereska] - the documentation is accurate in that it . The reality though is that everyone (or at least most users) interpret that to mean it is possible to achieve strict ordering within a partition which is necessary for several use-cases.
;;;","04/Feb/16 02:04;jjkoshy;Sorry - hit enter too soon. ""in that it does not specifically say that it can be used to prevent reordering within a partition"";;;","04/Feb/16 02:20;enothereska;[~jjkoshy], [~becket_qin] Makes sense. I can't help but think of the analogy to file systems. The only way to guarantee order is to do synchronous requests one at a time. Async requests can never guarantee order. I believe the current solution you are providing would work, but I wonder if it's worth taking a step back and simplifying the options (perhaps to just two: async ---with any number of requests outstanding --- and sync).;;;","04/Feb/16 07:59;becket_qin;[~enothereska] We have already defined sync and async in the producer at per message level when user call send(). Having another configuration is a little confusing. If the only purpose for send ""sync"" is to send messages in order, making it clear in the configuration seems reasonable.;;;","04/Feb/16 08:34;jkreps;Would it be better to treat this more as a bug than a configurable thing in the in-flight=1 case? i.e. when would i have in-flight=1 and not want the reordering protection? I agree people are depending on that now.

Slightly longer term I think we are actively picking up that idempotence/txn/semantics line of work and I think it is possible that whatever is done for idempotence might be the more principled solution as it could solve this problem even in the presence of pipelining. The idea here is that there is a sequence number per-partition which the server uses to dedupe, and this ensures that if one request fails all other pipelined requests on that partition also fail (and then retry idempotently) so that you don't reorder irrespective of the depth of the pipelining.;;;","04/Feb/16 09:23;becket_qin;Hey Jay,

Yes, idempotent producer would solve the problem. And I completely agree that when people set in flight request to one they are expecting no re-ordering. 

I was initially thinking of treating in.flight.request.per.connection=1 as in.flight.batch.per.partition=1 implicitly needed. This does not need additional configuration. But there is a subtle difference in terms of performance. If a producer has a lot partitions to send to the same broker, theoretically we can allow in flight request > 1 as long as each request addresses distinct partitions. If we enforce in.flight.request=1, we lose this parallelism. But given this is what already there, so it is probably fine to leave it as is.

I'll update the patch to remove the newly added configuration but simply reuse in.flight.request.per.connection. Otherwise please let me know if you think the subtle optimization worth the configuration change.;;;","05/Feb/16 00:55;fpj;Treating it as a bug sounds right. In the example given in the description, when the producer connects to broker B, shouldn't it resend unacknowledged messages (0 in the example) over the new connection (to broker B in the example)? It can produce duplicates as has been pointed out, but eliminating duplicates is a separate matter.;;;","05/Feb/16 00:58;ijuma;I was wondering the same thing [~fpj];;;","05/Feb/16 02:17;becket_qin;[~fpj] [~ijuma] That was my first thinking as well. After a second thought it might be a little bit complicated for the current implementation.

This approach needs the following works:
1. Detect leader movement on each metadata refresh.
2. If leader moves, that does not necessarily mean the request to old leader failed. We can always send the unacknowledged message to new leader, but that probably introduce duplicate almost every time leader moves.
3. Currently after batches leave the record accumulator, we only track them in requests. If leader migrates, now we need to peek into every in flight request, take out the batches to the partition whose leader moved, and re-enqueue them into record accumulator. This is even more intrusive because we store the batches in the ProduceResponseHandler which we don't even track today. 

Compared with current approach, the benefit of doing that seems we potentially don't need to wait for request timeout if a broker is actually down. However, given the metadata refresh itself is usually triggered by request timeout, this benefit becomes marginal. 

So while the idea of resend unacknowledged message to both old and new leader is natural and makes sense, it seems much more complicated and error prone based on our current implementation and does not buy us much.;;;","05/Feb/16 07:02;fpj;[~becket_qin] thanks for the clarification. 

bq. If leader moves, that does not necessarily mean the request to old leader failed. We can always send the unacknowledged message to new leader, but that probably introduce duplicate almost every time leader moves.

I agree that duplicates are inconvenient, but in this scenario we aren't promising no duplicates, so I'd rather treat the duplicates separately.

bq. Currently after batches leave the record accumulator, we only track them in requests.

The record accumulator point is a good one and I'm not super familiar with that part of the code, so I don't have any concrete suggestion right now, but I'll have a closer look. However, 

bq. So while the idea of resend unacknowledged message to both old and new leader is natural and makes sense, it seems much more complicated and error prone based on our current implementation and does not buy us much.

True, from your description, it sounds like the change isn't trivial. But let me ask you this: don't we ever have to retransmit messages after a leader change? If we do, then the code path for retransmitting on a different connection must be there. I'm not super familiar with that part of the code, so I don't have any concrete suggestion right now, but I can have a look to see if I'm able to help out.

;;;","05/Feb/16 07:21;becket_qin;Thanks [~fpj].

Currently the error handling and retry logic is in the response handler. We wait for a request to fail, reenqueue failed batches in that requests into accumulator and then resend. The part makes me feel uncomfortable is that we have to look into the in flight requests if we want to resend a potentially failed batch to new leader.;;;","06/Feb/16 03:18;ijuma;[~becket_qin], the plan is to release 0.9.0.1 next week and since the details of how to fix this are still being discussed, do you agree that we should target 0.9.1.0 instead?;;;","06/Feb/16 03:47;becket_qin;[~ijuma] Sure, we can target it 0.9.1.0. Last minute change is always unwanted.;;;","26/Feb/16 07:01;jjkoshy;Hi [~fpj] so your suggestion is to preemptively invoke the retransmission logic to retry the affected partitions? It can be done, but I think it would necessitate some weird APIs in {{InFlightRequests}} since as Becket notes, we would need to also proactively fish out partitions from {{InFlightRequests}} and retry those on the new leader.
I’m +1 on the patch apart from the minor comments, but will leave this open for a few more days in case anyone has further concerns or better ideas.;;;","02/Mar/16 01:42;ijuma;[~jjkoshy], since the patch doesn't introduce any new configuration and it's relatively simple I think it's fine to go with this approach for now. If we find a better way in the future, we can consider it then.;;;","09/Mar/16 06:07;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/857
;;;","09/Mar/16 06:08;jjkoshy;Pushed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Log cleaner exits if last cleaned offset is lower than earliest offset,KAFKA-1641,12742602,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,jjkoshy,jjkoshy,19/Sep/14 07:05,20/Sep/19 09:21,22/Mar/23 15:10,24/Oct/14 06:43,0.8.1.1,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Encountered this recently: the log cleaner exited a while ago (I think because the topic had compressed messages). That issue was subsequently addressed by having the producer only send uncompressed. However, on a subsequent restart of the broker we see this:

In this scenario I think it is reasonable to just emit a warning and have the cleaner round up its first dirty offset to the base offset of the first segment.

{code}
[kafka-server] [] [kafka-log-cleaner-thread-0], Error due to 
java.lang.IllegalArgumentException: requirement failed: Last clean offset is 54770438 but segment base offset is 382844024 for log testtopic-0.
        at scala.Predef$.require(Predef.scala:145)
        at kafka.log.Cleaner.buildOffsetMap(LogCleaner.scala:491)
        at kafka.log.Cleaner.clean(LogCleaner.scala:288)
        at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:202)
        at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:187)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)
{code}",,davispw,deniszh,guozhang,jjkoshy,jonbringhurst,kostassoid,sriharsha,yogeshyadav,yuanjiali,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Oct/14 06:21;guozhang;KAFKA-1641.patch;https://issues.apache.org/jira/secure/attachment/12673223/KAFKA-1641.patch","10/Oct/14 04:04;guozhang;KAFKA-1641_2014-10-09_13:04:15.patch;https://issues.apache.org/jira/secure/attachment/12673984/KAFKA-1641_2014-10-09_13%3A04%3A15.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Sep 20 01:21:02 UTC 2019,,,,,,,,,,"0|i208gv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"20/Sep/14 01:08;jonbringhurst;I'd just like to mention that a possible workaround (depending on your situation in regard to keys) is to stop the broker, remove the cleaner offset checkpoint, and then start the broker again for each ISR member in serial to get the thread running again. Keep in mind that the cleaner will start from the beginning if you do this.;;;","07/Oct/14 06:21;guozhang;Created reviewboard https://reviews.apache.org/r/26390/diff/
 against branch origin/trunk;;;","10/Oct/14 04:04;guozhang;Updated reviewboard https://reviews.apache.org/r/26390/diff/
 against branch origin/trunk;;;","24/Oct/14 01:27;guozhang;[~jjkoshy] Could you take another look?;;;","24/Oct/14 06:43;jjkoshy;Thanks for the patch.

Pushed to trunk (after fixing the log message issue I noted on the RB);;;","28/Oct/15 09:08;deniszh;We are hitting that bug again and again. Is it possible to apply it to current 0.8.x release ?
I can create PR on Github if allowed, for example.;;;","28/Oct/15 16:26;deniszh;Ah, according to Github and release plan 0.9.0 is planned for Nov 2015 and no releases planned for 0.8.x *sigh*
;;;","02/Dec/16 19:37;yuanjiali;We are hitting this problem in 0.10.0.0. Log as blow:
[2016-12-02 11:33:52,744] ERROR [kafka-log-cleaner-thread-0], Error due to  (kafka.log.LogCleaner)
java.lang.IllegalArgumentException: requirement failed: Last clean offset is 282330655505 but segment base offset is 0 for log __consumer_offsets-11.
        at scala.Predef$.require(Predef.scala:224)
        at kafka.log.Cleaner.buildOffsetMap(LogCleaner.scala:617)
        at kafka.log.Cleaner.clean(LogCleaner.scala:329)
        at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:237)
        at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:215)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2016-12-02 11:33:52,744] INFO [kafka-log-cleaner-thread-0], Stopped  (kafka.log.LogCleaner);;;","21/Jan/17 03:08;davispw;""Me too"" on 0.10.0.1 - does this issue need to be reopened?

	java.lang.IllegalArgumentException: requirement failed: Last clean offset is 43056300 but segment base offset is 42738384 for log -redacted- -0.
	at scala.Predef$.require(Predef.scala:224)
	at kafka.log.Cleaner.buildOffsetMap(LogCleaner.scala:604)
	at kafka.log.Cleaner.clean(LogCleaner.scala:329)
	at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:237)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:215)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
;;;","20/Sep/19 09:21;yogeshyadav;Same here we are hitting the same problem with 0.10.0 

java.lang.IllegalArgumentException: requirement failed: Last clean offset is 1 but segment base offset is 0 for log __consumer_offsets-2.

 at scala.Predef$.require(Predef.scala:224)

 at kafka.log.Cleaner.buildOffsetMap(LogCleaner.scala:617)

 at kafka.log.Cleaner.clean(LogCleaner.scala:329)

 at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:237)

 at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:215)

 at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)

 

Is there a workaround for this problem without upgrading to higher versions?

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unmap before resizing,KAFKA-1008,12663349,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,lizziew,lizziew,13/Aug/13 12:28,16/Oct/13 06:58,22/Mar/23 15:10,16/Oct/13 06:58,0.8.0,,,,,,0.8.0,,,,,,,core,log,,,2,patch,,,,,"While I was studying how MappedByteBuffer works, I saw a sharing runtime exception on Windows. I applied what I learned to generate a patch which uses an internal open JDK API to solve this problem.

Following Jay's advice, I made a helper method called tryUnmap(). 
","Windows, Linux, Mac OS",davidlao,dennyglee,guozhang,jkreps,junrao,lizziew,nehanarkhede,sriramsub,tnachen,trjianjianjiao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,KAFKA-1065,,,,,,,,,,,,,,,,"29/Aug/13 08:23;jkreps;KAFKA-0.8-1008-v7.patch;https://issues.apache.org/jira/secure/attachment/12600516/KAFKA-0.8-1008-v7.patch","21/Sep/13 06:05;jkreps;KAFKA-0.8-1008-v8.patch;https://issues.apache.org/jira/secure/attachment/12604322/KAFKA-0.8-1008-v8.patch","22/Aug/13 04:21;jkreps;KAFKA-1008-v6.patch;https://issues.apache.org/jira/secure/attachment/12599263/KAFKA-1008-v6.patch","10/Oct/13 08:02;jkreps;KAFKA-1008-v9-trunk.patch;https://issues.apache.org/jira/secure/attachment/12607697/KAFKA-1008-v9-trunk.patch","23/Aug/13 16:13;lizziew;KAFKA-trunk-1008-v7.patch;https://issues.apache.org/jira/secure/attachment/12599592/KAFKA-trunk-1008-v7.patch","17/Aug/13 13:38;lizziew;unmap-v5.patch;https://issues.apache.org/jira/secure/attachment/12598572/unmap-v5.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,343350,,,Tue Oct 15 22:58:46 UTC 2013,,,,,,,,,,"0|i1n7nr:",343654,,,,,,,,,,,,,,,,,,,,"13/Aug/13 12:57;lizziew;Patch file;;;","13/Aug/13 13:18;guozhang;Will this patch restrict to Sun JVM-only environments?;;;","13/Aug/13 13:26;lizziew;For non Sun JVM environments, tryUnmap is no-op for now; we can add support for other JVM environments later on.;;;","13/Aug/13 23:36;jkreps;Hey Elizabeth, thanks for the patch!

Three follow-up items for us to take this:
1. If we refer to sun.nio.ch.DirectBuffer that introduces a build-time dependency on Sun java. I think that is probably okay. But what is the behavior of tryUnmap on a non-sun jvm at runtime (or if sun ever changes their implementation)? My suspicion is that we would get a ClassNotFoundException for sun.nio.ch.DirectBuffer right? I think we would be better off wrapping everything inside tryUnmap inside a try/catch and trace logging if there is an exception.
2. It looks like you added back in a call to flush which we removed as part of another patch. Probably accidental, right?
3. I would like to understand the security issue on the Sun ticket for unmap here: http://bugs.sun.com/view_bug.do?bug_id=4724038 If we don't understand what the concern is then there is a possibility we are introducing a security problem (though I don't think so...).;;;","14/Aug/13 09:02;lizziew;Thanks for the feedback!

1 - Currently tryUnmap does a type checking. If the super class of ""m"" is changed in the future, the type check will be false, and there will be no casting errors like ClassNotFoundException at runtime. 

2 - I removed the flush(). I probably used an older copy a couple of weeks ago.

3 - Reading through the bug report, I'm not sure if the cases matter in terms of Kafka - I think all the threads in a Kafka process should be trusted and the race condition between the unmap/remap shouldn't happen if coded properly. I noticed that in the most recent version, the resize method is synchronized, which should prevent multiple threads trying to resize/unmap the files. ;;;","14/Aug/13 12:02;jkreps;Hey Elizabeth, thanks for the patch.

Two issues.

The first is that I think that instanceof check will actually throw an exception on a non-sun jvm. See the experiment below and see what you think.

The second issue is actually a more subtle thing. Currently the synchronization is really just for changes to the buffer, the read-access are lock-free (which is good). My concern is what happens if we force clean a buffer while a read is occurring? Not sure if this can happen or not, but I think we need to somehow be sure it can't.

Here was my test:
$ cat /tmp/code/Test.java 
import test.MyTest;

public class Test {
    public static void main(String[] args) {
	Object o = new Object();
	    if(o instanceof MyTest)
		System.out.println(""Hello"");
    }
}

$ cat /tmp/code/test/MyTest.java 
package test;

public class MyTest {
  
}

I do 
javac /tmp/code/test/MyTest.java
javac -cp /tmp/code /tmp/code/Test.java
rm /tmp/code/test/MyTest.class
$ java -cp /tmp/code Test
Exception in thread ""main"" java.lang.NoClassDefFoundError: test/MyTest
	at Test.main(Test.java:6)
Caused by: java.lang.ClassNotFoundException: test.MyTest
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
	... 1 more

We also can't really be too sure what kind of exceptions clean() might throw.

;;;","15/Aug/13 01:38;lizziew;Thanks, I added the try/catch to handle the exceptions.

I found the following coding pattern 
val idx = mmap.duplicate
in this file. It seems like it always makes a copy of the buffer for ""read"". 

;;;","15/Aug/13 10:38;jkreps;But my understanding is that these copies are just copies of pointer object (i.e. a position, limit, mark, etc) so if you unmap the underlying mmap while reads are occurring something bad will happen.

Another way to say this is what happens in the following code execution:
MappedByteBuffer orig = // map file
MappedByteBuffer copy = orig.duplicate()
(orig.asInstanceOf[sun.nio.ch.DirectBuffer]).cleaner().clean()
copy.get()

My suspicion is that something terrible will happen, but I could be wrong.;;;","15/Aug/13 14:19;lizziew;That's right, the duplicate is a shallow copy of the buffer. Do you have a case where the buffer is being used while resizing? I did a quick grep, and it looks like resize is only being used during logfile loading or truncation.;;;","15/Aug/13 23:00;jkreps;Yeah, the problem is reads continue while the log is being rolled.

Here are a bunch of possible solutions I can think of
1. Lock reads
2. Delay the truncate until the larger mmap is collected

For (2) the problem is that it actually interferes with the recoverability of the log. If we have old log segments with a bunch of unfilled bytes in their index segment we need to recover those segments. But currently we only recover from the last flush point.

So I think we need to lock read access. This isn't the end of the world but I would prefer to do this only on windows. My suggestion on implementation would be
1. Change from synchronized in OffsetIndex to Lock
2. Add an object called Os in kafka.utils that is something like

object Os {
  private val osName = System.getProperty(""os.name"").toLowerCase
  val isWindows = osName.startsWith(""windows"")
}

We can expand this later if we need more specific OS detection capabilities or other OS-specific functionality.

Then elsewhere we can just do
  if(Os.isWindows) lock.lock()
and the corresponding unlock.

Does that seem like it would work?


;;;","15/Aug/13 23:01;jkreps;Here is a list of os.name values (at least according to this random page):
http://www.javaneverdie.com/java/java-os-name-property-values/;;;","16/Aug/13 13:26;lizziew;Sounds like a good idea to have lock reads. Do you want to file a separate JIRA to address the lock read issue? ;;;","17/Aug/13 01:02;jkreps;I think it makes sense to do it as part of this patch since unmapping is the reason we need it and without it we will core dump the process under concurrency (so I don't think we can take the resizing change without the locking change). Sound reasonable?

If we have the Os.isWindows check I think we can make BOTH the locking and the forced mmap clenaing all be inside the isWindows check. Thisshould fix things on windows and not functionally change perf at all on linux (which is good).;;;","17/Aug/13 13:39;lizziew;Thanks Jay!
Please review the patch to see if it reflects your suggestion. I'm still learning Scala, so please provide any feedback!;;;","22/Aug/13 02:53;tnachen;I wonder if this patch can go in soon? It's a major blocker for anyone that wants to use Kafka on windows;;;","22/Aug/13 04:21;jkreps;Hey Elizabeth, this basically looks good. A couple of minor things.

One is I'm not sure we are covering everything that needs to be locked. The next is that we are using synchronized with the lock instance which doesn't actually call lock (as in java that just acquires the monitor associated with the lock argument--sucky right?).

I took a stab at reworking it. To make things not get too crazy I added a helper method inLock which makes the try/finally locking pattern a little more readable (hopefully).

Would you be willing to take a detailed look at this and let me know if you think this works.

The next thing we need to do is actually get this tested on Windows. I'm not sure if there is anyone who has access to a Windows machine and could reproduce the old problem who could verify that this patch fixes it?;;;","22/Aug/13 05:28;lizziew;The code change looks good. Using a higher order function makes the code look a lot cleaner! 

;;;","23/Aug/13 09:57;davidlao;Hi Jay,
The patch does not seem to apply cleanly on the 0.8 branch (see below). Can you look into generating a new patch for 0.8? 

git apply --check KAFKA-1008-v6.patch
error: patch failed: core/src/main/scala/kafka/log/OffsetIndex.scala:52
error: core/src/main/scala/kafka/log/OffsetIndex.scala: patch does not apply
error: patch failed: core/src/main/scala/kafka/utils/Utils.scala:21
error: core/src/main/scala/kafka/utils/Utils.scala: patch does not apply
error: patch failed: core/src/test/scala/unit/kafka/utils/UtilsTest.scala:18
error: core/src/test/scala/unit/kafka/utils/UtilsTest.scala: patch does not apply
;;;","23/Aug/13 16:17;lizziew;I generated a patch against the trunk to fix some of the issues in Jay's patch. Please check if it works! ;;;","27/Aug/13 05:16;davidlao;Hi Jay,
The master branch seems to be broken on Windows. Can you look into this? or produce a patch for 0.8? 

[2013-08-26 14:09:41,761] FATAL [Replica Manager on Broker 3]: Error writing to highwatermark file:  (kafka.server.ReplicaManager)
java.io.IOException: File rename from c:\Apps\logs\broker-3\replication-offset-checkpoint.tmp to c:\Apps\logs\broker-3\replication-offset-checkpoint failed.
        at kafka.server.OffsetCheckpoint.liftedTree1$1(OffsetCheckpoint.scala:61)
        at kafka.server.OffsetCheckpoint.write(OffsetCheckpoint.scala:39)
        at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:312)
        at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:309)
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:119)
        at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:309)
        at kafka.server.ReplicaManager$$anonfun$startHighWaterMarksCheckPointThread$1.apply$mcV$sp(ReplicaManager.scala:92)
        at kafka.utils.KafkaScheduler$$anon$1.run(KafkaScheduler.scala:100)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:722)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:722)
;;;","29/Aug/13 08:23;jkreps;Attached a version rebased to 0.8.;;;","29/Aug/13 13:16;sriramsub;Looks good.

1. OffsetIndex.scala

1.1 Why do you need to re-calculate this.maxEntries = this.mmap.limit / 8 after remapping in resize instead of leaving it how it was previously (recalculated during the method call of maxEntries)?
1.2 maybeLock should be something that exist outside OffsetIndex. Seems like OS specific methods should reside together.
1.3 readLastOffset now locks. This is a behavior change on linux. This seems to only do a read so does it need to be ""maybeLock""?

2. Should we use the autolock for the cases below

TestUtils.scala

method - waitUntilLeaderIsElectedOrChanged

HighWaterCheckpoint.scala

method - write and read  

3. Is autolock a better name than inlock?;;;","30/Aug/13 09:30;davidlao;Thanks Jay. The 0.8 patch seems to be working on Windows. Please check it in.;;;","13/Sep/13 00:20;junrao;Thanks for the patch. Reviewed patch v7 for 0.8. Looks good overall. Just a couple of minor comments.

70. OffsetIndex: Should forceUnmap() be private?

71. Just a question. Does anyone know if the OS property shows up as windows on cygwin?

Sriram,

For 1.1, the purpose is probably to save the division calculation, which is a bit expensive.;;;","20/Sep/13 07:22;nehanarkhede;ping [~lizziew], [~jkreps]. Could you address Jun's review comments and see if we can resolve this JIRA? This is marked for the 0.8 final release;;;","21/Sep/13 06:17;jkreps;Sriram:
1.1 This is because this.mmap can be null so you have to either acquire the lock. To avoid this I just make the max size a separate variable.
1.2 It's actually only really useful in this class because the fact that we want to lock only on windows is very specific to the logic of this class.
1.3 Yeah this is technically not necessary since this method is only used during initialization but I try never to have the correctness of methods depend on when they are used.

2. Added a lock for the leader election test cases. I am skipping the other usage because that file was heavily refactored in trunk and that lock removed (I think).

3. I intend 
      inLock\(x\) {
        foo
      }
to be read as ""in lock x do foo"". So I like it since it is declarative.;;;","21/Sep/13 06:18;jkreps;Jun, added private on that method. Not sure about cygwin.;;;","21/Sep/13 06:24;sriramsub;+1;;;","23/Sep/13 09:55;lizziew;Sorry - I am not as active on this at the moment. I am back at Exeter to start my junior year. I just did a quick test on my friend's computer:
System.out.println(System.getProperty(""os.name""));   
prints out ""Windows 7"" for both Windows cmd shell and cygwin/bash. 

This makes sense since cygwin is mainly a shell. ;;;","23/Sep/13 23:18;junrao;Thanks for patch v8. Just one more comment.

80. OffsetIndex: The patch synchronizes in readLastOffset(), is that necessary?;;;","24/Sep/13 00:18;jkreps;Sriram had the same comment. It is possible to reason that the existing ways the method is used don't need synchronization but I don't think the method is thread safe since it depends on both size and mmap both of which can change (so e.g. mmap could be null and a truncate call could theoretically interleave with this call). I don't think it is very safe to have methods whose correctness depends on the existing call pattern. The synchronization doesn't hurt, in any case since this is not in any critical read or write path.;;;","24/Sep/13 00:32;junrao;Sorry, I missed that comment. +1 on v8.;;;","10/Oct/13 08:02;jkreps;Attached KAFKA-1008-v9-trunk.patch which ports the final 0.8 patch to trunk and also adds a fix for the windows compatibility issue in KAFKA-1036 in OffsetCheckpoint.scala.;;;","10/Oct/13 12:12;junrao;Thanks for the patch for trunk. +1.;;;","16/Oct/13 06:58;jkreps;Checked in on 0.8 and trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Controlled shutdown never succeeds until the broker is killed,KAFKA-999,12661600,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,swapnilghike,nehanarkhede,nehanarkhede,04/Aug/13 23:35,07/Aug/13 11:42,22/Mar/23 15:10,07/Aug/13 11:42,0.8.0,,,,,,,,,,,,,controller,,,,0,,,,,,"A race condition in the way leader and isr request is handled by the broker and controlled shutdown can lead to a situation where controlled shutdown can never succeed and the only way to bounce the broker is to kill it.

The root cause is that broker uses a smart to avoid fetching from a leader that is not alive according to the controller. This leads to the broker aborting a become follower request. And in cases where replication factor is 2, the leader can never be transferred to a follower since it keeps rejecting the become follower request and stays out of the ISR. This causes controlled shutdown to fail forever

One sequence of events that led to this bug is as follows -

- Broker 2 is leader and controller
- Broker 2 is bounced (uncontrolled shutdown)
- Controller fails over
- Controlled shutdown is invoked on broker 1
- Controller starts leader election for partitions that broker 2 led
- Controller sends become follower request with leader as broker 1 to broker 2. At the same time, it does not include broker 1 in alive broker list sent as part of leader and isr request
- Broker 2 rejects leaderAndIsr request since leader is not in the list of alive brokers
- Broker 1 fails to transfer leadership to broker 2 since broker 2 is not in ISR
- Controlled shutdown can never succeed on broker 1

Since controlled shutdown is a config option, if there are bugs in controlled shutdown, there is no option but to kill the broker",,nehanarkhede,sriramsub,swapnilghike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Aug/13 05:35;swapnilghike;kafka-999-v1.patch;https://issues.apache.org/jira/secure/attachment/12596431/kafka-999-v1.patch","07/Aug/13 07:25;swapnilghike;kafka-999-v2.patch;https://issues.apache.org/jira/secure/attachment/12596451/kafka-999-v2.patch","07/Aug/13 08:02;swapnilghike;kafka-999-v3.patch;https://issues.apache.org/jira/secure/attachment/12596460/kafka-999-v3.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,341789,,,Wed Aug 07 03:42:38 UTC 2013,,,,,,,,,,"0|i1my1z:",342095,,,,,,,,,,,,,,,,,,,,"06/Aug/13 03:45;nehanarkhede;I think the fix is to remove the smart in the broker's handling of a become follower request. Even if the leader is not alive, it should depend on the controller to send it another LeaderAndIsrRequest to connect to some other leader or to become a leader itself.;;;","06/Aug/13 03:48;sriramsub;+1 on the proposed fix. Also this could happen only if the retry attempt is infinite.;;;","06/Aug/13 09:16;swapnilghike;I think the right fix would be to undo any changes made to controllerContext during shutdownBroker() if the shutdown attempt failed on the controller. If the shutdown attempt failed, the controller's state should be equivalent to the state it would be in if the shutdown attempt was never made.

In this case, it would mean removing broker 1 which is being shut down from controllerContext.shuttingDownBrokerIds set if a shutdown attempt failed. Thus, when the controller is sending out leaderAndIsr requests after broker 2 comes up, it will include broker 1 in the alive brokers.

As far as dumbing down the broker is concerned to make it accept whatever controller says, I don't have a strong feeling. As Neha described, it will also resolve this ticket. However, doing only that and not fixing KafkaController.shutdownBroker() will hide an underlying bug - the controller had sent prematurely optimized information to broker 2 (the broker 1 was not dead, but the controller thought it will soon be dead, so why include it in alive leaders anyways).

I also think it's ok for the broker to be a bit intelligent. As such, become-follower operation starts a thread that fetches from the leader. This fetching is a peer-to-peer action, so I don't see anything wrong with a broker being able to decide whether it wants to fetch or not.

What do you think?
;;;","06/Aug/13 11:02;nehanarkhede;Sriram, Ack you are right. Forgot to mention that caveat in the bug description.

Swapnil,

The problem with undoing changes to controllerContext and removing the broker if the controlled shutdown request failed, is that there is a risk of mistakenly moving leaders to that broker. The reason is because even if the controlled shutdown attempt failed, it goes ahead with an uncontrolled shutdown. In that case, there is no value to letting it become a leader for more partitions since the point of controlled shutdown is to move existing leaders off.

Split brain is always a problem that is both dangerous and causes unnecessary failures (e.g. consumer rebalancing). The purpose of a controller in Kafka is to be the only brain in the cluster and make state change decisions based on a single global view of the system. In this case, even if we keep the extra check on the broker, the leader can fail immediately after the if statement succeeds. So that check doesn't help anyways (Jun had pointed that out to me in the past, but I wasn't convinced back then :) ). Also, even if the leader fails, the broker should depend on the controller to do the right thing and send another leader and isr request with a new leader. That way any changes to the controller logic (new features like controlled shutdown) will not cause unexpected side effects such as this bug.;;;","06/Aug/13 12:35;swapnilghike;I see your points. After thinking a bit about the controlled shutdown --> uncontrolled shutdown scenario, your comments make sense.

However controller passing live brokers minus shutting down brokers as live leaders in the LeaderAndIsrRequest sounds like a premature optimization and a bug. The check on the broker to not check live leaders will allow the broker to circumvent it.

But, the good news is that after we make the fix you proposed for broker's handling of LeaderAndIsrRequest, LeaderAndIsrRequest does not need to contain aliveLeaders. :) So deleting that field automatically solves my concern. ;;;","06/Aug/13 12:43;nehanarkhede;>> However controller passing live brokers minus shutting down brokers as live leaders in the LeaderAndIsrRequest sounds like a premature optimization and a bug

Well, the field is not required only after this JIRA is fixed, but there is no bug in the field. Like I explained above, live leaders cannot include the broker being shut down, so the controller passes accurate information to the broker. The bug is in the way the broker uses that field.

Deleting the field in the future is a good idea. However, it is a change in wire protocol, so I suggest we file that JIRA and handle that part on trunk.;;;","06/Aug/13 12:55;swapnilghike;Perhaps the word live misled me. Thanks for the clarifications, filed KAFKA-1002 to delete the field.;;;","06/Aug/13 14:46;swapnilghike;Since we need leader broker's host:port to create ReplicaFetcherThread, the easiest fix for this ticket's purpose seems to be to pass all leaders through LeaderAndIsrRequest:

val leaders = liveOrShuttingDownBrokers.filter(b => leaderIds.contains(b.id))
val leaderAndIsrRequest = new LeaderAndIsrRequest(partitionStateInfos, leaders, controllerId, controllerEpoch, correlationId, clientId)

Any suggestions on avoiding a wire protocol change?;;;","07/Aug/13 05:34;swapnilghike;Small-scale fix for 0.8. ;;;","07/Aug/13 07:15;nehanarkhede;Thanks for the patch Swapnil. Overall, well thought through. Few minor comments -

1. ControllerChannelManager

leaderIds is not used anymore

2. LeaderAndIsrRequest

The field actually means all the brokers in the cluster. So can we rename it from leaders to allBrokers?
Same for Partition.scala and ReplicaManager.scala;;;","07/Aug/13 07:25;swapnilghike;Thanks for pointing that out. Actually in ControllerChannelManager, we should rather pass liveOrShuttingDownBroker.filter(b => leaderIds.contains(b.id)) as the leaders to LeaderAndIsrRequest.

Attached patch v2.;;;","07/Aug/13 07:28;swapnilghike;Renamed to leaders at one another place.;;;","07/Aug/13 11:41;nehanarkhede;+1 on v3. ;;;","07/Aug/13 11:42;nehanarkhede;Committed v3 to 0.8;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LeaderNotAvailableException the first time a new message for a partition is processed.,KAFKA-899,12646751,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,jbrosenberg,jbrosenberg,09/May/13 13:18,02/Oct/14 07:01,22/Mar/23 15:10,31/May/13 13:18,0.8.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"I'm porting some unit tests from 0.7.2 to 0.8.0.  The test does the following, all embedded in the same java process:

-- spins up a zk instance
-- spins up a kafka server using a fresh log directory
-- creates a producer and sends a message
-- creates a high-level consumer and verifies that it can consume the message
-- shuts down the consumer
-- stops the kafka server
-- stops zk

The test seems to be working fine now, however, I consistently see the following exceptions (which from poking around the mailing list seem to be expected?).  If these are expected, can we suppress the logging of these exceptions, since it clutters the output of tests, and presumably, clutters the logs of the running server/consumers, during clean startup and shutdown......

When I call producer.send(), I get:

1071 [main] WARN kafka.producer.BrokerPartitionInfo  - Error while fetching metadata 	partition 0	leader: none	replicas: 	isr: 	isUnderReplicated: false for topic partition [test-topic,0]: [class kafka.common.LeaderNotAvailableException]
1081 [main] WARN kafka.producer.async.DefaultEventHandler  - Failed to collate messages by topic,partition due to
kafka.common.LeaderNotAvailableException: No leader for any partition
	at kafka.producer.async.DefaultEventHandler.kafka$producer$async$DefaultEventHandler$$getPartition(DefaultEventHandler.scala:212)
	at kafka.producer.async.DefaultEventHandler$$anonfun$partitionAndCollate$1.apply(DefaultEventHandler.scala:150)
	at kafka.producer.async.DefaultEventHandler$$anonfun$partitionAndCollate$1.apply(DefaultEventHandler.scala:148)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
	at kafka.producer.async.DefaultEventHandler.partitionAndCollate(DefaultEventHandler.scala:148)
	at kafka.producer.async.DefaultEventHandler.dispatchSerializedData(DefaultEventHandler.scala:94)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:72)
	at kafka.producer.Producer.send(Producer.scala:74)
	at kafka.javaapi.producer.Producer.send(Producer.scala:32)
	at com.squareup.kafka.server.KafkaServerTest.produceAndConsumeMessage(KafkaServerTest.java:98)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:69)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:48)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:292)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:77)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:195)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:63)
1133 [kafka-request-handler-1] WARN kafka.server.HighwaterMarkCheckpoint  - No highwatermark file is found. Returning 0 as the highwatermark for partition [test-topic,0]
	...
        ...

It would be great if instead of this exception, it would just log a meaningful message, like:

""No leader was available for partition X, one will now be created""

Jason",,Andras Hatvani,jbrosenberg,jbrosenberg@gmail.com,joshrosen,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/May/13 06:40;junrao;kafka-899.patch;https://issues.apache.org/jira/secure/attachment/12582535/kafka-899.patch","30/May/13 00:19;junrao;kafka-899_v2.patch;https://issues.apache.org/jira/secure/attachment/12585236/kafka-899_v2.patch","30/May/13 09:21;junrao;kafka-899_v3.patch;https://issues.apache.org/jira/secure/attachment/12585349/kafka-899_v3.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,327109,,,Wed Oct 01 23:01:39 UTC 2014,,,,,,,,,,"0|i1kftz:",327453,,,,,,,,,,,,,,,,,,,,"10/May/13 06:40;junrao;Attach a patch. Jason, could you give it a try?;;;","30/May/13 00:19;junrao;Attach patch v2 after the rebase.;;;","30/May/13 00:35;nehanarkhede;Thanks for the patch!

1. Another place where we can make it easier for the user to know the reason for the send failure -

            error(""Produce request with correlation id %d failed due to response %s. List of failed topic partitions is %s""
              .format(currentCorrelationId, response.toString, failedTopicPartitions.mkString("","")))

Here, we print the entire response. Rather we should only print the partition and corresponding error status for partitions with non-zero error code

2. When we do print the error status above, we should print the text name of the error instead of the integer error code. For this, we can override toString() in ProducerResponseStatus.;;;","30/May/13 09:21;junrao;Thanks for the review. Attach patch v3 that addresses the above issue. Changed the logging level from error to warning since the real error will be reported when all retries have failed.;;;","31/May/13 06:51;nehanarkhede;+1 on the latest patch;;;","31/May/13 13:18;junrao;Thanks for the review. Committed to 0.8 after fixing a bug and a typo.;;;","28/Sep/14 00:09;Andras Hatvani;This isn't fixed in 0.8.1.1 as the behavior is the same.

As a workaround increase retry.backoff.ms from the default 100 ms to 1000 ms.
In case this would be not enough for you, you can try to change the values of 
- message.send.max.retries from the default 5 to e.g. 10 and
- topic.metadata.refresh.interval.ms to 0.

This is the expected behavior, therefore an exception mustn't be thrown, rather it has to be communicated that the leader election is in progress. Furthermore, suggestions regarding changing the values variables I mentioned should be mandatory.;;;","29/Sep/14 06:08;junrao;This fix actually wasn't included in 0.8.1. Changed the fix version in the jira.;;;","29/Sep/14 22:12;Andras Hatvani;Jun, can I do any support regarding this issue (e.g. verify the implementation)?;;;","30/Sep/14 00:08;junrao;Andras,

It seems that your issue is a bit different from this jira. This jira is about removing the stacktrace in the producer log when the metadata is not available. Your issue seems to be that the metadata is not propagated as quickly as you expect. Normally, 100ms should be long enough for a new topic to be created and its metadata be propagated to all brokers. In your case, it seems that process takes more than 1 sec. Could you look at the controller and the state-change log to see where the delay is? For example, is the write to ZK slow or is the propagation of metadata from the controller to the broker slow?;;;","30/Sep/14 01:11;Andras Hatvani;Jun,

Although the reasons may be different, the objective is identical (see my last post in the thread ""LeaderNotAvailableException, although leader elected"" on the Kafka user mailing list): There shouldn't be any exception in case no leader can be communicated to the producer (whether it's because metadata propagation delay or non-completed leader election or any other valid non-erroneous cause), but rather a status message enabling the producer to be tuned.
This exception should really only cover exceptional cases. 

But you're right, my case will exactly be covered by KAFKA-1494. I'll provide further data in that issue.;;;","30/Sep/14 02:16;junrao;Andras,

If a message couldn't be sent (after all retries), we need to indicate this to the producer client. We currently do that by throwing an exception back to the caller. The caller can decide what to do. Are you suggesting sth else?;;;","30/Sep/14 04:29;Andras Hatvani;Jun,

Yes, I suggest a classification of the server's response so that the client can distinguish between technical failures (e.g. network unavailable) and functional state (e.g. leader election for partition in progress). For example, a topic's state could be: non-existent, being created, existent, leader election in progress, failed (and in this case the reason of the failure, like no disk-space). 
Furthermore, in case of topic auto-creation I'd separate and communicate the fact of creation from the message sending and handle the results and failures separately, too.
Returning a value instead of void would support both mechanisms. What do you think?;;;","02/Oct/14 07:01;junrao;We started doing that classification in the new java producer. For example, there are certain exceptions are of RetriableException. Transient failures like leader not available are in that category. Exceptions like MessageTooLarge are in a different category. Perhaps you can take a look at that in the new producer and see if that makes sense.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replication offset checkpoints (high water marks) can be lost on hard kills and restarts,KAFKA-1647,12743558,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,becket_qin,jjkoshy,jjkoshy,24/Sep/14 01:35,31/Oct/14 07:33,22/Mar/23 15:10,31/Oct/14 07:33,0.8.2.0,,,,,,0.8.2.0,,,,,,,,,,,0,newbie++,,,,,"We ran into this scenario recently in a production environment. This can happen when enough brokers in a cluster are taken down. i.e., a rolling bounce done properly should not cause this issue. It can occur if all replicas for any partition are taken down.

Here is a sample scenario:

* Cluster of three brokers: b0, b1, b2
* Two partitions (of some topic) with replication factor two: p0, p1
* Initial state:
p0: leader = b0, ISR = {b0, b1}
p1: leader = b1, ISR = {b0, b1}
* Do a parallel hard-kill of all brokers
* Bring up b2, so it is the new controller
* b2 initializes its controller context and populates its leader/ISR cache (i.e., controllerContext.partitionLeadershipInfo) from zookeeper. The last known leaders are b0 (for p0) and b1 (for p2)
* Bring up b1
* The controller's onBrokerStartup procedure initiates a replica state change for all replicas on b1 to become online. As part of this replica state change it gets the last known leader and ISR and sends a LeaderAndIsrRequest to b1 (for p1 and p2). This LeaderAndIsr request contains: {{p0: leader=b0; p1: leader=b1;} leaders=b1}. b0 is indicated as the leader of p0 but it is not included in the leaders field because b0 is down.
* On receiving the LeaderAndIsrRequest, b1's replica manager will successfully make itself (b1) the leader for p1 (and create the local replica object corresponding to p1). It will however abort the become follower transition for p0 because the designated leader b0 is offline. So it will not create the local replica object for p0.
* It will then start the high water mark checkpoint thread. Since only p1 has a local replica object, only p1's high water mark will be checkpointed to disk. p0's previously written checkpoint  if any will be lost.

So in summary it seems we should always create the local replica object even if the online transition does not happen.

Possible symptoms of the above bug could be one or more of the following (we saw 2 and 3):
# Data loss; yes on a hard-kill data loss is expected, but this can actually cause loss of nearly all data if the broker becomes follower, truncates, and soon after happens to become leader.
# High IO on brokers that lose their high water mark then subsequently (on a successful become follower transition) truncate their log to zero and start catching up from the beginning.
# If the offsets topic is affected, then offsets can get reset. This is because during an offset load we don't read past the high water mark. So if a water mark is missing then we don't load anything (even if the offsets are there in the log).
",,becket_qin,gw4722,jjkoshy,junrao,nehanarkhede,noslowerdna,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Oct/14 01:06;becket_qin;KAFKA-1647.patch;https://issues.apache.org/jira/secure/attachment/12673125/KAFKA-1647.patch","14/Oct/14 07:38;becket_qin;KAFKA-1647_2014-10-13_16:38:39.patch;https://issues.apache.org/jira/secure/attachment/12674645/KAFKA-1647_2014-10-13_16%3A38%3A39.patch","18/Oct/14 15:26;becket_qin;KAFKA-1647_2014-10-18_00:26:51.patch;https://issues.apache.org/jira/secure/attachment/12675659/KAFKA-1647_2014-10-18_00%3A26%3A51.patch","22/Oct/14 14:08;becket_qin;KAFKA-1647_2014-10-21_23:08:43.patch;https://issues.apache.org/jira/secure/attachment/12676274/KAFKA-1647_2014-10-21_23%3A08%3A43.patch","28/Oct/14 08:19;becket_qin;KAFKA-1647_2014-10-27_17:19:07.patch;https://issues.apache.org/jira/secure/attachment/12677471/KAFKA-1647_2014-10-27_17%3A19%3A07.patch","31/Oct/14 06:07;becket_qin;KAFKA-1647_2014-10-30_15:07:09.patch;https://issues.apache.org/jira/secure/attachment/12678325/KAFKA-1647_2014-10-30_15%3A07%3A09.patch","31/Oct/14 06:10;becket_qin;KAFKA-1647_2014-10-30_15:10:22.patch;https://issues.apache.org/jira/secure/attachment/12678327/KAFKA-1647_2014-10-30_15%3A10%3A22.patch","31/Oct/14 06:38;becket_qin;KAFKA-1647_2014-10-30_15:38:02.patch;https://issues.apache.org/jira/secure/attachment/12678335/KAFKA-1647_2014-10-30_15%3A38%3A02.patch","31/Oct/14 06:50;becket_qin;KAFKA-1647_2014-10-30_15:50:33.patch;https://issues.apache.org/jira/secure/attachment/12678337/KAFKA-1647_2014-10-30_15%3A50%3A33.patch",,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Oct 30 23:33:33 UTC 2014,,,,,,,,,,"0|i20een:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"26/Sep/14 04:57;nehanarkhede;[~jjkoshy] Sounds like a problem. I have a question about something that I don't quite understand. 
bq. On receiving the LeaderAndIsrRequest, b1's replica manager will successfully make b2 the leader for p1 (and create the local replica object corresponding to p1). It will however abort the become follower transition for p0 because the designated leader b2 is offline. So it will not create the local replica object for p0.

- Did you mean ""b1's replica manager will successfully make b1 the leader for p1""?
- I'm not sure why b1 ends up truncating all it's data for p0 even if it ends up aborting it's become follower transition? I see how the highwatermark checkpoint ends up removing p0's checkpoint, but not how b1 ends up deleting all it's data for p0.;;;","26/Sep/14 05:25;jjkoshy;If b1 aborts the follower transition the high watermark checkpoint can be removed. It does not truncate all the data at that point. However, on a subsequent become-follower transition (if any and if successful) it will truncate the log (since on unknown HW we take HW as zero).

This shouldn't be too difficult to fix though.;;;","26/Sep/14 11:56;nehanarkhede;I see. So for this to lose all the data for the concerned partition, b1 has to be bounced to become a follower again and at that time b0 should be up for the become follower to succeed. Right? It is a pretty corner case, but should be fixed. ;;;","26/Sep/14 13:33;jjkoshy;Yes that is one possibility but not the only one. For example, suppose this is a topic with replication factor three. This is typically when bringing up a cluster that was previously hard-killed. Suppose b1 and b2 are brought up simultaneously and lose their HW as described above. Suppose the controller then elects b1 as the leader. b2 then becomes the follower (successfully) but as part of that transition will truncate to zero. I think there should be more scenarios since I also saw this with a topic with replication factor of two but have not checked the logs yet to see if it was due to a subsequent bounce or something else.;;;","27/Sep/14 05:32;nehanarkhede;[~jjkoshy] Makes sense, thanks for the explanation! I guess the behavior of the follower dropping the partition out of the highwatermark checkpoint due to an aborted follower transition, needs to be fixed.;;;","29/Sep/14 05:45;junrao;Joel,

Is this because in ReplicaManger.makeFollowers(), we skip partition.makeFollower() if the leader is not alive? If so, we probably can just skip the check there. Then, another issue is that we will hit an exception in the following code, which will prevent the rest of the followers from being added to the fetcher. We probably need to do the try/catch there per partition and log an error if we hit an exception.
          new TopicAndPartition(partition) -> BrokerAndInitialOffset(
            leaders.find(_.id == partition.leaderReplicaIdOpt.get).get,
            partition.getReplica().get.logEndOffset.messageOffset);;;","30/Sep/14 01:53;jjkoshy;Yes that is exactly why it happens and the fix is relatively straightforward.;;;","07/Oct/14 01:06;becket_qin;Created reviewboard https://reviews.apache.org/r/26373/diff/
 against branch origin/trunk;;;","14/Oct/14 07:38;becket_qin;Updated reviewboard https://reviews.apache.org/r/26373/diff/
 against branch origin/trunk;;;","18/Oct/14 15:26;becket_qin;Updated reviewboard https://reviews.apache.org/r/26373/diff/
 against branch origin/trunk;;;","22/Oct/14 04:52;noslowerdna;[~nehanarkhede] Will this correction be included in 0.8.2-beta? It sounds like a blocker for the 0.8.2 release, in any case.;;;","22/Oct/14 14:08;becket_qin;Updated reviewboard https://reviews.apache.org/r/26373/diff/
 against branch origin/trunk;;;","23/Oct/14 00:45;nehanarkhede;[~noslowerdna] This is pretty corner case and we are trying to get it in 0.8.2 if it can go through some testing. 
[~becket_qin] I think my comment may have been lost in the reviewboard, so reposting it here - In order to accept this patch, I'd like us to repeat the kind of testing that was done to find this bug. Did you get a chance to do that on your latest patch?;;;","23/Oct/14 01:08;becket_qin;[~nehanarkhede] I haven't got a chance to do tests yet... I'll do the test later this week and verify if it works.;;;","23/Oct/14 02:56;jjkoshy;[~becket_qin] here are some steps to reproduce locally. There are probably simpler steps, but I ran into it while debugging something else, so here you go:

* Set up three brokers. Sample config: https://gist.github.com/jjkoshy/1ec36e5cef41ac4bd8fb (You will need to edit the logs directory and port)
* Create 50 topics;  each with 4 partitions; replication factor 2 {code}for i in {1..50}; do ./bin/kafka-topics.sh --create --topic test$i --zookeeper localhost:2181 --partitions 4 --replication-factor 2; done{code}
* Run producer performance: {code}./bin/kafka-producer-perf-test.sh --threads 4 --broker-list localhost:9092,localhost:9093 --vary-message-size --messages 922337203685477580 --topics test1,test2,test3,test4,test5,test6,test7,test8,test9,test10,test11,test12,test13,test14,test15,test16,test17,test18,test19,test20,test21,test22,test23,test24,test25,test26,test27,test28,test29,test30,test31,test32,test33,test34,test35,test36,test37,test38,test39,test40,test41,test42,test43,test44,test45,test46,test47,test48,test49,test50 --message-size 500{code}
* Parallel hard kill of all brokers: {{pkill -9 -f Kafka}}
* Kill producer performance
* Restart brokers
* You should see ""WARN No checkpointed highwatermark is found for partition...""
;;;","28/Oct/14 08:19;becket_qin;Updated reviewboard https://reviews.apache.org/r/26373/diff/
 against branch origin/trunk;;;","31/Oct/14 01:58;jjkoshy;Patch is good, but could you rebase?;;;","31/Oct/14 06:07;becket_qin;Updated reviewboard https://reviews.apache.org/r/26373/diff/
 against branch origin/trunk;;;","31/Oct/14 06:10;becket_qin;Updated reviewboard https://reviews.apache.org/r/26373/diff/
 against branch origin/trunk;;;","31/Oct/14 06:38;becket_qin;Updated reviewboard https://reviews.apache.org/r/26373/diff/
 against branch origin/trunk;;;","31/Oct/14 06:50;becket_qin;Updated reviewboard https://reviews.apache.org/r/26373/diff/
 against branch origin/trunk;;;","31/Oct/14 07:33;jjkoshy;Thanks for the patch - committed to 0.8.2 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
remove gradlew initial setup output from source distribution,KAFKA-1490,12720594,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,edgefox,joestein,joestein,11/Jun/14 22:33,26/Mar/16 00:31,22/Mar/23 15:10,24/Sep/14 00:06,,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,Our current source releases contains lots of stuff in the gradle folder we do not need,,copester,cos,edgefox,guozhang,jfarrell,jghoman,jimmiebfulton,joestein,junrao,omkreddy,sslavic,szczepiq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SAMZA-283,,KAFKA-2124,,,,,KAFKA-1559,,,"17/Sep/14 02:28;edgefox;KAFKA-1490-2.patch;https://issues.apache.org/jira/secure/attachment/12669124/KAFKA-1490-2.patch","17/Sep/14 00:50;edgefox;KAFKA-1490.patch;https://issues.apache.org/jira/secure/attachment/12669091/KAFKA-1490.patch","23/Sep/14 17:52;edgefox;rb25703.patch;https://issues.apache.org/jira/secure/attachment/12670679/rb25703.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,398793,,,Fri Mar 25 16:31:13 UTC 2016,,,,,,,,,,"0|i1wnmv:",398915,,joestein,,,,,,,,,,,,,,,,,,"12/Jun/14 00:04;jghoman;This is being discussed for other projects, and how Aurora dealt with this problem [on the incubator list|http://mail-archives.apache.org/mod_mbox/incubator-general/201406.mbox/%3CCADiKvVs%3DtKDbp3TWRnxds5dVepqcX4kWeYbj7xUx%2BZoDNM_Lyg%40mail.gmail.com%3E].;;;","12/Jun/14 01:58;jghoman;We're also discussing this in SAMZA-283.;;;","28/Jul/14 15:01;sslavic;SAMZA-283 solution doesn't make sense to me - why would one want to bootstrap gradle wrapper if one already has gradle installed?

I've raised the issue on Gradle forum (see [here|http://forums.gradle.org/gradle/topics/bootstrap_gradle_wrapper_with_gradle_wrapper_scripts]).;;;","05/Sep/14 05:55;guozhang;Should this be done before 0.8.2?;;;","17/Sep/14 00:52;edgefox;I've deleted the gradlew output jar file and left properties file for configuration needs.
If you want to use local gradle distribution use gradle, otherwise ./gradlew will download gradle with version specified in properties file;;;","17/Sep/14 01:24;edgefox;Sorry guys for my previous post. I've confused "".gradle"" and ""gradle"" directories.
So, my method should not work. However, I think that this issue is not related to Kafka project and should be resolved in Gradle instead.

Furthermore, if we eventually resolve this issue, than it could cause gradle version problems in future for Gradle 1.x and 2.x users, since some plugins work under 1.x, but not under 2.x.
;;;","17/Sep/14 01:28;joestein;it is our problem, we need to resolve this we shouldn't be shipping binary in source;;;","17/Sep/14 02:28;edgefox;Ok, I applied the patch which replays the functionality from Samza.;;;","17/Sep/14 02:40;edgefox;https://reviews.apache.org/r/25703/;;;","23/Sep/14 12:25;joestein;[~edgefox] can you rebase please, unless something else causing failing to apply otherwise looks good I can test and commit tomorrow (so for such long delay was traveling last week);;;","23/Sep/14 17:52;edgefox;Rebased to the latest trunk. Reviewboard has been updated accordingly.;;;","24/Sep/14 00:06;joestein;+1 committed to trunk, also minor update to readme 

{code}

diff --git a/README.md b/README.md
index 18a65b1..8e50945 100644
--- a/README.md
+++ b/README.md
@@ -2,6 +2,13 @@ Apache Kafka
 =================
 See our [web site](http://kafka.apache.org) for details on the project.
 
+You need to have [gradle](http://www.gradle.org/installation) installed.
+
+### First bootstrap and download the wrapper ###
+    gradle
+
+Now everything else will work
+
 ### Building a jar and running it ###
     ./gradlew jar  
 

{code};;;","24/Sep/14 00:40;copester;Should there have been a wrapper.gradle file added in that patch?
build.gradle L40:
{code}
apply from: file('wrapper.gradle')
{code}
;;;","24/Sep/14 00:46;joestein;yup, thanks missed the git add, pushed the file now;;;","24/Sep/14 00:47;copester;Ok so the wrapper.gradle was in the attached patch on this issue, just not in the github commit. However, I there may be another change that didn't make it in to the commit?
{noformat}
ubuntu@ip-10-183-61-60:~/kafka$ gradle

FAILURE: Build failed with an exception.

* Where:
Script '/home/ubuntu/kafka/gradle/license.gradle' line: 2

* What went wrong:
A problem occurred evaluating script.
> Could not find method create() for arguments [downloadLicenses, class nl.javadude.gradle.plugins.license.DownloadLicenses] on task set.

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED

Total time: 3.303 secs
{noformat};;;","24/Sep/14 00:53;joestein;can you clone latest trunk now please, I did fresh and it is working for me

{code}

new-host:apache_kafka joestein$ git clone https://git-wip-us.apache.org/repos/asf/kafka.git trunk
Cloning into 'trunk'...
remote: Counting objects: 20685, done.
remote: Compressing objects: 100% (10682/10682), done.
Receiving objects: 100% (20685/20685), 14.96 MiB | 620 KiB/s, done.
remote: Total 20685 (delta 12343), reused 11450 (delta 7041)
Resolving deltas: 100% (12343/12343), done.
new-host:apache_kafka joestein$ cd trunk/
new-host:trunk joestein$ gradle
Building project 'core' with Scala version 2.10.1
:downloadWrapper

BUILD SUCCESSFUL

Total time: 11.1 secs
new-host:trunk joestein$ ./gradlew jar
Building project 'core' with Scala version 2.10.1
:clients:compileJava
Note: Some input files use unchecked or unsafe operations.
Note: Recompile with -Xlint:unchecked for details.
:clients:processResources UP-TO-DATE
:clients:classes
:clients:jar
:contrib:compileJava UP-TO-DATE
:contrib:processResources UP-TO-DATE
:contrib:classes UP-TO-DATE
:contrib:jar
:core:compileJava UP-TO-DATE
:core:compileScala
/opt/apache_kafka/trunk/core/src/main/scala/kafka/admin/AdminUtils.scala:259: non-variable type argument String in type pattern scala.collection.Map[String,_] is unchecked since it is eliminated by erasure
        case Some(map: Map[String, _]) => 
                       ^
/opt/apache_kafka/trunk/core/src/main/scala/kafka/admin/AdminUtils.scala:262: non-variable type argument String in type pattern scala.collection.Map[String,String] is unchecked since it is eliminated by erasure
            case Some(config: Map[String, String]) =>
                              ^
/opt/apache_kafka/trunk/core/src/main/scala/kafka/server/KafkaServer.scala:142: a pure expression does nothing in statement position; you may be omitting necessary parentheses
    ControllerStats.uncleanLeaderElectionRate
                    ^
/opt/apache_kafka/trunk/core/src/main/scala/kafka/server/KafkaServer.scala:143: a pure expression does nothing in statement position; you may be omitting necessary parentheses
    ControllerStats.leaderElectionTimer
                    ^
/opt/apache_kafka/trunk/core/src/main/scala/kafka/utils/Utils.scala:81: a pure expression does nothing in statement position; you may be omitting necessary parentheses
    daemonThread(name, runnable(fun))
                                ^
/opt/apache_kafka/trunk/core/src/main/scala/kafka/network/SocketServer.scala:359: Visited SCOPE_EXIT before visiting corresponding SCOPE_ENTER. SI-6049
      maybeCloseOldestConnection
      ^
/opt/apache_kafka/trunk/core/src/main/scala/kafka/network/SocketServer.scala:379: Visited SCOPE_EXIT before visiting corresponding SCOPE_ENTER. SI-6049
      try {
      ^
there were 12 feature warning(s); re-run with -feature for details
8 warnings found
:core:processResources UP-TO-DATE
:core:classes
:core:copyDependantLibs
:core:jar
:examples:compileJava
:examples:processResources UP-TO-DATE
:examples:classes
:examples:jar
:contrib:hadoop-consumer:compileJava
Note: Some input files use or override a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
Note: Some input files use unchecked or unsafe operations.
Note: Recompile with -Xlint:unchecked for details.
:contrib:hadoop-consumer:processResources UP-TO-DATE
:contrib:hadoop-consumer:classes
:contrib:hadoop-consumer:jar
:contrib:hadoop-producer:compileJava
:contrib:hadoop-producer:processResources UP-TO-DATE
:contrib:hadoop-producer:classes
:contrib:hadoop-producer:jar

BUILD SUCCESSFUL

Total time: 2 mins 3.497 secs

{code};;;","24/Sep/14 01:25;copester;I'm still getting that DownloadLicenses error. By default it's building with Scala 2.9.1, but trying Scala 2.10.1 like you also gets the same error. Do you mind listing your dependency versions? There may be something out of date on my end.;;;","24/Sep/14 01:35;joestein;I think your trunk is out of date we bumped the Scala version back in August

{code}

4d075971 (Ivan Lyutov 2014-08-10 21:20:30 -0700 18) scalaVersion=2.10.1

{code}

here are my dependencies for core from a fresh clone of trunk

{code}

new-host:trunk joestein$ ./gradlew core:dependencies
Building project 'core' with Scala version 2.10.1
:core:dependencies

------------------------------------------------------------
Project :core
------------------------------------------------------------

archives - Configuration for archive artifacts.
No dependencies

compile - Compile classpath for source set 'main'.
+--- project :clients
|    +--- org.slf4j:slf4j-api:1.7.6
|    +--- org.xerial.snappy:snappy-java:1.1.1.3
|    \--- net.jpountz.lz4:lz4:1.2.0
+--- org.scala-lang:scala-library:2.10.1
+--- org.apache.zookeeper:zookeeper:3.4.6
|    +--- org.slf4j:slf4j-api:1.6.1 -> 1.7.6
|    +--- org.slf4j:slf4j-log4j12:1.6.1
|    |    +--- org.slf4j:slf4j-api:1.6.1 -> 1.7.6
|    |    \--- log4j:log4j:1.2.16
|    +--- log4j:log4j:1.2.16
|    \--- io.netty:netty:3.7.0.Final
+--- com.101tec:zkclient:0.3
|    +--- org.apache.zookeeper:zookeeper:3.3.1 -> 3.4.6 (*)
|    \--- log4j:log4j:1.2.14 -> 1.2.16
+--- com.yammer.metrics:metrics-core:2.2.0
|    \--- org.slf4j:slf4j-api:1.7.2 -> 1.7.6
\--- net.sf.jopt-simple:jopt-simple:3.2

default - Configuration for default artifacts.
+--- project :clients
|    +--- org.slf4j:slf4j-api:1.7.6
|    +--- org.xerial.snappy:snappy-java:1.1.1.3
|    \--- net.jpountz.lz4:lz4:1.2.0
+--- org.scala-lang:scala-library:2.10.1
+--- org.apache.zookeeper:zookeeper:3.4.6
|    +--- org.slf4j:slf4j-api:1.6.1 -> 1.7.6
|    +--- org.slf4j:slf4j-log4j12:1.6.1
|    |    +--- org.slf4j:slf4j-api:1.6.1 -> 1.7.6
|    |    \--- log4j:log4j:1.2.16
|    +--- log4j:log4j:1.2.16
|    \--- io.netty:netty:3.7.0.Final
+--- com.101tec:zkclient:0.3
|    +--- org.apache.zookeeper:zookeeper:3.3.1 -> 3.4.6 (*)
|    \--- log4j:log4j:1.2.14 -> 1.2.16
+--- com.yammer.metrics:metrics-core:2.2.0
|    \--- org.slf4j:slf4j-api:1.7.2 -> 1.7.6
\--- net.sf.jopt-simple:jopt-simple:3.2

runtime - Runtime classpath for source set 'main'.
+--- project :clients
|    +--- org.slf4j:slf4j-api:1.7.6
|    +--- org.xerial.snappy:snappy-java:1.1.1.3
|    \--- net.jpountz.lz4:lz4:1.2.0
+--- org.scala-lang:scala-library:2.10.1
+--- org.apache.zookeeper:zookeeper:3.4.6
|    +--- org.slf4j:slf4j-api:1.6.1 -> 1.7.6
|    +--- org.slf4j:slf4j-log4j12:1.6.1
|    |    +--- org.slf4j:slf4j-api:1.6.1 -> 1.7.6
|    |    \--- log4j:log4j:1.2.16
|    +--- log4j:log4j:1.2.16
|    \--- io.netty:netty:3.7.0.Final
+--- com.101tec:zkclient:0.3
|    +--- org.apache.zookeeper:zookeeper:3.3.1 -> 3.4.6 (*)
|    \--- log4j:log4j:1.2.14 -> 1.2.16
+--- com.yammer.metrics:metrics-core:2.2.0
|    \--- org.slf4j:slf4j-api:1.7.2 -> 1.7.6
\--- net.sf.jopt-simple:jopt-simple:3.2

signatures
No dependencies

testCompile - Compile classpath for source set 'test'.
+--- project :clients
|    +--- org.slf4j:slf4j-api:1.7.6
|    +--- org.xerial.snappy:snappy-java:1.1.1.3
|    \--- net.jpountz.lz4:lz4:1.2.0
+--- org.scala-lang:scala-library:2.10.1
+--- org.apache.zookeeper:zookeeper:3.4.6
|    +--- org.slf4j:slf4j-api:1.6.1 -> 1.7.6
|    +--- org.slf4j:slf4j-log4j12:1.6.1
|    |    +--- org.slf4j:slf4j-api:1.6.1 -> 1.7.6
|    |    \--- log4j:log4j:1.2.16
|    +--- log4j:log4j:1.2.16
|    \--- io.netty:netty:3.7.0.Final
+--- com.101tec:zkclient:0.3
|    +--- org.apache.zookeeper:zookeeper:3.3.1 -> 3.4.6 (*)
|    \--- log4j:log4j:1.2.14 -> 1.2.16
+--- com.yammer.metrics:metrics-core:2.2.0
|    \--- org.slf4j:slf4j-api:1.7.2 -> 1.7.6
+--- net.sf.jopt-simple:jopt-simple:3.2
+--- junit:junit:4.1
+--- org.easymock:easymock:3.0
|    +--- cglib:cglib-nodep:2.2
|    \--- org.objenesis:objenesis:1.2
+--- org.objenesis:objenesis:1.2
\--- org.scalatest:scalatest_2.10:1.9.1
     +--- org.scala-lang:scala-library:2.10.0 -> 2.10.1
     +--- org.scala-lang:scala-actors:2.10.0
     |    \--- org.scala-lang:scala-library:2.10.0 -> 2.10.1
     \--- org.scala-lang:scala-reflect:2.10.0
          \--- org.scala-lang:scala-library:2.10.0 -> 2.10.1

testRuntime - Runtime classpath for source set 'test'.
+--- project :clients
|    +--- org.slf4j:slf4j-api:1.7.6
|    +--- org.xerial.snappy:snappy-java:1.1.1.3
|    \--- net.jpountz.lz4:lz4:1.2.0
+--- org.scala-lang:scala-library:2.10.1
+--- org.apache.zookeeper:zookeeper:3.4.6
|    +--- org.slf4j:slf4j-api:1.6.1 -> 1.7.6
|    +--- org.slf4j:slf4j-log4j12:1.6.1 -> 1.7.6
|    |    +--- org.slf4j:slf4j-api:1.7.6
|    |    \--- log4j:log4j:1.2.17
|    +--- log4j:log4j:1.2.16 -> 1.2.17
|    \--- io.netty:netty:3.7.0.Final
+--- com.101tec:zkclient:0.3
|    +--- org.apache.zookeeper:zookeeper:3.3.1 -> 3.4.6 (*)
|    \--- log4j:log4j:1.2.14 -> 1.2.17
+--- com.yammer.metrics:metrics-core:2.2.0
|    \--- org.slf4j:slf4j-api:1.7.2 -> 1.7.6
+--- net.sf.jopt-simple:jopt-simple:3.2
+--- junit:junit:4.1
+--- org.easymock:easymock:3.0
|    +--- cglib:cglib-nodep:2.2
|    \--- org.objenesis:objenesis:1.2
+--- org.objenesis:objenesis:1.2
+--- org.scalatest:scalatest_2.10:1.9.1
|    +--- org.scala-lang:scala-library:2.10.0 -> 2.10.1
|    +--- org.scala-lang:scala-actors:2.10.0
|    |    \--- org.scala-lang:scala-library:2.10.0 -> 2.10.1
|    \--- org.scala-lang:scala-reflect:2.10.0
|         \--- org.scala-lang:scala-library:2.10.0 -> 2.10.1
\--- org.slf4j:slf4j-log4j12:1.7.6 (*)

zinc - The Zinc incremental compiler to be used for this Scala project.
\--- com.typesafe.zinc:zinc:0.3.1
     +--- org.scala-lang:scala-library:2.10.3
     +--- com.typesafe.sbt:incremental-compiler:0.13.1
     |    +--- com.typesafe.sbt:sbt-interface:0.13.1
     |    |    \--- org.scala-lang:scala-library:2.10.3
     |    +--- org.scala-lang:scala-library:2.10.3
     |    \--- org.scala-lang:scala-compiler:2.10.3
     |         +--- org.scala-lang:scala-library:2.10.3
     |         \--- org.scala-lang:scala-reflect:2.10.3
     |              \--- org.scala-lang:scala-library:2.10.3
     \--- com.typesafe.sbt:compiler-interface:0.13.1
          \--- org.scala-lang:scala-library:2.10.3

(*) - dependencies omitted (listed previously)

BUILD SUCCESSFUL

Total time: 10.48 secs

{code}

;;;","24/Sep/14 02:52;guozhang;Hey Joe,

After pulling in this patch the gradlew command seems not working for us any more:

{code}
./gradlew jar
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/gradle/wrapper/GradleWrapperMain
Caused by: java.lang.ClassNotFoundException: org.gradle.wrapper.GradleWrapperMain
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
Could not find the main class: org.gradle.wrapper.GradleWrapperMain.  Program will exit.
{code}

Do you know why?;;;","24/Sep/14 02:58;joestein;1) You now need to have gradle installed http://www.gradle.org/installation
2) after that 

{code}
gradle
{code}

That will execute the default task which is to download the wrapper and then everything else works the same. :)

It is kind of like a new bootstrap to get things working required now.

I updated README to explain https://github.com/apache/kafka/blob/trunk/README.md#apache-kafka 

;;;","24/Sep/14 03:00;copester;[~guozhang], you need to run gradle first now. The Readme has been updated.
{noformat}
gradle
./gradlew jar
{noformat};;;","24/Sep/14 06:00;junrao;Joe, Chris,

It wasn't obvious that gradle needs to be run from the kafka source dir. Added that to README to make this clear.

Thanks,;;;","24/Sep/14 19:00;szczepiq;Hey guys,

This is Szczepan from the gradle core team :) This issue was brought to my attention thanks to Guozhang Wang. I wanted to share my feedback about the current solution.

To me, it feels like the current approach defeats the purpose of the wrapper. It looks like samza team has solved the problem by removing the gradle wrapper files (including jar) from the source _distribution_ while keeping the wrapper files (and jar) in the source code. Is this approach not feasible with kafka?;;;","24/Sep/14 21:05;joestein;Thanks [~szczepiq] for jumping in I think the current solution in any form for Apache projects is kludgy. :(  Besides Samza I just checked and Aurora does it that way too (keeping jar files checked in but excluding from source release) but I am not sure that is better though.

For source releases we have to exclude it and we will have to explain to folks they have to bootstrap (and they will ask). I feel like there would be less confusion and questions from folks using a source release if their experience with the repo is the same.

My preference would be to not have to ""bootstrap"" at all.  Maybe the gradle team could modify things so we could pull the wrapper jar first without it being there.  Any chance of that? :)  It seems like a legitimate ask since ""source only releases"" are such a big thing it is is kludgy now no matter where you cut it... this solution just makes it consistency kludgy.

I think this solution favors consistency of how to interact with the repo and source release which leads to less community confusion.

Also, the way we have always done releases https://cwiki.apache.org/confluence/display/KAFKA/Release+Process has been to copy the repository 1:1 for the source release.  This means what is tagged is exactly what is in the source release.  Technically speaking we could change that (of course) and create a source release task but not sure if we would want to-do that. If we decide to keep the jar in the repo we need to make sure the release manager has a way to create a source release differently than has been done before.
;;;","24/Sep/14 22:11;szczepiq;Hey,

Thanks for info! What's the purpose of 'source releases'? E.g. what's the benefit for developer over just cloning the repo?;;;","24/Sep/14 22:26;joestein;A source release is meant for general public consumption and use and not just for developers.  Technically speaking any version we put out is really about the source release the binaries are only an aid for folks that don't have the tools to make their own build from source http://www.apache.org/dev/release.html#what and http://www.apache.org/dev/release.html#what-must-every-release-contain

Any chance of the core gradle team making the gradle-wrapper.jar hosted and signed and then it can get downloaded (and signatures checked) if not found?  I think this would start to help wider adoption within apache projects and create a better uses experience for everyone always using gradle (assuming that approach satisfies apache requirements I believe it would best to get more Apache folks to verify that which we could do of course).  Let me know if you can get that change going and I can kick a discussion off (having a link to your ticketing change would help drive it) to make sure it will be workable within the Apache foundation (prior to you doing the work).;;;","24/Sep/14 22:40;jfarrell;I do not see what the issue is with having a bootstrapping step for the source release, lots of projects have this type of setup requirement. And with a fixed wrapper task it guarantees that everyone will be using the same version and meets the ASF source dist requirements;;;","24/Sep/14 23:42;omkreddy;1.  I am getting following exception after updating my local repo to latest. Do i need to clone new repo to use ./gradlew command?

{noformat}
 gradle

FAILURE: Build failed with an exception.

* Where:
Build file '/safe/KAFKA/kafkaTrunk/build.gradle' line: 40

* What went wrong:
A problem occurred evaluating root project 'kafkaTrunk'.
> Could not read script '/safe/KAFKA/kafkaTrunk/wrapper.gradle' as it does not exist.

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED

Total time: 3.184 secs

$./gradlew jar
Error: Could not find or load main class org.gradle.wrapper.GradleWrapperMain
{noformat}

2. I cloned the latest trunk and installed gradle. On running ./gradlew, it is downloading gradle.zip. Is it correct?

{noformat}
gradle
Building project 'core' with Scala version 2.10.1
:downloadWrapper UP-TO-DATE

BUILD SUCCESSFUL

Total time: 5.641 secs
$./gradlew jar
Downloading https://services.gradle.org/distributions/gradle-2.0-bin.zip
..........................................................................
{noformat};;;","24/Sep/14 23:52;joestein;In your first step you needed to have gradle installed, yes.

Yes, downloading the distribution for the gradle version we are using is the right thing to see and you should be good to go now.

I confirmed this works with a pull and not requiring a new clone (at least on the setup I have)

{code}

new-host:trunk joestein$ git pull
remote: Counting objects: 19, done.
remote: Compressing objects: 100% (13/13), done.
remote: Total 13 (delta 10), reused 0 (delta 0)
Unpacking objects: 100% (13/13), done.
From http://git-wip-us.apache.org/repos/asf/kafka
   6d70575..27bc372  trunk      -> origin/trunk
Updating 6d70575..27bc372
Fast-forward
 README.md                                |   8 ++++++++
 build.gradle                             |   5 +++++
 gradle/wrapper/gradle-wrapper.jar        | Bin 49875 -> 0 bytes
 gradle/wrapper/gradle-wrapper.properties |   6 ------
 gradlew                                  |   2 +-
 gradlew.bat                              | 180 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++------------------------------------------------------------------------------------------
 wrapper.gradle                           |  25 +++++++++++++++++++++++++
 7 files changed, 129 insertions(+), 97 deletions(-)
 delete mode 100644 gradle/wrapper/gradle-wrapper.jar
 delete mode 100644 gradle/wrapper/gradle-wrapper.properties
 create mode 100644 wrapper.gradle
new-host:trunk joestein$ gradle
Building project 'core' with Scala version 2.10.1
:downloadWrapper

BUILD SUCCESSFUL

Total time: 15.882 secs
new-host:trunk joestein$ ./gradlew clean
Building project 'core' with Scala version 2.10.1
:clients:clean
:contrib:clean
:core:clean
:examples:clean
:contrib:hadoop-consumer:clean
:contrib:hadoop-producer:clean

BUILD SUCCESSFUL

Total time: 14.111 secs

{code}

If there is something else/different you think can be added to the README https://github.com/apache/kafka/blob/trunk/README.md please suggest however; I think Jun's update was good for more clarity and it is makes sense.;;;","25/Sep/14 03:21;szczepiq;Thanks for info. I'll send an email to the gradle dev mailing list. Not sure though if something will happen in near future regarding the wrapper (I believe the priorities are elsewhere atm).

Cheers!;;;","25/Sep/14 06:03;joestein;[~szczepiq] Thanks! Hans just shot me the thread discussion about this http://gradle.1045684.n5.nabble.com/wrapper-jar-td5713148.html so in the future we can ./gradlew jar and if gradle-wrapper.jar is not found it will download it :) exciting!  will continue to bootstrap for now.;;;","03/Oct/14 18:52;szczepiq;Hey

The current bootstrap workflow in kafka is something like. The user:
- clones the repo
- looks into the 'build.gradle' file to find out which Gradle version he needs
- downloads this version of gradle (or maybe already has it)
- sets up this version of gradle, ensures it is on the PATH, etc.
- invokes this version of gradle to grab the wrapper
- now can build kafka OS via ./gradlew

Steps like above increase complexity and offer ways to break stuff (e.g. wrong version of gradle on PATH causing unexpected behavior, etc.). The wrapper was invented to avoid those kind of situations.

It's a bit of a shame that the jar file is involved - I would much prefer if there was no need for any jar to have 'wrapper' functionality available. Hopefully, in future version of Gradle it will be improved!;;;","15/Apr/15 06:36;jimmiebfulton;This breaks the expected gradlew contract, and makes for a poor user experience.  Every other project I've run into containing a gradlew script ""just works"".  If a user has to follow the steps as provided by [~szczepiq@gmail.com] above, there is very little point in gradlew, and having to switch Gradle versions for a specific project is very invasive to an existing developer environment.;;;","15/Apr/15 06:53;jghoman;bq. The current bootstrap workflow in kafka is something like. The user:
Not quite.  For repos, the gradlew script is still included.  However, I just checked it out and it's not running for me right out of the box.  This is a bug and I'll look into it.

Current bootstrap workflow for cloning a repo (assuming gradlew is working...):
* Clone repo
* Do whatever you like with ./gradlew

Current bootstrap workflow for building from a source release:
* Have some version of Gradle installed - yeah, this is annoying but for the reasons discussed above, currently unavoidable...
* Untar source release
* gradle downloadWrapper - This task should probably be moved to a separate boostrap.gradle file, as Samza has done, to be as simple and therefore as compatible with as many versions of Gradle as possible;;;","15/Apr/15 06:56;jghoman;Linking to issue to track current gradlew splat.;;;","26/Mar/16 00:31;cos;I came across this long closed issue because of BIGTOP-2365 and I should say that there's an easy way out of the situation. In Bigtop we simply have a modified version of the wrapper that download all required binaries unless they are present. The wrapper is source only, hence no binaries are getting checked into our repo. Perhaps, something to look at. Cheers.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Store logical offset in log,KAFKA-506,12607147,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,jkreps,jkreps,12/Sep/12 07:23,16/Nov/17 18:04,22/Mar/23 15:10,09/Oct/12 03:15,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"Currently we only support retention by dropping entire segment files. A more nuanced retention policy would allow dropping individual messages from a segment file by recopying it. This is not currently possible because the lookup structure we use to locate messages is based on the file offset directly.

To fix this we should move to a sequential, logical offset (0,1,2,3,...) which would allow deleting individual messages (e.g. 2) without deleting the entire segment.

It is desirable to make this change in the 0.8 timeframe since we are already doing data format changes.

As part of this we would explicitly store the key field given by the producer for partitioning (right now there is no way for the consumer to find the value used for partitioning).

This combination of features would allow a key-based retention policy that would clean obsolete values either by a user defined key.

The specific use case I am targeting is a commit log for local state maintained by a process doing some kind of near-real-time processing. The process could log out its local state changes and be able to restore from this log in the event of a failure. However I think this is a broadly useful feature.

The following changes would be part of this:
1. The log format would now be
      8 byte offset
      4 byte message_size
      N byte message
2. The offsets would be changed to a sequential, logical number rather than the byte offset (e.g. 0,1,2,3,...)
3. A local memory-mapped lookup structure will be kept for each log segment that contains the mapping from logical to physical offset.

I propose to break this into two patches. The first makes the log format changes, but retains the physical offset. The second adds the lookup structure and moves to logical offset.

Here are a few issues to be considered for the first patch:
1. Currently a MessageSet implements Iterable[MessageAndOffset]. One surprising thing is that the offset is actually the offset of the next message. I think there are actually several uses for the current offset. I would propose making this hold the current message offset since with logical offsets the next offset is always just current_offset+1. Note that since we no longer require messages to be dense, it is not true that if the next offset is N the current offset is N-1 (because N-1 may have been deleted). Thoughts or objections?
2. Currently during iteration over a ByteBufferMessageSet we throw an exception if there are zero messages in the set. This is used to detect fetches that are smaller than a single message size. I think this behavior is misplaced and should be moved up into the consumer.
3. In addition to adding a key in Message, I made two other changes: (1) I moved the CRC to the first field and made it cover the entire message contents (previously it only covered the payload), (2) I dropped support for Magic=0, effectively making the attributes field required, which simplifies the code (since we are breaking compatibility anyway).

",,jjkoshy,jkreps,junrao,nehanarkhede,smeder,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-414,,,,,,,,,KAFKA-634,,,,,,,,,,"11/Oct/12 07:48;jkreps;KAFKA-506-neha-post-review-v2.patch;https://issues.apache.org/jira/secure/attachment/12548670/KAFKA-506-neha-post-review-v2.patch","10/Oct/12 11:59;jkreps;KAFKA-506-neha-post-review.patch;https://issues.apache.org/jira/secure/attachment/12548519/KAFKA-506-neha-post-review.patch","28/Sep/12 09:05;jkreps;KAFKA-506-phase-2-v1.patch;https://issues.apache.org/jira/secure/attachment/12546937/KAFKA-506-phase-2-v1.patch","29/Sep/12 04:20;jkreps;KAFKA-506-phase-2-v2.patch;https://issues.apache.org/jira/secure/attachment/12547038/KAFKA-506-phase-2-v2.patch","03/Oct/12 05:33;jkreps;KAFKA-506-phase-2-v3.patch;https://issues.apache.org/jira/secure/attachment/12547447/KAFKA-506-phase-2-v3.patch","04/Oct/12 04:52;jkreps;KAFKA-506-phase-2-v4.patch;https://issues.apache.org/jira/secure/attachment/12547593/KAFKA-506-phase-2-v4.patch","06/Oct/12 04:18;jkreps;KAFKA-506-phase-2-v5.patch;https://issues.apache.org/jira/secure/attachment/12548036/KAFKA-506-phase-2-v5.patch","05/Oct/12 01:22;jkreps;KAFKA-506-phase-2-v5.patch;https://issues.apache.org/jira/secure/attachment/12547788/KAFKA-506-phase-2-v5.patch","27/Sep/12 13:44;jkreps;KAFKA-506-phase-2.patch;https://issues.apache.org/jira/secure/attachment/12546813/KAFKA-506-phase-2.patch","14/Sep/12 05:27;jkreps;KAFKA-506-v1-draft.patch;https://issues.apache.org/jira/secure/attachment/12545057/KAFKA-506-v1-draft.patch","15/Sep/12 06:41;jkreps;KAFKA-506-v1.patch;https://issues.apache.org/jira/secure/attachment/12545234/KAFKA-506-v1.patch","04/Oct/12 04:52;jkreps;KAFKA-506-v4-changes-since-v3.patch;https://issues.apache.org/jira/secure/attachment/12547594/KAFKA-506-v4-changes-since-v3.patch",,,,,,,,,,,,,,,,12.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,240554,,,Fri Oct 12 00:16:01 UTC 2012,,,,,,,,,,"0|i013bb:",4306,,,,,,,,,,,,,,,,,,,,"14/Sep/12 05:27;jkreps;Add key to message and reorder some fields
Bump up Message magic number to 2
Add offset to MessageSet format
Make MessageAndOffset contain the current offset and add a nextOffset() method to get the next offset
Some misc. cleanups (delete some obsolete files, fix bad formatting)

There are still two problems with this patch:
1. Not handling offsets properly in compressed messages
2. Unit test failures in LogRecoveryTest;;;","15/Sep/12 06:41;jkreps;Updated the patch. This patch fixes the remaining failing tests and correctly handles compressed messages.

This patch is ready for review.;;;","15/Sep/12 06:42;jkreps;I am going to begin phase two of this, implementing the logical offset management in Log.;;;","17/Sep/12 11:47;junrao;Thanks for patch v1. Overall, the log format change is reasonable. Some comments:

1. MessageAndOffset: nextOffset is not correct for compressed messages. Currently, in the high-level consumer, after iterating each message, the consume offset is moved to the offset of the next message. So, if one consumes a message and then commits the offset, the committed offset points to the next message to be consumed. We could probably change the protocol to move the consumer offset to the offset of the current message. Then, the caller will need to commit the offset first and then consumes the message to get the same semantics.

2. Message:
2.1 The comment of the message has a bug. Payload should have (N- K - 10) bytes.
2.2 In constructor, should we assert that offset is btw 0 and bytes.length-1? Also, just to be clear that offset and size are for the payload, should we rename bytes, offset and size to something like payload, payloadOffset and payloadSize?
2.3 computeChecksum(): can use MagicOffset for both starting offset and length
2.4 remove unused import

3. MessageSet: Fix the comment in second line ""A The format"".

4. ByteBufferMessageSet: remove unused comment

5. Log:
5.1 append(): For verifying message size, we need to use the shallow iterator since a compressed message has to be smaller than the configured max message size.
5.2 append(): Compressed messages are forced to be decompressed and then compressed again. This will introduce some CPU overhead. What's the increase in CPU utilization if incoming messages are compressed? Also, for replicaFetchThread, it can just put the data fetched from the leader directly into the log without recomputing the offsets. Could we add a flag in append to bypass regenerating the offsets?
5.3 trimInvalidBytes(): There is a bug in the following statement: messages.size should be messages.sizeInBytes.
    if(messageSetValidBytes == messages.size) {

6. javaapi.ByteBufferMessageSet: Java users shouldn't really be using buffer. So, we don't need the bean property.

7. PartitionData: Do we need to override equal and hash since this is already a case class?

8. ZkUtils.conditionalUpdatePersistenPath(): This method expects exception due to version conflict. So there is no need to log the exception.

9. SyncProducerTest: remove unused imports

10. How do we handle the case that a consumer uses too small a fetch size?;;;","17/Sep/12 23:57;jkreps;Great feedback, thanks.

1. Good point about nextOffset. I think this is slightly tricky to fix. I think I will ignore this problem and work on phase 2 which will fix that issue by making nextOffset=offset+1. This means taking both patches at once which will be a bit big. Sound feasible?
2-4 Good feedback
5.1. Good point.
5.2. I will do a little micro-benchmark on decompression/re-compression. Yes, we can definitely avoid this for the replica fetcher thread. Depending on how much we want to optimize that path there are a lot of options. On the extreme side of total trust I think it might actually possible to do FileChannel.transferTo directly from the socket buffer, though there are complications around metrics and hw mark. I think for now it makes sense to just skip decompression. One question: let's say recompression turns out to be expensive, there are two options: (1) do not set internal offsets (as today), (2) eat the cost and recommend snappy instead of gzip. Personally I prefer (2) since I think we need to fix the correctness bugs, but I am open to implementing either if there is a consensus.
5.3. Good catch
6. OK
7. I am not sure. We had a custom implementation of equals but no hashcode which I think was likely wrong. We can remove both, but I would want to figure out why we added the equals.
8-9. OK
10. Ah, forgot to add that. I think the right thing is just to check (currentDataChunk.messages.size > 0 && currentDataChunk.buffer.size == fetchSize) throw Exception() in the ConsumerIterator. The only thing to consider is that this means there is no check for the simpleconsumer.
;;;","18/Sep/12 05:16;junrao;Actually, there is another thing.

11. We need to change DefaultEventHandler to put the key data into messages sent to the broker. Also, Producer currently can take any type as key, do we want to restrict it to bytes or do we want to define a serializer for key too?;;;","21/Sep/12 05:17;nehanarkhede;Thanks for the patch ! The log format change doesn't interfere with replication as of this patch. A few comments in addition to Jun's -

1. CompressionUtils: How about re-using the ByteBufferMessageSet.writeMessage() API for serializing the compressed message to a byte buffer ?

2. ByteBufferMessageSet.scala, FileMessageSet: Can we use MessageSet.LogOverhead instead of 12 for byte arithmetic ?

3. ConsumerIterator
The nextOffset issue for compressed message sets will get resolved when we actually use the sequential logical offsets. With that, the advantage is that the consumer will be able to fetch a message even if it is inside a compressed message. Today, there is no good way to achieve this unless we have level-2 message offsets for compressed messages. Even if we cannot make that change in time for replication, we can take this change and leave the message set iterator to return the next offset (valid fetch offset), just like we do today. So, either way, we are covered here.;;;","27/Sep/12 13:44;jkreps;This patch is incremental from the previous one. I will rebase and provide an up-to-date patch that covers both phases, but this shows the new work required to support logical offsets.

I think I have addressed most of the comments on the original patch, except:
1. I have put off any performance optimization (avoiding recompression for replicas, memory-mapping the log, etc). I would like to break this into a separate JIRA and write a reasonable standalone Log benchmark that covers these cases and then work against that. I have several other cleanups I would like to do as well: (1) get rid of SegmentList, (2) move more functionality in Log into LogSegment.
2. I am not yet storing the key in the message, this may change the produce api slightly so i think this should be a seperate JIRA too.
3. Neha--I change most of the uses of magical numbers except where the concrete number is more clear.

Here is a description of the new changes.
- Offset now always refers to a logical log offset. I have tried to change any instances where offset meant file offset to instead use the terminology ""position"". References to file positions should only occur in Log.scala and classes internal to that.
- As in the previous patch MessageAndOffset gives three things: (1) the message, (2) the offset of THAT message, and (3) a helper method to calculate the next offset.
- Log.append() is responsible for maintaining the logEndOffset and using it to assign offsets to the messageset before appending to the log.
- Offsets are now assigned to compressed messages too. One nuance is that the offset of the wrapper message is equal to the last offset of the messages it contains. This will be more clear in the discussion of the offset search changes.
- Log.read now accepts a new argument maxOffset, which is the largest (logical) offset that will be returned in addition to the maxSize which limits the size in bytes.
- I have changed Log.read to now support sparse offsets. That is, it is valid to have missing offsets. This sparseness is needed both for the key-retention but also for the correct handling of compressed messages. I will describe the read path in more detail below.
- I moved FileMessageSet to the package kafka.log as already much of its functionality was specific to the log implementation.
- I changed FetchPurgatory back to use a simple counter for accumulated bytes. It was previously re-calculating the available bytes, but because this now is a more expensive operation, and because this calculation is redone for each topic/partition produce (i.e. potentially 200 times per produce request), I think this is better. This is less accurate, but since long poll is a heuristic anyway I think that is okay.
- I changed the default suffix of .kafka files to .log and added a new .index file that contains a sparse index of offset=>file_position to help efficiently resolve logical offsets.
- Entries are added to this index at a configurable frequency, controlled by a new configuration log.index.interval.bytes which defaults to 4096
- I removed numerous instances of byte calculations. I think this is a good thing for code quality.

Here is a description of the new read path.
1. First log tries to find the correct segment to read from using the existing binary search on log segments. I modified this search slightly in two ways. First we had a corner case bug which only occurred if you have two files with successive offsets (unlikely now, impossible before). Second, I now no longer check ranges but instead return the largest segment file less than or equal to the requested offset.
2. Once the segment is found we check the index on that segment. The index returns the largest offset less than or equal to the requested offset and the associated file position in the log file. This position represents a least upper bound on the position in the file, and it is the position from which we begin a linear search checking each message. The index itself is just a sorted sequence of (offset, position) pairs. Complete details are in the header comments on kafka.log.OffsetIndex.scala. It is not required that all messages have an entry in the OffsetIndex, instead there is a confgurable frequency in terms of bytes which is set in LogSegment. So, for example, we might have an entry every 4096 bytes. This frequency is approximate, since a single message may be larger than that.
3. Once we have a greatest lower bound on the location we use FileMessageSet.searchFor to search for the position of the first message with an offset at least as large as the target offset. This search just skips through the file checking the offset only.
;;;","28/Sep/12 09:05;jkreps;Okay attached a fully rebased patch that contains both phase 1 and phase 2 changes.;;;","29/Sep/12 05:54;jkreps;Three preliminary comments from Neha while she does deeper interogations:
- Would be nice if the DumpLogSegment tool also dumped the contents of the index file
- This patch implicitly assumes file segments are limited to 2GB (I use a 4 byte position pointer in the index). Turns out this isn't true. Proposed fix is to limit log segments to 2GB.
- We decided the corner case with sparse messages at the end of a segment isn't really a corner case as it effects compressed messages too. So I will fix that in the scope of this patch.;;;","29/Sep/12 06:43;nehanarkhede;2 additions to the preliminary comments -
- 3 unit tests fail on patch v2 - http://pastebin.com/ECUA2n1f
- It will be nice for maxIndexEntries to be a configurable property on the server;;;","01/Oct/12 11:55;junrao;Thanks for patch v2. Some more comments:

20. Log:
20.1 findRange(): Add to the comment that now this method returns the largest segment file <= the requested offset.
20.2 close(): move the closing } for the for loop to a new line.
20.3 bytesSinceLastIndexEntry is only set but is never read.
20.4 append(): This method returns the offset of the first message to be appended. This is ok for the purpose of returning the offset to the producer. However, when determining whether all replicas have received the appended messages, we need to use the log end offset after the messages are appended. So, what we should do is to have append() return 2 offsets, one before the append and one after the append. We use the former in producer response and use the latter for the replica check. To avoid complicating this patch further, another approach is to, in the jira, have append return the log end offset after the append and use it in both producer response and replica check. We can file a separate jira to have append return 2 offsets.
20.5 read(): The trace statement: last format pattern should be %d instead of %s.
20.6 truncateTo(): The usage of logEndOffset in the following statement is incorrect. It should be the offset of the next segment.
          segments.view.find(segment => targetOffset >= segment.start && targetOffset < logEndOffset)
20.7 There are several places where we need to create a log segment and the code for creating the new data file and the new index file is duplicate. Could we create a utility function createNewSegment to share the code?

21. LogSegment: bytesSinceLastIndexEntry needs to be updated in append().

22. FileMessageSet.searchFor(): The following check seems to be a bit strange. Shouldn't we use position + 12 or just position instead?
    while(position + 8 < size) {

23. OffsetIndex:
23.1 In the comment, ""mutable index can be created to"" seems to have a grammar bug.
23.2 mmap initialization: The following statement seems unnecessary. However, we do need to set the mapped buffer's position to end of file for mutable indexes. 
          idx.position(idx.limit).asInstanceOf[MappedByteBuffer]
23.3 append(): If index entry is full, should we automatically roll the log segment? It's ok if this is tracked in a separate jira.
23.4 makeReadOnly(): should we call flush after raf.setLength()? Also, should we remap the index file to the current length and make it read only?

24. LogManager.shutdown(): log indentation already adds LogManager in the prefix of each log entry.

25. KafkaApis:
25.1 handleFetchRequest: topicDatas is weird since data is the plural form of datum. How about topicDataMap?
25.2 ProducerRequestPurgatory: It seems that it's useful to keep the logIndent since it can distinguish logs from the ProducerRequestPurgatory and FetchRequestPurgatory. Also, it's probably useful to pass in brokerId to RequestPurgatory for debugging unit tests.

26. Partition: There are a few places that the first character of info log is changed to lower case. The current convention is to already use upper case.

27. javaapi.ByteBufferMessageSet: underlying should be private val.

28. DumpLogSegment: Now that each message stores an offset, we should just print the offset in MessageAndOffset. There is no need for var offset now.

29. FetchedDataChunk: No need to use val for parameters in constructor since this is a case class now.

30. PartitionData:
30.1 No need to redefine equals and hashcode since this is already a case class.
30.2 initialOffset is no longer needed.

31. PartitionTopicInfo.enqueue(): It seems that next can be computed using shallow iterator since the offset of a compressed message is always the offset of the last internal message.

32. ByteBufferMessageSet: In create() and decompress(), we probably should close the output and the input stream in a finally clause in case we hit any exception during compression and decompression.

33. remove unused imports.

The following comment from the first round of review is still not addressed.
10. How do we handle the case that a consumer uses too small a fetch size?
;;;","03/Oct/12 05:33;jkreps;New patch with a few new things:

I rebased a few more times to pick up changes.

WRT Neha's comments:
- I made maxIndexEntries configurable by adding the property log.index.max.size. I did this in terms of index file size rather than entries since the user doesn't really know the entry size but may care about the file size.
- For the failing tests: (1) The message set failure is due to scalatest not handling parameterized tests, i had fixed this but somehow it didn't make it into the previous patch. It is in the current one. testHWCheckpointWithFailuresSingleLogSegment is a timing assumption in that test. Fixed it by adding a sleep :-(. The producer test failure I cannot reproduce.
- Wrote a test case using compressed messages to try to produce the corner case at the end of a segment. But actually this turns out not to be possible with compressed messages since the numbering is by the last offset. So effectively our segments are always dense right now. As such I would rather wait until I refactor segment list to fix it since it will be duplicate work otherwise.
- Turns out that log segments are limited to 2GB already, via a restriction in the config. Not actually sure why this is. Given this limitation one cleanup that might be nice to do would be to convert MessageSet.sizeInBytes to an Int, which would remove a lot of casts. Since this is an unrelated cleanup I will not do it in this patch.
- I added support to DumpLogSegment tool to display the index file. I had to revert Jun's change to check that last offset=file size since this is no longer true.

Jun's Comments:
First of all, this is an impressively thorough code review. Thanks!
20.1 Made the Log.findRange comment more reflective of what the method does. I hope to remove this entirely in the next phase.
20.2 Fixed mangled paren in close()
20.3 bytesSinceLastIndexEntry. Yes, good catch. This is screwed up. This was moved into LogSegment, but the read and update are split in two places. Fixed.
20.4 append(): ""We need to have both the begin offset and the end offset returned by Log.append()"". Made Log.append return (Long, Long). I am not wild about this change, but I see the need. I had to refactor KafkaApis slightly since we were constructing an intermediate response object in the produceToLocalLog method (which was kind of weird anyway) so there was only one offset and since this is an API object we can't change it. I think the use of API objects in the business logic is a bit dangerous for this reason.
20.5 Fixed broken log statement to use correct format param.
20.6 truncateTo(): The usage of logEndOffset in the following statement is incorrect. Changed this to use Log.findInRange which I think is the intention.
20.7 ""There are several places where we need to create a log segment and the code for creating the new data file and the new index file is duplicate. Could we create a utility function createNewSegment to share the code?"" Good idea, done. There is still a lot more refactoring that could be done between Log and LogSegment, but I am kind of putting that off.
21. LogSegment: ""bytesSinceLastIndexEntry needs to be updated in append()."" Fixed.
22. FileMessageSet.searchFor() fixed bad byte arithmetic.
23. OffsetIndex:
23.1 Fixed bad english in comment
23.2 mmap initialization: Yes, this doesn't make sense. The correct logic is that the mutable case must be set to index 0, and the read-only case doesn't matter. This was happening implicitly since byte buffers initialize to 0, but I switched it to make it explicit.
23.3 append(): ""If index entry is full, should we automatically roll the log segment?"" This is already handled in Log.maybeRoll(segment) which checks segment.index.isFull
23.4 makeReadOnly(): ""should we call flush after raf.setLength()?"" This is a good point. I think
what you are saying is that the truncate call itself needs the metadata to flush to be considered stable. Calling force on the mmap after the setLength won't do this. Instead I changed the file open to use synchronous mode ""rws"" which should automatically fsync metadata when we call setLength. The existing flush is okay: I verified that flush doesn't cause the sparse file to desparsify or anything like that. ""Also, should we remap the index file to the current length and make it read only?"" Well, this isn't really needed. There is no problem with truncating a file post mmap, but I guess making the mapping read-only could prevent corruption due to any bugs we might have so I made that change.
LogManager
24. ""log indentation already adds LogManager in the prefix of each log entry."" Oops.
25. KafkaApis:
25.1 ""handleFetchRequest: topicDatas is weird since data is the plural form of datum. How about topicDataMap?"" Changed to dataRead (I don't like having the type in the name).
25.2 ""ProducerRequestPurgatory: It seems that it's useful to keep the logIndent since it can distinguish logs from the ProducerRequestPurgatory and FetchRequestPurgatory. Also, it's probably useful to pass in brokerId to RequestPurgatory for debugging unit tests."" Agreed, accidentally removed this; added it back.
26. ""Partition: There are a few places that the first character of info log is changed to lower case. The current convention is to already use upper case."" Made all upper case.
27. ""javaapi.ByteBufferMessageSet: underlying should be private val."" Changed.
28. ""DumpLogSegment: Now that each message stores an offset, we should just print the offset in MessageAndOffset. There is no need for var offset now."" Removed.
29. ""FetchedDataChunk: No need to use val for parameters in constructor since this is a case class now."" Wait is everything a val in a case class? I made this change, but don't know what it means...
30. PartitionData:
30.1 ""No need to redefine equals and hashcode since this is already a case class."" Yeah, this was fixing a bug in the equals/hashcode stuff due to the array that went away when i rebased. Removed it
30.2 ""initialOffset is no longer needed."" I think PartitionData is also used by ProducerRequest. This is a bug, but I think we do need the initial offset for the other case. Until we separate these two I don't think I can remove it.
31. ""PartitionTopicInfo.enqueue(): It seems that next can be computed using shallow iterator."" Ah, very nice. Changed that.
32. ""ByteBufferMessageSet: In create() and decompress(), we probably should close the output and the input stream in a finally clause in case we hit any exception during compression and decompression."" These are not real output streams. I can close them, but they are just arrays so I think it is just noise, no?
33. ""remove unused imports."" Eclipse doesn't identify them, will swing by.
34. ""How do we handle the case that a consumer uses too small a fetch size?"" Added a check and throw for this in ConsumerIterator.
;;;","03/Oct/12 05:33;jkreps;Ran system test, passes:


2012-10-02 14:11:50,376 - INFO - ======================================================
2012-10-02 14:11:50,376 - INFO - stopping all entities
2012-10-02 14:11:50,376 - INFO - ======================================================

2012-10-02 14:12:43,105 - INFO - =================================================
2012-10-02 14:12:43,105 - INFO -                  TEST REPORTS
2012-10-02 14:12:43,105 - INFO - =================================================
2012-10-02 14:12:43,105 - INFO - test_case_name : testcase_1
2012-10-02 14:12:43,105 - INFO - test_class_name : ReplicaBasicTest
2012-10-02 14:12:43,105 - INFO - validation_status : 
2012-10-02 14:12:43,105 - INFO -     Leader Election Latency - iter 2 brokerid 3 : 49636.00 ms
2012-10-02 14:12:43,105 - INFO -     Validate leader election successful : PASSED
2012-10-02 14:12:43,106 - INFO -     Unique messages from consumer : 850
2012-10-02 14:12:43,106 - INFO -     Validate for data matched : PASSED
2012-10-02 14:12:43,106 - INFO -     Unique messages from producer : 850
2012-10-02 14:12:43,106 - INFO -     Leader Election Latency - iter 1 brokerid 2 : 354.00 ms
;;;","03/Oct/12 13:08;junrao;Thanks for patch v3. We are almost there. A few more comments:

40. Log.append: It seems that it's easier if lastOffset returned is just nextOffset instead of nextOffset -1. Then, in KafkaApis, we can just pass end, instead of end+1 to ProducerResponseStatus.

41. OffsetIndex: When initializing mmap, if the index is mutable, shouldn't we move the position to the end of the buffer for append operations?

42. KafkaApis: It's useful to pass in brokerId to RequestPurgatory for debugging unit tests.

43. DumpLogSegments: Currently, the message iterator in FileMessageSet will stop when it hits the first non parsable message. So, we need to check if at the end of the message iteration, location == FileMessageSet.sizeInBytes(). If not, we should report the offset from which data is corrupted.

44. ConsumerIterator: The check for guarding small fetch size doesn't work. This is because in PartitionTopicInfo.enqueue(), we only add ByteBufferMessageSet that has positive valid bytes. We can log an error in PartitionTopicInfo.enqueue() and enqueue a special instance of FetchedDataChunk that indicates an error. In ConsumerIterator, when seeing the special FetchedDataChunk, it can throw an exception.

29. Yes, all parameters in the constructor in a case class are implicitly val.
;;;","04/Oct/12 00:09;junrao;There is another issue:

45. ConsumerIterator: Now that we index each message inside a compressed message, we need to handle the case when a fetch request starting on an offset in the middle of a compressed message. In makeNext(), we need to first skip messages whose offset is less than currentDataChunk.fetchOffset. Otherwise, the consumer would get duplicates. We probably can do this in a followup jira since currently the consumer can get duplicates on compressed messages too.

;;;","04/Oct/12 04:52;jkreps;Here is a new patch that addresses these comments. I also did an incremental diff against the previous patch so you can see the specific changes for the below items (that is KAFKA-506-v4-changes-since-v3.patch)

Also rebased again.

40. I actually disagree. It is more code to add and subtract, but I think it makes more sense. This way we would say the append api returns ""the first and last offset for the messages you appended"" rather than ""the first offset for the messages you appended and the offset of the next message that would be appended"". This is not a huge deal so I can go either way, but I did think about it both ways and that was my rationale.

41. My thinking was that there were only two cases: re-creating a new, mutable index (at position 0) and opening a read-only index. In reality there are three cases: in addition to the previous two you can be re-opening an existing log that went through clean shutdown. I was not handling this properly and in fact was truncating the index on re-open, so the existing entries in the last segment would be unindexed. There are now two cases for mutable indexes. Recall that on clean-shutdown the index is always truncated to the max valid entry. So now when we open an index, if the file exists, I set the position to the end of the file. If the file doesn't exist I allocate it and start at position 0. The recovery process well still re-create the index if it runs, if the shutdown was clean then we will just roll to a new segment on the first append (since the index was truncated, it is now full).

43. I removed that feature since the iterator only has the offset not the file position. However after thinking about it I can add it back by just using MessageSet.entrySize(message) on each entry and use the sum of these to compare to the messageSet.sizeInBytes. Added that.

44. Changed the check to be the messageSet.sizeInBytes. This check was really meant to guard the case where we are at the end of the log and get an empty set. I think it was using validBytes because it needed to calculate the next offset. Now that calculation is gone, so I think it is okay to just use messageSet.sizeInBytes. This would result in a set with 0 valid bytes being enqueued, and then the error getting thrown to the consumer. The fetcher would likely continue to fetch this message set, but that should be bounded by the consumer queue size.

45. The behavior after this patch should be exactly the same as the current behavior, so my hope was to do this as a follow up patch.

Also: Found that I wasn't closing the index when the log was closed, and found a bug in the index re-creation logic in recovery; fixed both, and expanded tests for this.;;;","04/Oct/12 06:01;junrao;Patch v4 looks good overall. A couple of remaining issues:

50. testCompressionSetConsumption seems to fail transiently for me with the following exception. This seems to be related to the change made for #44.
kafka.common.MessageSizeTooLargeException: The broker contains a message larger than the maximum fetch size of this consumer. Increase the fetch size, or decrease the maximum message size the broker will allow.
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:87)

51. ConsumerIterator: When throwing MessageSizeTooLargeException, could we add the topic/partition/offset to the message string in the exception?
;;;","05/Oct/12 01:22;jkreps;Rebased again and fixed the above issues to make v5

50. I looked into this. It is slightly subtle. The problem was that validBytes is cached in a local variable, and the incremental computation was done on the member variable in ByteBufferMessageSet. The next problem was that AbstractFetcherThread and the ConsumerIterator could both be calling this at the same time, which would lead to setting validBytes to 0 and then iterating over the messages to count the bytes. If the check and the computation occurred at precisely the same time it is possible for validBytes to return essentially any value. The fix is (1) avoid mucking with the MessageSet once it is handed over to ConsumerFetcherThread.processPartitionData, and (2) use a local variable to compute the validbytes, this way even if we do have future threading bugs the worst case is that we recompute the same cached value twice instead of accessing a partial computation (we could also make the variable volatile, but that doesn't really add any additional protection since we don't need precise memory visibility).

51. Done.;;;","05/Oct/12 04:31;junrao;Thanks for patch v5. 

50. There is still a potential issue in that shallowValidByteCount is a long and long value is not guaranteed to be exposed atomically without synchronization in java. So, 1 thread could see a partially updated long value. Thinking about this, since ByteBufferMessageSet is not updatable, is it better to compute validBytes once in the constructor?

51. ConsumerIterator: Could you include currentDataChunk.fetchOffset in the message string in MessageSizeTooLargeException? This will make debugging easier.

Since this is a large patch, it would be good if someone else takes a closer look at it too. At least Neha expressed interests in taking another look at the latest patch.;;;","05/Oct/12 05:25;jkreps;50. It can actually only take Int values, so I don't think this can happen. I will file a follow-up clean-up issue to change sizeInBytes to be an Int (I had mentioned that earlier in the thread) since this anyways leads to innumerable safe-but-annoying casts to int. I think this is better than pre-computing it because in many cases we instantiate a ByteBufferMessageSet without necessarily using validBytes.

51. Yes, I will add this as part of the checkin.;;;","05/Oct/12 06:20;nehanarkhede;I will free up tomorrow after Grace Hopper conference is over. Would like to take another closer look at the follow up patches. If you guys don't mind, please can we hold this at least for this weekend ?;;;","05/Oct/12 06:42;jkreps;It is really hard/error-prone to keep this patch alive and functioning, I basically spend half of each day on rebasing then debugging the new bugs i introduce during rebasing. Could we do it as a post commit review? I am totally down to fix/change things, but the problem is each new change may take a few iterations and meanwhile the whole hunk has to be kept alive. In an ideal world I would have found a way to have done this in smaller pieces, but it is kind of a cross-cutting change so that was hard.;;;","05/Oct/12 09:14;junrao;What we can do is to hold off committing other conflicting patches for now and have this patch more thoroughly reviewed. If there are no major concerns, we can just commit the patch and have follow-up jiras to address minor issues. Neha, do you think that you can finish the review by Saturday?;;;","05/Oct/12 09:19;jjkoshy;Rebasing is painful for sure, especially since 0.8 is moving quite fast. I think the other patches in flight are either small or otherwise straightforward to rebase as they don't have significant overlap. So it seems holding off all check-ins until after this weekend would work for everyone right?
;;;","06/Oct/12 01:42;jkreps;jkreps-mn:kafka-git jkreps$ git pull
remote: Counting objects: 72, done.
remote: Compressing objects: 100% (37/37), done.
remote: Total 42 (delta 26), reused 0 (delta 0)
Unpacking objects: 100% (42/42), done.
From git://git.apache.org/kafka
   0aa1500..65e139c  0.8        -> origin/0.8
Auto-merging core/src/main/scala/kafka/api/FetchResponse.scala
CONFLICT (content): Merge conflict in core/src/main/scala/kafka/api/FetchResponse.scala
Auto-merging core/src/main/scala/kafka/api/ProducerRequest.scala
CONFLICT (content): Merge conflict in core/src/main/scala/kafka/api/ProducerRequest.scala
Auto-merging core/src/main/scala/kafka/consumer/ConsumerFetcherThread.scala
Auto-merging core/src/main/scala/kafka/server/AbstractFetcherThread.scala
CONFLICT (content): Merge conflict in core/src/main/scala/kafka/server/AbstractFetcherThread.scala
Auto-merging core/src/main/scala/kafka/server/KafkaApis.scala
CONFLICT (content): Merge conflict in core/src/main/scala/kafka/server/KafkaApis.scala
Auto-merging core/src/main/scala/kafka/server/ReplicaFetcherThread.scala
Auto-merging core/src/test/scala/unit/kafka/api/RequestResponseSerializationTest.scala
Auto-merging core/src/test/scala/unit/kafka/producer/SyncProducerTest.scala
Auto-merging core/src/test/scala/unit/kafka/utils/TestUtils.scala
Automatic merge failed; fix conflicts and then commit the result.

:-(;;;","06/Oct/12 04:18;jkreps;Rebased patch and improved error message for the MessageSizeTooLargeException.;;;","08/Oct/12 23:55;nehanarkhede;Agree that rebasing is painful. In addition to more reviews, the hope was to check in ~20 more test cases as part of KAFKA-502, so we could test it out thoroughly. But we can check it in and return to fixing issues later as well. ;;;","09/Oct/12 00:00;nehanarkhede;Btw, which svn revision does patch v5 apply correctly on ? ;;;","09/Oct/12 00:06;jkreps;Should apply on HEAD.;;;","09/Oct/12 01:54;junrao;+1 from me.;;;","09/Oct/12 03:15;jkreps;Committed.;;;","10/Oct/12 05:11;nehanarkhede;I have to mention that there is a possibility that some of my comments are not related to this patch directly, but were found while inspecting the new code closely :) Since you know the code better, feel free to file follow up JIRAs

1. Log

1.2 In findRange, the following statements runs the risk of hitting overflow, giving incorrect results from the binary search -
      val mid = ceil((high + low) / 2.0).toInt
Will probably be better to use
     val mid = low + ceil((high - low)/2.0).toInt
1.3 It seems that there are only 2 usages of the findRange API that takes in the array length . We already have an API that covers that use case - findRange[T <: Range](ranges: Array[T], value: Long) and this is used by a majority of API calls.
We can make the findRange method that has the actual binary search logic private and changes the 2 use cases in Log.scala to use the public method that assumes the array length.
1.4 In truncateTo, it is possible that the log file was successfully deleted but the index file was not. In this case, we would end up an unused index file that is never deleted from the kafka log directory.
1.5 In loadSegments, we need to rebuild any missing index files. Or it will error out at a later time. Do we have a follow up JIRA to cover this, it seems like a blocker to me.

2. LogManager
2.1 numPartitions is an unused class variable

3. FileMessageSet
3.1. In searchFor API, fix comment to mention that it searches for the first/least offset that is >= the target offset. Right now it says search for the last offset that is >= target offset
3.2 The searchFor API returns a pair of (offset, position). Right now, it does not always return the offset of the message at the returned position. If the file message set is sparse, it returns the offset of the next message, so the offset and position do not point to the same message in the log. Currently, we are not using the offset returned by the read() API, but in the future if we do, it will be good for it to be consistent.
3.3 In searchFor API, one of the statements uses 12 and the other uses MessageSet.LogOverhead. I think the while condition is better understood if it said MessageSet.LogOverhead.

4. LogSegment
4.1 It is better to make translateOffset return an Option. That way, every usage of this API will be forced to handle the case when the position was not found in the log segment.
4.2 I guess it might make sense to have all the places that uses this segment size to a an Int instead of Long. 

5. ConsumerIterator

Right now, while committing offsets for a compressed message set, the consumer can still get duplicates. However, we could probably fix this by making the ConsumerIterator smarter and discarding messages with offset < fetch offset.

6. ReplicaFetcherThread

When the follower fetches data from the leader, it uses log.append which re-computes the logical message ids. This involves recompression when the data is compressed, which it is in production. This can be avoided by making the data copy from leader -> follower smarter

7. MessageCompressionTest
There are 2 unused imports in this file

8. ByteBufferMessageSet
8.1 There are 3 unused imports in this file
8.2 The return statement in create() API is redundant

9. OffsetIndex
9.1 The last return statement in indexSlotFor is redundant
9.1 The first return statement in indexSlotFor can be safely removed by using case-match or putting the rest of the logic in the else part of if-else block.

10. Performance
Performance test to see the impact on throughput/latency if any due to this patch. What I am curious about is the performance impact due to the following, which are the changes that can impact performance as compared to pre KAFKA-506 -
10.1 Recompression of data during replica reads
10.2 Recompression of data to assign correct offsets inside a compressed message set
10.3 The linear search in the file segment to find the message with a given id. This depends on the index interval and there needs to be a balance between index size and index interval.
10.4 The impact of making the log memory mapped.
10.5 Overhead of using the index to read/write data in Kafka

11. KafkaApis
Unused imports in this file

Just to summarize so that we understand the follow up work and also the JIRAs that got automatically resolved due to this feature. Please correct me if I missed something here -

Follow up JIRAs
1. Retain key in producer (KAFKA-544)
2. Change sizeInBytes() to Int (KAFKA-556)
3. Fix consumer offset commit in ConsumerIterator for compressed message sets (KAFKA-546)
4. Remove the recompression involved while fetching data from follower to leader (KAFKA-557)
5. Rebuild missing index files (KAFKA-561)
6. Add performance test for log subsystem (KAFKA-545)
7. Overall Performance analysis due to the factors listed above

JIRAs resolved due to this feature
1. Fix offsets returned as part of producer response (KAFKA-511)
2. Consumer offset issue during unclean leader election (KAFKA-497)


;;;","10/Oct/12 11:59;jkreps;Hi Neha, here are some comments on your comments and a patch that addresses the comments we are in agreement on.

1. Log
1.2, 1.3 True. This problem exists in both OffsetIndex and Log, though I don't think either are actually possible. In Log this requires one to have 2 billion segment files, though, which is not physically possible; in OffsetIndex one would need to have ~2 billion entries in an index, which isn't possible as the message overhead would fill up the log segment first. I am going to leave it alone in Log since that code I want to delete asap anyway. I fixed it in the OffsetIndex since that code is meant to last.
1.4. This logic is a little odd, I will fix it, but actually this reminds me of a bigger problem. If file.delete() fails on the log file, the presence of that log file will effectively corrupt the log on restart (since we will have a file with the given offset but will also start another log with a parallel offset that we actually append to--on restart the bad file will mask part of the new file). Obviously if file.delete() fails things are pretty fucked and there is nothing we can do in software to recover. So what I would like to do is throw KafkaStorageException and have Partition.makeFollower() shut down the server. What would happen in the leadership transfer if I did that?
1.5 Filed a JIRA for this.

LogManager
2.1 Deleted numPartitions (not related to this patch, I don't think)

FileMessageSet
3.1 Good catch, fixed.
3.2 Right, so I return the offset specifically to be able to differentiate the case where I found the exact location versus the next message. This is important for things like truncate. I always return the offset and corresponding file position of the first offset that meets the >= criteria. So either I am confused, or I think it works the way you are saying it should.
3.3 Well, but the code actually reads and Int and Long out of the resulting buffer, so if MessageSet.LogOverhead != 12 there is a bug, so we aren't abstracting anything just adding a layer of obfuscation. But, yes, it should be consistent, so changed it.

LogSegment
4. LogSegment
4.1 I don't want to allocate an object for each call as this method is internal to LogSegment. I will make it private to emphasize that.
4.2 I agree, though we have had the 2gb limit for a while now so this isn't new. We repurposed KAFKA-556 for this.

5. ConsumerIterator
Agreed. Broke this into a separate issue since current state is no worse than 0.7.x. JIRA is KAFKA-546.

6. ReplicaFetcherThread
Agreed this was discussed above. JIRA is KAFKA-557.

7. Only IDEA detects this, which I don't have. So can't help on this.

8. ByteBufferMessageSet
8.2 Fixed

9. OffsetIndex 
9.1 Fixed
9.2 This is true but I think it would be more convoluted. Simple test and exits make it so you don't have to add another layer of nesting.

10 Agreed, of the various things on my plate I think this is the most important. Any issues here are resolvable, but we need to first get the data.
;;;","11/Oct/12 07:48;jkreps;This patch is identical to the previous Neha related patch except that now in the event that a log segment can't be deleted we throw KafkaStorageException. In KafkaApis.handleLeaderAndISRRequest we catch this exception and shutdown the server.;;;","11/Oct/12 12:04;nehanarkhede;+1. Looks good and thanks for addressing the late review comments. One minor comment -

The following error statement is slightly misleading. The broker could either be in the middle of becoming a leader or a follower, not necessarily the former. 

fatal(""Disk error while becoming leader."");;;","12/Oct/12 00:07;jkreps;Ah, nice catch. Changed it to ""Disk error during leadership change.""

Checked in with the change.;;;","12/Oct/12 08:05;smeder;I think you missed a change to KafkaETLContext. It needs:

diff --git a/contrib/hadoop-consumer/src/main/java/kafka/etl/KafkaETLContext.java b/contrib/hadoop-consumer/src/main/java/kafka/etl/KafkaETLContext.java
index bca1757..9498169 100644
--- a/contrib/hadoop-consumer/src/main/java/kafka/etl/KafkaETLContext.java
+++ b/contrib/hadoop-consumer/src/main/java/kafka/etl/KafkaETLContext.java
@@ -205,7 +205,7 @@ public class KafkaETLContext {
             
             key.set(_index, _offset, messageAndOffset.message().checksum());
             
-            _offset = messageAndOffset.offset();  //increase offset
+            _offset = messageAndOffset.nextOffset();  //increase offset
             _count ++;  //increase count
             
             return true;

or something similar. As it stands it'll run forever...
;;;","12/Oct/12 08:16;jkreps;Ack, nice catch, fixed it.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Cached zkVersion not equal to that in zookeeper, broker not recovering.",KAFKA-2729,12910010,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,onurkaraman,danil,danil,03/Nov/15 23:00,24/Jul/22 00:14,22/Mar/23 15:10,23/Dec/17 02:34,0.10.0.0,0.10.1.0,0.11.0.0,0.8.2.1,0.9.0.0,2.4.1,1.1.0,,,,,,,,,,,52,,,,,,"After a small network wobble where zookeeper nodes couldn't reach each other, we started seeing a large number of undereplicated partitions. The zookeeper cluster recovered, however we continued to see a large number of undereplicated partitions. Two brokers in the kafka cluster were showing this in the logs:

{code}
[2015-10-27 11:36:00,888] INFO Partition [__samza_checkpoint_event-creation_1,3] on broker 5: Shrinking ISR for partition [__samza_checkpoint_event-creation_1,3] from 6,5 to 5 (kafka.cluster.Partition)
[2015-10-27 11:36:00,891] INFO Partition [__samza_checkpoint_event-creation_1,3] on broker 5: Cached zkVersion [66] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
{code}
For all of the topics on the effected brokers. Both brokers only recovered after a restart. Our own investigation yielded nothing, I was hoping you could shed some light on this issue. Possibly if it's related to: https://issues.apache.org/jira/browse/KAFKA-1382 , however we're using 0.8.2.1.",,a.aseev,abhinavddr@gmail.com,adamkeyser,adeetikaushal,agomez,ajs,alexwang,allenzhuyi,amaniates,amatenda,aneale,astubbs,axrj,BigAndy,bobrik,boniek,butterhc,chemist,chenhaifeng,cmolter,cpennello_opentable,crazyjvm,crodier,cwright,daluu,dang@cloudera.com,danil,davispw,dawg,derek@chen-becker.org,DEvil0000,dinavahi,donis,ecomar,egor_m,elevy,epitrochoid,evildracula,fravigotti,gauss,gherreros,hai_lin,hightea,Hugh O'Brien,ijuma,JahyunGu,jalaziz,JanosKranczler,jeffwidman,jlintz,joseph.aliase07@gmail.com,joshua.dickerson@dealer.com,jpfaff,jthakrar,junrao,justen_walker,KaneK,klesta490,kzadorozhny-tubemogul,l0co,liyezhang556520,llamahunter,locatelli,ltagliamonte,manmedia@gmail.com,mgabriel,mingaliu,MiniMizer,mjuarez,mkizner,mnantern,murri71,neilfordyce,oleksiys,padilo,peoplemerge,prasincs,prateekjaipuria,raybooysen,roczei,Ronghua Lin,rrukavina@rbauction.com,rthille,sam.nguyen@sendgrid.com,sdeokulecluster,SeaAndHill,shturman,simonxia,sini,skidank,sroset,sslavic,steven.aerts,tbischel,timoha,toidi,travees,trueneu,tscoville2012,umesh9794@gmail.com,vanskang,victorgp,viktorsomogyi,vikumar,waewoo,waleedfateem,wangbo23,williamyu,wushujames,yangguo1220,ybennour,yzang,Zhangg,zhangzs,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3042,KAFKA-3083,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Jul 23 16:12:02 UTC 2022,,,,,,,,,,"0|i2nvrj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"25/Nov/15 02:10;toidi;Our kafka cluster met the same issue:
{noformat}
kafka2 1448388319:093 [2015-11-24 21:05:19,387] INFO Partition [dstat_wc_cpl_log,13] on broker 2: Shrinking ISR for partition [dstat_wc_cpl_log,13] from 2,1 to 2 (kafka.cluster.Partition)
kafka2 1448388319:094 [2015-11-24 21:05:19,404] INFO Partition [dstat_wc_cpl_log,13] on broker 2: Cached zkVersion [332] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
{noformat}

We use confluent.io's kafka distribution.
Kafka version is 0.8.2.2.;;;","13/Jan/16 17:50;agomez;Our kafka cluster met the same issue too:

{noformat}
[2016-01-12 01:16:15,907] INFO Partition [__consumer_offsets,10] on broker 0: Shrinking ISR for partition [__consumer_offsets,10] from 0,1 to 0 (kafka.cluster.Partition)
[2016-01-12 01:16:15,909] INFO Partition [__consumer_offsets,10] on broker 0: Cached zkVersion [3240] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-01-12 01:16:15,909] INFO Partition [__consumer_offsets,45] on broker 0: Shrinking ISR for partition [__consumer_offsets,45] from 0,1 to 0 (kafka.cluster.Partition)
[2016-01-12 01:16:15,911] INFO Partition [__consumer_offsets,45] on broker 0: Cached zkVersion [3192] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-01-12 01:16:15,911] INFO Partition [__consumer_offsets,24] on broker 0: Shrinking ISR for partition [__consumer_offsets,24] from 0,1 to 0 (kafka.cluster.Partition)
[2016-01-12 01:16:15,912] INFO Partition [__consumer_offsets,24] on broker 0: Cached zkVersion [3233] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
{noformat}

Kafka version is 0.8.2.2;;;","05/Feb/16 13:54;elevy;Had the same issue happen here while testing a 5 node Kafka cluster with a 3 node ZK ensemble on Kubernetes on AWS.  After running for a while broker 2 started showing the ""Cached zkVersion [29] not equal to that in zookeeper, skip updating ISR"" error message for al the partitions it leads.  For those partition it is the only in sync replica.  That has led to the Samza jobs I was running to stop.

I should note that I am running 0.9.0.0.;;;","18/Feb/16 07:33;wushujames;We ran into the same issue today, when running 0.9.0.0.

{quote}
[2016-02-17 22:49:52,638] INFO Partition [the.topic.name,22] on broker 2: Cached zkVersion [5] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
{quote}
;;;","23/Feb/16 20:07;akheron;This happened to me (again) a few days ago on 0.9.0.0 on a cluster of 2 kafka nodes.;;;","29/Feb/16 07:59;michal.harish;Hit this on Kafka 0.8.2.2 as well;;;","28/Apr/16 07:30;KaneK;Same problem with the same symptoms occurred on kafka 0.8.2.1. After network glitch brokers fall out of ISR set with
Cached zkVersion [5] not equal to that in zookeeper, skip updating ISR

Broker never recovers from this state until restart.

;;;","29/Apr/16 15:30;srdo;We hit this on 0.9.0.1 today
{code}
[2016-04-28 19:18:22,834] INFO Partition [dce-data,13] on broker 3: Shrinking ISR for partition [dce-data,13] from 3,2 to 3 (kafka.cluster.Partition)
[2016-04-28 19:18:22,845] INFO Partition [dce-data,13] on broker 3: Cached zkVersion [304] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-04-28 19:18:32,785] INFO Partition [dce-data,16] on broker 3: Shrinking ISR for partition [dce-data,16] from 3,2 to 3 (kafka.cluster.Partition)
[2016-04-28 19:18:32,803] INFO Partition [dce-data,16] on broker 3: Cached zkVersion [312] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
{code}
which continued until we rebooted broker 3. The ISR at this time in Zookeeper had only broker 2, and there was no leader for the affected partitions. I believe the preferred leader for these partitions was 3.;;;","30/May/16 21:31;jpfaff;We have hit that as well on 0.9.0.1 today, same logs, and only a reboot of the faulty broker recovered the problem.;;;","07/Jul/16 22:58;crodier;We also observed this identical issue, on 0.9.0.1 today.  Restart of the failed broker resolved the issue without difficulty as a work around.  This seems like a high priority issue where you could lose nodes, and/or lose a cluster fairly easily due to zookeeper instability / elections.

;;;","14/Jul/16 06:13;tbischel;We are also seeing this issue in 0.10.0.0 pretty much daily right now.
{code}
[2016-07-13 21:30:50,170]  1292384 [kafka-scheduler-0] INFO  kafka.cluster.Partition  - Partition [events,580] on broker 10432234: Cached zkVersion [1267] not equal to that in zookeeper, skip updating ISR
{code};;;","27/Jul/16 23:13;williamyu;We are also seeing this in our production cluster: Running on Kafka: 0.9.0.1

Is restarting the only solution?

{code}
[2016-07-27 14:36:15,807] INFO Partition [tasks,265] on broker 4: Cached zkVersion [182] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2016-07-27 14:36:15,807] INFO Partition [tasks,150] on broker 4: Shrinking ISR for partition [tasks,150] from 6,4,7 to 4 (kafka.cluster.Partition)
{code};;;","28/Jul/16 00:12;kipz;That's our experience, though the only other thing we've tried is leaving it for a while.;;;","28/Jul/16 00:38;KaneK;This is hitting us badly on kafka 0.10.0.0, it doesn't recover by itself for several days at least.;;;","30/Jul/16 04:06;kzadorozhny-tubemogul;Seeing the same issue in our staging and production environments on 0.9.0.1. Bouncing brokers helps, but still not ideal.

Staging cluster were left to ""recover"" for a day. Didn't happen.;;;","02/Aug/16 06:02;joshua.dickerson@dealer.com;This has bit us twice in our live environment. 0.9.0.1
Restarting the affected broker(s) is the only thing that seems to fix it. ;;;","09/Aug/16 01:33;skidank;We seem to be having a similar problem running 0.10.0.0. However no amount of broker restarting corrects the problem. Once it happens, I see periodic ""Cached zkVersion"" messages along with complete instability in the ISRs. Continuous shrinking and expanding of the ISRs that makes the cluster unusable as we need 2 ISRs for our durability requirements. 

The only thing that fixes the problem is to delete all topics, recreate and reload. This isn't a practical approach for our production system in which we are using Kafka as a transactionally consistent replica of a relational database.

Anyone have any clues about how to prevent this from happening?;;;","09/Aug/16 03:59;KaneK;For us the reason was high percentage of lost packets to one of ZK nodes (from broker to ZK). After we fixed that, situation got a lot better.;;;","06/Sep/16 23:29;cmolter;Hi,

We had this issue on a test cluster running 0.10.0.0 so I took time to investigate some more.

We had a bunch of disconnections to Zookeeper and we had 2 changes of controller in a short time.

Broker 103 was controller with epoch 44
Broker 104 was controller with epoch 45

I looked at one specific partitions and found the following pattern:

101 was the broker which thought was leader but kept failing shrink the ISR with:
Partition [verifiable-test-topic,0] on broker 101: Shrinking ISR for partition [verifiable-test-topic,0] from 101,301,201 to 101,201
Partition [verifiable-test-topic,0] on broker 101: Cached zkVersion [185] not equal to that in zookeeper, skip updating ISR

Looking at ZK we have:
get /brokers/topics/verifiable-test-topic/partitions/0/state
{""controller_epoch"":44,""leader"":301,""version"":1,""leader_epoch"":96,""isr"":[301]}

And metadata (to a random broker) is saying:
Topic: verifiable-test-topic	Partition: 0	Leader: 301	Replicas: 101,201,301	Isr: 301

Digging in the logs here’s what we think happened:

1. 103 sends becomeFollower to 301 with epoch 44 and leaderEpoch 95
2. 104 sends becomeLeader to 101 with epoch 45 and leaderEpoch 95 (after update zk!)
3. 103 sends becomeLeader to 301 with epoch 44 and leaderEpoch 96 (after updating zk!)
4. 104 sends becomeFollower to 301 with epoch 45 and leaderEpoch 95

4) Is ignored by 301 as the leaderEpoch is older than the current one.

We are missing a request: 103 sends becomeFollower to 101 with epoch 44 and leaderEpoch 95

I believe this happened because when the controller steps down it empties its request queue so this request never left the controller: https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/controller/ControllerChannelManager.scala#L53-L57

So we ended up in a case where 301 and 101 think they are both leaders. Obviously 101 wants to update the state in ZK to remove 301 as it’s not even fetching from 101.

Does this seem correct to you?

It seems impossible to avoid having no Controller overlap, which could make it quite hard to avoid having 2 leaders for a short time. Though there should be a way for this situation to get back to a good state.

I believe the impact of this would be:
- writes = -1 unavailability
- writes != -1 possible log divergence (I’m unsure about this).

Hope this helps. While I had to fix the cluster by bouncing a node I kept most of the logs so let me know if you need more info.;;;","23/Nov/16 23:31;derek@chen-becker.org;I'm on 0.10.1.0 and seeing the same thing. Maybe related to [~cmolter] is saying above, what we see in the logs just prior to a broker becoming under-replicated is a flurry of

{noformat}
org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition.
{noformat}

messages. After that we see a bunch of activity around adding and removing fetchers, then it goes into the infinite ISR shrink loop. The only way we can recover is to restart.;;;","18/Jan/17 05:59;sini;Same issue on 0.10.1.1. Do you need logs? I can collect them next time I see this.;;;","27/Jan/17 05:31;peoplemerge;Same with us, on 0.10.1.1 (following upgrade from 0.10.1.0 where we saw the same issue).;;;","10/Feb/17 17:03;sini;Do you have any plan to resolve this? Or is there a workaround for this issue?;;;","14/Feb/17 17:48;prasincs;This is still replicable in Kafka 0.10.1.1 when Kafka brokers are partitioned from each other and zookeeper gets disconnected from the brokers briefly and comes back. This situation leads to brokers getting stuck in comparing Cached zkVersion and unable to expand the ISR. 

The code in Partition.scala does not seem to be handling enough error conditions other than the stale zkVersion. In addition to skipping in the current loop, I think it should reconnect to zookeeper to update the current state and version.     

Here's a suggestion to do this.. doing it asynchronously doesn't break the existing flow and you can update the state. ZkVersion may not be the only thing to update here.

{code}
val newLeaderAndIsr = new LeaderAndIsr(localBrokerId, leaderEpoch, newIsr.map(r => r.brokerId).toList, zkVersion)
    val (updateSucceeded,newVersion) = ReplicationUtils.updateLeaderAndIsr(zkUtils, topic, partitionId,
      newLeaderAndIsr, controllerEpoch, zkVersion)

    if(updateSucceeded) {
      replicaManager.recordIsrChange(new TopicAndPartition(topic, partitionId))
      inSyncReplicas = newIsr
      zkVersion = newVersion
      trace(""ISR updated to [%s] and zkVersion updated to [%d]"".format(newIsr.mkString("",""), zkVersion))
    } else {
      info(""Cached zkVersion [%d] not equal to that in zookeeper, skip updating ISR"".format(zkVersion))
      zkVersion = asyncUpdateTopicPartitionVersion(topic,partitionId)
    }
{code};;;","16/Feb/17 09:55;elevy;Hit this again during testing with 0.10.0.1 on a 10 node broker cluster with a 3 node ZK ensemble.  This should have priority Blocker instead of Major.;;;","16/Feb/17 18:34;klesta490;[~elevy] Agree, we are experiencing same issue, this is real blocker and we are loosing trust in Kafka...;;;","23/Feb/17 03:45;prateekjaipuria;Having the same issue with 0.10.1.0 on a 8 node cluster. Restarting node also does not help, the problem just moves on to another node. This is becoming a deal breaker. Definitely losing trust in Kafka. Definitely a BLOCKER!;;;","23/Feb/17 04:07;granthenke;I am curious if everyone on this Jira is actually seeing the reported issue. I have had multiple cases where someone presented my with an environment they thought was experiencing this issue. After researching the environment and logs, to date it has always been something else. 

The main culprits so far have been:
* Long GC pauses causing zookeeper sessions to timeout
* Slow or poorly configured zookeeper
* Bad network configuration

All of the above resulted in a soft reoccurring failure of brokers. That churn often caused addition load perpetuating the issue. 

If you are seeing this issue do you see the following pattern repeating in the logs?:
{noformat}
INFO org.I0Itec.zkclient.ZkClient: zookeeper state changed (Disconnected)
...
INFO org.I0Itec.zkclient.ZkClient: zookeeper state changed (Expired)
INFO org.apache.zookeeper.ClientCnxn: Unable to reconnect to ZooKeeper service, session 0x153ab38abdbd360 has expired, closing socket connection
...
INFO org.I0Itec.zkclient.ZkClient: zookeeper state changed (SyncConnected)
INFO kafka.server.KafkaHealthcheck: re-registering broker info in ZK for broker 32
INFO kafka.utils.ZKCheckedEphemeral: Creating /brokers/ids/32 (is it secure? false)
INFO kafka.utils.ZKCheckedEphemeral: Result of znode creation is: OK
{noformat}

If so, something is causing communication with zookeeper to take too long and the broker is unregistering itself. This will cause ISRs to shrink and expand over and over again.

I don't think this will solve everyones issue here, but hopefully it will help solve some.

;;;","23/Feb/17 04:52;peoplemerge;[~granthenke] We don't see brokers recovering.  The message we see is:
{noformat}
Cached zkVersion [xxx] not equal to that in zookeeper, skip updating ISR
{noformat}

;;;","23/Feb/17 06:15;prateekjaipuria;[~granthenke] We don't see any zookeeper disconnections.

Just
{code}
INFO Partition [topic,n] on broker m: Cached zkVersion [xxx] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
{code};;;","23/Feb/17 08:24;KaneK;In my opinion it doesn't matter what's causing it (in our case that was indeed lost packets to zookeeper), the culprit is that brokers will not recover by itself until rolling restart. This is real problem and has to be fixed.
;;;","23/Feb/17 09:53;junrao;Sorry to hear about the impact to production. Grant mentioned ZK session expiration, which is indeed a potential cause of this issue. A related issue has been reported in KAFKA-3083. The issue is that when the controller's ZK session expires and loses its controller-ship, it's possible for this zombie controller to continue updating ZK and/or sending LeaderAndIsrRequests to the brokers for a short period of time. When this happens, the broker may not have the most up-to-date information about leader and isr, which can lead to subsequent ZK failure when isr needs to be updated.

Fixing this issue requires us change the way how we use the ZK api and may take some time. In the interim, one suggestion is to make sure ZK session expiration never happens. This can be achieved by making sure that (1) ZK servers are performing, (2) the brokers don't have long GCs, (3) the ZK session expiration time is large enough.;;;","23/Feb/17 13:23;prasincs;[~junrao] Thanks for looking into this. Do you mind elaborating on what you need to change in the ZK api and whether https://issues.apache.org/jira/browse/KAFKA-3083 is going to solve it. The issue here is that -- in case of network partitions which are unrelated to the 3 points and can happen at any time, this can happen and leave the brokers in messed up state until a restart. Can this be fixed by handling the ZK Connection errors?

If restarting the broker is the only fix, maybe the proper thing to do is to crash and let supervisor, etc. restart the service?;;;","24/Feb/17 00:46;junrao;[~prasincs], if the controller is partitioned off other brokers and ZK, the expected flow is the following: (1) ZK server detects that the old controller's session expires; (2) the controller path is removed by ZK; (3) a new controller is elected and changes leaders/isrs; (4) network is back on the old controller; (5) old controller receives ZK session expiration event; (6) old controller stops doing the controller stuff and resign. Note that the old controller doesn't really know that it's no longer the controller until step (5). The gap we have now is that step (6) is not done in a timely fashion.

Are you deploying Kafka in the same data center? What kind of network partitions are you seeing? Typically, we expect network partitions are rare within the same data center. If there are short network glitches, one temporary fix is to increase the ZK session timeout to accommodate for that until the network issue is fixed.;;;","02/Mar/17 08:21;mjuarez;We are also running into this problem in our staging cluster, running Kafka 0.10.0.1.  Basically it looks like this happened yesterday: 

{noformat}
[2017-02-28 18:41:33,513] INFO Client session timed out, have not heard from server in 7799ms for sessionid 0x159d7893eab0088, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
{noformat}

I'm attributing that to a transient network issue, since we haven't seen any other issues.  And less than a minute later, we started seeing these errors:

{noformat}
[2017-02-28 18:42:45,739] INFO Partition [analyticsInfrastructure_KafkaAvroUserMessage,16] on broker 101: Shrinking ISR for partition [analyticsInfrastructure_KafkaAvroUserMessage,16] from 102,101,105 to 101 (kaf
[2017-02-28 18:42:45,751] INFO Partition [analyticsInfrastructure_KafkaAvroUserMessage,16] on broker 101: Cached zkVersion [94] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-02-28 18:42:45,751] INFO Partition [qa_exporter11_slingshot_salesforce_invoice,6] on broker 101: Shrinking ISR for partition [qa_exporter11_slingshot_salesforce_invoice,6] from 101,105,104 to 101 (kafka.clu
[2017-02-28 18:42:45,756] INFO Partition [qa_exporter11_slingshot_salesforce_invoice,6] on broker 101: Cached zkVersion [237] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-02-28 18:42:45,756] INFO Partition [GNRDEV_counters_singleCount,2] on broker 101: Shrinking ISR for partition [GNRDEV_counters_singleCount,2] from 101,105,104 to 101 (kafka.cluster.Partition)
[2017-02-28 18:42:45,761] INFO Partition [GNRDEV_counters_singleCount,2] on broker 101: Cached zkVersion [334] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-02-28 18:42:45,761] INFO Partition [sod-spins-spark-local,1] on broker 101: Shrinking ISR for partition [sod-spins-spark-local,1] from 101,103,104 to 101 (kafka.cluster.Partition)
[2017-02-28 18:42:45,764] INFO Partition [sod-spins-spark-local,1] on broker 101: Cached zkVersion [379] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-02-28 18:42:45,764] INFO Partition [sod-spins-spark-local,11] on broker 101: Shrinking ISR for partition [sod-spins-spark-local,11] from 102,101,105 to 101 (kafka.cluster.Partition)
[2017-02-28 18:42:45,767] INFO Partition [sod-spins-spark-local,11] on broker 101: Cached zkVersion [237] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
{noformat}

The ""current"" server is 101.  So it thinks it's the leader for basically every partition on that node, but it's refusing to update the ISRs, because the cached zkversion doesn't match the one in zookeeper.  This is causing permanently under-replicated partitions, because server doesn't ever catch up, since it doesn't think there's a problem.  Also, the metadata reported by the 101 server to consumers indicates it thinks it's part of the ISR, but every other broker doesn't think so.

Let me know if more logs/details would be helpful.  I'll try to fix this by restarting the node, and hopefully it fixes the issue.;;;","07/Mar/17 08:02;junrao;[~mjuarez], did you see ZK session expiration in the server.log in the controller around that time? The log will look like the following.

INFO zookeeper state changed (Expired) (org.I0Itec.zkclient.ZkClient);;;","21/Mar/17 10:23;Ronghua Lin;[~junrao], we also have this problem in a small cluster which has 3 brokers, running Kafka 0.10.1.1. When it happened, the logs of each broker look like this:
{code:title=broker 2 | borderStyle=solid}
[2017-03-20 01:03:48,903] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2017-03-20 01:13:27,283] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-03-20 01:13:27,293] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-03-20 01:13:27,294] INFO 2 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2017-03-20 01:13:28,203] INFO re-registering broker info in ZK for broker 2 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2017-03-20 01:13:28,205] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-03-20 01:13:28,218] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-03-20 01:13:28,219] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT -> EndPoint(xxxxx, xxxx,PLAINTEXT) (kafka.utils.ZkUtils)
[2017-03-20 01:13:28,219] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2017-03-20 01:13:28,220] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2017-03-20 01:13:28,224] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2017-03-20 01:13:28,227] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2017-03-20 01:13:38,812] INFO Partition [topic1,1] on broker 2: Shrinking ISR for partition [topic1,1] from 0,2,1 to 2,1 (kafka.cluster.Partition)
[2017-03-20 01:13:38,825] INFO Partition [topic1,1] on broker 2: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-03-20 01:13:38,825] INFO Partition [topic2,1] on broker 2: Shrinking ISR for partition [topic2,1] from 0,2,1 to 2,1 (kafka.cluster.Partition)
[2017-03-20 01:13:38,835] INFO Partition [topic2,1] on broker 2: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-03-20 01:13:38,835] INFO Partition [topic3,0] on broker 2: Shrinking ISR for partition [topic3,0] from 0,2,1 to 2,1 (kafka.cluster.Partition)
[2017-03-20 01:13:38,847] INFO Partition [topic3,0] on broker 2: Cached zkVersion [6] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
....
{code}

{code:title=broker 1 | borderStyle=solid}
[2017-03-20 01:03:38,255] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2017-03-20 01:13:27,451] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2017-03-20 01:13:27,490] INFO re-registering broker info in ZK for broker 1 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2017-03-20 01:13:27,491] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-03-20 01:13:27,503] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-03-20 01:13:27,503] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT -> EndPoint(xxxx,xxxx,PLAINTEXT) (kafka.utils.ZkUtils)
[2017-03-20 01:13:27,504] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2017-03-20 01:13:27,504] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2017-03-20 01:13:27,508] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2017-03-20 01:13:38,134] INFO Partition [__consumer_offsets,40] on broker 1: Shrinking ISR for partition [__consumer_offsets,40] from 1,0 to 1 (kafka.cluster.Partition)
[2017-03-20 01:13:38,155] INFO Partition [__consumer_offsets,40] on broker 1: Cached zkVersion [2] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-03-20 01:13:38,156] INFO Partition [__consumer_offsets,0] on broker 1: Shrinking ISR for partition [__consumer_offsets,0] from 1,0 to 1 (kafka.cluster.Partition)
[2017-03-20 01:13:38,161] INFO Partition [__consumer_offsets,0] on broker 1: Cached zkVersion [2] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-03-20 01:13:38,162] INFO Partition [__consumer_offsets,12] on broker 1: Shrinking ISR for partition [__consumer_offsets,12] from 1,0 to 1 (kafka.cluster.Partition)
[2017-03-20 01:13:38,170] INFO Partition [__consumer_offsets,12] on broker 1: Cached zkVersion [2] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-03-20 01:13:38,171] INFO Partition [__consumer_offsets,14] on broker 1: Shrinking ISR for partition [__consumer_offsets,14] from 1,0 to 1 (kafka.cluster.Partition)
[2017-03-20 01:13:38,191] INFO Partition [__consumer_offsets,14] on broker 1: Cached zkVersion [2] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-03-20 01:13:38,191] INFO Partition [__consumer_offsets,24] on broker 1: Shrinking ISR for partition [__consumer_offsets,24] from 1,0 to 1 (kafka.cluster.Partition)
[2017-03-20 01:13:38,200] INFO Partition [__consumer_offsets,24] on broker 1: Cached zkVersion [2] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-03-20 01:13:38,200] INFO Partition [__consumer_offsets,48] on broker 1: Shrinking ISR for partition [__consumer_offsets,48] from 1,0 to 1 (kafka.cluster.Partition)
[2017-03-20 01:13:38,209] INFO Partition [__consumer_offsets,48] on broker 1: Cached zkVersion [2] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-03-20 01:13:38,209] INFO Partition [__consumer_offsets,2] on broker 1: Shrinking ISR for partition [__consumer_offsets,2] from 1,0 to 1 (kafka.cluster.Partition)
[2017-03-20 01:13:38,215] INFO Partition [__consumer_offsets,2] on broker 1: Cached zkVersion [2] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-03-20 01:13:38,216] INFO Partition [__consumer_offsets,32] on broker 1: Shrinking ISR for partition [__consumer_offsets,32] from 1,0 to 1 (kafka.cluster.Partition)
{code}

{code:title=broker 0 | borderStyle=solid}
[2017-03-20 01:03:09,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2017-03-20 01:13:09,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2017-03-20 01:13:27,317] INFO re-registering broker info in ZK for broker 0 (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2017-03-20 01:13:27,320] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2017-03-20 01:13:27,333] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2017-03-20 01:13:27,333] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(xxxx,xxxx,PLAINTEXT) (kafka.utils.ZkUtils)
[2017-03-20 01:13:27,333] INFO done re-registering broker (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2017-03-20 01:13:27,334] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck$SessionExpireListener)
[2017-03-20 01:13:27,342] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2017-03-20 01:13:27,362] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2017-03-20 01:13:28,128] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions xxxxx,xxxxx(all topics) (kafka.server.ReplicaFetcherManager)
[2017-03-20 01:13:28,142] INFO [ReplicaFetcherThread-0-2], Shutting down (kafka.server.ReplicaFetcherThread)
[2017-03-20 01:13:28,465] INFO [ReplicaFetcherThread-0-2], Stopped  (kafka.server.ReplicaFetcherThread)
[2017-03-20 01:13:28,465] INFO [ReplicaFetcherThread-0-2], Shutdown completed (kafka.server.ReplicaFetcherThread)
[2017-03-20 01:13:28,481] INFO [ReplicaFetcherThread-0-1], Shutting down (kafka.server.ReplicaFetcherThread)
[2017-03-20 01:13:28,597] INFO [ReplicaFetcherThread-0-1], Stopped  (kafka.server.ReplicaFetcherThread)
[2017-03-20 01:13:28,597] INFO [ReplicaFetcherThread-0-1], Shutdown completed (kafka.server.ReplicaFetcherThread)
{code}
The broker 0 worked fine. But broker 1 and broker 2(leader) had the same problem. Notice that the topics in broker 1 and broker 2 which refused to update the ISRs are different. Not all the topic in Kafka cluster were refusing to update ISRs.;;;","23/Mar/17 08:40;stephane.maarek@gmail.com;If I may add, this is a pretty bad issue, but it got worse. You not only have to recover Kafka, but also recover your Kafka Connect ClusterS. They got stuck for me in the following state:

[2017-03-23 00:06:05,478] INFO Marking the coordinator kafka-1:9092 (id: 2147483626 rack: null) dead for group connect-MyConnector (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[2017-03-23 00:06:05,478] INFO Marking the coordinator kafka-1:9092 (id: 2147483626 rack: null) dead for group connect-MyConnector (org.apache.kafka.clients.consumer.internals.AbstractCoordinator);;;","30/Mar/17 00:58;sam.nguyen@sendgrid.com;We ran into this today on kafka_2.11-0.10.0.1.

There is unexpected behavior with regards to partition availability.  One out of 3 total brokers in our cluster entered this state (emitting ""Cached zkVersion [140] not equal to that in zookeeper, skip updating ISR"" errors).  

We have our producer ""required acks"" config set to wait for all (-1), and the min.insync.replicas set to 2.  I would have expected to be able to still be able to produce to the topic, but our producer (sarama) was getting timeouts.  After restarting the broken broker, we were able to continue producing.

I confirmed that even after performing a graceful shutdown on 1 out of 3 brokers, we are still able to produce since we have 2 out of 3 brokers still alive to serve produce and acknowledge produce requests.;;;","09/Apr/17 17:48;allenzhuyi;we see the bug in kafka_2.12-0.10.2.0,when there is long lantency ping timeout.We have 3 brokers,2 Brokes find the error below
[
Partition [__consumer_offsets,9] on broker 3: Shrinking ISR for partition [__consumer_offsets,9] from 3,1,2 to 3,2 (kafka.cluster.Paition)
Partition [__consumer_offsets,9] on broker 3: Cached zkVersion [89] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
]
but another one  broker does'n realize the bug,the producer continuly report timeout exception and send message fail,Until finally  the broker zk session expired and re-registering broker info in ZK for broker. The System is recovered.
It is a serious bug,Please help us to solve it quickly.
Thank you.;;;","13/Apr/17 23:09;junrao;Thanks for the additional info. In both [~Ronghua Lin] and [~allenzhuyi]'s case, it seems ZK session expiration had happened. As I mentioned earlier in the jira, there is a known issue reported in KAFKA-3083 that when the controller's ZK session expires and loses its controller-ship, it's possible for this zombie controller to continue updating ZK and/or sending LeaderAndIsrRequests to the brokers for a short period of time. When this happens, the broker may not have the most up-to-date information about leader and isr, which can lead to subsequent ZK failure when isr needs to be updated.

It may take some time to have this issue fixed. In the interim, the workaround for this issue is to make sure ZK session expiration never happens. This first thing is to figure out what's causing the ZK session to expire. Two common causes are (1) long broker GC and (2) network glitches. For (1), one needs to tune the GC in the broker properly. For (2), one can look at the reported time that the ZK client can't hear from the ZK server and increase the ZK session expiration time according.;;;","13/Apr/17 23:25;ecomar;FWIW - we saw the same message 
{{  Cached zkVersion [66] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition) }}

when redeploying kafka 0.10.0.1 in a cluster after we had run 0.10.2.0
after having wiped kafka's storage, but having kept zookeeper's version (the one bundled with kafka 0.10.2) and its storage

For us eventually the cluster recovered.
HTH.;;;","08/Jun/17 18:58;padilo;Guys, this issue is not only affecting to 0.8.2.1 as many people here are saying. We had this same problem on a 0.10.2 during an upgrade from 0.8.2, we workaround it increasing the zk session and connection timeouts and worked fine, but we don't feel very safe.

I suggest to add all the affected versions people are saying.;;;","23/Jun/17 05:34;timoha;Seeing the same issue on 0.10.2. 

A node running zookeeper lost networking for split second and initiated an election which caused some sessions to expire with:


{noformat}
2017-06-22 02:07:36,092 [myid:3] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running
{noformat}


which caused controller resignation:


{noformat}
[2017-06-22 02:07:36,363] INFO [SessionExpirationListener on 158980], ZK expired; shut down all controller components and try to re-elect (kafka.controller.KafkaController$SessionExpirationListener)
[2017-06-22 02:07:37,028] DEBUG [Controller 158980]: Controller resigning, broker id 158980 (kafka.controller.KafkaController)
[2017-06-22 02:07:37,028] DEBUG [Controller 158980]: De-registering IsrChangeNotificationListener (kafka.controller.KafkaController)
[2017-06-22 02:07:37,028] INFO [Partition state machine on Controller 158980]: Stopped partition state machine (kafka.controller.PartitionStateMachine)
[2017-06-22 02:07:37,028] INFO [Replica state machine on controller 158980]: Stopped replica state machine (kafka.controller.ReplicaStateMachine)
[2017-06-22 02:07:37,028] INFO [Controller 158980]: Broker 158980 resigned as the controller (kafka.controller.KafkaController)
{noformat}


and after that just kept getting this in broker's server logs for next 8 hours until just restarting manually it:

{noformat}
[2017-06-22 17:41:06,928] INFO Partition [A,5] on broker 158980: Shrinking ISR for partition [A,5] from 158980,133641,155394 to 158980 (kafka.cluster.Partition)
[2017-06-22 17:41:06,935] INFO Partition [A,5] on broker 158980: Cached zkVersion [73] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
{noformat};;;","23/Jun/17 06:21;junrao;[~timoha], we are trying to address the ZK session expiration issue in the controller improvement work under https://issues.apache.org/jira/browse/KAFKA-5027.;;;","31/Jul/17 16:24;MiniMizer;Happened in 0.11.0.0 as well. Had to restart the broker to bring it back to operational state.;;;","31/Jul/17 17:36;padilo;Happened to us with timeout workaround:

{code:java}
zookeeper.connection.timeout.ms=10000
zookeeper.session.timeout.ms=10000
{code}

On AWS eu-west-1 on saturday using a 0.10.2.0 cluster of 3 brokers and 3 zks with message format 0.8.2.0.

;;;","18/Aug/17 05:39;joseph.aliase07@gmail.com;Have happened to us twice in Prod. Restart seems to be a only solution. ;;;","30/Aug/17 00:46;davispw;[~junrao] Per your previous [comment|https://issues.apache.org/jira/browse/KAFKA-2729?focusedCommentId=16060110&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16060110], is this issue definitely covered under KAFKA-5027 then?  It is not linked there.

EDIT: fixed link;;;","07/Sep/17 06:25;junrao;[~davispw], the issue due to ZK session expiration will be addressed in KAFKA-5642.;;;","09/Oct/17 19:55;sumit.jain;Facing the same issue.. here's the question I asked on stack overflow https://stackoverflow.com/questions/46644764/kafka-cached-zkversion-not-equal-to-that-in-zookeeper-broker-not-recovering;;;","13/Oct/17 16:47;fravigotti;I'm having the same issue and definitely losing trust in kafka, every 2 months there is something that force me to reset the whole cluster, I'm searching for a good alternative for a distributed-persisted-fast-queue for a while.. yet to find something that give me a good vibe.. 

anyway I'm facing this same issue with some small differences
- restarting all brokers ( together and rolling-restart ) didn't fix it..

all brokers in the cluster log such errors :
--- broker 5 

{code:java}

[2017-10-13 08:13:57,429] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,17] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2017-10-13 08:13:57,429] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,23] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2017-10-13 08:13:57,429] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,47] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2017-10-13 08:13:57,429] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,29] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)

{code}

--- broker3

)
{code:java}

[2017-10-13 08:13:58,547] INFO Partition [__consumer_offsets,20] on broker 3: Expanding ISR for partition __consumer_offsets-20 from 3,2 to 3,2,5 (kafka.cluster.Partition)
[2017-10-13 08:13:58,551] INFO Partition [__consumer_offsets,44] on broker 3: Expanding ISR for partition __consumer_offsets-44 from 3,2 to 3,2,5 (kafka.cluster.Partition)
[2017-10-13 08:13:58,554] INFO Partition [__consumer_offsets,5] on broker 3: Expanding ISR for partition __consumer_offsets-5 from 2,3 to 2,3,5 (kafka.cluster.Partition)
[2017-10-13 08:13:58,557] INFO Partition [__consumer_offsets,26] on broker 3: Expanding ISR for partition __consumer_offsets-26 from 3,2 to 3,2,5 (kafka.cluster.Partition)
[2017-10-13 08:13:58,563] INFO Partition [__consumer_offsets,29] on broker 3: Expanding ISR for partition __consumer_offsets-29 from 2,3 to 2,3,5 (kafka.cluster.Partition)
[2017-10-13 08:13:58,566] INFO Partition [__consumer_offsets,32] on broker 3: Expanding ISR for partition __consumer_offsets-32 from 3,2 to 3,2,5 (kafka.cluster.Partition)
[2017-10-13 08:13:58,570] INFO Partition [legacyJavaVarT,2] on broker 3: Expanding ISR for partition legacyJavaVarT-2 from 3 to 3,5 (kafka.cluster.Partition)
[2017-10-13 08:13:58,573] INFO Partition [test4,3] on broker 3: Expanding ISR for partition test4-3 from 2,3 to 2,3,5 (kafka.cluster.Partition)
[2017-10-13 08:13:58,577] INFO Partition [test4,0] on broker 3: Expanding ISR for partition test4-0 from 3,2 to 3,2,5 (kafka.cluster.Partition)
[2017-10-13 08:13:58,582] INFO Partition [test3,5] on broker 3: Expanding ISR for partition test3-5 from 3 to 3,5 (kafka.cluster.Partition)

{code}


--- broker2 

{code:java}

[2017-10-13 08:13:36,289] INFO Partition [__consumer_offsets,11] on broker 2: Expanding ISR for partition __consumer_offsets-11 from 2,5 to 2,5,3 (kafka.cluster.Partition)
[2017-10-13 08:13:36,293] INFO Partition [__consumer_offsets,41] on broker 2: Expanding ISR for partition __consumer_offsets-41 from 2,5 to 2,5,3 (kafka.cluster.Partition)
[2017-10-13 08:13:36,296] INFO Partition [test3,2] on broker 2: Expanding ISR for partition test3-2 from 2 to 2,3 (kafka.cluster.Partition)
[2017-10-13 08:13:36,300] INFO Partition [__consumer_offsets,23] on broker 2: Expanding ISR for partition __consumer_offsets-23 from 2,5 to 2,5,3 (kafka.cluster.Partition)
[2017-10-13 08:13:36,304] INFO Partition [__consumer_offsets,5] on broker 2: Expanding ISR for partition __consumer_offsets-5 from 2,5 to 2,5,3 (kafka.cluster.Partition)
[2017-10-13 08:13:36,337] INFO Partition [__consumer_offsets,35] on broker 2: Expanding ISR for partition __consumer_offsets-35 from 2,5 to 2,5,3 (kafka.cluster.Partition)
[2017-10-13 08:13:36,372] INFO Partition [test_mainlog,24] on broker 2: Expanding ISR for partition test_mainlog-24 from 2 to 2,3 (kafka.cluster.Partition)
[2017-10-13 08:13:36,375] INFO Partition [test_mainlog,6] on broker 2: Expanding ISR for partition test_mainlog-6 from 2 to 2,3 (kafka.cluster.Partition)
[2017-10-13 08:13:36,379] INFO Partition [test_mainlog,18] on broker 2: Expanding ISR for partition test_mainlog-18 from 2 to 2,3 (kafka.cluster.Partition)
[2017-10-13 08:13:36,384] INFO Partition [test_mainlog,0] on broker 2: Expanding ISR for partition test_mainlog-0 from 2 to 2,3 (kafka.cluster.Partition)
[2017-10-13 08:13:36,388] INFO Partition [test_mainlog,12] on broker 2: Expanding ISR for partition test_mainlog-12 from 2 to 2,3 (kafka.cluster.Partition)
[2017-10-13 08:13:40,367] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions __consumer_offsets-47 (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,367] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[2017-10-13 08:13:40,374] INFO [ReplicaFetcherThread-0-3], Starting  (kafka.server.ReplicaFetcherThread)
[2017-10-13 08:13:40,374] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([__consumer_offsets-47, initOffset 0 to broker BrokerEndPoint(3,--hidden----.73,9092)] ) (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,376] ERROR [ReplicaFetcherThread-0-3], Error for partition [__consumer_offsets,47] to broker 3:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2017-10-13 08:13:40,393] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions __consumer_offsets-29 (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,393] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[2017-10-13 08:13:40,402] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([__consumer_offsets-29, initOffset 0 to broker BrokerEndPoint(3,--hidden----.73,9092)] ) (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,403] ERROR [ReplicaFetcherThread-0-3], Error for partition [__consumer_offsets,29] to broker 3:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2017-10-13 08:13:40,407] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions __consumer_offsets-41 (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,407] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[2017-10-13 08:13:40,413] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([__consumer_offsets-41, initOffset 0 to broker BrokerEndPoint(3,--hidden----.73,9092)] ) (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,414] ERROR [ReplicaFetcherThread-0-3], Error for partition [__consumer_offsets,41] to broker 3:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2017-10-13 08:13:40,419] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions test_mainlog-6 (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,419] INFO Truncating log test_mainlog-6 to offset 4997933406. (kafka.log.Log)
[2017-10-13 08:13:40,425] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([test_mainlog-6, initOffset 4997933406 to broker BrokerEndPoint(3,--hidden----.73,9092)] ) (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,432] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions __consumer_offsets-17 (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,432] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[2017-10-13 08:13:40,438] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([__consumer_offsets-17, initOffset 0 to broker BrokerEndPoint(3,--hidden----.73,9092)] ) (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,443] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions test_mainlog-0 (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,443] INFO Truncating log test_mainlog-0 to offset 5704085814. (kafka.log.Log)
[2017-10-13 08:13:40,449] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([test_mainlog-0, initOffset 5704085814 to broker BrokerEndPoint(3,--hidden----.73,9092)] ) (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,464] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions __consumer_offsets-14 (kafka.server.ReplicaFetcherManager)
[2017-10-13 08:13:40,464] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[2017-10-13 08:13:40,472] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([__consumer_offsets-14, initOffset 0 to broker BrokerEndPoint(3,--hidden----.73,9092)] ) (kafka.server.ReplicaFetcherManager)

{code}







those logs goes for hours and the cluster never recover, the only things that change something is when I repeatedly from zookeeper
delete /controller # repeatedly untill it get assigned to kafka3 node 

and at this point all errors stop ( no more error logs ) , kafka seems working, kafkamanager show offsets for all partitions ( while some offset was missing ) , data ingestion /consumption works , the only things that presages something wrong is that on one topic with 30 partitions and replication 2 there is 1 broker skew ( 1 broker have 1 partitions more than normal and one broker have 1 partition less than normal )
and the situation remain stable with this small anomaly for hours..  nodes delete indexes, delete segments , roll new segments.. 

If i now delete the controller again, or restart the kafka3-node evreything goes to the previous situation again ( all errors logged ) and at this point I don't even know how to recover , the only ""fix"" I'm left to try is to wipe the whole cluster data and restart  :( but what to do then if this happens again in future ?

I don't know why two nodes seems to have a (""broken controller"" ??) and the cluster remain in this in-consistent state forever.. 
If you have any suggestion... on what to inspect / how to try to fix , those are very welcomed..

Thank you,
Francesco

;;;","13/Oct/17 16:59;ijuma;[~fravigotti], none of your log messages seems to be about the zkVersion issue, is it really the same issue as this one? If not, you should file a separate JIRA including the Kafka version.;;;","13/Oct/17 17:58;fravigotti;At the beginning of my cluster screw up I've got tons of zkVersion issue that's why I've posted here , but because seems that the problems for you goes away when you restarted your brokers maybe my problem is different.. 
kafka version : 0.10.2.1;;;","14/Oct/17 00:00;fravigotti;After having lost 2 days on this I've reset whole cluster, stopped all kafka brokers, stopped zookeeper cluster, delete all directories,stopped all consumer and producer ,then restarted everything , recreated topics and now guess what? :)

one node reports... 
{code:java}

[2017-10-13 15:54:52,893] INFO Partition [__consumer_offsets,5] on broker 2: Expanding ISR for partition __consumer_offsets-5 from 10,13,2 to 10,13,2,5 (kafka.cluster.Partition)
[2017-10-13 15:54:52,906] INFO Partition [__consumer_offsets,5] on broker 2: Cached zkVersion [13] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-10-13 15:54:52,908] INFO Partition [__consumer_offsets,25] on broker 2: Expanding ISR for partition __consumer_offsets-25 from 10,2,13 to 10,2,13,5 (kafka.cluster.Partition)
[2017-10-13 15:54:52,915] INFO Partition [__consumer_offsets,25] on broker 2: Cached zkVersion [10] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-10-13 15:54:52,916] INFO Partition [__consumer_offsets,45] on broker 2: Expanding ISR for partition __consumer_offsets-45 from 10,13,2 to 10,13,2,5 (kafka.cluster.Partition)
[2017-10-13 15:54:52,925] INFO Partition [__consumer_offsets,45] on broker 2: Cached zkVersion [15] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-10-13 15:54:52,926] INFO Partition [__consumer_offsets,5] on broker 2: Expanding ISR for partition __consumer_offsets-5 from 10,13,2 to 10,13,2,5 (kafka.cluster.Partition)
[2017-10-13 15:54:52,936] INFO Partition [__consumer_offsets,5] on broker 2: Cached zkVersion [13] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2017-10-13 15:54:52,939] INFO Partition [__consumer_offsets,25] on broker 2: Expanding ISR for partition __consumer_offsets-25 from 10,2,13 to 10,2,13,5 (kafka.cluster.Partition)
{code}

while others 


{code:java}
[2017-10-13 15:57:08,128] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,40] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2017-10-13 15:57:09,129] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,40] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2017-10-13 15:57:10,260] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,40] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2017-10-13 15:57:11,262] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,40] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2017-10-13 15:57:12,265] ERROR [ReplicaFetcherThread-0-2], Error for partition [__consumer_offsets,40] to broker 2:org.apache.kafka.common.errors.NotLeaderForPartitionException: This server is not the leader for that topic-partition. (kafka.server.ReplicaFetcherThread)
[2017-10-13 15:57:13,289] ERROR [ReplicaFetcherThread-0-2], Error fo
{code}


cluster still being inconsistent, I've also added 2 more nodes hoping in an increasing of stability but nothing, I don't know if something is wrong because if kafka do some kind of pre-flight checks during startup it does log nothing.. the only logs are those which have no sense because the leader should be re-elected when there are ISR available.. and there are 
I've started looking for an alternative software to  use, I'm trying to use kafka is so frustrating :(
;;;","14/Oct/17 00:12;ijuma;If you're seeing the issue this often, then there's most likely a configuration issue. If you file a separate issue with all the logs (including GC logs) and configs (broker and ZK), maybe someone can help.;;;","14/Oct/17 07:52;junrao;[~fravigotti], sorry to hear that. A couple of quick suggestions.

(1) Do you see any ZK session expiration in the log (e.g., INFO zookeeper state changed (Expired) (org.I0Itec.zkclient.ZkClient))? There are known bugs in Kafka in handling ZK session expiration. So, it would be useful to avoid it in the first place. Typical causes of ZK session expiration are long GC in the broker or network glitches. So you can either tune the broker or increase zookeeper.session.timeout.ms.

(2) Do you have lots of partitions (say a few thousands) per broker? If so, you want to check if the controlled shutdown succeeds when shutting down a broker. If not, restarting the broker too soon could also lead the cluster to a weird state. To address this issue, you can increase request.timeout.ms on the broker.

We are fixing the known issue in (1) and improving the performance with lots of partitions in (2) in KAFKA-5642 and we expect the fix to be included in the 1.1.0 release in Feb.;;;","26/Oct/17 18:34;fravigotti;I've maybe found the problem to my issue which maybe is not related to this topic because in my case simple broker restart didn't worked, I've create a dedicated issue then... https://issues.apache.org/jira/browse/KAFKA-6129
;;;","23/Dec/17 02:34;ijuma;We believe this is fixed in trunk (to become 1.1.0). If someone sees this again with that version, please reopen.;;;","22/Jan/18 21:48;dawg;Confirmed that for me all occurrences of this issue were preceded by ZK session timeouts/expirations. Looking forward to have this finally fixed.;;;","27/Jan/18 02:09;simonxia;Happened to me several times，version 0.10.0.0  

timeline goes as
 # [2018-01-24 13:07:40] broker 18, the old controller expired
 # [2018-01-24 13:07:41,176] broker 26, then took the controller
 # [2018-01-24 13:07:40,293] broker 18 resigned as the controller
 # [2018-01-24 13:07:41,176] broker 16 successfully elected as leader
 # [2018-01-24 13:08:17,928] broker 26 resigned as the controller

 

and then repeated log show on broker 18

 
{code:java}
 [2018-01-24 13:07:59,138] INFO Partition [fusion-rtlog-std-prod,21] on broker 18: Cached zkVersion [422946] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)  
{code}
 

 all related log can be found in [https://drive.google.com/file/d/1g7tf2YYP9AuwBYe4yMLVCgxDmmc2d_dc/view?usp=sharing]

ps: I recovered from this by restarting current controller, which is killed the current controller and a new election is triggered, then everything is ok;;;","27/Jan/18 06:44;oleksiys;[~ijuma] can you please provide more information on the issue you guys fixed, because here people report issues, which may or may not be related, so it would be good to understand what exactly you guys were able to reproduce and fix.;;;","27/Jan/18 08:52;junrao;The problem that we fixed related to this jira is KAFKA-5642. Previously, when the controller's ZK session expires and loses its controller-ship, it's possible for this zombie controller to continue updating ZK and/or sending LeaderAndIsrRequests to the brokers for a short period of time. When this happens, the broker may not have the most up-to-date information about leader and isr, which can lead to subsequent ZK failure when isr needs to be updated. KAFKA-5642 fixes the issue by handling the ZK session expiration event properly.;;;","27/Jan/18 09:46;oleksiys;Thank you, that really helped!;;;","06/Oct/18 05:46;ltagliamonte;This issue seems not fixed in 1.1

Cluster details:
 * 3 Kafka nodes cluster running 1.1
 * 3 Zookeeper node cluster running 3.4.10

Today meanwhile I was replacing a zookeeper server the leader among the brokers experienced this issue:
{code:java}
[2018-10-05 21:03:02,799] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2018-10-05 21:08:20,060] INFO Unable to read additional data from server sessionid 0x34663b434985000e, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2018-10-05 21:08:21,001] INFO Opening socket connection to server 10.48.208.70/10.48.208.70:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2018-10-05 21:08:21,003] WARN Session 0x34663b434985000e for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
[2018-10-05 21:08:21,797] INFO Opening socket connection to server 10.48.210.44/10.48.210.44:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2018-10-05 21:08:21,799] INFO Socket connection established to 10.48.210.44/10.48.210.44:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2018-10-05 21:08:21,802] INFO Session establishment complete on server 10.48.210.44/10.48.210.44:2181, sessionid = 0x34663b434985000e, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2018-10-05 21:08:28,015] INFO Creating /controller (is it secure? false) (kafka.zk.KafkaZkClient)
[2018-10-05 21:08:28,015] INFO Creating /controller (is it secure? false) (kafka.zk.KafkaZkClient)
[2018-10-05 21:08:28,025] ERROR Error while creating ephemeral at /controller, node already exists and owner '3703712903740981258' does not match current session '3775770497779040270' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2018-10-05 21:08:28,025] ERROR Error while creating ephemeral at /controller, node already exists and owner '3703712903740981258' does not match current session '3775770497779040270' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2018-10-05 21:08:28,025] INFO Result of znode creation at /controller is: NODEEXISTS (kafka.zk.KafkaZkClient)
[2018-10-05 21:08:28,025] INFO Result of znode creation at /controller is: NODEEXISTS (kafka.zk.KafkaZkClient)
[2018-10-05 21:08:42,561] INFO [Partition <PT_NAME>-store-changelog-7 broker=1] Shrinking ISR from 2,1,3 to 1 (kafka.cluster.Partition)
[2018-10-05 21:08:42,561] INFO [Partition <PT_NAME>-store-changelog-7 broker=1] Shrinking ISR from 2,1,3 to 1 (kafka.cluster.Partition)
[2018-10-05 21:08:42,569] INFO [Partition <PT_NAME>-store-changelog-7 broker=1] Cached zkVersion [11] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2018-10-05 21:08:42,569] INFO [Partition <PT_NAME>-store-changelog-7 broker=1] Cached zkVersion [11] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2018-10-05 21:08:42,569] INFO [Partition <PT_NAME>bycontact_0-19 broker=1] Shrinking ISR from 2,1,3 to 1 (kafka.cluster.Partition)
[2018-10-05 21:08:42,569] INFO [Partition <PT_NAME>bycontact_0-19 broker=1] Shrinking ISR from 2,1,3 to 1 (kafka.cluster.Partition)
[2018-10-05 21:08:42,574] INFO [Partition <PT_NAME>bycontact_0-19 broker=1] Cached zkVersion [44] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2018-10-05 21:08:42,574] INFO [Partition <PT_NAME>bycontact_0-19 broker=1] Cached zkVersion [44] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition){code}
 The only way in order to recover was to restart the broker.;;;","13/Oct/18 01:11;adamkeyser;Still seeing it here as well - 1.1.1;;;","04/Dec/18 16:39;wangbo23;I also got the same problem with 1.1.0, whether there is a patch or version that solves this problem.;;;","05/Dec/18 10:12;junrao;We fixed another issue that can fail the re-creation of the broker registration in ZK in KAFKA-7165 in 2.2.0.;;;","13/Dec/18 00:24;murri71;[~junrao], this issue is not yet fixed it seems.   We, as others here, are experiencing the same loop replication of partitions when trying to delete topics via the bin/kakfa-topics command using 1.1 brokers.

If fixed as you say, could someone update the exact broker version where it is fixed?

If am torn to upgrade to 2.2 on the brokers, as this bug report does not reflect what you imply by your ""We fixed another issue"" - that is, assuming the issue is fixed - comment above.;;;","14/Dec/18 09:32;junrao;[~murri71], my earlier comment was referring to that we fixed the following issue in KAFKA-7165. It's possible that issue may suffice ""Cached zkVersion"" in some scenarios. I am not sure if there are other issues that can still lead to ""Cached zkVersion"". So, my recommendation is to upgrade to 2.2 when it's released and file a separate Jira if the issue still exists.

 
[2018-10-05 21:08:28,025] ERROR Error while creating ephemeral at /controller, node already exists and owner '3703712903740981258' does not match current session '3775770497779040270' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2018-10-05 21:08:28,025] ERROR Error while creating ephemeral at /controller, node already exists and owner '3703712903740981258' does not match current session '3775770497779040270' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2018-10-05 21:08:28,025] INFO Result of znode creation at /controller is: NODEEXISTS (kafka.zk.KafkaZkClient);;;","15/Apr/19 23:46;evildracula;Hello [~junrao], I'm now using 0.11.0.3 which is in affected versions. I would like to reproduce this issue in my DEV environment. Could you please help to provide reproduce steps? Many thanks.

I'm now reproducing by **systemctl start/stop iptables**  but failed.;;;","23/Apr/19 17:01;DEvil0000;[~evildracula] In an older version of kafka it was reproducable with a very high network load.

Possibly when switches/network is at its limits. Maybe in combination with dropped packets.

Try to add delay or load to the network and machines, maybe drop some amount of packets.;;;","26/Apr/19 21:16;evildracula;Thank you [~DEvil0000], I'm searching for if any git commits diff patch for fixing.;;;","19/Oct/20 01:14;manmedia@gmail.com;This has resurfaced for us in production environment yesterday and caused an outage. Has anyone else seen this issue recently? We are using Kafka 2.4.1 (through Confluent), but without any customisation. 

It'd be good to know if there are any steps to reproduce this successfully. The above mentioned test (network stretch or switching) is quite difficult for us to run at the moment. ;;;","03/Jan/21 01:14;victorgp;Yes, it seems this issue is not yet fixed. This should be reopened.

We just had this problem with version 1.1.0;;;","06/Jan/21 08:35;junrao;If you still see this issue, it would be useful to confirm the following.
 # Is ""Cached zkVersion"" for the same partition long lasting? Transient ""Cached zkVersion"" can happen and is ok.
 # Does the zkVersion for the partition state in ZK match that of the latest recorded zkVersion in the controller (logged in the state-change log)? If not, this indicates a potential problem in ZK.
 # Otherwise, did the broker receive the latest zkVersion in the leaderAndIsr request from the controller (logged in the state-change log)?;;;","24/Jun/21 15:09;l0co;This problem is certainly not fixed in `1.1.0` as we still experience it with this Kafka version. This ticket should be reopened, unless the problem is being resolved elsewhere (KAFKA-3042, KAFKA-7888?).

Our scenario is the following: we have `kafka0`, `kafka1` and `kafka2` nodes.

1. `kafka0` loses zookeper connection
{code:java}
WARN Unable to reconnect to ZooKeeper service, session 0x27a31276f6d0000 has expired (org.apache.zookeeper.ClientCnxn)
INFO Unable to reconnect to ZooKeeper service, session 0x27a31276f6d0000 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
INFO EventThread shut down for session: 0x27a31276f6d0000 (org.apache.zookeeper.ClientCnxn)
{code}
2. However, a second later the connection is established properly:
{code:java}
[ZooKeeperClient] Initializing a new session to [...] (kafka.zookeeper.ZooKeeperClient)
[2021-06-22 14:06:47,838] INFO Opening socket connection to server [...]. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2021-06-22 14:06:47,873] INFO Socket connection established to [...], initiating session (org.apache.zookeeper.ClientCnxn)
[2021-06-22 14:06:47,933] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2021-06-22 14:06:47,959] INFO Session establishment complete on server [...], sessionid = 0x27a31276f6d0003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
{code}
3. But a few seconds later `ReplicaFetcherThread` is shut down in `kafka0`:
{code:java}
INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
{code}
We suppose this shutdown is the source of the problem.

4. Now, because of no replication requests from `kafka0` to `kafka1` and `kafka2`, `kafka1` and `kafka2` shink ISR list and start to complain about zkVersion.
{code:java}
INFO [Partition __consumer_offsets-30 broker=1] Shrinking ISR from 1,2,0 to 1,2 (kafka.cluster.Partition)
INFO [Partition __consumer_offsets-30 broker=1] Cached zkVersion [212] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
{code}
This happens forever, until the whole cluster is restarted. Note, that cluster state is inconsistent now because `kafka0` stops to be a replica for `kafka1` and `kafka2`, but `kafka1` and `kafka2` are still working as replicas for `kafka0`. This is due to `ReplicationFetcherThread` has only been stopped in `kafka0`.

5. Finally, the whole kafka cluster doesn't work and stops processing events, at least for partitions leaded by `kafka0` because of:
{code:java}
ERROR [ReplicaManager broker=0] Error processing append operation on partition __consumer_offsets-18 (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.NotEnoughReplicasException: Number of insync replicas for partition __consumer_offsets-18 is [1], below required minimum [2]
{code}
We also suspect that in this scenario `kafka0` becomes a leader for all partitions, but this is not confirmed yet.

 ;;;","29/Jun/21 00:44;junrao;[~l0co], thanks for reporting this. The ""Cached zkVersion [212]"" error indicates the leader epoch was changed by the controller but somehow wasn't propagated to the broker. Could you grep for ""Partition __consumer_offsets-30"" in the controller and state-change log and see which controller changed the leader epoch corresponding to zk version 212 and whether the controller tried to propagate that info to the brokers?;;;","29/Jun/21 16:02;l0co;[~junrao] thanks for the reply. Unfortunately from preserved logs from this breakdown I only have this useful:
{code:java}
[2021-06-22 14:06:50,637] INFO 1/kafka0/server.log.2021-06-22-14: [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 117 from offset 2612283. Previous Leader Epoch was: 116 (kafka.cluster.Partition)
[2021-06-22 14:07:04,184] INFO 1/kafka1/server.log.2021-06-22-14: [Partition __consumer_offsets-30 broker=1] Shrinking ISR from 1,2,0 to 1,2 (kafka.cluster.Partition)
[2021-06-22 14:07:04,186] INFO 1/kafka1/server.log.2021-06-22-14: [Partition __consumer_offsets-30 broker=1] Cached zkVersion [212] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2021-06-22 14:07:09,146] INFO 1/kafka1/server.log.2021-06-22-14: [Partition __consumer_offsets-30 broker=1] Shrinking ISR from 1,2,0 to 1,2 (kafka.cluster.Partition)
[2021-06-22 14:07:09,147] INFO 1/kafka1/server.log.2021-06-22-14: [Partition __consumer_offsets-30 broker=1] Cached zkVersion [212] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
{code}
After the zookeeper reconnection in kafka0, kafka0 becomes the leader with epoch 117, and then kafka1 starts to complain that cached zkVersion is not 212, which is a greater number. What does it mean for you? We suspect that zookeeper of kafka0 has been disconnected from kafka1 and kafka2 zookeepers and established its own separate cluster, and then after all zookeepers got back into one cluster, it became inconsistent. Does it make sense for you?;;;","01/Jul/21 05:45;junrao;[~l0co] the leaderEpoch doesn't always match the zkVersion. For example, when the leader expands/shrinks ISR, it changes the zkVersion, but not the leaderEpoch.;;;","29/Jul/21 19:58;axrj;Hi [~junrao] ,

This was just hit in our production as well although I was able to resolve it by only restarting the broker that reported errors as opposed to the controller or the whole cluster.

Kafka version : 2.3.1

I can confirm the events are identical to what [~l0co]  explained above. 
 * ZK session disconnected on broker 5
 * Replica Fetchers stopped on other brokers
 * ZK Connection re-established on broker 5 after a few seconds
 * Broker 5 came back online and started reporting the ""Cached zkVersion[130] not equal to..."" and shrunk ISRs to only itself

As it didn't recover automatically, I restarted the broker after 30 minutes and it then went back to normal.

I did see that the controller tried to send correct metadata to broker 5 but which was rejected due to epoch inconsistency.
{noformat}
ERROR [KafkaApi-5] Error when handling request: clientId=21, correlationId=2, api=UPDATE_METADATA, body={controller_id=21,controller_epoch=53,broker_epoch=223338313060,topic_states=[{topic-a,partition_states=[{partition=0,controller_epoch=53,leader=25,leader_epoch=70,isr=[25,17],zk_version=131,replicas=[5,25,17],offline_replicas=[]}...
...
java.lang.IllegalStateException: Epoch 223338313060 larger than current broker epoch 223338311791
        at kafka.server.KafkaApis.isBrokerEpochStale(KafkaApis.scala:2612)
        at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:194)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:117)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
        at java.base/java.lang.Thread.run(Thread.java:834)
...
...
...
[2021-07-29 11:07:30,210] INFO [Partition topic-a-0 broker=5] Cached zkVersion [130] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
...

{noformat}
 

Preferred leader election error as seen on controller
{noformat}
[2021-07-29 11:11:57,432] ERROR [Controller id=21] Error completing preferred replica leader election for partition topic-a-0 (kafka.controller.KafkaController)
kafka.common.StateChangeFailedException: Failed to elect leader for partition topic-a-0 under strategy PreferredReplicaPartitionLeaderElectionStrategy
        at kafka.controller.ZkPartitionStateMachine$$anonfun$doElectLeaderForPartitions$3.apply(PartitionStateMachine.scala:381)
        at kafka.controller.ZkPartitionStateMachine$$anonfun$doElectLeaderForPartitions$3.apply(PartitionStateMachine.scala:378)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
        at kafka.controller.ZkPartitionStateMachine.doElectLeaderForPartitions(PartitionStateMachine.scala:378)
        at kafka.controller.ZkPartitionStateMachine.electLeaderForPartitions(PartitionStateMachine.scala:305)
        at kafka.controller.ZkPartitionStateMachine.doHandleStateChanges(PartitionStateMachine.scala:215)
        at kafka.controller.ZkPartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
        at kafka.controller.KafkaController.kafka$controller$KafkaController$$onPreferredReplicaElection(KafkaController.scala:646)
        at kafka.controller.KafkaController$$anonfun$checkAndTriggerAutoLeaderRebalance$3.apply(KafkaController.scala:995)
        at kafka.controller.KafkaController$$anonfun$checkAndTriggerAutoLeaderRebalance$3.apply(KafkaController.scala:976)
        at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)
        at kafka.controller.KafkaController.checkAndTriggerAutoLeaderRebalance(KafkaController.scala:976)
        at kafka.controller.KafkaController.processAutoPreferredReplicaLeaderElection(KafkaController.scala:1004)
        at kafka.controller.KafkaController.process(KafkaController.scala:1564)
        at kafka.controller.QueuedEvent.process(ControllerEventManager.scala:53)
        at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply$mcV$sp(ControllerEventManager.scala:137)
        at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:137)
        at kafka.controller.ControllerEventManager$ControllerEventThread$$anonfun$doWork$1.apply(ControllerEventManager.scala:137)
        at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:31)
        at kafka.controller.ControllerEventManager$ControllerEventThread.doWork(ControllerEventManager.scala:136)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89){noformat}
 

After the restart of broker-5, it was able to take back leadership of the desired partitions

 

Kindly let me know if anything else is needed.

 ;;;","10/Aug/21 02:30;junrao;[~axrj]: If broker 5's ZK session expires and gets re-established, its broker epoch will change. So, it's possible for broker 5 to receive and reject a LeaderAndIsr request from the controller temporarily. The question is whether broker 5 eventually receives the LeaderAndIsr request when the controller has detected the new broker registration. This can be verified from the controller and the state-change log.;;;","10/Jan/22 23:43;mgabriel;Hey [~junrao],

We also have the same issue recurring once a week in version 1.1.0, which is marked as the ""Fix version"".

We run a cluster with 3 Kafka Brokers:

Node-1
{code:java}
[2021-12-31 19:12:23,540] INFO [Partition topicXYZ-1 broker=1] Shrinking ISR from 5,3,1 to 5,1 (kafka.cluster.Partition)
[2021-12-31 19:12:23,544] INFO [Partition topicXYZ-1 broker=1] Cached zkVersion [326] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition){code}
On Node-2 we do not see any related message for the timeperiod

On Node-3 we have the following message, which we are not sure if its related at all.
{code:java}
2021-12-31 19:12:23,541 [myid:3] - INFO  [ProcessThread(sid:3 cport:-1)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x1004521e6ed0000 type:setData cxid:0xbca4 zxid:0x3a40000a372 txntype:-1 reqpath:n/a Error Path:/brokers/topics/topicXYZ/partitions/1/state Error:KeeperErrorCode = BadVersion for /brokers/topics/topicXYZ/partitions/1/state{code}
Do you have any idea what we could do or which data we could deliver to give you additional insights?

Thanks
Matthias;;;","11/Jan/22 02:19;junrao;[~mgabriel] : The BadVersion on ZK server just indicates that a conditional update has failed. It's the result and not the cause. To understand the cause, we need to know if the controller changed the metadata for partition topicXYZ-1 before the time when Cached zkVersion is reported. You can grep the state-change log in the controller to find that out. If the controller didn't make the change, you can parse the ZK commit log to see which client updated the partition metadata. If the controller did make the change, you can then look at the state-change log in node 1 to see if it has received the latest partition metadata from the controller.;;;","28/Jan/22 05:57;yzang;We are still seeing this issue for 2.7.0, I'm not sure if this issue is resolved or not. When this happens, we got partitions under minISR and produce requests starts to fail. This is often triggered when a single broker was restarted. ;;;","24/Jul/22 00:12;chenhaifeng;We saw this issue in 1.1 during kafka reconnects to zookeeper. It caused under minISR and got recovered in 2 minutes.;;;"
[0.8.0 - windows]  FATAL - [highwatermark-checkpoint-thread1] (Logging.scala:109) - Attempt to swap the new high watermark file with the old one failed,KAFKA-903,12647144,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,junrao,reefedjib,reefedjib,11/May/13 09:18,28/Sep/17 09:27,22/Mar/23 15:10,04/Jun/13 07:52,0.8.0,,,,,,0.8.0,,,,,,,core,,,,0,,,,,,"This FATAL shuts down both brokers on windows, 
{2013-05-10 18:23:57,636} DEBUG [local-vat] (Logging.scala:51) - Sending 1 
messages with no compression to [robert_v_2x0,0]
{2013-05-10 18:23:57,637} DEBUG [local-vat] (Logging.scala:51) - Producer 
sending messages with correlation id 178 for topics [robert_v_2x0,0] to 
broker 1 on 192.168.1.100:9093
{2013-05-10 18:23:57,689} FATAL [highwatermark-checkpoint-thread1] 
(Logging.scala:109) - Attempt to swap the new high watermark file with the 
old one failed
{2013-05-10 18:23:57,739}  INFO [Thread-4] (Logging.scala:67) - [Kafka 
Server 0], shutting down

Furthermore, attempts to restart them fail, with the following log:
{2013-05-10 19:14:52,156}  INFO [Thread-1] (Logging.scala:67) - [Kafka Server 0], started
{2013-05-10 19:14:52,157}  INFO [ZkClient-EventThread-32-localhost:2181] (Logging.scala:67) - New leader is 0
{2013-05-10 19:14:52,193} DEBUG [ZkClient-EventThread-32-localhost:2181] (ZkEventThread.java:79) - Delivering event #1 done
{2013-05-10 19:14:52,193} DEBUG [ZkClient-EventThread-32-localhost:2181] (ZkEventThread.java:69) - Delivering event #4 ZkEvent[Data of /controller_epoch changed sent to kafka.controller.ControllerEpochListener@5cb88f42]
{2013-05-10 19:14:52,210} DEBUG [SyncThread:0] (FinalRequestProcessor.java:78) - Processing request:: sessionid:0x13e9127882e0001 type:exists cxid:0x1d zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller_epoch
{2013-05-10 19:14:52,210} DEBUG [SyncThread:0] (FinalRequestProcessor.java:160) - sessionid:0x13e9127882e0001 type:exists cxid:0x1d zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller_epoch
{2013-05-10 19:14:52,213} DEBUG [Thread-1-SendThread(localhost:2181)] (ClientCnxn.java:838) - Reading reply sessionid:0x13e9127882e0001, packet:: clientPath:null serverPath:null finished:false header:: 29,3  replyHeader:: 29,37,0  request:: '/controller_epoch,T  response:: s{16,36,1368231712816,1368234889961,1,0,0,0,1,0,16} 
{2013-05-10 19:14:52,219}  INFO [Thread-5] (Logging.scala:67) - [Kafka Server 0], shutting down
","Windows 7 with SP 1; jdk 7_0_17; scala-library-2.8.2, probably copied on 4/30. kafka-0.8, built current on 4/30.

-rwx------+ 1 reefedjib None   41123 Mar 19  2009 commons-cli-1.2.jar
-rwx------+ 1 reefedjib None   58160 Jan 11 13:45 commons-codec-1.4.jar
-rwx------+ 1 reefedjib None  575389 Apr 18 13:41 commons-collections-3.2.1.jar
-rwx------+ 1 reefedjib None  143847 May 21  2009 commons-compress-1.0.jar
-rwx------+ 1 reefedjib None   52543 Jan 11 13:45 commons-exec-1.1.jar
-rwx------+ 1 reefedjib None   57779 Jan 11 13:45 commons-fileupload-1.2.1.jar
-rwx------+ 1 reefedjib None  109043 Jan 20  2008 commons-io-1.4.jar
-rwx------+ 1 reefedjib None  279193 Jan 11 13:45 commons-lang-2.5.jar
-rwx------+ 1 reefedjib None   60686 Jan 11 13:45 commons-logging-1.1.1.jar
-rwx------+ 1 reefedjib None 1891110 Apr 18 13:41 guava-13.0.1.jar
-rwx------+ 1 reefedjib None  206866 Apr  7 21:24 jackson-core-2.1.4.jar
-rwx------+ 1 reefedjib None  232245 Apr  7 21:24 jackson-core-asl-1.9.12.jar
-rwx------+ 1 reefedjib None   69314 Apr  7 21:24 jackson-dataformat-smile-2.1.4.jar
-rwx------+ 1 reefedjib None  780385 Apr  7 21:24 jackson-mapper-asl-1.9.12.jar
-rwx------+ 1 reefedjib None   47913 May  9 23:39 jopt-simple-3.0-rc2.jar
-rwx------+ 1 reefedjib None 2365575 Apr 30 13:06 kafka_2.8.0-0.8.0-SNAPSHOT.jar
-rwx------+ 1 reefedjib None  481535 Jan 11 13:46 log4j-1.2.16.jar
-rwx------+ 1 reefedjib None   20647 Apr 18 13:41 log4j-over-slf4j-1.6.6.jar
-rwx------+ 1 reefedjib None  251784 Apr 18 13:41 logback-classic-1.0.6.jar
-rwx------+ 1 reefedjib None  349706 Apr 18 13:41 logback-core-1.0.6.jar
-rwx------+ 1 reefedjib None   82123 Nov 26 13:11 metrics-core-2.2.0.jar
-rwx------+ 1 reefedjib None 1540457 Jul 12  2012 ojdbc14.jar
-rwx------+ 1 reefedjib None 6418368 Apr 30 08:23 scala-library-2.8.2.jar
-rwx------+ 1 reefedjib None 3114958 Apr  2 07:47 scalatest_2.10-1.9.1.jar
-rwx------+ 1 reefedjib None   25962 Apr 18 13:41 slf4j-api-1.6.5.jar
-rwx------+ 1 reefedjib None   62269 Nov 29 03:26 zkclient-0.2.jar
-rwx------+ 1 reefedjib None  601677 Apr 18 13:41 zookeeper-3.3.3.jar
",jkreps,junrao,nehanarkhede,reefedjib,seglo,sriramsub,tnachen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-876,,,,,,,,,,,,,,,,"11/May/13 13:04;junrao;kafka-903.patch;https://issues.apache.org/jira/secure/attachment/12582769/kafka-903.patch","12/May/13 06:09;junrao;kafka-903_v2.patch;https://issues.apache.org/jira/secure/attachment/12582802/kafka-903_v2.patch","29/May/13 12:47;junrao;kafka-903_v3.patch;https://issues.apache.org/jira/secure/attachment/12585155/kafka-903_v3.patch","12/May/13 06:10;junrao;kafka_2.8.0-0.8.0-SNAPSHOT.jar;https://issues.apache.org/jira/secure/attachment/12582803/kafka_2.8.0-0.8.0-SNAPSHOT.jar",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,327501,,,Mon Jun 03 23:52:27 UTC 2013,,,,,,,,,,"0|i1ki93:",327845,,,,,,,,,,,,,,,,,,,,"11/May/13 13:04;junrao;Attach a patch. Rob, could you give it a try?;;;","11/May/13 13:28;reefedjib;I'd love too.  Could you build me a jar and email it too me, please?  :)
;;;","11/May/13 13:53;junrao;Attach the kafka jar with the patch.;;;","11/May/13 14:32;reefedjib;That jar is missing a lot - it only has a MANIFEST.  Should I be able to do anything with it?;;;","11/May/13 23:39;junrao;Attach the right jar this time.;;;","12/May/13 00:09;reefedjib;It still fails.  Where should I look in the jar to ensure the patch is in there?  Which class method?   Also, could you generate a jar for me with sources?

thanks a lot and happy saturday!


{2013-05-11 10:00:58,630} DEBUG [local-vat] (Logging.scala:51) - Producer sent messages with correlation id 232 for topics [robert_v_2x0,0] to broker 0 on 192.168.1.100:9092
{2013-05-11 10:00:58,637} DEBUG [local-vat] (Logging.scala:51) - Getting broker partition info for topic robert_v_2x0
{2013-05-11 10:00:58,638} DEBUG [local-vat] (Logging.scala:51) - Partition [robert_v_2x0,0] has leader 0
{2013-05-11 10:00:58,639} DEBUG [local-vat] (Logging.scala:51) - Broker partitions registered for topic: robert_v_2x0 are 0
{2013-05-11 10:00:58,639} DEBUG [local-vat] (Logging.scala:51) - Sending 1 messages with no compression to [robert_v_2x0,0]
{2013-05-11 10:00:58,640} DEBUG [local-vat] (Logging.scala:51) - Producer sending messages with correlation id 234 for topics [robert_v_2x0,0] to broker 0 on 192.168.1.100:9092
{2013-05-11 10:00:58,648} DEBUG [kafka-request-handler-1] (Logging.scala:51) - [Kafka Request Handler 1 on Broker 0], handles request Request(1,sun.nio.ch.SelectionKeyImpl@2b12cf49,null,1368288058646,/192.168.1.100:60622)
{2013-05-11 10:00:58,649} DEBUG [kafka-request-handler-1] (Logging.scala:51) - Adding index entry 115 => 5220900 to 00000000000000000000.index.
{2013-05-11 10:00:58,650} DEBUG [kafka-request-handler-1] (Logging.scala:51) - Partition [robert_v_2x0,0] on broker 0: Highwatermark for partition [robert_v_2x0,0] updated to 116
{2013-05-11 10:00:58,650} DEBUG [kafka-request-handler-1] (Logging.scala:51) - [KafkaApi-0] Produce to local log in 2 ms
{2013-05-11 10:00:58,656} DEBUG [local-vat] (Logging.scala:51) - Producer sent messages with correlation id 234 for topics [robert_v_2x0,0] to broker 0 on 192.168.1.100:9092
{2013-05-11 10:00:58,666} DEBUG [local-vat] (Logging.scala:51) - Getting broker partition info for topic robert_v_2x0
{2013-05-11 10:00:58,667} DEBUG [local-vat] (Logging.scala:51) - Partition [robert_v_2x0,0] has leader 0
{2013-05-11 10:00:58,667} DEBUG [local-vat] (Logging.scala:51) - Broker partitions registered for topic: robert_v_2x0 are 0
{2013-05-11 10:00:58,669} DEBUG [local-vat] (Logging.scala:51) - Sending 1 messages with no compression to [robert_v_2x0,0]
{2013-05-11 10:00:58,670} DEBUG [local-vat] (Logging.scala:51) - Producer sending messages with correlation id 236 for topics [robert_v_2x0,0] to broker 0 on 192.168.1.100:9092
{2013-05-11 10:00:58,716} DEBUG [kafka-request-handler-0] (Logging.scala:51) - [Kafka Request Handler 0 on Broker 0], handles request Request(1,sun.nio.ch.SelectionKeyImpl@2b12cf49,null,1368288058674,/192.168.1.100:60622)
{2013-05-11 10:00:58,717} DEBUG [kafka-request-handler-0] (Logging.scala:51) - Adding index entry 116 => 5232005 to 00000000000000000000.index.
{2013-05-11 10:00:58,718} DEBUG [kafka-request-handler-0] (Logging.scala:51) - Partition [robert_v_2x0,0] on broker 0: Highwatermark for partition [robert_v_2x0,0] updated to 117
{2013-05-11 10:00:58,718} DEBUG [kafka-request-handler-0] (Logging.scala:51) - [KafkaApi-0] Produce to local log in 2 ms
{2013-05-11 10:00:58,726} FATAL [highwatermark-checkpoint-thread1] (Logging.scala:109) - Attempt to swap the new high watermark file with the old one failed
;;;","12/May/13 03:56;junrao;Hmm, this may have to do with Windows not supporting file.renameTo() if the target file already exists (http://stackoverflow.com/questions/1000183/reliable-file-renameto-alternative-on-windows). We periodically checkpoint high watermarks to disk. The way we do this is to first write all values to a tmp file replication-offset-checkpoint.tmp and then rename the tmp file to replication-offset-checkpoint. This way, if there is any I/O error during checkpointing, we still have the old checkpoint file for use. Not sure what the best way to do this in Windows.

Could you try java 7 and see if it still has the same issue (the above link suggests that it's fixed in jdk 7)?;;;","12/May/13 04:39;reefedjib;I am on jdk 7.0.17,  That thread mentions apache.commons.io.FileUtils.moveFile().   Also, my suggestion to be done with the issue: I know there is a way to detect platform, just write a small strategy pattern for the general platform and for windows and plug her in.;;;","12/May/13 06:09;junrao;Attach patch v2. If a file can't be renamed, it deletes the target file first. The implication is that during a hard crash, if the high watermark file is missing, one has to manually rename it from the temporary high watermark file.;;;","12/May/13 06:10;junrao;Deleted the old jar and a attach a new jar built with patch v2.;;;","13/May/13 05:50;reefedjib;Jun, it looks like this works.  I have 23 MB in the log file, on broker0.  No replication and I guess I am only sending to partition 0.  So, please close this issue.

I am still having trouble with consumption, but given it is a weekend, I am busy with other stuff.  I will dig in to it later and report my progress.  

Thanks for all your help,
rob;;;","17/May/13 02:31;jkreps;I don't think this rename functionality is such a good idea. There are many ways a rename can fail: (1) permissions, (2) disk errors, (3) bad target name, (4) rename is to another volume, etc. Java doesn't differentiate these, so in any of these cases we would then try to delete the file. Not sure this is a good idea.

Another approach would be to add a Utils.IsWindows = System.getProperty(""os.name"").startsWith(""Windows"") and using this to fall back to the funky non-atomic behavior.;;;","17/May/13 04:59;sriramsub;There are two claims in this JIRA -

1. ""this may have to do with Windows not supporting file.renameTo() if the target file already exists""
2. renameTo is not atomic in windows

Claim 1 is wrong. MoveFileEx is the native api that helps you to rename an existing file. ""MOVEFILE_REPLACE_EXISTING"" is the flag you would use. This might be a bug in the java api or as the SO link indicates, does not work for non empty directories. (http://msdn.microsoft.com/en-us/library/windows/desktop/aa365240(v=vs.85).aspx)

Claim 2 is possible depending on the OS settings. The caller of MoveFileEx is supposed to handle the failure.;;;","29/May/13 06:30;tnachen;Do you know when this is going to be pushed to 0.8 branch?;;;","29/May/13 12:47;junrao;Attach patch v3. 

To address Jay's concern, instead of using a generic renameTo util, only falls back to the non-atomic renameTo in checkpointing the high watermark file. Since both files are in the same dir and we control the naming, those other causes you listed that can fail renameTo won't happen. I didn't do the os level checking since I am not sure it that works well for environments like cygwin. We could guard this under a broker config parameter, but I am not sure if it's worth it.

For Sriram's concern, this seems to be at least a problem for some versions of java on Windows since other projects like Hadoop (https://issues.apache.org/jira/browse/HADOOP-959) have also seen this before.
  ;;;","01/Jun/13 01:56;nehanarkhede;+1 on v3;;;","04/Jun/13 07:32;jkreps;+1;;;","04/Jun/13 07:52;junrao;Thanks for the review. Committed v3 to 0.8.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
producer record can stay in RecordAccumulator forever if leader is no available,KAFKA-1788,12756628,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,parth.brahmbhatt,junrao,junrao,20/Nov/14 13:25,18/Aug/15 11:25,22/Mar/23 15:10,18/Aug/15 11:25,0.8.2.0,,,,,,0.9.0.0,,,,,,,core,producer ,,,1,newbie++,,,,,"In the new producer, when a partition has no leader for a long time (e.g., all replicas are down), the records for that partition will stay in the RecordAccumulator until the leader is available. This may cause the bufferpool to be full and the callback for the produced message to block for a long time.",,becket_qin,Bmis13,bpot,ewencp,jkreps,junrao,limbo,mgharat,nehanarkhede,parth.brahmbhatt,stevenz3wu,Yoel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2135,KAFKA-2120,,,,,,,,,,,,,,,,,"24/Dec/14 04:42;parth.brahmbhatt;KAFKA-1788.patch;https://issues.apache.org/jira/secure/attachment/12688914/KAFKA-1788.patch","07/Jan/15 02:42;parth.brahmbhatt;KAFKA-1788_2015-01-06_13:42:37.patch;https://issues.apache.org/jira/secure/attachment/12690387/KAFKA-1788_2015-01-06_13%3A42%3A37.patch","07/Jan/15 02:44;parth.brahmbhatt;KAFKA-1788_2015-01-06_13:44:41.patch;https://issues.apache.org/jira/secure/attachment/12690389/KAFKA-1788_2015-01-06_13%3A44%3A41.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jul 14 17:27:51 UTC 2015,,,,,,,,,,"0|i22ld3:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"03/Dec/14 03:56;parth.brahmbhatt;If noone else has a plan to work on this, I would like to pick this one up to get familiarize with code base.;;;","03/Dec/14 04:08;nehanarkhede;[~parth.brahmbhatt] Please go ahead. ;;;","05/Dec/14 04:35;Bmis13;We also need to fix the Producer Close which hangs JVM because io.join() thread does not exit.  Please refer to KAFKA-1642 for more details.  So Kakfa core Dev needs to give guidance on how to solve this problem.

Please see below comments from that linked issue.


1) Producer.close() method issue is not address with patch. In event of network connection lost or other events happens, IO thread will not be killed and close method hangs. In patch that I have provided, I had timeout for join method and interrupted IO thread. I think we need similar solution.

[~ewencp],

1. I'm specifically trying to address the CPU usage here. I realize from your perspective they are closely related since they're both can be triggered by a loss of network connectivity, but internally they're really separate issues – the CPU usage has to do with incorrect timeouts and the join() issues is due to the lack of timeouts on produce operations. That's why I pointed you toward KAFKA-1788. If a timeout is added for data in the producer, that would resolve the close issue as well since any data waiting in the producer would eventually timeout and the IO thread could exit. I think that's the cleanest solution since it solves both problems with a single setting (the amount of time your willing to wait before discarding data). If you think a separate timeout specifically for Producer.close() is worthwhile I'd suggest filing a separate JIRA for that.

;;;","16/Dec/14 13:09;bpot;I've been digging into this a little bit and in addition to an individual partition being unavailable there is also a case where all brokers become unavailable and we are unable to refresh metadata. This is distinct case because the producer still thinks it has a leader for the partition (AFAICT, the metadata is never updated). The behavior I have seen is that the producer will continue to accept records for any partition which previously had a leader but the batches will never exit the accumulator.

It seems like we could track how long it has been since we've been able to connect to any known brokers and after a certain threshold complete all outstanding record batches with an error and reset the metadata so that new production attempts don't end up in the accumulator.

On the other hand, we could just start failing record batches if they have been in the accumulator for too long. That would solve both failure scenarios. Although, it seems like we should be resetting the metadata for an unavailable cluster at some point.;;;","17/Dec/14 07:02;ewencp;[~bpot] that sounds right, I'm pretty sure metadata never gets cleared if all brokers become unavailable -- it's only updated when the producer starts and when it gets a metadataResponse message.

You can actually get into the state you're talking about for a long time without losing all the brokers. Metadata update requests use NetworkClient.leastLoadedNode to select which node to send the request to, which means requests may repeatedly go to the same node even if its connection isn't getting any data through but the TCP connection hasn't timed out yet. That can result in waiting for many minutes even though the metadata might be retrievable from a different node.

But I'm not sure it's really a distinct problem, just another variant -- the batch stays in the RecordAccumulator eating up bufferpool space until there's a network error or response to the request that included the batch. This means any failure to make progress sending data would trigger the same issue. I think a proper fix for this bug would add a timeout for messages as soon as send() is called, and would need to be able to remove them from any point in the pipeline after that timeout, cleaning up any resources they use.

The metadata issue is another interesting problem. If you reset the metadata, the current implementation will block on any subsequent send() calls since the first thing send() does is waitOnMetadata(). Arguably, given the interface of send() I'm not sure that blocking that way should ever be allowed, although at least now its restricted to the initial send() call and probably simplifies a bunch of code. Resetting the metadata could also be counterproductive since the set of bootstrap nodes could be smaller than the subset of the cluster you had metadata for. One alternative idea: change the use of leastLoadedNode and after a certain amount of time, allow it to start considering the bootstrap nodes as well as the set currently in the metadata.;;;","17/Dec/14 09:10;jkreps;Currently the producer supports either blocking or dropping when it cannot send to the cluster as fast as data is arriving. This could occur because the cluster is down, or just because it isn't fast enough to keep up.

Kafka provides high availability for partitions so the case where a partition is permanently unavailable should be rare.

Timing out requests might be nice, but it's not 100% clear that is better than the current strategy. The current strategy is just to buffer as long as possible and then either block or drop data when the buffer is exhausted. Arguably dropping when you are out of space is better than dropping after a fixed time (since in any case you have to drop when you are out of space).

As Ewen says we can't reset the metadata because the bootstrap servers may no longer exist and if they do they are by definition a subset of the current cluster metadata. I think Ewen solution of just making sure leastLoadedNode eventually tries all nodes is the right way to go. We'll have to be careful, though, as that method is pretty constrained.


;;;","17/Dec/14 09:25;Bmis13;[~jkreps],

Can we just take quick look at the NodeConnectionState ?  If all registered Nodes are down, then  exit it quickly or attempt to connect ?  This will have accurate status of all Nodes registered... (may we can do TCP ping for all nodes).  I am not sure if producer key is fixed to only one brokers then does it still have all Node status ?

Here is reference code:
https://github.com/apache/kafka/blob/0.8.2/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java 
https://github.com/apache/kafka/blob/0.8.2/clients/src/main/java/org/apache/kafka/clients/NodeConnectionState.java

I did this in experimental path for o KAFKA-1642   (but used hard coded timeout for join method for IO thread and interrupted if it does not get killed ).  

Thanks,

Bhavesh ;;;","23/Dec/14 06:19;parth.brahmbhatt;[~nehanarkhede] [~junrao] Can you provide input on what you think needs to be done here. There are 2 problems being discussed: 

* No leader is actually available for a long time, which is the original issue in this jira. This is the case where all replicas are in single DC/AZ and DC/AZ faces outage. In this case the record stays in RecordAccumulator forever as no node is ever ready, so no retries are ever attempted and as the max retries are not exhausted this batch is never dropped. The only way I see to solve this is by adding an expiry on batches and perform a cleanup on expired batches.
* stale metadata because NetworkClient.leastLoadedNode() returns a bad node and keeps retrying against a bad node. unless I am missing something here, I think this just indicates bad configuration, we could reduce default TCP connection-socket/read timeout so we can fail fast but I am not entirely sure if we need to do anything in code to handle this case. The method already goes through  all the nodes in the bootstrap list as leastLoadedNode() starts off with this.metadata.fetch().nodes() and tries to find a good node with fewest outstanding request. 

;;;","24/Dec/14 04:42;parth.brahmbhatt;Created reviewboard https://reviews.apache.org/r/29379/diff/
 against branch trunk;;;","24/Dec/14 07:44;Bmis13;HI All,

I did NOT try this patch, but when one or two or all brokers are down then I see application will not shutdown due to close() method:


Application does not gracefully shutdown when there one or more brokers are down. (io Thread never exits this is know issue ) 

{code}
""SIGTERM handler"" daemon prio=5 tid=0x00007f8bd79e4000 nid=0x17907 waiting for monitor entry [0x000000011e906000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bd5159000 nid=0x1cb0b waiting for monitor entry [0x000000011e803000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bdd147800 nid=0x15d0b waiting for monitor entry [0x000000011e30a000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bdf820000 nid=0x770b waiting for monitor entry [0x000000011e207000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bdc393800 nid=0x1c30f waiting for monitor entry [0x000000011e104000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""Thread-4"" prio=5 tid=0x00007f8bdb39f000 nid=0xa107 in Object.wait() [0x000000011ea89000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.$$YJP$$wait(Native Method)
        at java.lang.Object.wait(Object.java)
        at java.lang.Thread.join(Thread.java:1280)
        - locked <0x0000000705c2f650> (a org.apache.kafka.common.utils.KafkaThread)
        at java.lang.Thread.join(Thread.java:1354)
        at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:322)
        at 

""kafka-producer-network-thread | error"" daemon prio=5 tid=0x00007f8bd814e000 nid=0x7403 runnable [0x000000011e6c0000]
   java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.KQueueArrayWrapper.$$YJP$$kevent0(Native Method)
        at sun.nio.ch.KQueueArrayWrapper.kevent0(KQueueArrayWrapper.java)
        at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:200)
        at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
        - locked <0x0000000705c109f8> (a sun.nio.ch.Util$2)
        - locked <0x0000000705c109e8> (a java.util.Collections$UnmodifiableSet)
        - locked <0x0000000705c105c8> (a sun.nio.ch.KQueueSelectorImpl)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
        at org.apache.kafka.common.network.Selector.select(Selector.java:322)
        at org.apache.kafka.common.network.Selector.poll(Selector.java:212)
        at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:192)
        at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:184)
        at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:128)
        at java.lang.Thread.run(Thread.java:744)
{code}

Thanks,
Bhavesh ;;;","24/Dec/14 11:29;parth.brahmbhatt;[~Bmis13] The patch I provided solves the issue listed on this jira where the records occupy memory space forever if no leader is available. Do you want to open a separate jira for the other issues that you are describing? if you think the problem is related to the theme of this jira can you elaborate how?;;;","27/Dec/14 06:35;Bmis13;The use case I have is little different but similar:

Here is my use case:
1) Lets suppose we have  3 brokers (b1,b2, b3)   and a topic with 30 partitions and replication 1.  So partition 1 to 10 is on b1 (is leader), partition 11 to 20 on b2 and 21 to 30 is on b3.  Zk has all leadership info and every thing is fine.
2) From the Client every is working fine, but only b1 broker is not reachable (due to network or firewall issue) and note that leader is still reported as b1.
3)  The patch you have provided will not address the above issue where you detect that leader is not available and then you purge batch.  So case is little different, leader is available but not able to connect or firewall rule in in-place. 

Based on above use case,  I see following two problems which I have reported on  Please refer to KAFKA-1642 for more details. 

1) record-error-rate metric remain zero despite following firewall rule.  In my opinion, it should have called  org.apache.kafka.clients.producer.Callback  but I did not see that happening either  one or two are brokers not reachable. 

{code}

sudo ipfw add reject tcp from me to b1.ip dst-port 9092
sudo ipfw add reject tcp from me to b2.ip dst-port 9092

00100 reject tcp from me to b1.ip dst-port 9092
00200 reject tcp from me to b2.ip dst-port 9092
{code}

{code}
	class LoggingCallBackHandler implements Callback {

		/**
		 * A callback method the user can implement to provide asynchronous
		 * handling of request completion. This method will be called when the
		 * record sent to the server has been acknowledged. Exactly one of the
		 * arguments will be non-null.
		 * 
		 * @param metadata
		 *            The metadata for the record that was sent (i.e. the
		 *            partition and offset). Null if an error occurred.
		 * @param exception
		 *            The exception thrown during processing of this record.
		 *            Null if no error occurred.
		 */
		@Override
		public void onCompletion(RecordMetadata metadata, Exception exception) {
			if(exception != null){
				exception.printStackTrace();
			}
		}
	}
{code}

I do not see any exception at all on console....not sure why ?

2)	Application does NOT gracefully shutdown when there one or more brokers are not reachable.

{code}
""SIGTERM handler"" daemon prio=5 tid=0x00007f8bd79e4000 nid=0x17907 waiting for monitor entry [0x000000011e906000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bd5159000 nid=0x1cb0b waiting for monitor entry [0x000000011e803000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bdd147800 nid=0x15d0b waiting for monitor entry [0x000000011e30a000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bdf820000 nid=0x770b waiting for monitor entry [0x000000011e207000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""SIGTERM handler"" daemon prio=5 tid=0x00007f8bdc393800 nid=0x1c30f waiting for monitor entry [0x000000011e104000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - waiting to lock <0x000000070008f7c0> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:744)

""Thread-4"" prio=5 tid=0x00007f8bdb39f000 nid=0xa107 in Object.wait() [0x000000011ea89000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.$$YJP$$wait(Native Method)
        at java.lang.Object.wait(Object.java)
        at java.lang.Thread.join(Thread.java:1280)
        - locked <0x0000000705c2f650> (a org.apache.kafka.common.utils.KafkaThread)
        at java.lang.Thread.join(Thread.java:1354)
        at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:322)
        at 

""kafka-producer-network-thread | error"" daemon prio=5 tid=0x00007f8bd814e000 nid=0x7403 runnable [0x000000011e6c0000]
   java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.KQueueArrayWrapper.$$YJP$$kevent0(Native Method)
        at sun.nio.ch.KQueueArrayWrapper.kevent0(KQueueArrayWrapper.java)
        at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:200)
        at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
        - locked <0x0000000705c109f8> (a sun.nio.ch.Util$2)
        - locked <0x0000000705c109e8> (a java.util.Collections$UnmodifiableSet)
        - locked <0x0000000705c105c8> (a sun.nio.ch.KQueueSelectorImpl)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
        at org.apache.kafka.common.network.Selector.select(Selector.java:322)
        at org.apache.kafka.common.network.Selector.poll(Selector.java:212)
        at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:192)
        at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:184)
        at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:128)
        at java.lang.Thread.run(Thread.java:744)
{code}


The goal is to make client resilient, and robust of any network failure and not cause single point of failure when network or brokers are down or not reachable.

Thanks,

Bhavesh ;;;","27/Dec/14 09:34;Bmis13;[~junrao],

Please let me know your opinion on behavior of new producer in above case.  Also, issue 1 and 2 reported. Also, how should the expiration behave respect to ack setting and reporting error back to CallBack Handler.

Thanks,
Bhavesh ;;;","31/Dec/14 02:57;Bmis13;[~parth.brahmbhatt],

The close() (#2) issue will be address by the jira ticket  https://issues.apache.org/jira/browse/KAFKA-1788, but still following will not be address when leader is available, but no records can be sent.   [~junrao], [~jkreps]  and [~nehanarkhede],  please let me know correct behavior in case of above use case.  should I file another issue ?   

1) record-error-rate metric remain zero despite firewall rule. In my opinion, it should have called org.apache.kafka.clients.producer.Callback but I did not see that happening either one or two are brokers not reachable.

Thanks,

Bhavesh ;;;","07/Jan/15 02:42;parth.brahmbhatt;Updated reviewboard https://reviews.apache.org/r/29379/diff/
 against branch origin/trunk;;;","07/Jan/15 02:44;parth.brahmbhatt;Updated reviewboard https://reviews.apache.org/r/29379/diff/
 against branch origin/trunk;;;","19/Feb/15 06:36;parth.brahmbhatt;Can someone from the kafka team respond to the questions asked above. ;;;","23/Feb/15 14:30;ewencp;Ok, I'll try to clear up a few issues.

I think that just making sure we make NetworkClient.leastLoadedNode eventually returns all nodes isn't sufficient. I was just raising another case where this issue could occur. The reason this isn't sufficient for the original case is due to the type of situation [~Bmis13] raises. If you have a temporary network outage to a single broker (e.g. due to firewall misconfiguration or just a network partition issues), it may still correctly be listed as leader. If holding the data in the RecordAccumulator only affected data sent to that one broker, then as [~jkreps] points out, we could potentially get away with just holding on to the messages indefinitely since errors should manifest in other ways. (I think it's *better* to have the timeouts, but not strictly necessary).

However, since the RecordAccumulator is a shared resource, holding onto these messages also means you're going to block sending data to other brokers once your buffer fills up with data for the unreachable broker. Adding timeouts at least ensures messages for these other brokers will eventually get a chance to send data, even if there are periods where they are automatically rejected because the buffer is already full. So [~parth.brahmbhatt], I think the approach you're trying to take in the patch is definitely the right thing to do, and I agree with [~Bmis13] that the error record metrics definitely should (eventually) be increasing.

More generally -- yes, pretty much everything that could potentially block things up for a long time/indefinitely *should* have a timeout. And in a lot of cases this is true even if the operation will eventually timeout ""naturally"", e.g. due to a TCP timeout. It's better to have control over the timeout (even if we highly recommend using the default values) than rely on settings from other systems, especially when they may be adjusted in unexpected ways outside of our control. This is a pervasive concern that we should keep an eye out for with new code, and try to file JIRAs for as we find missing timeouts in existing code.

Given the above, I think the options for controlling memory usage may not be very good for some use cases -- we've been saying people should use a single producer where possible since it's very fast and you actually benefit from sharing the network thread since you can collect all data for all topic-partitions destined for the same broker into a single request. But it turns out that sharing the underlying resources (the buffer) can lead to starvation for some topic-partitions when it shouldn't really be necessary. Would it make sense to allow a per-topic, or even per-partition limit on memory usage? So the effect would be similar to fetch.message.max.bytes for the consumer, where your actual memory usage cap is a n times the value, where n is the number of topic-partitions you're working with? It could also be by broker, but I think that leads to much less intuitive and harder to predict behavior. If people think that's a good idea we can file an additional issue for that.;;;","03/May/15 03:17;becket_qin;I took a shot to incorporate the solution to this problem in KAFKA-2142.
The approach I took there is to just use metadata timeout instead of add a new timeout. Because I think this is essentially metadata not available. So we should treat it the same as in send(). This also saves us another timeout configuration.
[~ewencp] My concern about having cap on the buffer for each topic-partition is that what if the traffic of each topic-partition is not balanced. If so we might end up waiting on a busy topic-partition's buffer allocation while we actually have plenty of memory to use. That could hurt the performance a lot.;;;","14/Jul/15 00:17;parth.brahmbhatt;[~becket_qin] So is this jira irrelavant at this point? If yes can I resolve it? If no, can you describe what needs to be done? I know you had a KIP and multiple discussions but I am not sure if you are taking of it as part of KAFKA-2142. I will be happy to continue working on this jira if you can describe what needs to be done.;;;","14/Jul/15 00:52;mgharat;Hi [~parth.brahmbhatt], this is been handled as a part of KIP-19.
Jira : https://issues.apache.org/jira/browse/KAFKA-2120


Thanks,

Mayuresh;;;","15/Jul/15 01:27;becket_qin;[~parth.brahmbhatt], yes, we can resolve this ticket now. I will submit another patch for KAFKA-2142 after KIP-19 is done if necessary. But hopefully we can solve everything in KIP-19.;;;","15/Jul/15 01:27;becket_qin;Will be covered by KAFKA-2120;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bump up default scala version to 2.10.4 to compile with java 8,KAFKA-1624,12739156,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,joestein,joestein,04/Sep/14 23:56,30/Dec/14 08:03,22/Mar/23 15:10,25/Nov/14 03:59,,,,,,,0.8.2.0,,,,,,,,,,,1,newbie,,,,,"{code}

Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0
error: error while loading CharSequence, class file '/usr/lib/jvm/java-8-oracle/jre/lib/rt.jar(java/lang/CharSequence.class)' is broken
(class java.lang.RuntimeException/bad constant pool tag 18 at byte 10)
error: error while loading Comparator, class file '/usr/lib/jvm/java-8-oracle/jre/lib/rt.jar(java/util/Comparator.class)' is broken
(class java.lang.RuntimeException/bad constant pool tag 18 at byte 20)
error: error while loading AnnotatedElement, class file '/usr/lib/jvm/java-8-oracle/jre/lib/rt.jar(java/lang/reflect/AnnotatedElement.class)' is broken
(class java.lang.RuntimeException/bad constant pool tag 18 at byte 76)
error: error while loading Arrays, class file '/usr/lib/jvm/java-8-oracle/jre/lib/rt.jar(java/util/Arrays.class)' is broken
(class java.lang.RuntimeException/bad constant pool tag 18 at byte 765)
/tmp/sbt_53783b12/xsbt/ExtractAPI.scala:395: error: java.util.Comparator does not take type parameters
	private[this] val sortClasses = new Comparator[Symbol] {
                                            ^
5 errors found
:core:compileScala FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':core:compileScala'.
> org.gradle.messaging.remote.internal.PlaceholderException (no error message)

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED

Total time: 1 mins 48.298 secs
{code}",,aiyer,ewencp,guozhang,gwenshap,hzshlomi,ijuma,joestein,jonbringhurst,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Nov/14 08:23;guozhang;KAFKA-1624.patch;https://issues.apache.org/jira/secure/attachment/12682537/KAFKA-1624.patch","25/Nov/14 03:02;guozhang;KAFKA-1624_2014-11-24_11:01:56.patch;https://issues.apache.org/jira/secure/attachment/12683386/KAFKA-1624_2014-11-24_11%3A01%3A56.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Dec 30 00:03:48 UTC 2014,,,,,,,,,,"0|i1zos7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"17/Sep/14 05:55;sslavic;If I'm not mistaken, this error is caused by Scala 2.10 (and older) incompatibility with (reading) Java 8.
{{./gradlew clean test_core_2_11}} with Java 8 passes successfully for me on current trunk, although even Scala 2.11 just has experimental support for Java 8.

Scala 2.12 will require Java 8 (see [Scala 2.12 roadmap|http://www.scala-lang.org/news/2.12-roadmap]).;;;","18/Sep/14 00:15;joestein;Thanks, so nothing to fix/to-do yet but lets leave this open as I expect it will come up again so folks know what is going on.  We can eventually turn it into managing multiple builds for JDK version and Scala version down the road. ;;;","05/Oct/14 05:13;ijuma;Note that Scala 2.10.4 also includes a number of fixes for Java 8 support.;;;","12/Nov/14 03:18;gwenshap;Closing with ""not a problem"", since this is just a matter of building with:
-PscalaVersion=2.10.3 or -PscalaVersion=2.11;;;","15/Nov/14 06:21;guozhang;I did some tests locally with various Scala versions. Only the default 2.10.1 seems not compile with Java 8; 2.10.2, 2.10.3 and 2.11 are all compatible with it. Shall we change the default version of Scala to at least 2.10.2?;;;","18/Nov/14 02:29;joestein;<< I did some tests locally with various Scala versions. Only the default 2.10.1 seems not compile with Java 8; 2.10.2, 2.10.3 and 2.11 are all compatible with it. Shall we change the default version of Scala to at least 2.10.2?

[~guozhang] Thanks for testing the versions out. Your suggestions makes sense to me, folks are going to keep bringing this up more and more moving forward and no reason to make them keep making a minor change we can ship in 0.8.2 final (i think it would be ok to-do it there)

Do we want to go with 2.10.3 instead of 2.10.2 since it is later version? 

Any one else issues with doing this for 0.8.2?;;;","18/Nov/14 06:14;guozhang;Thanks Joe. So I will bump up the default version to 2.10.3 if no one else have issues with it.;;;","18/Nov/14 07:36;ewencp;Isn't 2.10.4 the latest version in the 2.10 series?;;;","20/Nov/14 08:23;guozhang;Created reviewboard https://reviews.apache.org/r/28268/diff/
 against branch origin/trunk;;;","25/Nov/14 03:02;guozhang;Updated reviewboard https://reviews.apache.org/r/28268/diff/
 against branch origin/trunk;;;","30/Dec/14 08:03;joestein;committed to 0.8.2 branch, just noticed the commit message says 2.11.4 but it is 2.10.4 per the JIRA title (just changed the title);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Broker Exception: Attempt to read with a maximum offset less than start offset,KAFKA-725,12628820,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,srdo,criccomini,criccomini,23/Jan/13 07:16,06/May/16 20:59,22/Mar/23 15:10,06/May/16 20:59,0.8.0,,,,,,0.10.0.0,,,,,,,log,,,,0,,,,,,"I have a simple consumer that's reading from a single topic/partition pair. Running it seems to trigger these messages on the broker periodically:

2013/01/22 23:04:54.936 ERROR [KafkaApis] [kafka-request-handler-4] [kafka] []  [KafkaApi-466] error when processing request (MyTopic,4,7951732,2097152)
java.lang.IllegalArgumentException: Attempt to read with a maximum offset (7951715) less than the start offset (7951732).
        at kafka.log.LogSegment.read(LogSegment.scala:105)
        at kafka.log.Log.read(Log.scala:390)
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$readMessageSet(KafkaApis.scala:372)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$readMessageSets$1.apply(KafkaApis.scala:330)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$readMessageSets$1.apply(KafkaApis.scala:326)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:105)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)
        at scala.collection.immutable.Map$Map1.map(Map.scala:93)
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$readMessageSets(KafkaApis.scala:326)
        at kafka.server.KafkaApis$$anonfun$maybeUnblockDelayedFetchRequests$2.apply(KafkaApis.scala:165)
        at kafka.server.KafkaApis$$anonfun$maybeUnblockDelayedFetchRequests$2.apply(KafkaApis.scala:164)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.server.KafkaApis.maybeUnblockDelayedFetchRequests(KafkaApis.scala:164)
        at kafka.server.KafkaApis$$anonfun$handleProducerRequest$2.apply(KafkaApis.scala:186)
        at kafka.server.KafkaApis$$anonfun$handleProducerRequest$2.apply(KafkaApis.scala:185)
        at scala.collection.immutable.Map$Map2.foreach(Map.scala:127)
        at kafka.server.KafkaApis.handleProducerRequest(KafkaApis.scala:185)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:58)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:41)
        at java.lang.Thread.run(Thread.java:619)

When I shut the consumer down, I don't see the exceptions anymore.

This is the code that my consumer is running:
          while(true) {
            // we believe the consumer to be connected, so try and use it for a fetch request
            val request = new FetchRequestBuilder()
              .addFetch(topic, partition, nextOffset, fetchSize)
              .maxWait(Int.MaxValue)
              // TODO for super high-throughput, might be worth waiting for more bytes
              .minBytes(1)
              .build

            debug(""Fetching messages for stream %s and offset %s."" format (streamPartition, nextOffset))
            val messages = connectedConsumer.fetch(request)
            debug(""Fetch complete for stream %s and offset %s. Got messages: %s"" format (streamPartition, nextOffset, messages))
            if (messages.hasError) {
              warn(""Got error code from broker for %s: %s. Shutting down consumer to trigger a reconnect."" format (streamPartition, messages.errorCode(topic, partition)))
              ErrorMapping.maybeThrowException(messages.errorCode(topic, partition))
            }
            messages.messageSet(topic, partition).foreach(msg => {
              watchers.foreach(_.onMessagesReady(msg.offset.toString, msg.message.payload))
              nextOffset = msg.nextOffset
            })
          }

Any idea what might be causing this error?",,becket_qin,chienle,criccomini,diwakar,githubbot,guozhang,gwenshap,ijuma,junrao,lokeshbirla,mauzhang,muditcse,nehanarkhede,rmetzger,srdo,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-727,,,,,,,,FLINK-3288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,308298,,,Fri May 06 12:59:09 UTC 2016,,,,,,,,,,"0|i1b1l3:",272555,,guozhang,,,,,,,,,,,,,,,,,,"23/Jan/13 08:43;nehanarkhede;This looks exactly like KAFKA-698. Chris, did you try with a Kafka cluster that includes a fix for KAFKA-698 ?;;;","06/Dec/14 01:45;lokeshbirla;Neha,

I still see this issue in 0.8.1.1.

https://issues.apache.org/jira/browse/KAFKA-1806;;;","13/Jan/15 02:01;diwakar;Neha,

we have 6 brokers and 131 partitions per topic(replication factor : 3 ) and recently updated to kafka_2.10-0.8.2.0 and facing similar issue causing lot of below errors.Due to this it seems like producers are unable to produce to kafka successfully.

[2015-01-11 05:21:56.604-0700] ERROR [Replica Manager on Broker 2]: Error when processing fetch request for partition [application-access,13] offset 42748276 from consumer with correlation id 4974. Possible cause: Attempt to read with a maximum offset (42748275) less than the start offset (42748276). 


Any solution available to fix this.

Thanks
Diwakar
;;;","22/Jan/16 08:25;mauzhang;Is anyone still looking at this issue ? We have run into this exception on a 4-node kafka_2.10-0.8.2.1 cluster where 4 producers produce data with throughput of 17k messages/s on each node.
;;;","22/Jan/16 09:29;gwenshap;KAFKA-2477 has somewhat similar symptoms. Perhaps you are running into that? You can try applying the patch and checking if it fixes your issue.;;;","22/Jan/16 14:17;becket_qin;[~gwenshap] [~mauzhang] Not sure if it is related to KAFKA-2477. KAFKA-2477 should only affect replica fetchers, and we never set maxOffset for replica fetchers. The error log here seems caused by a regular consumers trying to fetch beyond high watermark. But this should not affect producing.;;;","17/Feb/16 13:19;mauzhang;I can reproduce this on 0.9.0.0. The error log is 

[2016-01-28 16:12:32,840] ERROR [Replica Manager on Broker 1]: Error processing fetch operation on partition [ad-events,1] offset 75510318 (kafka.server.ReplicaManager)

I also print the sent offset from producer 

time   partition offset 
16:12:32.840   1   75510318

It seems the offset is produced and consumed at the same time. 
;;;","17/Feb/16 14:22;mauzhang;I can reproduce this on 0.9.0.0. The error log is 

[2016-01-28 16:12:32,840] ERROR [Replica Manager on Broker 1]: Error processing fetch operation on partition [ad-events,1] offset 75510318 (kafka.server.ReplicaManager)

I also print the sent offset from producer 

time   partition offset 
16:12:32.840   1   75510318

It seems the offset is produced and consumed at the same time. 
;;;","01/Apr/16 21:14;srdo;We're seeing this on 8.2.2. I'm not sure Log/LogSegment handles the high watermark as gracefully as they maybe could.

My guess at how it's happening:
Assume a replica set of at least 2.
A consumer (in our case the Storm KafkaSpout) reads up to the end of the committed log, say up to message 5. 
The leader for the relevant partition then receives one or more messages (6). 
Before the new message(s) are replicated, the consumer increments its offset and fetches (from 6). 
The leader receives the fetch, sets the maxOffset for read to the high watermark (5), and compares the end of the log to the requested offset (see https://github.com/apache/kafka/blob/0.9.0.1/core/src/main/scala/kafka/log/Log.scala#L482). This check passes because the end of the log is at 6.
When the read on LogSegment is reached, it will error out when the maxOffset is smaller than the start offset, which causes this error log. https://github.com/apache/kafka/blob/0.9.0.1/core/src/main/scala/kafka/log/LogSegment.scala#L146

Maybe the check in Log should include whether the maxOffset is larger than offset as well?

Edit: Or maybe Kafka should allow the fetch to wait until the requested offset is available, similar to how minBytes can be waited for?;;;","02/Apr/16 22:56;githubbot;GitHub user srdo opened a pull request:

    https://github.com/apache/kafka/pull/1178

    KAFKA-725: Change behavior of Log/LogSegment when attempting read on an offset that's above high watermark.

    This should make Log.read act the same when startOffset is larger than maxOffset as it would if startOffset was larger than logEndOffset. The current behavior can result in an IllegalArgumentException from LogSegment if a consumer attempts to fetch an offset above the high watermark which is present in the leader's log. It seems more correct if Log.read presents the view of the log to consumers as if it simply ended at maxOffset (high watermark).
    
    I've tried to describe an example scenario of this happening here https://issues.apache.org/jira/browse/KAFKA-725?focusedCommentId=15221673&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15221673
    
    I'm not sure I understand why ReplicaManager sets maxOffset to the high watermark, and not high watermark + 1. Isn't the high watermark the last committed message, and readable by consumers?
    
    Tests passed for me locally on second try, seems like it just hit a flaky test.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/srdo/kafka KAFKA-725

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1178.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1178
    
----
commit 5c7d583ec1af0892e9fadc4bbdcbeaa94390524e
Author: Stig Rohde Døssing <sdo@it-minds.dk>
Date:   2016-04-02T12:20:50Z

    KAFKA-725: Throw OffsetOutOfRangeException when reading from Log with maxOffset > startOffset

commit 5546433916d49b30b0869964a779e1af189be0ce
Author: Stig Rohde Døssing <sdo@it-minds.dk>
Date:   2016-04-02T13:37:22Z

    KAFKA-725: Return empty message set if reading from Log with maxOffset+1 == startOffset

commit 5808b31828d3703729569476217880971bf279af
Author: Stig Rohde Døssing <sdo@it-minds.dk>
Date:   2016-04-02T14:09:40Z

    KAFKA-725: Return only message offset when reading one beyond maxOffset

----
;;;","03/Apr/16 02:27;srdo;Nevermind this, I misunderstood the high watermark to be the last committed offset. It seems to be the last committed offset + 1. There's still a minor issue if a consumer requests an offset that's in the log but above the high watermark, which the PR should fix.;;;","04/Apr/16 02:47;githubbot;Github user srdo closed the pull request at:

    https://github.com/apache/kafka/pull/1178
;;;","04/Apr/16 02:47;githubbot;GitHub user srdo reopened a pull request:

    https://github.com/apache/kafka/pull/1178

    KAFKA-725: Change behavior of Log/LogSegment when attempting read on an offset that's above high watermark.

    This should make Log.read act the same when startOffset is larger than maxOffset as it would if startOffset was larger than logEndOffset. The current behavior can result in an IllegalArgumentException from LogSegment if a consumer attempts to fetch an offset above the high watermark which is present in the leader's log. It seems more correct if Log.read presents the view of the log to consumers as if it simply ended at maxOffset (high watermark).
    
    I've tried to describe an example scenario of this happening here https://issues.apache.org/jira/browse/KAFKA-725?focusedCommentId=15221673&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15221673
    
    I'm not sure I understand why ReplicaManager sets maxOffset to the high watermark, and not high watermark + 1. Isn't the high watermark the last committed message, and readable by consumers?
    
    Tests passed for me locally on second try, seems like it just hit a flaky test.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/srdo/kafka KAFKA-725

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1178.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1178
    
----
commit c7bab99b77b71c73380d473facda1138799e42a6
Author: Stig Rohde Døssing <sdo@it-minds.dk>
Date:   2016-04-02T12:20:50Z

    KAFKA-725: Throw OffsetOutOfRangeException when reading from Log with maxOffset > startOffset

commit 4f5b415651ec45d3040c22393d24293de4f2cfd0
Author: Stig Rohde Døssing <sdo@it-minds.dk>
Date:   2016-04-02T23:29:02Z

    KAFKA-725: Put check for HW from consumer in ReplicaManager.readFromLocalLog instead of Log.read

----
;;;","08/Apr/16 12:37;guozhang;[~Srdo] I think your reasoning still makes sense, because a producer usually produces in batches. So following your case, after receiving a batch of 5 messages, the log end offset could then be 5 + 5 + 1 = 11, but before it was replicated to follower the high watermark is still 5 + 1 = 6. Hence this check will fail.;;;","08/Apr/16 16:23;muditcse;Hi,

We are seeing below exception in our kafka logs on one of the broker id.

[2016-04-08 07:59:58,486] ERROR [Replica Manager on Broker 3]: Error processing fetch operation on partition [subscribed_product_logs,17] offset 483780 (kafka.server.ReplicaManager)
java.lang.IllegalStateException: Failed to read complete buffer for targetOffset 483780 startPosition 958861516 in /kafka/kafka-logs/subscribed_product_logs-17/00000000000000378389.log
        at kafka.log.FileMessageSet.searchFor(FileMessageSet.scala:133)
        at kafka.log.LogSegment.translateOffset(LogSegment.scala:105)
        at kafka.log.LogSegment.read(LogSegment.scala:126)
        at kafka.log.Log.read(Log.scala:506)
        at kafka.server.ReplicaManager$$anonfun$readFromLocalLog$1.apply(ReplicaManager.scala:536)
        at kafka.server.ReplicaManager$$anonfun$readFromLocalLog$1.apply(ReplicaManager.scala:507)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
        at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
        at scala.collection.AbstractTraversable.map(Traversable.scala:104)
        at kafka.server.ReplicaManager.readFromLocalLog(ReplicaManager.scala:507)
        at kafka.server.ReplicaManager.fetchMessages(ReplicaManager.scala:462)
        at kafka.server.KafkaApis.handleFetchRequest(KafkaApis.scala:431)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:69)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
        at java.lang.Thread.run(Thread.java:745)
[2016-04-08 07:59:58,486] ERROR [Replica Manager on Broker 3]: Error processing fetch operation on partition [subscribed_product_logs,8] offset 592637 (kafka.server.ReplicaManager)
java.lang.IllegalStateException: Failed to read complete buffer for targetOffset 592637 startPosition 780606424 in /kafka/kafka-logs/subscribed_product_logs-8/00000000000000505731.log
        at kafka.log.FileMessageSet.searchFor(FileMessageSet.scala:133)
        at kafka.log.LogSegment.translateOffset(LogSegment.scala:105)
        at kafka.log.LogSegment.read(LogSegment.scala:126)
        at kafka.log.Log.read(Log.scala:506)
        at kafka.server.ReplicaManager$$anonfun$readFromLocalLog$1.apply(ReplicaManager.scala:536)
        at kafka.server.ReplicaManager$$anonfun$readFromLocalLog$1.apply(ReplicaManager.scala:507)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
        at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
        at scala.collection.AbstractTraversable.map(Traversable.scala:104)
        at kafka.server.ReplicaManager.readFromLocalLog(ReplicaManager.scala:507)
        at kafka.server.ReplicaManager.fetchMessages(ReplicaManager.scala:462)
        at kafka.server.KafkaApis.handleFetchRequest(KafkaApis.scala:431)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:69)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
        at java.lang.Thread.run(Thread.java:745)

seems this is related to same bug.Any update on this?;;;","09/Apr/16 00:45;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1178
;;;","09/Apr/16 00:45;guozhang;Issue resolved by pull request 1178
[https://github.com/apache/kafka/pull/1178];;;","09/Apr/16 01:14;srdo;[~guozhang] Makes sense. I'm wondering if it would be better for the request to be put into purgatory then? If the request hits inbetween the high watermark and the end of the log, we can reasonably expect that offset to be readable shortly, while if the client gets a general OffsetOutOfRangeException, it might make more sense for the client to restart at either end of the log.

What I mean is basically, what does proper handling of this exception look like on the client-side now?;;;","09/Apr/16 01:22;guozhang;Usually client code should gracefully handle OffsetOutOfRangeException by requesting the current log end offset and retry fetching. Note that this handling would just make this exception potentially being triggered multiple times until the data is replicated complete and HW advanced; in most cases this is fine as it is only transient. But I agree that a more ideal solution is to park the request in purgatory so that we can reduce round trips retrying in this case as well.;;;","11/Apr/16 20:39;srdo;[~guozhang] Okay, returning the error should be fine then. I can't really think of a case where this error can happen if the client is well behaved and unclean leader election is turned off. If the client never increments its offset by more than 1 past the most recently consumed message, it shouldn't be possible for it to request an offset higher than the high watermark, since the most recent offset it can have consumed is HW - 1.;;;","04/May/16 23:10;junrao;[~Srdo], thanks for the patch. It's still not very clear to me how a consumer can trigger the IllegalArgumentException even without the patch. The broker only returns messages up to the high watermark (HW) to the consumer. So, the offset from a consumer should always be <= HW. The problem can only occur if a consumer uses an offset > HW, but <= the log end offset, which should never happen in a normal consumer.;;;","05/May/16 01:39;becket_qin;[~junrao] I asked this question in the RB. It seems the consumer in this case is not the Java consumer. Theoretically a java consumer can only fetch beyond HW when unclean leader election occurs.;;;","05/May/16 12:06;junrao;Reopen this jira since the fix exposes a new issue. When the leader switches (say due to leader balancing), the new leader's HW can actually be smaller than the previous leader's HW since HW is propagated asynchronously. The new leader's log end offset is >= than the previous leader's HW and eventually its HW will move to its log end offset. Before that happens, if a consumer fetches data using previous leader's HW, with the patch, the consumer will get OffsetOutOfRangeException and thus has to reset the offset, which is bad. Without the patch, the consumer will get an empty response instead.

So, it seems that we should revert the changes in this patch.;;;","05/May/16 23:09;guozhang;Jun, thanks for pointing it out. While reverting this change, I'm thinking we should change https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/log/LogSegment.scala#L147 to return empty response instead of throw exceptions as well. What do you think?;;;","06/May/16 00:37;junrao;Yes, I agree. If the requested offset is > MaxOffset, it's better to just return an empty response instead of throwing an IllegalStateException. We can add a comment on why we want to do that. Also, while you are there, could you fix the following comment above LogSegment.read()? maxPosition is not optional.

   * @param maxPosition An optional maximum position in the log segment that should be exposed for read.
;;;","06/May/16 03:04;githubbot;GitHub user guozhangwang opened a pull request:

    https://github.com/apache/kafka/pull/1327

    HOTFIX: follow-up on KAFKA-725 to remove the check and return empty response instead of throw exceptions

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/guozhangwang/kafka K725r

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1327.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1327
    
----
commit 9fdfe9ce1a0242f78775cbc5e24fc4a059a07296
Author: Guozhang Wang <wangguoz@gmail.com>
Date:   2016-05-05T19:03:30Z

    follow-up on KAFKA-725

----
;;;","06/May/16 03:54;srdo;Thanks for fixing this. The scenario Jun describes is probably a better match for the times we saw the exception originally. We're using Storm's storm-kafka component to consume, and it shouldn't go beyond the HW if the HW never moves backwards. It seems plausible that the logs coincided with leader failover for us.;;;","06/May/16 07:55;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1327
;;;","06/May/16 20:59;ijuma;[~guozhang]'s PR was merged to trunk and 0.10.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Zookeeper leader election stuck in ephemeral node retry loop,KAFKA-1029,12665679,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,smeder,smeder,smeder,27/Aug/13 17:39,22/Aug/14 00:58,22/Mar/23 15:10,28/Aug/13 01:20,0.8.0,,,,,,0.8.0,,,,,,,controller,,,,0,,,,,,"We're seeing the following log statements (over and over):

[2013-08-27 07:21:49,538] INFO conflict in /controller data: { ""brokerid"":3, ""timestamp"":""1377587945206"", ""version"":1 } stored data: { ""brokerid"":2, ""timestamp"":""1377587460904"", ""version"":1 } (kafka.utils.ZkUtils$)

[2013-08-27 07:21:49,559] INFO I wrote this conflicted ephemeral node [{ ""brokerid"":3, ""timestamp"":""1377587945206"", ""version"":1 }] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)

where the broker is essentially stuck in the loop that is trying to deal with left-over ephemeral nodes. The code looks a bit racy to me. In particular:

ZookeeperLeaderElector:

  def elect: Boolean = {
    controllerContext.zkClient.subscribeDataChanges(electionPath, leaderChangeListener)
    val timestamp = SystemTime.milliseconds.toString
    val electString = ...

    try {
      createEphemeralPathExpectConflictHandleZKBug(controllerContext.zkClient, electionPath, electString, leaderId,
        (controllerString : String, leaderId : Any) => KafkaController.parseControllerId(controllerString) == leaderId.asInstanceOf[Int],
        controllerContext.zkSessionTimeout)

leaderChangeListener is registered before the create call (by the way, it looks like a new registration will be added every elect call - shouldn't it register in startup()?) so can update leaderId to the current leader before the call to create. If that happens then we will continuously get node exists exceptions and the checker function will always return true, i.e. we will never get out of the while(true) loop.

I think the right fix here is to pass brokerId instead of leaderId when calling create, i.e.

createEphemeralPathExpectConflictHandleZKBug(controllerContext.zkClient, electionPath, electString, brokerId,
        (controllerString : String, leaderId : Any) => KafkaController.parseControllerId(controllerString) == leaderId.asInstanceOf[Int],
        controllerContext.zkSessionTimeout)

The loop dealing with the ephemeral node bug is now only triggered for the broker that owned the node previously, although I am still not 100% sure if that is sufficient.


",,guozhang,jbrosenberg@gmail.com,junrao,miguno,nehanarkhede,smeder,tysonnorris,vincentye38,Yiyang Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Aug/13 00:51;smeder;0002-KAFKA-1029-Use-brokerId-instead-of-leaderId-when-tri.patch;https://issues.apache.org/jira/secure/attachment/12600201/0002-KAFKA-1029-Use-brokerId-instead-of-leaderId-when-tri.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,345619,,,Thu Aug 21 16:58:58 UTC 2014,,,,,,,,,,"0|i1nlm7:",345920,,,,,,,,,,,,,,,,,,,,"28/Aug/13 00:36;guozhang;Thanks for the catch Sam. Yes the comparison value should be brokerId instead of leaderId. This is a bug in the patch of KAFKA-992.

Also I agree that we only need to register leaderChangeListener once, which we can do in startup, before the elect statement. Could you also make this change?

Thanks,
Guozhang;;;","28/Aug/13 00:40;nehanarkhede;Good catch. The election and leader change update happens on the same lock. It is possible that the old controller becomes the new controller, and the leaderId field is not updated since the elect() API has acquired the controllerLock. This makes broker 3 retry the controller election on behalf of broker 2 and it may never stop until the next controller election.

+1 on this patch;;;","28/Aug/13 00:52;smeder;Updated patch to also include moving the listener registration to startup();;;","28/Aug/13 01:06;guozhang;Thanks for v2. +1 on this one.;;;","28/Aug/13 01:20;nehanarkhede;Thanks for patch v2. Committed it to 0.8;;;","22/Mar/14 13:28;jbrosenberg@gmail.com;I'm seeing this happening now (we are running 0.8).  Should this have been fixed?

It appears to only happen every once in a while, but when it does, it seems persist and repeat indefinitely.  Sometimes restarting the consumer app can fix the problem, but not always.;;;","23/Mar/14 05:00;guozhang;This is a little wired. The patch should have been in 0.8 already. Could you upload the related logs here?;;;","24/Mar/14 14:22;jbrosenberg@gmail.com;Perhaps this should be re-opened a separate ticket?

The issue seems to have started when we had a network outage.  Several high-level consumers could not communicate at all with zookeeper (or kafka) for several minutes.  When the network was restarted, these continual ""I wrote this conlicted ephemeral node...."" log messages have been running steadily, e.g.:

2014-03-19 00:13:14,165  INFO [ZkClient-EventThread-51-myzkserver] utils.ZkUtils$ - conflict in /consumers/myapp/ids/myapp_myhost-1394905418548-e159fc25 data: { ""pattern"":""white_list"", ""subscription"":{ ""(^\\Qmy.event\\E(\\.[\\w-]+)*$)"" : 1 }, ""timestamp"":""1395187970147"", ""version"":1 } stored data: { ""pattern"":""white_list"", ""subscription"":{ ""(^\\Qmy.event\\E(\\.[\\w-]+)*$)"" : 1 }, ""timestamp"":""1395187967170"", ""version"":1 }
2014-03-19 00:13:14,166  INFO [ZkClient-EventThread-51-myzkserver] utils.ZkUtils$ - I wrote this conflicted ephemeral node [{ ""pattern"":""white_list"", ""subscription"":{ ""(^\\Qmy.event\\E(\\.[\\w-]+)*$)"" : 1 }, ""timestamp"":""1395187970147"", ""version"":1 }] at /consumers/myapp/ids/myapp_awa60.sjc1b.square-1394905418548-e159fc25 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry

These are happening continuously.  We have tried doing a rolling restart of our consumer apps, and even a rolling restart of zk.  We are using zk 3.3.6, in this case, but will try upgrading to 3.4.5 shortly.

It seems that these ephemeral node errors always happen right after a consumer rebalance occurs.;;;","24/Mar/14 23:40;jbrosenberg@gmail.com;I'm starting to suspect my issue is actually due to network latency introduced between the consumers and the zk servers, which is causing zk connection timeouts and flapping.  Thus, I think the issue is probably not related to the original bug in this issue per se (it is having trouble with zk timeouts, possibly resulting in consumer clients not seeing/updating a consistent view of these ephemeral nodes?  Does that make sense?

That being said, it still doesn't seem to make sense that an ephemeral node would not ever get removed eventually.  Also, perhaps the strange folksy error log messaging in this case is assuming rather specific scenarios that don't always apply, which could be more simplified here?;;;","25/Mar/14 00:29;nehanarkhede;[~jbrosenberg@gmail.com] It is a little difficult to say what's going on. It would help if you can tell us how to reproduce this? If you suspect this is due to network outage, try doing a test where you disable the network interface and see if you can reproduce it. That will help us troubleshoot this.;;;","25/Mar/14 11:09;smeder;We've seen this as well (once or twice in ~4 months). The exact conditions under which it occurs have been pretty hard to pin-point.;;;","31/Mar/14 23:51;jbrosenberg@gmail.com;Just to wrap this up, it turns out the app that was seeing this behavior had a but which was causing unnecessary memory pressure and continual garbage collection.  This ended up slowing the app down, such that zk timeouts were continual, and the consumer connector decided continually to keep re-balancing.  This caused the flapping of ephemeral nodes, and other problems, it would seem (the last part here is conjecture).

So, I think the app was the problem, not the high-level kafka consumer code.  However, perhaps there is something that can be done to prevent or throttle continual re-balancing in this case!  It was confusing to look at the logs and see almost exclusively warnings/exceptions coming from kafka, and not the app itself.;;;","29/Apr/14 20:58;miguno;Interestingly I ran into a very similar issue while doing basic validation of Kafka 0.8.1.1.  Note that unlike Jason Rosenberg's case I was only using code/tools/scripts that are shipped with Kafka (e.g. console producer and console consumer).

Here is an example log message, which was repeated indefinitely:

{code}
[2014-04-29 09:48:27,207] INFO conflict in /controller data: {""version"":1,""brokerid"":0,""timestamp"":""1398764901156""} stored data: {""version"":1,""brokerid"":0,""timestamp"":""1398764894941""} (kafka.utils.ZkUtils$)
[2014-04-29 09:48:27,218] INFO I wrote this conflicted ephemeral node [{""version"":1,""brokerid"":0,""timestamp"":""1398764901156""}] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
{code}

*How to reproduce (unsolved)*

Unfortunately I cannot consistently reproduce the issue and, to be honest, I am still not sure what actually triggers the bug.  As such I can only summarize what I did before and around the time when this bug was triggered, which I could observe through errors in log files and through errors being displayed after running certain commands.  So yes, it's a bit like shooting in the dark.

Here's an overview of my test setup:

- I deployed Kafka 0.8.1.1 to one machine {{kafka1}} and ZooKeeper 3.4.5 to a second machine {{zookeeper1}}.
- I followed the Kafka 0.8.1 quick start guide to create a topic ""test"" with 1 partition and a replication factor of 1.
- I sent test messages to the topic ""test"" via the console producer.
- I read test messages from the topic ""test"" via the console consumer.
- Apart from producing and consuming a handful of test messages I also ran some supposedly read-only admin commands such as ""describing"" the topic, and running the consumer offset checker tool.
- At ""some"" point, Kafka was caught in an indefinite loop complaining about ""conflict in {{/controller}} data"".


The following paragraphs list in more detail what I did before the error popped up.

Producer:

{code}
$ sudo su - kafka
$ cd /opt/kafka

# This command returned no topics at this point = worked as expected
$ bin/kafka-topics.sh --list --zookeeper zookeeper1

# I created a topic, worked as expected
$ bin/kafka-topics.sh --create --zookeeper zookeeper1 --replication-factor 1 --partitions 1 --topic test

# I requested details of topic ""test"", worked as expected
$ bin/kafka-topics.sh --zookeeper zookeeper1 --describe --topic test
Topic:test	PartitionCount:1	ReplicationFactor:1	Configs:
	Topic: test	Partition: 0	Leader: 0	Replicas: 0	Isr: 0

# I started a console producer and manually send a handful of test messages, worked as expected (see consumer below)
$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
{code}

Consumer:

{code}
$ sudo su - kafka
$ cd /opt/kafka

# I started a console consumer, worked as expected (i.e. could read messages sent by producer, see above)
$ bin/kafka-console-consumer.sh --zookeeper zookeeper1 --topic test --from-beginning
{code}

Up to that point, everything worked.  But then the Kafka broker went the way of the dodo.  As I said I can't pinpoint the cause, and re-running the same commands on a fresh Kafka/ZooKeeper deployment (fresh VMs etc.) didn't consistently trigger the issue like I hoped.

Here's what I did after the commands above, and at some point I eventually did observe the original error described in this JIRA ticket.  Again, at the moment I cannot tell what actually triggered the bug.

Producer:

{code}
# Test-driving the consumer offset checker
$ bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zkconnect zookeeper1
# At this point consumer ""foo"" was not expected to exist.
$ bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zkconnect zookeeper1 --broker-info --group foo

#
# I then re-started the console producer (see below), now configured to use the group id ""foo"".
#
{code}

Consumer:

{code}
# I re-started the console consumer, now configured to use the group id ""foo"".
$ bin/kafka-console-consumer.sh --zookeeper zookeeper1 --topic test --from-beginning --group foo
{code}

At this point ""describing"" the topic gave the following info, indicating that there was a problem (e.g. no leader for partition, no ISR available):

{code}
$ bin/kafka-topics.sh --zookeeper zookeeper1 --describe --topic test
Topic:test	PartitionCount:1	ReplicationFactor:1	Configs:
	Topic: test	Partition: 0	Leader: -1	Replicas: 0	Isr:
{code}

Log files such as {{state-change.log}} showed these error messages:

{code}


[2014-04-29 07:44:47,673] TRACE Controller 0 epoch 1 changed partition [test,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[2014-04-29 07:44:47,679] TRACE Controller 0 epoch 1 changed state of replica 0 for partition [test,0] from NonExistentReplica to NewReplica (state.change.logger)
[2014-04-29 07:44:47,703] TRACE Controller 0 epoch 1 changed partition [test,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[2014-04-29 07:44:47,708] TRACE Controller 0 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) with correlationId 7 to broker 0 for partition [test,0] (state.change.logger)
[2014-04-29 07:44:47,716] TRACE Controller 0 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) with correlationId 7 to broker 0 for partition [test,0] (state.change.logger)
[2014-04-29 07:44:47,721] TRACE Controller 0 epoch 1 changed state of replica 0 for partition [test,0] from NewReplica to OnlineReplica (state.change.logger)
[2014-04-29 07:44:47,729] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) correlation id 7 from controller 0 epoch 1 for partition [test,0] (state.change.logger)
[2014-04-29 07:44:47,733] TRACE Broker 0 handling LeaderAndIsr request correlationId 7 from controller 0 epoch 1 starting the become-leader transition for partition [test,0] (state.change.logger)
[2014-04-29 07:44:47,741] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 1 with correlation id 7 for partition [test,0] (state.change.logger)
[2014-04-29 07:44:47,783] TRACE Broker 0 completed LeaderAndIsr request correlationId 7 from controller 0 epoch 1 for the become-leader transition for partition [test,0] (state.change.logger)
[2014-04-29 07:44:47,796] TRACE Controller 0 epoch 1 received response correlationId 7 for a request sent to broker id:0,host:kafka1,port:9092 (state.change.logger)
[2014-04-29 07:44:47,816] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition [test,0] in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 7 (state.change.logger)
[2014-04-29 07:44:47,818] TRACE Controller 0 epoch 1 received response correlationId 7 for a request sent to broker id:0,host:kafka1,port:9092 (state.change.logger)
[2014-04-29 08:48:06,559] TRACE Controller 0 epoch 1 changed partition [test,0] state from OnlinePartition to OfflinePartition (state.change.logger)
[2014-04-29 08:48:06,561] TRACE Controller 0 epoch 1 started leader election for partition [test,0] (state.change.logger)
[2014-04-29 08:48:06,574] ERROR Controller 0 epoch 1 initiated state change for partition [test,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [test,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
        at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:61)
        at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:336)
        at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:185)
        at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:99)
        at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:96)
        at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
[2014-04-29 09:33:16,161] INFO conflict in /controller data: {""version"":1,""brokerid"":0,""timestamp"":""1398761286651""} stored data: {""version"":1,""brokerid"":0,""timestamp"":""1398761286608""} (kafka.utils.ZkUtils$)
[2014-04-29 09:33:16,163] INFO I wrote this conflicted ephemeral node [{""version"":1,""brokerid"":0,""timestamp"":""1398761286651""}] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
{code}

I also tried a few admin commands to see what would happen:

{code}
$ bin/kafka-preferred-replica-election.sh --zookeeper zookeeper1 --path-to-json-file /tmp/test.json
Failed to start preferred replica election
kafka.common.AdminCommandFailedException: Admin command failed
	at kafka.admin.PreferredReplicaLeaderElectionCommand.moveLeaderToPreferredReplica(PreferredReplicaLeaderElectionCommand.scala:115)
	at kafka.admin.PreferredReplicaLeaderElectionCommand$.main(PreferredReplicaLeaderElectionCommand.scala:60)
	at kafka.admin.PreferredReplicaLeaderElectionCommand.main(PreferredReplicaLeaderElectionCommand.scala)
Caused by: kafka.admin.AdminOperationException: Preferred replica leader election currently in progress for Set(). Aborting operation
	at kafka.admin.PreferredReplicaLeaderElectionCommand$.writePreferredReplicaElectionData(PreferredReplicaLeaderElectionCommand.scala:101)
	at kafka.admin.PreferredReplicaLeaderElectionCommand.moveLeaderToPreferredReplica(PreferredReplicaLeaderElectionCommand.scala:113)
	... 2 more
{code}

*Workaround*

One workaround I found was to delete the {{/controller}} znode in ZooKeeper, but this seems like swinging a big hammer.  Here's the console history of my ZooKeeper session.  The data associated with {{/controller}} was from a ""buggy"" test run, i.e. a test run where I did observe the indefinite loop error.

{code}
[zk: zookeeper1:2181(CONNECTED) 7] ls /
[zookeeper, admin, consumers, config, controller, brokers, controller_epoch]
[zk: zookeeper1:2181(CONNECTED) 21] ls /controller
[]
[zk: zookeeper1:2181(CONNECTED) 22] get /controller
{""version"":1,""brokerid"":0,""timestamp"":""1398764894941""}
cZxid = 0x2f2
ctime = Tue Apr 29 09:48:21 UTC 2014
mZxid = 0x2f2
mtime = Tue Apr 29 09:48:21 UTC 2014
pZxid = 0x2f2
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x145ac679efa0023
dataLength = 54
numChildren = 0
[zk: zookeeper1:2181(CONNECTED) 23] rmr /controller
{code}


*Addendum 1*

In Jason Rosenberg's case Kafka complained about a {{/consumer/*}} znode:

{code}
conflict in /consumers/myapp/ids/myapp_myhost-1394905418548-e159fc25 data: [...] stored data: [...]
2014-03-19 00:13:14,166 INFO [ZkClient-EventThread-51-myzkserver] utils.ZkUtils$ - I wrote this conflicted ephemeral node [...] at /consumers/myapp/ids/myapp_awa60.sjc1b.square-1394905418548-e159fc25 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry
{code}

In my case Kafka complained about {{/controller}}:

{code}
[2014-04-29 08:48:06,574] ERROR Controller 0 epoch 1 initiated state change for partition [test,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [test,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
[...]
[2014-04-29 09:33:16,161] INFO conflict in /controller data: {""version"":1,""brokerid"":0,""timestamp"":""1398761286651""} stored data: {""version"":1,""brokerid"":0,""timestamp"":""1398761286608""} (kafka.utils.ZkUtils$)
[2014-04-29 09:33:16,163] INFO I wrote this conflicted ephemeral node [{""version"":1,""brokerid"":0,""timestamp"":""1398761286651""}] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
{code}

From what I understand my error message is rather similar to the original error report, which a) also mentions a conflict for {{/controller}}, and b) where the issue seems to be different timestamp values.

*Addendum 2*

FWIW I noticed another similarity between my two ""buggy"" test runs.  In both cases the bug ""triggered"" 64 minutes after the last normal/successful state change.  Not sure what to make out of this observation. :-)  Unfortunately I do not have the full log files from those test runs, otherwise I would have provided them here.  I will make sure to capture all log files now that I'm on alert.

Buggy run #1, going from 07:44:47 to 08:48:06.
{code}
[2014-04-29 07:44:47,783] TRACE Broker 0 completed LeaderAndIsr request correlationId 7 from controller 0 epoch 1 for the become-leader transition for partition [test,0] (state.change.logger)
[2014-04-29 07:44:47,796] TRACE Controller 0 epoch 1 received response correlationId 7 for a request sent to broker id:0,host:kafka1,port:9092 (state.change.logger)
[2014-04-29 07:44:47,816] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition [test,0] in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 7 (state.change.logger)
[2014-04-29 07:44:47,818] TRACE Controller 0 epoch 1 received response correlationId 7 for a request sent to broker id:0,host:kafka1,port:9092 (state.change.logger)
[2014-04-29 08:48:06,559] TRACE Controller 0 epoch 1 changed partition [test,0] state from OnlinePartition to OfflinePartition (state.change.logger)
[2014-04-29 08:48:06,561] TRACE Controller 0 epoch 1 started leader election for partition [test,0] (state.change.logger)
[2014-04-29 08:48:06,574] ERROR Controller 0 epoch 1 initiated state change for partition [test,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [test,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
{code}

Buggy run #2, going from 10:08:31 to 11:12:31.
{code}
[2014-04-29 10:03:16,837] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition [test,0] in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 7 (state.change.logger)
[2014-04-29 10:03:16,838] TRACE Controller 0 epoch 1 received response correlationId 7 for a request sent to broker id:0,host:kafka1,port:9092 (state.change.logger)
[2014-04-29 10:08:31,393] TRACE Controller 0 epoch 1 started leader election for partition [test,0] (state.change.logger)
[2014-04-29 10:08:31,407] TRACE Controller 0 epoch 1 changed partition [test,0] from OnlinePartition to OnlinePartition with leader 0 (state.change.logger)
[2014-04-29 11:12:31,318] TRACE Controller 0 epoch 1 changed partition [test,0] state from OnlinePartition to OfflinePartition (state.change.logger)
[2014-04-29 11:12:31,318] TRACE Controller 0 epoch 1 started leader election for partition [test,0] (state.change.logger)
[2014-04-29 11:12:31,333] ERROR Controller 0 epoch 1 initiated state change for partition [test,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [test,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
{code};;;","29/Apr/14 23:11;junrao;Interesting, did you see any ZK session expiration in the broker log (search for Expired)?;;;","30/Apr/14 02:34;jbrosenberg@gmail.com;I'll add that we still see this from time to time (we're still on 0.8.0), and it's usually after an abnormal event, such as a failed meta-data request for a large group of topics, that times out, etc.  But once this happens, it's very difficult to make it go away, other than restarting the consumer.;;;","30/Apr/14 23:26;miguno;I could finally reproduce the bug again, though still not consistently yet.

And I think I have an idea what the root cause might be:  I was test-driving Kafka in several VMs locally on a Mac MBP laptop, and the energy saver settings (or sth similar) might be responsible for triggering the problem when the laptop was idle.  (In the test run below I intentionally let the laptop idle for 2-3 hours after creating a ""test"" topic and sending/consuming a few test massages.)  The timestamp of when the problem was triggered (11:01) correlates with me unlocking the laptop (user screen).  What's strange is that the laptop is configured not to go to sleep when idle, the hard disk is not asked to sleep either (and even if you did enable that setting in Mac OS X it does not have an effect on SSD's, which is the only disk installed in the laptop I was using), etc.  -- only the display is allowed to turn off after 10 minutes.  So even though the laptop is configured to be ""always on"" there apparently is something that throws off Kafka/ZooKeeper.  Also, as I said in my earlier comment I still cannot reproduce the issue consistently, i.e. sometimes Kafka/ZK work correctly after idling/unlocking;  still I think the root cause has ultimately to do with idling on Mac OS X.

Lastly, I don't know what the expected failure handling of Kafka/ZK is in such a scenario.  From what I can read from the logs below my setup seems to have simulated what could happen during a network partitioning (Kafka broker could not talk to ZooKeeper for a long time, hence ZK session expired, then Kafka could talk again to ZK, but couldn't fully recover).

FWIW I still list further log messages and details just in case that information may be useful in the future.


@Jun Rao:  Yes, I did see ZK expiration in {{controller.log}}:

{code}
INFO [SessionExpirationListener on 0], ZK expired; shut down all controller components and try to re-elect (kafka.controller.KafkaController$SessionExpirationListener)
{code}

Below are some further details.  Things turn bad at 11:01.

*kafka1 (Kafka broker)*

{{server.log}}

{code}
[2014-04-30 07:18:56,481] INFO Completed load of log test-0 with log end offset 0 (kafka.log.Log)
[2014-04-30 07:18:56,485] INFO Created log for partition [test,0] in /app/kafka/log with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, cleanup.policy -> delete, segment.ms -> 172800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 172800000}. (kafka.log.LogManager)
[2014-04-30 07:18:56,486] WARN Partition [test,0] on broker 0: No checkpointed highwatermark is found for partition [test,0] (kafka.cluster.Partition)
[2014-04-30 07:19:32,637] INFO Closing socket connection to /127.0.1.1. (kafka.network.Processor)
[2014-04-30 07:19:37,328] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2014-04-30 07:19:56,356] INFO Closing socket connection to /127.0.1.1. (kafka.network.Processor)
[2014-04-30 07:20:52,090] ERROR Closing socket for /127.0.1.1 because of error (kafka.network.Processor)
java.io.IOException: Connection reset by peer
        at sun.nio.ch.FileDispatcher.read0(Native Method)
        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:251)
        at sun.nio.ch.IOUtil.read(IOUtil.java:224)
        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:254)
        at kafka.utils.Utils$.read(Utils.scala:375)
        at kafka.network.BoundedByteBufferReceive.readFrom(BoundedByteBufferReceive.scala:54)
        at kafka.network.Processor.read(SocketServer.scala:347)
        at kafka.network.Processor.run(SocketServer.scala:245)
        at java.lang.Thread.run(Thread.java:701)
[2014-04-30 07:21:02,805] INFO Closing socket connection to /127.0.1.1. (kafka.network.Processor)
[2014-04-30 07:21:05,803] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2014-04-30 11:01:57,138] INFO Closing socket connection to /127.0.1.1. (kafka.network.Processor)
[2014-04-30 11:01:59,561] INFO Closing socket connection to /127.0.1.1. (kafka.network.Processor)
[2014-04-30 11:01:59,648] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2014-04-30 11:01:59,692] INFO conflict in /controller data: {""version"":1,""brokerid"":0,""timestamp"":""1398855719690""} stored data: {""version"":1,""brokerid"":0,""timestamp"":""1398855719646""} (kafka.utils.ZkUtils$)
[2014-04-30 11:01:59,699] INFO I wrote this conflicted ephemeral node [{""version"":1,""brokerid"":0,""timestamp"":""1398855719690""}] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2014-04-30 11:02:05,704] INFO conflict in /controller data: {""version"":1,""brokerid"":0,""timestamp"":""1398855719690""} stored data: {""version"":1,""brokerid"":0,""timestamp"":""1398855719646""} (kafka.utils.ZkUtils$)
[2014-04-30 11:02:05,711] INFO I wrote this conflicted ephemeral node [{""version"":1,""brokerid"":0,""timestamp"":""1398855719690""}] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
{code}


{{state-change.log}}

{code}
[2014-04-30 07:18:56,433] TRACE Controller 0 epoch 1 changed state of replica 0 for partition [test,0] from NewReplica to OnlineReplica (state.change.logger)
[2014-04-30 07:18:56,443] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) correlation id 7 from controller 0 epoch 1 for partition [test,0] (state.change.logger)
[2014-04-30 07:18:56,448] TRACE Broker 0 handling LeaderAndIsr request correlationId 7 from controller 0 epoch 1 starting the become-leader transition for partition [test,0] (state.change.logger)
[2014-04-30 07:18:56,455] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 1 with correlation id 7 for partition [test,0] (state.change.logger)
[2014-04-30 07:18:56,495] TRACE Broker 0 completed LeaderAndIsr request correlationId 7 from controller 0 epoch 1 for the become-leader transition for partition [test,0] (state.change.logger)
[2014-04-30 07:18:56,506] TRACE Controller 0 epoch 1 received response correlationId 7 for a request sent to broker id:0,host:kafka1,port:9092 (state.change.logger)
[2014-04-30 07:18:56,525] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition [test,0] in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 7 (state.change.logger)
[2014-04-30 07:18:56,526] TRACE Controller 0 epoch 1 received response correlationId 7 for a request sent to broker id:0,host:kafka1,port:9092 (state.change.logger)
[2014-04-30 11:01:59,564] TRACE Controller 0 epoch 1 changed partition [test,0] state from OnlinePartition to OfflinePartition (state.change.logger)
[2014-04-30 11:01:59,569] TRACE Controller 0 epoch 1 started leader election for partition [test,0] (state.change.logger)
[2014-04-30 11:01:59,589] ERROR Controller 0 epoch 1 initiated state change for partition [test,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [test,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
        at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:61)
        at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:336)
        at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:185)
        at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:99)
        at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:96)
        at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
        at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
        at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:96)
        at kafka.controller.KafkaController.onBrokerFailure(KafkaController.scala:433)
        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ReplicaStateMachine.scala:344)
        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$apply$mcV$sp$1.apply(ReplicaStateMachine.scala:330)
        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$apply$mcV$sp$1.apply(ReplicaStateMachine.scala:330)
        at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply$mcV$sp(ReplicaStateMachine.scala:329)
        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply(ReplicaStateMachine.scala:328)
        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply(ReplicaStateMachine.scala:328)
        at kafka.utils.Utils$.inLock(Utils.scala:538)
        at kafka.controller.ReplicaStateMachine$BrokerChangeListener.handleChildChange(ReplicaStateMachine.scala:327)
        at org.I0Itec.zkclient.ZkClient$7.run(ZkClient.java:568)
        at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2014-04-30 11:01:59,625] TRACE Controller 0 epoch 1 changed state of replica 0 for partition [test,0] from OnlineReplica to OfflineReplica (state.change.logger)
[2014-04-30 11:01:59,676] TRACE Controller 0 epoch 2 started leader election for partition [test,0] (state.change.logger)
[2014-04-30 11:01:59,686] ERROR Controller 0 epoch 2 initiated state change for partition [test,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [test,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
        at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:61)
{code}


{{controller.log}}

{code}
[2014-04-30 07:18:56,354] DEBUG [TopicChangeListener on Controller 0]: Topic change listener fired for path /brokers/topics with children test (kafka.controller.PartitionStateMachine$TopicChangeListener)
[2014-04-30 07:18:56,373] INFO [TopicChangeListener on Controller 0]: New topics: [Set(test)], deleted topics: [Set()], new partition replica assignment [Map([test,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[2014-04-30 07:18:56,373] INFO [Controller 0]: New topic creation callback for [test,0] (kafka.controller.KafkaController)
[2014-04-30 07:18:56,376] INFO [Controller 0]: New partition creation callback for [test,0] (kafka.controller.KafkaController)
[2014-04-30 07:18:56,376] INFO [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [test,0] (kafka.controller.PartitionStateMachine)
[2014-04-30 07:18:56,391] INFO [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=test,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[2014-04-30 07:18:56,394] INFO [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [test,0] (kafka.controller.PartitionStateMachine)
[2014-04-30 07:18:56,395] DEBUG [Partition state machine on Controller 0]: Live assigned replicas for partition [test,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[2014-04-30 07:18:56,398] DEBUG [Partition state machine on Controller 0]: Initializing leader and isr for partition [test,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[2014-04-30 07:18:56,431] INFO [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=test,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[2014-04-30 11:01:59,560] INFO [BrokerChangeListener on Controller 0]: Broker change listener fired for path /brokers/ids with children  (kafka.controller.ReplicaStateMachine$BrokerChangeListener)
[2014-04-30 11:01:59,560] INFO [BrokerChangeListener on Controller 0]: Newly added brokers: , deleted brokers: 0, all live brokers:  (kafka.controller.ReplicaStateMachine$BrokerChangeListener)
[2014-04-30 11:01:59,561] INFO [Controller-0-to-broker-0-send-thread], Shutting down (kafka.controller.RequestSendThread)
[2014-04-30 11:01:59,562] INFO [Controller-0-to-broker-0-send-thread], Stopped  (kafka.controller.RequestSendThread)
[2014-04-30 11:01:59,562] INFO [Controller-0-to-broker-0-send-thread], Shutdown completed (kafka.controller.RequestSendThread)
[2014-04-30 11:01:59,563] INFO [Controller 0]: Broker failure callback for 0 (kafka.controller.KafkaController)
[2014-04-30 11:01:59,564] INFO [Controller 0]: Removed ArrayBuffer() from list of shutting down brokers. (kafka.controller.KafkaController)
[2014-04-30 11:01:59,564] INFO [Partition state machine on Controller 0]: Invoking state change to OfflinePartition for partitions [test,0] (kafka.controller.PartitionStateMachine)
[2014-04-30 11:01:59,588] DEBUG [OfflinePartitionLeaderSelector]: No broker in ISR is alive for [test,0]. Pick the leader from the alive assigned replicas:  (kafka.controller.OfflinePartitionLeaderSelector)
[2014-04-30 11:01:59,595] INFO [Replica state machine on controller 0]: Invoking state change to OfflineReplica for replicas [Topic=test,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[2014-04-30 11:01:59,597] DEBUG [Controller 0]: Removing replica 0 from ISR 0 for partition [test,0]. (kafka.controller.KafkaController)
[2014-04-30 11:01:59,625] INFO [Controller 0]: New leader and ISR for partition [test,0] is {""leader"":-1,""leader_epoch"":1,""isr"":[]} (kafka.controller.KafkaController)
[2014-04-30 11:01:59,628] DEBUG The stop replica request (delete = true) sent to broker 0 is  (kafka.controller.ControllerBrokerRequestBatch)
[2014-04-30 11:01:59,629] DEBUG The stop replica request (delete = false) sent to broker 0 is [Topic=test,Partition=0,Replica=0] (kafka.controller.ControllerBrokerRequestBatch)
[2014-04-30 11:01:59,635] WARN [Channel manager on controller 0]: Not sending request Name: StopReplicaRequest; Version: 0; CorrelationId: 11; ClientId: ; DeletePartitions: false; ControllerId: 0; ControllerEpoch: 1; Partitions: [test,0] to broker 0, since it is offline. (kafka.controller.ControllerChannelManager)
[2014-04-30 11:01:59,644] INFO [Controller 0]: Controller shutdown complete (kafka.controller.KafkaController)
[2014-04-30 11:01:59,649] INFO [Controller 0]: Broker 0 starting become controller state transition (kafka.controller.KafkaController)
[2014-04-30 11:01:59,651] INFO [Controller 0]: Controller 0 incremented epoch to 2 (kafka.controller.KafkaController)
[2014-04-30 11:01:59,672] INFO [Controller 0]: Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
[2014-04-30 11:01:59,672] INFO [Controller 0]: Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
[2014-04-30 11:01:59,672] INFO [Controller 0]: Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
[2014-04-30 11:01:59,673] INFO [Controller 0]: Partitions being reassigned: Map() (kafka.controller.KafkaController)
[2014-04-30 11:01:59,673] INFO [Controller 0]: Partitions already reassigned: List() (kafka.controller.KafkaController)
[2014-04-30 11:01:59,673] INFO [Controller 0]: Resuming reassignment of partitions: Map() (kafka.controller.KafkaController)
[2014-04-30 11:01:59,675] INFO [Controller 0]: List of topics to be deleted:  (kafka.controller.KafkaController)
[2014-04-30 11:01:59,675] INFO [Controller 0]: List of topics ineligible for deletion: test (kafka.controller.KafkaController)
[2014-04-30 11:01:59,675] INFO [Controller 0]: Currently active brokers in the cluster: Set() (kafka.controller.KafkaController)
[2014-04-30 11:01:59,675] INFO [Controller 0]: Currently shutting brokers in the cluster: Set() (kafka.controller.KafkaController)
[2014-04-30 11:01:59,675] INFO [Controller 0]: Current list of topics in the cluster: Set(test) (kafka.controller.KafkaController)
[2014-04-30 11:01:59,676] INFO [Replica state machine on controller 0]: Started replica state machine with initial state -> Map([Topic=test,Partition=0,Replica=0] -> ReplicaDeletionIneligible) (kafka.controller.ReplicaStateMachine)
[2014-04-30 11:01:59,685] DEBUG [OfflinePartitionLeaderSelector]: No broker in ISR is alive for [test,0]. Pick the leader from the alive assigned replicas:  (kafka.controller.OfflinePartitionLeaderSelector)
[2014-04-30 11:01:59,686] INFO [Partition state machine on Controller 0]: Started partition state machine with initial state -> Map([test,0] -> OfflinePartition) (kafka.controller.PartitionStateMachine)
[2014-04-30 11:01:59,687] INFO [Controller 0]: Broker 0 is ready to serve as the new controller with epoch 2 (kafka.controller.KafkaController)
[2014-04-30 11:01:59,688] INFO [Controller 0]: Starting preferred replica leader election for partitions  (kafka.controller.KafkaController)
[2014-04-30 11:01:59,688] INFO [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions  (kafka.controller.PartitionStateMachine)
[2014-04-30 11:01:59,690] INFO [SessionExpirationListener on 0], ZK expired; shut down all controller components and try to re-elect (kafka.controller.KafkaController$SessionExpirationListener)
[2014-04-30 11:01:59,690] INFO [Controller 0]: Controller shutdown complete (kafka.controller.KafkaController)
{code}


*zookeeper1 (ZooKeeper server)*

{{zookeeper.log}}

{code}
2014-04-30 07:32:37,460 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /10.0.0.21:43468
2014-04-30 07:32:37,462 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@793] - Connection request from old client /10.0.0.21:43468; will be dropped if server is in r-o mode
2014-04-30 07:32:37,462 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@832] - Client attempting to renew session 0x145b15f015d0000 at /10.0.0.21:43468
2014-04-30 07:32:37,463 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@595] - Established session 0x145b15f015d0000 with negotiated timeout 6000 for client /10.0.0.21:43468
2014-04-30 11:01:57,832 [myid:] - INFO  [SessionTracker:ZooKeeperServer@325] - Expiring session 0x145b15f015d0000, timeout of 6000ms exceeded
2014-04-30 11:01:57,833 [myid:] - INFO  [SessionTracker:ZooKeeperServer@325] - Expiring session 0x145b15f015d0009, timeout of 6000ms exceeded
2014-04-30 11:01:57,837 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@476] - Processed session termination for sessionid: 0x145b15f015d0000
2014-04-30 11:01:57,837 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@476] - Processed session termination for sessionid: 0x145b15f015d0009
2014-04-30 11:01:57,842 [myid:] - INFO  [SyncThread:0:NIOServerCnxn@1001] - Closed socket connection for client /10.0.0.21:43468 which had sessionid 0x145b15f015d0000
2014-04-30 11:01:57,845 [myid:] - INFO  [SyncThread:0:NIOServerCnxn@1001] - Closed socket connection for client /10.0.0.21:43467 which had sessionid 0x145b15f015d0009
2014-04-30 11:01:59,001 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /10.0.0.21:43469
2014-04-30 11:01:59,002 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@793] - Connection request from old client /10.0.0.21:43469; will be dropped if server is in r-o mode
2014-04-30 11:01:59,002 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@832] - Client attempting to renew session 0x145b15f015d0009 at /10.0.0.21:43469
2014-04-30 11:01:59,003 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@588] - Invalid session 0x145b15f015d0009 for client /10.0.0.21:43469, probably expired
2014-04-30 11:01:59,004 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1001] - Closed socket connection for client /10.0.0.21:43469 which had sessionid 0x145b15f015d0009
2014-04-30 11:01:59,005 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /10.0.0.21:43470
2014-04-30 11:01:59,008 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@793] - Connection request from old client /10.0.0.21:43470; will be dropped if server is in r-o mode
2014-04-30 11:01:59,008 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@839] - Client attempting to establish new session at /10.0.0.21:43470
2014-04-30 11:01:59,012 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@595] - Established session 0x145b15f015d000b with negotiated timeout 6000 for client /10.0.0.21:43470
2014-04-30 11:01:59,545 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /10.0.0.21:43471
2014-04-30 11:01:59,545 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@793] - Connection request from old client /10.0.0.21:43471; will be dropped if server is in r-o mode
2014-04-30 11:01:59,545 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@832] - Client attempting to renew session 0x145b15f015d0000 at /10.0.0.21:43471
2014-04-30 11:01:59,546 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@588] - Invalid session 0x145b15f015d0000 for client /10.0.0.21:43471, probably expired
2014-04-30 11:01:59,546 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1001] - Closed socket connection for client /10.0.0.21:43471 which had sessionid 0x145b15f015d0000
2014-04-30 11:01:59,553 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /10.0.0.21:43472
2014-04-30 11:01:59,555 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@793] - Connection request from old client /10.0.0.21:43472; will be dropped if server is in r-o mode
2014-04-30 11:01:59,556 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@839] - Client attempting to establish new session at /10.0.0.21:43472
2014-04-30 11:01:59,557 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@595] - Established session 0x145b15f015d000c with negotiated timeout 6000 for client /10.0.0.21:43472
2014-04-30 11:01:59,687 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@627] - Got user-level KeeperException when processing sessionid:0x145b15f015d000c type:delete cxid:0x19 zxid:0x5c txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2014-04-30 11:01:59,689 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@627] - Got user-level KeeperException when processing sessionid:0x145b15f015d000c type:create cxid:0x1a zxid:0x5d txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2014-04-30 11:02:05,700 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@627] - Got user-level KeeperException when processing sessionid:0x145b15f015d000c type:create cxid:0x1d zxid:0x5e txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
{code}


*State of topic after issue did trigger*

{code}
$ date;bin/kafka-topics.sh --zookeeper zookeeper1 --describe --topic test
Wed Apr 30 11:02:25 UTC 2014
Topic:test	PartitionCount:1	ReplicationFactor:1	Configs:
	Topic: test	Partition: 0	Leader: -1	Replicas: 0	Isr:
{code}


*Notes*

Kafka kinda recovered at some point.

What indicated a recovery:

- {{state-change.log}} reverted back to normal messages (partition wen tfrom OfflinePartition to OnlinePartition with leader 0; leader -1 was replaced with leader 0; etc.)
- {{kafka-topics.sh --descripe --topic test}} showed normal operations, too, i.e. one partition with one replica with one leader and with one ISR.

What speaks against a full recovery:

- {{server.log}} was still showing an indefinite loop of messages {{I wrote this conflicted ephemeral node [{""version"":1,""brokerid"":0,""timestamp"":""1398860644679""}] at /controller a while back in a different session}}.;;;","24/Jul/14 14:58;vincentye38;I think the problem is because registerSessionExpirationListener() is called before controllerElector.startup in kafkaController.startup().
If the session expired before the election happens in controllerElector.startup, SessionExpirationListener calls election to create a ephemeral node. Then the election triggered by controllerElector.startup will run into the infinite loop dealing with the ephemeral node bug.;;;","25/Jul/14 13:19;junrao;I think the proposed fix in KAFKA-1451 will fix this issue too.;;;","21/Aug/14 23:49;Yiyang Li;Hello, I am totally new to Kafka, and we are .Net developers who is testing the kafka by the kafka-net library. The Nuget package is still under alpha version, leaving lots of functionality not implemented. 

We recently got this problem when we embed a producer in a service, where according to the library, it will do a ResponseTimeoutCheck every 30000 ms. However, one of the client throws an error (the others are fine)

ERROR Closing socket for /10.207.x.x because of error (kafka.network.Processor)
java.io.IOException: An existing connection was forcibly closed by the remote host
        at sun.nio.ch.SocketDispatcher.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:51)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:466)
        at kafka.api.FetchResponseSend.writeTo(FetchResponse.scala:217)
        at kafka.network.Processor.write(SocketServer.scala:375)
        at kafka.network.Processor.run(SocketServer.scala:247)
        at java.lang.Thread.run(Thread.java:745)
log4j:ERROR Failed to rename [/cygdrive/c/kafka/bin/../logs/server.log] to [/cygdrive/c/kafka/bin/../logs/server.log.2014-08-20-17].

under the kafka-server-start.sh

I have change the log4j properties to 

log4j.appender.kafkaAppender.DatePattern='.'yyyy-MM
log4j.appender.kafkaAppender.File=${kafka.logs.dir}/server.log

Other backgound:
Kafka binaries: Scala 2.9.2 - kafka_2.9.2-0.8.1.1
Brokers: 3 brokers in 3 different machines, using the same port under each IP  (borker id = 0, 1, 2)
Zookeeper: 2181 port at one of the brokers

I understand that it might be hard to reproduce as it might be the problem in incomplete .Net client

Details of ResponseTimeoutCheck:

https://github.com/YiyangLi/kafka-net/blob/master/src/kafka-net/KafkaConnection.cs (Line 200)

Thanks. 
;;;","22/Aug/14 00:32;guozhang;Hello Yiyang,

Could you send an email to the users mailing list about your issue since it seems not relevant to this jira?;;;","22/Aug/14 00:36;Yiyang Li;could you elaborate the users mailing list? 

It's the same issue as the following:

http://grokbase.com/t/kafka/users/141nmnah7e/kafka-server-occure-java-nio-bufferunderflowexception;;;","22/Aug/14 00:58;guozhang;You can send an email to users@kafka.apache.org.

Here is the summary of the mailing lists:

http://kafka.apache.org/contact.html;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Initial checkout and build failing,KAFKA-1940,12773946,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,mlem,mlem,mlem,11/Feb/15 04:19,28/Apr/15 10:37,22/Mar/23 15:10,28/Apr/15 10:37,0.8.1.2,,,,,,0.9.0.0,,,,,,,build,,,,0,build,,,,,"when performing `gradle wrapper` and `gradlew build` as a ""new"" developer, I get an exception: 
{code}
C:\development\git\kafka>gradlew build --stacktrace
<...>
FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':core:compileScala'.
> com.typesafe.zinc.Setup.create(Lcom/typesafe/zinc/ScalaLocation;Lcom/typesafe/zinc/SbtJars;Ljava/io/File;)Lcom/typesaf
e/zinc/Setup;
{code}

Details: https://gist.github.com/mlem/ddff83cc8a25b040c157

Current Commit:
{code}
C:\development\git\kafka>git rev-parse --verify HEAD
71602de0bbf7727f498a812033027f6cbfe34eb8
{code}

I am evaluating kafka for my company and wanted to run some tests with it, but couldn't due to this error. I know gradle can be tricky and it's not easy to setup everything correct, but this kind of bugs turns possible commiters/users off.","Groovy:       1.8.6
Ant:          Apache Ant(TM) version 1.9.2 compiled on July 8 2013
Ivy:          2.2.0
JVM:          1.8.0_25 (Oracle Corporation 25.25-b02)
OS:           Windows 7 6.1 amd64",becket_qin,junrao,mlem,yaitskov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Apr/15 01:28;yaitskov;zinc-upgrade.patch;https://issues.apache.org/jira/secure/attachment/12727962/zinc-upgrade.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Apr 28 02:37:41 UTC 2015,,,,,,,,,,"0|i25fsv:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"24/Apr/15 16:30;yaitskov;I tried to upgrade zinc library up to 0.3.7 and the issue disappeared.
With the patch applied tests on Scala are launched successfully.
Though 4 of these tests are appeared broken. I don't know whether it's related to the upgrade because the change Scala tests were  not runnable.

{noformat}
kafka.server.LogRecoveryTest > testHWCheckpointWithFailuresMultipleLogSegments FAILED
    junit.framework.AssertionFailedError: Failed to update high watermark for follower after timeout
        at junit.framework.Assert.fail(Assert.java:47)
        at kafka.utils.TestUtils$.waitUntilTrue(TestUtils.scala:619)
        at kafka.server.LogRecoveryTest.testHWCheckpointWithFailuresMultipleLogSegments(LogRecoveryTest.scala:214)

kafka.server.LogRecoveryTest > testHWCheckpointNoFailuresMultipleLogSegments FAILED
    junit.framework.AssertionFailedError: Failed to update high watermark for follower after timeout
        at junit.framework.Assert.fail(Assert.java:47)
        at kafka.utils.TestUtils$.waitUntilTrue(TestUtils.scala:619)
        at kafka.server.LogRecoveryTest.testHWCheckpointNoFailuresMultipleLogSegments(LogRecoveryTest.scala:168)
{noformat}

{noformat}
kafka.producer.AsyncProducerTest > testFailedSendRetryLogic FAILED
    kafka.common.FailedToSendMessageException: Failed to send messages after 3 tries.
        at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:91)
        at kafka.producer.AsyncProducerTest.testFailedSendRetryLogic(AsyncProducerTest.scala:415)

kafka.producer.AsyncProducerTest > testQueueTimeExpired PASSED

kafka.producer.AsyncProducerTest > testNoBroker FAILED
    org.scalatest.junit.JUnitTestFailedError: Should fail with FailedToSendMessageException
        at org.scalatest.junit.AssertionsForJUnit$class.newAssertionFailedException(AssertionsForJUnit.scala:101)
        at org.scalatest.junit.JUnit3Suite.newAssertionFailedException(JUnit3Suite.scala:149)
        at org.scalatest.Assertions$class.fail(Assertions.scala:711)
        at org.scalatest.junit.JUnit3Suite.fail(JUnit3Suite.scala:149)
        at kafka.producer.AsyncProducerTest.testNoBroker(AsyncProducerTest.scala:300)
{noformat};;;","25/Apr/15 01:28;yaitskov;Reattach the patch file without colored diff.;;;","27/Apr/15 12:15;becket_qin;The kafka.producer.AsyncProducerTest failures should be irrelevant. KAFKA-2103 is created for those two tests failures.;;;","28/Apr/15 10:37;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
broker can not start itself after kafka is killed with -9,KAFKA-1112,12677081,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,jkreps,KaneK,KaneK,01/Nov/13 23:03,14/Jan/15 13:22,22/Mar/23 15:10,19/Nov/13 10:33,0.8.0,0.8.1,,,,,0.8.1,,,,,,,log,,,,3,,,,,,"When I kill kafka with -9, broker cannot start itself because of corrupted index logs. I think kafka should try to delete/rebuild indexes itself without manual intervention. ",,alexismidon,davidlao,dgoya,dmaverick,eidi,guozhang,jkreps,junrao,KaneK,kzadorozhny,mazhar.shaikh.in,nehanarkhede,noslowerdna,qdutj,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-757,,,,,,,,,,"13/Nov/13 13:04;jkreps;KAFKA-1112-v1.patch;https://issues.apache.org/jira/secure/attachment/12613527/KAFKA-1112-v1.patch","15/Nov/13 04:57;jkreps;KAFKA-1112-v2.patch;https://issues.apache.org/jira/secure/attachment/12613931/KAFKA-1112-v2.patch","16/Nov/13 02:04;jkreps;KAFKA-1112-v3.patch;https://issues.apache.org/jira/secure/attachment/12614094/KAFKA-1112-v3.patch","19/Nov/13 06:10;junrao;KAFKA-1112-v4.patch;https://issues.apache.org/jira/secure/attachment/12614489/KAFKA-1112-v4.patch","06/Nov/13 02:57;guozhang;KAFKA-1112.out;https://issues.apache.org/jira/secure/attachment/12612219/KAFKA-1112.out",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,356457,,,Wed Jan 14 05:22:10 UTC 2015,,,,,,,,,,"0|i1pg8n:",356745,,,,,,,,,,,,,,,,,,,,"02/Nov/13 01:22;dmaverick;We've also faced with such behavior. Moreover, it doesn't fail right after startup, it start listening for requests(at least open the port) before checking  the index and syncing internal state. Thus it kind of difficult to figure out from startup script whether Kafka actually started without adding some ugly sleeps.;;;","06/Nov/13 02:43;nehanarkhede;Stack trace -

[2013-11-01 17:46:02,685] INFO Loading log 'foo-4' (kafka.log.LogManager)
[2013-11-01 17:46:04,898] FATAL Fatal error during KafkaServerStable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
java.lang.IllegalArgumentException: requirement failed: Corrupt index found, index file (/mnt/u001/temp/kafka-logs/foo-4/00000000000000000000.index) has non-zero size but the last offset is 0 and the base offset is 0
at scala.Predef$.require(Predef.scala:145)
at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:161)
at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:160)
at scala.collection.Iterator$class.foreach(Iterator.scala:631)
at scala.collection.JavaConversions$JIteratorWrapper.foreach(JavaConversions.scala:474)
at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
at scala.collection.JavaConversions$JCollectionWrapper.foreach(JavaCo;;;","06/Nov/13 02:57;guozhang;Attached another stack trace with more debugging turned on. The root cause is that when we load the index file, the initial size is set to the limit of the file, and hence the position is pointing to the last entry. In most cases the last entry will be 0, and the recoveryLog process will skip since it shows the latest offset is smaller than the checkpoint. But when doing the sanity check it finds the number of entries is non-zero (actually the max number of entries) while the last offset is equal to the base offset since reading the last entry gives you 0 relative offset.;;;","08/Nov/13 21:21;dmaverick;Could be related to this issue KAFKA-757;;;","09/Nov/13 03:53;guozhang;Yes. We have realized this bug before and tried to fix it, but it seems we still missed some cases.;;;","13/Nov/13 13:04;jkreps;The way the check was supposed to work was this: if the last offset in the file is the recoveryPoint-1 then skip the recovery (because the whole file is flushed). The way this was implemented was by using the last entry in the index to find the final message.

Overall I feel this is a bit of a hack, but we wanted to separate out the ""fsync is async"" feature from a full incremental recovery implementation that only recovers unflushed data.

The immediate problem was that we broke the short circuit by adding code to try to handle a corner case: what if log is truncated after to a flush and hence the end of the log is < recovery point. This was just totally broken and we were short circuiting out of the check in virtually all cases including corrupt index.

This issue wasn't caught because there was a bug in the log corruption unit test that gave a false pass on all index corruptions. :-(

The fix is the following:
1. Fix the logical bug
2. Add LogSegment.needsRecovery() which is a more paranoid version of what we were doing before that attempts to be safe regardless of any index or log corruption that may have occurred. Having this method here is a little hacky but probably okay until we get a full incremental recovery impl.
3. Fix the unit test that covers this.
;;;","14/Nov/13 01:25;junrao;Thanks for the patch. A few comments.

1. I am a bit concerned of depending on a potentially corrupted index to look for recoveryPoint - 1 in LogSegment.needsRecovery(). If the index points to an arbitrary position in FileMessageSet, the offset value that FileMessageSet.searchFor() finds  is garbage. If that value happens to be larger than targetOffset, we will assume that we find targetOffset, but in fact we haven't.

2. LogTest.testCorruptLog(): Is the println statement needed?

3. Could you rebase?;;;","14/Nov/13 01:56;nehanarkhede;Thanks for the patch. Few comments -

1. In the most common case of needsRecovery, the position of the last entry will be zero. In this case, we will search the entire log segment up until the recovery point. This will slow down server startup but probably only when we really need recovery.
2. LogSegment: We have to be carefully => We have to be careful
3. Log: If sanityCheck throws an exception, can we automatically invoke index rebuild instead of bailing out?
4. Could you rebase?
5. Could you give the patch review tool a spin? The setup is minimal and we can save time for this and future reviews - https://cwiki.apache.org/confluence/display/KAFKA/Kafka+patch+review+tool#Kafkapatchreviewtool-1.Setup
Usage: 
python kafka-patch-review.py -j KAFKA-1112 -b trunk;;;","14/Nov/13 01:58;jkreps;Actually I am attempting to cover every possible case here, so the only case that should go through is the one where the offset of the final message is recoveryPoint-1 exactly. Notice that the unit test actually runs through 50 cases of random garbage appended to the index so assuming that test is write I think this does work.;;;","14/Nov/13 02:23;guozhang;Regarding Jun's comment #1, I am more concerned about using searchFor function on a FileMessageSet that might be corrupted. From the code it seems if FileMessageSet is corrupted the searchFor function may actually not return due to variable position not monotonically increasing?;;;","14/Nov/13 13:54;davidlao;I hitting this exact issue. For what it's worth the content of the corrupt index file is consist of 00's for the entire file.;;;","14/Nov/13 15:14;davidlao;Jay , can you provide a patch for the 0.8 branch as well? Thanks.;;;","15/Nov/13 04:57;jkreps;Added a new patch that addresses issues raised.

Jun
1. I don't think this is true. The check is for exact match.
2. Removed.
3. Done

Neha
1. I think I am handling this--in the case of zero we don't do a full scan.
2. Ack, fixed.
3. Well the sanity check is POST recovery. So if we have a corrupt index after recovery we have a bug, I don't think we should automatically try to recovery from this (that would be another recovery).
4. done
5. Yeah, haven't had time yet.;;;","15/Nov/13 13:14;junrao;The following is my confusion.

The patch relies on a potentially corrupted index to find the right starting position in the segment file. What if the starting position given by the last index entry is corrupted? Then, the position could point to the middle of a message in the segment file. Then, the offset value we read from the segment file could be anything. If that value happens to match recoverPoint - 1, we could think no recovery is needed, but the segment file is actually corrupted. 

Similarly, even if the index file is not corrupted, the segment file could still be corrupted before recoverPoint - 1 (since the unit of flushing is a page). It's also possible that we read a corrupted piece of data as the offset that happens to match recoverPoint - 1, and therefore incorrectly think that recovery is not needed.;;;","16/Nov/13 01:14;jkreps;David, this should not be happening in 0.8. If it is I suspect it is a different problem that causes the same bad outcome. Are you seeing this on 0.8? If so how reproducable is it?;;;","16/Nov/13 01:20;jkreps;Jun, this is true.

However, if you think about it recovery of the log has the same problem. We read a message and then compare it to its CRC. The CRC is a 32 bit number. The crc could certainly match the message by chance.

In this case we compare to a 64 bit number so this should be less likely. But in reality there are many rare events here: (1) we hard crash, (2) hard crash leads to corruption, (3) corruption of index points to a location that exactly matches the recovery offset.

In general I think peoples concern with this approach is that it is just kind of hacky. I agree with this complaint and am sort of disappointed with this set of changes overall.

I will post a slightly more paranoid version of the check, and then let's discuss that.;;;","16/Nov/13 02:04;jkreps;Okay here is a maximally paranoid patch.;;;","16/Nov/13 02:07;guozhang;How about we resort back to the clean shutdown file for recovery checking, and if recovery is needed, we can use the recovery point to optimize recovery overhead.;;;","16/Nov/13 04:43;jkreps;Yeah I would not be opposed to that as an alternative. Both are really a hack.

I guess the questions is what should the end state be?;;;","19/Nov/13 01:13;junrao;Thinking about this a bit more. The end state is that we want to only recover the portion of the log segment from the recovery point, instead of recovering the whole log segment. The dilemma is that we are not sure what portion of the index is valid. Scanning from the beginning of the log segment defeats the purpose of incremental recovery. One possible solution is to checkpoint an index recovery point, in addition to the recovery offset per log. The index recovery point is the # of valid index entries in the segment to which the recovery offset belongs. This way, on startup, we will be sure that the data in the last valid index entry is not corrupted and we can use it to quickly locate the recovery offset in the log file.

;;;","19/Nov/13 02:36;guozhang;Did some research on network about ""fsync"", and it seems fsync can be reliable even with disk's block-write behavior since it is sequential, which means even file system crashed during fsync we will not expect random behavior.

;;;","19/Nov/13 02:57;nehanarkhede;[~junrao] This approach seems reasonable unless I'm missing any caveats in Log. [~jkreps] what do you think?;;;","19/Nov/13 04:02;jkreps;Yeah at a high-level there are a couple of things we could do:
1. Non-incremental 
    a. Harden the current approach (what the attached patches do)
    b. Use the clean shutdown file 
2. Implement incremental recovery (what Jun is proposing)

All of these are good. 1a is implemented, but is arguably gross. I am open to 1b or 2 or a short-term/long-term thing.

For 2 I think the details to figure out would be 
1. OffsetCheckpoint is shared so adding the position to that file will impact other use cases how will that be handled?
2. I suspect that if we want to move to positions we should do something like (file, log_position, index_position) rather than a mixture of logical and physical.
3. We need to ensure that log compaction is thought through. This could cause the physical position to change. That could be fine but we need to reason through it.
4. We need to ensure that we handle truncation which implies that a position X could be stable, then deleted, then rewritten differently without flush. This may be fine we just have to think it through.;;;","19/Nov/13 06:10;junrao;Ok, so it seems that the end state is not that simple and may need some more thoughts. I took patch v3 , removed the recovery part in LogSegment and replaced it with the simpler approach using the clean shutdown file.;;;","19/Nov/13 06:53;nehanarkhede;Thanks for the patch, Jun! Overall, looks good (+1). Few minor comments that you can address on checkin -

1. Log
- okay we need to actually recovery this log => okay we need to actually recover this log

2. OffsetIndex
- In sanityCheck(), in one error message, we print the index file's absolute path and in another, we print only the name. Can we standardize on one? It is better to print the entire path since we can have more than one data directories.
;;;","19/Nov/13 07:07;jkreps;+1 lgtm.;;;","19/Nov/13 10:33;junrao;Thanks for the reviews. Committed to trunk after addressing Neha's comments.;;;","26/Dec/13 03:25;dgoya;Commenting here as requested.

After migrating a cluster from 0.8.0 to 0.8.1 (trunk/87efda7) I had a few brokers that wouldn't come up.

This is the exception I ran into, I was able to fix it by deleting the /data/kafka/logs/Events2-124/ directory.  That directory contained a non zero size index file and a zero size log file.  I had a bunch of these directories scattered around the cluster.  I suspect they were there from partition reassignment failures which happened when the cluster was at 0.8.0.

[2013-12-18 02:40:37,163] FATAL Fatal error during KafkaServerStable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
java.lang.IllegalArgumentException: requirement failed: Corrupt index found, index file (/data/kafka/logs/Events2-124/00000000000000000000.index) has non-zero size but the last offset is 0 and the base offset is 0
	at scala.Predef$.require(Predef.scala:145)
	at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:160)
	at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:159)
	at scala.collection.Iterator$class.foreach(Iterator.scala:631)
	at scala.collection.JavaConversions$JIteratorWrapper.foreach(JavaConversions.scala:474)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
	at scala.collection.JavaConversions$JCollectionWrapper.foreach(JavaConversions.scala:495)
	at kafka.log.Log.loadSegments(Log.scala:159)
	at kafka.log.Log.<init>(Log.scala:64)
	at kafka.log.LogManager$$anonfun$loadLogs$1$$anonfun$apply$3.apply(LogManager.scala:120)
	at kafka.log.LogManager$$anonfun$loadLogs$1$$anonfun$apply$3.apply(LogManager.scala:115)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)
	at scala.collection.mutable.ArrayOps.foreach(ArrayOps.scala:34)
	at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:115)
	at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:107)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:32)
	at kafka.log.LogManager.loadLogs(LogManager.scala:107)
	at kafka.log.LogManager.<init>(LogManager.scala:59);;;","12/Jul/14 08:09;alexismidon;Hello,

I suffered from the same error using Kafka 0.8.1. Should I reopen this issue or create a new one?

{code}
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,696 INFO main kafka.server.KafkaServer.info - [Kafka Server 847605514], starting
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,698 INFO main kafka.server.KafkaServer.info - [Kafka Server 847605514], Connecting to zookeeper on zk-main0.XXX:2181,zk-main1.XXX:2181,zk-main2.XXXX:2181/production/kafka/main
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,708 INFO ZkClient-EventThread-14-zk-main0.XXX.com:2181,zk-main1.XXX.com:2181,zk-main2.XXX.com:2181,zk-main3.XXX.com:2181,zk-main4.XXX.com:2181/production/kafka/main org.I0Itec.zkclient.ZkEventThread.run - Starting ZkClient event thread.
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,714 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:zookeeper.version=3.3.3-1203054, built on 11/17/2011 05:47 GMT
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,714 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:host.name=i-6b948138.inst.aws.airbnb.com
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,714 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.version=1.7.0_55
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,715 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.vendor=Oracle Corporation
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,715 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.home=/usr/lib/jvm/jre-7-oracle-x64/jre
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,715 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.class.path=libs/snappy-java-1.0.5.jar:libs/scala-library-2.10.1.jar:libs/slf4j-api-1.7.2.jar:libs/jopt-simple-3.2.jar:libs/metrics-annotation-2.2.0.jar:libs/log4j-1.2.15.jar:libs/kafka_2.10-0.8.1.jar:libs/zkclient-0.3.jar:libs/zookeeper-3.3.4.jar:libs/metrics-core-2.2.0.jar
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,715 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,716 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.io.tmpdir=/tmp
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,716 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.compiler=<NA>
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,716 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:os.name=Linux
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,716 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:os.arch=amd64
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,717 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:os.version=3.2.0-61-virtual
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,717 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:user.name=kafka
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,717 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:user.home=/srv/kafka
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,717 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:user.dir=/srv/kafka/kafka_2.10-0.8.1
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,718 INFO main org.apache.zookeeper.ZooKeeper.<init> - Initiating client connection, connectString=zk-main0.XXX.com:2181,zk-main1.XXX.com:2181,zk-main2.XXX.com:2181,zk-main3.XXX.com:2181,zk-main4.XXX.com:2181/production/kafka/main sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4758af63
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,733 INFO main-SendThread() org.apache.zookeeper.ClientCnxn.startConnect - Opening socket connection to server zk-main1.XXX.com/10.12.135.61:2181
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,738 INFO main-SendThread(zk-main1.XXX.com:2181) org.apache.zookeeper.ClientCnxn.primeConnection - Socket connection established to zk-main1.XXX.com/10.12.135.61:2181, initiating session
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,745 INFO main-SendThread(zk-main1.XXX.com:2181) org.apache.zookeeper.ClientCnxn.readConnectResult - Session establishment complete on server zk-main1.XXX.com/10.12.135.61:2181, sessionid = 0x646838f07761601, negotiated timeout = 6000
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,747 INFO main-EventThread org.I0Itec.zkclient.ZkClient.processStateChanged - zookeeper state changed (SyncConnected)
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,961 INFO main kafka.log.LogManager.info - Found clean shutdown file. Skipping recovery for all logs in data directory '/mnt/kafka_logs'
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,962 INFO main kafka.log.LogManager.info - Loading log 'flog-30'
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg 2014-07-11 - 00:53:18,349 FATAL main kafka.server.KafkaServerStartable.fatal - Fatal error during KafkaServerStable startup. Prepare to shutdown
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg java.lang.IllegalArgumentException: - requirement failed: Corrupt index found, index file (/mnt/kafka_logs/flog-30/00000000000121158146.index) has non-zero size but the last offset is 121158146 and the base offset is 121158146
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.Predef$.require(Predef.scala:233)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.OffsetIndex.sanityCheck(OffsetIndex.scala:352)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:159)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:158)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.Iterator$class.foreach(Iterator.scala:727)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.Log.loadSegments(Log.scala:158)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.Log.<init>(Log.scala:64)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager$$anonfun$loadLogs$1$$anonfun$apply$4.apply(LogManager.scala:118)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager$$anonfun$loadLogs$1$$anonfun$apply$4.apply(LogManager.scala:113)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:105)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:113)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:105)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager.loadLogs(LogManager.scala:105)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager.<init>(LogManager.scala:57)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:275)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.server.KafkaServer.startup(KafkaServer.scala:72)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:34)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.Kafka$.main(Kafka.scala:46)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.Kafka.main(Kafka.scala)
2014-07-11T00:53:18+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:18,351 INFO main kafka.server.KafkaServer.info - [Kafka Server 847605514], shutting down
2014-07-11T00:53:18+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:18,353 INFO ZkClient-EventThread-14-zk-main0.XXX.com:2181,zk-main1.XXX.com:2181,zk-main2.XXX.com:2181,zk-main3.XXX.com:2181,zk-main4.XXX.com:2181/production/kafka/main org.I0Itec.zkclient.ZkEventThread.run - Terminate ZkClient event thread.
{code};;;","16/Jul/14 23:22;junrao;This seems to happen on a clean restart (the following log entry indicates there is no log recovery). So, this could be a different issue. Could you open a separate jira?

2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,961 INFO main kafka.log.LogManager.info - Found clean shutdown file. Skipping recovery for all logs in data directory '/mnt/kafka_logs';;;","22/Jul/14 01:49;alexismidon;I created https://issues.apache.org/jira/browse/KAFKA-1554.
thanks;;;","14/Jan/15 13:22;qdutj;I also met similar issues in Kafka-2.9.2-0.8.1 ( after an uncleanShutDown --- kill -9. ). 
I am afraid that I cannot provide more logs since it was months ago: 
******************************************************************************************************************************
FATAL Fatal error during KafkaServerStable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
java.lang.IllegalArgumentException: requirement failed: Corrupt index found, index file (/home/storm/kafka_2.9.2-0.8.1/logs/tracker-1/00000000000006911940.index) has non-zero size but the last offset is 6911940 and the base offset is 6911940
******************************************************************************************************************************
Here is my analysis:
Once unclean shutdown, Kafka needs to rebuild index files for her logsegments when restarted.
If InvalidOffsetException is thrown when appending entries to an index file,    recoverLog()  function will handle it by truncating the log segment to baseOffset (==> lastIndexEntry == baseOffset ). 
However, since the index files are written by mmap, OS will flush the update to disks in time. It means the index file already has some entries now.
I am a beginner for scala, just guessing the logSegment with InvalidOffsetException thrown has been passed by the iterator, so it was not deleted in fact? (I mean all log segments after it will be deleted in recoverLog() in log.scala. )
This log segment missed to delete could not pass sanityCheck(), since it has index file with non-zero size but lastIndexEntry == baseOffset ( it was truncated to baseOffset when handling the InvalidOffsetException. ).
Quite sorry if any mistake above.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Exception categories / hierarchy in clients,KAFKA-1863,12767525,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,guozhang,guozhang,15/Jan/15 03:07,17/May/16 22:15,22/Mar/23 15:10,14/Mar/15 06:18,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"In the new clients package we introduces a new set of exceptions, but its hierarchy is not very clear as of today:

{code}
RuntimeException -> KafkaException -> BufferExhastedException
                                                           -> ConfigException
                                                           -> SerializationException
                                                           -> QuotaViolationException
                                                           -> SchemaException

                                                           -> ApiException

ApiException -> InvalidTopicException
                     -> OffsetMetadataTooLarge (probabaly need to be renamed)
                     -> RecordBatchTooLargeException
                     -> RecordTooLargeException
                     -> UnknownServerException

                     -> RetriableException

RetriableException -> CorruptRecordException
                               -> InvalidMetadataException
                               -> NotEnoughtReplicasAfterAppendException
                               -> NotEnoughReplicasException
                               -> OffsetOutOfRangeException
                               -> TimeoutException
                               -> UnknownTopicOrPartitionException
{code}

KafkaProducer.send() may throw KafkaExceptions that are not ApiExceptions; other exceptions will be set in the returned future metadata.

We need better to

1. Re-examine the hierarchy. For example, for producers only exceptions that are thrown directly from the caller thread before it is appended to the batch buffer should be ApiExceptions; some exceptions could be renamed / merged.

2. Clearly document the exception category / hierarchy as part of the release.

[~criccomini] may have some more feedbacks for this issue from Samza's usage experience. [~jkreps]",,criccomini,dana.powers,guozhang,jkreps,navina,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1865,,SAMZA-227,,,,,,,,"05/Mar/15 02:39;guozhang;KAFKA-1863.patch;https://issues.apache.org/jira/secure/attachment/12702577/KAFKA-1863.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Mar 13 22:17:57 UTC 2015,,,,,,,,,,"0|i24djz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"15/Jan/15 06:36;navina;Summarizing the issue we face in Samza:

In Samza, we want to be able to retry producer.send when certain exceptions (mostly, RetriableException) occur, that can be mitigated over time with retries. This way, we can leverage the pipelining feature in the new API, while also making sure that a single send failure does not bring down the Samza container.

The main point of concern is that the defined callback can get invoked in either the main thread or the IO thread from Kafka. This means we have to catch exceptions in more than one point in Samza producer code to ensure that we retry on the right exceptions and also, have to share states across the main thread and the IO thread (which executes the callback). 

A clearly defined hierarchy of exceptions will be a good starting point to ensure that our implementation logic is correct and deterministic.

The patch for KafkaSystemProducer in Samza with the new producer API is available in this [patch|https://reviews.apache.org/r/29899/diff/#];;;","15/Jan/15 07:30;jkreps;Hey guys, I put some thought into this but I agree it isn't very clearly documented. Let's see if it makes sense:

ApiException denotes server-side exceptions and map to Kafka error codes. They indicate a server or network error.

RetriableException are things that, if retried, might work. You want to avoid retrying things like RecordTooLargeException because it is not going to change.

The next question is why do some exceptions get thrown by send() and some not? First, obviously not all exceptions can be thrown by send() since the error may occur asynchronously. So the choice is either to have all errors go to the callback or not. The rationale for throwing some exceptions directly is that these are things you should not ignore even if you don't wait on the future --- e.g. a serialization error. The rationale for handling api exceptions in the application thread was to simplify error handling. Some exceptions that can be thrown by the server can also be thrown by the client --- e.g. TimeoutException. It seems simpler to be able to say that timeout exceptions will ALWAYS go to the callback even if the timeout occurs waiting on a metadata update.

[~navina] I don't think I understand what you are saying. Is your objection that the error can be handled in two different threads? Is that a problem? Also, the producer has built in retries which will be a bit more efficient as they retry using the serialized data, do those not work?



;;;","15/Jan/15 08:29;criccomini;Here's how Samza's KafkaSystemProducer currently works. We use a sync Kafka producer to send messages. We batch inside Samza's KafkaSystemProducer, so calling KafkaSystemProducer.send() prepends your message to a buffer inside the KafkaSystemProducer (we don't send it to the underlying Kafka producer at this point). When the buffer reaches some max (say, 200), the send() call will trigger a sync KafkaSystemProducer.flush() call, which will call send() on the underlying producer. Since the underlying kafka producer's send() call is blocking, any exception that occurs happens on the thread that's calling send(), so we just simply wrap the send() call in a try/catch. Flush is also called before Samza checkpoints its offsets, to make sure that any outstanding output is sent (so we don't lose data if there's a failure).

Samza's KafkaSystemProducer is currently setup to retry forever, no matter what, when sends to Kafka fail. It waits 10s, and retries. This behavior has come in handy in scenarios where we have (un)expected downtime or cluster maintenance on a Kafka grid. When the grid's offline, we don't want 50 Samza jobs to kill themselves. We just want them to chill out until the grid's back.

This strategy has some drawbacks, though. 

# The KafkaSystemProducer.flush() call is blocking. This hurts throughput. Sometimes, quite severely.
# Some exceptions are never going to get better. Retrying doesn't make sense in this case.

When we upgrade to the new Producer, we want to address these issues. For (1), the new producer everything is async, so that gets fixed automatically. For (2), we'd like to only retry with RetriableException, and fail for the rest.

The trick is, if the sends are no longer sync, we have to have a mechanism by which we can verify that all outstanding messages have been successfully sent before we return.

{code}
send()
send()
send()
flush() // when this returns, all messages must be in Kafka.. inflight must be 0 and buffer must be 0
{code}

The naive approach would be to just hold on to a future for each send() call, and stuff it in a list. When flush is invoked, simply iterate over the list, and call Future.get(). The confusing thing with this approach is what to do if Future.get() tells us that there was an exception when the message send was attempted. It seems that re-sending the message at this point would result in out of order messages. Is that correct?

{code}
send() // success
send() // failed
send() // enqueued
flush()
{code}

In the above example, if we call Future.get() on the second send()'s future, and we see it's a failure, the third send() could have already happened. In this case, if we re-send the failed message, then we get the third message before the second, right?

Another oddity of this approach is that it seems we would have to double-buffer the messages in order to resend them, since RecordMetadata doesn't have the actual message that we sent. In order to re-send, we'd have to keep the message in a buffer in KafkaSystemProducer, along with its future, until the Future.get() returns successfully.

We then thought that we would set:

{noformat}
retries=2000000000
{noformat}

At this point, we thought that the producer would re-send forever from the send thread, which is pretty much what we wanted in the case of a failure. But then we realized that if we had multiple in-flight requests, this could lead to out of order messages, so we forced:

{noformat}
max.in.flight.requests.per.connection=1
{noformat}

So at this point, we believe that any message that gets into the send thread will be guaranteed to be sent, and in the right order, always.

But, talking with [~guozhang], it sounds like there are some cases where ApiExceptions are thrown from the main thread, not the send thread. In this case, it seems that our {{retries}} setting has no effect, because the message hasn't even made it into the queue for the send thread yet. So, if an exception is thrown in the main thread, we seem to have to catch the RetriableException that's thrown, and re-send the message.

This is the current implementation that [~navina] is working on. Part of me is thinking, ""This can't be right. We must be misunderstanding something."" So, I 1) want to confirm that we're not misunderstanding anything, and 2) see if there is a better way to accomplish what we want:

# Async sends.
# A ""flush"" mechanism that blocks until all messages have been sent to Kafka.
# In-order retries when a RetriableFailure occurs.
# Forward a non-RetriableException when it occurs.

I'm pretty confident that my mental model is broken, so any help correcting it would be appreciated. Also, any tips on a better way to accomplish what we want would be appreciated.;;;","15/Jan/15 09:03;guozhang;My original motivation of this ticket is to make it more clear to the users about ""when"" does ""which"" exception can possibly be thrown, and upon catching them ""what"" could be done. With that in mind I was thinking the following things can be done here:

1) rename OffsetMetadataTooLarge to OffsetMetadataTooLargeException.
2) document for each exception thrown from producer.send, are they retriable or fatal (today only BufferExhausted are retriable).
3) document for each exception thrown in future, user can tell what to do based on the exception type (extended from RetriableException or not).

For concrete use cases like Chris/Navina's, we can also document about the semantics of the thrown exceptions such as 1) did the exception cause the whole batch to fail, 2) does it possibly cause out-of-order and how it is related to pipelining scheme / in-flight requests, 3) etc...;;;","15/Jan/15 10:08;jkreps;[~guozhang] Makes sense. You're correct that the docs on this suck, the send method doesn't even list the exceptions it throws so there is no way to figure this out except by reading the code.

[~criccomini] Your understanding is correct. Setting max.in.flight.requests.per.connection=1 and retries=infinity should give you what you want.

send() can throw exceptions in certain cases. Specifically if:
1. The serialization of the message fails.
2. You time out waiting for metadata about the cluster/topic on the very first request
3. You configure the client to fail rather than block if it's internal queue is full and the internal queue is full
4. You set a partition on the ProducerRecord which is invalid (i.e. larger than the largest) and various other IllegalArgumentExceptions

I think none of these should be an issue since (1) is a bug, (2) should be configured to infinite for you, (3) you won't do, and (4) is a bug.

The mental model here is that we throw the exception directly if we can't even enqueue the message. 

The next question is, great, you have given me information about each individual send but how can I know that all my stuff is sent correctly. The easiest thing here would be to hang on to all the futures and just call get on them as you suggest.

So I think the take aways are:
1. We need to document the errors (and rename that one)
2. We need to document the retry behavior with multiple in-flight requests
3. It might be nice to add a flush() call that waits for all the currently buffered or in-flight requests to complete assuming this doesn't add inefficiency in the normal case.





;;;","15/Jan/15 10:10;criccomini;bq. It might be nice to add a flush() call that waits for all the currently buffered or in-flight requests to complete assuming this doesn't add inefficiency in the normal case.

+1 This would be very helpful.;;;","15/Jan/15 10:17;criccomini;[~jkreps], so it sounds like we can fail our containers on all exceptions that we see, and rely on retries=2000000000 to handle all RetriableExceptions, correct?
;;;","15/Jan/15 10:17;jkreps;Cool, filed KAFKA-1865;;;","23/Jan/15 06:19;navina;As a part of the documentation, can you also add a comparison table for the configuration variables between the old and new Kafka versions of the Kafka Producer? It can probably be part of a separate document which describes the differences between the old and new producer design. If such a document already exists, please let me know!
;;;","05/Mar/15 02:39;guozhang;Created reviewboard https://reviews.apache.org/r/31735/diff/
 against branch origin/trunk;;;","05/Mar/15 02:40;guozhang;Add some more docs in the possible exception hierarchy, with this and Jay's modified throws exception in send() I think this ticket can be covered.;;;","14/Mar/15 06:17;guozhang;Added the docs accordingly, closing this ticket for now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cleaner gets confused about deleted and re-created topics,KAFKA-1819,12761671,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,gwenshap,gian,gian,15/Dec/14 10:24,13/Jan/15 13:33,22/Mar/23 15:10,13/Jan/15 13:33,,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"I get an error like this after deleting a compacted topic and re-creating it. I think it's because the brokers don't remove cleaning checkpoints from the cleaner-offset-checkpoint file. This is from a build based off commit bd212b7.

java.lang.IllegalArgumentException: requirement failed: Last clean offset is 587607 but segment base offset is 0 for log foo-6.
        at scala.Predef$.require(Predef.scala:233)
        at kafka.log.Cleaner.buildOffsetMap(LogCleaner.scala:502)
        at kafka.log.Cleaner.clean(LogCleaner.scala:300)
        at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:214)
        at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:192)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)",,donnchadh,gian,gwenshap,jjkoshy,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Dec/14 02:59;gwenshap;KAFKA-1819.patch;https://issues.apache.org/jira/secure/attachment/12688087/KAFKA-1819.patch","27/Dec/14 05:58;gwenshap;KAFKA-1819_2014-12-26_13:58:44.patch;https://issues.apache.org/jira/secure/attachment/12689200/KAFKA-1819_2014-12-26_13%3A58%3A44.patch","31/Dec/14 08:01;gwenshap;KAFKA-1819_2014-12-30_16:01:19.patch;https://issues.apache.org/jira/secure/attachment/12689598/KAFKA-1819_2014-12-30_16%3A01%3A19.patch","13/Jan/15 02:34;gwenshap;KAFKA-1819_2015-01-12_10:34:07.patch;https://issues.apache.org/jira/secure/attachment/12691690/KAFKA-1819_2015-01-12_10%3A34%3A07.patch","13/Jan/15 03:18;gwenshap;KAFKA-1819_2015-01-12_11:17:53.patch;https://issues.apache.org/jira/secure/attachment/12691703/KAFKA-1819_2015-01-12_11%3A17%3A53.patch","13/Jan/15 09:01;gwenshap;KAFKA-1819_2015-01-12_17:01:53.patch;https://issues.apache.org/jira/secure/attachment/12691811/KAFKA-1819_2015-01-12_17%3A01%3A53.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jan 13 05:33:32 UTC 2015,,,,,,,,,,"0|i23f7z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"16/Dec/14 11:07;gwenshap;Yep, looks like a bug.

When we delete a topic we abort the cleanup for the log:
 if (cleaner != null)
        cleaner.abortCleaning(topicAndPartition)

I think we need to add to the LogCleanerManager class a removeLog method. 
This should take a lock, read the checkpoints, remove the log we are deleting from the map and write the checkpoints back.

Then we need to call it after aborting the cleaning.

If this makes sense to someone who knows what they are doing ([~nehanarkhede] ?) I can implement this.;;;","16/Dec/14 16:16;jjkoshy;This is a similar stack-trace to KAFKA-1641 but that is a different (in fact uncertain) root cause.

I think the log is already removed from the map (pool) in LogManager.deleteLog - that same map is passed through to the cleaner. The issue is that in doneCleaning (where the checkpoint file is written) we never remove entries. So we can probably just filter out topic-partitions that are no longer present in the logs map when writing the checkpoint file. We will need to refactor a little to force write the checkpoints if cleaning for that topicPartition was not in progress.;;;","17/Dec/14 02:19;gwenshap;Thanks for pointing the similar issue [~jjkoshy].

The log is indeed removed from the pool in LogManager.deleteLog, and we could remove them in doneCleaning. 

However, I think we want to be able to force cleaning as part of the topic delete.
If we don't do it, the checkpoint file will only get updated some time later when doneCleaning is called. This can be more challenging to troubleshoot and also may not happen before Gian creates a new topic with same name.;;;","17/Dec/14 12:07;nehanarkhede;[~jjkoshy] Shouldn't we remove the deleted topic from all files that maintain either a cleaner or recovery checkpoint before delete topic is considered completed?;;;","17/Dec/14 12:34;gwenshap;The recovery checkpoints are currently handled correctly (By LogManager, I think?), the only issue is with the cleaner file.;;;","17/Dec/14 14:08;jjkoshy;[~gwenshap] that's right - that's what I meant by ""force write the checkpoints if cleaning was not in progress"". As you said, it needs to happen proactively when deleting a log, but we probably don't need to force a cleaning for that since we just need to update the cleaner checkpoint file. So I was thinking we could refactor the code a tiny bit to have a helper write out the checkpoint file and call that from both doneCleaning as well as when deleting logs.;;;","18/Dec/14 01:27;nehanarkhede;+1 on [~jjkoshy]'s suggestion. That makes more sense. ;;;","19/Dec/14 02:59;gwenshap;Created reviewboard https://reviews.apache.org/r/29210/diff/
 against branch trunk;;;","27/Dec/14 05:58;gwenshap;Updated reviewboard https://reviews.apache.org/r/29210/diff/
 against branch trunk;;;","30/Dec/14 06:15;nehanarkhede;[~gwenshap] Thanks for the updated patch! Left a minor comment. I can help you check this in after that is addressed.;;;","31/Dec/14 08:01;gwenshap;Updated reviewboard https://reviews.apache.org/r/29210/diff/
 against branch trunk;;;","06/Jan/15 06:04;nehanarkhede;[~gwenshap]. Thanks for incorporating the review suggestions. Left another suggestion to refactor the test, so that all other delete topics tests, current and future, can benefit from the cleaner checkpoint validation check. ;;;","06/Jan/15 09:26;gwenshap;Moving the check will not always verify deletion from checkpoint file. 
The checkpoints file only exists if brokers are configured with ""compact"" and not ""delete"" and cleanup actually happened before topic deletion (this requires very small segments and writing to the topic before its deleted). Thats why testDeleteTopicWithCleaner is a fairly involved test with very specific broker configuration.  So by moving the check we will check the contents of an empty file most of the time.

Since the new test covers the Cleaner codepath, I'm not sure what are the benefits of adding the check to all tests.  Do you want to activate the Cleaner on every test? Or run the validation regardless of whether the cleaner was active?
;;;","08/Jan/15 10:19;nehanarkhede;[~gwenshap] What I was trying to achieve by moving the check to the generic validator API is to benefit future tests that also end up using the compaction policy. I'm also ok with doing that when we write the next test that has a use for it :)
Will go ahead and merge your patch.;;;","10/Jan/15 02:01;nehanarkhede;[~gwenshap] Saw the following unit test failures on the latest patch on 0.8.2 branch and trunk, while trying to check it in -

{code}
kafka.server.ServerShutdownTest > testCleanShutdownWithDeleteTopicEnabled FAILED
    junit.framework.AssertionFailedError: expected:<0> but was:<1>
        at junit.framework.Assert.fail(Assert.java:47)
        at junit.framework.Assert.failNotEquals(Assert.java:277)
        at junit.framework.Assert.assertEquals(Assert.java:64)
        at junit.framework.Assert.assertEquals(Assert.java:195)
        at junit.framework.Assert.assertEquals(Assert.java:201)
        at kafka.server.ServerShutdownTest.verifyNonDaemonThreadsStatus(ServerShutdownTest.scala:145)
        at kafka.server.ServerShutdownTest.testCleanShutdownWithDeleteTopicEnabled(ServerShutdownTest.scala:114)

kafka.server.ServerShutdownTest > testCleanShutdownAfterFailedStartup FAILED
    junit.framework.AssertionFailedError: expected:<0> but was:<1>
        at junit.framework.Assert.fail(Assert.java:47)
        at junit.framework.Assert.failNotEquals(Assert.java:277)
        at junit.framework.Assert.assertEquals(Assert.java:64)
        at junit.framework.Assert.assertEquals(Assert.java:195)
        at junit.framework.Assert.assertEquals(Assert.java:201)
        at kafka.server.ServerShutdownTest.verifyNonDaemonThreadsStatus(ServerShutdownTest.scala:145)
        at kafka.server.ServerShutdownTest.testCleanShutdownAfterFailedStartup(ServerShutdownTest.scala:141)

kafka.server.ServerShutdownTest > testCleanShutdown FAILED
    junit.framework.AssertionFailedError: expected:<0> but was:<1>
        at junit.framework.Assert.fail(Assert.java:47)
        at junit.framework.Assert.failNotEquals(Assert.java:277)
        at junit.framework.Assert.assertEquals(Assert.java:64)
        at junit.framework.Assert.assertEquals(Assert.java:195)
        at junit.framework.Assert.assertEquals(Assert.java:201)
        at kafka.server.ServerShutdownTest.verifyNonDaemonThreadsStatus(ServerShutdownTest.scala:145)
        at kafka.server.ServerShutdownTest.testCleanShutdown(ServerShutdownTest.scala:101)
{code};;;","10/Jan/15 05:51;gwenshap;I'm having trouble reproducing the errors:

{code}
gshapira-MBP:kafka082 gshapira$ ./gradlew -Dtest.single=ServerShutdownTest core::test
To honour the JVM settings for this build a new JVM will be forked. Please consider using the daemon: http://gradle.org/docs/2.0/userguide/gradle_daemon.html.
Building project 'core' with Scala version 2.10.4
:clients:compileJava UP-TO-DATE
:clients:processResources UP-TO-DATE
:clients:classes UP-TO-DATE
:clients:jar UP-TO-DATE
:core:compileJava UP-TO-DATE
:core:compileScala UP-TO-DATE
:core:processResources UP-TO-DATE
:core:classes UP-TO-DATE
:core:compileTestJava UP-TO-DATE
:core:compileTestScala UP-TO-DATE
:core:processTestResources UP-TO-DATE
:core:testClasses UP-TO-DATE
:core:test

kafka.server.ServerShutdownTest > testCleanShutdown PASSED

kafka.server.ServerShutdownTest > testCleanShutdownWithDeleteTopicEnabled PASSED

kafka.server.ServerShutdownTest > testCleanShutdownAfterFailedStartup PASSED

BUILD SUCCESSFUL

Total time: 8.504 secs
{code};;;","10/Jan/15 07:05;gwenshap;Looking more into this, I'm not even sure if it can be related. 

testCleanShutdownWithDeleteTopicEnabled does enable topic deletion, but it never creates or deletes topics - just startup and shutdown. So the code-path for deleting topics (and our changes) don't seem to execute here.

Still trying to figure out what's going on.;;;","12/Jan/15 14:53;gwenshap;Hey [~nehanarkhede], can you double check that you tested on branches with KAFKA-1815 applied?
It seems to resolve the exact error you encountered.;;;","12/Jan/15 15:02;gwenshap;Ick, never mind. I see that the DeleteLog test I added doesn't shut down properly. Thats probably it :(
I'll upload a new patch tomorrow morning.

I still have no idea why the error doesn't reproduce in my environment.;;;","13/Jan/15 02:34;gwenshap;Updated reviewboard https://reviews.apache.org/r/29210/diff/
 against branch trunk;;;","13/Jan/15 02:40;nehanarkhede;[~gwenshap] Thanks for looking into the possible cause. I just looked at the patch and looks like there are a few changes unrelated to the patch - https://reviews.apache.org/r/29210/diff/3-4/ ? I guess the only changed expected should be in the tests right?;;;","13/Jan/15 02:42;gwenshap;Ouch. Yes. Good catch! 

Let me check how this got in. Probably unclean repo.;;;","13/Jan/15 03:18;gwenshap;Updated reviewboard https://reviews.apache.org/r/29210/diff/
 against branch trunk;;;","13/Jan/15 09:01;gwenshap;Updated reviewboard https://reviews.apache.org/r/29210/diff/
 against branch trunk;;;","13/Jan/15 13:33;nehanarkhede;Thanks for the patches, [~gwenshap]. Appreciate your help getting this into the 0.8.2 release. Pushed to trunk and 0.8.2;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hadoop Consumer goes into an infinite loop when  kafka.request.limit is set to -1,KAFKA-131,12521223,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,sampd,sampd,03/Sep/11 03:20,30/Sep/11 02:39,22/Mar/23 15:10,13/Sep/11 09:20,0.7,,,,,,0.7,,,,,,,contrib,,,,0,patch,,,,,There is a bug in  KafkaETLContext.java  where in a new Iterator instance is being created every time. This causes endless loops.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Sep/11 01:34;sampd;KAFKA-131.patch;https://issues.apache.org/jira/secure/attachment/12493181/KAFKA-131.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,40345,,,Thu Sep 29 18:39:11 UTC 2011,,,,,,,,,,"0|i15z33:",242984,,,,,,,,,,,,,,,,,,,,"03/Sep/11 04:38;sampd;Adding an instance variable _respIterator , so that response.iterator() isn't called multiple times;;;","03/Sep/11 05:38;sampd;Fix for the infinite loop bug in KafkaETLContext.java;;;","03/Sep/11 07:36;rbpark;Just one thing's missing.
On line 201 (of original file):
_offset += msgAndOffset.offset();

That's incorrect. The msgAndOffset returns the offset, not the offset increment. So it should be:
_offset = msgAndOffset.offset();
;;;","07/Sep/11 01:34;sampd;Adding the fix for offsets (Line 201);;;","07/Sep/11 01:41;rbpark;Great. I'm good with this patch.;;;","08/Sep/11 05:48;junrao;Thanks Sam and Richard. I just committed this.;;;","30/Sep/11 02:08;felixgv;I just wanted to point out that this bug seems to happen whether kafka.request.limit is set to -1 or not.

The current 0.6 release that is available on the site is not very usable because of this bug...

The current trunk does fix this problem though, which is great. Thanks :) !;;;","30/Sep/11 02:23;bmatheny;We have run into this as well Felix. I'd like to backport whatever change fixed this in trunk into our 0.6.1 branch. Any idea where I should look?;;;","30/Sep/11 02:30;sampd;Blake,
   You could apply the attached patch  (https://issues.apache.org/jira/secure/attachment/12493181/KAFKA-131.patch)  to the file KafkaETLContext.java;;;","30/Sep/11 02:39;bmatheny;Sorry I should have been more clear. We actually run into this issue not using the KafkaETL. We occasionally see regular consumers go into a loop (continue to fetch the same offset), I thought the comment from Felix was referring to that specifically.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Connection backoff/blackout period should start when a connection is disconnected, not when the connection attempt was initiated",KAFKA-2459,12858100,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,enothereska,ewencp,ewencp,23/Aug/15 06:55,22/Oct/15 01:00,22/Mar/23 15:10,22/Oct/15 01:00,0.8.2.1,,,,,,0.9.0.0,,,,,,,clients,consumer,producer ,,1,,,,,,"Currently the connection code for new clients marks the time when a connection was initiated (NodeConnectionState.lastConnectMs) and then uses this to compute blackout periods for nodes, during which connections will not be attempted and the node is not considered a candidate for leastLoadedNode.

However, in cases where the connection attempt takes longer than the blackout/backoff period (default 10ms), this results in incorrect behavior. If a broker is not available and, for example, the broker does not explicitly reject the connection, instead waiting for a connection timeout (e.g. due to firewall settings), then the backoff period will have already elapsed and the node will immediately be considered ready for a new connection attempt and a node to be selected by leastLoadedNode for metadata updates. I think it should be easy to reproduce and verify this problem manually by using tc to introduce enough latency to make connection failures take > 10ms.

The correct behavior would use the disconnection event to mark the end of the last connection attempt and then wait for the backoff period to elapse after that.

See http://mail-archives.apache.org/mod_mbox/kafka-users/201508.mbox/%3CCAJY8EofpeU4%2BAJ%3Dw91HDUx2RabjkWoU00Z%3DcQ2wHcQSrbPT4HA%40mail.gmail.com%3E for the original description of the problem.

This is related to KAFKA-1843 because leastLoadedNode currently will consistently choose the same node if this blackout period is not handled correctly, but is a much smaller issue.",,astubbs,enothereska,ewencp,githubbot,guozhang,ksenji,njzhuyuqi,serialx,stevenz3wu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1843,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Oct 21 17:00:18 UTC 2015,,,,,,,,,,"0|i2j94n:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"23/Sep/15 16:54;serialx;How's the status of this issue? We use Kafka in AWS EC2. When a Kafka instance is terminated, we experience this problem.

I tried to fix this myself. But looking at the code, it seems to need many refactoring for this to work out. If no one is working on this issue, can anyone give me some guidance for me to proceed?;;;","09/Oct/15 08:05;githubbot;GitHub user enothereska opened a pull request:

    https://github.com/apache/kafka/pull/290

    KAFKA-2459: connection backoff, timeouts and retries

    This fix applies to three JIRAs, since they are all connected.
    
    KAFKA-2459Connection backoff/blackout period should start when a connection is disconnected, not when the connection attempt was initiated
    Backoff when connection is disconnected
    
    KAFKA-2615Poll() method is broken wrt time
    Added Time through the NetworkClient API. Minimal change.
    
    KAFKA-1843Metadata fetch/refresh in new producer should handle all node connection states gracefully
    I’ve partially addressed this for a specific failure case in the JIRA.


You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/enothereska/kafka trunk

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/290.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #290
    
----
commit 90c0085a76374fafe6fa62c18e3d24504852e687
Author: Eno Thereska <eno.thereska@gmail.com>
Date:   2015-10-07T00:06:49Z

    Commits to fix timing issues in three JIRAs

commit ee66491fb36d55527d156afda90c3addc3eb3175
Author: Eno Thereska <eno.thereska@gmail.com>
Date:   2015-10-07T00:07:21Z

    Merge remote-tracking branch 'apache-kafka/trunk' into trunk

commit 17a373733e414456475217248cbc7b0bc98fda40
Author: Eno Thereska <eno.thereska@gmail.com>
Date:   2015-10-07T15:15:19Z

    Merge remote-tracking branch 'apache-kafka/trunk' into trunk

commit eb5fbf458a5b455ae8b3c8b3ebf32524f5a3ab3e
Author: Eno Thereska <eno.thereska@gmail.com>
Date:   2015-10-07T16:20:45Z

    Removed debug messages

commit 041baae45012cf8f99afd2c8b5d9a8099a8a928b
Author: Eno Thereska <eno.thereska@gmail.com>
Date:   2015-10-07T17:35:12Z

    Pick a node, but not one that is blacked out

commit 69679d7e61d36f76d2ea1dd1fcc0a1192c9b50d6
Author: Eno Thereska <eno.thereska@gmail.com>
Date:   2015-10-08T17:18:02Z

    Removed unneeded checks

commit 3ce5e151396575f45d1f022720f454ac36653d0d
Author: Eno Thereska <eno.thereska@gmail.com>
Date:   2015-10-08T17:18:18Z

    Merge remote-tracking branch 'apache-kafka/trunk' into trunk

commit 76e6a0d8ab3fe847b28edde2e0072e7fe06484ff
Author: Eno Thereska <eno.thereska@gmail.com>
Date:   2015-10-08T23:35:41Z

    More efficient implementation of nodesEverSeen

----
;;;","22/Oct/15 01:00;guozhang;Issue resolved by pull request 290
[https://github.com/apache/kafka/pull/290];;;","22/Oct/15 01:00;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/290
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LogCleaner offset map overflow,KAFKA-2235,12834338,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ivan.simonenko,ivan.simonenko,ivan.simonenko,02/Jun/15 03:04,04/May/16 05:05,22/Mar/23 15:10,23/Jun/15 00:21,0.8.1,0.8.2.0,,,,,0.9.0.0,,,,,,,core,log,,,0,,,,,,"We've seen log cleaning generating an error for a topic with lots of small messages. It seems that cleanup map overflow is possible if a log segment contains more unique keys than empty slots in offsetMap. Check for baseOffset and map utilization before processing segment seems to be not enough because it doesn't take into account segment size (number of unique messages in the segment).

I suggest to estimate upper bound of keys in a segment as a number of messages in the segment and compare it with the number of available slots in the map (keeping in mind desired load factor). It should work in cases where an empty map is capable to hold all the keys for a single segment. If even a single segment no able to fit into an empty map cleanup process will still fail. Probably there should be a limit on the log segment entries count?

Here is the stack trace for this error:
2015-05-19 16:52:48,758 ERROR [kafka-log-cleaner-thread-0] kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Error due to
java.lang.IllegalArgumentException: requirement failed: Attempt to add a new entry to a full offset map.
       at scala.Predef$.require(Predef.scala:233)
       at kafka.log.SkimpyOffsetMap.put(OffsetMap.scala:79)
       at kafka.log.Cleaner$$anonfun$kafka$log$Cleaner$$buildOffsetMapForSegment$1.apply(LogCleaner.scala:543)
       at kafka.log.Cleaner$$anonfun$kafka$log$Cleaner$$buildOffsetMapForSegment$1.apply(LogCleaner.scala:538)
       at scala.collection.Iterator$class.foreach(Iterator.scala:727)
       at kafka.utils.IteratorTemplate.foreach(IteratorTemplate.scala:32)
       at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
       at kafka.message.MessageSet.foreach(MessageSet.scala:67)
       at kafka.log.Cleaner.kafka$log$Cleaner$$buildOffsetMapForSegment(LogCleaner.scala:538)
       at kafka.log.Cleaner$$anonfun$buildOffsetMap$3.apply(LogCleaner.scala:515)
       at kafka.log.Cleaner$$anonfun$buildOffsetMap$3.apply(LogCleaner.scala:512)
       at scala.collection.immutable.Stream.foreach(Stream.scala:547)
       at kafka.log.Cleaner.buildOffsetMap(LogCleaner.scala:512)
       at kafka.log.Cleaner.clean(LogCleaner.scala:307)
       at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:221)
       at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:199)
       at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)",,ivan.simonenko,jjkoshy,junrao,toddpalino,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3587,,,,,,,,"02/Jun/15 03:08;ivan.simonenko;KAFKA-2235_v1.patch;https://issues.apache.org/jira/secure/attachment/12736626/KAFKA-2235_v1.patch","22/Jun/15 19:15;ivan.simonenko;KAFKA-2235_v2.patch;https://issues.apache.org/jira/secure/attachment/12741012/KAFKA-2235_v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,Patch,,,,,,,,,9223372036854775807,,,Mon Oct 26 17:56:18 UTC 2015,,,,,,,,,,"0|i2fh0f:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"17/Jun/15 07:27;junrao;Thanks for the patch. Nice catch! A couple of comments below.

1. When there are not enough slots to build a map for a single segment, it would be useful to suggest the action In the message string for require(). Sth like ""please increase log.cleaner.dedupe.buffer.size"".
2. Our current coding convention is to not include {} for single line statement under if/else. ;;;","22/Jun/15 19:28;ivan.simonenko;[~junrao] thank you for review. Please check the patch v2. I think in most cases mentioning log.cleaner.dedupe.buffer.size should be enough, but as log.cleaner.threads is also used in determining map size I've added both of them. If someone increases threads num and start getting this message he can easily understand cause of the problem;;;","23/Jun/15 00:21;junrao;Thanks for patch v2. +1. Committed to trunk after changing the following statement from testing < to <=.

      if (map.size + segmentSize <= maxDesiredMapSize)
;;;","24/Oct/15 03:51;jjkoshy;While I think the change is well-motivated I'm not sure this is the right fix for this issue as the check is too conservative. i.e., especially with highly compressible messages the message-count in the segment may be extremely high but the unique-key-count may be low.;;;","24/Oct/15 04:00;toddpalino;I'm sure [~jjkoshy] will follow along with more detail on this, but we've run into a serious problem with this check. Basically, it's impossible to perform this kind of check accurately before the offset map is built. We now have partitions that should be able to be compacted as the total number of unique keys is far below the size of the offset map (currently at ~39 million for our configuration) but the messages are very frequent and very small. Even at a segment size of 64 MB, we have over 300 million messages in those segments. So this check creates a situation where log compaction should succeed, but fails because of a speculative check.

While I can play the game of trying to walk back segment sizes, there's no way to size segments by number of messages, so it's a guessing game. In addition, the check is clearly wrong in that case, so I shouldn't have to config around it. Lastly, the check causes the log cleaner thread to exit, which means log compaction on the broker fails entirely, rather than just skipping that partition.

A better way to handle this would be to cleanly catch the original error you are seeing, generate a clear error message in the logs as to what the failure is, and allow the log cleaner to continue and handle other partitions. You could also maintain a blacklist of partitions in memory in the log cleaner to make sure you don't come back around and try and compact the partition again.;;;","24/Oct/15 04:38;junrao;[~toddpalino], thanks for reporting this issue. I agree that it's better to log an error and then continue. For your use case, it seems that you can just increase log.cleaner.dedupe.buffer.size.;;;","24/Oct/15 04:40;toddpalino;I don't think we can. I have already increased it from 512MB to 1GB, and we still hit the same problems. That only provides a 2x increase in the size of the map, and I would need almost a 10x increase to solve the problem.;;;","24/Oct/15 05:08;ivan.simonenko;The core problem is that offset map is limited by number of messages while segment is limited by size in bytes and this patch doesn't fix it. But the way it handles the problem (just throws exception end stops compacting) is consistent with other errors in compactor.;;;","27/Oct/15 00:28;jjkoshy;Agreed with Todd - this is very similar to the proposal in btw, https://issues.apache.org/jira/browse/KAFKA-1755?focusedCommentId=14216486;;;","27/Oct/15 01:56;junrao;One way to get around your problem now is to set log.cleaner.io.buffer.load.factor to a larger value. Currently, it doesn't seem that we check the range of the value. So you can set it to a value larger than 1.0, which will allow you to build a bigger offset map with the same buffer size.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AbstractFetcherThread.shutdown() should not block on ReadableByteChannel.read(buffer),KAFKA-2241,12834854,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,lindong,lindong,lindong,03/Jun/15 06:49,17/Jul/15 07:39,22/Mar/23 15:10,17/Jul/15 07:39,,,,,,,0.9.0.0,,,,,,,,,,,0,quotas,,,,,"This is likely a bug from Java. This affects Kafka and here is the patch to fix it.

Here is the description of the bug. By description of SocketChannel in Java 7 Documentation. If another thread interrupts the current thread while the read operation is in progress, the it should closes the channel and throw ClosedByInterruptException. However, we find that interrupting the thread will not unblock the channel immediately. Instead, it waits for response or socket timeout before throwing an exception.

This will cause problem in the following scenario. Suppose one console_consumer_1 is reading from a topic, and due to quota delay or whatever reason, it block on channel.read(buffer). At this moment, another console_consumer_2 joins and triggers rebalance at console_consumer_1. But consumer_1 will block waiting on the channel.read before it can release partition ownership, causing consumer_2 to fail after a number of failed attempts to obtain partition ownership.

In other words, AbstractFetcherThread.shutdown() is not guaranteed to shutdown due to this bug.

The problem is confirmed with Java 1.7 and java 1.6. To check it by yourself, you can use the attached server.java and client.java -- start the server before the client and see if client unblock after interruption.
",,ijuma,junrao,lindong,v.himanshu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jun/15 07:54;lindong;KAFKA-2241.patch;https://issues.apache.org/jira/secure/attachment/12737046/KAFKA-2241.patch","04/Jun/15 06:30;lindong;KAFKA-2241_2015-06-03_15:30:35.patch;https://issues.apache.org/jira/secure/attachment/12737387/KAFKA-2241_2015-06-03_15%3A30%3A35.patch","10/Jul/15 06:36;lindong;KAFKA-2241_2015-07-09_15:35:49.patch;https://issues.apache.org/jira/secure/attachment/12744589/KAFKA-2241_2015-07-09_15%3A35%3A49.patch","14/Jul/15 04:30;lindong;KAFKA-2241_2015-07-13_13:30:07.patch;https://issues.apache.org/jira/secure/attachment/12745113/KAFKA-2241_2015-07-13_13%3A30%3A07.patch","14/Jul/15 05:52;lindong;KAFKA-2241_2015-07-13_14:51:42.patch;https://issues.apache.org/jira/secure/attachment/12745133/KAFKA-2241_2015-07-13_14%3A51%3A42.patch","03/Jun/15 06:51;lindong;client.java;https://issues.apache.org/jira/secure/attachment/12737033/client.java","03/Jun/15 06:51;lindong;server.java;https://issues.apache.org/jira/secure/attachment/12737032/server.java",,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jul 16 23:39:05 UTC 2015,,,,,,,,,,"0|i2fjmf:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"03/Jun/15 06:51;lindong;Run server before client. Then check if channel.read() will unblock after the thread is interrupted.;;;","03/Jun/15 06:54;ijuma;[~lindong], it looks like you filed two issues for the same thing KAFKA-2240 and KAFKA-2241. Maybe close one of them as a duplicate?;;;","03/Jun/15 07:38;lindong;Oh, I thought the first issue creation has failed.

Thanks for your notice.;;;","03/Jun/15 07:54;lindong;Created reviewboard https://reviews.apache.org/r/34965/diff/
 against branch origin/trunk;;;","04/Jun/15 06:30;lindong;Updated reviewboard https://reviews.apache.org/r/34965/diff/
 against branch origin/trunk;;;","13/Jun/15 05:46;junrao;[~lindong], thanks for reporting this. Does this happen on java 8?;;;","13/Jun/15 09:47;lindong;[~junrao] No, this bug is fixed in java 1.8.0.

Can you let me know if we should drop this ticket?;;;","07/Jul/15 04:48;lindong;Hi [~junrao], could you please review this patch when you have time?;;;","10/Jul/15 06:36;lindong;Updated reviewboard https://reviews.apache.org/r/34965/diff/
 against branch origin/trunk;;;","14/Jul/15 04:30;lindong;Updated reviewboard https://reviews.apache.org/r/34965/diff/
 against branch origin/trunk;;;","14/Jul/15 05:52;lindong;Updated reviewboard https://reviews.apache.org/r/34965/diff/
 against branch origin/trunk;;;","17/Jul/15 07:39;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New consumer hangs indefinitely when broker list is misconfigured,KAFKA-2568,12895571,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,hachikuji,hachikuji,hachikuji,23/Sep/15 04:16,09/Dec/15 07:38,22/Mar/23 15:10,09/Dec/15 07:38,0.9.0.0,,,,,,,,,,,,,,,,,0,,,,,,"If you accidentally point the broker list configuration to something other than an 0.9 Kafka cluster, the consumer will hang indefinitely in poll() while it tries to discover the coordinator. This is less than ideal for users since it provides no indication of the problem. An incompatible server could respond in two ways:

1. It may send back an invalid response.
2. It may just terminate the connection.

The first case is straightforward: we should get an ApiException which can be propagated to the user. The second case is trickier since it's difficult to distinguish this case from a regular broker failure. We might see this happen if the new consumer is pointed to an 0.8 broker for example. I'm not sure there's much we can do in this case other than making the disconnects visible in logging, but that is better than eating the errors silently.",,hachikuji,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Dec 08 23:38:37 UTC 2015,,,,,,,,,,"0|i2lf93:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"09/Dec/15 07:38;hachikuji;We ended up fixing the main problem here in KAFKA-2683. The consumer will raise an exception to the user if it receives an unexpected response from the server. However, if the server sends no response and just disconnects, the consumer will still block indefinitely. This will be addressed in KAFKA-2391, so I'm resolving this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
in ConsoleProducer - properties key.separator and parse.key no longer work,KAFKA-1824,12762628,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,gwenshap,gwenshap,gwenshap,19/Dec/14 01:19,28/Feb/15 23:42,22/Mar/23 15:10,28/Feb/15 23:42,,,,,,,0.9.0.0,,,,,,,tools,,,,0,,,,,,"Looks like the change in kafka-1711 breaks them accidentally.

reader.init is called with readerProps which is initialized with commandline properties as defaults.

the problem is that reader.init checks:
    if(props.containsKey(""parse.key""))
and defaults don't return true in this case.",,gwenshap,joestein,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Dec/14 09:56;gwenshap;KAFKA-1824.patch;https://issues.apache.org/jira/secure/attachment/12688211/KAFKA-1824.patch","19/Dec/14 03:08;gwenshap;KAFKA-1824.patch;https://issues.apache.org/jira/secure/attachment/12688090/KAFKA-1824.patch","28/Feb/15 08:40;gwenshap;KAFKA-1824.v1.patch;https://issues.apache.org/jira/secure/attachment/12701505/KAFKA-1824.v1.patch","23/Dec/14 08:17;gwenshap;KAFKA-1824_2014-12-22_16:17:42.patch;https://issues.apache.org/jira/secure/attachment/12688747/KAFKA-1824_2014-12-22_16%3A17%3A42.patch","27/Feb/15 15:05;gwenshap;KAFKA-1824_2015-02-26_23:05:10.patch;https://issues.apache.org/jira/secure/attachment/12701287/KAFKA-1824_2015-02-26_23%3A05%3A10.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Feb 28 15:42:44 UTC 2015,,,,,,,,,,"0|i23l1r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Dec/14 03:08;gwenshap;Created reviewboard https://reviews.apache.org/r/29211/diff/
 against branch trunk;;;","19/Dec/14 09:06;nehanarkhede;Thanks for the patch. Pushed to trunk.;;;","19/Dec/14 09:08;gwenshap;Thanks for the quick review [~nehanarkhede]!;;;","19/Dec/14 09:56;gwenshap;Created reviewboard https://reviews.apache.org/r/29231/diff/
 against branch trunk;;;","19/Dec/14 09:58;gwenshap;My apologies! 

Additional round of tests revealed that my first patch accidentally breaks what was fixed in KAFKA-1711 - i.e. the ""WARN Property topic is not valid"" message returned. Those VerifiableProperties are tricky!

I added a new patch, on top of the one already committed that removes the extra properties before creating the producer and eliminates the WARN messages.;;;","19/Dec/14 10:21;nehanarkhede;[~gwenshap] Good catch. I wonder if we should just add tests given the tricky logic involved.;;;","19/Dec/14 10:28;gwenshap;Yes, lets do that. Will help us avoid another round of the break-and-fix cycle.

Hold off on this patch and I'll provide tests in a day or two.;;;","23/Dec/14 08:17;gwenshap;Updated reviewboard https://reviews.apache.org/r/29231/diff/
 against branch trunk;;;","23/Dec/14 08:23;gwenshap;I added tests, I also did some refactoring to ConsoleProducer to allow testing (i.e. pulled some portions off main() to separate functions where we can test them). 

One caveat - This patch removes an undocumented feature: 
Before the patch, properties specified in --property were passed to the producer (even though it is documented as properties for the MessageReader), so users could configure producer properties not supported by the console producer directly to the underlying producer.
Now the properties specified in --property are only sent to the reader, as documented.

If we think that allowing users to send custom properties to producer is useful, I can add an additional option (--producer-property).;;;","23/Dec/14 11:55;joestein;Shouldn't this go into 0.8.2 branch also since it is a fix for a regression bug?;;;","27/Dec/14 03:14;gwenshap;[~joestein] 0.8.2 branch is actually ok (i.e. you get a warning about ""invalid property"", but key.separator and parse.key work fine).
So this just needs to go into trunk.;;;","20/Jan/15 06:31;gwenshap;I noticed that [~junrao] committed KAFKA-1711 to 0.8.2 branch last week, so we need this patch on 0.8.2 as well.;;;","20/Jan/15 08:20;junrao;Gwen, thanks for point this out. I am reverting KAFKA-1711 from the 0.8.2 branch before cutting RC1.;;;","20/Jan/15 08:55;junrao;Reopening the issue since the followup patch hasn't been committed yet.;;;","20/Jan/15 11:14;gwenshap;Thanks, Jun. 
I changed status to Patch Available, so once the 0.8.2 madness calms down a bit, we can review and get it into trunk.;;;","13/Feb/15 05:17;gwenshap;pinging for review :);;;","22/Feb/15 11:42;nehanarkhede;[~gwenshap] Is this the rb you are asking a review on? https://reviews.apache.org/r/29231/diff/;;;","22/Feb/15 14:17;gwenshap;Thats the right RB, [~nehanarkhede].

;;;","23/Feb/15 04:17;nehanarkhede;[~gwenshap] I'm having trouble applying the patch on trunk -
{code}
nnarkhed-mn1:kafka nnarkhed$ git apply --check 1824.patch 
error: patch failed: core/src/main/scala/kafka/tools/ConsoleProducer.scala:36
error: core/src/main/scala/kafka/tools/ConsoleProducer.scala: patch does not apply
error: patch failed: core/src/main/scala/kafka/tools/ConsoleProducer.scala:34
error: core/src/main/scala/kafka/tools/ConsoleProducer.scala: patch does not apply
{code};;;","27/Feb/15 15:05;gwenshap;Updated reviewboard https://reviews.apache.org/r/29231/diff/
 against branch trunk;;;","28/Feb/15 08:29;nehanarkhede;[~gwenshap] Still doesn't apply. Not sure if I'm doing something incorrectly-
{code}
nnarkhed-mn1:kafka nnarkhed$ git apply --check ~/Projects/kafka-patches/1824.patch 
error: patch failed: core/src/main/scala/kafka/tools/ConsoleProducer.scala:36
error: core/src/main/scala/kafka/tools/ConsoleProducer.scala: patch does not apply
error: patch failed: core/src/main/scala/kafka/tools/ConsoleProducer.scala:34
error: core/src/main/scala/kafka/tools/ConsoleProducer.scala: patch does not apply
error: core/src/test/scala/kafka/tools/ConsoleProducerTest.scala: already exists in working directory
error: patch failed: core/src/main/scala/kafka/tools/ConsoleProducer.scala:76
error: core/src/main/scala/kafka/tools/ConsoleProducer.scala: patch does not apply
error: patch failed: core/src/main/scala/kafka/tools/ConsoleProducer.scala:266
error: core/src/main/scala/kafka/tools/ConsoleProducer.scala: patch does not apply
{code};;;","28/Feb/15 08:40;gwenshap;I'll blame the patch-tool.

I generated new patch with ""git diff"" and tested on trunk. Seems to work :);;;","28/Feb/15 23:42;nehanarkhede;Thanks for the patches. Pushed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Due to OS caching Kafka might loose offset files which causes full reset of data,KAFKA-1539,12727045,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,dmitrybugaychenko,dmitrybugaychenko,14/Jul/14 15:38,22/Jul/14 22:21,22/Mar/23 15:10,22/Jul/14 07:57,0.8.1.1,,,,,,0.8.2.0,,,,,,,log,,,,0,,,,,,"Seen this while testing power failure and disk failures. Due to chaching on OS level (eg. XFS can cache data for 30 seconds) after failure we got offset files of zero length. This dramatically slows down broker startup (it have to re-check all segments) and if high watermark offsets lost it simply erases all data and start recovering from other brokers (looks funny - first spending 2-3 hours re-checking logs and then deleting them all due to missing high watermark).

Proposal: introduce offset files rotation. Keep two version of offset file, write to oldest, read from the newest valid. In this case we would be able to configure offset checkpoint time in a way that at least one file is alway flushed and valid.",,aozeritsky,dmitrybugaychenko,jkreps,joestein,junrao,sriramsub,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jul/14 01:24;jkreps;KAFKA-1539.patch;https://issues.apache.org/jira/secure/attachment/12656897/KAFKA-1539.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,405152,,,Tue Jul 22 13:58:16 UTC 2014,,,,,,,,,,"0|i1xq53:",405187,,,,,,,,,,,,,,,,,,,,"14/Jul/14 15:49;joestein;Did you have the log.flush.interval.messages == 1 when doing this?  If not then you can either do something like that and sacrifice performance and futz with a single broker flush or have (instead) replicas/brokers outside of zones that are sharing power grids for a partition you are working with.  Use replication to achieve your durability with less sacrifice to performance using more than one broker. If you need/want something within a single broker there are lots of toggle to use in the broker configuration https://kafka.apache.org/documentation.html#brokerconfigs. ;;;","14/Jul/14 16:58;dmitrybugaychenko;This is not about log files themselves, but about chekpoint offset files 

{code}
-rw-r--r--  1 root root   158 Jul 14 12:11 recovery-point-offset-checkpoint
-rw-r--r--  1 root root   163 Jul 14 12:11 replication-offset-checkpoint
-rw-r--r--  1 root root     0 May 28 13:09 cleaner-offset-checkpoint
{code}

If recovery-point-offset-checkpoint got corrupted, broker startup slows down dramatically (to hours), if replication-offset-checkpoint got corrupted, then broker removes all the data it has and starts recovering from other replicas. If both got corrupted then you get both - broker spending hours checking log segment files and then removeing them all.
;;;","15/Jul/14 11:23;junrao;Hmm, interesting. The way that we checkpoint those offset files is to first write to a temp file, force a flush, and then do a rename. This is very close to the two versions of the offset file that you are proposing. Not sure how a zero length file is introduced. Is that easily reproducible?;;;","15/Jul/14 14:05;dmitrybugaychenko;It looks like even after flush data are not necesary written to HDD. In XFS by default it could be cached up to 30 secodns, it also can be cached by a disk controller and etc. Wrtiting to temp file is a good idea, but it is better to keep the previous file untouched (do not replace it with the temp one).

On a 20 HDD server with XFS it is pretty easy to reproduce - after power failure we got corrupted offset files on 4-5 disks.;;;","16/Jul/14 09:36;junrao;If flush is not guaranteed, will keeping two versions of the file help? At some point, we will have flushed both versions and neither one is guaranteed to persist.;;;","21/Jul/14 02:29;dmitrybugaychenko;Digged the problem a bit more. It looks like calling flush on new BufferedWriter(new FileWriter(temp)) only forces buffered writer to dump everything into a FileOutputStream under the FileWriter and call flush on it. However, according to http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/7u40-b43/java/io/FileOutputStream.java#FileOutputStream it does nothing. In order to really force data to be written to disk you need to call fos.getFD().sync(). According to that the patch could be like that:

{code}
  def write(offsets: Map[TopicAndPartition, Long]) {
    lock synchronized {
      // write to temp file and then swap with the existing file
      val temp = new File(file.getAbsolutePath + "".tmp"")

      val fileOutputStream = new FileOutputStream(temp)
      val writer = new BufferedWriter(new FileWriter(fileOutputStream))
      try {
        // write the current version
        writer.write(0.toString)
        writer.newLine()
      
        // write the number of entries
        writer.write(offsets.size.toString)
        writer.newLine()

        // write the entries
        offsets.foreach { case (topicPart, offset) =>
          writer.write(""%s %d %d"".format(topicPart.topic, topicPart.partition, offset))
          writer.newLine()
        }
      
        // flush and overwrite old file
        writer.flush()
        
        // Force fsync to disk
        fileOutputStream.getFD.sync()
      } finally {
        writer.close()
      }
      
      // swap new offset checkpoint file with previous one
      if(!temp.renameTo(file)) {
        // renameTo() fails on Windows if the destination file exists.
        file.delete()
        if(!temp.renameTo(file))
          throw new IOException(""File rename from %s to %s failed."".format(temp.getAbsolutePath, file.getAbsolutePath))
      }
    }
  }
{code}

Note that the problem is easily reproducable only on XFS, ext3/ext4 seems to handle this case much better. Hope we will be able to try the patch later this week and check if it helps.;;;","22/Jul/14 01:24;jkreps;Created reviewboard https://reviews.apache.org/r/23743/
 against branch trunk;;;","22/Jul/14 01:25;jkreps;This is a really good catch, were clearly thinking flush() meant fsync, which is totally wrong. I uploaded a patch with your fix. If you are doing testing with this let me know that this actually fixes the issue you saw.;;;","22/Jul/14 01:29;sriramsub;I had encountered the same issue in another project and had to explicitly use fsync to fix it.;;;","22/Jul/14 07:57;jkreps;I'm checking this in since it seems to fix a clear problem, but [~arhagnel] it would still be good to get confirmation that the problem you were producing is fixed by this.;;;","22/Jul/14 14:32;dmitrybugaychenko;Going to test power failure again later today, I'll get back with results as soon as we get them.;;;","22/Jul/14 21:58;dmitrybugaychenko;With fileOutputStream.getFD.sync() patch we passed the power failure tests without loosing offset files. So, it seems to work.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Produce request: Leader not local for partition [test,0] on broker 0 ",KAFKA-876,12644633,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Duplicate,nehanarkhede,flyingyin,flyingyin,26/Apr/13 01:24,28/Jun/13 14:13,22/Mar/23 15:10,28/Jun/13 14:13,0.8.0,,,,,,0.8.0,,,,,,,clients,replication,,,0,,,,,,"Follow the quick start to open zookeeper, one broker, one producer and one consumer. In the producer console, there is an LeaderNotAvailableException for the first message, and the broker complains ""Produce request: Leader not local for partition [test,0] on broker 0"" for all following messages. 

Kafka-List-Topic shows ""[2013-04-25 10:21:24,689] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient) topic: test     partition: 0    leader: 0       replicas: 0     isr: 0"". With --unavailable-partitions option, it doesn't list any topic.

=========================Broker Log=============================

Set JMX_PORT to default value : 9999
C:\Projects\Kafka\kafka\bin\..
log4j:ERROR Failed to rename [server.log] to [server.log.2013-04-25-09].
[2013-04-25 10:08:49,531] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] INFO Property socket.send.buffer.bytes is overridden to 1048576 (kafka.utils.VerifiablePropert
ies)
[2013-04-25 10:08:49,578] INFO Property socket.request.max.bytes is overridden to 104857600 (kafka.utils.VerifiablePrope
rties)
[2013-04-25 10:08:49,578] INFO Property log.dir is overridden to /tmp/kafka-logs (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] INFO Property log.cleanup.interval.mins is overridden to 1 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] INFO Property log.retention.hours is overridden to 168 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] INFO Property num.io.threads is overridden to 2 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] INFO Property broker.id is overridden to 0 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] WARN Property kafka.csv.metrics.reporter.enabled is not valid (kafka.utils.VerifiablePropertie
s)
[2013-04-25 10:08:49,578] INFO Property port is overridden to 9092 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] INFO Property log.flush.interval.messages is overridden to 10000 (kafka.utils.VerifiableProper
ties)
[2013-04-25 10:08:49,578] INFO Property zk.connection.timeout.ms is overridden to 1000000 (kafka.utils.VerifiablePropert
ies)
[2013-04-25 10:08:49,578] WARN Property kafka.metrics.reporters is not valid (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] WARN Property kafka.csv.metrics.dir is not valid (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] INFO Property log.flush.interval.ms is overridden to 1000 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] WARN Property kafka.metrics.polling.interval.secs is not valid (kafka.utils.VerifiableProperti
es)
[2013-04-25 10:08:49,578] INFO Property num.network.threads is overridden to 2 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] INFO Property socket.receive.buffer.bytes is overridden to 1048576 (kafka.utils.VerifiableProp
erties)
[2013-04-25 10:08:49,578] INFO Property log.segment.bytes is overridden to 536870912 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,578] INFO Property zk.connect is overridden to localhost:2181 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,594] INFO Property num.partitions is overridden to 1 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:49,609] INFO [Kafka Server 0], starting (kafka.server.KafkaServer)
[2013-04-25 10:08:49,625] INFO [Log Manager on Broker 0] Log directory 'C:\tmp\kafka-logs' not found, creating it. (kafk
a.log.LogManager)
[2013-04-25 10:08:49,625] INFO [Log Manager on Broker 0] Starting log cleaner every 60000 ms (kafka.log.LogManager)
[2013-04-25 10:08:49,640] INFO [Log Manager on Broker 0] Starting log flusher every 3000 ms with the following overrides
 Map() (kafka.log.LogManager)
[2013-04-25 10:08:49,656] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2013-04-25 10:08:49,656] INFO [Socket Server on Broker 0], started (kafka.network.SocketServer)
[2013-04-25 10:08:49,672] INFO connecting to ZK: localhost:2181 (kafka.server.KafkaZooKeeper)
[2013-04-25 10:08:49,672] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2013-04-25 10:08:49,672] INFO Client environment:zookeeper.version=3.3.3-1203054, built on 11/17/2011 05:47 GMT (org.ap
ache.zookeeper.ZooKeeper)
[2013-04-25 10:08:49,672] INFO Client environment:host.name=YIYIN-MAIN.redmond.corp.microsoft.com (org.apache.zookeeper.
ZooKeeper)
[2013-04-25 10:08:49,672] INFO Client environment:java.version=1.7.0_21 (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:49,672] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:49,672] INFO Client environment:java.home=C:\Program Files (x86)\Java\jdk1.7.0_21\jre (org.apache.zook
eeper.ZooKeeper)
[2013-04-25 10:08:49,687] INFO Client environment:java.io.tmpdir=C:\Users\yiyin\AppData\Local\Temp\ (org.apache.zookeepe
r.ZooKeeper)
[2013-04-25 10:08:49,687] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:49,687] INFO Client environment:os.name=Windows 8 (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:49,687] INFO Client environment:os.arch=x86 (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:49,687] INFO Client environment:os.version=6.2 (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:49,687] INFO Client environment:user.name=yiyin (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:49,687] INFO Client environment:user.home=C:\Users\yiyin (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:49,687] INFO Client environment:user.dir=C:\Projects\Kafka\kafka\bin (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:49,687] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=or
g.I0Itec.zkclient.ZkClient@16e73e3 (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:49,703] INFO Opening socket connection to server localhost/127.0.0.1:2181 (org.apache.zookeeper.Client
Cnxn)
[2013-04-25 10:08:49,703] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache
.zookeeper.ClientCnxn)
[2013-04-25 10:08:49,781] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x13e422b2
f620000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2013-04-25 10:08:49,781] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2013-04-25 10:08:49,812] INFO Registered broker 0 at path /brokers/ids/0 with address YIYIN-MAIN.redmond.corp.microsoft
.com:9092. (kafka.utils.ZkUtils$)
[2013-04-25 10:08:49,812] INFO [Kafka Server 0], Connecting to ZK: localhost:2181 (kafka.server.KafkaServer)
[2013-04-25 10:08:49,859] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2013-04-25 10:08:49,875] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2013-04-25 10:08:49,984] INFO No state transitions triggered since no partitions are assigned to brokers 0 (kafka.utils
.ZkUtils$)
[2013-04-25 10:08:49,984] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2013-04-25 10:08:50,000] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2013-04-25 10:08:55,969] INFO Closing socket connection to /10.123.11.25. (kafka.network.Processor)
[2013-04-25 10:09:03,234] INFO [KafkaApi-0] Auto creation of topic test with 1 partitions and replication factor 1 is su
ccessful! (kafka.server.KafkaApis)
[2013-04-25 10:09:03,281] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2013-04-25 10:09:03,281] INFO [Replica Manager on Broker 0]: Handling LeaderAndIsr request Name:LeaderAndIsrRequest;Ver
sion:0;Controller:0;ControllerEpoch:1;CorrelationId:5;ClientId:id_0-host_null-port_9092;AckTimeoutMs:1000 ms;PartitionSt
ate:(test,0) -> (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1);Leaders:id:0,hos
t:YIYIN-MAIN.redmond.corp.microsoft.com,port:9092 (kafka.server.ReplicaManager)
[2013-04-25 10:09:03,281] INFO [ReplicaFetcherManager on broker 0] Removing fetcher for partition [test,0] (kafka.server
.ReplicaFetcherManager)
[2013-04-25 10:09:03,297] INFO [Kafka Log on Broker 0], Completed load of log test-0 with log end offset 0 (kafka.log.Lo
g)
[2013-04-25 10:09:03,297] INFO [Log Manager on Broker 0] Created log for topic test partition 0 in C:\tmp\kafka-logs. (k
afka.log.LogManager)
[2013-04-25 10:09:03,297] INFO [Replica Manager on Broker 0]: Handled leader and isr request Name:LeaderAndIsrRequest;Ve
rsion:0;Controller:0;ControllerEpoch:1;CorrelationId:5;ClientId:id_0-host_null-port_9092;AckTimeoutMs:1000 ms;PartitionS
tate:(test,0) -> (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1);Leaders:id:0,ho
st:YIYIN-MAIN.redmond.corp.microsoft.com,port:9092 (kafka.server.ReplicaManager)
[2013-04-25 10:09:03,438] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2013-04-25 10:09:03,453] WARN [KafkaApi-0] Produce request: Leader not local for partition [test,0] on broker 0 (kafka.
server.KafkaApis)
[2013-04-25 10:09:05,453] WARN [KafkaApi-0] Produce request: Leader not local for partition [test,0] on broker 0 (kafka.
server.KafkaApis)
[2013-04-25 10:09:07,250] WARN [KafkaApi-0] Produce request: Leader not local for partition [test,0] on broker 0 (kafka.
server.KafkaApis)
[2013-04-25 10:09:08,891] WARN [KafkaApi-0] Produce request: Leader not local for partition [test,0] on broker 0 (kafka.
server.KafkaApis)



=============================Producer Log==============================

C:\Projects\Kafka\kafka\bin\..
[2013-04-25 10:08:52,531] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:52,547] INFO Property queue.buffering.max.messages is overridden to 10000 (kafka.utils.VerifiablePrope
rties)
[2013-04-25 10:08:52,547] INFO Property key.serializer.class is overridden to kafka.serializer.StringEncoder (kafka.util
s.VerifiableProperties)
[2013-04-25 10:08:52,547] INFO Property compression.codec is overridden to 0 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:52,547] INFO Property serializer.class is overridden to kafka.serializer.StringEncoder (kafka.utils.Ve
rifiableProperties)
[2013-04-25 10:08:52,547] INFO Property request.timeout.ms is overridden to 1500 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:52,547] INFO Property broker.list is overridden to localhost:9092 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:52,547] INFO Property send.buffer.bytes is overridden to 102400 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:52,547] INFO Property request.required.acks is overridden to 0 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:52,547] INFO Property producer.type is overridden to sync (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:52,547] INFO Property queue.buffering.max.ms is overridden to 1000 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:52,547] INFO Property queue.enqueue.timeout.ms is overridden to 0 (kafka.utils.VerifiableProperties)
hello
[2013-04-25 10:09:03,203] INFO Fetching metadata with correlation id 0 for 1 topic(s) Set(test) (kafka.client.ClientUtil
s$)
[2013-04-25 10:09:03,203] INFO Connected to localhost:9092 for producing (kafka.producer.SyncProducer)
[2013-04-25 10:09:03,281] INFO Disconnecting from localhost:9092 (kafka.producer.SyncProducer)
[2013-04-25 10:09:03,281] WARN Error while fetching metadata    partition 0     leader: none    replicas:       isr:
isUnderReplicated: false for topic partition [test,0]: [class kafka.common.LeaderNotAvailableException] (kafka.producer.
BrokerPartitionInfo)
[2013-04-25 10:09:03,297] WARN Failed to collate messages by topic,partition due to (kafka.producer.async.DefaultEventHa
ndler)
kafka.common.LeaderNotAvailableException: No leader for any partition
        at kafka.producer.async.DefaultEventHandler.kafka$producer$async$DefaultEventHandler$$getPartition(DefaultEventH
andler.scala:212)
        at kafka.producer.async.DefaultEventHandler$$anonfun$partitionAndCollate$1.apply(DefaultEventHandler.scala:150)
        at kafka.producer.async.DefaultEventHandler$$anonfun$partitionAndCollate$1.apply(DefaultEventHandler.scala:148)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.async.DefaultEventHandler.partitionAndCollate(DefaultEventHandler.scala:148)
        at kafka.producer.async.DefaultEventHandler.dispatchSerializedData(DefaultEventHandler.scala:94)
        at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:72)
        at kafka.producer.Producer.send(Producer.scala:74)
        at kafka.producer.ConsoleProducer$.main(ConsoleProducer.scala:159)
        at kafka.producer.ConsoleProducer.main(ConsoleProducer.scala)
[2013-04-25 10:09:03,406] INFO Fetching metadata with correlation id 2 for 1 topic(s) Set(test) (kafka.client.ClientUtil
s$)
[2013-04-25 10:09:03,406] INFO Connected to localhost:9092 for producing (kafka.producer.SyncProducer)
[2013-04-25 10:09:03,438] INFO Disconnecting from localhost:9092 (kafka.producer.SyncProducer)
[2013-04-25 10:09:03,453] INFO Connected to YIYIN-MAIN.redmond.corp.microsoft.com:9092 for producing (kafka.producer.Syn
cProducer)
hello
hello
hello


=================================ZooKeeper Log====================================

C:\Projects\Kafka\kafka\bin\..
[2013-04-25 10:08:46,500] INFO Reading configuration from: ..\config\zookeeper.properties (org.apache.zookeeper.server.q
uorum.QuorumPeerConfig)
[2013-04-25 10:08:46,500] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.
zookeeper.server.quorum.QuorumPeerMain)
[2013-04-25 10:08:46,515] INFO Reading configuration from: ..\config\zookeeper.properties (org.apache.zookeeper.server.q
uorum.QuorumPeerConfig)
[2013-04-25 10:08:46,515] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2013-04-25 10:08:46,531] INFO Server environment:zookeeper.version=3.3.3-1203054, built on 11/17/2011 05:47 GMT (org.ap
ache.zookeeper.server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO Server environment:host.name=YIYIN-MAIN.redmond.corp.microsoft.com (org.apache.zookeeper.
server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO Server environment:java.version=1.7.0_21 (org.apache.zookeeper.server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperS
erver)
[2013-04-25 10:08:46,531] INFO Server environment:java.home=C:\Program Files (x86)\Java\jdk1.7.0_21\jre (org.apache.zook
eeper.server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO Server environment:java.io.tmpdir=C:\Users\yiyin\AppData\Local\Temp\ (org.apache.zookeepe
r.server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO Server environment:os.name=Windows 8 (org.apache.zookeeper.server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO Server environment:os.arch=x86 (org.apache.zookeeper.server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO Server environment:os.version=6.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO Server environment:user.name=yiyin (org.apache.zookeeper.server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO Server environment:user.home=C:\Users\yiyin (org.apache.zookeeper.server.ZooKeeperServer)

[2013-04-25 10:08:46,531] INFO Server environment:user.dir=C:\Projects\Kafka\kafka\bin (org.apache.zookeeper.server.ZooK
eeperServer)
[2013-04-25 10:08:46,531] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2013-04-25 10:08:46,531] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2013-04-25 10:08:46,547] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxn)
[2013-04-25 10:08:46,562] INFO Snapshotting: 0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2013-04-25 10:08:49,703] INFO Accepted socket connection from /127.0.0.1:8001 (org.apache.zookeeper.server.NIOServerCnx
n)
[2013-04-25 10:08:49,703] INFO Client attempting to establish new session at /127.0.0.1:8001 (org.apache.zookeeper.serve
r.NIOServerCnxn)
[2013-04-25 10:08:49,703] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2013-04-25 10:08:49,781] INFO Established session 0x13e422b2f620000 with negotiated timeout 6000 for client /127.0.0.1:
8001 (org.apache.zookeeper.server.NIOServerCnxn)
[2013-04-25 10:08:49,812] INFO Got user-level KeeperException when processing sessionid:0x13e422b2f620000 type:create cx
id:0x1 zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NoNode for /b
rokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2013-04-25 10:08:49,812] INFO Got user-level KeeperException when processing sessionid:0x13e422b2f620000 type:create cx
id:0x2 zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /broke
rs (org.apache.zookeeper.server.PrepRequestProcessor)
[2013-04-25 10:08:49,875] INFO Got user-level KeeperException when processing sessionid:0x13e422b2f620000 type:setData c
xid:0xb zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode
for /controller_epoch (org.apache.zookeeper.server.PrepRequestProcessor)
[2013-04-25 10:08:49,984] INFO Got user-level KeeperException when processing sessionid:0x13e422b2f620000 type:delete cx
id:0x19 zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
(org.apache.zookeeper.server.PrepRequestProcessor)
[2013-04-25 10:08:55,594] INFO Accepted socket connection from /127.0.0.1:8007 (org.apache.zookeeper.server.NIOServerCnx
n)
[2013-04-25 10:08:55,609] INFO Client attempting to establish new session at /127.0.0.1:8007 (org.apache.zookeeper.serve
r.NIOServerCnxn)
[2013-04-25 10:08:55,672] INFO Established session 0x13e422b2f620001 with negotiated timeout 6000 for client /127.0.0.1:
8007 (org.apache.zookeeper.server.NIOServerCnxn)
[2013-04-25 10:08:55,687] INFO Accepted socket connection from /127.0.0.1:8010 (org.apache.zookeeper.server.NIOServerCnx
n)
[2013-04-25 10:08:55,687] INFO Client attempting to establish new session at /127.0.0.1:8010 (org.apache.zookeeper.serve
r.NIOServerCnxn)
[2013-04-25 10:08:55,687] INFO Established session 0x13e422b2f620002 with negotiated timeout 30000 for client /127.0.0.1
:8010 (org.apache.zookeeper.server.NIOServerCnxn)
[2013-04-25 10:08:55,703] INFO Processed session termination for sessionid: 0x13e422b2f620002 (org.apache.zookeeper.serv
er.PrepRequestProcessor)
[2013-04-25 10:08:55,703] INFO Closed socket connection for client /127.0.0.1:8010 which had sessionid 0x13e422b2f620002
 (org.apache.zookeeper.server.NIOServerCnxn)
[2013-04-25 10:08:55,750] INFO Got user-level KeeperException when processing sessionid:0x13e422b2f620001 type:create cx
id:0x2 zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a Error Path:/consumers/console-consumer-70983/ids Error:Keeper
ErrorCode = NoNode for /consumers/console-consumer-70983/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2013-04-25 10:08:55,750] INFO Got user-level KeeperException when processing sessionid:0x13e422b2f620001 type:create cx
id:0x3 zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a Error Path:/consumers/console-consumer-70983 Error:KeeperErro
rCode = NoNode for /consumers/console-consumer-70983 (org.apache.zookeeper.server.PrepRequestProcessor)
[2013-04-25 10:08:55,750] INFO Got user-level KeeperException when processing sessionid:0x13e422b2f620001 type:create cx
id:0x4 zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NoNode for /con
sumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2013-04-25 10:09:03,219] INFO Got user-level KeeperException when processing sessionid:0x13e422b2f620000 type:create cx
id:0x21 zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NoNode fo
r /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2013-04-25 10:09:03,266] INFO Got user-level KeeperException when processing sessionid:0x13e422b2f620000 type:create cx
id:0x2f zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a Error Path:/brokers/topics/test/partitions/0 Error:KeeperErr
orCode = NoNode for /brokers/topics/test/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[2013-04-25 10:09:03,266] INFO Got user-level KeeperException when processing sessionid:0x13e422b2f620000 type:create cx
id:0x30 zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a Error Path:/brokers/topics/test/partitions Error:KeeperError
Code = NoNode for /brokers/topics/test/partitions (org.apache.zookeeper.server.PrepRequestProcessor)


==============================Consumer Log=======================================

C:\Projects\Kafka\kafka\bin\..
[2013-04-25 10:08:55,516] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:55,547] INFO Property zk.connect is overridden to localhost:2181 (kafka.utils.VerifiablePro
[2013-04-25 10:08:55,547] INFO Property group.id is overridden to console-consumer-70983 (kafka.utils.Verifia
es)
[2013-04-25 10:08:55,547] INFO Property fetch.message.max.bytes is overridden to 1048576 (kafka.utils.Verifia
es)
[2013-04-25 10:08:55,547] INFO Property consumer.timeout.ms is overridden to -1 (kafka.utils.VerifiableProper
[2013-04-25 10:08:55,547] INFO Property socket.timeout.ms is overridden to 30000 (kafka.utils.VerifiablePrope
[2013-04-25 10:08:55,547] INFO Property auto.offset.reset is overridden to smallest (kafka.utils.VerifiablePr
[2013-04-25 10:08:55,547] INFO Property socket.receive.buffer.bytes is overridden to 2097152 (kafka.utils.Ver
erties)
[2013-04-25 10:08:55,547] INFO Property fetch.wait.max.ms is overridden to 100 (kafka.utils.VerifiablePropert
[2013-04-25 10:08:55,547] INFO Property auto.commit.enable is overridden to true (kafka.utils.VerifiablePrope
[2013-04-25 10:08:55,547] INFO Property auto.commit.interval.ms is overridden to 10000 (kafka.utils.Verifiabl
)
[2013-04-25 10:08:55,547] INFO Property fetch.min.bytes is overridden to 1 (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:55,562] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], Connecting to zook
nce at localhost:2181 (kafka.consumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,562] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2013-04-25 10:08:55,578] INFO Client environment:zookeeper.version=3.3.3-1203054, built on 11/17/2011 05:47
ache.zookeeper.ZooKeeper)
[2013-04-25 10:08:55,578] INFO Client environment:host.name=YIYIN-MAIN.redmond.corp.microsoft.com (org.apache
ZooKeeper)
[2013-04-25 10:08:55,578] INFO Client environment:java.version=1.7.0_21 (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:55,578] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKee
[2013-04-25 10:08:55,578] INFO Client environment:java.home=C:\Program Files (x86)\Java\jdk1.7.0_21\jre (org.
eeper.ZooKeeper)
[2013-04-25 10:08:55,578] INFO Client environment:java.io.tmpdir=C:\Users\yiyin\AppData\Local\Temp\ (org.apac
r.ZooKeeper)
[2013-04-25 10:08:55,578] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:55,578] INFO Client environment:os.name=Windows 8 (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:55,578] INFO Client environment:os.arch=x86 (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:55,578] INFO Client environment:os.version=6.2 (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:55,578] INFO Client environment:user.name=yiyin (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:55,578] INFO Client environment:user.home=C:\Users\yiyin (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:55,578] INFO Client environment:user.dir=C:\Projects\Kafka\kafka\bin (org.apache.zookeeper.
[2013-04-25 10:08:55,578] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000
g.I0Itec.zkclient.ZkClient@1124f52 (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:55,594] INFO Opening socket connection to server localhost/127.0.0.1:2181 (org.apache.zooke
Cnxn)
[2013-04-25 10:08:55,594] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session
.zookeeper.ClientCnxn)
[2013-04-25 10:08:55,672] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid =
f620001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2013-04-25 10:08:55,672] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2013-04-25 10:08:55,672] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], starting auto comm
 10000 ms (kafka.consumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,687] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=3000
rg.I0Itec.zkclient.ZkClient@13033a (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:55,687] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2013-04-25 10:08:55,687] INFO Opening socket connection to server localhost/127.0.0.1:2181 (org.apache.zooke
Cnxn)
[2013-04-25 10:08:55,687] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session
.zookeeper.ClientCnxn)
[2013-04-25 10:08:55,687] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid =
f620002, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[2013-04-25 10:08:55,687] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2013-04-25 10:08:55,703] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2013-04-25 10:08:55,703] INFO Session: 0x13e422b2f620002 closed (org.apache.zookeeper.ZooKeeper)
[2013-04-25 10:08:55,703] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[2013-04-25 10:08:55,734] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], begin registering
nsole-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,750] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], end registering co
ole-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c in ZK (kafka.consumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,750] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], starting watcher e
ead for consumer console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c (kafka.consumer.ZookeeperConsumerCo
[2013-04-25 10:08:55,766] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], begin rebalancing
nsole-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,891] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2013-04-25 10:08:55,906] INFO Property broker.list is overridden to YIYIN-MAIN.redmond.corp.microsoft.com:90
tils.VerifiableProperties)
[2013-04-25 10:08:55,906] INFO Property request.timeout.ms is overridden to 30000 (kafka.utils.VerifiableProp
[2013-04-25 10:08:55,906] INFO Property client.id is overridden to console-consumer-70983 (kafka.utils.Verifi
ies)
[2013-04-25 10:08:55,922] INFO Fetching metadata with correlation id 0 for 0 topic(s) Set() (kafka.client.Cli
[2013-04-25 10:08:55,922] INFO Connected to YIYIN-MAIN.redmond.corp.microsoft.com:9092 for producing (kafka.p
cProducer)
[2013-04-25 10:08:55,969] INFO Disconnecting from YIYIN-MAIN.redmond.corp.microsoft.com:9092 (kafka.producer.
r)
[2013-04-25 10:08:55,969] INFO [ConsumerFetcherManager-1366909735672] Stopping leader finder thread (kafka.co
umerFetcherManager)
[2013-04-25 10:08:55,969] INFO [ConsumerFetcherManager-1366909735672] Stopping all fetchers (kafka.consumer.C
herManager)
[2013-04-25 10:08:55,969] INFO [ConsumerFetcherManager-1366909735672] All connections stopped (kafka.consumer
tcherManager)
[2013-04-25 10:08:55,969] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], Cleared all releva
or this fetcher (kafka.consumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,969] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], Cleared the data c
l the consumer message iterators (kafka.consumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,969] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], Committing all off
clearing the fetcher queues (kafka.consumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,969] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], Releasing partitio
 (kafka.consumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,984] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], Updating the cache
sumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,984] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], Consumer console-c
83_YIYIN-MAIN-1366909735562-a3d9410c selected partitions :  (kafka.consumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,984] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c-leader-finder-thread
  (kafka.consumer.ConsumerFetcherManager$LeaderFinderThread)
[2013-04-25 10:08:55,984] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], end rebalancing co
ole-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c try #0 (kafka.consumer.ZookeeperConsumerConnector)
[2013-04-25 10:08:55,984] INFO [console-consumer-70983_YIYIN-MAIN-1366909735562-a3d9410c], Not creating event
r trivial whitelist test (kafka.consumer.ZookeeperConsumerConnector)
",Windows,flyingyin,junrao,reefedjib,sriramsub,swapnilghike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-903,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,324998,,,Fri Jun 28 06:13:08 UTC 2013,,,,,,,,,,"0|i1k2jr:",325343,,,,,,,,,,,,,,,,,,,,"26/Apr/13 12:13;junrao;Hmm, this is weird. The broker log shows that broker 0 has successfully become the leader of topic test partition 0 after handling the leaderAndIsr request. However, afterwards, it still has the warning ""Leader not local for partition [test,0]"". Wondering if this is somehow a Windows specific issue.;;;","26/Apr/13 14:41;swapnilghike;Starting from 10:08:55,750, the zookeeper log shows user-level KeeperExceptions, one of which is:

[2013-04-25 10:09:03,219] INFO Got user-level KeeperException when processing sessionid:0x13e422b2f620000 type:create cx 
id:0x21 zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NoNode fo 
r /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor) 

Could you check if your zookeeper is healthy (using zkClient say) after you start seeing the ""Leader not local"" messages?;;;","26/Apr/13 22:33;junrao;That ZK log entry is ok. It's at INFO level, not error. Our ZK client auto-creates certain ZK paths when they don't exist.;;;","27/Apr/13 05:55;junrao;Could you add the following line to config/log4j/properties after the line "" # Turn on all our debugging info""?
log4j.logger.kafka.cluster.Partition=TRACE, kafkaAppender

Could you rerun quickstart and see if there is any trace logging in the broker that looks like the following?
""Broker 0 discarded the become-leader request ..."";;;","27/Apr/13 06:19;reefedjib;I redid what you wanted (I switched to kafka8-tmp to differentiate from tmp for kafka7, but forgot to point the broker to there) and here is the results, primarily this ERROR, in the state-change.log.  It seems it may be a filePath issue, on Windows:

[2013-04-26 16:14:38,209] ERROR Error on broker 0 while processing LeaderAndIsr request correlationId 5 received from controller 0 epoch 1 for partition (unittest,0) (state.change.logger)
java.util.NoSuchElementException: key not found: \kafka8-tmp\kafka-logs

in the server.log:
[2013-04-26 16:14:49,113] WARN [KafkaApi-0] Leader not local for partition [unittest,0] on broker 0 (kafka.server.KafkaApis)


***********************

in the state-change,log:

[2013-04-26 16:14:38,034] TRACE Controller 0 epoch 1 changed partition [unittest,0] state from NotExists to New with assigned replicas 0 (state.change.logger)
[2013-04-26 16:14:38,039] TRACE Controller 0 epoch 1 changed state of replica 0 for partition [unittest,0] to NewReplica (state.change.logger)
[2013-04-26 16:14:38,137] TRACE Controller 0 epoch 1 changed partition [unittest,0] from OnlinePartition to OnlinePartition with leader 0 (state.change.logger)
[2013-04-26 16:14:38,141] TRACE Controller 0 epoch 1 sending become-leader LeaderAndIsr request with correlationId 5 to broker 0 for partition [unittest,0] (state.change.logger)
[2013-04-26 16:14:38,143] TRACE Controller 0 epoch 1 changed state of replica 0 for partition [unittest,0] to OnlineReplica (state.change.logger)
[2013-04-26 16:14:38,149] TRACE Broker 0 handling LeaderAndIsr request correlation id 5 received from controller 0 epoch 1 for partition [unittest,0] (state.change.logger)
[2013-04-26 16:14:38,152] TRACE Broker 0 received LeaderAndIsr request correlationId 5 from controller 0 epoch 1 starting the become-leader transition for partition [unittest,0] (state.change.logger)
[2013-04-26 16:14:38,209] ERROR Error on broker 0 while processing LeaderAndIsr request correlationId 5 received from controller 0 epoch 1 for partition (unittest,0) (state.change.logger)
java.util.NoSuchElementException: key not found: \kafka8-tmp\kafka-logs
	at scala.collection.MapLike$class.default(MapLike.scala:223)
	at scala.collection.immutable.Map$Map1.default(Map.scala:93)
	at scala.collection.MapLike$class.apply(MapLike.scala:134)
	at scala.collection.immutable.Map$Map1.apply(Map.scala:93)
	at kafka.cluster.Partition.getOrCreateReplica(Partition.scala:83)
	at kafka.cluster.Partition$$anonfun$1.apply(Partition.scala:149)
	at kafka.cluster.Partition$$anonfun$1.apply(Partition.scala:149)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
	at scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:61)
	at scala.collection.immutable.List.foreach(List.scala:45)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)
	at scala.collection.immutable.List.map(List.scala:45)
	at kafka.cluster.Partition.makeLeader(Partition.scala:149)
	at kafka.server.ReplicaManager.kafka$server$ReplicaManager$$makeLeader(ReplicaManager.scala:256)
	at kafka.server.ReplicaManager$$anonfun$becomeLeaderOrFollower$3.apply(ReplicaManager.scala:220)
	at kafka.server.ReplicaManager$$anonfun$becomeLeaderOrFollower$3.apply(ReplicaManager.scala:212)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:105)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:212)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:79)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:64)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:41)
	at java.lang.Thread.run(Thread.java:662)
[2013-04-26 16:14:38,210] TRACE Broker 0 handled LeaderAndIsr request correlationId 5 received from controller 0 epoch 1 for partition [unittest,0] (state.change.logger)
[2013-04-26 16:14:38,215] TRACE Controller 0 epoch 1 received response correlationId 5 for a request sent to broker 0 (state.change.logger)

;;;","27/Apr/13 06:29;sriramsub;1. Is this the latest kafka checkout? If not, can you try on a more recent build?
2. Could you attach the server config that you are using?;;;","27/Apr/13 07:25;reefedjib;It was current yesterday.  I had trouble pulling tonight, but did so, with the top of the git log.  Now I cannot run the broker with the below exception.  I attached my server.properties below:

D:\dish\workspace\kafka>git log
commit e37a4644209de00f265a5361b31ca63cafc895e9
Author: Joel Koshy <jjkoshy@gmail.com>
Date:   Fri Apr 26 14:13:00 2013 -0700

    Trivial commit - warn on consumer fetch request errors.

commit 6e640e355632d97e322e462c2bbc379c05d407a4
Author: Jun Rao <junrao@gmail.com>
Date:   Thu Apr 25 19:03:21 2013 -0700

    kafka-880; NoLeaderPartitionSet should be cleared before leader finder threa


broker ERROR:

[2013-04-26 17:23:39,076] FATAL Fatal error during KafkaServerStable startup. Pr
epare to shutdown (kafka.server.KafkaServerStartable)
java.lang.NullPointerException
        at org.apache.zookeeper.ClientCnxn.<init>(ClientCnxn.java:361)
        at org.apache.zookeeper.ClientCnxn.<init>(ClientCnxn.java:332)
        at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:383)
        at org.I0Itec.zkclient.ZkConnection.connect(ZkConnection.java:64)
        at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:872)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:98)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:84)
        at kafka.common.KafkaZookeeperClient$.getZookeeperClient(KafkaZookeperCl
ient.scala:31)
        at kafka.server.KafkaZooKeeper.startup(KafkaZooKeeper.scala:39)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:76)
        at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:
34)
        at kafka.Kafka$.main(Kafka.scala:46)
        at kafka.Kafka.main(Kafka.scala)


server.properties:

# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
# 
#    http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# see kafka.server.KafkaConfig for additional details and defaults

############################# Server Basics #############################

# The id of the broker. This must be set to a unique integer for each broker.
broker.id=0

############################# Socket Server Settings #############################

# The port the socket server listens on
port=9092

# Hostname the broker will bind to and advertise to producers and consumers.
# If not set, the server will bind to all interfaces and advertise the value returned from
# from java.net.InetAddress.getCanonicalHostName().
#host.name=localhost

# The number of threads handling network requests
num.network.threads=2
 
# The number of threads doing disk I/O
num.io.threads=2

# The send buffer (SO_SNDBUF) used by the socket server
socket.send.buffer.bytes=2096576

# The receive buffer (SO_RCVBUF) used by the socket server
socket.receive.buffer.bytes=2096576

# The maximum size of a request that the socket server will accept (protection against OOM)
socket.request.max.bytes=104857600


############################# Log Basics #############################

# The directory under which to store log files
log.dir=/kafka8-tmp/kafka-logs

# The number of logical partitions per topic per server. More partitions allow greater parallelism
# for consumption, but also mean more files.
num.partitions=1

############################# Log Flush Policy #############################

# The following configurations control the flush of data to disk. This is the most
# important performance knob in kafka.
# There are a few important trade-offs here:
#    1. Durability: Unflushed data is at greater risk of loss in the event of a crash.
#    2. Latency: Data is not made available to consumers until it is flushed (which adds latency).
#    3. Throughput: The flush is generally the most expensive operation. 
# The settings below allow one to configure the flush policy to flush data after a period of time or
# every N messages (or both). This can be done globally and overridden on a per-topic basis.

# The number of messages to accept before forcing a flush of data to disk
log.flush.interval.messages=10000

# The maximum amount of time a message can sit in a log before we force a flush
log.flush.interval.ms=1000

# Per-topic overrides for log.flush.interval.ms
#log.flush.intervals.ms.per.topic=topic1:1000, topic2:3000

############################# Log Retention Policy #############################

# The following configurations control the disposal of log segments. The policy can
# be set to delete segments after a period of time, or after a given size has accumulated.
# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens
# from the end of the log.

# The minimum age of a log file to be eligible for deletion
log.retention.hours=168

# A size-based retention policy for logs. Segments are pruned from the log as long as the remaining
# segments don't drop below log.retention.bytes.
#log.retention.bytes=1073741824

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
log.segment.bytes=536870912

# The interval at which log segments are checked to see if they can be deleted according 
# to the retention policies
log.cleanup.interval.mins=1

############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. ""127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002"".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
zookeeper.connect=localhost:2191

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=1000000

# metrics reporter properties
kafka.metrics.polling.interval.secs=5
kafka.metrics.reporters=kafka.metrics.KafkaCSVMetricsReporter
kafka.csv.metrics.dir=/tmp/kafka_metrics
# Disable csv reporting by default.
kafka.csv.metrics.reporter.enabled=false

;;;","27/Apr/13 08:31;sriramsub;is this a valid path in windows ? /kafka8-tmp/kafka-logs ;;;","27/Apr/13 08:55;reefedjib;It should resolve to D:\kafka8-tmp\kafka-logs.  My kafka 7 works under cygwin, but I am running kafka8 under windows.  When I ran before pulling, there was a D:\kafka8-tmp\kafka-logs created, but I did not check if there were any index files inside.  I have since deleted the dir to reset the indexes.

After pulling this afternoon, the new error does not explicitly state that it is a filePath issue.

2013-04-26 17:23:39,076] FATAL Fatal error during KafkaServerStable startup. Prepare to shutdown (kafka.server.KafkaServerStartable) 
java.lang.NullPointerException 
        at org.apache.zookeeper.ClientCnxn.<init>(ClientCnxn.java:361) ;;;","27/Apr/13 22:44;junrao;Could you do the following and retry?

./sbt +package
./sbt assembly-package-dependency
;;;","27/Apr/13 22:54;reefedjib;I may try to get into work, tomorrow, and check it out, or it will be Monday.  I cannot run kafka8 under cygwin or dos here at home.  Here is the inane error I get under dos:

c:\rob\comp\workspace\kafka\bin>windows\zookeeper-server-start.bat ..\config\zookeeper.properties
c:\rob\comp\workspace\kafka\bin\..
The system cannot find the path specified.

I thought it was kidding, the first time I saw it.

thanks,
rob;;;","30/Apr/13 00:29;junrao;It seems that the exception was caused in the following statement in Partition.
replicaManager.highWatermarkCheckpoints(log.dir.getParent)

It tries to look up in a map of highWatermarkCheckpoint files to find the key ""\kafka8-tmp\kafka-logs"", but it doesn't exist. We register the keys using the property value in log.dirs. What property value did you set log.dirs to? It seems to be different from ""\kafka8-tmp\kafka-logs"".;;;","30/Apr/13 21:56;reefedjib;The property is named ""log.dir"", not ""log.dirs"" in my properties file.  Here is what I have:

############################# Log Basics #############################

# The directory under which to store log files
log.dir=/kafka8-tmp/kafka-logs
;;;","30/Apr/13 23:43;junrao;It seems that log.dir.getParent() returns a path with forward slash \kafka8-tmp\kafka-logs. Could you use forward slash in log.dir instead of backward slash?;;;","11/May/13 08:47;reefedjib;Jun, I changed the properties for the brokers to use backward slashes, as you suggested.  As in \tmp\kafka0-logs.  This worked and I was able to produce data for awhile.  It seems the bug this issue is about is fixed and could be closed.  

However, zookeeper accepts forward slashes (/tmp/zookeeper) and is successful with this.  Kafka should be agnostic as well, I think - to make it all it will be.

After producing for awhile, it logs this FATAL error, in one of the brokers, and both brokers are shutdown:

{2013-05-10 18:23:57,689} FATAL [highwatermark-checkpoint-thread1] (Logging.scala:109) - Attempt to swap the new high watermark file with the old one failed

I will log a new issue.;;;","28/Jun/13 14:13;junrao;This is fixed in kafka-903.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka producer hangs on producer.close() call if the producer topic contains single quotes in the topic name,KAFKA-3018,12923359,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,anandkanav,anandkanav,21/Dec/15 15:39,20/Jun/18 17:17,22/Mar/23 15:10,20/Jun/18 17:17,0.10.0.0,0.11.0.0,1.0.0,,,,,,,,,,,producer ,,,,0,,,,,,"While creating topics with quotes in the name throws a exception but if you try to close a producer configured with a topic name with quotes the producer hangs.
It can be easily replicated and verified by setting topic.name for a producer with a string containing single quotes in it.",,anandkanav,becket_qin,githubbot,hoangchi,ijuma,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-5098,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jun 20 09:17:15 UTC 2018,,,,,,,,,,"0|i2q5br:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Jan/16 17:48;ijuma;Thanks for the report. Does this also happen in 0.9.0.0 with the new producer?;;;","23/Feb/16 08:33;hoangchi;I encountered this, if not a similar, problem.  I unknowingly had double-quotes in the topic name and I couldn't get topic metadata from the cluster because the server tried the validate the topic and determined it was not valid.  The message the server returned was InvalidTopicException, but the producer logs only showed INVALID_TOPIC_EXCEPTION - ""The request attempted to perform an operation on an invalid topic.""  I had a lot of trouble tracking this down.

This could be be improved by failing early adding a topic name validation in the ProducerRecord instantiation.

I ran this against trunk and 0.9.0.0 to confirm that the behavior is the same in each.;;;","24/Feb/16 09:22;githubbot;GitHub user choang opened a pull request:

    https://github.com/apache/kafka/pull/961

    KAFKA-3018: added topic name validator to ProducerRecord

    Added validation for topic name when creating a `ProducerRecord`, and added corresponding tests.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/choang/kafka kafka-3018

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/961.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #961
    
----
commit de2e599268189921bf768de66bf003e56b9e879f
Author: Chi Hoang <chi.hoang@zuora.com>
Date:   2016-02-23T22:06:58Z

    KAFKA-3018: added topic name validator to ProducerRecord

----
;;;","25/Feb/16 02:34;becket_qin;I am not sure if we should let producer to check if a topic name is valid or not. At the end of the day, it is the server which determines whether a topic name is valid or not. Would it help if we improve the error message of InvalidTopicException a little bit to give some possible causes?;;;","25/Feb/16 03:30;hoangchi;In this case, there are two problems:
- the send operation seems to hang because it waits for a valid metadata update to return
- the message only shows up in the logs and is not clear

We could change the send operation to better handle the metadata update, and fail faster if you insist on having the server be the arbitrator of whether a topic name is valid.;;;","25/Feb/16 04:16;granthenke;[~hoangchi],

I agree with [~becket_qin] that the ""true"" place for this validation is in the server. Though I am not against some fail fast filters in the client either. The main reason being that clients support a concept of ""auto topic creation"" which actually trigger on the client but is carried out by the server.

I am always for better more clear error messages. So if we can do that, we should. Especially because even if we add validation client side, the server may not agree and the error messages will need to be handled/communicated.;;;","25/Feb/16 06:09;becket_qin;I agree that the producer should throw exception to user. 

As [~granthenke] mentioned, the problem comes from auto topic creation. Can we follow the similar way we are handling unauthorized topics? We can have a map of topicsWithErrors in Metadata and put the topics with errors we see in the MetadataResponse into this map. This way we can bubble up the exception to user thread easily.

BTW, after KIP-4, we should be able to easily bubble up the InvalidTopicException.;;;","25/Feb/16 06:23;hoangchi;I'm going to go ahead and close the PR, and come back to this once I get a better understanding of the metadata update interactions.;;;","25/Feb/16 06:23;githubbot;Github user choang closed the pull request at:

    https://github.com/apache/kafka/pull/961
;;;","07/Mar/16 08:41;hoangchi;Coming back to this.  Seems like the more appropriate design would be to split server from core, and start moving code that will be shared by both client and server to core.  The suggestion to wait until the server rejects the topic means we have to wait and have more complex interactions to get the true nature of the problem.  I would still prefer to have the failure occur the moment the topic is referenced, and in this case, it is during instantiation of a ProducerRecord.  I'm also in favor of the server being the ultimate enforcer of the topic name.

To save a few cycles, Topic can be a formal object which owns the validation, and the ProducerRecord would take a Topic object instead of a String, so the ProducerRecord constructor would not be responsible for validating the topic.

Splitting out another module would probably require a KIP, so I'm not going to take another shot at this until we establish a direction.;;;","07/Mar/16 09:05;ijuma;The path Kafka has taken is actually a bit different. There is a `common` package in the `clients` module which is shared by both the clients and the broker. One of the things to keep in mind is that newer brokers support older clients so even with shared logic, it can happen that they may not be the same due to different versions. I think everyone agrees that validation on the broker side is required either way, so it may make sense to start with that and then decide whether it's worth doing it on the client-side too.;;;","07/Mar/16 09:23;hoangchi;The server is already correctly validating the topic name, and the message coming from the server is also pretty clear.  The problem described in this ticket revolve around how the client handles it.

[~granthenke]'s original suggestion was to move the topic validation to the common client code, and I thought it was sensible and would have made things simpler.  However, that meant that core would continue to depend on client, and that part was not so sensible to me.  I don't know the history behind making core dependent on client - git blame shows that KAFKA-1237 introduced this relationship - so if we want to maintain this dependency chain, I would go back to Grant's original suggestion and move the logic to clients-->common.  I have enough context to make that change and push a new pr.;;;","07/Mar/16 09:35;becket_qin;[~chi_groupon] The situation we are trying to avoid here is that the client and server has different judgement of whether a topic is valid or not. e.g. the clients said the topic is invalid and the broker said it is valid. This will be confusing to the user.

The issue we have today is that the invalid topic error is only shown in the log but not thrown as an exception to the user. Instead user thread will block. We can fix that and propagate the exception properly. But I think we should avoid validating the topic on both client an server side because the code might be different as [~ijuma] mentioned.;;;","20/Jun/18 17:17;omkreddy;Resolving this as duplicate of KAFKA-5098.  Please reopen if you think otherwise;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
IllegalThreadStateException in topic watcher for Kafka mirroring,KAFKA-212,12532524,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,24/Nov/11 03:43,01/Dec/11 09:04,22/Mar/23 15:10,01/Dec/11 09:04,,,,,,,0.7.1,,,,,,,,,,,0,,,,,,"If the kafka mirroring embedded consumer receives a new topic watcher notification, it runs into the following exception 

[2011-11-23 02:49:15,612] FATAL java.lang.IllegalThreadStateException (kafka.consumer.ZookeeperTopicEventWatcher)
[2011-11-23 02:49:15,612] FATAL java.lang.IllegalThreadStateException
        at java.lang.Thread.start(Thread.java:595)
        at kafka.server.EmbeddedConsumer$$anonfun$startNewConsumerThreads$3.apply(KafkaServerStartable.scala:142)
        at kafka.server.EmbeddedConsumer$$anonfun$startNewConsumerThreads$3.apply(KafkaServerStartable.scala:142)
        at scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:61)
        at scala.collection.immutable.List.foreach(List.scala:45)
        at kafka.server.EmbeddedConsumer.startNewConsumerThreads(KafkaServerStartable.scala:142)
        at kafka.server.EmbeddedConsumer.handleTopicEvent(KafkaServerStartable.scala:109)
        at kafka.consumer.ZookeeperTopicEventWatcher$ZkTopicEventListener.liftedTree2$1(ZookeeperTopicEventWatcher.scala:83)
        at kafka.consumer.ZookeeperTopicEventWatcher$ZkTopicEventListener.handleChildChange(ZookeeperTopicEventWatcher.scala:78)
        at org.I0Itec.zkclient.ZkClient$7.run(ZkClient.java:568)
        at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
 (kafka.consumer.ZookeeperTopicEventWatcher)

This happens since it tries to start a thread which has finished executing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Nov/11 04:47;nehanarkhede;KAFKA-212.patch;https://issues.apache.org/jira/secure/attachment/12504924/KAFKA-212.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,218257,,,Thu Dec 01 01:04:02 UTC 2011,,,,,,,,,,"0|i0l40v:",121302,,,,,,,,,,,,,,,,,,,,"24/Nov/11 04:47;nehanarkhede;This patch clears the threadList that holds the older thread references, before adding newer threads to it. This avoids trying to start an already finished thread, thus avoiding IllegalThreadStateException ;;;","24/Nov/11 05:00;jkreps;Any thread that doesn't shut down cleanly will leak, is that a problem? Can that happen?;;;","24/Nov/11 05:04;nehanarkhede;the thread shutdown is guarded by a countdown latch. It will finish shutdown only after the thread exists the run() method. The problem here is that we keep older shutdown thread references in that list and end up calling start on those, which leads to the exception;;;","29/Nov/11 03:04;nehanarkhede;Can somebody help review this ?;;;","29/Nov/11 04:01;jkreps;I don't think that answers my question, though, which is how do we know if we are leaking threads? I guess the patch doesn't make it better or worse, since we definitely don't want to keep them in the list, but can you assess what happens if shutdown fails? Can that happen? Do we log it? Or is there a guarantee that the thread must shutdown in some bounded period of time?;;;","29/Nov/11 05:38;nehanarkhede;>> which is how do we know if we are leaking threads? 

Good question. From what I see, the entire thread run() method is guarded by a try-catch-finally block. In the finally block, we count down the latch. So if the thread itself runs into some exception/error, it will exit the run() method and shut itself down. The other case of thread shutdown is when the mirroring thread itself calls the shutdown API. Here, we wait until the current producer send operation succeeds to count down the latch. In both cases, I don't see how we can leak threads

>> I guess the patch doesn't make it better or worse, since we definitely don't want to keep them in the list, but can you assess what happens if shutdown fails?

Not true. The patch fixes the bug filed here. Your concerns are about the shutdown logic of the thread, which if you suspect is a bug, can go in a separate JIRA.

>> Do we log it? 

Yes, in any case of shutdown, it gets logged as a FATAL error.

>> Or is there a guarantee that the thread must shutdown in some bounded period of time? 

Maybe. If the producer send operation hangs indefinitely, which is a serious bug in the producer send logic.
;;;","01/Dec/11 08:11;junrao;We shouldn't be leaking threads. If we can get to the code that creates new MirrorThreads, the old threads should have finished since shutdown is blocking. If the shutdown blocks forever, we won't be able to create new threads. Again, there is no thread leak. Although the latter would suggest another serious bug somewhere else.

+1 on the patch.;;;","01/Dec/11 09:04;nehanarkhede;Fix is committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Consumer and broker have different networks,KAFKA-2036,12783763,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,junrao,nyaapa,nyaapa,21/Mar/15 05:45,24/May/18 18:46,22/Mar/23 15:10,24/May/18 18:46,0.8.2.1,,,,,,,,,,,,,network,,,,0,,,,,,"If broker is connected to several networks ( for example ipv6 and ipv4 ) and not all of them are reachable to consumer then {{kafka.network.BlockingChannel}} gives up to connect after the first ""Network is unreachable"" error not triyng remaining networks","oracle java {7,8}, ipv6 only consumer, ipv4 + ipv6 broker",junrao,nyaapa,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-6863,KAFKA-6195,,,,,,,,,,,,,,,,,"23/Mar/15 21:57;nyaapa;patch;https://issues.apache.org/jira/secure/attachment/12706525/patch","21/Apr/15 20:58;nyaapa;patch2;https://issues.apache.org/jira/secure/attachment/12726876/patch2",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu May 24 10:46:55 UTC 2018,,,,,,,,,,"0|i272gv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Mar/15 05:55;nyaapa;simple solution with exhaustive search through all broker's addresses is in [patch|https://issues.apache.org/jira/secure/attachment/12706525/patch];;;","23/Mar/15 21:57;nyaapa;simplified patch;;;","19/Apr/15 00:24;junrao;Thanks for the patch. The new consumer/producer client will be using the network code in org.apache.kafka.common.network. Does it have the same problem? It's more important to fix the issue there since BlockingChannel will be go away in the future.;;;","21/Apr/15 20:36;nyaapa;I find that {{InetSocketAddress}} is only passed into clients/src/main/java/org/apache/kafka/common/network.
{{org.apache.kafka.clients.NetworkClient.initiateConnect}}:499 constructs incorrectly {{InetSocketAddress}} and passes it to {{Selectable}}. 
{{org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses}} has the same problem as {{BlockingChannel}}: we need to create {{InetSocketAddress}} and test it at once, we can't return it. So, it seems like the {{parseAndValidateAddresses}} logic is incorrect and we need to return sockets or use that resolvers/validators at place.

There is some sort of patch for {{org.apache.kafka.clients.NetworkClient.initiateConnect}}: {{this.connectionStates.connecting(node.id(), now)}} and {{selector.connect(...)}}  are swapped around because {{selector.connect()}} can throw an error.;;;","21/Apr/15 20:58;nyaapa;{{patch}} is tested in production, {{patch2}} is tested only with kafka tests, they completes each other, not replaces.;;;","24/May/18 18:46;omkreddy;Resolving this duplicate of KIP-235/KIP-302 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JBOD Support,KAFKA-2188,12829177,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,abiletskyi,abiletskyi,abiletskyi,12/May/15 20:10,05/Dec/17 03:05,22/Mar/23 15:10,05/Dec/17 03:05,,,,,,,,,,,,,,,,,,0,,,,,,https://cwiki.apache.org/confluence/display/KAFKA/KIP-18+-+JBOD+Support,,abiletskyi,bobrik,fpj,ijuma,jimhoagland,junrao,nickt,tfield,tnachen,umesh9794@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jul/15 16:18;tnachen;KAFKA-2188.patch;https://issues.apache.org/jira/secure/attachment/12745411/KAFKA-2188.patch","14/Jul/15 14:23;tnachen;KAFKA-2188.patch;https://issues.apache.org/jira/secure/attachment/12745195/KAFKA-2188.patch","12/May/15 20:39;abiletskyi;KAFKA-2188.patch;https://issues.apache.org/jira/secure/attachment/12732225/KAFKA-2188.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Dec 04 19:05:29 UTC 2017,,,,,,,,,,"0|i2em9j:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"12/May/15 20:39;abiletskyi;Created reviewboard https://reviews.apache.org/r/34103/diff/
 against branch origin/trunk;;;","14/Jul/15 14:23;tnachen;Created reviewboard https://reviews.apache.org/r/36474/diff/
 against branch origin/trunk;;;","15/Jul/15 16:18;tnachen;Created reviewboard https://reviews.apache.org/r/36503/diff/
 against branch origin/trunk;;;","17/Jul/15 07:04;junrao;[~tnachen], thanks for the patch.

It seems that KIP-18 is still under discussion and hasn't been approved. A couple of thoughts on this.

1. Instead of auto re-replicating the partitions on the failed disk to some other disks, I was thinking that a less aggressive approach is to simply fail those affected replicas w/o triggering the re-replication, but keep the broker running. The controller will still be informed of those failed replicas, but won't restart them. If those failed replicas are leaders, the controller will move the leaders to other replicas. This approach is probably simpler and gives us the main benefit, which is you don't hard-fail a broker immediately on single disk failure. The admin can cleanly shut down this broker at the appropriate time and fix the disk issue.

2. For 0.8.3 release, we are mainly trying to get the new consumer and some of the security features done. Could we defer this until 0.8.3 is out?
;;;","21/Jul/15 23:35;fpj;hey tim, I had a look at the proposal, and I have some feedback, mostly questions at this point. I like this improvement, and in general, I've found that we can improve quite a bit exception handling in Kafka. This is clearly one such great effort. Specifically, here are more concrete points:

# In the exception handler section, I'd say that the best approach is to be conservative and remove the drive in the case of an error. Let's not optimize too much trying to get the exact partitions that are affected by an error and such. If there is an error, then let an operator check it out and reinsert the drive when fixed. As part of this comment, I'd say that it'd be a good feature to allow drives to be inserted (manually).
# In the notifying controller discussion, could you be more specific about the race you're concerned about? I can tell that you're pointing out to a potential race, but I'm not sure what it is.
# Open question 1: disk availability. It's kind of hard to detect exactly what happened with a faulty disk. It could be disk full, drive is bad, or even just some annoying data corruption. I don't think it is worth spending tons of time and effort trying to make a great check. If we spot an error, then remove the drive and log it. I don't know if there is any typical mechanism to notify operators with Kafka.
# Open question 2: log read. I think I know the problem you're referring to, and I'll have a look to see if I can suggest some decent alternative, but we might need to make it a bit less efficient to be able to handle IO errors properly.
# Open question 3: restart partition. This is about the race I asked above. 
# Open question 4: operation retries. What would be a situation in which it is worth retrying? 

I was actually wondering if some users would be interested in the case of leaving a fraction of the drives unused to replace faulty drives over time. The advantage is to be able to maintain the capacity of a broker despite faulty drives, but surely you have some unused IO capacity in the broker. ;;;","22/Jul/15 00:05;junrao;Another thing that's worth mentioning is that currently we don't have throttling when bootstrapping new replicas. Bootstrapping too many new replicas at the same time can degrade the performance of the cluster. So, if we want to do any kind of auto re-replication, it would be good if we have the replication throttling in place first.;;;","05/Dec/17 03:05;ijuma;KIP-112 and KIP-113 replaced this one.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testZKSendWithDeadBroker fails intermittently due to ZKNodeExistsException,KAFKA-320,12548191,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,27/Mar/12 05:27,08/Apr/12 10:00,22/Mar/23 15:10,08/Apr/12 10:00,0.7,0.8.0,,,,,,,,,,,,core,,,,0,,,,,,"The testZKSendWithDeadBroker inside ProducerTest fails intermittently with the following exception -

[error] Test Failed: testZKSendWithDeadBroker(kafka.producer.ProducerTest)
java.lang.RuntimeException: A broker is already registered on the path /brokers/ids/0. This probably indicates that you either have configured a brokerid that is already in use, or else you have shutdown this broker and restarted it faster than the zookeeper timeout so it appears to be re-registering.
        at kafka.utils.ZkUtils$.registerBrokerInZk(ZkUtils.scala:109)
        at kafka.server.KafkaZooKeeper.kafka$server$KafkaZooKeeper$$registerBrokerInZk(KafkaZooKeeper.scala:60)
        at kafka.server.KafkaZooKeeper.startup(KafkaZooKeeper.scala:52)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:84)
        at kafka.producer.ProducerTest.testZKSendWithDeadBroker(ProducerTest.scala:174)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at junit.framework.TestCase.runTest(TestCase.java:164)
        at junit.framework.TestCase.runBare(TestCase.java:130)
        at junit.framework.TestResult$1.protect(TestResult.java:110)
        at junit.framework.TestResult.runProtected(TestResult.java:128)
        at junit.framework.TestResult.run(TestResult.java:113)
        at junit.framework.TestCase.run(TestCase.java:120)
        at junit.framework.TestSuite.runTest(TestSuite.java:228)
        at junit.framework.TestSuite.run(TestSuite.java:223)
        at junit.framework.TestSuite.runTest(TestSuite.java:228)
        at junit.framework.TestSuite.run(TestSuite.java:223)
        at org.scalatest.junit.JUnit3Suite.run(JUnit3Suite.scala:309)
        at org.scalatest.tools.ScalaTestFramework$ScalaTestRunner.run(ScalaTestFramework.scala:40)
        at sbt.TestRunner.run(TestFramework.scala:53)
        at sbt.TestRunner.runTest$1(TestFramework.scala:67)
        at sbt.TestRunner.run(TestFramework.scala:76)
        at sbt.TestFramework$$anonfun$10$$anonfun$apply$11.runTest$2(TestFramework.scala:194)
        at sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)
        at sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)
        at sbt.NamedTestTask.run(TestFramework.scala:92)
        at sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)
        at sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)
        at sbt.TaskManager$Task.invoke(TaskManager.scala:62)
        at sbt.impl.RunTask.doRun$1(RunTask.scala:77)
        at sbt.impl.RunTask.runTask(RunTask.scala:85)
        at sbt.impl.RunTask.sbt$impl$RunTask$$runIfNotRoot(RunTask.scala:60)
        at sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)
        at sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)
        at sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)
        at sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)
        at sbt.Control$.trapUnit(Control.scala:19)
        at sbt.Distributor$Run$Worker.run(ParallelRunner.scala:131)

The test basically restarts a server and fails with this exception during the restart

This is unexpected, since server1, after shutting down, should trigger the deletion of its registration of the broker id from ZK. But, here is the Kafka bug causing this problem -

In the test during server1.shutdown(), we do close the zkClient associated with the broker and it successfully deletes the broker's registration info from Zookeeper. After this, server1 can be succesfully started. Then the test completes and in the teardown(), we call server1.shutdown(). During this, the server doesn't really shutdown, since it is protected with the isShuttingDown variable, which was never set to false in the startup() API. Now, this leads to an open zkclient connection for the current test run. 

If you try to re-run ProducerTest without exiting sbt, it will first bring up the zookeeper server. Then, since the kafka server during the previous run is still running, it can succesfully renew its session with zookeeper, and retain the /brokers/ids/0 ephemeral node. If it does this before server1.startup() is called in the test, the test will fail.

The fix is to set the shutdown related variables correctly in the startup API of KafkaServer. Also, during debugging this, I found that we don't close zkclient in the Producer as well. Due to this, unit tests throw a whole bunch of WARN that look like - 

[2012-03-26 14:14:27,703] INFO Opening socket connection to server nnarkhed-ld /127.0.0.1:2182 (org.apache.zookeeper.ClientCnxn:1061)
[2012-03-26 14:14:27,703] WARN Session 0x13650dbf8dd0005 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn:1188)
java.net.ConnectException: Connection refused
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1146)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Mar/12 05:43;nehanarkhede;kafka-320-v2.patch;https://issues.apache.org/jira/secure/attachment/12520518/kafka-320-v2.patch","07/Apr/12 06:04;junrao;kafka-320-v3-delta.patch;https://issues.apache.org/jira/secure/attachment/12521772/kafka-320-v3-delta.patch","07/Apr/12 03:54;nehanarkhede;kafka-320-v3.patch;https://issues.apache.org/jira/secure/attachment/12521721/kafka-320-v3.patch","27/Mar/12 05:36;nehanarkhede;kafka-320.patch;https://issues.apache.org/jira/secure/attachment/12520016/kafka-320.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,233288,,,Sun Apr 08 02:00:49 UTC 2012,,,,,,,,,,"0|i09m8v:",54037,,,,,,,,,,,,,,,,,,,,"27/Mar/12 05:36;nehanarkhede;This patch includes the following -

1. Fixes the kafka server restart bug by resetting the shutdown state variables in the startup() API of the KafkaServer. 

2. Shuts down the zkclient in the Producer

3. ZkClient and Zookeeper can be set to WARN since we fixed the real issue, causing several warnings during the unit tests.
;;;","30/Mar/12 00:53;nehanarkhede;Can someone review this ?;;;","30/Mar/12 01:14;junrao;That's a good finding. We should probably patch it in both trunk and 0.8. Just one comment.

We should only allow a KafkaServer to startup if it has been shutdown.;;;","30/Mar/12 01:29;prashanth.menon;Great catch!  +1, looks good and works on my machine.;;;","30/Mar/12 05:43;nehanarkhede;OK, I made some more changes -

1. Cleaned up zkClient instance creations in unit tests. Now it is wrapped up inside ZookeeperTestHarness, so we ensure that it gets cleanup at an appropriate time. 

2. Changed Kafka server startup and shutdown behavior. Possibly made it more complex. Basically, 

2.1 A Kafka server can startup if it is not already starting up, if it is not currently being shutdown, or if it hasn't been already started

2.2 A Kafka server can shutdown if it is not already shutting down, if it is not currently starting up, or if it hasn't been already shutdown. ;;;","03/Apr/12 02:11;junrao;The ZookeeperTestHarness change looks nice. a couple more comments:

4. KafkaServer: It does look  a bit more complex now and some of the testing is not done atomically. How about the following? 
4.1 add an AtomticBoolean isServerStartable and initialize to true;
4.2 in startup(), if we can atomically set isServerStartable from true to false, proceed with startup; otherwise throw an exception.
4.3 in shutdown(), if isServerStartable is false, proceed with shutdown, at the very end, set isServerStartable to true. 
Startup() and shutdown() are expected to be called from the same thread. So we can expect a shutdown won't be called until a startup completes.

5. SyncProducerTest: unused imports
;;;","03/Apr/12 02:37;nehanarkhede;Thanks for the review!

4. Regarding this, what do people think about the conditions under which a Kafka server should be allowed to startup and shutdown (listed under 2.1 and 2.2 above) ?
5. Will fix this before checkin.
6. Also, looks like improving the kafka server startup and shutdown is orthogonal to this bug fix. Can this be fixed (cleanly) through another JIRA ? I'd like to include just the fix for this issue as part of the checkin. ;;;","03/Apr/12 12:30;junrao;Yes, we can use another jira to see how we can improve kafka server startup and shutdown. For this jira, we can just make minimal changes in kafka server.;;;","07/Apr/12 03:54;nehanarkhede;Filed KAFKA-328 for improving startup and shutdown API of Kafka server.

Kept everything in v2 minus the complexity of changes in Kafka server.;;;","07/Apr/12 06:04;junrao;Overall, patch v3 looks good. I made a minor tweak of KafkaServer on top of v3. How does that look? You will need to:
1. apply patch v3
2. svn revert core/src/main/scala/kafka/server/KafkaServer.scala
3. apply patch kafka-320-v3-delta.patch;;;","07/Apr/12 08:39;nehanarkhede;After applying the v3-delta patch, I see that some zkclient connections are not closed cleanly - 
[2012-04-06 17:34:12,805] WARN Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running (org.apache.zookeeper
.server.NIOServerCnxn:639)
[2012-04-06 17:34:12,809] WARN Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running (org.apache.zookeeper
.server.NIOServerCnxn:639)
[2012-04-06 17:34:13,201] WARN EndOfStreamException: Unable to read additional data from client sessionid 0x1368a38c37a0005, likely client has clos
ed socket (org.apache.zookeeper.server.NIOServerCnxn:634)
[2012-04-06 17:34:13,264] WARN EndOfStreamException: Unable to read additional data from client sessionid 0x1368a38a86a0080, likely client has clos
ed socket (org.apache.zookeeper.server.NIOServerCnxn:634)

Also, after you set the isShutdown variable and before you check canStart, there can be interleaving between startup and shutdown, that can lead to open zookeeper client connection.;;;","07/Apr/12 10:05;junrao;Ok, we can take v3 for now and track the broker startup/shutdown in kafka-328.;;;","08/Apr/12 10:00;nehanarkhede;Checked into trunk and 0.8 branch;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka-console-consumer.sh should not create zookeeper path when no brokers found and chroot was set in zookeeper.connect,KAFKA-2088,12787885,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,ransom,ransom,ransom,03/Apr/15 10:38,18/Apr/15 23:49,22/Mar/23 15:10,18/Apr/15 23:49,0.8.2.1,,,,,,0.9.0.0,,,,,,,clients,,,,0,,,,,,"1. set server.properties
server.properties:
zookeeper.connect = 192.168.0.10:2181,192.168.0.10:2181,192.168.0.10:2181/kafka

2 default zookeeepr path:
[zk: 192.168.0.10:2181(CONNECTED) 10] ls /
[zookeeper, kafka, storm]

3.start console consumer use a not exist topic and zookeeper address without chroot.
[root@stream client_0402]# kafka-console-consumer.sh --zookeeper 192.168.0.10:2181 --topic test --from-beginning
[2015-04-03 18:15:28,599] WARN [console-consumer-63060_stream-1428056127990-d35ca648], no brokers found when trying to rebalance. (kafka.consumer.ZookeeperConsumerConnector)


4.then ""/consumer"" and ""/brokers"" path was create in zookeeper.

[zk: 192.168.0.10:2181(CONNECTED) 2] ls /
[zookeeper, consumers, kafka, storm, brokers]

so it is a bug. consumer should not create ""/consumer"" and ""/brokers"" path .
",,gwenshap,junrao,ransom,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Apr/15 22:20;ransom;kafka-2088.1.patch;https://issues.apache.org/jira/secure/attachment/12724940/kafka-2088.1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Apr 18 15:49:40 UTC 2015,,,,,,,,,,"0|i27qjz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"13/Apr/15 22:24;ransom;https://reviews.apache.org/r/33132/diff/
please review it.;;;","17/Apr/15 23:25;gwenshap;Thanks for fixing this and for the friendly error message. The patch looks good to me.

I suspect that we have a similar issue with TopicCommand, if you have time, perhaps you can check it as well.;;;","18/Apr/15 00:09;ransom;[~gwenshap]
I have aleady test topic command in kafka 0.8.2.1 
./kafka-topics.sh --zookeeper 127.0.0.1:2181 --list
./kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe 
./kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe test
./kafka-topics.sh --zookeeper 127.0.0.1:2181 --create --topic test --partitions 1 --replication-factor 2
these all does not create path in zookeeper. they all looks good.
I does't found the same issues.;;;","18/Apr/15 01:47;gwenshap;Awesome, thanks for checking :);;;","18/Apr/15 01:48;gwenshap;Pinging [~junrao] [~jjkoshy] [~nehanarkhede] [~guozhang] for taking a look and perhaps committing :);;;","18/Apr/15 02:06;junrao;[~ransom], thanks for the patch. It may be reasonable to start a console consumer before the data is produced or even the Kafka cluster is started. It just won't get any data until the cluster is up and the data is produced. It's reasonable for the console consumer to create /consumer path. However, it probably shouldn't create /brokers, do you know what triggered this inside console consumer?;;;","18/Apr/15 03:21;gwenshap;I think the main problem here is that someone mistyping the zookeeper chroot path (or points a consumer at the wrong ZK) looks indistinguishable from someone starting a consumer before the cluster exists. The first is far more common though (at least in my experience), so it will be nice to warn the user that things are not  as he expected.;;;","18/Apr/15 11:11;ransom;[~junrao]
II have read codes but not found where to create these path in zookeeper.
So I add a check before kafka-console-consumer.sh start.;;;","18/Apr/15 23:49;junrao;Thanks for the explanation. That makes sense. +1 on the patch and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add acknowledgement to the produce request.,KAFKA-49,12514686,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,prashanth.menon,junrao,,20/Jul/11 05:32,02/May/13 10:29,22/Mar/23 15:10,29/May/12 02:02,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"Currently, the produce request doesn't get acknowledged. We need to have a broker send a response to the producer and have the producer wait for the response before sending the next request.",,craigwblake,felixgv,heavydawson,prashanth.menon,sharadag,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-50,,,,,,,,KAFKA-57,,,,KAFKA-305,,,,,,,,,KAFKA-73,KAFKA-240,,"05/Apr/12 08:50;prashanth.menon;KAFKA-49-continued-v2.patch;https://issues.apache.org/jira/secure/attachment/12521435/KAFKA-49-continued-v2.patch","30/Mar/12 01:54;prashanth.menon;KAFKA-49-continued.patch;https://issues.apache.org/jira/secure/attachment/12520461/KAFKA-49-continued.patch","07/Mar/12 11:35;prashanth.menon;KAFKA-49-v1.patch;https://issues.apache.org/jira/secure/attachment/12517358/KAFKA-49-v1.patch","13/Mar/12 08:57;prashanth.menon;KAFKA-49-v2.patch;https://issues.apache.org/jira/secure/attachment/12518130/KAFKA-49-v2.patch","14/Mar/12 09:17;prashanth.menon;KAFKA-49-v3.patch;https://issues.apache.org/jira/secure/attachment/12518276/KAFKA-49-v3.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,67068,,,Mon May 28 18:02:36 UTC 2012,,,,,,,,,,"0|i09m33:",54011,,,,,,,,,,,,,,,,,,,,"16/Nov/11 14:03;jkreps;If there are any other producer-related changes coming we should try to batch these together at the same time to avoid having to update clients too often.;;;","22/Nov/11 22:19;prashanth.menon;So I've started a little work on this.  Looks to me like the ProducerRequest is going to need an additional ""acknowledge"" boolean field (default false) which we send along with the rest of the fields.  On the producer side, there are a couple of options:

1. We can leave the producer API and have producers (both sync and async) acknowledge all or non of their messages.  This behaviour will be driven by a configuration field or a class parameter.
2. We add the acknowledgement parameter (default false) to the producer send API for and leave the remaining behaviour the same.  The producer then handles waiting or not waiting for acks on a per-message case.
 
I would prefer the second option as it's simple to do and gives the option to clients.  Waiting on the producing end shouldn't be an issue.  On the broker side, it becomes easy as we just send a boolean response after handling the request (ditto for the multi-produce request).  

Did anyone else have any thoughts on this?;;;","23/Nov/11 00:36;junrao;Prshanth, thanks for getting started on this. I agree with your second approach. Basically, add a new parameter in SyncProducer.send/multisend to indicate whether an ack is needed or not. The high level producer can then set that parameter based on ProducerConfig (probably true for sync mode and false for async mode). 

Another question is what kind of ack does the broker send back. A simple approach is to send back a boolean. Another possibility is to return for each partition in the produce request, the latest offset after the request is served. Some clients could potentially make use of the returned offset.;;;","23/Nov/11 01:05;tgautier;I second returning the new offset.;;;","23/Nov/11 01:36;jkreps;+1 for returning the offset

If we are changing the request format it would also be good to think it through in some detail to get it right since these kinds of API changes are harder to rollout then to make. Some questions:
1. Are we trying to maintain compatibility for this change? If so we should bump up the request id number and ignore the new fields for the old request id. This is not too hard, but requires a little extra work.
2. Currently we have ProduceRequest and MultiProducerRequest and FetchRequest and MultiFetchRequest. I recommend we rename MultiProducerRequest to ProduceRequest and delete the existing ProduceRequest. The current ProduceRequest has no advantages over MultiProducerRequest and having both means each change we make has to be done for both. The two variations are just there for historical reasons--originally there was no multi-* version of the requests and we added that later. I recommend we do the same for the FetchRequest/MultiFetchRequest. This will make our lives simpler going forward.
3. Both of the MultiProducerRequest has the format [(topic, partition, messages), (topic, partition, messages), ...]. This is because it is just a bunch of repeated ProducerRequests. This is really inefficient, though, as a common case is that we are producing a bunch of messages for different partitions under the same topic (i.e. if we are doing the key-based partitioning). It would be better for the format to be [(topic, [(partition, messages), ...], topic, [(partition, messages), ...], ...]. This would mean that each topic is only given once.

I would like to get a quick consensus on the desired format of the produce and fetch requests up front, then we can break this into appropriate sub tasks so we don't expand the scope of Prasanth's work too much.;;;","23/Nov/11 02:04;junrao;Both 2 and 3 make sense. 

If we do this in a bug fix release in 0.7, we probably need to maintain backward compatibility. If we do this as part of the replication work, we probably can make a non-backward compatible change. My preference is the latter.;;;","23/Nov/11 02:12;tgautier;Generally I think it's a good idea to have a version embedded into the protocol.  This allows for backwards and forwards compatibility.  In a sense, the request id works as such, so in some sense it's a matter of semantics, but the only way to identify that there are multiple versions of the same request is to have some kind of external mapping that says id 2 and id 8 are really the same request, just different versions.

OTOH, if you use a version, you can then have:

id 2 version 1
id 2 veriosn 2

etc. and this is imho easier to manage.

Usually, the version should in fact be the first value in the protocol, so that you never have formatting issues that lie outside the realm of the versioned data.

Currently, all requests are preceded by a header, which contains the length of the data.  This is where I would start, we should either strive for:

version: 2 bytes
length: 4 bytes

or 

length: 4 bytes
version: 2 bytes

Note that the message request already has a way to represent versions, using the magic field, but honestly I find it a little bit non explicit for my taste.

I would also include a 64-bit ""flags"" area that will allow for future flags to be set to indicate various things.

So, if I were to suggest a standard header for requests and responses it would look like:

length: 2 bytes
version: 2 bytes
reuest id: 2 bytes
flags: 4 bytes
payload: n bytes
;;;","23/Nov/11 02:14;tgautier;It could be possible to split the current request id - 2 bytes - into a version and an id field one byte long each.   Assuming there's not much need for a vocabulary greater than 256 verbs, and versions > 256, this would probably work within the current binary protocol and give backwards compatibility to 0.6 and 0.7 clients...;;;","23/Nov/11 02:38;jkreps;Hi Taylor, as you say the request id was meant to be the version. However in retrospect I do think I like the idea of separating the request and the version of the request. I agree it would be nice to split this.

I think the open question here is whether we should try to maintain backwards compatibility for the next major release. It would probably be very convenient for us at code-writing time not to, but is more painful at rollout time.;;;","23/Nov/11 03:01;tgautier;Well, how many versions do you think you want?  Maybe we could split the request field up into say the first 5 or 6 bits instead of 8 for the versions.;;;","23/Nov/11 13:09;jkreps;So guys, my thought is the best plan of attack would be fully think through the protocol changes for all the use cases we currently know about and do those all at once (even if the features the new fields support aren't yet available). This will avoid doing this in lots of little patches that all conflict, and it will make us think things through holistically.

I created a wiki with some of the outstanding ideas, I am going to move this discussion to the main dev and user lists to get broader feedback. It would be good if people could give their thoughts there so we can try to get these changes right.;;;","06/Jan/12 03:09;nehanarkhede;KAFKA-240 implements the new wire format for producer and consumer. Since this JIRA requires the new format, it depends on KAFKA-240;;;","02/Mar/12 06:33;nehanarkhede;KAFKA-239 is complete and KAFKA-240 is almost there. 

Prashanth, in your comment above, you've mentioned you've started work on this. If so, mind assigning this JIRA to yourself ? This looks like the next JIRA to work on after KAFKA-240 is in. (https://issues.apache.org/jira/browse/KAFKA-50?focusedCommentId=13180712&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13180712);;;","02/Mar/12 06:53;prashanth.menon;Sure, but I actually can't change assignments.  Could be a privileges issue?;;;","02/Mar/12 07:56;nehanarkhede;Looks like you didn't exist in the Apache Kafka JIRA list. Added you there, also assigned this JIRA to you;;;","05/Mar/12 11:51;prashanth.menon;Hey all.  Getting the acknowledgements done was fairly straightforward - I've ""todo-ed"" actually waiting for replica acknowledgements as part of kafka-44 when it introduces true replicas and partitions.  Having the sync producer wait for a response when it requires acknowledgements was trivial.  My question is what to do with the async producer.  Was the intent to perform some logic in the default event handler, or to expect clients to write custom event handlers that deal errors?  Should we bubble up the response to the producer level?;;;","06/Mar/12 06:43;junrao;Prashanth,

That's a good question. Initially, I was just thinking that for async producers, if we get an error during send (after retries), we will just log the error without telling the client. Currently, the event handler is not really extensible. I can image that we add some kind of callback to return those errors. The question is what will the client do on those errors. Will it resend? If so, we will need to pass the failed requests through callback too. I am curious about how other messaging systems like activeMQ do in the async mode.;;;","06/Mar/12 07:20;prashanth.menon;If I remember right, HornetQ allows  you to implement a callback interface to be notified of message acknowledgments.  We could do something similar, passing back the request and response for the erroneous parts.  To your second point, I suppose it depends on the error.  Some may be logged and skipped, some will require a refresh of topic metadata .  The default behaviour should cover the base cases.

Curious to hear other thoughts;;;","06/Mar/12 07:33;junrao;The current defaulteventhandler already refreshes topic metadata on retries. So, if we return any failed request to the client, there is probably not much the client can do, except for logging it. In any case, we should use a separate jira to track if we need any aysnc callback on the producer side.;;;","06/Mar/12 11:39;prashanth.menon;Sounds good to me.  Doing some additional work on DefaultEventHandler, I noticed something off in the retry logic that I'd like to get confirmed.  Consider the case where I've got data destined for more than one broker, say three.  
- Enter handleSerializedData()
  - Partioning and collating makes a map with three key/value pairs (broker -> topic partition data and messages).  
  - Enter for loop
    - Assume the first send works on the first try for broker #1.  
    - Next iteration, the second send to broker #2 fails on the first try, we fall into the retry loop and recursive into handleSerializedData with requiredRetries = 0.
      - In handleSerializedData
      - This time, the partitioned data will one one key/value pair for the single broker (broker #2) we're attempting to resend data to.  
      - Enter for loop
        - Attempt to send data to broker #2, the send succeeds
      - We exhaust the map entries and the for loop condition.
    - We return to the retry loop for retry=1 on broker #2 in the catch block.  
    - The previous send succeeded on first try and now there's the ""return"" statement.  This exists the function, but we have one more broker (broker #3) to send data to.

Does the flow sound about right?  I think what needs to happen is to set a flag and break the retry while loop after a successful retry.  Then we check the flag after the loop and either throw the exception or continue the outer for loop.

Am I crazy?  Am I missing something in my sleep-deprived state here?;;;","07/Mar/12 00:45;junrao;Prashanth,

Yes, that's actually a real bug. Instead of returning in retry, we should just set a boolean to indicate that a send has succeeded. At the end, we will throw FailedToSendMessageException if the boolean is not set. Otherwise, we will continue with the for loop. Could you file a separate jira to fix that? Thanks for catching the bug.;;;","07/Mar/12 04:12;prashanth.menon;Done, created KAFKA-295.  Expect patch for this jira later tonight.;;;","07/Mar/12 11:42;prashanth.menon;I've attached a patch for this.  A few comments:

- Modified ProducerResponse
- Broker does not actually wait for replica ACKS.  This will be done with KAFKA-44.
- Sync producer has been modified to wait for response from broker.  Async producer isn't aware of request level errors, this will require a separate ticket.
- Some general cleanup on producer request, async producer and removal of MultiProduce request key.

One oddity is since we use Arrays in the request and response, it breaks the case class equality/hashcode logic since Java's arrays are broken.  We should probably make them Seq's (separate JIRA?) or WrappedArrays.
;;;","09/Mar/12 01:25;junrao;Prashanth,

Thanks for the patch. Overall, it looks pretty good. Some comments:
1. KafkaApis: Even when the produce request requires no ack, we will still need to send error code back. So we should always send a ProduceResponse. When no ack is specified, we probably don't need to send offsets back.
2. ProduceRequest.getNumMessages: rename it to something like getNumTopicPartitions
3. AsyncProducerTeest.testDefaultHanlderRetryLogic: doesn't really test retry
4. SyncProducerTest.testProduceBlocksWhenRequired: Use createTopic instead of creating ZK path directly.
5. I agree that it's probably better to use Seq in our requests/response, instead of Array. Then we need a java version to convert Seq to java array and vice versa. Please open a separate jira to track this.
;;;","09/Mar/12 10:50;prashanth.menon;Thanks for the pointers!  

1.  Hmmm, do you propose returning an empty offsets array back to the client when no ack is required?  That seems perfectly reasonable since the broker can't make guarantees as to the offsets; but it  does feel somehow incongrous since one would expect the errors and offsets array sizes to be equal.  I'm fine with the idea as long as it's agreed in the wire format.  If I've completely missed the point, forgive me!
2.  Done.
3.  Done.  Wow, that wasn't supposed to be included.  It was part of my sanity check for the incorrect retry logic I mentioned earlier.
4.  Done.
5.  Done.;;;","09/Mar/12 13:03;junrao;1. Or we can just treat noacks the same as act=1 for now.;;;","12/Mar/12 08:18;prashanth.menon;A few more concerns popped up as a result of making the send in syncproducer blocking.  

1. Edit: So it turns out that using the channel in SyncProducer like we are to perform reads won't trigger socket timeouts though we set it and will block forever which is bad news(check http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4614802 and http://stackoverflow.com/questions/2866557/timeout-for-socketchannel for workaround).  The latter post has a simple solution that involves creating a separate ReadableByteChannel instance for timeout-enabled reads.  The other option being using non-blocking sockets with selectors which is more complex.
2.  It is conceivable that a broker listed in the replica set /brokers/topics/[topic]/partitions/[partition]/replicas is offline or shutdown which means their ephemeral entries are missing in ZK.  A problem then arises when an active broker attempts to pull metadata and node information for topics these brokers host since AdminUtils assumes any broker in AR or ISR must have paths/info in ZK /brokers/ids/[brokerId], but since they don't an NoNodeException is thrown.  A corner case for sure, but something that should probably be fixed.;;;","13/Mar/12 09:01;prashanth.menon;I've attached an updated patch.  

1. ProduceRequest always receives a ProducerResponse.  If acks=0, offsets in the response are treated as if acks=1, meaning only the leader has acked.
2. SyncProducer blocks waiting for a response from a ProducerRequest.
3. I've commented out ProducerTest.testZKSendWithDeadBroker since it relies on SyncProducer logic that will need to change.  It also will need to be rewritten with the changes coming in as part of KAFKA-45 leader election logic.

Let me know if I've missed anything!
;;;","14/Mar/12 08:33;junrao;Prashanth,

I am ready to commit your patch. A couple things:

1. Your patch added a new class ResponseHandler, but it's not used. Should that be removed?
2. Your concern #1 is valid. Could you create another jira to track this?
3. For your concern #2, it's ok for getMetadataApi to return empty leader in a transition state. The client will simply backoff a bit and call getMetadataApi again.;;;","14/Mar/12 09:26;prashanth.menon;Hi Jun, I've attached a new patch.

1. Yes, I've removed it.
2. Done.
3. You are correct in the case of leaders, but I believe the problem stands when pulling topic metadata with atleast one offline broker listed in the assigned replicas.

;;;","14/Mar/12 09:38;junrao;Thanks for the patch Prashanth. Just committed to 0.7 branch.

For 3, if a broker is offline, then eventually it will not be in ISR. In the transition state, we could have an ISR broker without matching host and port.;;;","15/Mar/12 13:24;nehanarkhede;Sorry for visiting this late. I have a few questions about producer ACK. 

1. In DefaultEventHandler, the producer ACK is not used. Shouldn't it be used to figure out if the send operation needs to be retried ? 
2. In DefaultEventHandler, should the producer wait for ACK and timeout if it doesn't receive one ?
3. In KafkaApis, why doesn't the broker send an error back to the producer if it received a producer request for a partition that is not hosted on that broker ?;;;","15/Mar/12 21:21;prashanth.menon;Better late than never.  A second review is always a plus!  To your points:

1. Absolutely, this was overlooked.  Expect patch later tonight or tomorrow.
2. The DefaultEventHandler does wait for the ack by waiting for the response.  Unfortunately, the current SyncProduer doesn't timeout correctly for which KAFKA-305 was created.
3. KafkaApis does not explicitly do the check, instead relying on LogManager which currently does.  It makes sense to move that piece of logic along with the TODO from LogManager into KafkaApis for clarity and to separate ZK from LogManager.

What do you think?;;;","16/Mar/12 05:57;nehanarkhede;1. I'm refactoring some part of DefaultEventHandler as part of KAFKA-300. I'll upload a patch tonight. You can either choose to work off of the changed code or not. Your call.
2. Sounds good
3. In handleProduceRequest, the logManager.append() throws InvalidPartitionException when it receives a request for a partition that it does not own. Does it make sense to send an ACK to the producer with an error code like  NotLeaderForPartitionException ?

;;;","17/Mar/12 01:16;nehanarkhede;Reopening this issue to address some review suggestions and to fix KAFKA-305 as part of this JIRA;;;","29/Mar/12 00:22;nehanarkhede;Prashanth, thanks for resolving KAFKA-305 ! Would you be up for finishing up the remaining work on this ? It seems like a good idea to complete earlier JIRAs, before moving to the later ones.;;;","30/Mar/12 01:54;prashanth.menon;Okay, I've attached a patch that should take care of the outstanding items.  A couple of points:

1. KafkaApis not checks whether a partition has a leader on the broker.  It uses KafkaZooKeeper to check this, for now, but should probably rely on ReplicaManager and the Replica itself to determine this.  KAFKA-46 should take care of this.
2. I've removed the random partition check on the server-side since the partitioning is done in default event handler.  Producers should know which broker a partition belongs to.
3. I've added a new NotLeaderForPartitionException and added it to ErrorMapping so clients can receive it.
4. DefaultEventHandler.send now returns a list of topic/partition tuples that represents those messages that need to be resent due to an error.
5. Due to the changes in KafkaApis produce check, some of the tests have been modified to ensure topics are in ZK and to wait for leadership.

I think that covers all, please point out any issues!;;;","30/Mar/12 07:03;nehanarkhede;+1. Thanks for incorporating the review suggestions !;;;","04/Apr/12 02:25;junrao;Prashanth,

Patch looks good: Just one minor thing.

6. Unused imports: KafkaZookeeper

While looking at the patch, I realized that there are a couple of other things that we will need to follow up.

a. In DefaultEventHandler, it seems that we rely on the fact that broker.id is a non-negative integer. However, we don't enforce that in broker startup.
b. With the create topic ddl, some of the broker configs like topic.partition.count.map probably don't make sense anymore.

I will create a jira for each item to follow up.;;;","05/Apr/12 08:50;prashanth.menon;Thanks for the review!  I've attached newest patch for #6 resolved.;;;","06/Apr/12 02:17;junrao;Prashanth,

Thanks for the patch. It seems that kafka-48 is almost ready. Since that's a relatively large patch, I will commit your patch after kafka-48 is committed.;;;","08/May/12 05:45;junrao;Prashanth,

Now that kafka-48 is committed to 0.8, we can commit your patch. Since you are a committer now, could you commit this yourself?;;;","24/May/12 10:20;prashanth.menon;Sorry for the delay everyone.  I'm planning to block off some time this weekend to commit this patch, and hoping I don't run into any access/permissions issues :);;;","29/May/12 02:02;prashanth.menon;Excellent, committed this to 0.8.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Client: Infinite ""conflict in /consumers/""",KAFKA-1585,12733091,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,,adenysenko,adenysenko,10/Aug/14 14:57,05/Sep/14 05:59,22/Mar/23 15:10,05/Sep/14 05:59,0.8.1.1,,,,,,0.8.2.0,,,,,,,consumer,,,,0,,,,,,"Periodically we have kafka consumers cycling in ""conflict in /consumers/"" and ""I wrote this conflicted ephemeral node"". 
Please see attached log extract.
After restarting the process kafka consumers are working perfectly. 

We are using Zookeeper 3.4.5


",,adenysenko,guozhang,joestein,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1451,,,,,,,,,,"10/Aug/14 14:58;adenysenko;kafka_consumer_ephemeral_node_extract.zip;https://issues.apache.org/jira/secure/attachment/12660842/kafka_consumer_ephemeral_node_extract.zip",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,411119,,,Thu Sep 04 21:59:00 UTC 2014,,,,,,,,,,"0|i1yqav:",411111,,,,,,,,,,,,,,,,,,,,"10/Aug/14 16:04;joestein;FWIW there were a lot of bug fixes released in the Zookeeper 3.4.6 http://zookeeper.apache.org/doc/r3.4.6/releasenotes.html from 3.4.5 version.

You could be hitting ZOOKEEPER-1382 which was fixed in the 3.4.6 release

Current Kafka 0.8.1.1 zookeeper recommend https://kafka.apache.org/documentation.html#zk though folks are using 3.4.6 in production and that should be Zookeeper version for 0.8.2

In regards to your logs, before this happened it looks like you had errors and then a reconnect and consumer shutdown

Line 132356: 18:31:38,948 [7-cloudera:2181] INFO  kafka.utils.Logging$class - [Q_dev-1407608193903-1cb30b18], Q_dev-1407608193903-1cb30b18-0 attempting to claim partition 0
Line 132357: 18:31:38,975 [26-d7f0e66a-0-0] ERROR kafka.utils.Logging$class - [ConsumerFetcherThread-Q_dev-1407608195226-d7f0e66a-0-0], Current offset 15 for partition [gk.q.event,0] out of range; reset offset to 0
Line 132358: 18:31:38,980 [62-1d81f64b-0-0] ERROR kafka.utils.Logging$class - [ConsumerFetcherThread-Q_dev-1407608193962-1d81f64b-0-0], Current offset 4 for partition [gk.q.mail.api,0] out of range; reset offset to 0
Line 132359: 18:31:38,994 [84-ceea5788-0-0] WARN  kafka.utils.Logging$class - Reconnect due to socket error: null
Line 132360: 18:31:38,995 [84-ceea5788-0-0] INFO  kafka.utils.Logging$class - [ConsumerFetcherThread-dev_dev-1407608194884-ceea5788-0-0], Stopped 
Line 132361: 18:31:38,995 [atcher_executor] INFO  kafka.utils.Logging$class - [ConsumerFetcherThread-dev_dev-1407608194884-ceea5788-0-0], Shutdown completed
Line 132362: 18:31:38,995 [atcher_executor] INFO  kafka.utils.Logging$class - [ConsumerFetcherManager-1407608194890] All connections stopped
Line 132363: 18:31:38,996 [atcher_executor] INFO  kafka.utils.Logging$class - [dev_dev-1407608194884-ceea5788], Cleared all relevant queues for this fetcher
Line 132364: 18:31:38,996 [atcher_executor] INFO  kafka.utils.Logging$class - [dev_dev-1407608194884-ceea5788], Cleared the data chunks in all the consumer message iterators
Line 132365: 18:31:38,996 [atcher_executor] INFO  kafka.utils.Logging$class - [dev_dev-1407608194884-ceea5788], Committing all offsets after clearing the fetcher queues
Line 132366: 18:31:38,996 [atcher_executor] INFO  kafka.utils.Logging$class - [dev_dev-1407608194884-ceea5788], Releasing partition ownership
Line 132367: 18:31:39,005 [7-cloudera:2181] INFO  kafka.utils.Logging$class - conflict in /consumers/Q/owners/gk.q.log/0 data: Q_dev-1407608193903-1cb30b18-0 stored data: Q_dev-1407608205503-9cfb99aa-0

likely what happened is when it reconnected the timeout with zk never occurred and it got stuck there.  Could be the Zk bug, could also be related somewhat to KAFKA-1387 or KAFKA-1451 I will link the JIRAs so when we test 0.8.2 see about reproducing this on a good zk version

To resolve that you can stop the consumer, wait for the zk nodes to expire and start up the consumers again.

;;;","11/Aug/14 05:21;adenysenko;I've tried with Zookeeper 3.4.6 - same problem.

KAFKA-1029 have some comments related to ""consumers"" as well: https://issues.apache.org/jira/browse/KAFKA-1029?focusedCommentId=13944775;;;","05/Sep/14 05:59;guozhang;I think this issue is already resolved by KAFKA-1451. Please re-open it with 0.9.0 version if you still see it.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Empty log index file created when it shouldn't be empty,KAFKA-593,12613975,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,yeyangever,yeyangever,30/Oct/12 08:07,06/Nov/12 11:44,22/Mar/23 15:10,06/Nov/12 11:44,,,,,,,,,,,,,,,,,,0,,,,,,"We have met empty index file during system test when it shouldn't be empty. In this case, there're around 100 messages in each segment, each of size around 100 bytes, given the ""logIndexIntervalBytes"" 4096, there should be at least 2 log index entries, but we see empty index file. The kafka and zookeeper logs are attached



[yye@yye-ld kafka_server_3_logs]$ cd test_1-2/
[yye@yye-ld test_1-2]$ ls -l
total 84
-rw-r--r-- 1 yye eng        8 Oct 29 15:22 00000000000000000000.index
-rw-r--r-- 1 yye eng    10248 Oct 29 15:22 00000000000000000000.log
-rw-r--r-- 1 yye eng        8 Oct 29 15:22 00000000000000000100.index
-rw-r--r-- 1 yye eng    10296 Oct 29 15:22 00000000000000000100.log
-rw-r--r-- 1 yye eng        0 Oct 29 15:23 00000000000000000200.index
-rw-r--r-- 1 yye eng    10293 Oct 29 15:23 00000000000000000200.log
-rw-r--r-- 1 yye eng        0 Oct 29 15:23 00000000000000000300.index
-rw-r--r-- 1 yye eng    10274 Oct 29 15:23 00000000000000000300.log
-rw-r--r-- 1 yye eng        0 Oct 29 15:23 00000000000000000399.index
-rw-r--r-- 1 yye eng    10276 Oct 29 15:23 00000000000000000399.log
-rw-r--r-- 1 yye eng        0 Oct 29 15:23 00000000000000000498.index
-rw-r--r-- 1 yye eng    10256 Oct 29 15:23 00000000000000000498.log
-rw-r--r-- 1 yye eng 10485760 Oct 29 15:23 00000000000000000596.index
-rw-r--r-- 1 yye eng     3564 Oct 29 15:23 00000000000000000596.log
",,jkreps,junrao,nehanarkhede,yeyangever,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-583,,,,,,,,,,,,,,,,,,,,,,,,"30/Oct/12 08:08;yeyangever;kafka_583_zk_kafka_data.tar.gz;https://issues.apache.org/jira/secure/attachment/12551284/kafka_583_zk_kafka_data.tar.gz","02/Nov/12 10:48;yeyangever;kafka_593_v1.diff;https://issues.apache.org/jira/secure/attachment/12551812/kafka_593_v1.diff","03/Nov/12 07:41;yeyangever;kafka_593_v2.diff;https://issues.apache.org/jira/secure/attachment/12551947/kafka_593_v2.diff","03/Nov/12 09:02;yeyangever;kafka_593_v3.diff;https://issues.apache.org/jira/secure/attachment/12551957/kafka_593_v3.diff","06/Nov/12 03:47;yeyangever;kafka_593_v4.diff;https://issues.apache.org/jira/secure/attachment/12552150/kafka_593_v4.diff","06/Nov/12 08:08;yeyangever;kafka_593_v5.diff;https://issues.apache.org/jira/secure/attachment/12552187/kafka_593_v5.diff",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,252903,,,Tue Nov 06 03:44:23 UTC 2012,,,,,,,,,,"0|i0da87:",75586,,,,,,,,,,,,,,,,,,,,"30/Oct/12 11:59;jkreps;I am not sure that this is a bug. The index entries are not placed at exact intervals. Rather, we add a single index entry per append if the bytesSinceLastIndexEntry > indexIntervalBytes. What this means is that you could get a log of 10,296 bytes by appending a single message set of that size or by appending one message set <= 4095 and then another that made up the difference.

What was batch size being used in this test?;;;","31/Oct/12 00:28;junrao;Producer used sync mode. So, there is 1 message per batch and each segment has about 100 messages. I expect at least 2 index entries being added per segment.;;;","31/Oct/12 23:12;junrao;Here is the issue. We rolled a new segment in the follower. The follower in one fetch gets 10k bytes of data and appends to its log. This won't add any index entry since it's the very first append to this segment. After the append, the log rolled since the max segment size is reached. This leaves an empty index.

Technically, the logic is still correct. It does mean that index entries may not be generated as frequently as one expects, depending on the fetch size used in the follower fetcher thread and how far behind a follower is. This may impact consumer performance a bit.;;;","31/Oct/12 23:46;jkreps;Makes sense, clever. I thought a bit about this during the implementation and decided not to try to make the index entries exact just to reduce complexity. It would be possible to be more exact by having LogSegment calculate inter-messageset positions and append multiple entries to the index if necessary. This would not necessarily be a bad change, but there is definitely some complexity, especially in the face of truncation, so this would need pretty thorough testing.;;;","31/Oct/12 23:47;jkreps;Err, that should read ""intra-messageset positions"".;;;","02/Nov/12 10:48;yeyangever;
Basically the problem was during restarting the server and truncation from existing log and index files. 

When after the restart or truncation the existing index file is empty (so it's always full), one of the conditions of maybeRoll() will be true, so a new log segment will be rolled ---- we will end up with two log segments starting from the same offset, one of them is empty.

To fix it, we change the function trimToSize() in OffsetIndex to trimOrReallocate(), it does either trimming or reallocating the offset index file (and memory mapping). At truncation or restart, it will do reallocation, so that enough space for offset index is allocated.

We also check existing log segments at roll() function, and throws exception if some segment exists with the same offset as the target offset. (This should not happen)

;;;","02/Nov/12 12:51;junrao;Thanks for the patch. A couple of comments:

1. Log.rollToOffset(): We just need to verify that the starting offset of the last segment doesn't equal to the new offset.

2. OffsetIndex: When loading the log segment on broker startup, it is possible to have a segment with empty data and empty index. So, we will hit the same issue of rolling a segment with a duplicated name. We probably should extend the index size to max index size in the constructor of OffsetIndex.;;;","02/Nov/12 23:50;jkreps;trimOrReallocate(isReallocate: Boolean)  is a bit of a hacky interface. This supports resizing to two sizes: entries or maxSize, but it would be better to just implement the more general
  resize(numEntries: Int)
numEntries is the mmap.limit/8. It might be nice to leave the helper method trimToSize as a less error prone alias
  def trimToSize() = resize(entries)
If we do this we should be able to use resize to implement OffsetIndex.truncateTo (the difference between truncateTo and resize is that truncateTo is in terms of offset whereas resize is in terms of entries).

We should also add a test case to cover these corner cases.

;;;","03/Nov/12 07:41;yeyangever;
Jay, Jun,

Thanks for the comments.

Jun also pointed out that there may still be cases where at startup, the last log segment has empty index and empty log file ---- and the trimOrReallocate() is not called because it was a clean shutdown before. 

What about an alternative idea, which is, whenever we load a log segment, we always make sure its offset index has enough disk space and memory. In this case, when we truncate back to old segment, its index will not be full, when we start the last log segment with empty log file and index file, its index will also not be full. 

To do this, we just need to change the constructor of OffsetIndex, by always set the index file size and mmap limit to maxIndexSize.
;;;","03/Nov/12 09:02;yeyangever;

Thanks for the discussions, and here's the third patch which is also verified to be working.;;;","06/Nov/12 01:54;junrao;Thanks for patch v3. Looks good. Some minor comments.

30. Log.rollToOffset():  segmentsView.last.index.file.getName.split(""\\."")(0).toLong can just be segmentsView.last.start.

31. Log.loadSegments(): Just to be consistent. Should we use index.maxIndexSize instead of maxIndexSize in the following statement?
      logSegments.get(logSegments.size() - 1).index.resetSizeTo(maxIndexSize)
;;;","06/Nov/12 03:40;yeyangever;
For 30,
It's fixed

For 31,
It seems simpler to keep as it is


Jay, can you help have a look at this patch?;;;","06/Nov/12 03:53;jkreps;Looks good, two minor things:
1. Can we name resetSize to resize?
2. Can we change the argument to be in terms of number of entries rather than number of bytes? It is incorrect to set to a number of bytes that is not a multiple of the entry size and the entry size is kind of an implementation detail of that class so this would be nicer.
3. Can we add a test for this case?;;;","06/Nov/12 05:54;jkreps;Discussed with Victor. (1) and (3) should be doable, but (2) is not very convenient because the usage actually resizes to indexMaxSize which is in terms of bytes. So our solution was to have the API take bytes and just round to a multiple of 8.;;;","06/Nov/12 08:08;yeyangever;
Thanks for the comments, changes in v5:

1. rename resetSize() to resize()
2. add using roundToMultiple() in resize()
3. add comments to resize()
4. add one unit test ""testIndexResizingAtTruncation"" in LogTest for this case;;;","06/Nov/12 08:20;jkreps;+1;;;","06/Nov/12 11:44;nehanarkhede;+1 on v5. Committed this patch;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ServerShutdownTest fails in trunk.,KAFKA-1815,12760475,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,fanatoly,fanatoly,fanatoly,10/Dec/14 00:44,14/Dec/14 00:10,22/Mar/23 15:10,13/Dec/14 03:39,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"I ran into these failures consistently when trying to build Kafka locally:

kafka.server.ServerShutdownTest > testCleanShutdown FAILED
    java.lang.NullPointerException
        at kafka.server.ServerShutdownTest$$anonfun$verifyNonDaemonThreadsStatus$2.apply(ServerShutdownTest.scala:147)
        at kafka.server.ServerShutdownTest$$anonfun$verifyNonDaemonThreadsStatus$2.apply(ServerShutdownTest.scala:147)
        at scala.collection.TraversableOnce$$anonfun$count$1.apply(TraversableOnce.scala:114)
        at scala.collection.TraversableOnce$$anonfun$count$1.apply(TraversableOnce.scala:113)
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
        at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:105)
        at scala.collection.TraversableOnce$class.count(TraversableOnce.scala:113)
        at scala.collection.mutable.ArrayOps$ofRef.count(ArrayOps.scala:105)
        at kafka.server.ServerShutdownTest.verifyNonDaemonThreadsStatus(ServerShutdownTest.scala:147)
        at kafka.server.ServerShutdownTest.testCleanShutdown(ServerShutdownTest.scala:101)

kafka.server.ServerShutdownTest > testCleanShutdownWithDeleteTopicEnabled FAILED
    java.lang.NullPointerException
        at kafka.server.ServerShutdownTest$$anonfun$verifyNonDaemonThreadsStatus$2.apply(ServerShutdownTest.scala:147)
        at kafka.server.ServerShutdownTest$$anonfun$verifyNonDaemonThreadsStatus$2.apply(ServerShutdownTest.scala:147)
        at scala.collection.TraversableOnce$$anonfun$count$1.apply(TraversableOnce.scala:114)
        at scala.collection.TraversableOnce$$anonfun$count$1.apply(TraversableOnce.scala:113)
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
        at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:105)
        at scala.collection.TraversableOnce$class.count(TraversableOnce.scala:113)
        at scala.collection.mutable.ArrayOps$ofRef.count(ArrayOps.scala:105)
        at kafka.server.ServerShutdownTest.verifyNonDaemonThreadsStatus(ServerShutdownTest.scala:147)
        at kafka.server.ServerShutdownTest.testCleanShutdownWithDeleteTopicEnabled(ServerShutdownTest.scala:114)

kafka.server.ServerShutdownTest > testCleanShutdownAfterFailedStartup FAILED
    java.lang.NullPointerException
        at kafka.server.ServerShutdownTest$$anonfun$verifyNonDaemonThreadsStatus$2.apply(ServerShutdownTest.scala:147)
        at kafka.server.ServerShutdownTest$$anonfun$verifyNonDaemonThreadsStatus$2.apply(ServerShutdownTest.scala:147)
        at scala.collection.TraversableOnce$$anonfun$count$1.apply(TraversableOnce.scala:114)
        at scala.collection.TraversableOnce$$anonfun$count$1.apply(TraversableOnce.scala:113)
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
        at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:105)
        at scala.collection.TraversableOnce$class.count(TraversableOnce.scala:113)
        at scala.collection.mutable.ArrayOps$ofRef.count(ArrayOps.scala:105)
        at kafka.server.ServerShutdownTest.verifyNonDaemonThreadsStatus(ServerShutdownTest.scala:147)
        at kafka.server.ServerShutdownTest.testCleanShutdownAfterFailedStartup(ServerShutdownTest.scala:141)

It looks like Jenkins also had issues with these tests:

https://builds.apache.org/job/Kafka-trunk/351/console

I would like to provide a patch that fixes this.",,copester,fanatoly,joestein,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Dec/14 00:45;fanatoly;shutdown_test_fix.patch;https://issues.apache.org/jira/secure/attachment/12686031/shutdown_test_fix.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Dec 13 16:10:30 UTC 2014,,,,,,,,,,"0|i238e7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"11/Dec/14 02:02;copester;Dear Committers, I have verified that shutdown_test_fix.patch does indeed fix the test failures in trunk. Please apply.

Cheers!;;;","12/Dec/14 23:56;copester;Unexpectedly, this was fixed by https://github.com/apache/kafka/commit/e8ffbd0fee0bc715ad0fe6c9afe85715f84d8e51 that [~joestein] committed to fix KAFKA-1812. I'm looking through his commit and don't see why it would fix this bug, but the test results don't lie.;;;","13/Dec/14 00:10;joestein;CI says it is still broken https://builds.apache.org/view/All/job/Kafka-trunk/ and it was broken for me when I did that commit... I didn't see this ticket until just now will look through it later when I have some time towards fixing this, I mentioned KAFKA-1650 about it also;;;","13/Dec/14 00:20;copester;I spoke too soon. I'm now getting different test results after running this a bunch of times on our test farm. Sometimes the 3 tests on this ticket fail. Sometimes testMetricsLeak fails. Sometimes all 4 fail together.;;;","13/Dec/14 03:39;junrao;Thanks for the patch. +1 and committed to trunk.;;;","13/Dec/14 10:17;copester;Thanks, [~junrao], though that was actually [~fanatoly]'s patch. In terms of current state of tests passing since the latest commit 523b36589e942cb99a95debd2c45e795ae533d08 for KAFKA-1813, and I'm seeing consistent passing of all the tests except for the occasional KAFKA-1501 failures which continue to haunt me. Thanks!;;;","14/Dec/14 00:10;junrao;Thanks, updated the assignee to Anatoly.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KafkaHealthCheck kills the JVM in handleSessionEstablishmentError,KAFKA-2405,12851526,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jaikiran,jaikiran,jaikiran,05/Aug/15 06:34,20/Jun/17 05:23,22/Mar/23 15:10,05/Aug/15 08:11,,,,,,,0.9.0.0,,,,,,,core,,,,0,,,,,,"The current code in KafkaHealthCheck in trunk does this:

{code}
override def handleSessionEstablishmentError(error: Throwable): Unit = {
      fatal(""Could not establish session with zookeeper"", error)
      System.exit(-1)
    }
{code}

thus terminating the JVM. A session establishment error shouldn't cause the JVM to terminate.",,githubbot,gwenshap,ijuma,jaikiran,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jun 19 21:23:44 UTC 2017,,,,,,,,,,"0|i2ic5z:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"05/Aug/15 06:39;githubbot;GitHub user jaikiran opened a pull request:

    https://github.com/apache/kafka/pull/111

    KAFKA-2405 Don't kill the JVM on session establishment failure

    As noted in the JIRA https://issues.apache.org/jira/browse/KAFKA-2405 currently the KafkaHealthCheck causes the JVM to terminate in cases where session establishment with Zookeeper fails. I don't know if retrying (after a while) is a better way to fix this but at least, IMO, the session establishment failure shouldn't kill the JVM. This commit removes the `System.exit()` call.


You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/jaikiran/kafka kafka-2405

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/111.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #111
    
----
commit f809162fcaf6cba9eddbc33dd4349ea453a1d8d8
Author: Jaikiran Pai <jaikiran.pai@gmail.com>
Date:   2015-08-04T22:36:40Z

    KAFKA-2405 Don't kill the JVM on session establishment failure

----
;;;","05/Aug/15 06:39;jaikiran;Pull request sent https://github.com/apache/kafka/pull/111
;;;","05/Aug/15 08:10;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/111
;;;","05/Aug/15 22:27;ijuma;We have 43 instances of `System.exit` in `core` and a few instances of `Runtime.halt`. Is there a document explaining when it's OK to exit and when it is not?;;;","06/Aug/15 00:56;gwenshap;It is supported to create KafkaServer by instantiating the class directly (without going though Kafka.main). We use it in our tests (I think), and sounds like LinkedIn uses this in production.

So System.exit of anything below this level sounds like a problem.;;;","20/Jun/17 05:23;junrao;Just realized this change. This seems to cause the ZK session expiration handling to be worse than before. Filed https://issues.apache.org/jira/browse/KAFKA-5473 to address this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Messages sometimes not delivered by new consumer after Kafka restart ,KAFKA-2877,12915592,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,hachikuji,rsivaram,rsivaram,24/Nov/15 05:33,25/May/16 00:46,22/Mar/23 15:10,25/Nov/15 08:18,0.9.0.0,,,,,,0.9.0.1,,,,,,,consumer,,,,0,,,,,,"After a Kafka restart, our health check consumer which subscribes to five topics with one partition each, was receiving messages from four out of the five topics. This has happened twice, the second time today was on 0.9.0.0 RC3. 

Some of the system test failures in http://jenkins.confluent.io/job/kafka_system_tests_branch_builder/220/ when the replication test was modified to use SSL/SASL clients and the throughput of the producer was reduced, also show a similar problem. Many of the replication tests  fail intermittently when new consumer is used in order to run clients with SSL/SASL. 
",,githubbot,guozhang,hachikuji,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Nov 25 00:18:08 UTC 2015,,,,,,,,,,"0|i2otyn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"25/Nov/15 03:53;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/582

    KAFKA-2877: handle request timeout in sync group

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-2877

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/582.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #582
    
----
commit de0ce834b66939f2b901397e489e7bd1d72cec3e
Author: Jason Gustafson <jason@confluent.io>
Date:   2015-11-24T19:52:02Z

    KAFKA-2877: handle request timeout in sync group

----
;;;","25/Nov/15 03:56;hachikuji;It looks like when we updated the new consumer for persistence in KAFKA-2017, we forgot to add handling for the request timeout error code. This code is possible when group metadata is written to the log if the write timeout expires before enough replicas have acknowledged it. I've added a simple patch which checks for this error.;;;","25/Nov/15 08:17;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/582
;;;","25/Nov/15 08:18;guozhang;Issue resolved by pull request 582
[https://github.com/apache/kafka/pull/582];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka-run-class.sh should use reasonable gc settings,KAFKA-718,12628759,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,jkreps,jkreps,23/Jan/13 02:40,06/Aug/13 01:16,22/Mar/23 15:10,06/Aug/13 01:16,,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"Our start script seems to use the default ""stop the world"" collector. It would be good to default to well tuned gc settings including gc logging, CMS, etc. Whatever we are using in prod and perf lab...

Many people who want to use kafka basically don't know java well so they won't succeed in figuring this stuff out on their own and just think it is broken and timing out if we don't have good defaults.",,ashwanthfernando@gmail.com,jkreps,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jul/13 08:22;ashwanthfernando@gmail.com;718-v1.patch;https://issues.apache.org/jira/secure/attachment/12591330/718-v1.patch","12/Jul/13 05:28;jkreps;KAFKA-718-v2.patch;https://issues.apache.org/jira/secure/attachment/12591911/KAFKA-718-v2.patch","12/Jul/13 07:32;jkreps;KAFKA-718-v3.patch;https://issues.apache.org/jira/secure/attachment/12591933/KAFKA-718-v3.patch","04/Aug/13 01:47;jkreps;KAFKA-718-v4.patch;https://issues.apache.org/jira/secure/attachment/12595759/KAFKA-718-v4.patch","05/Aug/13 05:33;jkreps;KAFKA-718-v5.patch;https://issues.apache.org/jira/secure/attachment/12595831/KAFKA-718-v5.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,308237,,,Mon Aug 05 17:16:53 UTC 2013,,,,,,,,,,"0|i1b17j:",272494,,,,,,,,,,,,,,,,,,,,"03/Jul/13 12:08;ashwanthfernando@gmail.com;Hi, This bug seems to be open for a long time. I can take this up if its not been paid attention.;;;","03/Jul/13 12:20;jkreps;That would be great.;;;","04/Jul/13 16:52;ashwanthfernando@gmail.com;I checked out 0.8, committed my changes and while rebasing with the trunk (which I believe holds 0.7), there are a whole lot of inbound patches which have conflicts with 0.8 code. Do I try to manual merge these conflicts? I have no clue what those patches are.

Followed the simple contributor workflow here - https://cwiki.apache.org/confluence/display/KAFKA/Git+Workflow except that for ""git checkout -b xyz remotes/origin/trunk"" I did git checkout -b 718 remotes/origin/0.8
;;;","08/Jul/13 11:43;junrao;Since this is not critical for 0.8, I suggest that we make the patch for trunk.;;;","08/Jul/13 12:41;ashwanthfernando@gmail.com;ok. I will do that and get back. Tx.;;;","09/Jul/13 02:10;jkreps;Hey Jun, this should be a trivial change and will likely catch a lot of people (most people don't check the gc settings). GC leads to all kinds of irritiating problems so i think it would be good to get this in 0.8 if possible.;;;","09/Jul/13 08:18;ashwanthfernando@gmail.com;The change is trivial. I guess where I am having problems in sending out a patch is that I checked out 0.8, made my changes, committed to my local git repo. While rebasing with the trunk, there are a whole lot of inbound patches that need to be added to 0.8 branch. Do I merge these patches, because I don't feel comfortable dealing with the conflicts, because these patches are not authored by me.

Or, do I rebase with 0.8 instead of the trunk, if I am working on 0.8?;;;","09/Jul/13 08:22;ashwanthfernando@gmail.com;Eitherways, I have a patch that cleanly applies on trunk.

Basically the kafka-run-class.sh has a lot of .sh clients which use it. A majority of these clients are non-daemon and a couple (zk and kafkaServer) are daemons. For the non daemons, we don't need gc logs so I have the following settings:

-XX:+AggressiveOpts -XX:+UseCompressedOops -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC

For the daemon processes (zk and kafkaServer) I have the above options set + the options to emit GC Logs.

-Xloggc:$base_dir/$GC_LOG_FILE_NAME -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps

Where GC_LOG_FILE_NAME is either zookeeper_gc.log or kafkaServer_gc.log depending on which is the daemon that is run. This is done, so that when developers run both zk and kafkaServer on the same filesystem, the two processes don't clobber the same file.;;;","12/Jul/13 05:28;jkreps;Hey Ashwanth, thanks for the patch.

I applied it to 0.8 and I want to abuse this ticket to include a bunch of trivial ""good housekeeping"" fixes I think we need for the 0.8 final release that probably don't warrant a ticket of thier own.

This includes:
1. Your gc settings, but minus the +AggressiveOpts which doesn't seem to work on all versions of java 1.6
2. Clean up the README which has a number of outdated things in it.
3. Remove unused properties from server.properties to fix WARN messages.
4. Change to use log.dirs in the example server config so people know about multiple log directories
5. Remove incorrect description of flush.interval in example server config.;;;","12/Jul/13 07:32;jkreps;Separate out a few more command line variables (GC, GC logging, SCALA_VERSION, etc).

Also remove delete_topic.sh command since that doesn't work yet.;;;","12/Jul/13 07:39;ashwanthfernando@gmail.com;Thanks Jay !! Can we mark this as resolved or do you have some more?;;;","12/Jul/13 07:46;jkreps;Since 0.8 is somewhat locked down I am just waiting on close sanity checking from a few others before I check in. I'll close it up then.;;;","04/Aug/13 01:47;jkreps;New patch. Rebased. Fixed logging in tools so that we no longer spew crazy log messages intermingled with the tool output.;;;","05/Aug/13 05:33;jkreps;Patch v5: move all logs to a logs/ directory to avoid polluting the main directory with a half dozen rolling logs.;;;","05/Aug/13 06:29;junrao;Thanks for patch v4. Got the following exception running kafka-console-producer.sh (ditto for kafka-console-consumer.sh)

bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
log4j:ERROR Could not read configuration file from URL [file:bin/../config/tools-log4j.properties].
java.io.FileNotFoundException: bin/../config/tools-log4j.properties (No such file or directory)
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:120)
	at java.io.FileInputStream.<init>(FileInputStream.java:79)
	at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:70)
	at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:161)
	at java.net.URL.openStream(URL.java:1010)
	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:459)
	at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:471)
	at org.apache.log4j.LogManager.<clinit>(LogManager.java:125)
	at org.apache.log4j.Logger.getLogger(Logger.java:105)
	at kafka.utils.Logging$class.logger(Logging.scala:24)
	at kafka.utils.VerifiableProperties.logger(VerifiableProperties.scala:23)
	at kafka.utils.Logging$class.info(Logging.scala:66)
	at kafka.utils.VerifiableProperties.info(VerifiableProperties.scala:23)
	at kafka.utils.VerifiableProperties.verify(VerifiableProperties.scala:180)
	at kafka.producer.ProducerConfig.<init>(ProducerConfig.scala:57)
	at kafka.producer.ConsoleProducer$.main(ConsoleProducer.scala:147)
	at kafka.producer.ConsoleProducer.main(ConsoleProducer.scala)
;;;","05/Aug/13 10:21;jkreps;Sorry, I had missed that file in v4. I had fixed it in v5, can you try that?;;;","05/Aug/13 23:16;junrao;+1 on v5.;;;","06/Aug/13 01:16;jkreps;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Disconnect idle socket connection in Selector,KAFKA-1282,12697266,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nmarasoi,junrao,junrao,26/Feb/14 08:34,16/Oct/15 09:54,22/Mar/23 15:10,16/Oct/15 09:54,0.8.2.0,,,,,,0.9.0.0,,,,,,,producer ,,,,0,newbie++,,,,,"To reduce # socket connections, it would be useful for the new producer to close socket connections that are idle. We can introduce a new producer config for the idle time.",,donnchadh,jjkoshy,jkreps,junrao,me.venkatr,nehanarkhede,nmarasoi,nmarasoiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1941,,,,,,,,,,,,,,,,KAFKA-1928,,"01/Jun/15 21:57;nmarasoi;1282_access-order_+_test_(same_class).patch;https://issues.apache.org/jira/secure/attachment/12736556/1282_access-order_%2B_test_%28same_class%29.patch","22/Aug/14 22:48;nmarasoiu;KAFKA-1282_Disconnect_idle_socket_connection_in_Selector.patch;https://issues.apache.org/jira/secure/attachment/12663665/KAFKA-1282_Disconnect_idle_socket_connection_in_Selector.patch","01/Jun/15 22:01;nmarasoi;access-order_+_test.patch;https://issues.apache.org/jira/secure/attachment/12736558/access-order_%2B_test.patch","01/Jun/15 22:24;nmarasoi;access_order_+_test_waiting_from_350ms_to_1100ms.patch;https://issues.apache.org/jira/secure/attachment/12736567/access_order_%2B_test_waiting_from_350ms_to_1100ms.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,375740,,,Fri Oct 16 01:54:45 UTC 2015,,,,,,,,,,"0|i1sqxz:",376036,,nehanarkhede,,,,,,,,,,,,,,,,,,"18/Jul/14 21:07;nmarasoiu;Right, the limitation is more critical on the client side of a client-server connection due to port count limitation, and/or socket/file count restrictions of the client env.

On the other hand, the brokers could close the connections too on such condition, rather than relying on the clients(producers) to protect it.

However, what is any other reason to reduce the socket connections count? To make the NIO select lighter on the server, on a lesser number of connections? I think epoll is quite relaxed on this.

I would like to work on this, but also understand the original problem(s) / concern(s) to see if we can also see any more suitable solutions to the particular concern?;;;","18/Jul/14 23:54;jkreps;The goal is just to reduce server connection count. In our environment there might be a single Kafka producer in each process we run publishing to a small Kafka cluster (say ~20 servers). However there are tens of thousands of client processes. Connections can end up going unused when leadership migrates and we should eventually close these out rather than retaining them indefinitely.

As you say it is not critical as the server seems to do a good job of dealing with high connection counts, but it seems like a good thing to do.

I agree that doing this on the server might be better. This does mean it is possible that the server will attempt to close the socket while the client is attempting to send something. But if the timeout is 10 mins, it is unlikely that this will happen often (i.e. if nothing was sent in the last 10 mins, it will not likely happen in the 0.5 ms it takes to do the close). The advantage of doing it on the server is that it will work for all clients.

This change would be in core/.../kafka/network/SocketServer.scala.

The only gotcha is that we likely need to avoid iterating over all connections to avoid latency impact (there could be 100k connections). One way to do this would be to use java.util.LinkedHashMap to implement an LRU hash map of the SelectionKeys, and access this every time the selection key comes up in a select operation. (There are a ton of details in LinkedHashMap--needs to be ""access order"", etc). Then every 5-10 select loop iterations we would iterate the map expiring connections until we come to a connection that doesn't need expiring, then stop.;;;","19/Jul/14 00:15;nmarasoiu;Beautiful, I can't wait to work this out, so I take this to code right?:)
;;;","23/Jul/14 21:49;nmarasoiu;[~junrao] You agree with the approach, do you?;;;","23/Jul/14 22:48;junrao;Yes. Thanks for picking it up.;;;","06/Aug/14 21:46;nehanarkhede;Hey [~nmarasoiu], are you actively working on this patch yet? If not, do you mind if we have someone else pick it up?;;;","08/Aug/14 22:52;nmarasoi;Hi,

I will spend up to 4 hours per day the next week (11-15 august), when I have this time.
So I would like to keep this nice task.
My estimate, I will have a first working solution to put up for review in ~3 days, so Thursday.

Does that sound good?;;;","13/Aug/14 05:11;nmarasoi;I attached a first version of the patch.
I am still thinking on any other implications, but wanted to share a first draft to collect some feedback already.
Thanks;;;","14/Aug/14 22:33;nehanarkhede;Thanks for picking this up [~nmarasoi]. Assigning to myself for review. ;;;","14/Aug/14 22:49;nehanarkhede;Took a look at the patch. How about the following -
1. Limit the LRU cache size to the number of active connections that should be supported by the Kafka server. I'm guessing this should be a config. 
2. Override removeEldestEntry to evict the oldest entry if the cache size exceeds the configured number of LRU connections.

That way, we don't have to traverse the map several times in the main loop, which can be expensive.;;;","14/Aug/14 23:05;nmarasoi;Traversing is quite cheap (it is traversing a linked list underneath, and only a prefix of it) and can be done every 1000 selects.
The intent of your suggestion is to optimize, I understand, but the effects is a different behavior as I feel it (changes the expiration by time and switches it to an expiration by connection count), and to a low performance benefit (I think traversing is much cheaper than blocking close on each channel, that would happen either way).
The idea of limited connection count can be used complementary to the existing traversing, but if you mean to take out the traversing every n selects, that changes the expiration by time and switches it to an expiration by connection count - is it an agreed requirements change with [~junrao]? I must warn that it is dangerous in my view to configure a maximum connection count per broker, because in event many brokers go down, and many clients need to use the system, this connection thrashing would not help anybody, and be a worse effect than not having this connection expiration at all, in such a scenario, relevant to a highly available system.;;;","15/Aug/14 02:56;nmarasoi;To make the ~O(1) cost of ""traversing"" more clear, typically only the first element in the linked list is accessed, and it will typically be used in the last 10 minutes, and in this case nothing happens anymore. Of course, this is if the low volume topics do not generate many connections, which they won't, with this cleaning up in place. And I am checking now that map() and the rest are lazy, or else for sure I can make so that only the relevant ""prefix/first"" part of the collection is iterated, typically first element only.;;;","15/Aug/14 08:31;nehanarkhede;My suggestion was not just to address the performance concern which is somewhat of an issue nevertheless. The motivation was that there is an upper bound on the number of open connections you can support on the broker. That number is the # of open file handles configured on the box. Since that number is known anyway, you probably would want to configure your server so that the connections never exceed a certain percentage of that upper limit. Currently, if the server runs out of open file handles, it effectively stays alive, but is unable to serve any data and becomes a 'zombie'. 

But a downside of the expiration based on the connection count is that it doesn't necessarily achieve the goal of expiring really old connections. Instead it tries to solve the problem of preventing the broker from running out of available file handles, in which case we probably need a fairer strategy for expiring connections. 

Thinking more, I think it might be sufficient to override removeEldestEntry and check if the oldest entry is older than the threshold and let the map remove it. If the oldest entry is not above the threshold, traversing the map doesn't buy you anything. The downside is that if no new activity takes place on any of the connections all of a sudden, the server wouldn't proactively drop all connections, which is less of a concern. 

The advantage is that you will still get the same benefit of expiring older connections and it removes the need to traverse.
;;;","15/Aug/14 16:08;nmarasoiu;Hi, I am sorry, but traversing will be limited to the connections that will actually be expired, so there is no traversing of non-expiring connections (please see the detailed example below). 

I do agree on the other hand that there will be a polling on the first entry until it expires, but this is how we can implement the requirement exactly as intended (expiration taking into account just time as per stated ""stale connections"" issue, not connection count or activity as well), and it can be done every 1000 selects. 

If we want to protect brokers from becoming zombies, this is a different concern I feel. However, I completely agree that we can do the LRU limiting as well to avoid zombeing (as part of this jira or another one). Both mechanisms to expire can be at work and solve both problems with no overhead in doing so (there would just be 2 contexts in which an evict+close would be performed, if we do not count the evict done in a normal close call).

[~junrao], [~jkreps], what do you think?

Say the server hold 100K connections. Say 100 connections are not used in the last 10 minutes.

What the program does (or I will make sure it does) is just iterate through the first 101 connections, the first 100 will be expired and it will stop at number 101.
I think this is an exact achievement of expected behavior of the jira task, as intended, and there is no performance penalty to that really!

I will rewrite with a loop /(tail-)recursive function, to check the first entry, and if stale call close (which also does a remove on the map anyways), and retry the next entry. This would be to avoid copying of the first 100 selectionKeys as well as to avoid any overhead/eagerness in map function.;;;","22/Aug/14 01:09;nmarasoi;After discussion with Neha, we agreed that using the removeEldestEntry approach works better in the sense that avoids disruption caused by potentially many connections being up for close at once, and evens out that overhead. The disadvantage remains that an inactive server will not close connections but seems less than the advantage of closing overhead leveling and of performance plus of not traversing and of not polling the oldest entry.;;;","25/Aug/14 12:24;junrao;Thanks for the patch. Looks good to me overall. Some minor comments below.

1. Could we make connectionsLruTimeout a broker side configuration?

2. Do we need to insert the key to lruConnections in write()? It seems to me doing that in read() (for incoming requests) is enough.

3. The patch doesn't seem to apply for me. Could you rebase?

git  apply -p0 ~/Downloads/KAFKA-1282_Disconnect_idle_socket_connection_in_Selector.patch 
/Users/jrao/Downloads/KAFKA-1282_Disconnect_idle_socket_connection_in_Selector.patch:13: trailing whitespace.
import java.util
/Users/jrao/Downloads/KAFKA-1282_Disconnect_idle_socket_connection_in_Selector.patch:21: trailing whitespace.
import java.util.Map.Entry
/Users/jrao/Downloads/KAFKA-1282_Disconnect_idle_socket_connection_in_Selector.patch:30: trailing whitespace.
  private val connectionsLruTimeout: Long = TimeUnit.MINUTES.toNanos(10)
/Users/jrao/Downloads/KAFKA-1282_Disconnect_idle_socket_connection_in_Selector.patch:31: trailing whitespace.
  private var currentTime: Long = SystemTime.nanoseconds
/Users/jrao/Downloads/KAFKA-1282_Disconnect_idle_socket_connection_in_Selector.patch:32: trailing whitespace.
  private val lruConnections = new util.LinkedHashMap[SelectionKey, Long](100, .75F, true) {
error: patch failed: core/src/main/scala/kafka/network/SocketServer.scala:16
error: core/src/main/scala/kafka/network/SocketServer.scala: patch does not apply
;;;","26/Aug/14 12:35;nmarasoi;Hi, Thank you, for 2. I agree for producers but I am not sure if the same SocketServer is used to serve consumers as well, and in this case, for consumers, the read/write ratio may be well in favor of writes making it risky perhaps to account just the reads?;;;","26/Aug/14 22:30;junrao;Nicu,

Similar to producers, consumers just issue fetch requests. The SocketServer first reads the fetch request from the network and then writes the fetch response to the network once the fetch request is served by the broker. So, there is a 1-to-1 mapping btw reads and writes and writes typically happen within a second after the reads. ;;;","28/Aug/14 03:20;nmarasoi;uploaded with parametrization and no more access-touch from write;;;","29/Aug/14 03:59;nmarasoi;[~nehanarkhede] Hi, I implemented our discussion and applied Jun Rao suggestions, can you check and perhaps commit it if looks good? Hope for more tasks like this, do you have any suggestions?:);;;","29/Aug/14 05:36;junrao;Thanks for the patch. The following should be * 1000000, right?

  private val connectionsLruTimeout: Long = connectionsMaxIdleMs * 1000;;;","30/Aug/14 02:26;nmarasoi;Patch updated. Configurable max idleness of a connection since the last read on it. On creating new N connections, the server will be Closing at most N idle connections too, if they are idle for more than the mentioned threshold, default 10 minutes.;;;","02/Sep/14 02:24;junrao;Looking at the patch again, in removeEldestEntry(), shouldn't we close the socket for eldest if the entry is to be removed? Right now, it seems that we only remove the entry from LRU w/o actually closing the idle socket connection.;;;","02/Sep/14 02:56;nmarasoi;I am sorry, Yes, that was the intent! I will write unit tests from now on to avoid such slips.

Moreover, the removeEldestEntry will return false all the time, because it keeps the responsability of mutating the map for itself, as part of calling the close method. 

Attached the patch, tests pass.;;;","03/Sep/14 00:30;junrao;Thanks for the latest patch. I was trying to do some local testing. The following are my observations.

1. I first started a local ZK and broker (setting connections.max.idle.ms 10secs). I then started a console-producer and a console-consumer. Then, I typed in sth in console-producer every 15 secs. However, I don't see the producer connection gets killed. I added sth instrumentation. It doesn't seem that removeEldestEntry() is called on every fetch request.

2. As I was debugging this, I realized that it's kind of weird to kill idle connections only when there is another non-idle connection. This makes debugging harder since one can't just test this out with a single connection. It's much simpler to understand if the idle connection can just be killed after the connection idle time, independent of other connections to the broker. To address the concern of closing many sockets in one iteration of the selector, we can calculate the time that a socket entry is expected to be killed (this is the access time of the oldest entry + maxIdleTime, or maxIdleTime if no entry exists). When that time comes during the iteration of the selector, we can just check the oldest entry and see if it needs to be closed.

3. It would be good to check if our clients (especially the producer, both old and new) can handle a closed idle connection properly. For example, when detecting an already closed socket, the producer should be able to resend the message and therefore we shouldn't see any data loss.;;;","05/Sep/14 13:25;nmarasoi;Hi, I am not completely sure I fully understood your solution in point 2: 

Do you mean to close at most one connection per iteration, right? This is ok, the worst case scenario is closing 100K old connections in 10 hours, one per select.

On storing the time to close in a local variable, the access of the oldest entry every iteration is O(1) super cheap so I would skip this optimization. ;;;","08/Sep/14 20:47;nmarasoi;[~junrao], hi, can you answer please? I agree with what you say if I understood all of it, I am doing a small patch right now;;;","08/Sep/14 20:49;nmarasoi;[~nehanarkhede] Hi, can you also check the new idea? It is consistent with my initial approach and solves the potential overhead of closing too many connections on a single iteration.;;;","15/Sep/14 00:11;nehanarkhede;Thanks for the patch, [~nmarasoi]! Looks good overall. Few review comments -

1. Do we really need connectionsLruTimeout in addition to connectionsMaxIdleMs? It seems to me that we are translating the idle connection timeout plugged in by the user to 1000000x times more than what is configured. That's probably why Jun saw the behavior he reported earlier. 
2. I don't really share Jun's concern in #2 and we can state that more clearly in the comment that describes the new config in KafkaConfig. Connections that are idle for more than connections.max.idle.ms *may* get killed. I don't think the users particularly care about a hard guarantee of their connections getting killed here. So the simplicity of this approach is well justified.
3. I do think that adding a produce and fetch test where the connections get killed will be great ;;;","16/Sep/14 12:45;junrao;Nicu,

On #2, I wasn't worried about any performance optimization. My concern is mostly on testing and ease of understanding. Since removeEldestEntry is only called on update, you can't test the logic on a single connection to the broker. It's a bit weird that if there is only a single idle connection, that connection is never killed. But as soon as a second connection is added, the idle connection will be killed. For the user's perspective, it's simpler to understand how idle connections are killed if they are not tied to # of connection.

Also, could you explain how you fixed #1 in the latest patch? It wasn't obvious to me.;;;","16/Sep/14 22:53;nmarasoiu;Hi, 

I have understood what you say and I agree it is highly unintuitive and we should change that. I just saw you propose a solution which included a precomputation of the time to close, and it was bit confusion, looked like an attempt of micro optimization.

I have not made any patch yet, I waited for feedback from Neha too, but I will do the patch today: it looks ok to me the idea of closing at most one old connection per selector iteration.

So the solution will look more like the previous patch, but instead of traversing n+1 entries to close n old connections, it will just pick the oldest and check if it is time to close.

For #1, the way Neha and me discussed, and the way you understood it works (for the latest patch), is that an old connection is taken into consideration for close only when a new connection is being opened up (or activity exists on an existing connection too). But this will no longer be the case.;;;","17/Sep/14 03:56;nmarasoi;Attached patch: every select iteration, zero or one connections are closed for being idle for too long.
The units pass well, but
For the moment I am blocked by:
./kafka-console-producer.sh
Error: Could not find or load main class kafka.tools.ConsoleProducer;;;","17/Sep/14 12:36;junrao;Did you do ""./gradlew jar"" first?;;;","17/Sep/14 17:47;nmarasoi;Hi,

Unfortunately the client used in console-producer is not very robust with respect to disconnections, as will detail below. Is this the ""old"" scala producer, and can we hope for a resilient behaviour that I can test with the new java producer?

More specifically, the connection is closed from the broker side, but the producer is unaware of this. The first message after the close is lost (and is not retried later). The second message sees the broken channel, outputs the exception below, and reconnects and is succesfully retried, I can see it consumed.

[2014-09-17 12:44:12,009] WARN Failed to send producer request with correlation id 15 to broker 0 with data for partitions [topi,0] (kafka.producer.async.DefaultEventHandler)
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.writev0(Native Method)
	at sun.nio.ch.SocketDispatcher.writev(SocketDispatcher.java:51)
	at sun.nio.ch.IOUtil.write(IOUtil.java:149)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:483)
	at java.nio.channels.SocketChannel.write(SocketChannel.java:493)
	at kafka.network.BoundedByteBufferSend.writeTo(BoundedByteBufferSend.scala:56)
	at kafka.network.Send$class.writeCompletely(Transmission.scala:75)
	at kafka.network.BoundedByteBufferSend.writeCompletely(BoundedByteBufferSend.scala:26)
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:100)
;;;","17/Sep/14 18:00;nmarasoi;re-attached fixed patch, but we may have a blocker to the whole solution on the broker side, pls see comment above/below (first message after disconnect is lost on the client used in console-prod);;;","17/Sep/14 20:08;nmarasoi;here is a time line:

he -> produced
he -> consumed
[ wait beyond timeout here, connection got closed underneath by the other side]
[2014-09-17 15:02:28,689] INFO Got user-level KeeperException when processing sessionid:0x148837ce1800001 type:setData cxid:0x24 zxid:0xec txntype:-1 reqpath:n/a Error Path:/consumers/console-consumer-87959/offsets/topi/0 Error:KeeperErrorCode = NoNode for /consumers/console-consumer-87959/offsets/topi/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[2014-09-17 15:02:28,691] INFO Got user-level KeeperException when processing sessionid:0x148837ce1800001 type:create cxid:0x25 zxid:0xed txntype:-1 reqpath:n/a Error Path:/consumers/console-consumer-87959/offsets Error:KeeperErrorCode = NoNode for /consumers/console-consumer-87959/offsets (org.apache.zookeeper.server.PrepRequestProcessor)
dddddddddddddd --> produce attempt (never retried, or never reached the broker or at least never reached the consumer)
[ many seconds wait, to see if the message is being retried, apparently not, even though the default retry is 3 times]
wwwwwwwwwwwwwwwww --> new attempt (immediattely I see the message below with the stack trace, and reconnect + retry is instantly sucesfull)
[2014-09-17 15:03:12,599] WARN Failed to send producer request with correlation id 9 to broker 0 with data for partitions [topi,0] (kafka.producer.async.DefaultEventHandler)
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.writev0(Native Method)
	at sun.nio.ch.SocketDispatcher.writev(SocketDispatcher.java:51)
	at sun.nio.ch.IOUtil.write(IOUtil.java:149)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:483)
	at java.nio.channels.SocketChannel.write(SocketChannel.java:493)
	at kafka.network.BoundedByteBufferSend.writeTo(BoundedByteBufferSend.scala:56)
	at kafka.network.Send$class.writeCompletely(Transmission.scala:75)
	at kafka.network.BoundedByteBufferSend.writeCompletely(BoundedByteBufferSend.scala:26)
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:100)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:72)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:71)
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(SyncProducer.scala:102)
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply(SyncProducer.scala:102)
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply(SyncProducer.scala:102)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.producer.SyncProducer$$anonfun$send$1.apply$mcV$sp(SyncProducer.scala:101)
	at kafka.producer.SyncProducer$$anonfun$send$1.apply(SyncProducer.scala:101)
	at kafka.producer.SyncProducer$$anonfun$send$1.apply(SyncProducer.scala:101)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:100)
	at kafka.producer.async.DefaultEventHandler.kafka$producer$async$DefaultEventHandler$$send(DefaultEventHandler.scala:255)
	at kafka.producer.async.DefaultEventHandler$$anonfun$dispatchSerializedData$2.apply(DefaultEventHandler.scala:106)
	at kafka.producer.async.DefaultEventHandler$$anonfun$dispatchSerializedData$2.apply(DefaultEventHandler.scala:100)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at kafka.producer.async.DefaultEventHandler.dispatchSerializedData(DefaultEventHandler.scala:100)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:72)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:104)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:87)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:67)
	at scala.collection.immutable.Stream.foreach(Stream.scala:547)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:66)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)
[2014-09-17 15:03:12,712] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
wwwwwwwwwwwwwwwww;;;","17/Sep/14 20:18;nmarasoiu;in fact, this is something that needs fixing in the producer(s) anyway, but the issue is with the currently deployed producers.
One of the main reasons to go with a broker side close of the idle connections was that it is easier to redeploy brokers then producers.
But if this is indeed a bug in the producer(s) as I reproduced, those producers would need redeploy.
So moving this to the producer side as a configuration may again be an option on the table.;;;","17/Sep/14 23:36;junrao;Interesting. The data loss may have to do with ack=0, which is the default in console producer. Could you try ack=1?;;;","18/Sep/14 03:33;nmarasoi;Indeed, ack=1 solves it for most times but not for all:
- in 6 of 7 tests it gets a reset by peer and a socket timeout on fetch meta, than re connects and sends message.
- in one test, after leaving one night the laptop, I entered:
sdfgsdfgdsfg --> that never returned, no exception, nothing at all reported
aaaaaaaaaaa
aaaaaaaaaaa
ff
ff

The ""ok"" flow, which reproduces most of the time with ack=1 is (sometimes with just one of the 2 expcetions):
gffhgfhgfjfgjhfhjfgjhf
[2014-09-18 08:22:35,057] WARN Failed to send producer request with correlation id 43 to broker 0 with data for partitions [topi,0] (kafka.producer.async.DefaultEventHandler)
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
..
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)
[2014-09-18 08:22:36,663] WARN Fetching topic metadata with correlation id 44 for topics [Set(topi)] from broker [id:0,host:localhost,port:9092] failed (kafka.client.ClientUtils$)
java.net.SocketTimeoutException
	at sun.nio.ch.SocketAdaptor$SocketInputStream.read(SocketAdaptor.java:226)
..
[2014-09-18 08:22:36,664] ERROR fetching topic metadata for topics [Set(topi)] from broker [ArrayBuffer(id:0,host:localhost,port:9092)] failed (kafka.utils.Utils$)
kafka.common.KafkaException: fetching topic metadata for topics [Set(topi)] from broker [ArrayBuffer(id:0,host:localhost,port:9092)] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:71)
..
Caused by: java.net.SocketTimeoutException
	at sun.nio.ch.SocketAdaptor$SocketInputStream.read(SocketAdaptor.java:226)
	.. kafka.network.BoundedByteBufferReceive.readCompletely(BoundedByteBufferReceive.scala:29)
	at kafka.network.BlockingChannel.receive(BlockingChannel.scala:108)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:74)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:71)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:57)
	... 12 more
gffhgfhgfjfgjhfhjfgjhf;;;","18/Sep/14 22:02;nehanarkhede;Thanks for the updated patch. Overall, looks great. Few comments -
1. Can you rename initialNextIdleCloseCheckTimeValue to nextIdleCloseCheckTimeValue?
2. It will be easier to understand the code if we rename currentTime to currentTimeNanos.
;;;","19/Sep/14 03:13;nmarasoi;attached, renamed time and for the ""initial/reset value of the nextIdleCheck"", i just inlined the function, the code is more clear like this i think;;;","19/Sep/14 05:04;junrao;Do you think you can reproduce that data loss issue in 1 out of your 7 tests? With ack=1 and retries, this shouldn't happen. Perhaps it's useful to enable the trace logging in the producer to see what's exactly happening there.

Could you also do the same test by enabling the new producer in console producer?;;;","21/Sep/14 03:48;nehanarkhede;+1 on your latest patch. I'm leaning towards accepting the patch since the test above points to an issue that seems unrelated to the patch. [~nmarasoi], it will be great if you can follow Jun's suggestion to reproduce the issue. Then file a JIRA to track it. I'm guessing killing idle connections shouldn't lead to data loss.;;;","21/Sep/14 04:52;nehanarkhede;Pushed the latest patch to trunk.;;;","07/Nov/14 10:37;junrao;Nicu,

I was doing some manual testing of this feature. What I observed is that sometimes, the idle connections are not closed. The following was what I did.

1. Configure a small connections.max.idle.ms = 10000.
2. start ZK and Kafka broker
3. start a console consumer
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic topic1 --from-beginning
4. start a console producer and type in sth every 15 secs or so. 
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic1 --request-required-acks 1

What I observed was that initially, the producer connections kept getting killed by the broker correctly after being idle for 10 secs. The next producer send would hit an IOException and trigger a resend. However, after typing in 10 or so messages, at some point, no idle connections were killed by the broker any more and the producer send always succeeded.;;;","08/Nov/14 22:54;nmarasoi;Indeed, I can reproduce this. I did saw an instance where no exception was thrown by the producer but still the broker mentioned new connection being listened to suggesting close took place. However, checking with required-acks 0 I can see that after some time the connection does not close anymore.;;;","09/Nov/14 00:41;nmarasoi;Fixed it - I have mistakenly deleted at some point the fact that the linked hash map needs to be in access order :( 
I tested with your scenario and looks ok now.;;;","10/Nov/14 10:15;nehanarkhede;good catch [~nmarasoi]. +1 on your change;;;","11/Nov/14 02:56;junrao;Nicu,

Thanks for the patch. Do you think it's easy to add a unit test on Processor?;;;","13/Nov/14 06:25;nmarasoi;I want, yes, I will add a few tests this week.;;;","19/Nov/14 05:36;jjkoshy;This is already in 0.8.2 so we should incorporate the follow-ups there as well I think.;;;","30/Dec/14 06:21;nehanarkhede;[~nmarasoi], [~junrao] This is marked for 0.8.2. Is anyone working or planning to work on this?;;;","30/Dec/14 06:59;nmarasoiu;I will do unit tests tommorow / day after. The fix should be ok otherwise,
and ready to be pushed on trunk and 0.8.2. I will announce when done with
units.

On Tue, Dec 30, 2014 at 12:21 AM, Neha Narkhede (JIRA) <jira@apache.org>

;;;","01/Jun/15 21:57;nmarasoi;Hi [~junrao], [~nehanarkhede], I added a test, please review. The patch has 2 variations (latest 2 patches), explained at point 2 below, while the latest implements 1' below.

1. I wanted to sleep on MockTime, but here we actually need to physically wait at leat one epoll/select cycle. Since I have put 10ms idle time & it works, mocked time would not bring benefits, i.e. only the select time needs to be waited over. 

1'. Because of potentially large & not deterministically bounded select times, I implemented a mechanism to try a few times, waiting 50% more time every time.

2. Seems to work with low (10ms) idle timeout for all current test methods. However, I attach a patch with separate test class for this (and yet another utils class for reuse), to isolate configuration between group of test methods.

3. Shall I do a multiple connections test?;;;","02/Jun/15 07:59;junrao;[~nmarasoi], thanks for the patch. We are changing SocketServer to reuse Selector right now in KAFKA-1928. Once that's done, the idle connection logic will be moved into Selector and should be easier to test since Selector supports mock time. That patch is almost ready. Perhaps you can wait until it's committed and submit a new patch. ;;;","20/Aug/15 23:00;nmarasoi;Hi,

I noticed that the dependencies are done and I will resume this task.
The task contributions had been:
- a fix
- unit test(s)

As far as the fix is concerned, I noticed that it is already fixed in the current Selector, namely the lruConnections is a LinkedHashMap with accessOrder=true. This was the only fix needed, and I am 100% convinced that the fix is already done.

I already have a unit test too, I will try to put a patch here this week.

Just wanted to mention that the old connections should be closed by the kafka installations using the new reusable network code.

Thanks
Nicu;;;","16/Oct/15 09:54;junrao;[~nmarasoi], yes, the actual problem is now fixed in trunk. We just need to add a unit test. I created a followup jira KAFKA-2661 for that. Resolving this jira.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka does not properly parse multiple ZK nodes with non-root chroot,KAFKA-1664,12745375,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,singhashish,rickysaltzer,rickysaltzer,02/Oct/14 06:37,02/Mar/15 13:16,22/Mar/23 15:10,28/Feb/15 07:10,,,,,,,,,,,,,,clients,,,,0,newbie,,,,,"When using a non-root ZK directory for Kafka, if you specify multiple ZK servers, Kafka does not seem to properly parse the connection string. 

*Error*
{code}
[root@hodor-001 bin]# ./kafka-console-consumer.sh --zookeeper baelish-001.edh.cloudera.com:2181/kafka,baelish-002.edh.cloudera.com:2181/kafka,baelish-003.edh.cloudera.com:2181/kafka --topic test-topic
[2014-10-01 15:31:04,629] ERROR Error processing message, stopping consumer:  (kafka.consumer.ConsoleConsumer$)
java.lang.IllegalArgumentException: Path length must be > 0
	at org.apache.zookeeper.common.PathUtils.validatePath(PathUtils.java:48)
	at org.apache.zookeeper.common.PathUtils.validatePath(PathUtils.java:35)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:766)
	at org.I0Itec.zkclient.ZkConnection.create(ZkConnection.java:87)
	at org.I0Itec.zkclient.ZkClient$1.call(ZkClient.java:308)
	at org.I0Itec.zkclient.ZkClient$1.call(ZkClient.java:304)
	at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
	at org.I0Itec.zkclient.ZkClient.create(ZkClient.java:304)
	at org.I0Itec.zkclient.ZkClient.createPersistent(ZkClient.java:213)
	at org.I0Itec.zkclient.ZkClient.createPersistent(ZkClient.java:223)
	at org.I0Itec.zkclient.ZkClient.createPersistent(ZkClient.java:223)
	at org.I0Itec.zkclient.ZkClient.createPersistent(ZkClient.java:223)
	at kafka.utils.ZkUtils$.createParentPath(ZkUtils.scala:245)
	at kafka.utils.ZkUtils$.createEphemeralPath(ZkUtils.scala:256)
	at kafka.utils.ZkUtils$.createEphemeralPathExpectConflict(ZkUtils.scala:268)
	at kafka.utils.ZkUtils$.createEphemeralPathExpectConflictHandleZKBug(ZkUtils.scala:306)
	at kafka.consumer.ZookeeperConsumerConnector.kafka$consumer$ZookeeperConsumerConnector$$registerConsumerInZK(ZookeeperConsumerConnector.scala:226)
	at kafka.consumer.ZookeeperConsumerConnector$WildcardStreamsHandler.<init>(ZookeeperConsumerConnector.scala:755)
	at kafka.consumer.ZookeeperConsumerConnector.createMessageStreamsByFilter(ZookeeperConsumerConnector.scala:145)
	at kafka.consumer.ConsoleConsumer$.main(ConsoleConsumer.scala:196)
	at kafka.consumer.ConsoleConsumer.main(ConsoleConsumer.scala)
{code}


*Working*
{code}
[root@hodor-001 bin]# ./kafka-console-consumer.sh --zookeeper baelish-001.edh.cloudera.com:2181/kafka --topic test-topic
{code}",,gwenshap,jcreasy,junrao,nehanarkhede,rickysaltzer,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Nov/14 13:45;singhashish;KAFKA-1664.1.patch;https://issues.apache.org/jira/secure/attachment/12683216/KAFKA-1664.1.patch","11/Dec/14 14:18;singhashish;KAFKA-1664.2.patch;https://issues.apache.org/jira/secure/attachment/12686456/KAFKA-1664.2.patch","17/Nov/14 03:52;singhashish;KAFKA-1664.patch;https://issues.apache.org/jira/secure/attachment/12681803/KAFKA-1664.patch","30/Jan/15 02:27;singhashish;KAFKA-1664_2015-01-29_10:26:20.patch;https://issues.apache.org/jira/secure/attachment/12695323/KAFKA-1664_2015-01-29_10%3A26%3A20.patch","25/Feb/15 03:02;singhashish;KAFKA-1664_2015-02-24_11:02:23.patch;https://issues.apache.org/jira/secure/attachment/12700546/KAFKA-1664_2015-02-24_11%3A02%3A23.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Mar 02 05:16:07 UTC 2015,,,,,,,,,,"0|i20phb:",9223372036854775807,,nehanarkhede,,,,,,,,,,,,,,,,,,"02/Oct/14 06:42;gwenshap;This happens with other high-level consumer clients. So its not just the ConsoleConsumer. 

Topic admin tools don't throw an exception, but don't show topics either.

I'm working on a patch.;;;","02/Oct/14 08:51;junrao;Actually, namespace should only be included once in a ZK url, not after every host:port. So the correct ZK URL should be

 baelish-001.edh.cloudera.com:2181,baelish-002.edh.cloudera.com:2181,baelish-003.edh.cloudera.com:2181/kafka;;;","02/Oct/14 09:19;rickysaltzer;Yes I've tried that as well, same problem.

;;;","02/Oct/14 10:53;junrao;So, it seems that namespace doesn't exist. For tools, auto-creating those namespaces may not be ideal. Perhaps we just need to provide a more meaningful error.;;;","02/Oct/14 12:06;nehanarkhede;+1 on providing a more meaningful error.;;;","03/Oct/14 02:01;rickysaltzer;[~junrao] my apologies, thanks for the recommendation, that *did* actually work. +1 for a more meaningful error. ;;;","03/Oct/14 05:37;gwenshap;For a more meaningful error, I'm thinking: Catch the exception thrown by zkClient at createParentPath, log an error like ""Invalid ZooKeeper path, please check syntax and that path exists"" and throw our own ConfigException

Since the original error is thrown by zkClient, we'll need to handle that in multiple places where we call it. Does it make sense to patch zkClient instead?

;;;","06/Oct/14 07:57;junrao;Perhaps we can add a wrapper in ZkUtils for creating a path in ZK. The wrapper will first check the existence of namespace. If it doesn't, throw a meaningful exception.;;;","16/Nov/14 02:13;singhashish;[~gwenshap] I am thinking of taking a look at this. If it is OK with you, kindly assign the JIRA to me.;;;","16/Nov/14 18:05;gwenshap;Here you go, [~singhashish]. Have fun.;;;","17/Nov/14 03:52;singhashish;RB: https://reviews.apache.org/r/28108/;;;","12/Dec/14 03:48;singhashish;[~nehanarkhede] Addressed your review comment. Kindly take a look.;;;","30/Dec/14 06:38;singhashish;[~nehanarkhede] still waiting for your review.;;;","17/Jan/15 07:24;singhashish;Testing file [KAFKA-1664.2.patch|https://issues.apache.org/jira/secure/attachment/12686456/KAFKA-1664.2.patch] against branch trunk took 0:09:06.543433.

{color:red}Overall:{color} -1 due to 2 errors

{color:red}ERROR:{color} Some unit tests failed (report)
{color:red}ERROR:{color} Failed unit test: {{kafka.consumer.ZookeeperConsumerConnectorTest > testConsumerRebalanceListener FAILED
}}
{color:green}SUCCESS:{color} Gradle bootstrap was successful
{color:green}SUCCESS:{color} Clean was successful
{color:green}SUCCESS:{color} Patch applied correctly
{color:green}SUCCESS:{color} Patch add/modify test case
{color:green}SUCCESS:{color} Gradle bootstrap was successful
{color:green}SUCCESS:{color} Patch compiled

This message is automatically generated.;;;","30/Jan/15 02:27;singhashish;Updated reviewboard https://reviews.apache.org/r/28108/
 against branch trunk;;;","24/Feb/15 10:16;singhashish;[~nehanarkhede] could you review this when you get a chance.;;;","25/Feb/15 00:35;nehanarkhede;[~ashishujjain] Thanks for the reminder. The patch looks good, the only comment I have is that it introduces a bunch of build warnings-
{code}
/Users/nnarkhed/Projects/kafka/core/src/test/scala/unit/kafka/zk/ZKPathTest.scala:45: This catches all Throwables. If this is really intended, use `case exception : Throwable` to clear this warning.
      case exception => fail(""Should have thrown ConfigException"")
{code}
;;;","25/Feb/15 03:02;singhashish;Updated reviewboard https://reviews.apache.org/r/28108/
 against branch trunk;;;","25/Feb/15 03:04;singhashish;[~nehanarkhede] addressed the warnings issue. Thanks for the review.;;;","26/Feb/15 06:46;jcreasy;I think this is because it expects the string to be:

baelish-001.edh.cloudera.com:2181,baelish-002.edh.cloudera.com:2181,baelis
h-003.edh.cloudera.com:2181/kafka


I don¹t think you would ever want to have a different root per host.;;;","26/Feb/15 06:47;jcreasy;nevermind, missed Jun's response farther up. Carry on! :);;;","28/Feb/15 07:10;nehanarkhede;Thanks for the patch. Pushed to trunk.;;;","01/Mar/15 01:12;junrao;Thanks for the patch. The patch makes every create operation in ZK a bit more expensive since it has to do an extra exists check. This may slow down operations like creating a new topic, especially when there are lots of partitions.

The checking of the chroot really just needs to be done once at the beginning. I am thinking that one way to improve this is to make ZkPath a singleton. It will do the chroot check on first create and remembers the result. Subsequent create calls will just reuse the result.;;;","02/Mar/15 13:16;singhashish;[~junrao] thanks for bringing up this point. Created KAFKA-1994 to track this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mirror maker system test hangs and eventually fails,KAFKA-2573,12895684,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,singhashish,singhashish,singhashish,23/Sep/15 13:46,07/Oct/15 05:07,22/Mar/23 15:10,07/Oct/15 05:07,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Due to changes made in KAFKA-2015, handling of {{--consumer.config}} has changed, more details is specified on KAFKA-2467. This leads to the exception.

{code}
Exception in thread ""main"" java.lang.NoSuchMethodError: java.util.concurrent.ConcurrentHashMap.keySet()Ljava/util/concurrent/ConcurrentHashMap$KeySetView;
	at kafka.utils.Pool.keys(Pool.scala:77)
	at kafka.consumer.FetchRequestAndResponseStatsRegistry$.removeConsumerFetchRequestAndResponseStats(FetchRequestAndResponseStats.scala:69)
	at kafka.metrics.KafkaMetricsGroup$.removeAllConsumerMetrics(KafkaMetricsGroup.scala:189)
	at kafka.consumer.ZookeeperConsumerConnector.shutdown(ZookeeperConsumerConnector.scala:200)
	at kafka.consumer.OldConsumer.stop(BaseConsumer.scala:75)
	at kafka.tools.ConsoleConsumer$.process(ConsoleConsumer.scala:98)
	at kafka.tools.ConsoleConsumer$.run(ConsoleConsumer.scala:57)
	at kafka.tools.ConsoleConsumer$.main(ConsoleConsumer.scala:41)
	at kafka.tools.ConsoleConsumer.main(ConsoleConsumer.scala)
{code}",,ewencp,githubbot,granders,guozhang,ijuma,lindong,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Oct 06 21:07:10 UTC 2015,,,,,,,,,,"0|i2lfxb:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"23/Sep/15 13:58;githubbot;GitHub user SinghAsDev opened a pull request:

    https://github.com/apache/kafka/pull/234

    KAFKA-2573: Mirror maker system test hangs and eventually fails

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/SinghAsDev/kafka KAFKA-2573

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/234.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #234
    
----
commit ab79b2857c21cfadb1ce9ce648fb13a51d576668
Author: Ashish Singh <asingh@cloudera.com>
Date:   2015-09-22T23:21:27Z

    KAFKA-2573: Mirror maker system test hangs and eventually fails

----
;;;","23/Sep/15 16:52;ijuma;The exception you pasted happens if you compile with Java 8 and run it with Java 7. Are you sure you pasted the right exception?;;;","24/Sep/15 02:44;singhashish;[~ijuma] thanks for pointing it out. I was under impression that Kafka code is compiled on the vagrant hosts and never thought it could be the java version causing the issue. Yes, it was due to using java8 at compile time and java 7 at run time. I am not sure, but I think that is not something we should be worried about. Let me know your thoughts, and we can close the JIRA accordingly.;;;","24/Sep/15 02:50;ijuma;How does your PR handle this problem? This is a user error, but if we can provide a better error message somewhat easily, then that's a good thing.;;;","24/Sep/15 04:30;singhashish;In my PR I removed {{consumer.wait()}} that gets blocked and eventually the test fails due to timeout while waiting for the consumer thread to finish. Instead, I am doing my asserts on a separate thread by getting consumed messages from consumer thread and then I stop the thread without waiting on it. This approach is used in console_consumer_test as well. Does that sound reasonable to you?;;;","24/Sep/15 04:44;granders;See what you think of my comment on https://github.com/apache/kafka/pull/234
;;;","24/Sep/15 04:54;singhashish;[~granders] +1 on your suggested change, will incorporate that. By hang I meant it will be stuck before timing out and failing. What are your thoughts on the PR to address java incompatibility issue?;;;","24/Sep/15 05:22;granders;After speaking a bit with Ashish, I think I understand the intent behind the changes better now:
it seems these changes are intended to get the test to pass despite the remote console consumer process hanging during shutdown (correct me if I misunderstood, [~singhashish]).

My argument is that failure of the test in this case is exactly what we want - how else would we have known an issue with conflicting java versions had caused the process to blow up during shutdown?

That said, it is a very reasonable error to compile locally with java 8 (I'm 100% sure this will cause trouble for others as well), so we should at least document this in the system test README 
;;;","24/Sep/15 06:14;singhashish;I think the test is failing due to a reason it is not intending to test, or is it. I am not saying that we should not be catching such issues, my question is that should we be failing mirror-maker test due to an issue with consumer shutdown? May be we should. I am fine either ways, but just something we should agree upon.

If we choose to let the test fail, I can change the PR to just make it fail fast instead of waiting for 10 minutes.;;;","24/Sep/15 22:56;ijuma;I think the test should fail fast indeed. The system tests are meant to test the system working together and if one part is failing (for whatever reason), we should know about it. This is one of the main benefits of system tests when compared to the JUnit tests we have (which isolate things more).;;;","25/Sep/15 05:00;singhashish;OK, I have updated the PR to just make the test fail faster.;;;","28/Sep/15 22:05;ijuma;KAFKA-2585 is related, cc [~lindong];;;","29/Sep/15 01:31;lindong;[~ijuma] Thanks for referring me to this ticket. Yes, I think this is the same issue I described in KAFKA-2585. The solution I used in https://github.com/apache/kafka/pull/247 is different from that used by [~singhashish].

I think it would be better to fix it on the ConsoleConsumer.scala for this particular error -- because ConsoleConsumer shouldn't hang forever upon exception.

I can see value for having a hardtimeout for any remove process in Ducktape test. But from my test experience I think there is already hard timeout as of Ducktape ac67e3f312d94c23ba06673c555fe557f1c9f39b, no? If we were to add a hard timeout, would it be better to enforce it as a general mechanism than having specific timeout for specific test, as is done in https://github.com/apache/kafka/pull/234?;;;","06/Oct/15 10:55;ewencp;Agreed with [~lindong] that the tools itself should also be fixed, but I think it would be fine to commit this in order to handle the immediate issue with the system tests and file a follow up JIRA about ConsoleConsumer.

I think this is getting lost in the shuffle since it doesn't have a reviewer. [~guozhang] I'm going to assign you as reviewer for the moment so at least one committer is keeping track of it.;;;","07/Oct/15 05:07;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/234
;;;","07/Oct/15 05:07;guozhang;Issue resolved by pull request 234
[https://github.com/apache/kafka/pull/234];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka server unable to connect to zookeeper,KAFKA-3102,12930001,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,mohitanchlia,mohitanchlia,14/Jan/16 07:52,26/Sep/16 23:08,22/Mar/23 15:10,15/Jul/16 15:35,,,,,,,,,,,,,,security,,,,1,,,,,,"Server disconnects from the zookeeper with the following log, and logs are not indicative of any problem. It works without the security setup however. 

I followed the security configuration steps from this site: http://docs.confluent.io/2.0.0/kafka/sasl.html

In here find the list of principals, logs and Jaas file:

1) Jaas file 
KafkaServer {
    com.sun.security.auth.module.Krb5LoginModule required

    useKeyTab=true
    storeKey=true
    keyTab=""/mnt/kafka/kafka/kafka.keytab""
    principal=""kafka/10.24.251.175@EXAMPLE.COM"";
};

Client {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    storeKey=true
    keyTab=""/mnt/kafka/kafka/kafka.keytab""
    principal=""kafka/10.24.251.175@EXAMPLE.COM"";
};


2) Principles from krb admin

kadmin.local:  list_principals
K/M@EXAMPLE.COM
kadmin/admin@EXAMPLE.COM
kadmin/changepw@EXAMPLE.COM
kadmin/ip-10-24-251-175.us-west-2.compute.internal@EXAMPLE.COM
kafka/10.24.251.175@EXAMPLE.COM
krbtgt/EXAMPLE.COM@EXAMPLE.COM

[2016-01-13 16:26:00,551] INFO starting (kafka.server.KafkaServer)
[2016-01-13 16:26:00,557] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-01-13 16:27:30,718] FATAL Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 6000
        at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:1223)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:155)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:129)
        at kafka.utils.ZkUtils$.createZkClientAndConnection(ZkUtils.scala:89)
        at kafka.utils.ZkUtils$.apply(ZkUtils.scala:71)
        at kafka.server.KafkaServer.initZk(KafkaServer.scala:278)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:168)
        at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
        at kafka.Kafka$.main(Kafka.scala:67)
        at kafka.Kafka.main(Kafka.scala)
[2016-01-13 16:27:30,721] INFO shutting down (kafka.server.KafkaServer)
[2016-01-13 16:27:30,727] INFO shut down completed (kafka.server.KafkaServer)
[2016-01-13 16:27:30,728] FATAL Fatal error during KafkaServerStartable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 6000
        at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:1223)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:155)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:129)
        at kafka.utils.ZkUtils$.createZkClientAndConnection(ZkUtils.scala:89)
        at kafka.utils.ZkUtils$.apply(ZkUtils.scala:71)
        at kafka.server.KafkaServer.initZk(KafkaServer.scala:278)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:168)
        at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
        at kafka.Kafka$.main(Kafka.scala:67)
        at kafka.Kafka.main(Kafka.scala)
[2016-01-13 16:27:30,729] INFO shutting down (kafka.server.KafkaServer)
""server.log"" 156L, 6404C                                                           ",RHEL 6,AZENEJJA@bouyguestelecom.fr,liuxinjian,mohitanchlia,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3090,,,,,,,,,,,KAFKA-3090,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Sep 26 15:08:44 UTC 2016,,,,,,,,,,"0|i2r9tj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"15/Jan/16 01:53;mohitanchlia;I enabled debug and still not much info:

Forwardable Ticket true
Forwarded Ticket false
Proxiable Ticket false
Proxy Ticket false
Postdated Ticket false
Renewable Ticket false
Initial Ticket false
Auth Time = Thu Jan 14 19:44:43 EST 2016
Start Time = Thu Jan 14 19:44:43 EST 2016
End Time = Fri Jan 15 19:44:43 EST 2016
Renew Till = null
Client Addresses  Null . (org.apache.zookeeper.Login)
[2016-01-14 19:44:28,212] INFO TGT valid starting at:        Thu Jan 14 19:44:43 EST 2016 (org.apache.zookeeper.Login)
[2016-01-14 19:44:28,212] INFO TGT expires:                  Fri Jan 15 19:44:43 EST 2016 (org.apache.zookeeper.Login)
[2016-01-14 19:44:28,213] INFO TGT refresh sleeping until: Fri Jan 15 15:53:07 EST 2016 (org.apache.zookeeper.Login)
[2016-01-14 19:44:28,223] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will attempt to SASL-authenticate using Login Context section 'Client' (org.apache.zookeeper.ClientCnxn)
[2016-01-14 19:44:28,231] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2016-01-14 19:44:28,232] INFO Accepted socket connection from /127.0.0.1:53042 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2016-01-14 19:44:28,233] DEBUG Session establishment request sent on localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2016-01-14 19:44:28,242] DEBUG Session establishment request from client /127.0.0.1:53042 client's lastZxid is 0x0 (org.apache.zookeeper.server.ZooKeeperServer)
[2016-01-14 19:44:28,244] INFO Client attempting to establish new session at /127.0.0.1:53042 (org.apache.zookeeper.server.ZooKeeperServer)
[2016-01-14 19:44:28,248] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2016-01-14 19:44:28,255] DEBUG Processing request:: sessionid:0x15242bd63420000 type:createSession cxid:0x0 zxid:0x1 txntype:-10 reqpath:n/a (org.apache.zookeeper.server.FinalRequestProcessor)
[2016-01-14 19:44:28,261] DEBUG sessionid:0x15242bd63420000 type:createSession cxid:0x0 zxid:0x1 txntype:-10 reqpath:n/a (org.apache.zookeeper.server.FinalRequestProcessor)
[2016-01-14 19:44:28,267] INFO Established session 0x15242bd63420000 with negotiated timeout 6000 for client /127.0.0.1:53042 (org.apache.zookeeper.server.ZooKeeperServer)
[2016-01-14 19:44:28,270] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x15242bd63420000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2016-01-14 19:44:28,272] DEBUG ClientCnxn:sendSaslPacket:length=0 (org.apache.zookeeper.client.ZooKeeperSaslClient)
[2016-01-14 19:44:28,273] DEBUG Received event: WatchedEvent state:SyncConnected type:None path:null (org.I0Itec.zkclient.ZkClient)
[2016-01-14 19:44:28,273] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2016-01-14 19:44:28,273] DEBUG Leaving process event (org.I0Itec.zkclient.ZkClient)
[2016-01-14 19:44:28,274] DEBUG saslClient.evaluateChallenge(len=0) (org.apache.zookeeper.client.ZooKeeperSaslClient)
[2016-01-14 19:44:28,301] DEBUG Responding to client SASL token. (org.apache.zookeeper.server.ZooKeeperServer)
[2016-01-14 19:44:28,302] DEBUG Size of client SASL token: 611 (org.apache.zookeeper.server.ZooKeeperServer)
[2016-01-14 19:44:28,302] ERROR cnxn.saslServer is null: cnxn object did not initialize its saslServer properly. (org.apache.zookeeper.server.ZooKeeperServer)
[2016-01-14 19:44:28,304] ERROR SASL authentication failed using login context 'Client'. (org.apache.zookeeper.client.ZooKeeperSaslClient)
---

kerberos server seems to show a successful exchange of the ticket:

Jan 15 15:39:44 ip-10-241-251-175.us-west-2.compute.internal krb5kdc[9767](info): AS_REQ (6 etypes {18 17 16 23 1 3}) 10.241.251.217: ISSUE: authtime 1452890384, etypes {rep=18 tkt=18 ses=18}, kafka/10.241.251.217@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
Jan 15 15:39:44 ip-10-241-251-175.us-west-2.compute.internal krb5kdc[9767](info): TGS_REQ (6 etypes {18 17 16 23 1 3}) 10.241.251.217: ISSUE: authtime 1452890384, etypes {rep=18 tkt=18 ses=18}, kafka/10.241.251.217@EXAMPLE.COM for zookeeper/localhost@EXAMPLE.COM
;;;","15/Jul/16 15:15;liuxinjian;is anyone working on this issue?;;;","15/Jul/16 17:39;liuxinjian;Hi,
   could you pls tell me the version get this fixed?;;;","15/Jul/16 17:49;omkreddy;[~liuxinjian] There is no kafka issue. This looks like config error from the issue reporter. If you have any specific issue/error, post it on kafka user mailing list.
;;;","15/Jul/16 18:20;liuxinjian;Thanks for replying. How can i post issues on kafka user mailing list. I am new here.
:);;;","15/Jul/16 18:26;omkreddy;Subscribe to user mailing list.   Details are here: http://kafka.apache.org/contact.html
;;;","18/Jul/16 11:13;liuxinjian;Thanks Manikuma. That helps;;;","26/Sep/16 23:08;AZENEJJA@bouyguestelecom.fr;Hello,

Have you find any solution for Kafka connection error.
I would like to configure Kafka to connect  on sasl zookeeper.

There in my error message :

Using builtin default etypes for default_tkt_enctypes
default etypes for default_tkt_enctypes: 17 16 23 1 3.
                [Krb5LoginModule] authentication failed
Checksum failed
[2016-09-26 16:30:13,159] WARN SASL configuration failed: javax.security.auth.login.LoginException: Checksum failed Will continue connection to Zookeeper server without SASL authentication, if Zookeeper server allows it. (org.apache.zookeeper.ClientCnxn)

Thanks a lot for your help,
Sincerely,

Azeddine


________________________________

L'intégrité de ce message n'étant pas assurée sur internet, la société expéditrice ne peut être tenue responsable de son contenu ni de ses pièces jointes. Toute utilisation ou diffusion non autorisée est interdite. Si vous n'êtes pas destinataire de ce message, merci de le détruire et d'avertir l'expéditeur.

The integrity of this message cannot be guaranteed on the Internet. The company that sent this message cannot therefore be held liable for its content nor attachments. Any unauthorized use or dissemination is prohibited. If you are not the intended recipient of this message, then please delete it and notify the sender.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replicas get ahead of leader and fail,KAFKA-2143,12823502,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,eapache,eapache,24/Apr/15 02:17,10/Feb/17 13:02,22/Mar/23 15:10,29/Jan/16 12:20,0.8.2.1,,,,,,0.9.0.1,,,,,,,replication,,,,8,,,,,,"On a cluster of 6 nodes, we recently saw a case where a single under-replicated partition suddenly appeared, replication lag spiked, and network IO spiked. The cluster appeared to recover eventually on its own,

Looking at the logs, the thing which failed was partition 7 of the topic {{background_queue}}. It had an ISR of 1,4,3 and its leader at the time was 3. Here are the interesting log lines:

On node 3 (the leader):
{noformat}
[2015-04-23 16:50:05,879] ERROR [Replica Manager on Broker 3]: Error when processing fetch request for partition [background_queue,7] offset 3722949957 from follower with correlation id 148185816. Possible cause: Request for offset 3722949957 but we only have log segments in the range 3648049863 to 3722949955. (kafka.server.ReplicaManager)
[2015-04-23 16:50:05,879] ERROR [Replica Manager on Broker 3]: Error when processing fetch request for partition [background_queue,7] offset 3722949957 from follower with correlation id 156007054. Possible cause: Request for offset 3722949957 but we only have log segments in the range 3648049863 to 3722949955. (kafka.server.ReplicaManager)
[2015-04-23 16:50:13,960] INFO Partition [background_queue,7] on broker 3: Shrinking ISR for partition [background_queue,7] from 1,4,3 to 3 (kafka.cluster.Partition)
{noformat}

Note that both replicas suddenly asked for an offset *ahead* of the available offsets.

And on nodes 1 and 4 (the replicas) many occurrences of the following:
{noformat}
[2015-04-23 16:50:05,935] INFO Scheduling log segment 3648049863 for log background_queue-7 for deletion. (kafka.log.Log) (edited)
{noformat}

Based on my reading, this looks like the replicas somehow got *ahead* of the leader, asked for an invalid offset, got confused, and re-replicated the entire topic from scratch to recover (this matches our network graphs, which show 3 sending a bunch of data to 1 and 4).

Taking a stab in the dark at the cause, there appears to be a race condition where replicas can receive a new offset before the leader has committed it and is ready to replicate?",,abraithwaite,akirillov,becket_qin,bobrik,boniek,BrickXu,bugzmanov,cagatayk,capricornius,cpsoman,eapache,ewencp,fullung,githubbot,guozhang,hakon,hariprasad kuppuswamy,innopre,jbrosenberg@gmail.com,junrao,kzadorozhny-tubemogul,mathieu.filotto,mazhar.shaikh.in,omnomnom,ottomata,snd,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2165,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Feb 10 04:59:39 UTC 2017,,,,,,,,,,"0|i2doc7:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"31/Jul/15 07:02;bugzmanov;I would like to add that we are experiencing this issue quite often. 
And the situation get worse when we have configs like this

replication factor: 2
unclean.leader.election.enable: true 

This leads to loss of a whole partition in case of two network glitches happening in a row. 

The failure scenario looks like this:
we have replica.lag.max.messages: 4000 so I'm guessing follower is always little bit behind leader for high volume topic (which means leader has a larger offset value than the follower)

1) Broker A (leader) has committed offset up-to 5000 
2) Broker B (follower) has committed offset up to 3000 (he is still in ISR because of  replica.lag.max.messages)
***network glitch happens***
3) Broker B becomes a leader, Broker A becomes a follower
4) Broker A (follower) asks leader for messages starting from 5000 
5) Broker A (follower)  receives message that this is invalid offset (Broker B has only 3000) and drops partition to 0
***network glitch happens***
6) Broker A becomes a leader (unclean election), Broker B becomes a follower
7) Broker B (follower) ask leader for messages starting from 3000
8) Broker B (follower) receives message that this is invalid offset (Broker A has only 0) and drops partition to 0

As a result we lost partition because of 2 network glitches. 

And if the configs are 
replication factor: 2
unclean.leader.election.enable: false (!)

the scenario repeats up to 5th step, but then Broker A got kicked out of ISR  and unclean election is not happening. ;;;","01/Aug/15 12:08;becket_qin;Hmm, with current design when the follower got OffsetOutOfRangeException during fetch, and if *leader's log end offset is smaller than follower's log end offset*, follower will not truncate to zero but the current leader's log end offsets. That means in step (5), broker A should start to fetch from offset 3000 instead of drop to 0 unless broker B really have nothing.

However, if the follower's log end offsets is smaller than the leader's log end offsets but we received offset out of range exception. We assume it was because the follower's log end offsets is too small and behind the earliest available offset of leader. But it might not necessarily be true, because we are fetching the latest offset again after we receive the exception. So it is possible that when the exception was returned, follower was ahead of the leader, but when it tries to handle the exception, since the new leader has got some new messages appended, the follower is now behind the leader. In that case, the follower will truncate its log to the log start offset of leader, which is the problem you described.

I think what happened is as below:

1) Broker A (leader) has committed offset up-to 5000
2) Broker B (follower) has committed offset up to 3000 (he is still in ISR because of replica.lag.max.messages)
***network glitch happens***
3) Broker B becomes a leader, Broker A becomes a follower
4) Broker A fetch from Broker B and got an OffsetOutOfRangeException.
4.1) Broker B got some new message and its log end offset become 6000.
4.2) Broker A tries to handle the Exception so it checks the log end offset on broker B and found it is greater than broker A's log end offset so it truncate itself to the starting offset of Broker B.

And the rest is pretty what you described.

By design at step (3) when Broker A become follower, it will truncate its log to its high watermark, which should be 3000. There is a possible related issue KAFKA-2334, which might make 3000 not the real high watermark on Broker B. And that issue triggered the offset out of range in step (4).

So it looks to me KAFKA-2334 and the ReplicaFetcherThread bug together caused the issue. I'll take both of the issues and see if they can be solved together.;;;","03/Aug/15 10:31;becket_qin;Actually I realized KAFKA-2334 is orthogonal to this issue. I submitted patch for this ticket and will leave KAFKA-2334 to be solved separately.;;;","06/Aug/15 08:51;wushujames;I'm trying to understand part of [~bugzmanov]'s description. If unclean.leader.election.enable=false, then in Step 5, as you say, Broker A is kicked out of the ISR list.

What happens, then, to the messages 3000-5000, that were originally in Broker A? Are they just lost?

What was the producer settings for request.required.acks (old producer) or acks (new producer) in this scenario? Was it 0 or 1? If it was -1 (old producer) or ""all"" (new producer), is it possible for the replica lag to get that large?;;;","06/Aug/15 12:33;becket_qin;In that case, yes, messages 3000-5000 will be lost. If producer is not producing with acks=-1, that is the expected behavior. If acks=-1, as long as producer got callback from broker, that means the message has been appended to all the brokers in ISR (NOT all the replicas!)

Here is a slide describing how to avoid data loss if you are interested:
http://www.slideshare.net/JiangjieQin/no-data-loss-pipeline-with-apache-kafka-49753844;;;","06/Aug/15 13:15;wushujames;Thanks [~becket_qin]. [~ewencp] sent me that slidedeck of yours. I added all your suggested settings to my team's ""Kafka recommended settings"" wiki. :)

Even with ack=-1, I think it's still possible for a replica to lag behind the leader by 2000 messages, right? It would be lagging behind by 2000 messages that were produced but not-yet-acknowledged. Not sure if losing those would count as message-loss, since they weren't actually ack'd?

replica.lag.max.messages is a broker-level config setting, not a topic level config setting. I think that means that it's hard to find a setting that works for high-volume topics and low-volume topics, right?

And... a bit of Googling around, and I think my observation is the exact thing that inspired https://cwiki.apache.org/confluence/display/KAFKA/KIP-16+-+Automated+Replica+Lag+Tuning and  http://www.confluent.io/blog/hands-free-kafka-replication-a-lesson-in-operational-simplicity/, right?

Is it possible for broker to be in the ISR for one topic, and to be out of the ISR for another topic?;;;","07/Aug/15 03:06;ewencp;[~wushujames] I think one easy way for a broker to be in ISR for one topic and out of ISR for another is a partition -- if topic A has broker 1 as leader and topic B has broker 2 as leader, then broker 3 replicating A and B could be in ISR for A, but unable to replicate data for B if there is a partition between brokers 1 and 3.;;;","11/Aug/15 02:04;githubbot;GitHub user becketqin opened a pull request:

    https://github.com/apache/kafka/pull/129

    KAFKA-2143: fix replica offset truncate to beginning during leader migration.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/becketqin/kafka KAFKA-2143

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/129.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #129
    
----
commit 71f8a4716e1f0b4fc2bd88aa30fe38aef8a9f92e
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2015-08-03T02:22:02Z

    Fix for KAFKA-2134, fix replica offset truncate to beginning during leader migration.

----
;;;","04/Sep/15 08:41;junrao;[~becket_qin], since before step (3), both A and B are in ISR, the last committed offset in A can't be larger than 3000. So, in step (3), if A becomes a follower, it has to first truncate its log to last committed offset before fetching. So, at that point, A's fetch offset can't be larger than 3000 and therefore won't be out of range.

The following is a alternative scenario that can cause this.

1) Broker A (leader) receives messages to 5000
2) Broker B (follower) receives messages to 3000 (it is still in ISR because of replica.lag.max.messages)
3) For some reason, B is dropped out of ISR.
4) Broker A (the only one in ISR) commits messages to 5000.
5) For some reason, Broker A is considered dead and Broker B is live.
6) Broker B is selected as the new leader (unclean leader election) and is the only one in ISR.
7) Broker A is considered live again and starts fetching from 5000 (last committed offset) and gets OffsetOutOfRangeException.
8) In the mean time, B receives more messages to offset 6000.
9) Broker A tries to handle OffsetOutOfRangeException and finds out leader B's log end offset is now larger than its log end offset and truncates all its log.

Your patch reduces the amount of the data that Broker A needs to replicate in step 9, which is probably fine. However, we probably should first verify if this is indeed what's happening since it seems that it should happen rarely. Also, KAFKA-2477 reports a similar issue w/o any leadership change. So, may be there is something else that can cause this.;;;","04/Sep/15 08:54;becket_qin;[~junrao], you are right. I realized there should be unclean leader election in this case. I'll check the code further to see if there is any finding for KAFKA-2477.;;;","15/Dec/15 04:36;ottomata;I'd like to add that Wikimedia is experiencing this as well.  It only started happening to us recently when we started producing to Kafka via a PHP process serving a web request.  This process is short lived, so only connects to Kafka in order to produce a single message, and then disconnects.  The only topic that this happens to is the one that this PHP process produces to.

Everything recovers as it should, but something is definitely wrong here.  Why is a follower trying to consume an offset ahead of what the leader has?

We're running 0.8.2.1 (with the snappy compression bugfix backported).;;;","15/Dec/15 07:52;becket_qin;[~ottomata], KAFKA-2477 is a more likely cause. You may want to take a look at that.;;;","29/Jan/16 12:19;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/129
;;;","29/Jan/16 12:20;guozhang;Issue resolved by pull request 129
[https://github.com/apache/kafka/pull/129];;;","30/Jan/16 01:48;becket_qin;Thanks, [~guozhang]. I almost forgot I had this ticket :);;;","15/Apr/16 12:31;jbrosenberg@gmail.com;Hello, I recently experienced this issue, as described in the original description above.  We are running 0.8.2.2.
Note, in the original description above (and in my case as well), there was no evidence of a network glitch, and no evidence of any partition leadership change.  So, I'm concerned whether the discussion that follows in this ticket (which describes network glitches and leadership changes almost exclusively) really addressed the original issue as reported (and my recent observation of this as well).

Can someone comment on this please?  [~becket_qin];;;","15/Apr/16 12:44;jbrosenberg@gmail.com;After looking at KAFKA-2477, I think that is the actual issue reported in this ticket (as opposed to the unrelated issue the first commenter raised), and I see that KAFKA-2477 seems to have been fixed.  So upgrading to 0.9.X is the thing to do, it would appear.;;;","10/Feb/17 12:59;mathieu.filotto;Is the upgrade the only option ?
Is 0.10 upgrade working too ?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Commit thread, ReplicaFetcherThread for intra-cluster replication",KAFKA-46,12514683,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,junrao,,20/Jul/11 05:32,02/Jun/12 04:58,22/Mar/23 15:10,02/Jun/12 04:58,,,,,,,0.8.0,,,,,,,,,,,0,,,,,,We need to implement the commit thread at the leader and the fetcher thread at the follower for replication the data from the leader.,,jkreps,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-302,,KAFKA-50,,,,,,,,,,,,,,,,,,,,,,,,"04/May/12 10:55;nehanarkhede;kafka-46-draft.patch;https://issues.apache.org/jira/secure/attachment/12525557/kafka-46-draft.patch","19/May/12 04:28;nehanarkhede;kafka-46-v1.patch;https://issues.apache.org/jira/secure/attachment/12528144/kafka-46-v1.patch","26/May/12 09:59;nehanarkhede;kafka-46-v2.patch;https://issues.apache.org/jira/secure/attachment/12529841/kafka-46-v2.patch","31/May/12 03:00;nehanarkhede;kafka-46-v3.patch;https://issues.apache.org/jira/secure/attachment/12530254/kafka-46-v3.patch","01/Jun/12 09:42;nehanarkhede;kafka-46-v4.patch;https://issues.apache.org/jira/secure/attachment/12530496/kafka-46-v4.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,67069,,,Fri Jun 01 01:42:01 UTC 2012,,,,,,,,,,"0|i09m7r:",54032,,,,,,,,,,,,,,,,,,,,"07/Feb/12 05:48;prashanth.menon;Should this be broken down into two sub tasks: One for the commiting thread on the leader and one for the fetcher thread on the follower?;;;","23/Feb/12 02:19;junrao;Some notes on the implementation:

1. If required_acks for a produce request is not 0 or 1, the commit thread will put the request in a DelayedQueue and adds it to a watch list for that topic/partition (similar implementation as long poll in kafka-48).
2. There will be an ""offset watcher"" per topic/partition. The watcher fires everytime a follower in the in-sync set advances the offset. Every time the watcher fires, it checks from the head of watcher list and see if any produce request can be satisfied on this partition. If so, marks this partition as satisfied, if all partitions of the produce requests are satisfied, dequeue the request an send back the ack. 
3. How to add/delete follower from in-sync set? We can run a background insync-check thread that does the following:
for each topic/partition
  get and save the offset of each partition of the leader replica
  wait for KeepInSyncTime
  check if any insync replica hasn't caught up to the saved offset, if so, drop it out of insync set (need to fire the corresponding offset watcher) 
  check if any replica (not in insync set) has caught up to the saved offset, if so, add it to insync set.

If we follow this approach, we can have 2 subtasks that implement ""offset watcher"" and insync-check thread. We can also have 1 separate subtask for the FetcherThread and another for the commit thread.
;;;","02/Mar/12 09:35;nehanarkhede;>> Should this be broken down into two sub tasks: One for the commiting thread on the leader and one for the fetcher thread on the follower? 

Lets not worry about that for now. I'll take care of this JIRA, once we resolve the other JIRAs. This one has many other dependencies.;;;","25/Mar/12 07:30;nehanarkhede;Started work on this, will upload a patch, once KAFKA-45 is resolved;;;","04/May/12 10:55;nehanarkhede;Attaching a draft patch for message replication. This is just to give a high level overview of the changes involved and is by no means ready to be committed. So no need for a detailed review. There are probably a few bugs lurking around. Since the changes are pretty significant, I was hoping to get some early feedback. 

1. Added ReplicaFetcherThread that reads data from the leader and appends to local replica log

2. Added highwatermark maintenance at the leader and the follower. The highwatermark is checkpointed in the partition directory in a file named highwatermark.

3. Added ISR maintenance logic on the leader. This involves possibly expanding the ISR while handling a fetch request from a follower. 

4. Also added ISRExpirationThread that tracks the highwatermark update time for all partitions that the leader owns and shrinks it if (hw update time + keep.in.sync.time.ms) < current time. 

5. Note that to get this patch going, I had to put in code to cover KAFKA-302. I would encourage a more detailed review for the becomeLeader() and becomeFollower() APIs. We would either like to check it in from this patch, or if Prashanth has some patch, review that one too. 

I will probably add v1 patch with unit tests early next week. 

Also, I would like to check this in parts, if possible. Starting with probably KAFKA-302, then the actual message replication logic. But that is open for discussion as well. 

;;;","07/May/12 05:52;prashanth.menon;I can comment on point 5, related to KAFKA-302.  After a first pass this is what I've got, let me know what you think:

1. In KafkaZooKeeper.leaderElection, if the replica isn't elected as the leader, it should issue a becomeFollower after reading who became the leader from ZK.
2. In KafkaServer.becomeLeader, the leader should probably update the ISR and CUR list by performing the same type of logic as the ISRExpirationThread does.  If the intention was to rely on the ISRET to perform this asynchronously, I think it'll need to be modified to update the partition's CUR list along with the ISR.
3. In ISRExpirationThread, you'll need to add the slowest partition back into the queue in every case.
4. It seems like there are two ways to update a leader replica's HW, either through Replica.hw itself or Partition.leaderHW.  To avoid confusion, can we simplify and provide only one API through which all clients to perform this?  The latter seems to do the same thing but just update the hw update time.  
5. Can the leo and hw methods in Replica make use of the isLocal method?  The logic is a little more clear this way, IMO.
6. In KafkaApis.handleFetchRequest, it looks the maybeAddReplicaToISR call is unncessary and is rolled into readMessageSets?  Any reason we need it there?
7. KafkaApis.readMessageSets should probably verify that the leader for the partition exists on the broker.

In general, I'm not entirely sold on the ISRExpirationThread.  From my point of view, there is a function that, given a partition, determines whether its ISR/CUR list needs to be updated in-memory and in ZK.  Right now, there is a single thread that uses a heap to pick off the partitions with the oldest update times, waits for expiry if necessary, then updates accordingly.  I'm wondering if it's possible instead to leverage a scheduled executor that appropriately schedules the execution of the above function on a given partition based on the same criteria (the partition's HW updated time); when the task actually executes, it's possible the hw would have moved, making the task an no-op.  The benefit there is simplicity, added concurrency and a slightly more accurate/real-time reflection of the ISR list in ZK meaning a possible reduction in message loss during leadership changes?;;;","09/May/12 09:51;nehanarkhede;Prashanth, 
Thanks for reviewing the patch, in detail. Like I mentioned earlier, this is just a draft patch and will clearly miss some details like you've pointed out. I'm looking more for high level feedback on data structures used, any ideas for refactoring etc.
;;;","09/May/12 10:04;junrao;Some comments on the draft.

High level:
1. We should consider whether to have 1 HW checkpoint file per partition vs 1 HW checkpoint file for all partitions. The benefit of the latter is fewer file writes during checkpoint and fewer file reads during broker startup. Also, to avoid corrupting the checkpointed file, we should probably first write the file to a tmp file and rename to the actual checkpointed file. This probably can be done in a separate jira.

2. The benefit of using an ISRExpirationThread is that it's relatively simple since there is 1 thread doing all the ISR expiration. One drawback I can see is that idle partitions are still constantly checked by the thread. This may or may not be a big concern.

Low level:
3. KafkaApis:
3.1 Agreed with #6 in Prashanth's comment. Probably don't need to call maybeAddReplicaToISR directly from handlFetchRequest.
3.2 A subtle issue is that we should probably wait until a (replica) fetch request is successful before updating the follower replica's LEO. This is because during an unclean failover (no live brokers in ISR), the offset of the first fetch request from a follower may not be valid.
3.3 We need to update ISR in ZK and in memory atomically since the ISR can be expanded and shrunk from different threads.

4. Partition:
4.1 We probably don't need to add reassignedReplicas in the patch and can add it later when we get to kafka-42, if necessary.
4.2 We probably don't need both catchUpReplicas and assignedReplicas since we can always derive one from another together with ISR.
4.3 Do we need to maintain a HashMap of <replica_id., Replica>, instead of a set of replicas for faster lookup? This may not be a big deal since the replica set is small.
4.4 Should we keep highWatermarkUpdateTime in Log where the HW is stored?

5. Replica:
5.1 leo(), if log is present, we should return l.leo not l.getHighwaterMark.

6. KafkaConfig: All follower related properties should be probably be prefixed with ""follower"".

7. Log:
7.1 recoverUptoLastCheckpointedHW(): if there are k+1 log segment files need to be truncated, we should delete the last k and truncate the first one.
;;;","19/May/12 04:28;nehanarkhede;Prashanth,

Regarding your high level comment -

If you use a scheduled thread pool executor to schedule every partition greadily, you would be spinning up a bunch of threads that might not do any work, since the priority of the items in the queue keeps changing. Also, you will need to change the priority of an already scheduled task, which might not be possible to do. What's more, if the threadpool maxes out, a partition that requires immediate ISR expiration might not get scheduled on time. 

I'm guessing it is unlikely that all the partitions on a node expire at the same time. Even if they do, it might take maybe a few seconds for the last partition to shrink its ISR, which is not a big deal. In reality, there would be very few partitions, maybe 1 or 2, that need to shrink their ISR due to slower followers. That's why a single thread seems to suffice for handling the ISR expiration for all partitions. 

Regarding your detailed review comments -

1. Fixed that
2. That is a good suggestion. I've attempted a refactoring, let me know if you have more feedback on it. The ISR thread updates the ISR in ZK AND in memory cache, where as the become leader API is passed in the latest ISR read from ZK and it just has to update its cache with that state, on becoming a leader. So, I wrapped up the cache + Zk update in an updateLeaderAndISR API in KafkaServer. This will be used by the ISR expiration thread. The become leader should not be updating anything in Zk, it should just be reading from Zk and updating its cache. 
3. The patch already does it at the end of the while loop. Or do you mean something else ?
5. Yes
6. The replica should be added to the ISR as soon as the fetch request is received by the server. I intended to add the replica to the ISR even if it might get ended up in the purgatory waiting for additional data. Ideally, would like to get rid of it from the readMessageSets() API.
7. Good point. Added that.

Jun

Regarding your high level comments -

1. Yes, I kept it simple in this patch, since the main goal is to get the message replication to work. Persisting all the HW in one file would definitely be a better approach and can be another JIRA
2. Idle partitions will cause one delete and one insert into the priority queue. It doesn't look like an issue, but could be resolved by adding a TTL to items in the queue. Idle partitions will expire from the queue and will be added back to the queue when the leader receives a produce request for that partition. However, I'd like to push that to later, since it does not improve correctness and does not look like a performance issue. 

Regarding your detailed review comments -

3.2 Good point. I think that is better too.
3.3 Yes, this is one of those “details” that I didn't include in the draft patch.
4.1 Removed it
4.2 Removed CUR
4.3 Kept it simple since replication factors that make sense in production are typically 3-5.
4.4 Yes, but when will it be used ?

5.1 Good catch !

6. That exists in the patch. Did I miss any ?
7. Good point. Fixed it
;;;","21/May/12 23:40;junrao;Thanks for the patch. Overall, a very encouraging patch given the complexity of this jira. Some comments:

From previous reviews:
Were 4.1 and 4.2 addressed in the patch? I still see CUR and reassignedReplicas.
For 4.4, I think highWatermarkUpdateTime can be used as described in 15.2 below.
For 6, I meant that all local variable names should also be prefixed with follower.

New review comments:
11. KafkaApis:
11.1 handleFetchRequest(): if the leader of one partition is not on this broker, we reject the whole request. Ideally, we should just send the error code for that partition in the response and fulfill the rest of the request. 
11.2 handleFetchRequest() and readMessageSets(): If the leader is not on this broker, we should probably return a new type of error like NotLeaderException, instead of using InvalidPartionException or throwing IllegalStateException. 
11.3 readMessageSets(): add a comment of what -1 means for replicaId

12. ReplicaManager:
12.1 remove unused imports
12.2 maybeIncrementLeaderHW(): if(newHw < oldHw) should be if(newHw > oldHw)
12.3 We will need to either synchronize the methods in this class or use ConcurrentHashMap for allReplicas since allReplicas can be read and updated concurrently.

13. Replica:
13.1 hw(): to be consistent, we should probably throw IllegalStateException, instead of InvalidPartitionException.

14. KafkaServer:
14.1 There are a couple of TODOs. Will they be addressed in this jira or separate jiras?

15. ISRExpirationThread:
15.1 It seems that when the time expires, we always update the ISR. We should only update ISR if it actually shrinks.
15.2 Currently, we take a replica out of ISR if its LEO is less than leaderHW after keepInSync time. We probably should use the following condition:
  leaderHW - r.leo > keepInSyncBytes || currentTime - r.highWatermarkUpdateTime > keepInSyncTime
  The first condition handles a slow follower and the second condition handles a stuck follower.
15.3 I think we can potentially get rid of the inner while loop by putting all the logic when time expires in a if statement and the awaitUtil part in the else clause of the if statement.
15.4 Also, instead of using a priority queue and keep adding and deleting partitions into the queue, would it be simpler to have the thread just check the isInsyncCondition for each partition every keepInSyncTime?

16. LogDisk: recoverUptoLastCheckpointedHW(): 
16.1 The second condition in
          segments.view.find(segment =>  lastKnownHW >= segment.start && lastKnownHW < segment.size) 
       seems incorrect. It seems that you want to use ""lastKnownHW < segment.messageSet.getEndOffset""
16.2 The files of all deleted segments should be deleted like that in LogManager.cleanupExpiredSegments().

17. LogOffsetTest:
17.1 There is no need to keep testEmptyLogs(), since we have a test that covers fetching from a non-existing topic using SimpleConsumer.

18. PrimitiveApiTest:
18.1 testConsumerNotExistTopic(): we probably shouldn't create the topic in this case.

19. ProducerTest:
19.1 testZKSendToNewTopic(): Which should fix the comment that says ""Available partition ids should be 0, 1, 2 and 3"" since there is only 1 partition created.

20. ReplicaFetchTest:
20.1 Since the test is already using in-memory log, we can remove TODO in testReplicaFetcherThread().
20.2 testReplicaFetcherThreadI(): Instead of sleeping and then checking log.get.getLogEndOffset, could we create a utility method that keeps checking until LEO reaches certain value up to a certain max wait time? Maybe we should make a more general util that waits up to a certain amount of time until a condition is satisfied. 
;;;","23/May/12 13:29;jkreps;Comments
Some of these we discussed in person but I wanted to post them here for anyone else following along. A number of these are really just structural or naming comments. When we get closer to final form I will do a pass on trying to understand all the logic and see if I can find any corner cases, but I haven't done that yet. As a result I am not really sure if I understand everything I am commenting on, so take it all with a grain of salt.
 
1. This patch pays really good attention to code structure and testability which is awesome since we are adding gobs of hard logic. Nice to see things getting cleaner as we do this.
2. For some reason I preferred just having Log instead of DiskLog and MemoryLog. I feel like doing it twice tends to lead to similar logic in both. I do like the idea of lightening unit tests. I wonder if a helper method to set up a log wouldn't be good enough, though? Not sure if this is a rational preference or just inertia on my part, though, so feel free to ignore. If we do separate out a Log trait I feel we should clean up that interface a bit it is kind of a disaster right now (probably we should do that regardless).
3. Maybe HW mark should move out of Log since now it really indicates something about the state of other servers and Log is meant to be just a simple stand alone log implementation.
4. I think expanding out some of the acronyms in public methods would be nice: i.e. highWatermark and logEndOffset. Having a concise local variable name is helpful but for the poor person trying to learn the code i think the slightly more verbose name is helpful. If you prefer the more concise naming then just having good javadoc that explains the abbreviations would be good.
5. Consider making Replica just be a dumb pojos (posos?) and move the ReplicaFetcherThread elsewhere.
6. We currently have Partition and BrokerPartitionInfo. We should clarify why both of these and make the naming make sense. To me a partition is logically just (topic, partId). I think BrokerPartitionInfo is really a bit hard to understand, though that is unrelated to this patch. Partition is more like the broker's information about replicas of that partition. Also both Partition and Replica are in the cluster package which was originally shared by client and server. Now with all the additional stuff this is really part of the server only, right? Probably we should change the package name...?
7. I sent a separate email on setters/getters. I think overall there area a lot of setter/getter methods. We should pick a style for these and go with that uniformly (we haven't been consistent so far). 
8. I think we should figure out a general strategy for managing the zookeeper interactions. I think it is wise to wrap up the zookeeper dependency but having everything in one class is too much. Maybe the way to go is to have generic ZkUtils and reusable infra like ZkQueue and then split KafkaZookeeper into the logical functions it covers.
9. For the config I recommend the prefix ""replication"" or ""replica"" instead of ""follower"" (e.g. replication.socket.timeout.ms), I think this is more clear to someone who hasn't read about the internals of our replication design and doesn't know the terminology.
10. A bit of internals have spilled into KafkaServer, such as locking, ISR management, etc. I think KafkaServer should just interact with the main subsystems of kafka in a very abstract way. I think the core problem is that we need to think more about the functionality and API of ReplicaManager. To my mind the replica manager should be the one running the ISR maintence, doing its own locking, etc. To me the main subsystems are (1) logs managed by the LogManager, (2) the network layer wrapped up by SocketServer, (3) the request processor pool (4) and now the ReplicaManager or ReplicationManager or whatever we want to call it.
11. ISRMaintenceThread--I think you are right that we will need to be very prompt about handling ISR expiration since this is effectively part of our failure detection time. It might be good, though to just stick in the polling loop Jun suggested for now, and then come back to optimize it later (even though we almost certain will have to), just to reduce the scope in this iteration. 
12. Also make sure the ISR thread either uses the Utils.newThread helper or handles the common gotchas (thread name, set daemon properly, set uncaught exception handler). Also think through the details of the lifecycle.
13. We have a lot of threads that basically run in a loop and use an isRunning atomic boolean and count down latch. You added two but I think we had a few others. Consider factoring this out into a helper runnable that these can extend. Verifying the lifecycle details for each is kind of a pain and it pretty easy to either not cleanly shutdown all the threads or block indefinitely or whatever.
14. The changes in KafkaApis seem kind of brute forced. ensureLeaderOnThisBroker and the massive expansion of logic in readMessageSets seems like we are just brute forcing through this problem. We need to find a way to structure this into methods that make sense and don't reach into the internals of other parts of the system. readMessageSet is already doing crazy funky stuff that needs to be fixed. I think restructuring readMessageSet will help with some of the problems, and the rest can maybe be solved by pushing all the replica/leo/isr logic here into ReplicaManager. Basically the API level should just say ReplicaManager.leaderForPartition(id) as part of the request validation and ReplicaManager.recordFollowerPosition(...) and move all the other details out of the KafkaApis. Not sure if I understand this well enough for that to make sense...
15. We should always return the hw mark in the PartitionData, right? This way we can do monitoring on the consumers. Currently it looks like we only do this for replicas.
16. Name for ReplicaManager.makeSurePartitionExists and ReplicaManager.assurePartitionExists doesn't really call out the difference. I would recommend calling them getOrCreatePartition() and ensureExists()
17. Overall I would think through the public API for ReplicaManager. I think it may be possible to move much more replica/replication/partitioning logic under this classes wrapper and out of other parts of the system which would be good. ;;;","24/May/12 00:43;junrao;Jay's comments remind another thing:

21. The follower's HW should be min(follower LEO, leader HW). This is to handle the case that a follower is still catching up.;;;","26/May/12 09:59;nehanarkhede;Thanks for the great feedback ! This is probably the largest jira for KAFKA-50, I've done my best to include the review changes in this JIRA. I will file separate JIRAs to include other review suggestions. Let me attempt to describe the changes made in this patch -

1. Simplied the ISR maintenance logic to iterate through the partitions every keepInSyncTimeMs ms. I guess the overhead is O(n) for isr expiration and O(1) for replica fetch requests. This seems reasonable since keepInSyncTimeMs is expected to be in the order of several seconds and replica fetch requests are easily more frequent than that.
2. Fixed ISR expiration logic to remove a slow follower as well as a stuck follower from the ISR
2. Moved replication specific logic inside ReplicaManager and Partition. So KafkaApis and KafkaServer have minimum replication specific code
3. Removed InMemoryLog, I guess that was an over optimization
4. Kept the high watermarks in a separate file, will fix it in a separate JIRA to contain the changes in this JIRA. ;;;","26/May/12 10:08;nehanarkhede;Regarding Jun's comments -

4, 6: Done

New review comments:
11. KafkaApis:
11.1 Makes sense
11.2 Added a new exception class NotLeaderForPartitionException. We can improve the naming going forward.
11.3 Done

12. ReplicaManager:
12.1 Done
12.2 Good catch 
12.3 Ideally, I would like to get rid of allReplicas, maybe do it differently. I'm thinking of fixing this in another JIRA. Let me know if you prefer fixing it in this one.

13. Replica:
13.1 Done

14. KafkaServer:
14.1 Removed the TODOs. They are addressed.

15. ISRExpirationThread:
15.1 Done
15.2 I've included logic for handling slow and stuck followers, and unit tested it.
15.3 It has completely disappeared now.
15.4 Agreed

16. LogDisk: recoverUptoLastCheckpointedHW():
16.1 That's a good point.
16.2 Done

17. LogOffsetTest:
17.1 Deleted it

18. PrimitiveApiTest:
18.1 testConsumerNotExistTopic() Actually I'm not too sure this test makes sense in the replication branch. Is this testing that the server returns some meaningful error code if it receives a request for an unknown topic ? If yes, maybe we don't need a consumer to test that logic. I haven't fixed this test, maybe we can think more on what exactly we want to test here. 

19. ProducerTest:
19.1 testZKSendToNewTopic(): Done

20. ReplicaFetchTest:
20.1 Right
20.2 testReplicaFetcherThreadI(): That is a good suggestion. I'd like to clean up unit tests and add related helper APIs, maybe in another JIRA.;;;","26/May/12 10:15;jkreps;Indeed, this is replication! The rest of it is just a simple matter of handling failures and a little tooling. :-) Very nicely done.;;;","26/May/12 10:18;nehanarkhede;Jay,

Thanks for thinking through the code structure, I've included more refactoring changes in this patch. Some of the suggestions are orthogonal to this patch and I'd prefer to fix it in another JIRA, given the complexity of this patch. Maybe I can create a 'refactoring' JIRA after this one to cover some of these -

2. Makes sense. I guess that was an over optimization.
3. This is a good suggestion, al though would prefer keeping it to refactoring JIRA
4. Picked descriptive names
5. Somehow I like the idea of wrapping up enough logic inside Replica to figure out if it is a follower or leader. ReplicaFetcherThread inside Replica allows that. Al though, I'm not sure that is the best way to achieve it.
6. Yeah, probably something to think about. Will move it to the refactoring JIRA
7. I like Option 4 there, hoping that can be fixed in a separate JIRA
8. Yeah, I moved some zookeeper client access to ReplicaManager so that all replication specific logic can be moved there.
9. Changed configs to replication.*
11. Simplified the ISR expiration. Looks better now.
12. Hmm, Utils.newThread returns Thread, but I think it is useful to use some APIs specific to ReplicaFetcherThread like getIfFollowerAndLeader(). But I see your point here. Given a choice, it is always better to use a helper method. I set the daemon property and the thread handles all Throwables. 
13. Yeah, this is a good suggestion. This also fits in generic refactoring category that can be fixed separately.
14. This is another great suggestion. Please see the included patch if you like it. 
15. Fixed it
16. Fixed it
17. Yeah, this will keep changing with the v3 code. Will be good to keep this in mind though.

Overall, I liked your refactoring suggestions, and I might have been lazy to describe all of the changes I made here. Will really appreciate it if you can read through the new patch and suggest improvements. I'm fine with working through more in this patch itself, if you feel that works better. ;;;","26/May/12 10:28;nehanarkhede;Filed KAFKA-350 for improving the high watermark maintenance
Filed KAFKA-351 to cover the refactoring suggestions. 

Now, we need some serious system testing for all this code ! :-);;;","29/May/12 07:05;junrao;Thanks for patch v2. To help people review the code, I summarized the logic of handling the produce and fetch request on the server in this wiki: https://cwiki.apache.org/confluence/display/KAFKA/Handling+Produce+and+Fetch+Requests+in+KafkaApi

Some new comments:
21. ISRExpirationThread: It seems that this class is no longer used. Let's remove it.

22. Partition.getOutOfSyncReplicas(): The first condition doesn't seem to implement what's in the comment. It doesn't check the leader's leo update time. Also, the condition specified in the comment doesn't seem sufficient. Suppose that the leader gets 100 bytes of more data, after which no more data is coming. A follower gets the first 50 bytes and then stopped. The follower's leo has been updated after the leader's leo was last updated. However, we still need to take the follower out of ISR. How about changing the condition to: select replicas whose leo is less than the leo of leader and whose leo hasn't been updated for keepInsyncTime. 

23. ReplicaManager:
23.1 makeLeader(): remove comment ""also add this partition to the ISR expiration priority queue""
23.2 makeFollower(): If a follower switches leader, we should stop the old FetchThread before starting the new one.

24. Replica.leoUpdateTime(): use logEndOffsetUpdateTime to be consistent.

25. KafkaConfig: Let's keep the variable name and property name consistent. If we choose to use replication as the prefix for property name, use the same prefix for variable names.

26. KafkaServer: To be consistent, we should probably name becomeLeader and becomeFollower as makeLeader and makeFollower, respectively.

27. Log.recoverUptoLastCheckpointedHW(): not sure if comment 16.2 is addressed. Removed segments are not physically deleted.

28. ISRExpirationTest:
28.1 testISRExpirationForSlowFollowers(): the comment says set leo of remote replica to sth like 2, but the code set it to 4.
28.2 testISRExpirationForStuckFollowers() and testISRExpirationForSlowFollowers(): is Thread.sleep() really needed? testISRExpirationForMultiplePartitions() didn't seem to use Thread.sleep().

29. PrimitiveApiTest.testConsumerNotExistTopic(): I think this test is just to make sure that the client can get the error code on a non-existing topic.

30. TestUtils:follower.socket.timeout.ms is now renamed to replication.socket.timeout.ms
;;;","30/May/12 10:35;nehanarkhede;Updated patch to address Jun's suggestions -

1. Fixed the ISR expiration for stuck followers case
2. HW maintenance work is postponed to KAFKA-350
3. System test (KAFKA-341), that tests message replication without failures, works on this patch

More detailed comments -

21. Removed it

22. Partition.getOutOfSyncReplicas(): Good catch ! Fixed the logic and added another test case for this.

23. ReplicaManager: Done

24. Replica: Changed the name to logEndOffsetUpdateTime()

25. KafkaConfig: Changed the variable and config names to replica.*

26. KafkaServer: Well, become* makes sense on the entity that is changing its state (Replica), make*, I thought made sense on the actor (KafkaServer). But that is just a matter of personal taste :)

27. There are some nitty gritty details about HW maintenance that I would like to fix as part of KAFKA-350

28. ISRExpirationTest: Done

29. PrimitiveApiTest.testConsumerNotExistTopic(): I think the right fix is to throw a descriptive exception is UnknownTopicException when a client makes a produce/consume request for a topic that has never been created. Filed KAFKA-351 to fix it.

30. TestUtils:Fixed it;;;","31/May/12 04:32;junrao;+ 1 from me for patch v3. Let's see if there are more comments from others.

For 27, it's ok to resolve this in kafka-350. Could you update the jira so that we remember all the changes that need to be made? Ditto for kafka-351.;;;","01/Jun/12 09:30;nehanarkhede;Attaching an updated patch that includes the rebase changes from KAFKA-348

Also, updated the follow up JIRAs - KAFKA-350 and KAFKA-351;;;","01/Jun/12 09:42;junrao;+1 for patch v4.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Corrupt log files for segment.bytes values close to Int.MaxInt,KAFKA-1670,12745831,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,sriharsha,rberdeen,rberdeen,04/Oct/14 05:06,14/Oct/14 00:37,22/Mar/23 15:10,12/Oct/14 23:54,0.8.1.1,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"The maximum value for the topic-level config {{segment.bytes}} is {{Int.MaxInt}} (2147483647). *Using this value causes brokers to corrupt their log files, leaving them unreadable.*

We set {{segment.bytes}} to {{2122317824}} which is well below the maximum. One by one, the ISR of all partitions shrunk to 1. Brokers would crash when restarted, attempting to read from a negative offset in a log file. After discovering that many segment files had grown to 4GB or more, we were forced to shut down our *entire production Kafka cluster* for several hours while we split all segment files into 1GB chunks.

Looking into the {{kafka.log}} code, the {{segment.bytes}} parameter is used inconsistently. It is treated as a *soft* maximum for the size of the segment file (https://github.com/apache/kafka/blob/0.8.1.1/core/src/main/scala/kafka/log/LogConfig.scala#L26) with logs rolled only after (https://github.com/apache/kafka/blob/0.8.1.1/core/src/main/scala/kafka/log/Log.scala#L246) they exceed this value. However, much of the code that deals with log files uses *ints* to store the size of the file and the position in the file. Overflow of these ints leads the broker to append to the segments indefinitely, and to fail to read these segments for consuming or recovery.

This is trivial to reproduce:

{code}
$ bin/kafka-topics.sh --topic segment-bytes-test --create --replication-factor 2 --partitions 1 --zookeeper zkhost:2181
$ bin/kafka-topics.sh --topic segment-bytes-test --alter --config segment.bytes=2147483647 --zookeeper zkhost:2181
$ yes ""Int.MaxValue is a ridiculous bound on file size in 2014"" | bin/kafka-console-producer.sh --broker-list localhost:6667 zkhost:2181 --topic segment-bytes-test
{code}

After running for a few minutes, the log file is corrupt:

{code}
$ ls -lh data/segment-bytes-test-0/
total 9.7G
-rw-r--r-- 1 root root  10M Oct  3 19:39 00000000000000000000.index
-rw-r--r-- 1 root root 9.7G Oct  3 19:39 00000000000000000000.log
{code}

We recovered the data from the log files using a simple Python script: https://gist.github.com/also/9f823d9eb9dc0a410796",,guozhang,gwenshap,jkreps,junrao,rberdeen,sokeefe,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/14 03:20;sriharsha;KAFKA-1670.patch;https://issues.apache.org/jira/secure/attachment/12674372/KAFKA-1670.patch","05/Oct/14 06:28;sriharsha;KAFKA-1670.patch;https://issues.apache.org/jira/secure/attachment/12672956/KAFKA-1670.patch","05/Oct/14 11:17;sriharsha;KAFKA-1670_2014-10-04_20:17:46.patch;https://issues.apache.org/jira/secure/attachment/12672966/KAFKA-1670_2014-10-04_20%3A17%3A46.patch","07/Oct/14 00:48;sriharsha;KAFKA-1670_2014-10-06_09:48:25.patch;https://issues.apache.org/jira/secure/attachment/12673118/KAFKA-1670_2014-10-06_09%3A48%3A25.patch","08/Oct/14 04:39;sriharsha;KAFKA-1670_2014-10-07_13:39:13.patch;https://issues.apache.org/jira/secure/attachment/12673417/KAFKA-1670_2014-10-07_13%3A39%3A13.patch","08/Oct/14 04:49;sriharsha;KAFKA-1670_2014-10-07_13:49:10.patch;https://issues.apache.org/jira/secure/attachment/12673423/KAFKA-1670_2014-10-07_13%3A49%3A10.patch","08/Oct/14 09:39;sriharsha;KAFKA-1670_2014-10-07_18:39:31.patch;https://issues.apache.org/jira/secure/attachment/12673501/KAFKA-1670_2014-10-07_18%3A39%3A31.patch",,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Oct 13 16:37:24 UTC 2014,,,,,,,,,,"0|i20sc7:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"05/Oct/14 06:28;sriharsha;Created reviewboard https://reviews.apache.org/r/26346/diff/
 against branch origin/trunk;;;","05/Oct/14 06:32;sriharsha;This is caused by maybeRoll  not checking for any boundary conditions for Int overflow. ;;;","05/Oct/14 11:17;sriharsha;Updated reviewboard https://reviews.apache.org/r/26346/diff/
 against branch origin/trunk;;;","05/Oct/14 11:23;sriharsha;[~nehanarkhede] [~junrao] LogConfig default values doesn't match broker configuration defaults here https://kafka.apache.org/08/configuration.html
example
  SegmentSize = 1024 * 1024 (LogConfig)  and in broker log.segment.bytes	1024 * 1024 * 1024
and also MaxIndexSize
any reason for them not to be same ?;;;","06/Oct/14 07:37;junrao;The default value in LogConfig is just for unit test (so some smaller values may make sense). In the full logic, we always pick the broker level value as the default.;;;","07/Oct/14 00:48;sriharsha;Updated reviewboard https://reviews.apache.org/r/26346/diff/
 against branch origin/trunk;;;","07/Oct/14 06:55;gwenshap;I think we'll want to change the segment size variable to ""long"" and remove the 4GB limit (which seems rather low for modern systems).
This may make sense as a separate Jira since [~harsha_ch] patch is necessary in any case.
;;;","07/Oct/14 07:11;jkreps;Actually the reason for limiting the segments to 4GB (or possibly 2GB since we are using java ints) is to keep the index pointers into the file limited to 4 bytes which keeps the index files small (4 byte relative offset and 4 byte file position). Index file size and density is important since we hope to keep those cached to make lookups cheap. We should fix the variable to avoid overflow and even extend to unsigned ints but we probably can't allow arbitrarily large segment files very easily.

The reasoning at the time was basically that there is no particular reason to want very large segment files, and since we always do recovery from the beginning of the file having 10GB segments would cause other problems when you crashed and had to do recovery on hundreds of 10GB files.;;;","07/Oct/14 07:26;gwenshap;Makes sense. Thanks [~jkreps];;;","08/Oct/14 04:39;sriharsha;Updated reviewboard https://reviews.apache.org/r/26346/diff/
 against branch origin/trunk;;;","08/Oct/14 04:49;sriharsha;Updated reviewboard https://reviews.apache.org/r/26346/diff/
 against branch origin/trunk;;;","08/Oct/14 09:39;sriharsha;Updated reviewboard https://reviews.apache.org/r/26346/diff/
 against branch origin/trunk;;;","09/Oct/14 22:44;sriharsha;[~junrao] I updated the patch with ErrorMapping and client errors change. Can you please take a look when you get a chance. Thanks.;;;","09/Oct/14 23:09;junrao;Thanks for the latest patch. +1. Committed to both 0.8.2 and trunk.;;;","11/Oct/14 02:02;guozhang;Hi [~sriharsha] [~junrao] this patch causes some regression errors on system tests, including replication / mirror maker test suites (you can try reproduce it with 5001/2/3 easily).

The log entries I saw from the producer:
{code}
[2014-10-10 05:32:46,714] ERROR Error when sending message to topic test_1 with key: 1 bytes, value: 500 bytes with error: The request included message batch larger than the configured segment size on the server. (org.apache.kafka.client
s.producer.internals.ErrorLoggingCallback)
[2014-10-10 05:32:46,714] ERROR Error when sending message to topic test_1 with key: 1 bytes, value: 500 bytes with error: The request included message batch larger than the configured segment size on the server. (org.apache.kafka.client
s.producer.internals.ErrorLoggingCallback)
[2014-10-10 05:32:46,714] ERROR Error when sending message to topic test_1 with key: 1 bytes, value: 500 bytes with error: The request included message batch larger than the configured segment size on the server. (org.apache.kafka.client
s.producer.internals.ErrorLoggingCallback)
[2014-10-10 05:32:46,714] ERROR Error when sending message to topic test_1 with key: 1 bytes, value: 500 bytes with error: The request included message batch larger than the configured segment size on the server. (org.apache.kafka.client
s.producer.internals.ErrorLoggingCallback)
[2014-10-10 05:32:46,714] ERROR Error when sending message to topic test_1 with key: 1 bytes, value: 500 bytes with error: The request included message batch larger than the configured segment size on the server. (org.apache.kafka.client
s.producer.internals.ErrorLoggingCallback)
{code};;;","11/Oct/14 02:04;sriharsha;[~guozhang] Sorry will fix those.;;;","11/Oct/14 04:05;guozhang;No worries :) Let me know if you need more information from me.;;;","12/Oct/14 03:20;sriharsha;Created reviewboard https://reviews.apache.org/r/26606/diff/
 against branch origin/trunk;;;","12/Oct/14 03:29;sriharsha;[~guozhang] log.segment.bytes on systems is set to 10240 and producer's message batch size bigger than that causing the failures.
changed the configs to 20580. ran systems tests
========================================================
Total failures count : 0
========================================================

[~junrao] rethinking a bit , should we enforce producer's message batch size  less than config segment.size? 
instead on Log side if the current message batch size is greater than config segment.size broker should push as many messages  can fit into the current segment and roll the log for the rest of messages in the batch. ;;;","12/Oct/14 23:54;junrao;Thanks for the followup patch for system tests. +1 and committed to trunk and 0.8.2.

Yes, it's possible for the broker to break the message set into smaller chunks that fit in the configured log segment size. However, there may be some benefit to keep the original message set as a whole. For example, if the message set is compressed, this guarantees that either all or none of the messages in the set are replicated to the followers.;;;","14/Oct/14 00:37;guozhang;Verified that system test has recovered, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Poison Message,KAFKA-66,12514703,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,,,20/Jul/11 05:32,20/Jul/11 05:32,22/Mar/23 15:10,20/Jul/11 05:32,,,,,,,,,,,,,,,,,,0,,,,,,"Unfortunately I wasn't able to figure out exactly how I accomplished this, but somehow I managed to get one or more poison messages in my test topic using fairly simple single threaded SimpleProducer/SimpleConsumer code. In this state, I could see several hundreds of thousands of messages in the topic via JMX and adding new messages appeared to succeed from the API calls, however each add resulted in the following error: 

[2010-12-08 14:56:04,952] ERROR kafka.message.InvalidMessageException (kafka.network.Processor) 
kafka.message.InvalidMessageException 
at kafka.log.Log$$anonfun$append$1.apply(Log.scala:187) 
at kafka.log.Log$$anonfun$append$1.apply(Log.scala:185) 
at scala.collection.Iterator$class.foreach(Iterator.scala:631) 
at kafka.utils.IteratorTemplate.foreach(IteratorTemplate.scala:29) 
at scala.collection.IterableLike$class.foreach(IterableLike.scala:79) 
at kafka.message.MessageSet.foreach(MessageSet.scala:63) 
at kafka.log.Log.append(Log.scala:185) 
at kafka.server.KafkaRequestHandlers.handleProducerRequest(KafkaRequestHandlers.scala:56) 
at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$1.apply(KafkaRequestHandlers.scala:40) 
at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$1.apply(KafkaRequestHandlers.scala:40) 
at kafka.network.Processor.handle(SocketServer.scala:268) 
at kafka.network.Processor.read(SocketServer.scala:291) 
at kafka.network.Processor.run(SocketServer.scala:202) 
at java.lang.Thread.run(Thread.java:662) 

Additionally, no consumers were functional, they were all blocked and not draining the existing messages. Stopping the service did not get things healthy, but stopping and removing the logs fixed the problem. 

Not sure what the design intent is, but it would seem that failure to process a message internally within the server should cause the message to be rejected at the client layer.",As of master from DEC-7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,67463,,,2011-07-19 21:32:27.0,,,,,,,,,,"0|i15yrz:",242934,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Controller can hang on controlled shutdown with auto leader balance enabled,KAFKA-1305,12701385,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,sriharsha,jjkoshy,jjkoshy,14/Mar/14 08:08,17/May/16 21:51,22/Mar/23 15:10,14/Oct/14 03:32,,,,,,,0.8.2.0,,,,,,,,,,,1,,,,,,"This is relatively easy to reproduce especially when doing a rolling bounce.
What happened here is as follows:

1. The previous controller was bounced and broker 265 became the new controller.
2. I went on to do a controlled shutdown of broker 265 (the new controller).
3. In the mean time the automatically scheduled preferred replica leader election process started doing its thing and starts sending LeaderAndIsrRequests/UpdateMetadataRequests to itself (and other brokers).  (t@113 below).
4. While that's happening, the controlled shutdown process on 265 succeeds and proceeds to deregister itself from ZooKeeper and shuts down the socket server.
5. (ReplicaStateMachine actually removes deregistered brokers from the controller channel manager's list of brokers to send requests to.  However, that removal cannot take place (t@18 below) because preferred replica leader election task owns the controller lock.)
6. So the request thread to broker 265 gets into infinite retries.
7. The entire broker shutdown process is blocked on controller shutdown for the same reason (it needs to acquire the controller lock).

Relevant portions from the thread-dump:

""Controller-265-to-broker-265-send-thread"" - Thread t@113
   java.lang.Thread.State: TIMED_WAITING
	at java.lang.Thread.sleep(Native Method)
	at kafka.controller.RequestSendThread$$anonfun$liftedTree1$1$1.apply$mcV$sp(ControllerChannelManager.scala:143)
	at kafka.utils.Utils$.swallow(Utils.scala:167)
	at kafka.utils.Logging$class.swallowWarn(Logging.scala:92)
	at kafka.utils.Utils$.swallowWarn(Utils.scala:46)
	at kafka.utils.Logging$class.swallow(Logging.scala:94)
	at kafka.utils.Utils$.swallow(Utils.scala:46)
	at kafka.controller.RequestSendThread.liftedTree1$1(ControllerChannelManager.scala:143)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:131)
	- locked java.lang.Object@6dbf14a7
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)

   Locked ownable synchronizers:
	- None

...

""Thread-4"" - Thread t@17
   java.lang.Thread.State: WAITING on java.util.concurrent.locks.ReentrantLock$NonfairSync@4836840 owned by: kafka-scheduler-0
	at sun.misc.Unsafe.park(Native Method)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:811)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:842)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1178)
	at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:186)
	at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:262)
	at kafka.utils.Utils$.inLock(Utils.scala:536)
	at kafka.controller.KafkaController.shutdown(KafkaController.scala:642)
	at kafka.server.KafkaServer$$anonfun$shutdown$9.apply$mcV$sp(KafkaServer.scala:242)
	at kafka.utils.Utils$.swallow(Utils.scala:167)
	at kafka.utils.Logging$class.swallowWarn(Logging.scala:92)
	at kafka.utils.Utils$.swallowWarn(Utils.scala:46)
	at kafka.utils.Logging$class.swallow(Logging.scala:94)
	at kafka.utils.Utils$.swallow(Utils.scala:46)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:46)
	at kafka.Kafka$$anon$1.run(Kafka.scala:42)

...

""kafka-scheduler-0"" - Thread t@117
   java.lang.Thread.State: WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@1dc407fc
	at sun.misc.Unsafe.park(Native Method)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1987)
	at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:306)
	at kafka.controller.ControllerChannelManager.sendRequest(ControllerChannelManager.scala:57)
	- locked java.lang.Object@578b748f
	at kafka.controller.KafkaController.sendRequest(KafkaController.scala:657)
	at kafka.controller.ControllerBrokerRequestBatch$$anonfun$sendRequestsToBrokers$2.apply(ControllerChannelManager.scala:290)
	at kafka.controller.ControllerBrokerRequestBatch$$anonfun$sendRequestsToBrokers$2.apply(ControllerChannelManager.scala:282)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)
	at scala.collection.Iterator$class.foreach(Iterator.scala:631)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:161)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:194)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:80)
	at kafka.controller.ControllerBrokerRequestBatch.sendRequestsToBrokers(ControllerChannelManager.scala:282)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:126)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:612)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$17$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1119)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$17$$anonfun$apply$5.apply(KafkaController.scala:1114)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$17$$anonfun$apply$5.apply(KafkaController.scala:1114)
	at kafka.utils.Utils$.inLock(Utils.scala:538)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$17.apply(KafkaController.scala:1111)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$17.apply(KafkaController.scala:1109)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)
	at scala.collection.Iterator$class.foreach(Iterator.scala:631)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:161)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:194)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:80)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1109)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1088)
	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:125)
	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:344)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1088)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:323)
	at kafka.utils.KafkaScheduler$$anon$1.run(KafkaScheduler.scala:100)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:317)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:150)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:98)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.runPeriodic(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:204)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)

   Locked ownable synchronizers:
	- locked java.util.concurrent.locks.ReentrantLock$NonfairSync@4836840

	- locked java.util.concurrent.locks.ReentrantLock$NonfairSync@4918530

...

""ZkClient-EventThread-18-/kafka-shadow"" - Thread t@18
   java.lang.Thread.State: WAITING on java.util.concurrent.locks.ReentrantLock$NonfairSync@4836840 owned by: kafka-scheduler-0
	at sun.misc.Unsafe.park(Native Method)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:811)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:842)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1178)
	at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:186)
	at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:262)
	at kafka.utils.Utils$.inLock(Utils.scala:536)
	at kafka.controller.ReplicaStateMachine$BrokerChangeListener.handleChildChange(ReplicaStateMachine.scala:328)
	at org.I0Itec.zkclient.ZkClient$7.run(ZkClient.java:568)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
",,becket_qin,dmitrybugaychenko,eidi,guozhang,gwenshap,jbrosenberg@gmail.com,jjkoshy,jkreps,junrao,nehanarkhede,noslowerdna,sriharsha,stevenz3wu,TaoFeng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1699,,,,,,,,"13/Oct/14 07:49;sriharsha;KAFKA-1305.patch;https://issues.apache.org/jira/secure/attachment/12674439/KAFKA-1305.patch","10/Oct/14 23:51;sriharsha;KAFKA-1305.patch;https://issues.apache.org/jira/secure/attachment/12674192/KAFKA-1305.patch","13/Oct/14 22:30;sriharsha;KAFKA-1305_2014-10-13_07:30:45.patch;https://issues.apache.org/jira/secure/attachment/12674511/KAFKA-1305_2014-10-13_07%3A30%3A45.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,379731,,,Mon Mar 16 12:25:12 UTC 2015,,,,,,,,,,"0|i1tfg7:",380016,,junrao,,,,,,,,,,,,,,,,,,"15/Mar/14 05:13;guozhang;This is a similar issue as for KAFKA-1235. One alternative solution to kill both birds is to allow the sender thread jump out of the infinite retry if it realize that the destination broker is shutting down.;;;","01/May/14 05:10;noslowerdna;Is it recommended to not set both auto.leader.rebalance.enable=true and controlled.shutdown.enable=true?

If this issue is encountered, killing the hung broker process sounds like the only resolution. Would that cause any issues for the other brokers in the cluster?  Also, would it be problematic if the hung broker is not killed in a timely manner?;;;","01/May/14 22:34;junrao;Right, until this is fixed, don't turn set auto.leader.rebalance.enable and controlled.shutdown.enable to be true.;;;","05/Sep/14 05:50;guozhang;Moving out of  0.8.2 for now.;;;","21/Sep/14 08:45;becket_qin;I looked into this problem and it seems to me the issue is mainly because the default controller queue size was too small.
The problem flow is as below:
1. Controller 265 received controlled shutdown request
2. Controller 265 put leaderAndIsrRequest into controller message queue and responded to broker 265.
3. Broker 265 received respond from Controller 265, shutdown successfully and de-registerred itself form zk.
4. Controller 265 request send thread started to send leaderAndIsrRequests which are put in step 2 to the brokers. Since broker 265 has already shutdown, it will start infinite retry. At this moment, the controller message queue size will never decrease. (Thread t@113)
5. Scheduled preferred leader election started, grabbed the controller lock and was trying to put the LeaderAndIsr request into controller message queue. However, because the queue size is only 10, it could not finish but just blocking on the put method while still holding the controller lock. (Thread t@117)
6. Broker change listener on controller 265 was triggered because broker path change in step 3, it was trying to grab the controller lock and stop thread t@113, but failed to do that because thread t@117 was holding controller lock and waiting on the controller message queue.

Currently the controller message queue size is 10. IMO if we can increase the number to be 100 or even bigger, this problem won't happen again. Actually, in most time, the number of messages in the queue will be small even empty because there should not be too many controller messages. So increasing the queue size won't cause memory consumption to increase.;;;","23/Sep/14 00:38;guozhang;Thanks [~becket_qin] for the great findings. It seems to me that as long as the controller's channel manager is async, no matter how large is its queue the corner-case issue can still happen in (i.e. request blocked in the queue for brokers that is already shutdown but the ZK watcher not fired yet), and causing some chain of lock conflicts.

Currently the controller has multiple threads for admin commands, ZK listeners, scheduled operations (leader electioner), etc, which complicates the locking mechanism inside controller. After going through the code I think it would be better to refactor the controller as following:

1. Besides the async channel manager's sender thread, we use only a single controller thread and have a single working queue for the controller thread.
3. ZK fire handling logic determines the event (topic/partition/broker change, admin operation, etc), and put the task into the queue.
4. Scheduled task is also created periodically and put into the queue.
5. The controller did one task at a time, which do not need to compete locks on controller metadata.
6. Make the channel manager's queue size infinite and add a metric on monitoring its size.

With this the controller logic would be easier to read / debug, may also help KAFKA-1558. The downside is that since a single thread is used, it loses parallelism for controller task handling, and the unbounded channel queue may also be an issue (when there is a bug). But since controller tasks are usually rare in practice, this should not be an issue.;;;","29/Sep/14 08:35;junrao;Guozhang,

Yes, I agree that the controller code is getting complicated and it's probably worth a refactoring. A single threaded controller perhaps will make the logic simpler and easier to understand. There are operations like reassigning partitions that are time consuming though. Instead of blocking on those operations, do we want to use a purgatory to track them?

Since it may take time to completely fix this issue, I suggest that we just disable this feature in 0.8.2. Otherwise, people may turn it on and hit this issue. ;;;","30/Sep/14 09:00;guozhang;Yeah. Reassigning partitions would take time and hence better be handled in a purgatory, but then there are a couple more subtle issues we need to be careful with:

1. Upon condition (new replica caught up, etc) satisfied, shall we execute the rest of the logic in the satisfaction checking thread, which will then be a different thread, or just put the rest of the job back into the queue?

2. Related to 1), as a topic is undergoing partition reassignment or any other ""delayable"" operations, we need to disable other operations under these topics, right?

I agree that this is a rather big change and maybe we should push after 0.8.2.;;;","30/Sep/14 10:48;nehanarkhede;This is a good but potentially very large change. Basically controller functionality would need to be modeled as multi-step actions that require need arbitrary delay between each of the steps that constitute an action. As such the rest of the logic definitely needs to go back into the queue.  ;;;","03/Oct/14 11:59;sriharsha;[~nehanarkhede] Is this still planned for 0.8.2 release. ;;;","04/Oct/14 08:56;nehanarkhede;[~sriharsha] Depends :) Basically, my perspective is that if doing this correctly requires delaying 0.8.2 by a month, then let's push it to 0.8.3. If there is a small fix for the issue, then let's include it. IIRC, [~junrao] was going to take a stab at thinking if there is a small fix or not.;;;","06/Oct/14 11:14;junrao;Thinking about this a bit more. As a short term fix, I think Jiangjie's suggestion actually has a point. Basically, if a channel queue is full (since the target broker is down), a thread that tries to put a request into the queue will block while holding the controller lock. This essentially will stall the controller since it can't process any other events, which is bad. Now, imagine what if we make the channel queue unbounded. In this case, no thread will block on putting requests into the queue. So, if a broker is down, the controller will always be able to act on it, which will clear up the queue and remove the channel to the dead broker. The only down side is that if there are outstanding requests in a queue, new important requests may be delayed. This is not a big concern because in the common case, the channel queue shouldn't build up.

Sriharsha,

Could you do a bit of testing on this? Basically, set the default value of controller.message.queue.size to sth large (e.g., 10K). Create a cluster with a few K partitions per broker. Enable auto leader balancing and keep doing rolling bounces of the cluster (with controlled shutdown enabled) and see there is any issue. Ideally, we want to hit the case that the auto leader balancing happens concurrently with the controlled shutdown in the controller. So, you may want to play with leader.imbalance.check.interval.seconds.;;;","07/Oct/14 03:28;jkreps;FWIW, from my perspective being able to enable auto leader balancing would be a huge win. This is arguably the biggest operational ""gotcha"" today...;;;","07/Oct/14 03:48;noslowerdna;> from my perspective being able to enable auto leader balancing would be a huge win

We are running with auto leader balance enabled and controlled shutdown disabled. Given that they're currently mutually exclusive options, is controlled shutdown generally considered more valuable than auto leader balancing? If so, why is that?;;;","07/Oct/14 03:54;jkreps;Well I guess the point is that they shouldn't be mutually exclusive. So hopefully we can make them both be enabled by default.;;;","09/Oct/14 22:50;sriharsha;[~junrao] Ran into this issue when I am testing delete topics along while simultaneously running preferred replica leader election tool. I am running the above test you suggested will update with the results.;;;","10/Oct/14 06:45;sriharsha;[~junrao]  I ran the above test you suggested with leader.imbalance.check.interval.seconds set to 30 and controller.message.queue.size set 10000. With 5 brokers and 1500 topics with 3 partitons and 3 replication factor. I am able to run into a case where a broker prints ""Shutdown completed"" but the process still hangs. Running the test by setting controller.message.queue.size  to higher number.
Here is thread dump

Full thread dump Java HotSpot(TM) 64-Bit Server VM (24.65-b04 mixed mode):

""Attach Listener"" daemon prio=10 tid=0x00007f8860003000 nid=0x26cc waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Controller-4-to-broker-3-send-thread"" prio=10 tid=0x00007f884c049000 nid=0x26b2 waiting on condition [0x00007f83c99e0000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00000000d2be8008> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:121)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)

""Thread-2"" prio=10 tid=0x00007f8868005800 nid=0x26b1 waiting on condition [0x00007f83c98df000]
   java.lang.Thread.State: TIMED_WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00000000d2a34508> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)
        at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1468)
        at kafka.utils.KafkaScheduler.shutdown(KafkaScheduler.scala:88)
        at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply$mcV$sp(KafkaController.scala:353)
        at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply(KafkaController.scala:348)
        at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply(KafkaController.scala:348)
        at kafka.utils.Utils$.inLock(Utils.scala:535)
        at kafka.controller.KafkaController.onControllerResignation(KafkaController.scala:348)
        at kafka.controller.KafkaController.shutdown(KafkaController.scala:663)
        at kafka.server.KafkaServer$$anonfun$shutdown$9.apply$mcV$sp(KafkaServer.scala:287)
        at kafka.utils.Utils$.swallow(Utils.scala:172)
        at kafka.utils.Logging$class.swallowWarn(Logging.scala:92)
        at kafka.utils.Utils$.swallowWarn(Utils.scala:45)
        at kafka.utils.Logging$class.swallow(Logging.scala:94)
        at kafka.utils.Utils$.swallow(Utils.scala:45)
        at kafka.server.KafkaServer.shutdown(KafkaServer.scala:287)
        at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:40)
        at kafka.Kafka$$anon$1.run(Kafka.scala:42)

""SIGTERM handler"" daemon prio=10 tid=0x00007f8860002000 nid=0x26ae in Object.wait() [0x00007f83c9be2000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        - waiting on <0x00000000d018bda8> (a kafka.Kafka$$anon$1)
        at java.lang.Thread.join(Thread.java:1281)
        - locked <0x00000000d018bda8> (a kafka.Kafka$$anon$1)
        at java.lang.Thread.join(Thread.java:1355)
        at java.lang.ApplicationShutdownHooks.runHooks(ApplicationShutdownHooks.java:106)
        at java.lang.ApplicationShutdownHooks$1.run(ApplicationShutdownHooks.java:46)
        at java.lang.Shutdown.runHooks(Shutdown.java:123)
        at java.lang.Shutdown.sequence(Shutdown.java:167)
        at java.lang.Shutdown.exit(Shutdown.java:212)
        - locked <0x00000000d0080660> (a java.lang.Class for java.lang.Shutdown)
        at java.lang.Terminator$1.handle(Terminator.java:52)
        at sun.misc.Signal$1.run(Signal.java:212)
        at java.lang.Thread.run(Thread.java:745)

""kafka-scheduler-0"" daemon prio=10 tid=0x00007f884c045000 nid=0x26aa waiting on condition [0x00007f83c9ee5000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
 - parking to wait for  <0x00000000cfb1b800> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:867)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1197)
        at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:214)
        at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:290)
        at kafka.utils.Utils$.inLock(Utils.scala:533)
        at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$17.apply(KafkaController.scala:1149)
        at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$17.apply(KafkaController.scala:1147)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
        at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1147)
        at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1126)
        at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:224)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:403)
        at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1126)        at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:326)
        at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:99)
        at kafka.utils.Utils$$anon$1.run(Utils.scala:54)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)

""Controller-4-to-broker-1-send-thread"" prio=10 tid=0x00007f884c019800 nid=0x26a9 waiting on condition [0x00007f83c9fe6000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00000000d2828b58> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442);;;","10/Oct/14 07:17;junrao;Sriharsha,

It seems that you found a deadlock.

In KafkaController.onControllerResignation(), it holds the controller lock while calling autoRebalanceScheduler.shutdown(). The auto rebalance scheduler couldn't shutdown since it's blocked waiting for the controller lock in checkAndTriggerPartitionRebalance().

To break the deadlock, we can move autoRebalanceScheduler.shutdown() in onControllerResignation() to before acquiring the controller lock. We don't need to hold on the controller lock while shutting down the scheduler.;;;","10/Oct/14 07:20;sriharsha;Thanks [~junrao]. Testing with above change.;;;","10/Oct/14 09:47;sriharsha;[~junrao] ran tests with your suggested change. All of the controller shutdown went through without any issue.
I'll file a separate JIRA for autoRebalanceScheduler.shutdown deadlock.;;;","10/Oct/14 12:17;junrao;Sriharsha,

Thanks for testing this out. Based on your result, it seems that auto leader balancing is stable with a large controller channel queue. Could you create a patch by changing the default value of controller.message.queue.size to 10000 and auto.leader.rebalance.enable to true? Once that's done, we can resolve this jira. We can file a separate jira for controller refactoring.

;;;","10/Oct/14 23:51;sriharsha;Created reviewboard https://reviews.apache.org/r/26560/diff/
 against branch origin/trunk;;;","11/Oct/14 00:10;nehanarkhede;[~junrao], [~sriharsha] What's the value in changing it from something to 10K vs unbounded?;;;","11/Oct/14 01:19;sriharsha;[~nehanarkhede] [~junrao] my understanding is that we created more room for KafkaController not to get into any of the above mentioned issues by setting to 10k but yes making unbounded is a better option as there could be a chance of exhausting 10k bounded queue and run into issues. We can get rid off  controller.message.queue.size as config option and make the LinkedBlockingQueue unbounded.  
;;;","11/Oct/14 01:44;junrao;Yes, in theory, we can make the queue unbounded. However, in practice, the queue shouldn't build up. I was a bit concerned that if we make the queue unbounded and another issue that causes the queue to build up, we may hit OOME. Then, we may not be able to take a thread dump to diagnose the issue.;;;","13/Oct/14 06:25;nehanarkhede;Increasing the queue size by a little doesn't really solve the problem. We should conduct more tests on an unbounded controller queue, if we have any doubt whether or not it will work. [~sriharsha] I will help you review changes to the controller, if you are up for updating your patch.;;;","13/Oct/14 07:20;sriharsha;[~nehanarkhede] so the changes you are looking for are remove the config option and make the LinkedBlockingQueue to unbounded?;;;","13/Oct/14 07:49;sriharsha;Created reviewboard https://reviews.apache.org/r/26633/diff/
 against branch origin/trunk;;;","13/Oct/14 12:20;junrao;Perhaps we can just set the default queue to max int for now. If we don't see any issue with this, we can make LinkedBlockingQueue to unbounded later. Could you also change the default value for auto.leader.rebalance.enable?;;;","13/Oct/14 22:30;sriharsha;Updated reviewboard https://reviews.apache.org/r/26633/diff/
 against branch origin/trunk;;;","14/Oct/14 02:25;nehanarkhede;[~sriharsha] Latest patch looks good. Pushing it to trunk and 0.8.2;;;","17/Nov/14 00:55;jbrosenberg@gmail.com;Is it safe to say then, if we are not yet on 0.8.2 (e.g. still on 0.8.1.1), we should not enable automatic preferred leader election?;;;","17/Nov/14 02:29;sriharsha;[~jbrosenberg@gmail.com] The fix is in config. So if you are using 0.8.1.1 you can enable automatic preferred leader election but make sure you set controller.message.queue.size to Int.MaxValue by default this is set to 10 in 0.8.1.1.;;;","13/Mar/15 20:01;dmitrybugaychenko;With a large controller queues size we see a significant datalos during prefered replica election for a brokers leading a lot of partitions (100+). The problem is that the prefered replica handles its requests fast, empties its request queue and stop following others, but the old leader hadles request much slower and it takse few minutes before it stop considering itself as a leader for all re-elected partitions. During these few minutes old leader continue to acknowledge produce requests and at the end it recognize its not longer a leader and truncates its logs deleting all data received...;;;","14/Mar/15 00:57;becket_qin;That's a good point. But I kind of think the right solution to that problem does not lie in the queue size. Because there will be data loss in leader migration today, more or less. The amount is actually non-deterministic. So my understanding is either user can tolerate data loss or user needs to use acks=-1.;;;","14/Mar/15 05:42;dmitrybugaychenko;Yes, data loss is tolerated to some extend. With small queue it was about lossing less then a second or even none of data and were considered fine, but with extended queue it is about few minutes - using acks in this case will simply cause producers to crash, denie their service or drop messages (because for few minutes they basically can not produce).  In the end we decided to reduce the queue to default and to apply three patches:

# Add throttling to prefered replica elections and controlled shuttdown leadership reasignement
# Add timeout for adding messages to queue in order to avoid locked controller
# Add separate timeout for sending controlled shutdown message - in our setup it takes about 10 minutes and this value is meaningless and dangerous for other kind of controller-to-broker communication

Things seems to work and data are not lost, but shutdown and rebalance are slow. Instead of throttling it could be better to wait for previous leader movement to be completed by all the participatnts before moving to next one. It is also possible to do leader movements in batches (at least api seems to support that).;;;","14/Mar/15 06:13;becket_qin;It is not clear to me how adding timeout when put messages to broker queue in controller would help. This operation is done in the controller lock and have to be infinitely retry. I would guess in a parallel shutdown, you might still see deadlock.;;;","14/Mar/15 13:53;dmitrybugaychenko;Retry itself is in the cahnnel manager independent of controller lock. Deadlock happens because one of the threads owning controller lock trying to put message to channel manager - it waits for free space but won't evere get it. With timeout it won't wait forever and eventually fail the operation given controller a chance to handle broker failure (which includes closing corresponding channel and emptying its queue).;;;","14/Mar/15 16:10;becket_qin;I see. The risk of this approach is that controller or broker could potentially be in a inconsistent state. Because it is not necessarily the case that timeout occurs on broker shutdown. In that case, some controller to broker messages are sent while some might not.
I think the key problem of current approach is that we mix the data plain and control plain, i.e. the controller message and user data are handled by same request handlers on Kafka server. So controller messages usually sitting in the queue behind many user requests. That could cause the handling of controller messages to delay for almost arbitrary time (the more leader a broker has, the worse the situation will be). The right solution is probably having a separate thread handling controller message or prioritize controller message handling. Giving priority to controller message probably has less change because we just need to insert the controller message to the head of the queue instead of the tail.;;;","16/Mar/15 20:25;dmitrybugaychenko;Even with a fast dedicated channel there will be a race condition in switching leadership. It could be removed either by complicating the protocol (eg. the new leader shoul take leadership only after getting ""not a leader"" respone in fetcher thread from the old one, while the old leader should stop handling produce request allowing fetches only from the new leader untill it gets everything), or, may be, it is worth to consider getting rid of controller in partition leader election and use distributed elections in ZK.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Offset in RecordMetadata is Incorrect with New Producer Ack = -1,KAFKA-1255,12694357,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,jkreps,guozhang,guozhang,11/Feb/14 05:37,08/Oct/16 01:03,22/Mar/23 15:10,20/Feb/14 00:32,,,,,,,,,,,,,,,,,,0,,,,,,"With the new producer's integration test, one observation is that when producer ack = -1, the returned offset is incorrect.

Output files with two scenarios (send 100 messages with ack = 1 and -1) attached.",,guozhang,jkreps,rathdeep,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1260,,,,,,,,,,,,,,,,"11/Feb/14 05:38;guozhang;sendwithAckMinusOne;https://issues.apache.org/jira/secure/attachment/12628064/sendwithAckMinusOne","11/Feb/14 05:38;guozhang;sendwithAckOne;https://issues.apache.org/jira/secure/attachment/12628063/sendwithAckOne",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,372866,,,Fri Oct 30 13:48:37 UTC 2015,,,,,,,,,,"0|i1s9af:",373170,,,,,,,,,,,,,,,,,,,,"11/Feb/14 05:57;jkreps;This is surprising as the offset comes through the same code path on the producer irrespective of the acks settings. The place that is set is in FutureRecordMetadata:
    private RecordMetadata valueOrError() throws ExecutionException {
        if (this.result.error() != null)
            throw new ExecutionException(this.result.error());
        else
            return new RecordMetadata(result.topicPartition(), this.result.baseOffset() + this.relativeOffset);
    }

Perhaps this is being set wrong on the server?;;;","12/Feb/14 12:24;jkreps;I looked into this and the offset is indeed being set incorrectly on the server if acks=-1, basically we pass the final offset into the response for delayed requests (which is just wrong I think). I will take a pass at fixing, should be straight-forward.;;;","20/Feb/14 00:32;guozhang;This issue has been fixed in KAFKA-1260;;;","30/Oct/15 21:48;rathdeep;when is this bug expected to release. Is there any workaround to get correct offset with ack = -1.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to pull Kafka binaries with Ivy,KAFKA-981,12659097,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,charmalloc,mumrah,mumrah,22/Jul/13 22:20,11/Oct/13 01:54,22/Mar/23 15:10,11/Oct/13 01:54,0.8.0,,,,,,,,,,,,,packaging,,,,0,,,,,,"I am trying to pull the published Kafka binary with a simple Ivy file.

<dependency org=""org.apache.kafka"" name=""kafka_2.9.2"" rev=""0.8.0-beta1"" conf=""default->default""/>

I get the following exception: [ivy:resolve] problem occurred while resolving dependency: org.apache.kafka#kafka_2.9.2;0.8.0-beta1 {default=[default]} with main: java.lang.IllegalArgumentException: null name not allowed
",,charmalloc,dorzey,jkreps,mumrah,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jul/13 22:21;mumrah;ant.log;https://issues.apache.org/jira/secure/attachment/12593516/ant.log","22/Jul/13 22:21;mumrah;ivy.xml;https://issues.apache.org/jira/secure/attachment/12593517/ivy.xml",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,339290,,,Thu Oct 10 17:54:22 UTC 2013,,,,,,,,,,"0|i1miqn:",339610,,,,,,,,,,,,,,,,,,,,"22/Jul/13 22:21;mumrah;stdout log from Ant showing full exception;;;","22/Jul/13 22:21;mumrah;Ivy descriptor file I used;;;","22/Jul/13 22:22;mumrah;Also should note this is Ivy 2.3.0;;;","22/Jul/13 22:24;mumrah;For a full example, try cloning this repository and running ""ant ivy""

https://github.com/mumrah/trihug-kafka-demo

I encountered this error when setting up this demo;;;","23/Jul/13 00:54;jkreps;Joe any idea what this might be?;;;","23/Jul/13 09:08;mumrah;Looking closer at the pom.xml, I see two <dependencies> sections. One of which looks like a copy/paste error from ivy.xml, the other looks like normal Maven pom dependencies. See https://gist.github.com/mumrah/6059092#file-pom-xml-L25 for what I'm talking about.;;;","23/Jul/13 09:55;charmalloc;The first dependency section you see is only from maven central http://repo1.maven.org/maven2/org/apache/kafka/kafka_2.9.2/0.8.0-beta1/kafka_2.9.2-0.8.0-beta1.pom its not there in https://repository.apache.org/content/repositories/releases/org/apache/kafka/kafka_2.9.2/0.8.0-beta1/kafka_2.9.2-0.8.0-beta1.pom which I believe is due to me posting the release more than once with making pom changes that did not bump the version in order to get things to work and through https://issues.apache.org/jira/browse/KAFKA-974

I don't know if that is what is causing the error but looking at the source here https://svn.apache.org/repos/asf/ant/ivy/core/trunk/src/java/org/apache/ivy/core/module/id/ModuleId.java that error is because the name of the module is coming in as null, which is odd.

Can you try to override the repository to use https://repository.apache.org/content/repositories/releases instead to see if it works as expected it has resolved other issues folks have brought up.  ;;;","23/Jul/13 10:18;mumrah;[~charmalloc], ah yes - that pesky ""released versions are immutable"" thing. Changing Ivy to pull from Apache's repo did the trick.

BTW, I debugged and stepped through Ivy during that error and it was failing on the bad part of the XML (the ivy <dependency/> elements). So it was definitely caused by the invalid pom.xml.

Now I'm getting failure to resolve ""com.sun.jdmk"" nonsense, but I can deal with that.

Should there be a beta2 release to fix this issue in Maven central?;;;","24/Jul/13 21:29;mumrah;Bump. We really should get the invalid pom out of Maven Central, it's affecting a lot of people. I'm not 100% sure, but I think once a release has been signed/published it is immutable. We probably need to delete beta1 and create beta2

Thoughts?;;;","03/Oct/13 22:50;dorzey;Just started investigating Kafka and hit the invalid Maven Central pom as well. I've used the Apache repo in my Gradle build and it works fine.

When will this get fixed in Maven Central? With the next release?

Thanks!;;;","03/Oct/13 23:02;charmalloc;Next release, yes;;;","11/Oct/13 01:54;charmalloc;See KAFKA-1018;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
WhiteList topic filter gets a NullPointerException on complex Regex,KAFKA-1180,12684311,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,joestein,jbrosenberg@gmail.com,jbrosenberg@gmail.com,13/Dec/13 02:00,20/Jul/14 09:00,22/Mar/23 15:10,20/Jul/14 09:00,0.8.0,,,,,,0.8.2.0,,,,,,,consumer,,,,0,,,,,,"We are needing to create a stream selector that essentially combines the logic of the BlackList and WhiteList classes (which is not easily exposed in the high-level consumer api).  That is, we want to select a topic that contains a certain prefix, as long as it doesn't also contain a secondary string.

This should be easy to do with ordinary java Regex's, but we're running into some issues, trying to do this with the WhiteList class only.

We have a pattern that uses negative lookahead, like this:

""test-(?!bad\\b)[\\w]+""

So this should select a topic like: ""test-good"", but exclude a topic like ""test-bad"", and also exclude a topic without the ""test"" prefix, like ""foo-bar"".

Instead, what we see is a NullPointerException in the call to createMessageStreamsByFilter (after having previously sent a message to ""test-good"" followed by a message to ""test-bad""):

21700 [ConsumerFetcherThread-group1_square-1a7ac0.local-1386869343370-dc19c7dc-0-1946108683] ERROR kafka.consumer.ConsumerFetcherThread  - [ConsumerFetcherThread-group1_square-1a7ac0.local-1386869343370-dc19c7dc-0-1946108683], Error due to 
kafka.common.KafkaException: error processing data for partition [test-bad,0] offset 0
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1$$anonfun$apply$mcV$sp$2.apply(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1$$anonfun$apply$mcV$sp$2.apply(AbstractFetcherThread.scala:109)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:105)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1.apply$mcV$sp(AbstractFetcherThread.scala:109)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1.apply(AbstractFetcherThread.scala:109)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1.apply(AbstractFetcherThread.scala:109)
	at kafka.utils.Utils$.inLock(Utils.scala:565)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:108)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:86)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)
Caused by: java.lang.NullPointerException
	at kafka.consumer.PartitionTopicInfo.enqueue(PartitionTopicInfo.scala:60)
	at kafka.consumer.ConsumerFetcherThread.processPartitionData(ConsumerFetcherThread.scala:49)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1$$anonfun$apply$mcV$sp$2.apply(AbstractFetcherThread.scala:128)
	... 9 more",,charmalloc,guozhang,jbrosenberg@gmail.com,joestein,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jan/14 09:29;charmalloc;KAFKA-1180.patch;https://issues.apache.org/jira/secure/attachment/12621898/KAFKA-1180.patch","21/Dec/13 02:08;charmalloc;KAFKA-1180.patch;https://issues.apache.org/jira/secure/attachment/12619873/KAFKA-1180.patch","22/Dec/13 14:25;charmalloc;KAFKA-1180_2013-12-22_01:24:57.patch;https://issues.apache.org/jira/secure/attachment/12620067/KAFKA-1180_2013-12-22_01%3A24%3A57.patch","10/Feb/14 09:22;charmalloc;KAFKA-1180_2014-02-09_20:21:49.patch;https://issues.apache.org/jira/secure/attachment/12627907/KAFKA-1180_2014-02-09_20%3A21%3A49.patch","14/Feb/14 03:50;charmalloc;KAFKA-1180_2014-02-13_14:50:40.patch;https://issues.apache.org/jira/secure/attachment/12628831/KAFKA-1180_2014-02-13_14%3A50%3A40.patch","14/Feb/14 04:13;charmalloc;KAFKA-1180_2014-02-13_15:13:17.patch;https://issues.apache.org/jira/secure/attachment/12628836/KAFKA-1180_2014-02-13_15%3A13%3A17.patch","14/Feb/14 04:22;charmalloc;KAFKA-1180_2014-02-13_15:21:51.patch;https://issues.apache.org/jira/secure/attachment/12628839/KAFKA-1180_2014-02-13_15%3A21%3A51.patch","14/Feb/14 04:24;charmalloc;KAFKA-1180_2014-02-13_15:23:28.patch;https://issues.apache.org/jira/secure/attachment/12628840/KAFKA-1180_2014-02-13_15%3A23%3A28.patch","14/Jul/14 09:13;jbrosenberg@gmail.com;apply-patch-1180-to-0.8.1.patch;https://issues.apache.org/jira/secure/attachment/12655482/apply-patch-1180-to-0.8.1.patch",,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,363383,,,Sun Jul 20 01:00:07 UTC 2014,,,,,,,,,,"0|i1qmz3:",363689,,,,,,,,,,,,,,,,,,,,"13/Dec/13 07:42;jbrosenberg@gmail.com;Here's some code which reproduces the issue.  Assume zkConnect points to a running zk cluster (and there's also a running kafka instance using the same zkConnect), and also that kafka is running  on localhost, and using using 'metadataport':

    List<KeyedMessage<Integer, String>> data =  ImmutableList.of(
            new KeyedMessage<Integer, String>(""test-topic"", ""test-message1""),
            new KeyedMessage<Integer, String>(""test-bad"", ""test-message2"")),
    String regex =  ""test-(?!bad\\b)[\\w]+"",

    Properties pProps = new Properties();
    pProps.put(""metadata.broker.list"", ""localhost:"" + metadataport);
    pProps.put(""serializer.class"", ""kafka.serializer.StringEncoder"");
    ProducerConfig pConfig = new ProducerConfig(pProps);
    Producer<Integer, String> producer = new Producer<Integer, String>(pConfig);
    for (KeyedMessage<Integer, String> data : toSend) {
      System.out.println(""write"");
      producer.send(data);
    }
    producer.close();

    Properties cProps = new Properties();
    cProps.put(""zookeeper.connect"", zkConnect);
    cProps.put(""group.id"", ""group1"");
    cProps.put(""auto.offset.reset"", OffsetRequest.SmallestTimeString());
    ConsumerConfig consumerConfig = new ConsumerConfig(cProps);
    ConsumerConnector consumerConnector = Consumer.createJavaConsumerConnector(consumerConfig);

    List<KafkaStream<byte[], byte[]>> streams =
        consumerConnector.createMessageStreamsByFilter(new Whitelist(regex), 1);
    System.out.println(""create streams"");

;;;","17/Dec/13 22:43;joestein;That code is all in TopicFilter, can you writeup a StreamSelector that extends TopicFilter(rawRegex) or another TopicFilter?  

case class Whitelist(rawRegex: String) extends TopicFilter(rawRegex) {
  override def requiresTopicEventWatcher = !regex.matches(""""""[\p{Alnum}-|]+"""""")

  override def isTopicAllowed(topic: String) = {
    val allowed = topic.matches(regex)

    debug(""%s %s"".format(
      topic, if (allowed) ""allowed"" else ""filtered""))

    allowed
  }


}

case class Blacklist(rawRegex: String) extends TopicFilter(rawRegex) {
  override def requiresTopicEventWatcher = true

  override def isTopicAllowed(topic: String) = {
    val allowed = !topic.matches(regex)

    debug(""%s %s"".format(
      topic, if (allowed) ""allowed"" else ""filtered""))

    allowed
  }

if can patch I can help it get upstream, might have a chance to get some to-do this in the next week or two ;;;","18/Dec/13 21:14;jbrosenberg@gmail.com;Joe, I'm not sure I understand your suggestion?  We are calling the WhiteList constructor from java.  Unfortunately, it does not look like there is an easy way to sub-class Whitelist (or even TopicFilter) from java.

Anyway, the bottom line, is that that regex I used in the example above causes an NPE, can you reproduce that?  I think that's the main issue in the bug.  Going beyond that, it would be great if WhiteList allowed arbitrary Regex's, that can you negative lookahead, etc., to allow complex patterns.  Or alternatively, a separate filter class, which is more general purpose.

There is some code I'm uncertain about in that WhiteList class (I am really not clear on what the distinction between 'regex' and 'rawRegex' is, and the business around 'requiresTopicEventWatcher'?).;;;","21/Dec/13 02:08;charmalloc;Created reviewboard https://reviews.apache.org/r/16425/
;;;","22/Dec/13 14:23;joestein;reproduced 

[2013-12-22 01:07:15,984] ERROR [ConsumerFetcherThread-console-consumer-55777_Joes-MacBook-Air.local-1387692435196-f52625ba-0-0], Error due to  (kafka.consumer.ConsumerFetcherThread)
kafka.common.KafkaException: error processing data for partition [test-bad,0] offset 0
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1$$anonfun$apply$mcV$sp$2.apply(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1$$anonfun$apply$mcV$sp$2.apply(AbstractFetcherThread.scala:109)
	at scala.collection.immutable.Map$Map4.foreach(Map.scala:180)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1.apply$mcV$sp(AbstractFetcherThread.scala:109)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1.apply(AbstractFetcherThread.scala:109)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1.apply(AbstractFetcherThread.scala:109)
	at kafka.utils.Utils$.inLock(Utils.scala:565)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:108)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:86)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)
Caused by: java.lang.NullPointerException
	at kafka.consumer.PartitionTopicInfo.enqueue(PartitionTopicInfo.scala:60)
	at kafka.consumer.ConsumerFetcherThread.processPartitionData(ConsumerFetcherThread.scala:49)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$1$$anonfun$apply$mcV$sp$2.apply(AbstractFetcherThread.scala:128)
	... 9 more
;;;","22/Dec/13 14:25;charmalloc;Updated reviewboard https://reviews.apache.org/r/16425/
;;;","22/Dec/13 20:00;jbrosenberg@gmail.com;So, is this patch applicable to the 0.8 branch?  I assume the fix will be committed, only to trunk / 0.8.1?;;;","22/Dec/13 22:26;joestein;Hi Jason, this patch was developed for you to try out against 0.8 branch, yes.

I would +1 on a 0.8.0.1 release with this fix (and anything else spring up) as it would also resolve the 2.8.0 zero length maven issue too (as that is just build related so two JIRA tickets).  I understand if folks didn't want to switch scala versions in production also along with making other changes in case something went wrong and what was the cause.   2.8.0 should be supported in maven but I still think (need to throw a documentation patch up for this) we should document sbt and maven using scala 2.10 (conflating JIRAs some here, sorry).

I haven't tried the patch yet on 0.8.1 as I wanted to 100% make sure first this resolved your issue and that you didn't hit another issue after this was fixed.

0.8.1 might not be too far away also and with release time and testing maybe 0.8.1 comes out within the same time frame the community would be looking for 0.8.0.1.  I haven't tried the Log Compaction stuff in 0.8.1 yet but it looks really awesome https://cwiki.apache.org/confluence/display/KAFKA/Log+Compaction will do that when I try this patch on 0.8.1 once you confirm it works for you as expected.;;;","03/Jan/14 02:05;jbrosenberg@gmail.com;[~joestein] I've applied this patch against the 0.8 branch, and can confirm that it seems to solve the issue we've been having.  Please go ahead and add it to the 0.8.1 branch.  I'm not sure it makes sense at this point to add a 0.8.0.1 release, but if you did, I would use that (for now, I'll run with my own patched 0.8.0 version).

Thanks!;;;","08/Jan/14 09:28;joestein;The KAFKA-1180_2013-12-22_01:24:57.patch is for the 0.8 branch;;;","08/Jan/14 09:29;charmalloc;Created reviewboard https://reviews.apache.org/r/16718/
 against branch origin/trunk;;;","08/Jan/14 09:31;joestein;Trunk patch = https://issues.apache.org/jira/secure/attachment/12621898/KAFKA-1180.patch;;;","03/Feb/14 04:05;jbrosenberg@gmail.com;Any updates on getting this merged into trunk, in time for 0.8.1?;;;","07/Feb/14 23:00;joestein;I have the changes done requested in the review, I need to dig them out of my branch and upload them for follow-up.  Should be able to-do that before Monday.;;;","10/Feb/14 09:22;charmalloc;Updated reviewboard https://reviews.apache.org/r/16718/
 against branch origin/0.8.1;;;","14/Feb/14 03:50;charmalloc;Updated reviewboard https://reviews.apache.org/r/16718/
 against branch origin/0.8.1;;;","14/Feb/14 03:51;joestein;The last patch uploaded just now is rebased on 0.8.1 and added blacklist test case that was missing too;;;","14/Feb/14 04:13;charmalloc;Updated reviewboard https://reviews.apache.org/r/16718/
 against branch origin/0.8.1;;;","14/Feb/14 04:22;charmalloc;Updated reviewboard https://reviews.apache.org/r/16718/
 against branch origin/0.8.1;;;","14/Feb/14 04:24;charmalloc;Updated reviewboard https://reviews.apache.org/r/16718/
 against branch origin/0.8.1;;;","14/Feb/14 04:26;joestein;version 3,4,5 were some issue with my local branches.  cleaned that up and fixed in version 6 (latest) which is reviewable now

added test cases and comments reviewed by Joel & Neha and missing Blacklist test reviewed by Guozhang;;;","20/Feb/14 22:13;jbrosenberg@gmail.com;is it too late to reconsider for 0.8.1?
will there at least be a patch applicable for 0.8.1?;;;","11/Apr/14 13:51;jbrosenberg@gmail.com;[~joestein] What's the status of this?  Will it be available only in 0.8.2?  If so, will there be a patch we can apply to 0.8.1 and 0.8.1.1?  Will the patch previously supplied for 0.8.0 work with 0.8.1.*?

We are currently using 0.8.0 with your patch.  We'd like to upgrade to 0.8.1, but would need to have the patch available before doing so!

Thanks,

Jason;;;","30/May/14 03:10;jbrosenberg@gmail.com;I see this is marked now for 0.8.2.  Is this confirmed?  What's the timeline for 0.8.2?

Thanks,

Jason;;;","14/Jul/14 09:13;jbrosenberg@gmail.com;I've uploaded a patch that refactors the previous patch, to work for the 0.8.1 branch (and presumably trunk).  I've tested and verified this patch and it's working for 0.8.1.1.;;;","15/Jul/14 00:53;guozhang;LGTM, +1. Patch applied with some line number offsets.;;;","15/Jul/14 10:59;jbrosenberg@gmail.com;anything more to be done to get this across the finish line?;;;","17/Jul/14 00:57;junrao;Joel Koshy, Joe Stein,

Do you want to review and commit this patch to trunk?;;;","17/Jul/14 01:17;charmalloc;Yes I can do it, sorry I am swamped to-do it at the moment.  Maybe tomorrow/Friday.  I am going to commit the patch that I did that Joel reviewed in rb to trunk when I do.  ;;;","18/Jul/14 01:09;nehanarkhede;[~charmalloc] Is there any more work to be done before we commit this? [~jjkoshy], If you think the patch looks good and if Joe doesn't have time, would you mind committing it?;;;","19/Jul/14 01:11;joestein;[~nehanarkhede] I was going to add to the WhiteList & BlackList test with the specific regex raised which [~jjkoshy] suggested in his comment for +1 the patch and then commit. I do not think committing without that is the worse thing (since the other test case does check for every scenario of escaping) but it does make the change overall more complete and concise which I think is what Joel was getting at.;;;","20/Jul/14 09:00;joestein;committed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time,KAFKA-1387,12707778,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,fpj,slon,slon,11/Apr/14 03:48,25/Sep/15 01:15,22/Mar/23 15:10,25/Sep/15 01:15,0.8.1.1,,,,,,0.9.0.0,,,,,,,,,,,12,newbie,patch,zkclient-problems,,,"Kafka broker re-registers itself in zookeeper every time handleNewSession() callback is invoked.

https://github.com/apache/kafka/blob/0.8.1/core/src/main/scala/kafka/server/KafkaHealthcheck.scala 

Now imagine the following sequence of events.
1) Zookeeper session reestablishes. handleNewSession() callback is queued by the zkClient, but not invoked yet.
2) Zookeeper session reestablishes again, queueing callback second time.
3) First callback is invoked, creating /broker/[id] ephemeral path.
4) Second callback is invoked and it tries to create /broker/[id] path using createEphemeralPathExpectConflictHandleZKBug() function. But the path is already exists, so createEphemeralPathExpectConflictHandleZKBug() is getting stuck in the infinite loop.

Seems like controller election code have the same issue.

I'am able to reproduce this issue on the 0.8.1 branch from github using the following configs.

# zookeeper
tickTime=10
dataDir=/tmp/zk/
clientPort=2101
maxClientCnxns=0

# kafka
broker.id=1
log.dir=/tmp/kafka
zookeeper.connect=localhost:2101

zookeeper.connection.timeout.ms=100
zookeeper.sessiontimeout.ms=100

Just start kafka and zookeeper and then pause zookeeper several times using Ctrl-Z.",,aauradkar,abhinavddr@gmail.com,anigam,blokecom,"chris|",clarkhaskins,CurryGaifan,darion,davars,eggsby,fpj,githubbot,guozhang,gwenshap,hakman,jeremypinkham,joestein,junrao,jwlent@gmail.com,jwlent55,kenmacd,kzadorozhny-tubemogul,leigh.jones,marcusai,mazhar.shaikh.in,mgharat,mrlabbe,nehanarkhede,nickdella,ryanwi,slon,twbecker,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1451,,,,,,,,ZOOKEEPER-1740,,"25/Aug/15 00:06;fpj;KAFKA-1387.patch;https://issues.apache.org/jira/secure/attachment/12752026/KAFKA-1387.patch","01/Oct/14 00:27;jwlent55;kafka-1387.patch;https://issues.apache.org/jira/secure/attachment/12672056/kafka-1387.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,386101,,,Thu Sep 24 17:14:44 UTC 2015,,,,,,,,,,"0|i1uii7:",386366,,guozhang,,,,,,,,,,,,,,,,,,"11/Apr/14 23:45;guozhang;Hi Fedor, do you think this is caused by the same issue described in https://issues.apache.org/jira/browse/KAFKA-1382 ?;;;","13/Apr/14 22:14;slon;I think it's a different issue.;;;","14/Apr/14 03:54;guozhang;I think the main issue here is when there is a zookeeper session timeout, the zkClient will re-try write the data which could be already committed to ZK and failed. This issue is the same as the one causing KAFKA-1382. But I think their fixes would be different.;;;","05/Aug/14 12:40;joestein;Here is another way to reproduce this issue.  I have seen it a few times now with folks getting going with their clusters.

steps to reproduce.  install a 3 node zk ensemble with 3 brokers cluster

e.g. 

git clone https://github.com/stealthly/scala-kafka
git checkout -b zkbk3 origin/zkbk3
vagrant up provider=virtualbox

now setup each node in the cluster as you would broker 1,2,3 and the ensemble

e.g.

vagrant ssh zkbkOne
sudo su
cd /vagrant/vagrant/ && ./up.sh
vagrant ssh zkbkTwo
sudo su
cd /vagrant/vagrant/ && ./up.sh
vagrant ssh zkbkThree
sudo su
cd /vagrant/vagrant/ && ./up.sh

start up zookeeper on all 3 nodes
cd /opt/apache/kafka && bin/zookeeper-server-start.sh config/zookeeper.properties 1>>/tmp/zk.log 2>>/tmp/zk.log &

now, start up broker on node 2 only
cd /opt/apache/kafka && bin/kafka-server-start.sh config/server.properties 1>>/tmp/bk.log 2>>/tmp/bk.log &

ok, now here is where it gets wonky

on server 3 change from broker.id=3 to broker.id=2 
now you need to start up server 1 and 3 (even though it is broker.id=2) at the same time

cd /opt/apache/kafka && bin/kafka-server-start.sh config/server.properties 1>>/tmp/bk.log 2>>/tmp/bk.log &
cd /opt/apache/kafka && bin/kafka-server-start.sh config/server.properties 1>>/tmp/bk.log 2>>/tmp/bk.log &
( you can have two tabs, hit enter in one switch to other tab and hit enter is close enough to same time)

and you get this looping forever

2014-08-05 04:34:38,591] INFO I wrote this conflicted ephemeral node [{""version"":1,""brokerid"":2,""timestamp"":""1407212148186""}] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2014-08-05 04:34:44,598] INFO conflict in /controller data: {""version"":1,""brokerid"":2,""timestamp"":""1407212148186""} stored data: {""version"":1,""brokerid"":2,""timestamp"":""1407211911014""} (kafka.utils.ZkUtils$)
[2014-08-05 04:34:44,601] INFO I wrote this conflicted ephemeral node [{""version"":1,""brokerid"":2,""timestamp"":""1407212148186""}] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2014-08-05 04:34:50,610] INFO conflict in /controller data: {""version"":1,""brokerid"":2,""timestamp"":""1407212148186""} stored data: {""version"":1,""brokerid"":2,""timestamp"":""1407211911014""} (kafka.utils.ZkUtils$)
[2014-08-05 04:34:50,614] INFO I wrote this conflicted ephemeral node [{""version"":1,""brokerid"":2,""timestamp"":""1407212148186""}] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2014-08-05 04:34:56,621] INFO conflict in /controller data: {""version"":1,""brokerid"":2,""timestamp"":""1407212148186""} stored data: {""version"":1,""brokerid"":2,""timestamp"":""1407211911014""} (kafka.utils.ZkUtils$)

the expected result that you get should be

[2014-08-05 04:07:20,917] INFO conflict in /brokers/ids/2 data: {""jmx_port"":-1,""timestamp"":""1407211640900"",""host"":""192.168.30.3"",""version"":1,""port"":9092} stored data: {""jmx_port"":-1,""timestamp"":""140721119
9464"",""host"":""192.168.30.2"",""version"":1,""port"":9092} (kafka.utils.ZkUtils$)
[2014-08-05 04:07:20,949] FATAL Fatal error during KafkaServerStable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
java.lang.RuntimeException: A broker is already registered on the path /brokers/ids/2. This probably indicates that you either have configured a brokerid that is already in use, or else you have shutdown 
this broker and restarted it faster than the zookeeper timeout so it appears to be re-registering.
        at kafka.utils.ZkUtils$.registerBrokerInZk(ZkUtils.scala:205)
        at kafka.server.KafkaHealthcheck.register(KafkaHealthcheck.scala:57)
        at kafka.server.KafkaHealthcheck.startup(KafkaHealthcheck.scala:44)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:103)
        at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:34)
        at kafka.Kafka$.main(Kafka.scala:46)
        at kafka.Kafka.main(Kafka.scala)
[2014-08-05 04:07:20,952] INFO [Kafka Server 2], shutting down (kafka.server.KafkaServer)
[2014-08-05 04:07:20,954] INFO [Socket Server on Broker 2], Shutting down (kafka.network.SocketServer)
[2014-08-05 04:07:20,959] INFO [Socket Server on Broker 2], Shutdown completed (kafka.network.SocketServer)
[2014-08-05 04:07:20,960] INFO [Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2014-08-05 04:07:20,992] INFO [Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2014-08-05 04:07:21,263] INFO [Replica Manager on Broker 2]: Shut down (kafka.server.ReplicaManager)
[2014-08-05 04:07:21,263] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)

which is what you get if you just start server 3 on its one configured with broker.id=2

I originally saw this on a 12 node AWS cluster same kafka 0.8.1.1 zk 3.3.4

I don't know how very critical this is, someone just brought up something similar but with /brokers/ids/x I don't know if they are related but something wonky is going on with the ZkUtils.createEphemeralPathExpectConflictHandleZKBug code paths.


;;;","05/Aug/14 23:48;junrao;Joe,

The issue that you described is probably fixed in KAFKA-1451?;;;","06/Aug/14 09:08;joestein;[~junrao] I tested on trunk and it is much worse now.

instead of looping on the /controller node (like it was before) ... node 3 actually overwrote/stole the /brokers/ids/2 (doing a get before had it as 192.168.30.1 and after it is 192.168.30.3)

so now i have a situation where I have two running broker servers, each with the same broker id running (2), server 3 is the (""active"") broker with all the topics being created on it and failing requests for producing and consuming (because all the data is on server 2 but that is not advertised).... and server 2 is still the controller handling preferred leader election, etc.

what is weird is broker.id = 2 was running already.  I started up broker.id=1 and another broker.id=2 at the same time



;;;","07/Aug/14 07:44;gwenshap;Attempted to reproduce with trunk as well.

I'm not seeing the same behavior as [~joestein]. 
In my experiment the new broker 2 fails with the correct error message. The old broker 2, OTOH, goes into a loop, printing:
""[2014-08-06 16:37:01,884] INFO Partition [test1,0] on broker 2: Cached zkVersion [89] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)""

Not a good behavior either. ;;;","11/Aug/14 06:48;junrao;Hmm, this seems really weird. Not sure why starting two brokers at the same time will affect the ZK registration. Is this reproducible by running multiple brokers on the same machine?;;;","28/Sep/14 10:19;jwlent55;I have seen the issue reported in the original problem description in our QA environment (3 ZooKeeper, 3 Kafka and several application specific nodes) several times now.  I have not tested any configurations where 2 nodes try to claim the same broker id.  The problem is triggered when the system is under stress (high I/O and CPU load) and the ZooKeeper connections become unstable.  When this happens Kafka threads can get stuck trying to register Brokers nodes and Application threads get stuck trying to register Consumer nodes. One way to recover is to restart the impacted nodes.  As an experiment I aslo tried deleting the blocking ZooKeeper nodes (hours later when the system was under no stress).  When I did so the createEphemeralPathExpectConflictHandleZKBug would finally complete processing the current Expire message (i.e. add the node), break out of its loop, but, then immediately reenter the loop when it tired to process the next expire message.  The few times I tested this approach I had to delete the node dozens of times before the problem would clear itself - in other words there were dozens of Expire messages wating to be processed. Obvoisuly I am looking into this issue from a configuration point of view (avoid the unstable connection issue), but, this Kafka error behavior concerns me.

I have reproduced it (somewhat artificially) in a dev environment as follows:

1) Start one ZooKeeper and one Kafka node.
2) Set a thread breakpoint in KafkaHealthCheck.java. 
{noformat}
    def handleNewSession() {
      info(""re-registering broker info in ZK for broker "" + brokerId)
-->   register()
      info(""done re-registering broker"")
      info(""Subscribing to %s path to watch for new topics"".format(ZkUtils.BrokerTopicsPath))
    }
{noformat}
3) Pause Kafka.
4) Wait for ZooKeeper to expire the first session and drop the ephemeral node.
5) Unpause Kafka.
6) Kafka reconnects with ZooKeeper, receives an Expire, and establishes a second session.
7) Breakpoint hit and event thread paused before handling the first Expire.
8) Pause Kafka again.
9) Wait for ZooKeeper to expire the second session and delete the ephemeral node (again).
10) Remove breakpoint, unpause Kafka, and finally release the event thread.
11) Kafka reconnects with ZooKeeper, receives a second Expire, and establishes a third session.
12) Kafka registers an ephemeral triggered by the first expire (which triggerd the second session), but, ZooKeeper associates it with the third Session. 
13) Kafka tries to register an an ephemeral triggered by the second expire, but, ZooKeeper already has a stable node.
14) Kafka assumes this node will go away soon, sleeps, and then retries.
15) The node is associcated with a valid session and threfore does not go away so Kafka remains stuck in the retry loop.

I have tested this with the latest code in trunk and noted the same behavior (the code looks pretty similar).

I have coded up a potential 0.8.1.1 patch for this issue based on the following principles:

# Ensure that when the node starts stale nodes are removed in main
#* For Brokers this means remove nodes with the same host name and port otherwise fail to start (the existing checker logic)
#* For Consumer nodes don't worry about stale nodes - the way they are named should prevent this from ever happening.
# In main add the initial node which should now always work with no looping required - direct call to createEphemeralPath
# Create a EphemeralNodeMonitor class that contains:
#* IZkDataListener
#* IZkStateListener
# The users of this class provide a path to monitor and a closure that defines what to do when the node is not found
# When the state listener is notifed about a new session it checks to see if the node is already gone:
#* Yes, call the provided function
#* No, ignore the event
# When the data listener is notified of a deletion it does the same thing
# Both the Broker and Comsumer registation use this new class in the same way they curently use their individual state listeners.  There only change in behavior is to call createEphemeralPath directly (and avoid the looping code).

Since all this work should be done in the event thread I don't think there are any race conditions and no other nodes should be adding these nodes (or we have a serious configuration issue that should have been detected at startup).

One assumption is that we will always recieve at least one more event (expire and/or delete) after the node is really deleted by ZooKeeper.  I think that is a valid assumption (ZooKeeper can't send the delete until the node is gone).  If the node was present when when we process the final Expire message then we should get notified of a delete if that node was actually related to a previous session.  I wonder if we could get away with just monitoring node deletions, but, that seems risky.  The only change in behavior should be that if the expire is recieved before the node is actually deleted then event loop is not blocked and could process other messages while waiting for the delete event.

Note: I have not touched the leader election / contoller node code (the third user of the createEphemeralPathExpectConflictHandleZKBug code).  That still uses the looping code.  I did apply the KAFKA-1451 patch to our 0.8.1.1 build.

If there is any interest in the code I can provide a patch of what I have so far.  I would very much like to get feedback.  I was not sure of the protocol for submitting patches for comment.


;;;","29/Sep/14 07:23;junrao;James,

Thanks for reporting this. Yes, what you discovered is a real problem. The fix is going to be tricky though. The issue is the following. When a client lose an ephemeral node in ZK due to session expiration, that ephemeral node is not removed exactly at expiration time, but a short time after (ZOOKEEPER-1740). When the client tries to recreate the ephemeral node and get a NodeExistException, one of the two things could happen: (1) the existing node is from the expired session and is on its way to be deleted, (2) the node is actually created on the latest session (The reason is what you discovered:  the client gets multiple handleNewSession() calls due to multiple session expiration events, but the node is created on the latest session). I am not sure if there is an easy way to distinguish the two cases though.

Overall, it seems to me that there are so many corner cases that one has to deal with during ZK session expiration. The simplest approach is probably to prevent session expiration from happening at all (e.g., set a larger session timeout).;;;","29/Sep/14 07:41;gwenshap;AFAIK the ZK bug was never reproduced in newer versions of ZK. I'm wondering if at some point we can say that ZK 3.3 is no longer supported and remove the work-around (which is creating few issues of its own).
;;;","29/Sep/14 07:48;junrao;Gwen,

From ZOOKEEPER-1809, it seems the design of not deleting ephemeral node immediately on session expiration still exists on ZK 3.4.x and beyond?;;;","29/Sep/14 08:33;gwenshap;ZOOKEEPER-1809 was closed because the re-creation of the issue was buggy (the test app was actually creating two sessions at same time). 

I agree that Flavio indicated that ZNodes can hang around after expiration, but he also indicated the opposite in the email thread for ZOOKEEPER-1740.

Its important to get this right, so I'll do more research on the expected ZooKeeper behavior here.

One thing I'm not sure about is why does createEphemeralPathExpectConflictHandleZKBug loop indefinitely? 
If ZK indeed takes a bit of extra time to clean up, we can loop for specific amount of time (number of retries), like Curator typically does. After few seconds, the probability that the ZNode belongs to an active session and not an expired one is very high.;;;","29/Sep/14 21:11;jwlent55;As background we are using ZooKeeper 3.4.5.

When trying to come up with a fix for this I did consider limiting the loop to 2 to 3 tries.  My concerns with this approach were:

# Slow to recover if there are lots of Expire messages to process and each of these could trigger redundant rebalance events until you get to the last one.
# What happens if you don't loop quite long enough?  You are again stuck in a bad state when the ephemeral does go away.

I also considered trying to access the Session Id and storing that value instead of (or in addition to) the timestamp in the node's data.  That appraoch looked difficult to implement, error prone, and had the application doing what I would consider ZooKeeper work.

I agree there are a lot of corner cases to consider, but, I think we are going to pursue the approach I outlined above.  I would be happy to post the proposed solution for your review, but, again I am not sure about the protocol around patch submission.  I would not want this to be mistaken by someone as any kind of offical patch without a lot more review.

When working on this appraoch I looked at the curator PersistentEphemeralNode for ideas:

https://github.com/bazaarvoice/curator-extensions/blob/master/recipes/src/main/java/com/bazaarvoice/curator/recipes/PersistentEphemeralNode.java

This is curator based so does not directly apply to Kafka (yet), but, it also keys off nodeDelete to restore the node.

In the end I went with the simple idea that:

""If when we process an Expire event the node still exists then ZooKeeper will inform us if that node later goes away.""

If we can't trust ZooKeeper/ZkClient to do that then ...

{noformat}
  class StateListener() extends IZkStateListener {

    def handleStateChanged(state: KeeperState) {}

    def handleNewSession() {
      if (zkClient.exists(path)) {
        info(""New session started, but, ephemeral %s already/still exists"".format(path))
      }
      else {
        info(""New session started, recreate ephemeral node %s"".format(path))
        recreateNode()
      }
    }
  }
{noformat};;;","29/Sep/14 21:20;jwlent55;In case anyone is interested in the complete code for the new class I am testing with:

{noformat}
class EphemeralNodeMonitor(zkClient: ZkClient, path: String, recreateNode: () => Unit) extends Logging {

  val dataListener = new DataListener()
  val stateListener = new StateListener()
  
  def start() {
    zkClient.subscribeStateChanges(stateListener)
    zkClient.subscribeDataChanges(path, dataListener)
  }
  
  def close() {
    zkClient.unsubscribeStateChanges(stateListener)
    zkClient.unsubscribeDataChanges(path, dataListener)
  }

  class DataListener() extends IZkDataListener {
    
    var oldData: scala.Any = null

    def handleDataChange(dataPath: String, newData: scala.Any) {
      if (newData != oldData) {
        oldData = newData
        info(""Ephemeral node %s has new data [%s]"".format(dataPath, newData))
      }
    }

    def handleDataDeleted(dataPath: String) {
      if (zkClient.exists(path)) {
        info(""Ephemeral node %s was deleted, but, has already been recreated"".format(dataPath))
      }
      else {
        info(""Ephemeral node %s was deleted, recreate it"".format(dataPath))
        recreateNode()
      }
    }
  }

  class StateListener() extends IZkStateListener {

    def handleStateChanged(state: KeeperState) {}

    def handleNewSession() {
      if (zkClient.exists(path)) {
        info(""New session started, but, ephemeral %s already/still exists"".format(path))
      }
      else {
        info(""New session started, recreate ephemeral node %s"".format(path))
        recreateNode()
      }
    }
  }
{noformat};;;","30/Sep/14 00:35;junrao;James,

Contributing code to Kafka is pretty simple. You just need to attach a patch to the jira.

As for your solution, we probably need to verify the following: will a watcher fire if it's registered on a path created by an already expired session and the path will be deleted soon.;;;","30/Sep/14 05:37;jwlent55;I aplogize in advance for my ignorance, but, I have one newbie question.  My starting point is the 0.8.1.1 tag (really the 0.8.1.1 source distribution).  Would it be OK for me to submit a patch against that baseline or would it be better for me to first merge the code to trunk and then create the patch?;;;","30/Sep/14 06:43;jwlent55;As for your question (which I agree is one of the key questions) I have the following comments:

* The ZooKeeper documentation states there is one case where a watch may be missed which I do not think applies to the situation I am trying to address:

""Watches are maintained locally at the ZooKeeper server to which the client is connected. This allows watches to be lightweight to set, maintain, and dispatch. When a client connects to a new server, the watch will be triggered for any session events. Watches will not be received while disconnected from a server. When a client reconnects, any previously registered watches will be reregistered and triggered if needed. In general this all occurs transparently. There is one case where a watch may be missed: a watch for the existence of a znode not yet created will be missed if the znode is created and deleted while disconnected.""

* In my testing the node is normally gone by the time the New Session event is handled which recreates the node. In that case I do not see a Delete message (I log that arrival of a delete event even if the node is already gone):

{noformat}
[2014-09-29 18:23:43,071] INFO zookeeper state changed (Expired) (org.I0Itec.zkclient.ZkClient)
[2014-09-29 18:23:43,071] INFO Unable to reconnect to ZooKeeper service, session 0x148c36a0a94000f has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:23:43,071] INFO Initiating client connection, connectString=localhost:2181/kafka/0.8 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@56404645 (org.apache.zookeeper.ZooKeeper)
[2014-09-29 18:23:43,072] INFO Opening socket connection to server localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:23:43,073] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:23:43,074] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:23:43,082] INFO Closing socket connection to /10.210.10.165. (kafka.network.Processor)
[2014-09-29 18:23:43,087] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x148c36a0a940010, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:23:43,087] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2014-09-29 18:23:43,099] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2014-09-29 18:23:43,143] INFO New session started, recreate ephemeral node /brokers/ids/0 (kafka.utils.EphemeralNodeMonitor)
[2014-09-29 18:23:43,144] INFO Start registering broker 0 in ZooKeeper (kafka.server.KafkaHealthcheck)
[2014-09-29 18:23:43,161] INFO Registered broker 0 at path /brokers/ids/0 with address jlent.digitalsmiths.com:9092. (kafka.utils.ZkUtils$)
[2014-09-29 18:23:43,218] INFO Ephemeral node /brokers/ids/0 has new data [{""jmx_port"":10001,""timestamp"":""1412029423148"",""host"":""jlent.digitalsmiths.com"",""version"":1,""port"":9092}] (kafka.utils.EphemeralNodeMonitor)
[2014-09-29 18:23:43,237] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
{noformat}

* I have seen cases where the node is still present when the New Session is handled and in that case I do see a Delete event a short while later.  I don't have the logs that document that (don't ask me why I don't have logs to document the most important scenario).  I will try to recreate that situation.
* As an alternative I modified the New Session handling code to do nothing (except log the arrival of the new session event).  In that case I do see the Delete event.  This could perhaps be viewed a more severe test.  In this case we get notified of a Delete that actually occured before we even handled the New Seesion event.  That was actually how I did some of my original testing.

{noformat}
[2014-09-29 18:14:31,414] INFO zookeeper state changed (Expired) (org.I0Itec.zkclient.ZkClient)
[2014-09-29 18:14:31,414] INFO Unable to reconnect to ZooKeeper service, session 0x148c36a0a94000c has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:14:31,414] INFO Initiating client connection, connectString=localhost:2181/kafka/0.8 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@15c58840 (org.apache.zookeeper.ZooKeeper)
[2014-09-29 18:14:31,414] INFO Opening socket connection to server localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:14:31,415] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:14:31,415] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:14:31,420] INFO Closing socket connection to /10.210.10.165. (kafka.network.Processor)
[2014-09-29 18:14:31,459] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x148c36a0a94000d, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:14:31,459] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2014-09-29 18:14:31,587] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2014-09-29 18:14:31,683] INFO New session started, DO NOT recreate ephemeral node /brokers/ids/0 (kafka.utils.EphemeralNodeMonitor)
[2014-09-29 18:14:31,701] INFO Ephemeral node /brokers/ids/0 was deleted, recreate it (kafka.utils.EphemeralNodeMonitor)
[2014-09-29 18:14:31,702] INFO Start registering broker 0 in ZooKeeper (kafka.server.KafkaHealthcheck)
[2014-09-29 18:14:31,722] INFO Registered broker 0 at path /brokers/ids/0 with address jlent.digitalsmiths.com:9092. (kafka.utils.ZkUtils$)
[2014-09-29 18:14:31,744] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2014-09-29 18:14:31,746] INFO Ephemeral node /brokers/ids/0 has new data [{""jmx_port"":10001,""timestamp"":""1412028871704"",""host"":""jlent.digitalsmiths.com"",""version"":1,""port"":9092}] (kafka.utils.EphemeralNodeMonitor)
{noformat}
;;;","01/Oct/14 00:16;jwlent55;Here is what I have so far.  Comments welcomed.;;;","01/Oct/14 00:41;jwlent55;I have messed things up.  I tried to use the Submit Patch option.  I filled out the fields in the form, but, it never asked me for a file.  I also specifed labels that I assumed were related to the patch, but, instead are associated with the issue itself.  I then directly attached the file to the issue.  That seemed to go OK.  Now the Submit Patch option is gone and the Status is Patch Available.  I don't think that is correct.  I decided it is best if I stop messing with the issue for now.  I have done enough damage.

I apologize for my ignorance of the process.;;;","02/Oct/14 22:55;junrao;James,

For my question, could you ask the ZK mailing list and get your understanding confirmed by their developers? Thanks,;;;","03/Oct/14 00:53;jwlent55;Good idea and done:

http://mail-archives.apache.org/mod_mbox/zookeeper-user/201410.mbox/browser;;;","17/Feb/15 04:11;twbecker;Can a project member comment on what it is going to take to get this patch accepted?  We have been running 0.8.1 with it for months, and I guess we'll have to apply it to 0.8.2 as well, but it would be nice to get it into the official tree...;;;","28/Apr/15 09:07;eggsby;I am seeing similar behavior in my consumer, using kafka 0.8.2.1 and zookeeper 3.4.6

In an infinite loop:

{code}
15/04/27 17:44:31 INFO utils.ZkUtils$: conflict in /consumers/******************
15/04/27 17:44:31 INFO utils.ZkUtils$: I wrote this conflicted ephemeral node ************** a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry
15/04/27 17:45:01 INFO INFO utils.ZkUtils$: conflict in /consumers/******************
15/04/27 17:45:01 INFO utils.ZkUtils$: I wrote this conflicted ephemeral node ************** a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry
{code};;;","29/Apr/15 19:57;marcusai;I've also encountered this issue running Kafka 0.8.2.0 and Zookeeper 3.4.6 in a three node cluster. The error occured after two zookeeper nodes got restarted at the same time. The error below repeatedly appeared in the Kafka logs. I resolved the issue by restarting Kafka.

{panel}
[2015-04-27 03:47:03,292] INFO I wrote this conflicted ephemeral node [""jmx_port"":-1,""timestamp"":""1430038275477"",""host"":""ams5mdppdmsbacmq01b.markit.partners"",""version"":1,""port"":9092] at /brokers/ids/2 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
{panel}
;;;","30/Apr/15 13:02;eggsby;It looks like this ""infinite retry"" behavior is only in kafka to accomodate another strange issue where zookeeper was deleting ephemeral nodes out from under it:

https://github.com/apache/kafka/blob/0.8.2.1/core/src/main/scala/kafka/utils/ZkUtils.scala#L272
https://issues.apache.org/jira/browse/ZOOKEEPER-1740

It seems the simplest thing to do would be to just delete the conflicted node and write the truth about the process environment it knows.

I see that my issue appeared in the consumer code, where this issue is occurring in the kafka brokers themselves, but the bug appears to be the same:

There are two exceptional cases in ephemeral nodes that I can see, either the ZOOKEEPER-1740 bug was hit in which case our ephemeral node mysteriously was lost out from under us, but our session is still active and we can just create a new one. The other bug I believe we are seeing is that the session is long gone but the ephemeral node is still hanging around until the consumer process exits.

Currently the first case is handled, but I the second case is not.;;;","05/May/15 01:58;nehanarkhede;When this happens, there isn't a way to get out of this without killing the broker. Marking it as a blocker.;;;","08/May/15 05:17;anigam;I have seen the ephemeral node issue before and the fix made there was exactly what Thomas mentioned:
""It seems the simplest thing to do would be to just delete the conflicted node and write the truth about the process environment it knows.""

Is there a reason why the approach outlined by Thomas does not work for kafka?;;;","31/Jul/15 05:54;clarkhaskins;This patch is listed as a blocker. Can the existing patch be committed? Is anyone actively working on it? 

This has been a problem for us recently and we would like to see this fixed soon.

Thanks,
-Clark;;;","12/Aug/15 02:39;mgharat;Can the person who uploaded the patch submit a testcase on how to reproduce this? 
We are hitting this in production but are not able to reproduce this locally.

;;;","12/Aug/15 02:43;slon;Have you tried steps from issue description?;;;","12/Aug/15 04:19;guozhang;[~fpj] Could you help taking a look at this issue?;;;","12/Aug/15 08:07;jwlent@gmail.com;It has been a while since I investigated this issue. I will take another look at it tomorrow and get back to you. 

Sent from my iPhone

;;;","13/Aug/15 03:32;jwlent55;After refreshing my memory of this issue I was unable to come up with any new ideas for how to create an automated test case for the issue.  I was only able to reproduce this issue in my dev environment using the cumbersome manual process I outlined in my Sept 27 comment.

My question posted to the zookeeper-user mailing list regarding the validity of the key assumption of the patch logic generated no feedback.

We have been using the patch I provided with Kafka 0.8.1.1 for almost a year now.  We have not seen a re-occurrence of the hung ephemeral connection issue since then.  Since the problem was intermittent and only triggered when the system was unstable, this may or may not be due to the presence of the patch.

There was one an NPE issue found during test in March when our application code changed and in certain cases tried to close a Connector that had never been fully started.  That was fixed as follows:

{noformat}
Index: core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
===================================================================
--- core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala	(revision 73668)
+++ core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala	(revision 73669)
@@ -162,7 +162,9 @@
       if (canShutdown) {
         info(""ZKConsumerConnector shutting down"")
 
-        consumerNodeMonitor.close()
+        if (consumerNodeMonitor != null) {
+          consumerNodeMonitor.close()
+        }
         
         if (wildcardTopicWatcher != null)
           wildcardTopicWatcher.shutdown()
{noformat}

Not sure any of this was of much help, but, I would be happy to try to answer any questions regarding the patch logic and/or update it based on your comments.;;;","14/Aug/15 21:34;fpj;I'm actually really sorry that this issue has been around for so long, I didn't realize it was going on and that I was even indirectly participating in it. Let me start by giving a sort of general overview of what to expect.

If a client has received a session expiration event, it means that the leader has expired the session and has broadcast the closeSession event to the followers. If the same client creates a new session successfully, then the server it connects to must have applied the previous closeSession, which deletes the ephemeral znodes, because ZK guarantees that txns are totally ordered. Consequently, the client shouldn't observe an ephemeral from an old session of its own. Note that another client could still observe the ephemeral znode after the session expiration if it is connected to a server that is a bit behind, but that's fine.

What I'm thinking is that one problem that could happen is that a client creates a new session before receiving the session expiration for an earlier session. In that case the ephemerals will still be there because the session still exists.

The bottom line is that if the client has seen the session expiration event, then it seems fine to go ahead and create new ephemerals without having to check whether ephemerals are stale or not. If the session creation isn't clean, then there are a few options like waiting for the timeout period, storing and recovering the session id.

I'll dig into the code to see how we can fix this, have a closer look at the patch, and will reopen the associated ZOOKEEPER-1740 issue until we sort this out. let me know if the explanation above makes sense in the meanwhile. ;;;","15/Aug/15 01:32;anigam;Thanks a lot for digging into this. Not sure if it helps but in the past
when I saw this issue it went like this:
a) Say session time out is 30 seconds.
b) If we kill the instance which create the zookeeper ephemeral node and
bring it back up quickly (less than 30 seconds) we would find the previous
session data (ephemeral node) still exists.

The solution was to assume the existing data was from an old session,
delete and re-create it during startup. However, we were processing the
zookeeper events on a single thread.

On Fri, Aug 14, 2015 at 6:34 AM, Flavio Junqueira (JIRA) <jira@apache.org>

;;;","15/Aug/15 06:50;guozhang;Thanks [~fpj], this is very helpful.

Just to add some more context regarding this issue, we have seen issues when ephemeral nodes were not deleted when brokers / consumers try to re-register themselves in ZK upon a session timeout event (details can be found in KAFKA-992). We tried to fix it via adding a registration timestamp into the registration node's data, and checking if the timestamp is different upon seeing it, and if not backing off to wait for this node to be removed.

However people have been also reporting a couple of times that the backing-off is never ending, i.e. the node has a different timestamp, but was never deleted. The suspicion was that there were multiple consequent session creation at a very short period of time, and the node with a different timestamp is created by a session that was not actually expired, and hence will never be gone. But no one has validated if this is the case though.

The logic of re-registration can be found in ZookeeperConsumerConnector.scala and KafkaHealthcheck.scala.;;;","17/Aug/15 21:24;fpj;There are two problems at a high level described here: zk losing ephemerals and ephemerals not going away. I haven't been able to reproduce the former, but I've been able to find one potential problem that could be causing it.

I started by finding suspicious that the ZK listeners were not dealing with session events at all:

{code}
def handleStateChanged(state: KeeperState) {
      // do nothing, since zkclient will do reconnect for us.
}
{code}

 It is quite typical with ZK that you wait for the connected event before making progress. Looking at the ZkClient implementation, I realized that it retries operations in the case of connection loss or session expiration until they go through. There is a race here, though. Say you submit a create, but instead of getting OK as a response, you get connection loss. ZkClient in this case will say ""well, need to retry"" and will get a node exists exception, which the code currently treats as a znode from a previous session. This znode will never go away because it belongs to the current session!

Now let's say we get rid of such corner cases. It is still possible that when the client recovers it finds a znode from a previous session. It can happen because the lease (session) corresponding to the znode is still valid, so ZK can't get rid of it. Revoking leases in general is a bit complicated, but it sounds ok in this case if there is no risky of having multiple incarnations of the same element (a broker) running concurrently.;;;","18/Aug/15 03:47;guozhang;I thought that when the previous session has ended (e.g. expired), its ephemeral node will be ""eventually"" removed? Does ZooKeeper itself have a leasing mechanism?;;;","18/Aug/15 04:44;fpj;bq. I thought that when the previous session has ended (e.g. expired), its ephemeral node will be ""eventually"" removed?

If the session ends cleanly, by the client submitting a closeSession request, then the session closes and the ephemerals are deleted with the request. But, if the client crashes and the server simply stops hearing from the client, then the session has to time out and expire so it takes some time.

bq. Does ZooKeeper itself have a leasing mechanism?

I'm referring to the fact that the ephemeral represents a lease that is revoked when the session times out.

I'm not sure if this is clear, but one of the problems I'm pointing out is that zkclient might end up creating the ephemeral znode in your *current* session. In this case, the znode won't go away. Here is actually another problem I found along the same lines. The createEphemeral call in ZkClient ends up calling retryUntilConnected, which retries even when the session expires:

{code}
            try {
                return callable.call();
            } catch (ConnectionLossException e) {
                // we give the event thread some time to update the status to 'Disconnected'
                Thread.yield();
                waitForRetry();
            } catch (SessionExpiredException e) {
                // we give the event thread some time to update the status to 'Expired'
                Thread.yield();
                waitForRetry();
            }
{code}

In this case, say that one call to createEphemeral via handleNewSession happens during a given session, but the session expires before the operation goes through. The client will retry with the new session. When the consumer tries again, it will fail because the znode is there and won't go away. This is another case in which the znode won't go away because it has been created in the current session.;;;","18/Aug/15 08:03;guozhang;[~fpj] That makes sense. So it seems the right resolution should be at the ZkClient layer, not on Kafka's layer?;;;","18/Aug/15 23:19;fpj;It doesn't look like it 'd be a small change to zkclient to fix this. We essentially need it to expose zk events as they occur. In the way it currently does it, the events are serialized and the operations are retried transparently so I don't know if the znode already exists because of a connection loss or if the session actually expired and there is a new one now. 

The simplest way around this seems to be to just re-register the consumer directly (delete and create) upon a node exists exception. This should work because of the following argument.

There are three possibilities when we get a node exists exception:

# The znode exists from a previous session and hasn't been reclaimed yet
# The znode exists because of a connection loss event while the znode was being created, so the second time we get an exception (event)
# The previous session has expired, a new one was created, and the registration was occurring around this transition, so when we execute handleNewSession for the new session, we get a node exists exception. 

In all these three cases, deleting and recreating seems fine. It is clearly conservative and more expensive than necessary, but at least it doesn't require changes to zkclient. Does it sound a reasonable? Do you see any problem? 

CC [~guozhang] [~jwlent@gmail.com];;;","19/Aug/15 00:16;guozhang;Thanks [~fpj], that makes sense to me. [~jwlent55] do you want to submit a new patch following this approach?;;;","19/Aug/15 00:51;fpj;[~guozhang] it looks like [~jwlent@gmail.com] isn't in the list of contributors, could you add him so that we can assign the jira to him?;;;","19/Aug/15 21:16;jwlent55;Your approach sounds much simpler than mine (which I like).  Similar to what I proposed doing only at startup (ensureNodeDoesNotExist method).  I am however not sure I understand the exact change you propose.  As I remember the createEphemeralPathExpectConflictHandleZKBug is called by three code paths:

- Register Broker
- Register Consumer
- Leadership election  

In my change I specifically tried avoid changing the Leadership election logic.

Is your change basically to implement your new logic (delete if already exists) instead of calling createEphemeralPathExpectConflictHandleZKBug in the first two cases?  If so I agree it sounds reasonable.  I suppose in a misconfiguration case two nodes might get into a registration war over the Broker node, but, that could (perhaps) be handled at startup (second one fails to start up).

If your propose replacing the createEphemeralPathExpectConflictHandleZKBug for the Leadership election case too then I am less comfortable making (and testing) that change.  I have never really dug into that logic too much.

One other factor to consider is that I am a bit backed up a work right now and this will not be issue will not be my highest priority.
;;;","20/Aug/15 02:38;guozhang;[~jwlent55] I agree that this fix may be just for broker / consumer registration, i.e. ZK should not be used to detect mis-configuration that two brokers / clients use the same Id. Hence for that case, in the new approach they may end-up in a delete-and-write war. We should consider fixing such mis-operation in a different manner which is orthogonal to this JIRA. For leader election, one should not simply delete the path upon conflict, we should leave it as is. In the future, we should either fix the root cause in ZkClient or move on to use a different client as KIP-30 is current discussing about.

If you do not have time this week and feel it is OK, [~fpj] could you help taking it over?;;;","20/Aug/15 05:22;fpj;I'm indeed proposing to get rid of createEphemeralPathExpectConflictHandleZKBug. I can investigate the impact to leadership election.;;;","25/Aug/15 00:06;fpj;Given that it isn't clear that we will be getting curator as a dependency, I started a fix that pretty much relies on the ZK handle that ZkClient creates. Here is a preliminary patch that fixes the issues we have been discussing for the consumer registration by simply not retrying the creation of the registration znode across sessions. Given that I'm not using the ZkClient API, there is a bit of wiring to be done, but I hope it is ok.;;;","26/Aug/15 03:37;guozhang;Thanks [~fpj], thanks for the patch. Here are some high-level comments:

1. Will the mixing usage of ZK directly and ZkClient together violate ordering? AFAIK ZkClient orders all events fired by watchers and hand them to the user callbacks one-by-one, if we use ZK's Watcher directly will its callback be called out-of-order with other events?

2. If we get a Code.OK in CreateCallback, do we still need to trigger a ZooKeeper.exist with ExistsCallback again?

3. For the consumer / server registration case particularly, we tries to handle parent path creation in ZkUtils.makeSurePersistentPathExists, so I feel we should expose the problem that parent path does not exist yet instead trying to hide it in createRecursive.;;;","29/Aug/15 23:17;githubbot;GitHub user fpj opened a pull request:

    https://github.com/apache/kafka/pull/178

    KAFKA-1387: Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time

    This is a patch to get around the problem discussed in the KAFKA-1387 jira. The tests are not passing in my box when I run them all, but they do pass when I run them individually, which indicates that there is something leaking from a test to the next. I still need to work this out and also work on further testing this. I wanted to open this PR now so that it can start getting reviewed.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/fpj/kafka 1387

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/178.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #178
    
----
commit f8be8657e649d0490e9ed1f1ef52234b3c31435e
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-23T13:55:11Z

    KAFKA-1387: First cut, node dependency on curator

commit b8f901b6478d4ac9c961e899d702e6fc11cfee07
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-23T13:55:11Z

    KAFKA-1387: First cut, node dependency on curator

commit 2369e66921f88b2ee1b24ddeff2bf2d050015447
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-23T14:07:41Z

    Merge branch '1387' of https://github.com/fpj/kafka into 1387

commit f03c301d5d919d9c05c6837de508b4f383906fdb
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-23T13:55:11Z

    KAFKA-1387: First cut, node dependency on curator

commit d8eab9e0f569eaaecb4afda4d486d00600ad1e6f
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-24T14:56:01Z

    KAFKA-1387: Some polishing

commit b7cbe5dbecbc28a564b99209114f39db785c73dd
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-24T15:50:58Z

    KAFKA-1387: Style fixes

commit 336f67c641c44b73ac1dbb66cdde4ff97f2fcd9a
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-24T15:53:18Z

    KAFKA-1387: More style fixes

commit 201ab2dcc33ba10a19c51f7452ce40497d3fcf83
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-24T15:59:32Z

    Merge branch '1387' of https://github.com/fpj/kafka into 1387

commit 9961665230e04331f7767d8aa8aaac0a14f46cd8
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-23T13:55:11Z

    KAFKA-1387: First cut, node dependency on curator

commit b52c12422f7a831137d8659f14779eaad1972217
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-24T14:56:01Z

    KAFKA-1387: Some polishing

commit b2400a0a37555250d50b1f1abfdda2c4d00b03ac
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-24T15:50:58Z

    KAFKA-1387: Style fixes

commit 888f6e0cf17d6a3a8d6b8dd46f8099731ba36511
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-24T15:53:18Z

    KAFKA-1387: More style fixes

commit d675b024b0e8627c4c2c9c113c07527851e81f7a
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-29T15:00:07Z

    KAFKA-1387

commit 4c83ac2609ed29a0f1887bf5087dab50e3e93488
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-29T15:07:23Z

    KAFKA-1387: Removing whitespaces.

commit 240b51a77715c53db784d5932702318ff28468c2
Author: flavio junqueira <fpj@apache.org>
Date:   2015-08-29T15:11:30Z

    Merge branch '1387' of https://github.com/fpj/kafka into 1387

----
;;;","23/Sep/15 05:09;fpj;hey [~guozhang]

bq. Will the mixing usage of ZK directly and ZkClient together violate ordering? AFAIK ZkClient orders all events fired by watchers and hand them to the user callbacks one-by-one, if we use ZK's Watcher directly will its callback be called out-of-order with other events?

ZkClient indeed handles the processing to a separate thread. To avoid blocking the dispatcher thread, it uses a separate thread to deliver events. This can be a problem if the events here and events handled directly by ZkClient are correlated. I tried to confine the ZK processing for this feature in the same class to avoid ordering issues. I don't see a problem concretely, but if you do, let me know. Right now it sounds like you're just speculating that it could be a problem, yes?

bq. If we get a Code.OK in CreateCallback, do we still need to trigger a ZooKeeper.exist with ExistsCallback again?

Right, that exists call is to set a watch.

bq. For the consumer / server registration case particularly, we tries to handle parent path creation in ZkUtils.makeSurePersistentPathExists, so I feel we should expose the problem that parent path does not exist yet instead trying to hide it in createRecursive.

I've commented on the PR about this. What's your specific concern here? If you could elaborate a bit more, I'd appreciate.  ;;;","25/Sep/15 01:14;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/178
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Exception in ConnectionQuotas while shutting down,KAFKA-1577,12732652,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,sriharsha,jjkoshy,jjkoshy,08/Aug/14 03:47,29/Sep/15 06:03,22/Mar/23 15:10,30/Sep/14 09:26,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,newbie,,,,,"{code}
[2014-08-07 19:38:08,228] ERROR Uncaught exception in thread 'kafka-network-thread-9092-0': (kafka.utils.Utils$)
java.util.NoSuchElementException: None.get
        at scala.None$.get(Option.scala:185)
        at scala.None$.get(Option.scala:183)
        at kafka.network.ConnectionQuotas.dec(SocketServer.scala:471)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:158)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:150)
        at kafka.network.AbstractServerThread.closeAll(SocketServer.scala:171)
        at kafka.network.Processor.run(SocketServer.scala:338)
        at java.lang.Thread.run(Thread.java:662)
{code}",,bcalmac,german.borbolla,jjkoshy,kengo,nehanarkhede,olindaspider,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Sep/14 06:41;sriharsha;KAFKA-1577.patch;https://issues.apache.org/jira/secure/attachment/12671574/KAFKA-1577.patch","14/Aug/14 00:11;sriharsha;KAFKA-1577.patch;https://issues.apache.org/jira/secure/attachment/12661480/KAFKA-1577.patch","21/Aug/14 10:58;sriharsha;KAFKA-1577_2014-08-20_19:57:44.patch;https://issues.apache.org/jira/secure/attachment/12663328/KAFKA-1577_2014-08-20_19%3A57%3A44.patch","26/Aug/14 22:33;sriharsha;KAFKA-1577_2014-08-26_07:33:13.patch;https://issues.apache.org/jira/secure/attachment/12664397/KAFKA-1577_2014-08-26_07%3A33%3A13.patch","27/Sep/14 10:13;sriharsha;KAFKA-1577_2014-09-26_19:13:05.patch;https://issues.apache.org/jira/secure/attachment/12671615/KAFKA-1577_2014-09-26_19%3A13%3A05.patch","31/Aug/14 00:01;bcalmac;KAFKA-1577_check_counter_before_decrementing.patch;https://issues.apache.org/jira/secure/attachment/12665570/KAFKA-1577_check_counter_before_decrementing.patch","15/Jan/15 12:22;german.borbolla;kafka-logs.tar.gz;https://issues.apache.org/jira/secure/attachment/12692440/kafka-logs.tar.gz",,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,410680,,,Mon Sep 28 22:03:08 UTC 2015,,,,,,,,,,"0|i1ynn3:",410673,,jjkoshy,,,,,,,,,,,,,,,,,,"14/Aug/14 00:11;sriharsha;Created reviewboard https://reviews.apache.org/r/24653/diff/
 against branch origin/trunk;;;","14/Aug/14 07:41;sriharsha;[~jjkoshy] Can you please share some details on which conditions this error happened. I tried reproduce the case with 3 brokers and 2 topics with  replicationFactor 2 . Shutting down any or all of the brokers didn't cause this exception to be thrown.  Thanks.;;;","14/Aug/14 09:39;jjkoshy;Unfortunately I don't have reliable steps to reproduce - it shows up rarely: bring up a single broker and shut it down immediately - let me revisit this tomorrow and I'll get back to you.;;;","15/Aug/14 05:17;jjkoshy;[~sriharsha] I tried reproducing this again and as I mentioned it is a
corner case so it is hard to catch. Anyway, here is the root cause:

This only happens during shutdown. We close out existing selection keys as
the requests are completed. When closing the key, we close the associated
channel (which decrements connection count) and then cancel the key.
Although the key is canceled, it will be removed from the selector only on
the next select. The shutdown process proceeds to close all the keys of the
selector (i.e., socket server's closeAll). However, the above key (and
associated closed channel) may still be there which is why we see this
exception.

So I think we can swallow this error if we are shutting down and place a
comment in the code on why we are swallowing it.
;;;","21/Aug/14 10:58;sriharsha;Updated reviewboard https://reviews.apache.org/r/24653/diff/
 against branch origin/trunk;;;","26/Aug/14 22:33;sriharsha;Updated reviewboard https://reviews.apache.org/r/24653/diff/
 against branch origin/trunk;;;","31/Aug/14 00:01;bcalmac;Aside from swallowing the exception at top level, wouldn't it be good to also fix {{ConnectionQuotas.dec()}} and check for {{isDefined()}} before decrementing the counter?

As an undesired side-effect of allowing the NoSuchElementException in the first place, the close() methods after dec() in the code below would not get called.

{code}
  def close(channel: SocketChannel) {
    if(channel != null) {
      debug(""Closing connection from "" + channel.socket.getRemoteSocketAddress())
      connectionQuotas.dec(channel.socket.getInetAddress)
      swallowError(channel.socket().close())
      swallowError(channel.close())
    }
  }
{code}

See https://reviews.apache.org/r/25213/ and the patch [^KAFKA-1577_check_counter_before_decrementing.patch].
;;;","06/Sep/14 03:10;jjkoshy;The exception would only occur if the socket and channel were closed in the first place, no?;;;","06/Sep/14 03:48;bcalmac;Maybe, I don't know the code well enough to draw that conclusion. But what would be a good reason to allow the exception in the first place? The exception isn't caused by an external factor but by a programming error (the assumption that the Option always has a value).

This puts pressure on all methods up the call hierarchy to do a proper cleanup after a RuntimeException. The {{close()}} method I mentioned was just an example. Why look for trouble?;;;","06/Sep/14 04:44;jjkoshy;I think the main reason to allow the exception (as opposed to an existence check) is that it should never happen. If it does, then it is a bug and we need to know about it. We can either receive a runtime exception or do an existence check and log an error. There are a number of places elsewhere in the code where we expect keys to be present. If not it is a (potentially serious) bug - we would rather let an exception be thrown rather than do an existence check and log an error especially if it is a serious issue. In this case we traced the cause of this occurrence to a race condition that only happens during shutdown which is why swallowing at that point is reasonable since that is the only circumstance under which a missing key is possible (and okay). Going forward, if the exception shows up anytime other than shutdown then we will need to again debug why that is the case and fix it - e.g., if it is related to the same race condition then we should fix that race condition.;;;","06/Sep/14 04:57;bcalmac;OK, makes sense. Now, if this is the case, shouldn't the exception be swallowed as soon as possible as below:

{code}
  def close(channel: SocketChannel) {
    if(channel != null) {
      debug(""Closing connection from "" + channel.socket.getRemoteSocketAddress())
      swallowError(connectionQuotas.dec(channel.socket.getInetAddress)) // known race condition may lead to NoSuchElementException
      swallowError(channel.socket().close())
      swallowError(channel.close())
    }
  }
{code}

It might make no difference at runtime, but the code is more readable.;;;","06/Sep/14 05:30;jjkoshy;We can do that, but it does allow the error to go undetected (apart from the error log) and execution continues (even in the non-shutdown case). It is a bug if the element does not exist - i.e., execution should not proceed beyond this point which is what an exception provides. The swallow is okay in the shutdown code because we explicitly allow the key's non-existence there.;;;","06/Sep/14 05:35;bcalmac;You're right. Thanks for the explanation.;;;","26/Sep/14 11:52;nehanarkhede;See KAFKA-1652;;;","27/Sep/14 02:40;sriharsha;[~nehanarkhede] [~jjkoshy]
This issue happens when the shutdown process started in the broker and the SocketServer.Processor.run throws EOFException and it calls close(key) which deletes the key from connectionQuota and also calls key.cancel() but it doesn't remove the key from the Selector.keys until next selection process begins  "" Cancelled keys are removed from the key set during selection operations."" (from java doc).
broker shutdown process calls SocketServer.shutdown() which goes through selector.keys and calls close on each of them since there is no selection operation happened cancelled key in the previous step still exist in selector.keys but its deleted from conncetionQuotas causing it throw that exception.
one way to fix this is to force the selection operation in closeAll() 
this.selector.selectNow()
Its an unnecessary operation in closeAll but it will clear up any cancelled keys from selector.keys(). Please let me know your thoughts on this.;;;","27/Sep/14 02:51;jjkoshy;Oh now I remember this - the root cause is as described above and in my earlier comment. The original patch only prevents the exception from escaping which actually causes shutdown to hang. The error is still logged - which I thought was annoying but can be addressed by logging. From my last comment in the original RB:

{quote}
Thanks for the patch - this is what I had in mind. The stack trace still shows up in the log though - I forgot that although swallow keeps the exception from bubbling up further, it still logs the exception which is annoying.
However, the shutdown no longer hangs (as it used to) so your patch works.
So I think it would be reasonable to just change this to swallow (which means swallowWarn) and let the exception show up in the logs for now.
There is a separate effort to improve our logging convention and the current recommendation (for this instance) is to avoid showing the stack trace. That will be done in the jiras that come out of https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Error+Handling+and+Logging
{quote}
;;;","27/Sep/14 02:56;jjkoshy;I think selectNow is a good option.;;;","27/Sep/14 03:44;nehanarkhede;[~jjkoshy] I could also reproduce the hang in addition to just the error message during shutdown.;;;","27/Sep/14 03:53;jjkoshy;Hmm.. that is really weird - since the swallow doesn't allow the exception to escape. Do you have a full threaddump when this happened?;;;","27/Sep/14 04:35;sriharsha;[~nehanarkhede] I am not able to reproduce the hang. Shutdown process goes through fine for me apart from the exception showing up in logs. Were you able to reproduce this by following steps in KAFKA-1652 with one broker . ;;;","27/Sep/14 05:03;nehanarkhede;[~jjkoshy], [~sriharsha] I remember I tried taking a thread dump and later couldn't find the output of the thread dump in server.log. Finally, just hard killed the broker and all of this happened within 2 minutes. Will try to reproduce again and spend more time collecting the thread dump. Also, thinking again, I'm actually not a 100% sure that I could reproduce the hang on latest trunk. It is possible that I hadn't rebased my local trunk :);;;","27/Sep/14 06:41;sriharsha;Created reviewboard https://reviews.apache.org/r/26107/diff/
 against branch origin/trunk;;;","27/Sep/14 10:13;sriharsha;Updated reviewboard https://reviews.apache.org/r/26107/diff/
 against branch origin/trunk;;;","30/Sep/14 09:26;jjkoshy;Committed to trunk;;;","10/Jan/15 08:55;german.borbolla;This is marked as Fix version for 0.8.2 however I just encountered the same issue using the latest source from the 0.8.2 branch.

Perhaps it was only committed to trunk? Is there any chance this will be included in 0.8.2?

Here's the stack trace: 
{noformat}
[2015-01-09 15:53:12,486] ERROR Uncaught exception in thread 'kafka-network-thread-9092-4': (kafka.utils.Utils$)
java.util.NoSuchElementException: None.get
        at scala.None$.get(Option.scala:322)
        at scala.None$.get(Option.scala:320)
        at kafka.network.ConnectionQuotas.dec(SocketServer.scala:524)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:165)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:157)
        at kafka.network.Processor.close(SocketServer.scala:374)
        at kafka.network.AbstractServerThread.closeAll(SocketServer.scala:180)
        at kafka.network.Processor.run(SocketServer.scala:364)
        at java.lang.Thread.run(Thread.java:745)
{noformat}

Thanks;;;","10/Jan/15 11:20;sriharsha;[~german.borbolla] The patch is in 0.8.2 branch . I'll try to see if I can reproduce this again. ;;;","10/Jan/15 11:42;german.borbolla;[~sriharsha] you're right, this happened twice to me today. In both cases the broker had something around 30000 partitions and controlled shutdown finished successfully. This is a nine node cluster and each was similarly loaded. 

I should be able to get you the logs if it helps to debug.;;;","10/Jan/15 11:56;sriharsha;[~german.borbolla] can you please attach some logs . Thanks.;;;","15/Jan/15 12:22;german.borbolla;[~sriharsha] Sorry for the delay, I lost the previous logs but I was able to reproduce this.;;;","16/Jan/15 00:11;jjkoshy;[~german.borbolla] can you make sure you don't have a stray kafka jar in your classpath? I have noticed this when switching across git hashes that include changes to our build mechanism. Do a gradlew clean and ensure that ""find . -name kafka*.jar"" returns nothing and then rebuild before trying to reproduce this.;;;","16/Jan/15 00:15;german.borbolla;I will try to reproduce with the release candidate for 0.8.2;;;","29/Sep/15 06:03;olindaspider;I believe I have found the root cause of this issue as explained here: https://issues.apache.org/jira/browse/KAFKA-1804?focusedCommentId=14909940&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14909940;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Metadata request issued with no backoff in new producer if there are no topics,KAFKA-1919,12772419,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,jkreps,jkreps,jkreps,05/Feb/15 01:11,23/Feb/15 07:07,22/Mar/23 15:10,22/Feb/15 08:00,0.8.2.0,,,,,,0.8.2.1,,,,,,,,,,,0,,,,,,"Original report:
We have observed high cpu and high network traffic problem when
1) cluster (0.8.1.1) has no topic
2) KafkaProducer (0.8.2-beta) object is created without sending any traffic

We have observed such problem twice. In both cases, problem went away
immediately after one/any topic is created.

Is this a known issue? Just want to check with the community first before I
spend much time to reproduce it.

I couldn't reproduce the issue with similar setup with unit test code in
IDE. start two brokers with no topic locally on my laptop. create a
KafkaProducer object without sending any msgs. but I only tested with
0.8.2-beta for both broker and producer.

Issue exists in 0.8.2 as well:
I have re-run my unit test with 0.8.2.0. same tight-loop problem happened
after a few mins.",,guozhang,jkreps,stevenz3wu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Feb/15 09:04;jkreps;KAFKA-1919-v1.patch;https://issues.apache.org/jira/secure/attachment/12696629/KAFKA-1919-v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Feb 22 00:00:12 UTC 2015,,,,,,,,,,"0|i256v3:",9223372036854775807,,jkreps,,,,,,,,,,,,,,,,,,"05/Feb/15 01:15;stevenz3wu;enabled TRACE level logging. it shows tight loop with metadata request. two metadata requests in the same milli-seconds
{code}
kafka-producer-network-thread | foo 08:58:34,917 TRACE NetworkClient:315 - Ignoring empty metadata response with correlation id 1473532.
kafka-producer-network-thread | foo 08:58:34,917 DEBUG NetworkClient:385 - Trying to send metadata request to node -2
kafka-producer-network-thread | foo 08:58:34,917 DEBUG NetworkClient:390 - Sending metadata request ClientRequest(expectResponse=true, payload=null, request=RequestSend(header={api_key=3,api_version=0,correlation_id=1473533,client_id=foo}, body={topics=[]})) to node -2
kafka-producer-network-thread | foo 08:58:34,917 TRACE NetworkClient:315 - Ignoring empty metadata response with correlation id 1473533.
kafka-producer-network-thread | foo 08:58:34,917 DEBUG NetworkClient:385 - Trying to send metadata request to node -2
kafka-producer-network-thread | foo 08:58:34,918 DEBUG NetworkClient:390 - Sending metadata request ClientRequest(expectResponse=true, payload=null, request=RequestSend(header={api_key=3,api_version=0,correlation_id=1473534,client_id=foo}, body={topics=[]})) to node -2
kafka-producer-network-thread | foo 08:58:34,918 TRACE NetworkClient:315 - Ignoring empty metadata response with correlation id 1473534.
kafka-producer-network-thread | foo 08:58:34,918 DEBUG NetworkClient:385 - Trying to send metadata request to node -2
kafka-producer-network-thread | foo 08:58:34,918 DEBUG NetworkClient:390 - Sending metadata request ClientRequest(expectResponse=true, payload=null, request=RequestSend(header={api_key=3,api_version=0,correlation_id=1473535,client_id=foo}, body={topics=[]})) to node -2
kafka-producer-network-thread | foo 08:58:34,918 TRACE NetworkClient:315 - Ignoring empty metadata response with correlation id 1473535.
kafka-producer-network-thread | foo 08:58:34,918 DEBUG NetworkClient:385 - Trying to send metadata request to node -2
{code};;;","05/Feb/15 05:12;stevenz3wu;this is the producer metrics at the beginning of the test. it's all idle.
{code}
main 13:06:54,212  INFO EmptyTopicTest:52 - [request-latency-avg] NaN
main 13:06:54,213  INFO EmptyTopicTest:52 - [outgoing-byte-rate] NaN
main 13:06:54,213  INFO EmptyTopicTest:52 - [batch-size-avg] NaN
main 13:06:54,213  INFO EmptyTopicTest:52 - [connection-close-rate] NaN
main 13:06:54,213  INFO EmptyTopicTest:52 - [record-size-max] -Infinity
main 13:06:54,214  INFO EmptyTopicTest:52 - [waiting-threads] 0.0
main 13:06:54,214  INFO EmptyTopicTest:52 - [record-queue-time-avg] NaN
main 13:06:54,214  INFO EmptyTopicTest:52 - [connection-count] 0.0
main 13:06:54,215  INFO EmptyTopicTest:52 - [metadata-age] 120.032
main 13:06:54,215  INFO EmptyTopicTest:52 - [request-size-max] -Infinity
main 13:06:54,215  INFO EmptyTopicTest:52 - [records-per-request-avg] NaN
main 13:06:54,216  INFO EmptyTopicTest:52 - [record-retry-rate] NaN
main 13:06:54,216  INFO EmptyTopicTest:52 - [record-send-rate] NaN
main 13:06:54,216  INFO EmptyTopicTest:52 - [buffer-total-bytes] 3.3554432E7
main 13:06:54,216  INFO EmptyTopicTest:52 - [network-io-rate] NaN
main 13:06:54,217  INFO EmptyTopicTest:52 - [response-rate] NaN
main 13:06:54,217  INFO EmptyTopicTest:52 - [io-wait-time-ns-avg] NaN
main 13:06:54,217  INFO EmptyTopicTest:52 - [compression-rate-avg] NaN
main 13:06:54,217  INFO EmptyTopicTest:52 - [incoming-byte-rate] NaN
main 13:06:54,217  INFO EmptyTopicTest:52 - [bufferpool-wait-ratio] NaN
main 13:06:54,218  INFO EmptyTopicTest:52 - [connection-creation-rate] NaN
main 13:06:54,218  INFO EmptyTopicTest:52 - [buffer-available-bytes] 3.3554432E7
main 13:06:54,218  INFO EmptyTopicTest:52 - [record-queue-time-max] -Infinity
main 13:06:54,218  INFO EmptyTopicTest:52 - [record-size-avg] NaN
main 13:06:54,219  INFO EmptyTopicTest:52 - [record-error-rate] NaN
main 13:06:54,219  INFO EmptyTopicTest:52 - [request-latency-max] -Infinity
main 13:06:54,219  INFO EmptyTopicTest:52 - [request-rate] NaN
main 13:06:54,219  INFO EmptyTopicTest:52 - [batch-size-max] -Infinity
main 13:06:54,220  INFO EmptyTopicTest:52 - [io-time-ns-avg] NaN
main 13:06:54,220  INFO EmptyTopicTest:52 - [select-rate] NaN
main 13:06:54,220  INFO EmptyTopicTest:52 - [io-ratio] NaN
main 13:06:54,220  INFO EmptyTopicTest:52 - [requests-in-flight] 0.0
main 13:06:54,220  INFO EmptyTopicTest:52 - [io-wait-ratio] NaN
main 13:06:54,221  INFO EmptyTopicTest:52 - [request-size-avg] NaN
{code};;;","05/Feb/15 05:13;stevenz3wu;this is the producer metrics when cpu shoot up to 100% on one core. it clears shows request rate shoot up to the roof.
 [request-rate] 18716.091686350177

{code}
main 13:10:54,254  INFO EmptyTopicTest:52 - [request-latency-avg] NaN
main 13:10:54,254  INFO EmptyTopicTest:52 - [outgoing-byte-rate] 393038.5293628348
main 13:10:54,254  INFO EmptyTopicTest:52 - [batch-size-avg] NaN
main 13:10:54,254  INFO EmptyTopicTest:52 - [connection-close-rate] NaN
main 13:10:54,254  INFO EmptyTopicTest:52 - [record-size-max] -Infinity
main 13:10:54,255  INFO EmptyTopicTest:52 - [waiting-threads] 0.0
main 13:10:54,255  INFO EmptyTopicTest:52 - [record-queue-time-avg] NaN
main 13:10:54,255  INFO EmptyTopicTest:52 - [connection-count] 1.0
main 13:10:54,255  INFO EmptyTopicTest:52 - [metadata-age] 360.072
main 13:10:54,255  INFO EmptyTopicTest:52 - [request-size-max] 21.0
main 13:10:54,255  INFO EmptyTopicTest:52 - [records-per-request-avg] NaN
main 13:10:54,255  INFO EmptyTopicTest:52 - [record-retry-rate] NaN
main 13:10:54,256  INFO EmptyTopicTest:52 - [record-send-rate] NaN
main 13:10:54,256  INFO EmptyTopicTest:52 - [buffer-total-bytes] 3.3554432E7
main 13:10:54,256  INFO EmptyTopicTest:52 - [network-io-rate] 37432.278670526
main 13:10:54,256  INFO EmptyTopicTest:52 - [response-rate] 18715.822784810127
main 13:10:54,256  INFO EmptyTopicTest:52 - [io-wait-time-ns-avg] 19766.866064623417
main 13:10:54,256  INFO EmptyTopicTest:52 - [compression-rate-avg] NaN
main 13:10:54,257  INFO EmptyTopicTest:52 - [incoming-byte-rate] 224586.38952733087
main 13:10:54,257  INFO EmptyTopicTest:52 - [bufferpool-wait-ratio] NaN
main 13:10:54,257  INFO EmptyTopicTest:52 - [connection-creation-rate] NaN
main 13:10:54,257  INFO EmptyTopicTest:52 - [buffer-available-bytes] 3.3554432E7
main 13:10:54,257  INFO EmptyTopicTest:52 - [record-queue-time-max] -Infinity
main 13:10:54,257  INFO EmptyTopicTest:52 - [record-size-avg] NaN
main 13:10:54,258  INFO EmptyTopicTest:52 - [record-error-rate] NaN
main 13:10:54,258  INFO EmptyTopicTest:52 - [request-latency-max] -Infinity
main 13:10:54,258  INFO EmptyTopicTest:52 - [request-rate] 18716.091686350177
main 13:10:54,258  INFO EmptyTopicTest:52 - [batch-size-max] -Infinity
main 13:10:54,258  INFO EmptyTopicTest:52 - [io-time-ns-avg] 5109.803392094824
main 13:10:54,258  INFO EmptyTopicTest:52 - [select-rate] 37431.806091235536
main 13:10:54,259  INFO EmptyTopicTest:52 - [io-ratio] 0.19126365661468897
main 13:10:54,259  INFO EmptyTopicTest:52 - [requests-in-flight] 1.0
main 13:10:54,259  INFO EmptyTopicTest:52 - [io-wait-ratio] 0.7398999567776041
main 13:10:54,259  INFO EmptyTopicTest:52 - [request-size-avg] 21.0
{code};;;","05/Feb/15 09:00;jkreps;Here is what I think is happening: in 0.8.1 the metadata request just gives back nodes for the requested topics. But in this case there are no requested topics so there are no nodes. When we get a metadata response with no nodes we actually ignore it, because if we update our view of the cluster with one that has no machines then we have nowhere to even make metadata requests. Unfortunately by not updating the cluster we are bypassing the backoff the prevents another request from being issued.

I suspect this doesn't happen against a 0.8.2 server because in 0.8.2 we are giving back all the nodes no matter what in the metadata response specifically to avoid every running into a situation where there is no one to issue metadata requests against. I think the fix is to ""update"" the metadata with the existing metadata not the new (empty) metadata so as to guarantee that the backoff will always come into effect.

[~stevenz3wu] I have a patch that I think will fix this if I understand the root cause. Want to give it a shot?;;;","05/Feb/15 12:34;stevenz3wu;this does happen with 0.8.2.0 server. In my local unit test, both producer and server are 0.8.2.0.

[~jkreps] will try the patch later this week. ;;;","07/Feb/15 06:58;stevenz3wu;[~jkreps] I tried your patch, it seems to fix the issue. 

I dumped the request-rate metric every minutes. you can see that there are some requests for metadata every 5 minutes, which is the default setting for “metadata.max.age.ms”.

results before the patch
=============================================
main 14:38:36,155  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:39:36,159  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:40:36,162  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:41:36,163  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:42:36,167  INFO EmptyTopicTest:55 - request-rate=55.55555555555556
main 14:43:36,171  INFO EmptyTopicTest:55 - request-rate=18419.406415509144
main 14:44:36,174  INFO EmptyTopicTest:55 - request-rate=18342.581182348044
main 14:45:36,177  INFO EmptyTopicTest:55 - request-rate=18233.315572132677
main 14:46:36,181  INFO EmptyTopicTest:55 - request-rate=18464.50452850293
main 14:47:36,183  INFO EmptyTopicTest:55 - request-rate=18489.045748152093
main 14:48:36,186  INFO EmptyTopicTest:55 - request-rate=18627.492758930654
main 14:49:36,190  INFO EmptyTopicTest:55 - request-rate=18563.315579227696
main 14:50:36,192  INFO EmptyTopicTest:55 - request-rate=18632.093998602006
main 14:51:36,195  INFO EmptyTopicTest:55 - request-rate=18558.976236437462
main 14:52:36,199  INFO EmptyTopicTest:55 - request-rate=18533.111480865224

results after the patch
=============================================
main 14:12:54,920  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:13:54,924  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:14:54,927  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:15:54,931  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:16:54,933  INFO EmptyTopicTest:55 - request-rate=55.55555555555556
main 14:17:54,935  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:18:54,939  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:19:54,942  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:20:54,946  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:21:54,950  INFO EmptyTopicTest:55 - request-rate=29.41176470588235
main 14:22:54,954  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:23:54,956  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:24:54,959  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:25:54,962  INFO EmptyTopicTest:55 - request-rate=NaN
main 14:26:54,964  INFO EmptyTopicTest:55 - request-rate=21.27659574468085;;;","09/Feb/15 08:08;guozhang;Comments for the patch: instead of calling metadata.update(), shall we just update its lastRefreshMs?;;;","09/Feb/15 09:05;jkreps;That's reasonable. Patch here:
https://reviews.apache.org/r/30777/

This is actually a more serious issue if the bug exists even against 0.8.2. Not sure that we should consider it serious enough for a 0.8.2.1 though.;;;","22/Feb/15 08:00;jkreps;Double committed against trunk and 0.8.2;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Offset Management API is either broken or mis-documented,KAFKA-993,12660911,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,eapache,eapache,31/Jul/13 22:43,24/Aug/13 01:36,22/Mar/23 15:10,21/Aug/13 21:27,0.8.0,0.8.1,,,,,,,,,,,,network,,,,0,,,,,,"I am in the process of building a set of Go client bindings for the new 0.8 protocol (https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol). Everything works but the Offset Commit/Fetch APIs. Fetch never returns any data, and trying to Commit results in the broker forcibly disconnecting my client. I have double-checked the bytes on the wire using Wireshark, and my client is obeying the protocol spec.

After some digging, I found KAFKA-852 which seems related, but I have tried my client against the 0.8 beta, 0.8 branch, and even trunk with the same results.

When I try and commit, the stack-trace that the broker produces is:
[2013-07-31 10:34:14,423] ERROR Closing socket for /192.168.12.71 because of error (kafka.network.Processor)
java.nio.BufferUnderflowException
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:127)
	at java.nio.ByteBuffer.get(ByteBuffer.java:675)
	at kafka.api.ApiUtils$.readShortString(ApiUtils.scala:38)
	at kafka.api.UpdateMetadataRequest$$anonfun$readFrom$1.apply(UpdateMetadataRequest.scala:42)
	at kafka.api.UpdateMetadataRequest$$anonfun$readFrom$1.apply(UpdateMetadataRequest.scala:41)
	at scala.collection.immutable.Range$ByOne$class.foreach(Range.scala:282)
	at scala.collection.immutable.Range$$anon$2.foreach(Range.scala:265)
	at kafka.api.UpdateMetadataRequest$.readFrom(UpdateMetadataRequest.scala:41)
	at kafka.api.RequestKeys$$anonfun$7.apply(RequestKeys.scala:42)
	at kafka.api.RequestKeys$$anonfun$7.apply(RequestKeys.scala:42)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:49)
	at kafka.network.Processor.read(SocketServer.scala:345)
	at kafka.network.Processor.run(SocketServer.scala:245)
	at java.lang.Thread.run(Thread.java:680)

Is this a bug, or is the protocol spec wrong? Also, since I can't seem to find a straight answer anywhere else: is offset fetch/commit expected to be in 0.8, 0.8.1, or some later release?

Thanks,
Evan",,eapache,edenhill,zhangzs,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-657,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,341100,,,Fri Aug 23 17:36:40 UTC 2013,,,,,,,,,,"0|i1mtvj:",341418,,,,,,,,,,,,,,,,,,,,"21/Aug/13 03:20;eapache;The library is now available at https://github.com/Shopify/sarama

In case somebody wants to add it to the wiki page of client libraries...;;;","21/Aug/13 05:39;lanzaa;I believe this is more of a documentation bug. In the push to get Kafka 0.8 out I think it was decided to postpone the release of the server side Offset Commit API.

As such, the OffsetCommit APIs are only available post 0.8.;;;","21/Aug/13 21:27;eapache;I have updated the protocol wiki to note that these APIs are not available in 0.8. Thanks for the clarification.;;;","24/Aug/13 01:36;lanzaa;Thank you for the help!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Log flush should complete upon broker shutdown,KAFKA-126,12520992,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,jjkoshy,jjkoshy,01/Sep/11 07:58,06/Oct/11 07:05,22/Mar/23 15:10,27/Sep/11 01:35,,,,,,,0.7,,,,,,,,,,,0,,,,,,"Broker shutdown currently forces the flush scheduler to shutdown(Now). This leads to an unclean shutdown. cleanupLogs may be affected by a similar scenario.

2011/08/31 09:45:34.833 ERROR [LogManager] [kafka-logflusher-0] [kafka] Error flushing topic MyTopic
java.nio.channels.ClosedByInterruptException
        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)
        at sun.nio.ch.FileChannelImpl.force(FileChannelImpl.java:362)
        at kafka.message.FileMessageSet.flush(FileMessageSet.scala:174)
        at kafka.log.Log.flush(Log.scala:306)
        at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$flushAllLogs$1.apply(LogManager.scala:274)
        at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$flushAllLogs$1.apply(LogManager.scala:263)
        at scala.collection.Iterator$class.foreach(Iterator.scala:631)
        at kafka.utils.IteratorTemplate.foreach(IteratorTemplate.scala:30)
        at kafka.log.LogManager.kafka$log$LogManager$$flushAllLogs(LogManager.scala:263)
        at kafka.log.LogManager$$anonfun$startup$1.apply$mcV$sp(LogManager.scala:129)
        at kafka.utils.Utils$$anon$2.run(Utils.scala:58)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:317)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:150)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:98)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.runPeriodic(ScheduledThreadPoolExecutor.java:181)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:205)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)

A possible fix this would be to use shutdown() instead of shutdownNow() in the scheduler.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-148,,,,,,,,,,,,,,,,,,"16/Sep/11 03:08;jjkoshy;KAFKA-126_v1.patch;https://issues.apache.org/jira/secure/attachment/12494678/KAFKA-126_v1.patch","21/Sep/11 09:08;jjkoshy;KAFKA-126_v2.patch;https://issues.apache.org/jira/secure/attachment/12495301/KAFKA-126_v2.patch","21/Sep/11 09:10;jjkoshy;KAFKA-126_v3.patch;https://issues.apache.org/jira/secure/attachment/12495302/KAFKA-126_v3.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,3201,,,Mon Sep 26 17:35:11 UTC 2011,,,,,,,,,,"0|i15z1z:",242979,,,,,,,,,,,,,,,,,,,,"16/Sep/11 03:08;jjkoshy;This is pretty much the simple fix that I suggested in the description. i.e., change the shutdown behavior of KafkaScheduler to use shutdown() instead of shutdownNow(). I also added a shutdownNow() method to KafkaScheduler for access to the immediate shutdown behavior.

For testing: I changed the flush settings to:
log.flush.interval=10000
log.default.flush.interval.ms=0
log.default.flush.scheduler.interval.ms=20
ran ProducerPerformance and shut down the broker a couple of times. These settings consistently reproduce the exception without this fix.

The other usages of shutdown (now called shutdownNow) are by the zookeeper offset committer, and the LogManager's log cleanup. I think these schedulers should also switch to using shutdown() and that is accomplished by this patch.

Finally, I'm piggy backing an small unrelated warning message in the producer config - i.e. when both zk.connect and broker.list are specified, zk.connect takes precedence. (Let me know if you prefer this to be removed from this patch.)
;;;","16/Sep/11 09:26;nehanarkhede;Using the executor shutdown API, the process would block until the currently executing thread finishes execution. I guess that works fine unless for some odd reason, the thread blocks on one action forever, in which case the process would have to be killed manually. I can't imagine of a concrete example of when it could block forever though. 

On the other hand, I guess that if/when that kind of blocking happens, it is a serious problem/bug that needs attention anyways. So using the shutdown() API looks like a good approach. 

+1;;;","20/Sep/11 23:46;junrao;Thanks Joel for the patch. The zookeeper offset committer should use shutdownNow. If there is anything wrong with ZK server, we still want to be able to shut down a consumer immedidately.;;;","21/Sep/11 09:08;jjkoshy;That makes sense. Here is the updated patch.;;;","21/Sep/11 09:10;jjkoshy;Oops - forgot to rebase.;;;","27/Sep/11 01:35;junrao;Thanks, Joel. Just committed this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"After a leader change, messages sent with ack=0 are lost",KAFKA-955,12654664,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,jbrosenberg,jbrosenberg,25/Jun/13 13:24,03/Nov/16 15:12,22/Mar/23 15:10,29/Aug/13 01:17,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"If the leader changes for a partition, and a producer is sending messages with ack=0, then messages will be lost, since the producer has no active way of knowing that the leader has changed, until it's next metadata refresh update.

The broker receiving the message, which is no longer the leader, logs a message like this:

Produce request with correlation id 7136261 from client  on partition [mytopic,0] failed due to Leader not local for partition [mytopic,0] on broker 508818741

This is exacerbated by the controlled shutdown mechanism, which forces an immediate leader change.

A possible solution to this would be for a broker which receives a message, for a topic that it is no longer the leader for (and if the ack level is 0), then the broker could just silently forward the message over to the current leader.

",,Bill Zhang,diederik,guozhang,jbrosenberg,jbrosenberg@gmail.com,jkreps,junrao,mazhar.shaikh.in,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Sep/13 06:17;guozhang;KAFKA-955-followup.v1.patch;https://issues.apache.org/jira/secure/attachment/12603129/KAFKA-955-followup.v1.patch","26/Jul/13 08:55;guozhang;KAFKA-955.v1.patch;https://issues.apache.org/jira/secure/attachment/12594303/KAFKA-955.v1.patch","26/Jul/13 07:51;guozhang;KAFKA-955.v1.patch;https://issues.apache.org/jira/secure/attachment/12594296/KAFKA-955.v1.patch","01/Aug/13 01:23;guozhang;KAFKA-955.v2.patch;https://issues.apache.org/jira/secure/attachment/12595217/KAFKA-955.v2.patch","03/Aug/13 06:35;guozhang;KAFKA-955.v3.patch;https://issues.apache.org/jira/secure/attachment/12595686/KAFKA-955.v3.patch","23/Aug/13 01:58;guozhang;KAFKA-955.v4.patch;https://issues.apache.org/jira/secure/attachment/12599462/KAFKA-955.v4.patch","24/Aug/13 00:59;guozhang;KAFKA-955.v5.patch;https://issues.apache.org/jira/secure/attachment/12599655/KAFKA-955.v5.patch","24/Aug/13 05:50;guozhang;KAFKA-955.v6.patch;https://issues.apache.org/jira/secure/attachment/12599718/KAFKA-955.v6.patch","27/Aug/13 07:28;guozhang;KAFKA-955.v7.patch;https://issues.apache.org/jira/secure/attachment/12600049/KAFKA-955.v7.patch",,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,334941,,,Thu Nov 03 07:12:34 UTC 2016,,,,,,,,,,"0|i1lryf:",335265,,,,,,,,,,,,,,,,,,,,"29/Jun/13 21:14;jbrosenberg;Here's a related scenario, that I see after a rolling restart of my brokers (using ack=0).

looking back at my logs, I'm wondering if a producer will reuse the same socket to send data to the same broker, for multiple topics (I'm guessing yes).  In which case, it looks like I'm seeing this scenario:

1. producer1 is happily sending messages for topicX and topicY to serverA (serverA is the leader for both topics, only 1 partition for each topic for simplicity).
2. serverA is restarted, and in the process, serverB becomes the new leader for both topicX and topicY.
3. producer1 decides to send a new message to topicX to serverA.
3a. this results in an exception (""Connection reset by peer"").  producer1's connection to serverA is invalidated.
3b. producer1 makes a new metadata request for topicX, and learns that serverB is now the leader for topicX.
3c. producer1 resends the message to topicX, on serverB.
4. producer1 decides to send a new message to topicY to serverA.
4a. producer1 notes that it's socket to serverA is invalid, so it creates a new connection to serverA.
4b. producer1 successfully sends it's message to serverA (without realizing that serverA is no longer the leader for topicY).
4c. serverA logs to it's console:  
2013-06-23 08:28:46,770  WARN [kafka-request-handler-2] server.KafkaApis - [KafkaApi-508818741] Produce request with correlation id 7136261 from client  on partition [mytopic,0] failed due to Leader not local for partition [mytopic,0] on broker 508818741
5. producer1 continues to send messages for topicY to serverA, and serverA continues to log the same messages.
6. 10 minutes later, producer1 decides to update it's metadata for topicY, and learns that serverB is now the leader for topidY.
7. the warning messages finally stop in the console for serverA.

I am pretty sure this scenario, or one very close to it, is what I'm seeing in my logs, after doing a rolling restart, with controlled shutdown.

I think this scenario makes the issue more severe than just a problem with controlled restart and ack=0.

;;;","01/Jul/13 12:20;junrao;It seems there are various ways that can cause this to happen. (a) In the above scenario, after the leaders fail over, topicX causes new sockets to be established. Then topicY uses the newly established socket without realizing that the leader for topic Y has changed. (b) When we fetch the metadata for a topic, we fetch the metadata for all partitions. Let's say that we never get to send any data to a particular partition. The socket for this partition is not established since  SyncProducer make socket connections lazily on first send. Then the leader for the partition changes. Finally, the producer sends a message to that partition. Now a socket is established to the wrong leader without the producer realizing it.

In general, if we hit any error for produce requests with ack=0, currently the producer won't notice it. For example, if the broker hits a MessageTooLargeException or if the broker hits any other unexpected exceptions. In those cases, forwarding the requests will not help. Also, forwarding requests will complicate the logic in the broker since we have to figure out the broker's host and port, and potentially cache the socket connection to other brokers.

An alternative solution is to simply close the socket connection when we hit any error for produce requests with ack=0. This way, the producer will realize the error on next send.
;;;","26/Jul/13 07:50;guozhang;Following the close-socket approach, I propose the following change:

1. Add a closeSocket: Boolean field in Response class.

2. In KafkaApi.handleProducerRequest, if requireAck == 0 check if numPartitionsInError != 0. If yes set closeSocket to true in the returning response.

3. SocketServer.Processor.processNewResponses, if curr.responseSend == null, check if closeSocket == true. If yes, log the closing socket info and close the key.

;;;","26/Jul/13 08:55;guozhang;Add one case for ack=0 in testSendWithDeadBroker, passed.;;;","31/Jul/13 23:13;junrao;Thanks for the patch. Some comments:

1. SocketServer: We should call updateRequestMetrics even when we close the socket. Otherwise, total time will be broken for that request.

2. ProducerTest: Let's add a new unit test instead of piggybacking on the existing one. What we can do is to create a sync producer and send a produce request with ack=0 that will introduce an error (e.g., a message larger than max size). After that, we can verified that the underlying socket is closed.

3. KafkaApi: In the debug logging, why not log the whole producer request? ;;;","01/Aug/13 01:23;guozhang;Thanks for the comments Jun.

1,2,3. Done.
;;;","03/Aug/13 01:20;junrao;Thanks for patch v2. Some more comments.

20. testSendWithAckZeroDeadBroker(): I am not sure if the unit test does what you want. First of all, setup() will always start brokers for each test unless you explicitly shut them down. So, in this test, the brokers are not dead. Second, the test doesn't really test that the socket is closed after error. I suggest that we add a new test in SyncProducerTest. We send a request with ack=0 with a large message. After that, we can try to send a new request again and we should hit a socket I/O exception. We may have to wait for some time between the two requests.;;;","03/Aug/13 02:13;guozhang;Sorry for the name misleading, I did not shut down the broker but instead send a large message to it to trigger the MessageSizeTooLargeException. The name of the test should be testSendTooLargeMessageWithAckZero.

I will use SyncProducer instead of Producer in this test, and send a normal message to the broker after this message, and expecting it to fail due to socket IO exception.;;;","03/Aug/13 06:35;guozhang;Add the testMessageSizeTooLargeWithAckZero to syncProducerTest, which:

1. First send a large message that will cause the MessageSizeTooLarge exception, and hence close the socket. But this message will be silently dropped and lost.

2. Then send another large message, but just to make sure its size exceeds the buffer size so the socket buffer will be flushed immediately; this send should fail since the socket has been closed.;;;","22/Aug/13 00:57;edenhill;
If the producer is sending messages through the same broker for other topic+partitions that did not have a leader change they will also be affected by the close of the socket, resulting in lost messages.

It would be better if the broker would notify all connected clients of broker changes (leader change, broker add/delete, topic add/delete)
by sending an unsolicited MetadataResponse message (with corrid 0) (or by some other mean).

This would propogate topology changes in a faster and less intrusive way.;;;","22/Aug/13 04:13;guozhang;Hello Magnus,

1. Under Ack=0, the producer does not expect any responses for produce request, and it does not listen to any possible connections from the producer either. So actively sending MetadataResponse would not work: producers are only expecting MetadataResponse when they send MetadataRequest.

2. When we close the socket, producer would be notified and try to refresh their Metadata and retry. Since by default each produce request will be retried multiple times before it is got dropped, the current approach would not cause lost messages.;;;","22/Aug/13 04:33;edenhill;Hi Guozhang,

I understand that you might not want to introduce a new message semantic at this point of the 0.8 beta, but it wont get easier after the release.

My proposal is a change of the protocol definition to allow unsolicited metadata response messages to be sent from the broker, this would of course require changes in most clients, but a very small one for those that are not interested in keeping their leader cache up to date.

Consider a producer forwarding >100kmsgs/s for a number of topics to a broker that suddenly drops the connection because one of those topics changed leader, the producer message queue will quickly build up and might start dropping messages (for topics that didnt loose their leader) due to local queue thresholds or very slowly recover if the current rate of messages is close to the maximum thruput.


In my mind closing the socket because one top+par changed leader is a very intrusive way to signal an event for sub-set of the communication, and it should instead be fixed properly with an unsoliticed metadata response message.

The unsolicited metadata response message is useful for other scenarios aswell, new brokers and topics being added, for instance.

My two cents on the topic, thank you.;;;","23/Aug/13 01:32;junrao;Magnus, thanks for your comment. What you suggested is interesting and could be a more effective way of communicating between the producer and the broker. It does require that the producer be able to receive requests initiated at the broker. We do plan to make the producer side processing selector based for efficiency reason. However, this will be a post 0.8 item. We could consider your suggestion then. Regarding your concern about dropped messages, my take is the following. If a client chooses not to receive an ack, it probably means that losing a few batch of messages is not that important. If a client does care about data loss, it can choose ack with 1 or -1. The throughout will be less. However, there are other ways to improve the throughput (e.g., using a larger batch size and/or more instances of producers).

Guozhang, patch v3 looks good to me overall. A few more comments:

30. SyncProducerTest.testMessagesizeTooLargeWithAckZero(): You hardcoded the sleep to 500ms. Could you change it to the waitUntil style wait such that the test can finish early if the conditions have been met?

31. KafkaApi.handleProducerRequest(): The logging should probably be at debug level since this doesn't indicate an error at the broker. It's really an error for the client.



;;;","23/Aug/13 01:58;guozhang;Thanks for the comments Jun.

30. Done.
31. After a second thought I realized that we do not need to sleep since the second message size is large enough to cause the socket buffer to flush immediately, and by then the socket close should have been triggered by the server. This has been verified in the unit test.

Made some minor changes on comments and rebased on 0.8;;;","24/Aug/13 00:15;nehanarkhede;Thanks for the patches, Guozhang. I reviewed patch v4 and here are some comments -

KafkaApis and SocketServer
1.1 One way to allow the socket server to close the channel is to just mark the request's key cancelled in the Response object. This way when the socket server is handling the response, it will throw a CancelledKeyException and we close the key in this case. One advantage of this approach is we can avoid introducing the close socket flag, just to handle this case. To make sure the request metrics are always updated, we can move curr.request.updateRequestMetrics to the first statement in the (curr.responseSend == null) block.
 
1.2 I think the below warn message can be improved -
Sending the close socket signal due to error handling produce request [%s] with Ack=0

Let's include the client id, correlation id and list of topics and partitions that this request had. This is probably more useful than printing the entire produce request as is, since that attempts to print things like ByteBufferMessageSet and is unreadable.;;;","24/Aug/13 00:59;guozhang;Thanks for the comments Neha.

1.1. Great point. The only concern is that now KafkaApis need to know that requestKey is actually java.nio.channels.SelectionKey. But I think this is fine.

1.2. Done.;;;","24/Aug/13 05:50;guozhang;After talking around with people I now proposed an approach similar to v4 but generalized with a responseCode instead of just a close socket flag. And on SocketServer the processor would act based on the code instead of checking if the responseSend is null or not.

Also change aliveBrokers in KafkaApis from var to val since it is not overwritten in lifetime.;;;","24/Aug/13 23:23;nehanarkhede;I like the way the responseCode is generalized. Patch v6 looks good, few minor comments before checkin -

1. Remove unused variable allBrokers from KafkaApis
2. This comment needs to be changed according to the new response code logic - 
// a null response send object indicates

Maybe we should wait for review from [~jkreps] since he has most context on the socket server.;;;","27/Aug/13 02:32;jkreps;Great fix. A few minor comments, mostly stylistic.

RequestChannel.scala:
1. This usage exposes a bit much:
   requestChannel.sendResponse(new RequestChannel.Response(request.processor, request, null, RequestChannel.CloseSocket))
I think it might be nicer to have this instead:
   requestChannel.close(request.processor, request)
and
   requestChannel.noResponse(req.processor, request)
Implementation would be the same, it just would just be a little more clear for the user and the response codes can be private.

Likewise in the response object I should be able to 

2. These are a little confusing:
val SendResponse: Short = 0
val NoResponse: Short = 1
val CloseSocket: Short = 9
Why is it 0, 1, and 9?

What is the relationship between these and ErrorMapping? It should be clear from reading.

Is there a reason we can't use a case class
  case class ResponseAction
  case object SendAction extends ResponseAction
  case object NoOpAction extends ResponseAction
  case object CloseConnectionAction extends ResponseAction

Then to use it
 
response.action match {
  case SendAction => do send
  case NoOpAction => read more
  case CloseConnectionAction => something
}

This seems clearer to me and I don't think it is significantly more expensive.

Can we also standardize the usage so that we no longer have the user EITHER give null or NoResponse? It should be one or the other.

3. This logging ""Cancelling the request key to notify socket server close the connection due to error handling produce request "" is not informative to the user. What does it mean to cancel a key? What broke? What should they do? I also think this should be info unless we want the server admin to take some action (I don't think so, right? This is a normal occurance).

SocketServer.scala
4. The comment ""a null response send object"" is retained but we are no longer using null to indicate this we are using RequestChannel.NoResponse. I think this comment is actually a little verbose given that we now have a nicely named response action.

ProducerTest.scala:
5. org.scalatest.TestFailedException: Is there a reason you are giving the full path here instead of importing it

Question on testing, what is the message loss rate with acks=0 under moderate load if we do something like a controlled shutdown with other replicas available?;;;","27/Aug/13 07:28;guozhang;Thanks for the comments, Neha, Jay.

Neha:

1. Done.
2. Incorporated with Jay's comments.

Jay:

1. Done.
2. Done. I ended up using trait and objects, and let requestChannel.close and requestChannel.noOperation (I changed the name from noResponse here since it matches the noOpAction better) create new responses themselves.
3. Done.
4. Done.
5. Done.

Regarding your question, the message loss is depending on the producer throughput and queue size. Since the first message will always be silently dropped, and once the producer noticed the socket closure, it will stop producing and refresh new metadata, and if during this time the producer queue is full then it will drop more messages. So the answer would be the range between [1, produce-throughput / time-taken-to-refresh-metadata - queue-size].;;;","29/Aug/13 01:06;jkreps;+1 Gorgeous.;;;","29/Aug/13 01:14;nehanarkhede;This is great. +1. One improvement on logging -

        info((""Send the close connection response due to error handling produce request "" +
          ""[clientId = %s, correlationId = %s, topicAndPartition = %s] with Ack=0"")
          .format(produceRequest.clientId, produceRequest.correlationId, produceRequest.topicPartitionMessageSizeMap.mkString(""["","","",""]"")))

Here we only want to print the topic and partition, so it seems that we should be printing the keys of the map, not the entire map ?
produceRequest.topicPartitionMessageSizeMap.keySet.mkString("","")

I can make this change on checkin.;;;","29/Aug/13 01:17;nehanarkhede;Committed patch v7 to 0.8 after making the logging fix described above;;;","03/Sep/13 23:14;junrao;Thanks for patch v7. A couple of more comments.

70. There is a long standing bug in ProducerRequest.handleError(). If ack=0, we shouldn't send a response when the broker hits an unexpected error. We should either close the socket connection or send no response. Not sure which one is better.

71. A minor issue. The following comment in RequestChannel is a bit confusing. It sounds like that it needs to read more data from network to complete this request, but it is not.
  /** No operation to take for the request, need to read more over the network */
  def noOperation(processor: Int, request: RequestChannel.Request) {
;;;","14/Sep/13 06:17;guozhang;Created reviewboard https://reviews.apache.org/r/14140/
;;;","14/Sep/13 07:18;junrao;Thanks for the followup patch. +1 and committed to 0.8.;;;","25/Aug/16 22:37;mazhar.shaikh.in;Hi All,

affected version & fixed version is same, just want to know if this fix is available in ""0.8.2""

I'm facing similar issue in ""0.8.2"".

Thanks.;;;","03/Nov/16 15:12;Bill Zhang;I am using Flume with Kafka Channel & facing below issues. 

Kafka Version: kafka_2.9.1-0.8.2.0
Flume Version: apache-flume-1.6.0

It seems was resolved from below :
Step 1: copy zookeeper Jar file to Flume classpath
Step 2: a1.channels.c1.kafka.producer.type = async

Note:
i didn't change default value of request.required.acks. It seems works, it is still in testing...


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Issue 1:
02 Nov 2016 22:20:06,201 WARN  [ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-2] (kafka.utils.Logging$class.warn:83)  - Reconnect due to socket error: null
02 Nov 2016 22:20:06,203 INFO  [ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-2] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-2], Stopped 
02 Nov 2016 22:20:06,203 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-2], Shutdown completed
02 Nov 2016 22:20:06,203 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-1], Shutting down
02 Nov 2016 22:20:06,204 WARN  [ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-1] (kafka.utils.Logging$class.warn:83)  - Reconnect due to socket error: null
02 Nov 2016 22:20:06,204 INFO  [ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-1] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-1], Stopped 
02 Nov 2016 22:20:06,204 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-1], Shutdown completed
02 Nov 2016 22:20:06,205 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherManager-1478087994042] All connections stopped
02 Nov 2016 22:20:06,207 INFO  [ZkClient-EventThread-58-SATL2036:2181,SATL2037:2181,SATL2038:2181/kafka] (org.I0Itec.zkclient.ZkEventThread.run:82)  - Terminate ZkClient event thread.
02 Nov 2016 22:20:06,212 WARN  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.warn:89)  - Failed to send producer request with correlation id 34198503 to broker 1 with data for partitions [channel-tbox-parsed-topic,3]
java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:511)
	at java.nio.channels.SocketChannel.write(SocketChannel.java:502)
	at kafka.network.BoundedByteBufferSend.writeTo(BoundedByteBufferSend.scala:56)
	at kafka.network.Send$class.writeCompletely(Transmission.scala:75)
	at kafka.network.BoundedByteBufferSend.writeCompletely(BoundedByteBufferSend.scala:26)
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:92)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:72)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:71)
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(SyncProducer.scala:102)
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply(SyncProducer.scala:102)
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply(SyncProducer.scala:102)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.producer.SyncProducer$$anonfun$send$1.apply$mcV$sp(SyncProducer.scala:101)
	at kafka.producer.SyncProducer$$anonfun$send$1.apply(SyncProducer.scala:101)
	at kafka.producer.SyncProducer$$anonfun$send$1.apply(SyncProducer.scala:101)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:100)
	at kafka.producer.async.DefaultEventHandler.kafka$producer$async$DefaultEventHandler$$send(DefaultEventHandler.scala:255)
	at kafka.producer.async.DefaultEventHandler$$anonfun$dispatchSerializedData$2.apply(DefaultEventHandler.scala:106)
	at kafka.producer.async.DefaultEventHandler$$anonfun$dispatchSerializedData$2.apply(DefaultEventHandler.scala:100)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at kafka.producer.async.DefaultEventHandler.dispatchSerializedData(DefaultEventHandler.scala:100)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:72)
	at kafka.producer.Producer.send(Producer.scala:76)
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)
	at java.lang.Thread.run(Thread.java:745)
02 Nov 2016 22:20:06,214 INFO  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.info:68)  - Back off for 100 ms before retrying send. Remaining retries = 3
02 Nov 2016 22:20:06,214 WARN  [PollableSourceRunner-KafkaSource-r1] (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit:363)  - Sending events to Kafka failed
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:76)
	at kafka.producer.Producer.send(Producer.scala:76)
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)
	at java.lang.Thread.run(Thread.java:745)
02 Nov 2016 22:20:06,215 ERROR [PollableSourceRunner-KafkaSource-r1] (org.apache.flume.source.kafka.KafkaSource.process:153)  - KafkaSource EXCEPTION, {}
org.apache.flume.ChannelException: Unable to put batch on required channel: org.apache.flume.channel.kafka.KafkaChannel{name: c1}
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:200)
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.flume.ChannelException: Commit failed as send to Kafka failed
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:364)
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)
	... 3 more
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:76)
	at kafka.producer.Producer.send(Producer.scala:76)
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)
	... 5 more
02 Nov 2016 22:20:06,233 INFO  [agent-shutdown-hook] (org.apache.zookeeper.ZooKeeper.close:684)  - Session: 0x2581dc726ab01ad closed
02 Nov 2016 22:20:06,233 INFO  [lifecycleSupervisor-1-1-EventThread] (org.apache.zookeeper.ClientCnxn$EventThread.run:512)  - EventThread shut down
02 Nov 2016 22:20:06,239 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [flume_tbox-topic_SATL2036-1478087994030-54387da2], ZKConsumerConnector shut down completed
02 Nov 2016 22:20:06,239 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SOURCE, name: r1 stopped
02 Nov 2016 22:20:06,239 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SOURCE, name: r1. source.start.time == 1478087994119
02 Nov 2016 22:20:06,239 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SOURCE, name: r1. source.stop.time == 1478096406239
02 Nov 2016 22:20:06,239 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. source.kafka.commit.time == 555
02 Nov 2016 22:20:06,239 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. source.kafka.event.get.time == 1409513
02 Nov 2016 22:20:06,239 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.append-batch.accepted == 0
02 Nov 2016 22:20:06,240 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.append-batch.received == 0
02 Nov 2016 22:20:06,240 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.append.accepted == 0
02 Nov 2016 22:20:06,240 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.append.received == 0
02 Nov 2016 22:20:06,240 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.events.accepted == 343
02 Nov 2016 22:20:06,240 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.events.received == 343
02 Nov 2016 22:20:06,240 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.open-connection.count == 0
02 Nov 2016 22:20:06,240 INFO  [agent-shutdown-hook] (org.apache.flume.source.kafka.KafkaSource.stop:237)  - Kafka Source r1 stopped. Metrics: SOURCE:r1{src.events.accepted=343, src.open-connection.count=0, src.append.received=0, source.kafka.event.get.time=1409513, src.append-batch.received=0, src.append-batch.accepted=0, src.append.accepted=0, src.events.received=343, source.kafka.commit.time=555}
02 Nov 2016 22:20:06,240 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21], ZKConsumerConnector shutting down
02 Nov 2016 22:20:06,241 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherManager-1478087993018] Stopping leader finder thread
02 Nov 2016 22:20:06,241 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-leader-finder-thread], Shutting down
02 Nov 2016 22:20:06,241 INFO  [flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-leader-finder-thread] (kafka.utils.Logging$class.info:68)  - [flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-leader-finder-thread], Stopped 
02 Nov 2016 22:20:06,241 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-leader-finder-thread], Shutdown completed
02 Nov 2016 22:20:06,241 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherManager-1478087993018] Stopping all fetchers
02 Nov 2016 22:20:06,241 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-0-1], Shutting down
02 Nov 2016 22:20:06,242 WARN  [ConsumerFetcherThread-flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-0-1] (kafka.utils.Logging$class.warn:83)  - Reconnect due to socket error: null
02 Nov 2016 22:20:06,242 INFO  [ConsumerFetcherThread-flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-0-1] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-0-1], Stopped 
02 Nov 2016 22:20:06,242 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-0-1], Shutdown completed
02 Nov 2016 22:20:06,242 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherManager-1478087993018] All connections stopped
02 Nov 2016 22:20:06,243 INFO  [ZkClient-EventThread-42-SATL2036:2181,SATL2037:2181,SATL2038:2181/kafka] (org.I0Itec.zkclient.ZkEventThread.run:82)  - Terminate ZkClient event thread.
02 Nov 2016 22:20:06,244 INFO  [agent-shutdown-hook] (org.apache.zookeeper.ZooKeeper.close:684)  - Session: 0x356eb2d4b833fab closed
02 Nov 2016 22:20:06,244 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21], ZKConsumerConnector shut down completed
02 Nov 2016 22:20:06,244 INFO  [SinkRunner-PollingRunner-FailoverSinkProcessor-EventThread] (org.apache.zookeeper.ClientCnxn$EventThread.run:512)  - EventThread shut down
02 Nov 2016 22:20:06,246 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - Shutting down producer
02 Nov 2016 22:20:06,247 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - Closing all sync producers
02 Nov 2016 22:20:06,256 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - Disconnecting from 10.25.20.36:9092
02 Nov 2016 22:20:06,256 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: c1 stopped
02 Nov 2016 22:20:06,256 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: c1. channel.start.time == 1478087992836
02 Nov 2016 22:20:06,256 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: c1. channel.stop.time == 1478096406256
02 Nov 2016 22:20:06,257 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.capacity == 0
02 Nov 2016 22:20:06,257 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.current.size == 0
02 Nov 2016 22:20:06,257 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.event.put.attempt == 0
02 Nov 2016 22:20:06,257 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.event.put.success == 343
02 Nov 2016 22:20:06,257 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.event.take.attempt == 0
02 Nov 2016 22:20:06,257 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.event.take.success == 342
02 Nov 2016 22:20:06,257 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.kafka.commit.time == 201
02 Nov 2016 22:20:06,258 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.kafka.event.get.time == 531
02 Nov 2016 22:20:06,258 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.kafka.event.send.time == 1789
02 Nov 2016 22:20:06,258 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.rollback.count == 0
02 Nov 2016 22:20:06,258 INFO  [agent-shutdown-hook] (org.apache.flume.channel.kafka.KafkaChannel.stop:123)  - Kafka channel c1 stopped. Metrics: CHANNEL:c1{channel.event.put.attempt=0, channel.event.put.success=343, channel.kafka.event.get.time=531, channel.current.size=0, channel.event.take.attempt=0, channel.event.take.success=342, channel.kafka.event.send.time=1789, channel.capacity=0, channel.kafka.commit.time=201, channel.rollback.count=0}
02 Nov 2016 22:20:06,264 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake:332)  - Error while getting events from Kafka
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:65)
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:33)
	at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)
	at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:306)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:97)
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
02 Nov 2016 22:20:06,274 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.kafka.KafkaSink.process:139)  - Failed to publish events
org.apache.flume.ChannelException: Error while getting events from Kafka
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:97)
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:65)
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:33)
	at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)
	at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:306)
	... 6 more
02 Nov 2016 22:20:06,275 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.SinkRunner$PollingRunner.run:160)  - Unable to deliver event. Exception follows.
org.apache.flume.EventDeliveryException: Failed to publish events
	at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:150)
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.flume.ChannelException: Error while getting events from Kafka
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:97)
	... 3 more
Caused by: java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:65)
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:33)
	at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)
	at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:306)
	... 6 more
02 Nov 2016 22:20:06,794 INFO  [flume_tbox-topic_SATL2036-1478087994030-54387da2_watcher_executor] (kafka.utils.Logging$class.info:68)  - [flume_tbox-topic_SATL2036-1478087994030-54387da2], stopping watcher executor thread for consumer flume_tbox-topic_SATL2036-1478087994030-54387da2
02 Nov 2016 22:20:06,816 INFO  [flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21_watcher_executor] (kafka.utils.Logging$class.info:68)  - [flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21], stopping watcher executor thread for consumer flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21
02 Nov 2016 22:20:06,887 WARN  [SinkRunner-PollingRunner-FailoverSinkProcessor] (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake:332)  - Error while getting events from Kafka
java.util.NoSuchElementException
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
02 Nov 2016 22:20:06,888 ERROR [SinkRunner-PollingRunner-FailoverSinkProcessor] (org.apache.flume.sink.hdfs.HDFSEventSink.process:459)  - process failed
org.apache.flume.ChannelException: Error while getting events from Kafka
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.util.NoSuchElementException
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)
	... 6 more
02 Nov 2016 22:20:06,889 WARN  [SinkRunner-PollingRunner-FailoverSinkProcessor] (org.apache.flume.sink.FailoverSinkProcessor.process:185)  - Sink k1 failed and has been sent to failover list
org.apache.flume.EventDeliveryException: org.apache.flume.ChannelException: Error while getting events from Kafka
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:463)
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.flume.ChannelException: Error while getting events from Kafka
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)
	... 3 more
Caused by: java.util.NoSuchElementException
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)
	... 6 more
02 Nov 2016 22:20:06,896 WARN  [SinkRunner-PollingRunner-FailoverSinkProcessor] (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake:332)  - Error while getting events from Kafka
java.util.NoSuchElementException
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
02 Nov 2016 22:20:06,897 ERROR [SinkRunner-PollingRunner-FailoverSinkProcessor] (org.apache.flume.sink.hdfs.HDFSEventSink.process:459)  - process failed
org.apache.flume.ChannelException: Error while getting events from Kafka
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.util.NoSuchElementException
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)
	... 6 more
02 Nov 2016 22:20:06,898 WARN  [SinkRunner-PollingRunner-FailoverSinkProcessor] (org.apache.flume.sink.FailoverSinkProcessor.process:185)  - Sink k2 failed and has been sent to failover list
org.apache.flume.EventDeliveryException: org.apache.flume.ChannelException: Error while getting events from Kafka
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:463)
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.flume.ChannelException: Error while getting events from Kafka
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)
	... 3 more
Caused by: java.util.NoSuchElementException
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)
	... 6 more
02 Nov 2016 22:20:06,898 WARN  [SinkRunner-PollingRunner-FailoverSinkProcessor] (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake:332)  - Error while getting events from Kafka
java.util.NoSuchElementException
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
02 Nov 2016 22:20:06,898 ERROR [SinkRunner-PollingRunner-FailoverSinkProcessor] (org.apache.flume.sink.hdfs.HDFSEventSink.process:459)  - process failed
org.apache.flume.ChannelException: Error while getting events from Kafka
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.util.NoSuchElementException
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)
	... 6 more
02 Nov 2016 22:20:06,899 WARN  [SinkRunner-PollingRunner-FailoverSinkProcessor] (org.apache.flume.sink.FailoverSinkProcessor.process:185)  - Sink k3 failed and has been sent to failover list
org.apache.flume.EventDeliveryException: org.apache.flume.ChannelException: Error while getting events from Kafka
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:463)
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.flume.ChannelException: Error while getting events from Kafka
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)
	... 3 more
Caused by: java.util.NoSuchElementException
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)
	... 6 more
02 Nov 2016 22:20:06,899 ERROR [SinkRunner-PollingRunner-FailoverSinkProcessor] (org.apache.flume.SinkRunner$PollingRunner.run:160)  - Unable to deliver event. Exception follows.
org.apache.flume.EventDeliveryException: All sinks failed to process, nothing left to failover to
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:191)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:745)
02 Nov 2016 22:20:07,216 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [flume_tbox_parsed_SATL2036-1478088061094-7badc6c0], ZKConsumerConnector shutting down
02 Nov 2016 22:20:07,217 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherManager-1478088061100] Stopping leader finder thread
02 Nov 2016 22:20:07,217 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-leader-finder-thread], Shutting down
02 Nov 2016 22:20:07,218 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-leader-finder-thread], Shutdown completed
02 Nov 2016 22:20:07,218 INFO  [flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-leader-finder-thread] (kafka.utils.Logging$class.info:68)  - [flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-leader-finder-thread], Stopped 
02 Nov 2016 22:20:07,218 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherManager-1478088061100] Stopping all fetchers
02 Nov 2016 22:20:07,218 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-2], Shutting down
02 Nov 2016 22:20:07,219 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-2], Shutdown completed
02 Nov 2016 22:20:07,219 INFO  [ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-2] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-2], Stopped 
02 Nov 2016 22:20:07,220 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-1], Shutting down
02 Nov 2016 22:20:07,220 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-1], Shutdown completed
02 Nov 2016 22:20:07,220 INFO  [ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-1] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-1], Stopped 
02 Nov 2016 22:20:07,221 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [ConsumerFetcherManager-1478088061100] All connections stopped
02 Nov 2016 22:20:07,223 INFO  [ZkClient-EventThread-48-SATL2036:2181,SATL2037:2181,SATL2038:2181/kafka] (org.I0Itec.zkclient.ZkEventThread.run:82)  - Terminate ZkClient event thread.
02 Nov 2016 22:20:07,226 INFO  [flume_tbox_parsed_SATL2036-1478088061094-7badc6c0_watcher_executor] (kafka.utils.Logging$class.info:68)  - [flume_tbox_parsed_SATL2036-1478088061094-7badc6c0], stopping watcher executor thread for consumer flume_tbox_parsed_SATL2036-1478088061094-7badc6c0
02 Nov 2016 22:20:07,226 INFO  [agent-shutdown-hook] (org.apache.zookeeper.ZooKeeper.close:684)  - Session: 0x156eb2d4a70421e closed
02 Nov 2016 22:20:07,226 INFO  [lifecycleSupervisor-1-0-EventThread] (org.apache.zookeeper.ClientCnxn$EventThread.run:512)  - EventThread shut down
02 Nov 2016 22:20:07,227 INFO  [agent-shutdown-hook] (kafka.utils.Logging$class.info:68)  - [flume_tbox_parsed_SATL2036-1478088061094-7badc6c0], ZKConsumerConnector shut down completed



Issue 2:
03 Nov 2016 13:31:29,287 INFO  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.info:68)  - Back off for 100 ms before retrying send. Remaining retries = 1
03 Nov 2016 13:31:29,388 INFO  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.info:68)  - Fetching metadata from broker id:1,host:SATL2037,port:9092 with correlation id 2307612 for 1 topic(s) Set(channel-tbox-topic)
03 Nov 2016 13:31:29,388 INFO  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.info:68)  - Connected to SATL2037:9092 for producing
03 Nov 2016 13:31:29,389 INFO  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.info:68)  - Disconnecting from SATL2037:9092
03 Nov 2016 13:31:29,443 INFO  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.info:68)  - Connected to SATL2037:9092 for producing
03 Nov 2016 13:31:29,549 INFO  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.info:68)  - Disconnecting from SATL2037:9092
03 Nov 2016 13:31:29,550 WARN  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.warn:89)  - Failed to send producer request with correlation id 2308613 to broker 2 with data for partitions [channel-tbox-topic,4]
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.writev0(Native Method)
	at sun.nio.ch.SocketDispatcher.writev(SocketDispatcher.java:51)
	at sun.nio.ch.IOUtil.write(IOUtil.java:148)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:504)
	at java.nio.channels.SocketChannel.write(SocketChannel.java:502)
	at kafka.network.BoundedByteBufferSend.writeTo(BoundedByteBufferSend.scala:56)
	at kafka.network.Send$class.writeCompletely(Transmission.scala:75)
	at kafka.network.BoundedByteBufferSend.writeCompletely(BoundedByteBufferSend.scala:26)
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:92)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:72)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:71)
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(SyncProducer.scala:102)
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply(SyncProducer.scala:102)
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply(SyncProducer.scala:102)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.producer.SyncProducer$$anonfun$send$1.apply$mcV$sp(SyncProducer.scala:101)
	at kafka.producer.SyncProducer$$anonfun$send$1.apply(SyncProducer.scala:101)
	at kafka.producer.SyncProducer$$anonfun$send$1.apply(SyncProducer.scala:101)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:100)
	at kafka.producer.async.DefaultEventHandler.kafka$producer$async$DefaultEventHandler$$send(DefaultEventHandler.scala:255)
	at kafka.producer.async.DefaultEventHandler$$anonfun$dispatchSerializedData$2.apply(DefaultEventHandler.scala:106)
	at kafka.producer.async.DefaultEventHandler$$anonfun$dispatchSerializedData$2.apply(DefaultEventHandler.scala:100)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at kafka.producer.async.DefaultEventHandler.dispatchSerializedData(DefaultEventHandler.scala:100)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:72)
	at kafka.producer.Producer.send(Producer.scala:76)
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)
	at java.lang.Thread.run(Thread.java:745)
03 Nov 2016 13:31:29,550 INFO  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.info:68)  - Back off for 100 ms before retrying send. Remaining retries = 0
03 Nov 2016 13:31:29,651 INFO  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.info:68)  - Fetching metadata from broker id:0,host:SATL2036,port:9092 with correlation id 2308614 for 1 topic(s) Set(channel-tbox-topic)
03 Nov 2016 13:31:29,651 INFO  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.info:68)  - Connected to SATL2036:9092 for producing
03 Nov 2016 13:31:29,652 INFO  [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.info:68)  - Disconnecting from SATL2036:9092
03 Nov 2016 13:31:29,653 ERROR [PollableSourceRunner-KafkaSource-r1] (kafka.utils.Logging$class.error:97)  - Failed to send requests for topics channel-tbox-topic with correlation ids in [2304607,2308614]
03 Nov 2016 13:31:29,653 WARN  [PollableSourceRunner-KafkaSource-r1] (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit:363)  - Sending events to Kafka failed
kafka.common.FailedToSendMessageException: Failed to send messages after 3 tries.
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:90)
	at kafka.producer.Producer.send(Producer.scala:76)
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)
	at java.lang.Thread.run(Thread.java:745)
03 Nov 2016 13:31:29,653 ERROR [PollableSourceRunner-KafkaSource-r1] (org.apache.flume.source.kafka.KafkaSource.process:153)  - KafkaSource EXCEPTION, {}
org.apache.flume.ChannelException: Unable to put batch on required channel: org.apache.flume.channel.kafka.KafkaChannel{name: c1}
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:200)
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.flume.ChannelException: Commit failed as send to Kafka failed
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:364)
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)
	... 3 more
Caused by: kafka.common.FailedToSendMessageException: Failed to send messages after 3 tries.
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:90)
	at kafka.producer.Producer.send(Producer.scala:76)
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)
	... 5 more





;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clean up Controller Object on forced Resignation,KAFKA-2818,12912509,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,fpj,mbruce@blackberry.com,mbruce@blackberry.com,12/Nov/15 23:54,02/Jun/17 03:43,22/Mar/23 15:10,02/Jun/17 03:43,0.9.0.0,,,,,,0.11.0.0,,,,,,,controller,,,,1,,,,,,"Currently if the controller does a forced resignation (if an exception is caught during updateLeaderEpochAndSendRequest, SendUpdateMetadataRequest or shutdownBroker), the Zookeeper resignation callback function OnControllerResignation doesn't get a chance to execute which leaves some artifacts laying around.  In particular the Sensors dont get cleaned up and if the Kafka broker ever gets re-elected as Controller it will fail due to some metrics already existing.  An Error and stack trace of such an event is below.

A forced resignation situation can be induced with a mis-config in broker.properties fairly easily, by settig only SASL_PLAINTTEXT listeners and setting inter.broker.protocol.version=0.8.2.X

{code}
listeners=SASL_PLAINTEXT://<HOST FQDN>:9092
inter.broker.protocol.version=0.8.2.X
security.inter.broker.protocol=SASL_PLAINTEXT
{code}



{code}
[2015-11-09 16:33:47,510] ERROR Error while electing or becoming leader on broker 182050300 (kafka.server.ZookeeperLeaderElector)
java.lang.IllegalArgumentException: A metric named 'MetricName [name=connection-close-rate, group=controller-channel-metrics, description=Connections closed per second in the window., tags={broker-id=182050300}]' already exists, can't register another one.
        at org.apache.kafka.common.metrics.Metrics.registerMetric(Metrics.java:285)
        at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:177)
        at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:162)
        at org.apache.kafka.common.network.Selector$SelectorMetrics.<init>(Selector.java:578)
        at org.apache.kafka.common.network.Selector.<init>(Selector.java:112)
        at kafka.controller.ControllerChannelManager.kafka$controller$ControllerChannelManager$$addNewBroker(ControllerChannelManager.scala:91)
        at kafka.controller.ControllerChannelManager$$anonfun$1.apply(ControllerChannelManager.scala:43)
        at kafka.controller.ControllerChannelManager$$anonfun$1.apply(ControllerChannelManager.scala:43)
        at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
        at kafka.controller.ControllerChannelManager.<init>(ControllerChannelManager.scala:43)
        at kafka.controller.KafkaController.startChannelManager(KafkaController.scala:819)
        at kafka.controller.KafkaController.initializeControllerContext(KafkaController.scala:747)
        at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:330)
        at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
        at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
        at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:146)
        at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:141)
        at kafka.server.ZookeeperLeaderElector$LeaderChangeListener$$anonfun$handleDataDeleted$1.apply(ZookeeperLeaderElector.scala:141)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
        at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:141)
        at org.I0Itec.zkclient.ZkClient$9.run(ZkClient.java:823)
        at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
{code}",,fpj,ijuma,lidel,mbruce@blackberry.com,valdis.rigdon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3173,,,,,,,,"12/Nov/15 23:55;mbruce@blackberry.com;KAFKA-2818.patch;https://issues.apache.org/jira/secure/attachment/12771985/KAFKA-2818.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jun 01 19:43:29 UTC 2017,,,,,,,,,,"0|i2ob13:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"12/Nov/15 23:55;mbruce@blackberry.com;diff --git a/core/src/main/scala/kafka/controller/KafkaController.scala b/core/src/main/scala/kafka/controller/KafkaController.scala
index 7c03a24..a48ffb2 100755
--- a/core/src/main/scala/kafka/controller/KafkaController.scala
+++ b/core/src/main/scala/kafka/controller/KafkaController.scala
@@ -278,6 +278,8 @@ class KafkaController(val config : KafkaConfig, zkUtils: ZkUtils, val brokerStat
                       error(""Forcing the controller to resign"")
                       brokerRequestBatch.clear()
                       controllerElector.resign()
+                      //Run the Resignation callback directly as it doesn't get called after the exception is propogated
+                      onControllerResignation()
 
                       throw e
                     }
@@ -913,6 +915,8 @@ class KafkaController(val config : KafkaConfig, zkUtils: ZkUtils, val brokerStat
             error(""Forcing the controller to resign"")
             brokerRequestBatch.clear()
             controllerElector.resign()
+           //Run the Resignation callback directly as it doesn't get called after the exception is propogated
+            onControllerResignation()
 
             throw e
           }
@@ -1033,6 +1037,8 @@ class KafkaController(val config : KafkaConfig, zkUtils: ZkUtils, val brokerStat
         error(""Forcing the controller to resign"")
         brokerRequestBatch.clear()
         controllerElector.resign()
+        //Run the Resignation callback directly as it doesn't get called after the exception is propogated
+        onControllerResignation()
 
         throw e
       }
diff --git a/core/src/main/scala/kafka/controller/TopicDeletionManager.scala b/core/src/main/scala/kafka/controller/TopicDeletionManager.scala
index c6f80ac..d4d1f50 100755
--- a/core/src/main/scala/kafka/controller/TopicDeletionManager.scala
+++ b/core/src/main/scala/kafka/controller/TopicDeletionManager.scala
@@ -106,7 +106,7 @@ class TopicDeletionManager(controller: KafkaController,
    */
   def shutdown() {
     // Only allow one shutdown to go through
-    if (isDeleteTopicEnabled && deleteTopicsThread.initiateShutdown()) {
+    if (isDeleteTopicEnabled && deleteTopicsThread != null && deleteTopicsThread.initiateShutdown()) {
       // Resume the topic deletion so it doesn't block on the condition
       resumeTopicDeletionThread()
       // Await delete topic thread to exit
;;;","07/Feb/16 13:15;fpj;[~mbruce@blackberry.com] You're right that {{onControllerResignation()}} isn't being called, but the problem is that {{ZooKeeperLeaderElector.handleDataDeleted()}} should be invoking it via {{onResigningAsLeader()}} and it isn't because {{amILeader}} is evaluating to false. It is evaluating to false because the call to {{resign()}} is setting {{leaderId}} to -1. I'm thinking that we shouldn't set {{leaderId}} to -1 in the {{resign()}} call. {{leaderId}} to will be set to -1 if {{getControllerID}} returns -1 when called inside {{elect}}.

What do you think?;;;","26/Feb/16 23:17;mbruce@blackberry.com;[~fpj] You would definitely know that code better than me.  If you think that's the route to go then it sounds good to me.;;;","02/Jun/17 03:43;ijuma;I think this is fixed by https://github.com/apache/kafka/commit/6021618f9dafa3478104575d307e7bcd2cb4cca9

Please reopen if not.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AdminUtils.deleteTopic does not work,KAFKA-1558,12730057,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,sriharsha,hgschmie,hgschmie,27/Jul/14 07:49,10/Oct/14 05:54,22/Mar/23 15:10,10/Oct/14 05:54,0.8.1.1,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"the AdminUtils:.deleteTopic method is implemented as

{code}
    def deleteTopic(zkClient: ZkClient, topic: String) {
        ZkUtils.createPersistentPath(zkClient, ZkUtils.getDeleteTopicPath(topic))
    }
{code}

but the DeleteTopicCommand actually does

{code}
    zkClient = new ZkClient(zkConnect, 30000, 30000, ZKStringSerializer)
    zkClient.deleteRecursive(ZkUtils.getTopicPath(topic))
{code}

so I guess, that the 'createPersistentPath' above should actually be 


{code}
    def deleteTopic(zkClient: ZkClient, topic: String) {
        ZkUtils.deletePathRecursive(zkClient, ZkUtils.getTopicPath(topic))
    }
{code}
",,chelseaz,dinghaifeng,guozhang,gwenshap,hgschmie,hongyu.bi,junrao,nehanarkhede,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1663,,,"10/Oct/14 05:13;sriharsha;KAFKA-1558.patch;https://issues.apache.org/jira/secure/attachment/12674003/KAFKA-1558.patch","30/Sep/14 13:24;sriharsha;kafka-thread-dump.log;https://issues.apache.org/jira/secure/attachment/12671963/kafka-thread-dump.log",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,408130,,,Thu Oct 09 21:54:19 UTC 2014,,,,,,,,,,"0|i1y873:",408135,,nehanarkhede,,,,,,,,,,,,,,,,,,"28/Jul/14 01:20;junrao;Delete topic is not supported in 0.8.1.1. It is implemented in trunk, but hasn't been fully tested. The way this works is not to delete the topic path directly. Instead, it first indicates in a separate path that we want to delete a topic. Once all data related to the topic is deleted, the controller will then delete the topic path.;;;","15/Aug/14 01:02;sriharsha;[~junrao] Incase if you are not working on this I would like to start working on this JIRA. Thanks.;;;","19/Aug/14 06:36;junrao;Sriharsha,

Yes, you can take this one. Clark will explain how to reproduce the problem and attach the relevant logs. Thanks,;;;","20/Aug/14 02:39;nehanarkhede;[~clarkhaskins], please can you attach all the server logs here when delete topic fails?;;;","27/Aug/14 23:02;sriharsha;[~clarkhaskins] can you please upload server logs for delete topic failures. Thanks.;;;","05/Sep/14 06:11;guozhang;It would be really great to have this in 0.8.2, but not sure we can make it though..;;;","05/Sep/14 06:55;sriharsha;[~guozhang] I am waiting some logs to show up supposed issue. I can put in sometime this week get this done if someone can give me reproduction steps or logs. Thanks;;;","11/Sep/14 08:50;sriharsha;[~junrao] Do you know any steps on reproducing this. Thanks.;;;","11/Sep/14 09:52;gwenshap;I don't think the issue as described above exists an more. 
I tested the trunk implementation of deleteTopic in simple cases and in all of them, if delete.topic.enable was true, the topic was deleted.

I think what we need now is to test deleteTopic under failure modes - leader election, partition reassignment, etc.;;;","12/Sep/14 04:00;nehanarkhede;bq. I think what we need now is to test deleteTopic under failure modes - leader election, partition reassignment, etc.

Yes, it would help if someone who has cycles can take this up and basically try to break delete topic under various failure scenarios. Currently, the approach to fixing delete topic is a little ad-hoc.;;;","12/Sep/14 04:11;sriharsha;[~gwenshap] Thanks for the info. [~nehanarkhede] I am working on testing those cases mentioned above. Thanks.;;;","12/Sep/14 04:18;nehanarkhede;Great. Thanks [~sriharsha] for taking this on.;;;","15/Sep/14 02:30;junrao;Sriharsha,

It would be useful to test if ""delete topic"" works under the following cases.
1. after the controller is restarted
2. after a soft failure (can simulate by pausing the jvm for longer that zk session timeout) of the controller
3. after a topic's partitions have been reassigned to some other brokers
4. after running a preferred leader command
5. after a topic's partition has been increased

Thanks,;;;","15/Sep/14 02:38;sriharsha;Thanks [~junrao] will test those cases.;;;","15/Sep/14 08:56;nehanarkhede;I'll add one more :)
After the controller broker is killed (kill -9);;;","16/Sep/14 07:40;sriharsha;[~junrao] [~nehanarkhede] I ran tests for above cases manually on a cluster 3 kafka nodes and 3 zookeeper nodes
for each of the tests topics are created and minimum size of the log per partition was > 1Gb

1)  after the controller is restarted
   issuing delete topic is successful , metadata is deleted and also the log file without any errors.

2)  after a soft failure (can simulate by pausing the jvm for longer that zk session timeout) of the controller
   I am not sure how to induce a pause in jvm , I tried with debug tools doesn't look it had any effect. If you have any pointers on this please let me know.

3)  after a topic's partitions have been reassigned to some other brokers
     used kafka-reassign-partitions and ran delete topic command this resulted in successful deleting of metadata and topics log files

4) after running a preferred leader command
     No issues here topic successfully deleted

5) after a topic's partition has been increased
    No issues here either . new partition data also deleted

6) controller broker is killed (kill -9)
  successfully deleted the topic and metadata. Once the killed controller back online the logfiles for that topic also got deleted.

Please let me know on the case 2. If you have any more cases that you would like to test please let me know.
Thanks.;;;","16/Sep/14 08:22;junrao;To simulate a soft failure of a broker, you can

1. kill -SIGSTOP
2. wait for a bit longer than zk session timeout
3. kill -SIGCONT;;;","17/Sep/14 01:50;sriharsha;Thanks [~junrao]
Case 2 works fine too the topic gets deleted.

Case 6 when I do kill -9 on the controller and immediately run delete topic from the same node or on different node
one of the brokers goes on printing these messages

[2014-09-16 16:38:17,607] INFO Reconnect due to socket error: java.nio.channels.ClosedChannelException (kafka.consumer.SimpleConsumer)
[2014-09-16 16:38:17,608] WARN [ReplicaFetcherThread-0-1], Error in fetch Name: FetchRequest; Version: 0; CorrelationId: 955460; ClientId: ReplicaFetcherThre
ad-0-1; ReplicaId: 2; MaxWait: 500 ms; MinBytes: 1 bytes; RequestInfo: [my-topic,1] -> PartitionFetchInfo(2558522,1048576). Possible cause: java.nio.channels
.ClosedChannelException (kafka.server.ReplicaFetcherThread)

I've to restart this broker and delete topic goes fine.
But if I wait after killing(kill -9) controller and fetcher is removed delete topic goes fine without any issues
[ReplicaFetcherManager on broker 3] Removed fetcher for partitions [my-topic,1] (kafka.server.ReplicaFetcherManager)
[2014-09-16 16:56:58,646] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions [my-topic,0] (kafka.server.ReplicaFetcherManager)

I am not sure if its related to delete topic though any ideas on this.

;;;","18/Sep/14 22:11;nehanarkhede;[~sriharsha] Delete topic shouldn't be affected by the replica fetcher issue. Have you let it stay as is and see if delete topic eventually completes? If not, have you taken a thread dump to see where it halts, if at all? 

For each of the tests above, an important scenario is a large number of topics being actively written to and read from. For the tests, it is important to create, say a 1000 topics, and run producers in parallel that write to those 1000 topics, consumers that consume and then introduce each of the failures above. Delete topic should succeed even if there are writes/reads happening to the topic.;;;","18/Sep/14 22:57;sriharsha;[~nehanarkhede] Should we also consider the topic's log size. I'll work on running the tests with 1000 topics and post results today or early tomorrow. Thanks.;;;","21/Sep/14 13:24;sriharsha;[~nehanarkhede] [~junrao] update on the tests.
I ran the above tests in 5 kafka brokers and 3 zookeeper node with 1000 topics with 3 partitions 3 replication factor.
All these topics being written to and read from simultaneously.

1)  after the controller is restarted
topic log files and metadata deleted successfully
2)  after a soft failure (can simulate by pausing the jvm for longer that zk session timeout) of the controller
I am not able to consistently pass this test. I am getting this error
""2014-09-21 01:21:39,101] INFO Partition [my-topic-435,0] on broker 5: Cached zkVersion [114] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)"" 
Initially thought it could be related KAFKA-1382
but from debug logs
""expected Some((Leader:2,ISR:2,LeaderEpoch:4,ControllerEpoch:7)) written Some((Leader:4,ISR:4,LeaderEpoch:5,ControllerEpoch:9)) (kafka.utils.ReplicationUtils$)""
Leader is different. This is causing the broker to keep on logging these messages.
I am not sure why  it didn't get the leader update. I didn't see any errors in zookeeper logs.
I'll get more details on this.
3)  after a topic's partitions have been reassigned to some other brokers
    topic deleted no issues
4) after running a preferred leader command
 topic successfully deleted
5) after a topic's partition has been increased
   topic and new partition data also deleted
6) controller broker is killed (kill -9)
successfully deleted the topic and metadata. Once the killed controller back online the logfiles for that topic partition on that broker also got deleted.
I am not able to reproduce ReplicaFetcher issue here that pointed out earlier. Before I was running tests on vms with low memory . I wasn't able to reproduce this on these nodes.


;;;","21/Sep/14 23:52;nehanarkhede;This is great, [~sriharsha]. Thanks for running these tests. For #3, #4, #5, was the reassignment, leader movement and partition increase running while the delete topic was running? It is worth trying these admin commands in parallel with delete topic. Will wait for more details on #2.
;;;","21/Sep/14 23:57;sriharsha;[~nehanarkhede] for 3,4,5 I ran them after the command is completed I'll try running them parallel.  ;;;","22/Sep/14 03:57;sriharsha;[~nehanarkhede] 3 and 5 test cases went fine with delete command running parallel and for test case 4 the topic gets deleted successfully but preferred leader command fails with
Failed to start preferred replica election
org.I0Itec.zkclient.exception.ZkNoNodeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /brokers/topics/my-topic-693/partitions
        at org.I0Itec.zkclient.exception.ZkException.create(ZkException.java:47)
which I think is to be expected.
;;;","30/Sep/14 13:22;sriharsha;[~nehanarkhede] [~junrao] Sorry couldn't get to work on this earlier. I spent more time on case 2 I can consistently reproduce this failure. 
1) kill -SIGSTOP pid
2) wait for zookeeper timeout
3) kill -SIGCONT pid
4) immediately delete  a topic
5) new controller keeps printing these messages 
DeleteTopicThread goes in a loop.  I am attaching thread dump from this broker.
[2014-09-30 05:21:39,598] INFO [delete-topics-thread-3], Handling deletion for topics my-topic-110 (kafka.controller.TopicDeletionManager$DeleteTopicsThread)
[2014-09-30 05:21:39,598] DEBUG [Replica state machine on controller 3]: Are all replicas for topic my-topic-110 deleted Map([Topic=my-topic-110,Partition=1,Replica=2] -> ReplicaDeletionSuccessful, [Topic=my-topic-110,Partition=1,Replica=3] -> ReplicaDeletionSuccessful, [Topic=my-topic-110,Partition=0,Replica=1] -> OfflineReplica, [Topic=my-topic-110,Partition=0,Replica=2] -> ReplicaDeletionSuccessful) (kafka.controller.ReplicaStateMachine)
[2014-09-30 05:21:39,599] INFO [delete-topics-thread-3], Not retrying deletion of topic my-topic-110 at this time since it is marked ineligible for deletion (kafka.controller.TopicDeletionManager$DeleteTopicsThread)
[2014-09-30 05:21:39,599] INFO [delete-topics-thread-3], Handling deletion for topics my-topic-110 (kafka.controller.TopicDeletionManager$DeleteTopicsThread)
[2014-09-30 05:21:39,599] DEBUG [Replica state machine on controller 3]: Are all replicas for topic my-topic-110 deleted Map([Topic=my-topic-110,Partition=1,Replica=2] -> ReplicaDeletionSuccessful, [Topic=my-topic-110,Partition=1,Replica=3] -> ReplicaDeletionSuccessful, [Topic=my-topic-110,Partition=0,Replica=1] -> OfflineReplica, [Topic=my-topic-110,Partition=0,Replica=2] -> ReplicaDeletionSuccessful) (kafka.controller.ReplicaStateMachine)
[2014-09-30 05:21:39,599] INFO [delete-topics-thread-3], Not retrying deletion of topic my-topic-110 at this time since it is marked ineligible for deletion (kafka.controller.TopicDeletionManager$DeleteTopicsThread)

topic doesn't get deleted 
;;;","01/Oct/14 00:21;sriharsha;[~nehanarkhede] [~junrao] This seems to be related to the earlier issue I reported https://issues.apache.org/jira/browse/KAFKA-1558?focusedCommentId=14142342&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14142342

possible issue is related to old controller doesn't shutdown properly when a new controller is elected.
I ran a simple test with 1000 topics in 5 broker cluster . This is without consumers or producers running and no delete topic command issued.

After a soft failure old controller log shows
[2014-09-30 15:59:53,398] INFO [SessionExpirationListener on 1], ZK expired; shut down all controller components and try to re-elect (kafka.controller.KafkaController$SessionExpirationListener)
[2014-09-30 15:59:53,400] INFO [delete-topics-thread-1], Shutting down (kafka.controller.TopicDeletionManager$DeleteTopicsThread)

It stops there and the server.log goes on with 
[2014-09-30 16:17:36,649] INFO Partition [my-topic-634,0] on broker 1: Shrinking ISR for partition [my-topic-634,0] from 1,3,4 to 1 (kafka.cluster.Partition)
[2014-09-30 16:17:36,653] INFO Partition [my-topic-634,0] on broker 1: Cached zkVersion [0] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2014-09-30 16:17:36,653] INFO Partition [my-topic-374,1] on broker 1: Shrinking ISR for partition [my-topic-374,1] from 1,2,3 to 1 (kafka.cluster.Partition)
[2014-09-30 16:17:36,656] INFO Partition [my-topic-374,1] on broker 1: Cached zkVersion [0] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)
[2014-09-30 16:17:36,657] INFO Partition [my-topic-549,2] on broker 1: Shrinking ISR for partition [my-topic-549,2] from 1,2,3 to 1 (kafka.cluster.Partition)

I tried reproduce this in a 3 node cluster in vms with 200 topics and with or without producers & consumers running.
But here old controller shutdown goes through fine.

[2014-09-30 14:50:55,193] INFO [SessionExpirationListener on 3], ZK expired; shut down all controller components and try to re-elect (kafka.controller.KafkaController$SessionExpirationListener)
[2014-09-30 14:50:55,196] INFO [delete-topics-thread-3], Shutting down (kafka.controller.TopicDeletionManager$DeleteTopicsThread)
[2014-09-30 14:50:55,200] INFO [delete-topics-thread-3], Stopped  (kafka.controller.TopicDeletionManager$DeleteTopicsThread)
[2014-09-30 14:50:55,200] INFO [delete-topics-thread-3], Shutdown completed (kafka.controller.TopicDeletionManager$DeleteTopicsThread)
[2014-09-30 14:50:55,202] INFO [Partition state machine on Controller 3]: Stopped partition state machine (kafka.controller.PartitionStateMachine)
[2014-09-30 14:50:55,202] INFO [Replica state machine on controller 3]: Stopped replica state machine (kafka.controller.ReplicaStateMachine)
[2014-09-30 14:50:55,202] INFO [Controller-3-to-broker-2-send-thread], Shutting down (kafka.controller.RequestSendThread)
[2014-09-30 14:50:55,202] INFO [Controller-3-to-broker-2-send-thread], Stopped  (kafka.controller.RequestSendThread)
[2014-09-30 14:50:55,202] INFO [Controller-3-to-broker-2-send-thread], Shutdown completed (kafka.controller.RequestSendThread)
[2014-09-30 14:50:55,202] INFO [Controller-3-to-broker-1-send-thread], Shutting down (kafka.controller.RequestSendThread)
[2014-09-30 14:50:55,202] INFO [Controller-3-to-broker-1-send-thread], Stopped  (kafka.controller.RequestSendThread)
[2014-09-30 14:50:55,203] INFO [Controller-3-to-broker-1-send-thread], Shutdown completed (kafka.controller.RequestSendThread)
[2014-09-30 14:50:55,203] INFO [Controller-3-to-broker-3-send-thread], Shutting down (kafka.controller.RequestSendThread)
[2014-09-30 14:50:55,203] INFO [Controller-3-to-broker-3-send-thread], Stopped  (kafka.controller.RequestSendThread)
[2014-09-30 14:50:55,203] INFO [Controller-3-to-broker-3-send-thread], Shutdown completed (kafka.controller.RequestSendThread)


Regarding TopicDeletionManager shouldn't we stop if one of the replicas are offline or atleast have configurable number of retries for topic deletion?



;;;","01/Oct/14 00:51;guozhang;Just wondering if it is caused by KAFKA-1578. Are you testing against trunk?;;;","01/Oct/14 01:02;sriharsha;[~guozhang] yes testing against trunk last updated yesterday.
 ⭠ trunk± ⮀ ~/code/kafka ⮀ 
» git log | grep -i KAFKA-1578 
    kafka-1578; Controller should de-register all listeners upon designation; patched by Guozhang Wang; reviewed by Jun Rao;;;","01/Oct/14 03:34;nehanarkhede;[~sriharsha] Thanks for running more tests. I have a few questions about the latest results you've shared above.
bq.I ran a simple test with 1000 topics in 5 broker cluster . This is without consumers or producers running and no delete topic command issued.

What were you testing here? What didn't work as expected? 
;;;","01/Oct/14 03:53;sriharsha;[~nehanarkhede] I was trying to test if the controller is recovering from  a soft failure successfully and above described behavior is outcome of issuing a delete topic command not necessarily anything to do with controller's ability to come out of soft failure.
Hence I removed the producers/consumers and didn't do delete topic command even than the old controller didn't shutdown properly and I believe this is what causing the delete topic to fail. Since the old controller didn't shutdown topic partition goes to offline which is causing new controller's TopicDeletionManager go into a loop where one of the topic partition replica's are offline and keep retrying to delete it.;;;","01/Oct/14 22:27;nehanarkhede;[~sriharsha] Controller's inability to not shutdown on a soft failure is actually a problem and we need to look into it before fixing that case for delete topic. Would you mind filing another JIRA and stating the steps to reproduce the controller issue and make this depend on that JIRA? Since this JIRA is a blocker for 0.8.2, we are hoping to make progress on it. ;;;","01/Oct/14 22:38;sriharsha;[~nehanarkhede] working on finding the issue behind controller's shutdown. I'll file a JIRA.;;;","04/Oct/14 06:45;guozhang;[~harsha_ch] could we also try one more test case: delete topic while leader rebalance is on-going?;;;","04/Oct/14 06:52;sriharsha;[~guozhang]  I'll work on that test will report the results.  Is there any way to induce the leader rebalance manually?;;;","04/Oct/14 08:36;nehanarkhede;[~sriharsha] Yes. The preferred replica election admin tool can be used to balance the leaders. You would have to have imbalanced leaders before that, though. A broker bounce is the easiest way to end up with leader imbalance.;;;","04/Oct/14 08:43;sriharsha;[~nehanarkhede] [~guozhang] I ran the preferred replica election tool in my tests. But I'll try bouncing the broker and run this tool.;;;","05/Oct/14 09:16;nehanarkhede;[~sriharsha] Now that KAFKA-1663 is pushed to trunk, the previously failing test should now pass right? The only other thing to wait on would be the leader rebalance tests. [~clarkhaskins], [~guozhang]: At this point, many failure tests pass on delete topic. It will be great to try delete topic on 100s of topics on some of LinkedIn's clusters, if possible. Any chance this test can happen in the 0.8.2 timeframe (1-2 weeks) ?;;;","05/Oct/14 09:26;sriharsha;[~nehanarkhede] I ran all the tests except leader rebalance tests with KAFKA-1663 all of them are passed in my tests. With 1000 topics set to partition 3 and replication factor of 3 and producers, consumers running on all of the topics. I am planning on doing the leader rebalance tests tonight will update the results. It will be great to do this testing on LinkedIn's cluster too :).;;;","10/Oct/14 00:51;sriharsha;[~nehanarkhede] [~guozhang] [~junrao] I ran tests for simultaneously running  preferred replica election tool and deleting multiple topics.
I kept running into KAFKA-1305 but by increasing controller.message.queue.size to 1000 I was able to run these tests successfully.
While testing this couple of things caught my eye.
following code in KafkaController.PreferredReplicaElectionListener
{code}
      val partitions = partitionsForPreferredReplicaElection -- controllerContext.partitionsUndergoingPreferredReplicaElection
      val partitionsForTopicsToBeDeleted = partitions.filter(p => controller.deleteTopicManager.isTopicQueuedUpForDeletion(p.topic))
      if(partitionsForTopicsToBeDeleted.size > 0) {
        error(""Skipping preferred replica election for partitions %s since the respective topics are being deleted""
          .format(partitionsForTopicsToBeDeleted))
      }
      else
        controller.onPreferredReplicaElection(partitions -- partitionsForTopicsToBeDeleted)
    }
{code}
It doesn't need a else part there since its calling onPreferredReplicaElection by removing partitionsForTopicsToBeDeleted

In PartitionStateMachine.DeleteTopicListener
{code}
        if(topicsToBeDeleted.size > 0) {
          info(""Starting topic deletion for topics "" + topicsToBeDeleted.mkString("",""))
          // add topic to deletion list
          controller.deleteTopicManager.enqueueTopicsForDeletion(topicsToBeDeleted)
          // mark topic ineligible for deletion if other state changes are in progress
          topicsToBeDeleted.foreach { topic =>
            val preferredReplicaElectionInProgress =
              controllerContext.partitionsUndergoingPreferredReplicaElection.map(_.topic).contains(topic)
            val partitionReassignmentInProgress =
              controllerContext.partitionsBeingReassigned.keySet.map(_.topic).contains(topic)
            if(preferredReplicaElectionInProgress || partitionReassignmentInProgress)
              controller.deleteTopicManager.markTopicIneligibleForDeletion(Set(topic))
          }
        }
{code}

The above code  enqueueTopicsForDeletion which calls resumeTopicDeletionThread() to start the deletion of topics 
mark topic ineligible should be before the enqueueTopicsForDeletion. This way deletion of the topic won't happen if there is preferred replica election or partitions reassignment going for the said topics. I am testing these changes. Let me know what you think of these changes. Thanks.
;;;","10/Oct/14 01:11;junrao;Sriharsha,

I think you are right on both points. Thanks for finding them out.;;;","10/Oct/14 01:40;nehanarkhede;[~sriharsha] Those observations are right, would you like to submit a patch?

bq. I kept running into KAFKA-1305 but by increasing controller.message.queue.size to 1000 I was able to run these tests successfully.

Thanks for running the tests. Did you get a chance to test it by making the queue unbounded?;;;","10/Oct/14 03:26;sriharsha;[~nehanarkhede] I am running above tests with the proposed changes. Will submit a patch shortly on this JIRA.
""Thanks for running the tests. Did you get a chance to test it by making the queue unbounded?""
I can set controller.message.queue.size to Int.MaxValue and run tests. ;;;","10/Oct/14 05:13;sriharsha;Created reviewboard https://reviews.apache.org/r/26521/diff/
 against branch origin/trunk;;;","10/Oct/14 05:15;sriharsha;[~junrao] [~nehanarkhede] re-ran all of the above tests with this patch. Tests passed.
I ran it with controller.message.queue.size set to 1000 and also Int.MaxValue which is what LinkedBlockingQueue does for unbounded queue.;;;","10/Oct/14 05:54;junrao;Thanks for the patch. +1. Committed to both trunk and 0.8.2.

Sriharsha,

Thanks a lot for helping out.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add metrics collection and graphs to the system test framework,KAFKA-489,12605259,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,29/Aug/12 01:32,07/Sep/12 06:28,22/Mar/23 15:10,07/Sep/12 06:28,0.8.0,,,,,,,,,,,,,,,,,0,replication-testing,,,,,"We have a new system test framework that allows defining a test cluster, starting kafka processes in the cluster, running tests and collecting logs. In addition to this, it will be great to have the ability to do the following for each test case run -

1. collect metrics as exposed by mbeans
2. collect various system metrics exposed by sar/vmstat/jvm
3. graph the metrics

The expected output of this work should be the ability to output a link to all the graphs for each test case.",,jfung,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Aug/12 05:29;nehanarkhede;kafka-489-broker-metrics.pdf;https://issues.apache.org/jira/secure/attachment/12542831/kafka-489-broker-metrics.pdf","29/Aug/12 05:29;nehanarkhede;kafka-489-consumer-metrics.pdf;https://issues.apache.org/jira/secure/attachment/12542832/kafka-489-consumer-metrics.pdf","29/Aug/12 05:29;nehanarkhede;kafka-489-producer-metrics.pdf;https://issues.apache.org/jira/secure/attachment/12542833/kafka-489-producer-metrics.pdf","29/Aug/12 03:50;nehanarkhede;kafka-489-v1.patch;https://issues.apache.org/jira/secure/attachment/12542814/kafka-489-v1.patch","29/Aug/12 08:59;nehanarkhede;kafka-489-v2.patch;https://issues.apache.org/jira/secure/attachment/12542874/kafka-489-v2.patch","29/Aug/12 05:29;nehanarkhede;kafka-metrics-home.pdf;https://issues.apache.org/jira/secure/attachment/12542834/kafka-metrics-home.pdf",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,241663,,,Wed Aug 29 17:37:39 UTC 2012,,,,,,,,,,"0|i029p3:",11172,,,,,,,,,,,,,,,,,,,,"29/Aug/12 03:49;nehanarkhede;
1. Added a new metrics definition file defined in json format. The purpose of this file is to define the graphs that we want to plot at the end of each test case run. The file is organized as a list of dashboards, one per role (zookeeper/broker/producer/consumer). Each dashboard has all the graphs associated for that role. Each graph is associated with a mbean and has -
1. Graph title
2. Mbean name
3. Attributes and respective y axis labels.
	A separate graph is plotted for each attribute specified for a mbean. 

2. Metrics are collected when an entity is started. The metrics definition json file is read and the JmxTool is used to collect all the attributes for a particular mbean in a separate csv file. So, we have one csv file per mbean definied in metrics.json

3. At the end of each test case run, the metrics scripts go through the metrics.json file, find the csv files for all entities associated with a mbean, and plot one graph per attribute. These graphs are placed under testcase/dashboards/[role]/. 

4. Once the graphs are plotted, another script goes through metrics.json and creates html dashboards arranging the graphs in html files, one per role. So we have 4 dashboards, one for zookeeper, broker, producer and consumer. To view the graphs, open testcase/dashboards/metrics.html

5. Here are the new packages used to build this framework -
5.1. The graphs are plotted using matplotlib. So matplotlib needs to be installed in order to get these graphs
5.2. I included a very lightweight python package “pyh” to create the html pages. This avoids writing boiler-plate code to create simple html pages.

6. Code changes -
6.1. metrics.py includes APIs to collect metrics, plot graphs and create dashboards
6.2. Currently, we use SnapshotStats to collect metrics. The problem is that it only supports collecting metrics at fixed time windows which is not configurable. It was hard coded to be 1 minute, but for tests, this turns out to be too large to get any meaningful metrics.  Another issue is that we use static objects to register mbeans in most places. I couldn't find a better way to pass the monitoring duration config parameter. For now, I've hardcoded that to 1s, I realize that this is not ideal. But since we will be scraping SnapshotStats as part of KAFKA-203, we can punt on this for now. 
6.3. The new codahale metrics for socket server and request purgatory attached the broker id to the mbean name. This is inconvenient for most monitoring systems since now they need to pick up the broker id from the application config in order to create the right mbean name for metrics collection. Also, since each broker starts in a separate JVM, there isn't much value in identifying the mbeans by the broker id. So, I removed the broker id from all mbeans exposed by the codahale metrics package. 
6.4. Right now, there is one csv file output per mbean. The other alternative is one csv file for all possible mbeans exposed by the kafka process. There are 2  concerns with including all metrics in one big csv file -
1. This file might become too large for long running tests. 
2. If some column gets wedged for some mbean, that can affect the graphs for all other mbeans
6.5. Arguably, we don't even need this metrics.json file if we decide to collect all mbeans exposed by a kafka process. The reason I have one is that each graph needs to have a meaningful x/y axes label and a meaningful title. But, if we think the fully qualified mbean name is not too bad for a graph title, and the mbean attribute name is workable as the yaxes label, we could remove it. 
6.6. Removed the single_host_multiple_brokers_test

To see the graphs -

1. Run the test
cd system_test
python -B system_test_runner.py

2. Open the system_test/replication_testsuite/testcase_1/dashboards/metrics.html in a browser;;;","29/Aug/12 05:29;nehanarkhede;Attaching some screenshots of the metrics dashboard for a test case run to give people an approximate idea of how the output looks like. 
;;;","29/Aug/12 07:26;jfung;Hi Neha,

The patch looks good in the system test framework part.

1. However, the following exception is seen when the test is trying to plot graph. Is this something we can ignore for now ?

2012-08-28 16:18:20,470 - ERROR - ERROR while plotting graph /home/jfung/workspace_kafka/kafka_r1378357_489v1_sanity/system_test/replication_testsuite/testcase_1/dashboards/broker/kafka.server:type=ProducerRequestPurgatory,name=SatisfactionRate:MeanRate.svg: [Errno 2] No such file or directory: u'/home/jfung/workspace_kafka/kafka_r1378357_489v1_sanity/system_test/replication_testsuite/testcase_1/dashboards/broker/kafka.server:type=ProducerRequestPurgatory,name=SatisfactionRate:MeanRate.svg' (metrics)
Traceback (most recent call last):
  File ""/home/jfung/workspace_kafka/kafka_r1378357_489v1_sanity/system_test/utils/metrics.py"", line 176, in draw_graph_for_role
    ""time"", labelAndAttribute[0], labelAndAttribute[1], outputGraphFile)
  File ""/home/jfung/workspace_kafka/kafka_r1378357_489v1_sanity/system_test/utils/metrics.py"", line 138, in plot_graphs
    plt.savefig(outputGraphFile)

2. This is the pathname of the file in the exception message:

/home/jfung/workspace_kafka/kafka_r1378357_489v1_sanity/system_test/replication_testsuite/testcase_1/dashboards/broker/kafka.server:type=ProducerRequestPurgatory,name=ExpirationRate:MeanRate.svg;;;","29/Aug/12 08:11;junrao;+1 on the patch. One minor issue: We should remove the info level logging in SyncProducerStats.recordProduceRequest().;;;","29/Aug/12 08:59;nehanarkhede;John, 

That was a bug in the patch that didn't pre-create the required dashboards directory. Hence the graph plotting script failed while writing to the svg file at that location. I've fixed that in patch v2. 

Fixed the info statement in SyncProducerStats.;;;","30/Aug/12 01:37;jfung;+1 on patch v2.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NullPointerException in KafkaConfigStorage when config storage starts right before shutdown request,KAFKA-2944,12918068,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,gwenshap,ewencp,ewencp,04/Dec/15 00:58,12/Jan/17 10:05,22/Mar/23 15:10,15/Jun/16 23:53,0.9.0.0,,,,,,0.10.0.0,,,,,,,KafkaConnect,,,,0,,,,,,"Relevant log where you can see a config update starting, then the request to shutdown happens and we end up with a NullPointerException:

{quote}
[2015-12-03 09:12:55,712] DEBUG Change in connector task count from 2 to 3, writing updated task configurations (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2015-12-03 09:12:56,224] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect)
[2015-12-03 09:12:56,224] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer)
[2015-12-03 09:12:56,227] INFO Stopped ServerConnector@10cb550e{HTTP/1.1}{0.0.0.0:8083} (org.eclipse.jetty.server.ServerConnector)
[2015-12-03 09:12:56,234] INFO Stopped o.e.j.s.ServletContextHandler@3f8a24d5{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2015-12-03 09:12:56,235] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer)
[2015-12-03 09:12:56,235] INFO Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2015-12-03 09:12:58,209] ERROR Unexpected exception in KafkaBasedLog's work thread (org.apache.kafka.connect.util.KafkaBasedLog)
java.lang.NullPointerException
	at org.apache.kafka.connect.storage.KafkaConfigStorage.completeTaskIdSet(KafkaConfigStorage.java:558)
	at org.apache.kafka.connect.storage.KafkaConfigStorage.access$1200(KafkaConfigStorage.java:143)
	at org.apache.kafka.connect.storage.KafkaConfigStorage$1.onCompletion(KafkaConfigStorage.java:476)
	at org.apache.kafka.connect.storage.KafkaConfigStorage$1.onCompletion(KafkaConfigStorage.java:372)
	at org.apache.kafka.connect.util.KafkaBasedLog.poll(KafkaBasedLog.java:235)
	at org.apache.kafka.connect.util.KafkaBasedLog.readToLogEnd(KafkaBasedLog.java:275)
	at org.apache.kafka.connect.util.KafkaBasedLog.access$300(KafkaBasedLog.java:70)
	at org.apache.kafka.connect.util.KafkaBasedLog$WorkThread.run(KafkaBasedLog.java:307)
[2015-12-03 09:13:26,704] ERROR Failed to write root configuration to Kafka:  (org.apache.kafka.connect.storage.KafkaConfigStorage)
java.util.concurrent.TimeoutException: Timed out waiting for future
	at org.apache.kafka.connect.util.ConvertingFutureCallback.get(ConvertingFutureCallback.java:74)
	at org.apache.kafka.connect.storage.KafkaConfigStorage.putTaskConfigs(KafkaConfigStorage.java:352)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnector(DistributedHerder.java:737)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnectorTasksWithRetry(DistributedHerder.java:677)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:673)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startWork(DistributedHerder.java:640)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.handleRebalanceCompleted(DistributedHerder.java:598)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.tick(DistributedHerder.java:184)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:159)
	at java.lang.Thread.run(Thread.java:745)
[2015-12-03 09:13:26,704] ERROR Failed to reconfigure connector's tasks, retrying after backoff: (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
org.apache.kafka.connect.errors.ConnectException: Error writing root configuration to Kafka
	at org.apache.kafka.connect.storage.KafkaConfigStorage.putTaskConfigs(KafkaConfigStorage.java:355)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnector(DistributedHerder.java:737)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnectorTasksWithRetry(DistributedHerder.java:677)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:673)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startWork(DistributedHerder.java:640)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.handleRebalanceCompleted(DistributedHerder.java:598)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.tick(DistributedHerder.java:184)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:159)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.util.concurrent.TimeoutException: Timed out waiting for future
	at org.apache.kafka.connect.util.ConvertingFutureCallback.get(ConvertingFutureCallback.java:74)
	at org.apache.kafka.connect.storage.KafkaConfigStorage.putTaskConfigs(KafkaConfigStorage.java:352)
	... 8 more
{quote}

I'm not certain that the issue is specifically due to shutting down (the KafkaConfigStorage.stop() hasn't been invoked yet when this occurs, so the underlying KafkaBasedLog is still running, although shutdown of the entire process has started), but this has only shown up during shutdown so far.",,ewencp,githubbot,gwenshap,jinxing6042@126.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3423,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jan 12 02:05:19 UTC 2017,,,,,,,,,,"0|i2p98f:",9223372036854775807,,ewencp,,,,,,,,,,,,,,,,,,"01/Jan/16 23:16;jinxing6042@126.com;Cannot reproduce this; believe it is transient failure;
Since method ""halt()"" in DistributedHerder has not executed yet, believe that it is not the issue of shutdown; 
In method of KafkaConfigStorage::putTaskConfigs, if failed to send messages with TASK but succeeded sending message with COMMIT_TASKS_PREFIX, the deferredTaskUpdates will not have corresponding key of connector, thus result in a NullPointerException in KafkaConfigStorage;
So it make sense to call a 'flush'  after sending easy message of connector or task configuration to KafkaBasedLog;;;;","01/Jan/16 23:29;githubbot;GitHub user ZoneMayor opened a pull request:

    https://github.com/apache/kafka/pull/723

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

    Lost of ""config messages"" can affect the logic of KafkaConfigStorage;
    Call readToEnd after sending each message to KafkaBasedLog to ensure that all config messages are flushed to Kafka;
    Since ""config messages""  sending to KafkaBasedLog are metadata, it will not affect performance too much;

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ZoneMayor/kafka trunk-KAFKA-2944

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/723.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #723
    
----
commit 34240b52e1b70aa172b65155f6042243d838b420
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-18T07:22:20Z

    Merge pull request #12 from apache/trunk
    
    2015-12-18

commit 52d02f333e86d06cfa8fff5facd18999b3db6d83
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-30T03:08:08Z

    Merge pull request #13 from apache/trunk
    
    2015-12-30

commit 82150dccc59ac0e436acc5186d2b8fb66c9df671
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-01T15:21:41Z

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

----
;;;","02/Jan/16 15:05;githubbot;Github user ZoneMayor closed the pull request at:

    https://github.com/apache/kafka/pull/723
;;;","02/Jan/16 15:05;githubbot;GitHub user ZoneMayor reopened a pull request:

    https://github.com/apache/kafka/pull/723

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

    Lost of ""config messages"" can affect the logic of KafkaConfigStorage;
    Call readToEnd after sending each message to KafkaBasedLog to ensure that all config messages are flushed to Kafka;
    Since ""config messages""  sending to KafkaBasedLog are metadata, it will not affect performance too much;

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ZoneMayor/kafka trunk-KAFKA-2944

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/723.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #723
    
----
commit 34240b52e1b70aa172b65155f6042243d838b420
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-18T07:22:20Z

    Merge pull request #12 from apache/trunk
    
    2015-12-18

commit 52d02f333e86d06cfa8fff5facd18999b3db6d83
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-30T03:08:08Z

    Merge pull request #13 from apache/trunk
    
    2015-12-30

commit 82150dccc59ac0e436acc5186d2b8fb66c9df671
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-01T15:21:41Z

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

----
;;;","02/Jan/16 15:06;githubbot;Github user ZoneMayor closed the pull request at:

    https://github.com/apache/kafka/pull/723
;;;","02/Jan/16 15:06;githubbot;GitHub user ZoneMayor reopened a pull request:

    https://github.com/apache/kafka/pull/723

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

    Lost of ""config messages"" can affect the logic of KafkaConfigStorage;
    Call readToEnd after sending each message to KafkaBasedLog to ensure that all config messages are flushed to Kafka;
    Since ""config messages""  sending to KafkaBasedLog are metadata, it will not affect performance too much;

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ZoneMayor/kafka trunk-KAFKA-2944

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/723.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #723
    
----
commit 34240b52e1b70aa172b65155f6042243d838b420
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-18T07:22:20Z

    Merge pull request #12 from apache/trunk
    
    2015-12-18

commit 52d02f333e86d06cfa8fff5facd18999b3db6d83
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-30T03:08:08Z

    Merge pull request #13 from apache/trunk
    
    2015-12-30

commit 82150dccc59ac0e436acc5186d2b8fb66c9df671
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-01T15:21:41Z

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

----
;;;","02/Jan/16 15:06;githubbot;Github user ZoneMayor closed the pull request at:

    https://github.com/apache/kafka/pull/723
;;;","02/Jan/16 15:31;githubbot;GitHub user ZoneMayor reopened a pull request:

    https://github.com/apache/kafka/pull/723

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

    Lost of ""config messages"" can affect the logic of KafkaConfigStorage;
    Call readToEnd after sending each message to KafkaBasedLog to ensure that all config messages are flushed to Kafka;
    Since ""config messages""  sending to KafkaBasedLog are metadata, it will not affect performance too much;

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ZoneMayor/kafka trunk-KAFKA-2944

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/723.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #723
    
----
commit 34240b52e1b70aa172b65155f6042243d838b420
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-18T07:22:20Z

    Merge pull request #12 from apache/trunk
    
    2015-12-18

commit 52d02f333e86d06cfa8fff5facd18999b3db6d83
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-30T03:08:08Z

    Merge pull request #13 from apache/trunk
    
    2015-12-30

commit 82150dccc59ac0e436acc5186d2b8fb66c9df671
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-01T15:21:41Z

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

----
;;;","03/Jan/16 21:20;githubbot;Github user ZoneMayor closed the pull request at:

    https://github.com/apache/kafka/pull/723
;;;","03/Jan/16 21:22;githubbot;GitHub user ZoneMayor reopened a pull request:

    https://github.com/apache/kafka/pull/723

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

    Lost of ""config messages"" can affect the logic of KafkaConfigStorage;
    Call readToEnd after sending each message to KafkaBasedLog to ensure that all config messages are flushed to Kafka;
    Since ""config messages""  sending to KafkaBasedLog are metadata, it will not affect performance too much;

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ZoneMayor/kafka trunk-KAFKA-2944

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/723.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #723
    
----
commit 34240b52e1b70aa172b65155f6042243d838b420
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-18T07:22:20Z

    Merge pull request #12 from apache/trunk
    
    2015-12-18

commit 52d02f333e86d06cfa8fff5facd18999b3db6d83
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-30T03:08:08Z

    Merge pull request #13 from apache/trunk
    
    2015-12-30

commit 82150dccc59ac0e436acc5186d2b8fb66c9df671
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-01T15:21:41Z

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

commit 320386d2c484dac7eed9b7fe1584ca376e4ad897
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-03T06:09:00Z

    fix

commit 67d1b21661886b204bbb86bc472a2ecce57613dc
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-03T07:45:53Z

    small fix

----
;;;","03/Jan/16 22:48;githubbot;Github user ZoneMayor closed the pull request at:

    https://github.com/apache/kafka/pull/723
;;;","03/Jan/16 22:52;githubbot;GitHub user ZoneMayor reopened a pull request:

    https://github.com/apache/kafka/pull/723

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

    Lost of ""config messages"" can affect the logic of KafkaConfigStorage;
    Call readToEnd after sending each message to KafkaBasedLog to ensure that all config messages are flushed to Kafka;
    Since ""config messages""  sending to KafkaBasedLog are metadata, it will not affect performance too much;

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ZoneMayor/kafka trunk-KAFKA-2944

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/723.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #723
    
----
commit 34240b52e1b70aa172b65155f6042243d838b420
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-18T07:22:20Z

    Merge pull request #12 from apache/trunk
    
    2015-12-18

commit 52d02f333e86d06cfa8fff5facd18999b3db6d83
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-30T03:08:08Z

    Merge pull request #13 from apache/trunk
    
    2015-12-30

commit 82150dccc59ac0e436acc5186d2b8fb66c9df671
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-01T15:21:41Z

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

commit 320386d2c484dac7eed9b7fe1584ca376e4ad897
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-03T06:09:00Z

    fix

commit 67d1b21661886b204bbb86bc472a2ecce57613dc
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-03T07:45:53Z

    small fix

----
;;;","17/Jan/16 21:57;githubbot;Github user ZoneMayor closed the pull request at:

    https://github.com/apache/kafka/pull/723
;;;","17/Jan/16 21:57;githubbot;GitHub user ZoneMayor reopened a pull request:

    https://github.com/apache/kafka/pull/723

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

    Lost of ""config messages"" can affect the logic of KafkaConfigStorage;
    Call readToEnd after sending each message to KafkaBasedLog to ensure that all config messages are flushed to Kafka;
    Since ""config messages""  sending to KafkaBasedLog are metadata, it will not affect performance too much;

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ZoneMayor/kafka trunk-KAFKA-2944

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/723.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #723
    
----
commit 34240b52e1b70aa172b65155f6042243d838b420
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-18T07:22:20Z

    Merge pull request #12 from apache/trunk
    
    2015-12-18

commit 52d02f333e86d06cfa8fff5facd18999b3db6d83
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-30T03:08:08Z

    Merge pull request #13 from apache/trunk
    
    2015-12-30

commit 82150dccc59ac0e436acc5186d2b8fb66c9df671
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-01T15:21:41Z

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

commit 320386d2c484dac7eed9b7fe1584ca376e4ad897
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-03T06:09:00Z

    fix

commit 67d1b21661886b204bbb86bc472a2ecce57613dc
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-03T07:45:53Z

    small fix

commit c31562642eaf2fa9bd35366246430fa6de8be6d8
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-09T10:46:43Z

    Revert ""small fix""
    
    This reverts commit 67d1b21661886b204bbb86bc472a2ecce57613dc.

commit ef1d9a8921d2e5060824878d7212b1d50454e0f9
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-09T10:48:44Z

    Revert ""fix""
    
    This reverts commit 320386d2c484dac7eed9b7fe1584ca376e4ad897.

commit 5c09181de11a5cdae78acf690513f0166a1d5c21
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-09T10:48:58Z

    Revert ""KAFKA-2944: fix NullPointerException in KafkaConfigStorage""
    
    This reverts commit 82150dccc59ac0e436acc5186d2b8fb66c9df671.

commit eba2a0737ae93f3d8e0137c5901277f53c62daac
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-10T08:25:36Z

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

----
;;;","18/Jan/16 00:14;githubbot;Github user ZoneMayor closed the pull request at:

    https://github.com/apache/kafka/pull/723
;;;","18/Jan/16 00:14;githubbot;GitHub user ZoneMayor reopened a pull request:

    https://github.com/apache/kafka/pull/723

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

    Lost of ""config messages"" can affect the logic of KafkaConfigStorage;
    Call readToEnd after sending each message to KafkaBasedLog to ensure that all config messages are flushed to Kafka;
    Since ""config messages""  sending to KafkaBasedLog are metadata, it will not affect performance too much;

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ZoneMayor/kafka trunk-KAFKA-2944

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/723.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #723
    
----
commit 34240b52e1b70aa172b65155f6042243d838b420
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-18T07:22:20Z

    Merge pull request #12 from apache/trunk
    
    2015-12-18

commit 52d02f333e86d06cfa8fff5facd18999b3db6d83
Author: ZoneMayor <jinxing6042@126.com>
Date:   2015-12-30T03:08:08Z

    Merge pull request #13 from apache/trunk
    
    2015-12-30

commit 82150dccc59ac0e436acc5186d2b8fb66c9df671
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-01T15:21:41Z

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

commit 320386d2c484dac7eed9b7fe1584ca376e4ad897
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-03T06:09:00Z

    fix

commit 67d1b21661886b204bbb86bc472a2ecce57613dc
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-03T07:45:53Z

    small fix

commit c31562642eaf2fa9bd35366246430fa6de8be6d8
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-09T10:46:43Z

    Revert ""small fix""
    
    This reverts commit 67d1b21661886b204bbb86bc472a2ecce57613dc.

commit ef1d9a8921d2e5060824878d7212b1d50454e0f9
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-09T10:48:44Z

    Revert ""fix""
    
    This reverts commit 320386d2c484dac7eed9b7fe1584ca376e4ad897.

commit 5c09181de11a5cdae78acf690513f0166a1d5c21
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-09T10:48:58Z

    Revert ""KAFKA-2944: fix NullPointerException in KafkaConfigStorage""
    
    This reverts commit 82150dccc59ac0e436acc5186d2b8fb66c9df671.

commit eba2a0737ae93f3d8e0137c5901277f53c62daac
Author: jinxing <jinxing@fenbi.com>
Date:   2016-01-10T08:25:36Z

    KAFKA-2944: fix NullPointerException in KafkaConfigStorage

----
;;;","02/Mar/16 11:50;gwenshap;Created PR https://github.com/apache/kafka/pull/993 for partial improvement here.;;;","03/Mar/16 10:51;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/993
;;;","15/Jun/16 23:53;ewencp;Refactoring has actually made it impossible to trigger this anymore -- the data passed in at the call site of the method that causes the problem is guaranteed to be non-null after the refactoring in KAFKA-3459. Marking with the same fix version, 0.10.0.0;;;","12/Jan/17 10:05;githubbot;Github user jinxing64 closed the pull request at:

    https://github.com/apache/kafka/pull/723
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate controlled shutdown into kafka shutdown hook,KAFKA-927,12650258,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriramsub,sriramsub,sriramsub,31/May/13 08:50,05/Jun/13 01:40,22/Mar/23 15:10,04/Jun/13 07:09,,,,,,,0.8.0,,,,,,,,,,,0,,,,,,The controlled shutdown mechanism should be integrated into the software for better operational benefits. Also few optimizations can be done to reduce unnecessary rpc and zk calls. This patch has been tested on a prod like environment by doing rolling bounces continuously for a day. The average time of doing a rolling bounce with controlled shutdown for a cluster with 7 nodes without this patch is 340 seconds. With this patch it reduces to 220 seconds. Also it ensures correctness in scenarios where the controller shrinks the isr and the new leader could place the broker to be shutdown back into the isr.,,jjkoshy,junrao,nehanarkhede,sriramsub,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jun/13 01:50;sriramsub;KAFKA-927-v2-revised.patch;https://issues.apache.org/jira/secure/attachment/12585900/KAFKA-927-v2-revised.patch","01/Jun/13 08:23;sriramsub;KAFKA-927-v2.patch;https://issues.apache.org/jira/secure/attachment/12585687/KAFKA-927-v2.patch","04/Jun/13 06:08;sriramsub;KAFKA-927-v3-removeimports.patch;https://issues.apache.org/jira/secure/attachment/12585967/KAFKA-927-v3-removeimports.patch","04/Jun/13 04:49;sriramsub;KAFKA-927-v3.patch;https://issues.apache.org/jira/secure/attachment/12585936/KAFKA-927-v3.patch","04/Jun/13 06:44;sriramsub;KAFKA-927-v4.patch;https://issues.apache.org/jira/secure/attachment/12585977/KAFKA-927-v4.patch","31/May/13 08:52;sriramsub;KAFKA-927.patch;https://issues.apache.org/jira/secure/attachment/12585519/KAFKA-927.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,330585,,,Tue Jun 04 17:40:32 UTC 2013,,,,,,,,,,"0|i1l17b:",330919,,,,,,,,,,,,,,,,,,,,"31/May/13 23:56;nehanarkhede;Sriram,

This patch doesn't compile with the following errors - 

[error] /home/nnarkhed/Projects/apache-kafka-git/core/src/main/scala/kafka/server/KafkaApis.scala:133: not found: type ControlledShutdownRequest
[error]     val controlledShutdownRequest = request.requestObj.asInstanceOf[ControlledShutdownRequest]
[error]                                                                     ^
[error] /home/nnarkhed/Projects/apache-kafka-git/core/src/main/scala/kafka/server/KafkaApis.scala:135: not found: type ControlledShutdownResponse
[error]     val controlledShutdownResponse = new ControlledShutdownResponse(controlledShutdownRequest.correlationId,
[error]                                          ^
[error] /home/nnarkhed/Projects/apache-kafka-git/core/src/main/scala/kafka/server/KafkaServer.scala:28: ControlledShutdownResponse is not a member of kafka.api
[error] import kafka.api.{ControlledShutdownResponse, ControlledShutdownRequest}
[error]        ^
[error] /home/nnarkhed/Projects/apache-kafka-git/core/src/main/scala/kafka/server/KafkaServer.scala:157: not found: type ControlledShutdownRequest
[error]             val request = new ControlledShutdownRequest(correlationId.getAndIncrement, config.brokerId)
[error]                               ^
[error] /home/nnarkhed/Projects/apache-kafka-git/core/src/main/scala/kafka/server/KafkaServer.scala:160: not found: value ControlledShutdownResponse
[error]             val shutdownResponse = ControlledShutdownResponse.readFrom(response.buffer)
[error]                                    ^
;;;","01/Jun/13 00:10;junrao;Thanks for the patch. Overall, a well thought-out patch. Some comments.

1. KafkaController.shutdownBroker: We should probably only do controlled shutdown if the controller is active.

2. KafkaApis: If the controller is not active, we should send an errorcode back to the ControlledShutdownRequest.

3. KafkaServer: I am not sure that we should call replicaManager.replicaFetcherManager.closeAllFetchers() at the beginning of the controlled shutdown. Once the fetchers are closed, the affected leaders have to wait for the timeout before committing new messages since they have to shrink the ISR. Instead, it's better if we let the fetcher to be closed through leaderAndIsr requests from the controller.

4. KafkaConfig: Could we consolidate controlledShutdownMaxRetries and controlledShutdownEnable to one config controlledShutDownWaitTime? If that value is <=0, no controlled shutdown is done. Otherwise, we will try controlled shutdown until that time has passed.

5. With the new logic added in ReplicaManager/Partition, I am not sure if the old controlled shutdown tool still works properly. Should we just remove the tool and the jmx hook?

6. There are new files not included in the patch.;;;","01/Jun/13 00:45;nehanarkhede;Thanks for the patch, very well thought out! Few comments -
1. KafkaServer
1.1 doControlledShutdown()
- Is there a reason why we cannot just invoke shutdown() on the ReplicaManager instead of hacking into the replica fetcher manager and shutting down the fetchers ?
- ""starting controlled shutdown"" -> ""Starting controlled shutdown"". Though it is not introduced in this patch, can we please change the same in the shutdown() API as well?
- Typo -> shutdownSuceeded
- This method is pretty big and slightly hard to read, for someone who is new to controlled shutdown. Can we move controller discovery/connection logic to a separate API named connectToController() ? -
        val controllerId = ZkUtils.getController(kafkaZookeeper.getZookeeperClient)
        ZkUtils.getBrokerInfo(kafkaZookeeper.getZookeeperClient, controllerId) match {
          case Some(broker) =>
            if (channel == null || prevController == null || !prevController.equals(broker)) {
              // if this is the first attempt or if the controller has changed, create a channel to the most recent
              // controller
              if (channel != null) {
                channel.disconnect()
              }
              channel = new BlockingChannel(broker.host, broker.port,
                BlockingChannel.UseDefaultBufferSize,
                BlockingChannel.UseDefaultBufferSize,
                config.controllerSocketTimeoutMs)
              channel.connect()
              prevController = broker
            }
          case None=>
            //ignore and try again
        }
- I also think it will be cleaner for the loop to look like, but it's upto you :) 
      while (!shutdownSucceeded && remainingRetries > 0) {
         val controller = connectToController(zkClient)
         val shutdownSucceeded = sendControllerShutdownRequest(controller)
         if(!shutdownSucceeded)
            Thread.sleep(...)
         remainingRetries -= 1
      }
- Can we add either a warn or an info message that the broker will retry controlled shutdown after n ms ?
        if (!shutdownSuceeded) {
          Thread.sleep(config.controlledShutdownRetryBackoffMs)
        }
- Can we rename doControlledShutdown() to just controlledShutdown(). This will follow the naming conventions in the rest of the code, since we don't name methods doSomething.
- Let's remove the zkClient unused variable

2. KafkaApis
- If the controller is not active, we should send the appropriate error code
  
3. KafkaController
- getPartitionsAssignedToBroker() does not need to read from zookeeper. The controller should already have the latest data available as the controllerLock is acquired at this point. 
- The following updates zookeeper which is not required since the leader would've done that long before the controller does it. This is because you shutdown the replica fetchers at the beginning of controlled shutdown. It will be much faster to just send a leader and isr request with the shrunk ISR to the existing leader, though I doubt that is required as well.
            else {
              // if the broker is a follower, updates the isr in ZK and notifies the current leader
              replicaStateMachine.handleStateChanges(Set(PartitionAndReplica(topicAndPartition.topic,
                topicAndPartition.partition, id)), OfflineReplica)
            }

4. We want to know that the broker is rejecting the become-follower request in the state change log when the following happens. So it is not enough to just surround the addFetcher call with this condition 
5. New files are not included in the patch
          if (!replicaManager.isShuttingDown.get()) {
            // start fetcher thread to current leader if we are not shutting down
            replicaFetcherManager.addFetcher(topic, partitionId, localReplica.logEndOffset, leaderBroker)
          }
;;;","01/Jun/13 08:22;sriramsub;Thank you for the review guys.

Jun - 

1. I did not add an explicit check since the state manager anyway throw. Added one explicitly.
3. I have thought different approaches to do it exactly right but all of them seems ugly. I will think a little bit more but it should not be a blocker since most of the active topic would realize the isr change soon due to the number of messages.
4. I don't like to overload config value with multiple meanings. The config name should do exactly what it is meant to in my opinion.
5. It works perfectly fine. Infact there is a unit test for the old tool that works fine. The functionality of the tool has not changed.
6. Added the missing files

Neha -
1.
1.1 Done
1.2 Done
1.3 Done
1.4 Refactoring the method is actually pretty tricky. There are actually multiple dependencies between the methods (previousController, channels). The individual functions (if we manage to refactor), dont really do a single operation to provide a good name to it. I have added comments to make things clear. 
1.6 Added a warn
1.7 renamed the method name

2. Done
3. If the leader did realize that the follower has fallen off the isr soon then there are no issues. However that does not seem to be the case. We use the number of messages or time period to decide when to remove the follower from the isr. The default time period used is 10sec. So it could take as long as 10 seconds to realize the isr change. However the controller may do it much sooner and hence we get the better of the two. Having said that, there is an ugly fix to make the leader realize the isr change immediately after the replica thread stops but I need more time to think about that.
4. updated the state change log
5. added the missing files

;;;","03/Jun/13 22:55;junrao;Thanks for patch v2. A few more comments:

20. KafkaController: If when shutdownBroker is called, the controller is no longer active, both state machines will throw an exception on state change calls. However, the issue is that we add the shutdown broker to controllerContext.shuttingDownBrokerIds and it's never reset. This may become a problem if this broker becomes a controller again. At the minimum, we need to reset controllerContext.shuttingDownBrokerIds in  onControllerFailover(). However, I am a bit confused why we never reset controllerContext.shuttingDownBrokerIds and the shutdown logic still works.

21. ControlledShutdownRequest.handleError(): We should probably set partitionsRemaining in ControlledShutdownResponse to empty instead of null, since the serialization of ControlledShutdownResponse doesn't handle partitionsRemaining being null.

22. testRollingBounce:
22.1 The test makes sure that the leader for topic1 is changed after broker 0 is shutdown. However, the leader for topic1 could be on broker 1 initially. In this case, the leader won't be changed after broker 0 is shutdown.
22.2 The default controlledShutdownRetryBackoffMs is 5secs, which is probably too long for the unit test. 

23. KafkaServer: We need to handle the errorCode in ControlledShutdownResponse since the controller may have moved after we send the ControlledShutdown request.

From the previous review:
3. I think a simple solution is to (1) not call replicaManager.replicaFetcherManager.closeAllFetchers() in KafkaServer during shutdown; (2) in KafkaController.shutdownBroker(), for each partition on the shutdown broker, we first send a stopReplicaRequest to it for that partition before going through the state machine logic. Since the state machine logic involves ZK reads/writes, it's very likely that the stopReplicaRequest will reach the broker before the subsequent LeaderAndIsr requests. So, in most cases, the leader should be able to shrink ISR quicker than the timeout, without churns in ISR.;;;","04/Jun/13 01:50;sriramsub;Realized my previous patch did not have my latest changes just the new files.

20. shuttingDownBrokerIds does get updated on broker failure
21 done
22.1 i had already fixed this. The new patch should have the change
23. This is also handled in the new patch

3. That sounds reasonable among all the hacky fixes. ;;;","04/Jun/13 02:07;nehanarkhede;Thanks for the revised v2 patch. Few more comments -

1. KafkaServer
1.1 startupComplete should either be a volatile variable to AtomicBoolean. Two different threads call startup() and controlledShutdown(), which modify startupComplete.
1.2 In controlledShutdown(), we need to handle error codes in ControlledShutdownResponse explicitly. It can happen that the error code is set and partitionsRemaining are 0, which will lead to errors.

2. Partition

From previous review #4, if the broker has to ignore the become follower request anyway, does it make sense to even process part of it and truncate log etc ?

3. From previous review #3, I meant that it is pointless to do the ZK write on the controller since right after the write, since the follower hasn't received the stop replica request and the leader hasn't received shrunk isr, the broker being shut down will get added back to ISR. You can verify that this happens from the logs. It also makes controlled shutdown very slow since typically in production we move ~1000 partitions from the broker and zk writes can take ~20ms which means several seconds wasted just doing the ZK writes. Instead, it is enough to let the leader shrink the isr by sending it the leader and isr request. On the other hand, we can argue that the OfflineReplica state change itself should be changed to avoid the ZK write. But that is a bigger change, so we should avoid that right now.;;;","04/Jun/13 04:49;sriramsub;1.1 Done
1.2 Done
2. We would need to do some of these to ensure the new leader is updated and the log itself is going to be truncated either on startup or shutdown. Hence did not feel a strong reason to make this path more optimized.

3. As we spoke offline, there seems to be edge case where not updating ZK could lead to bad things happening. So updating ZK before leaderisr request.;;;","04/Jun/13 05:57;junrao;Thanks for patch v3. A few more comments:

30. KafkaServer:
30.1 Could you combine isShuttingDown and startupComplete?
30.2 In controlledShutdown(), it's not clear if it's worth caching the socket channel. Technically, it's possible for a controller to come back on the broker with the same id, but with a different broker host/port. It's simpler to just always close the socket channel on each ControlledShutdownRequest and create a new channel on retry.

31. KafkaController:
31.1 remove unused import java.util.concurrent.{Semaphore
31.2 I think we still need to set shuttingDownBrokerIds to empty in onControllerFailover(). A controller may failover during a controlled shutdown and later regain the controllership. OnBrokerFailure() is only called if the controller is active. So shuttingDownBrokerIds may not be empty when the controllership switches back.;;;","04/Jun/13 06:02;nehanarkhede;+1 on v3 other than Jun's comments.;;;","04/Jun/13 06:07;sriramsub;30.1 Don't feel strong about this. I think it makes things less readable with not much savings
30.2 The new broker includes the host and port and hence it works.

31.1 Done
31.2 This is already there in the previous patch. It is in InitializeControllerContext;;;","04/Jun/13 06:44;sriramsub;From offline feedback
1. reset startupcomplete flag on shutdown for unit test
2. cleaned channel before shutting down;;;","04/Jun/13 07:09;junrao;Thanks for patch v4. +1 and committed to 0.8.;;;","05/Jun/13 01:40;jjkoshy;+1 - sorry I got to this late.

Small nit: the scaladoc for shutdown broker needs an edit which we will clean up later.
We probably don't need the adminTest's testShutdownBroker given that the rolling bounce test exercises the same logic.

Also, I think we can close KAFKA-817 - another approach with similar goals.

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Negative offsets in replication-offset-checkpoint file,KAFKA-1923,12772734,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,ovgolovin,ovgolovin,06/Feb/15 00:50,17/Jul/19 08:16,22/Mar/23 15:10,17/Jul/19 08:16,0.8.2.0,,,,,,,,,,,,,core,,,,1,reliability,,,,,"Today was the second time we witnessed negative offsets in replication-offset-checkpoint file. After restart the node stops replicating some of its partitions.
Unfortunately we can't reproduce it yet. But the two cases we encountered indicate a bug which should be addressed.",,aozeritsky,ewencp,ijuma,jeffwidman,kiranp,ovgolovin,rsivaram,suninside,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3978,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jan 29 19:36:21 UTC 2018,,,,,,,,,,"0|i258s7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"23/Dec/16 20:29;aozeritsky;Problem stil exists (v0.10.1.1). Trying to reproduce it. I've read the code and found that the only place with negative offsets is Replica.logEndOffset (for remote Replica), but I dont understand how it can get into highwatermark.;;;","24/Jan/17 14:46;ewencp;[~ijuma] Should this still be in 0.10.2.0 at this point since nobody's been assigned?;;;","26/Jan/17 00:42;ijuma;[~ewencp], moved to 0.10.3.0 since we don't know how this can happen.;;;","07/Nov/17 05:33;rsivaram;Since this is complex and there is no PR yet, moving this out to the next version.;;;","30/Jan/18 03:36;ewencp;This seems to just be getting bumped from one version to the next, I'm just going to remove the fix version at this point.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Readme should specify that Gradle 2.0 is required for initial bootstrap,KAFKA-1781,12755868,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Duplicate,,jfim,jfim,18/Nov/14 02:16,30/Dec/14 08:02,22/Mar/23 15:10,30/Dec/14 08:02,0.8.2.0,,,,,,0.8.2.0,,,,,,,build,,,,0,,,,,,"Current README.md says ""You need to have gradle installed.""

As the bootstrap procedure doesn't work with gradle 1.12, this needs to say that 2.0 or greater is needed.",,donnchadh,jfim,joestein,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Nov/14 02:17;jfim;gradle-2.0-readme.patch;https://issues.apache.org/jira/secure/attachment/12681949/gradle-2.0-readme.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Dec 30 00:02:32 UTC 2014,,,,,,,,,,"0|i22gu7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"18/Nov/14 02:17;jfim;Documentation patch that changes README.md to say ""You need to have gradle 2.0 or greater installed."";;;","18/Nov/14 02:27;joestein;[~jean-francois.lamy@teximus.com] I have this working with Gradle 1.8 on my machine but your point is valid, we should go with the min version (lets set that as 1.8). Do you mind updating the patch? Thanks!;;;","18/Nov/14 02:41;jfim;It doesn't seem to work with 1.8.

{quote}
$ rm -rf gradle/wrapper/
$ gradle -version

------------------------------------------------------------
Gradle 1.8
------------------------------------------------------------

Build time:   2013-09-24 07:32:33 UTC
Build number: none
Revision:     7970ec3503b4f5767ee1c1c69f8b4186c4763e3d

[snip]
$ gradle
[snip]
Building project 'core' with Scala version 2.10.1

FAILURE: Build failed with an exception.

* Where:
Build file '/home/jfim/projects/kafka/build.gradle' line: 199

* What went wrong:
A problem occurred evaluating root project 'kafka'.
> Could not create task of type 'ScalaDoc'.

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED

Total time: 15.229 secs
$ ./gradlew
Error: Could not find or load main class org.gradle.wrapper.GradleWrapperMain
{quote}

This is what happens in 2.0. I also tested with 1.12, it does the same as 1.8.

{quote}
$ rm -rf gradle/wrapper/
$ gradle -version

------------------------------------------------------------
Gradle 2.0
------------------------------------------------------------

Build time:   2014-07-01 07:45:34 UTC
Build number: none
Revision:     b6ead6fa452dfdadec484059191eb641d817226c

[snip]

$ gradle
Building project 'core' with Scala version 2.10.1
:downloadWrapper

BUILD SUCCESSFUL

Total time: 7.239 secs
$ ./gradlew
Building project 'core' with Scala version 2.10.1
:downloadWrapper UP-TO-DATE

BUILD SUCCESSFUL

Total time: 6.937 secs
{quote};;;","18/Nov/14 02:51;joestein;That is weird, I tried from a fresh clone just now

{code}

new-host:apache_kafka joestein$ git clone https://git-wip-us.apache.org/repos/asf/kafka.git KAFKA-1781
Cloning into 'KAFKA-1781'...
remote: Counting objects: 21794, done.
remote: Compressing objects: 100% (7216/7216), done.
remote: Total 21794 (delta 12923), reused 19669 (delta 11330)
Receiving objects: 100% (21794/21794), 15.18 MiB | 623 KiB/s, done.
Resolving deltas: 100% (12923/12923), done.
new-host:apache_kafka joestein$ cd KAFKA-1781/
new-host:KAFKA-1781 joestein$ git checkout -b 0.8.2 origin/0.8.2
Branch 0.8.2 set up to track remote branch 0.8.2 from origin.
Switched to a new branch '0.8.2'
new-host:KAFKA-1781 joestein$ gradle --version

------------------------------------------------------------
Gradle 1.8
------------------------------------------------------------

Build time:   2013-09-24 07:32:33 UTC
Build number: none
Revision:     7970ec3503b4f5767ee1c1c69f8b4186c4763e3d

Groovy:       1.8.6
Ant:          Apache Ant(TM) version 1.9.2 compiled on July 8 2013
Ivy:          2.2.0
JVM:          1.7.0_25 (Oracle Corporation 23.25-b01)
OS:           Mac OS X 10.8.5 x86_64

new-host:KAFKA-1781 joestein$ gradle
To honour the JVM settings for this build a new JVM will be forked. Please consider using the daemon: http://gradle.org/docs/1.8/userguide/gradle_daemon.html.
Building project 'core' with Scala version 2.10.1
:downloadWrapper

BUILD SUCCESSFUL

Total time: 18.37 secs
new-host:KAFKA-1781 joestein$ ./gradlew jar
To honour the JVM settings for this build a new JVM will be forked. Please consider using the daemon: http://gradle.org/docs/2.0/userguide/gradle_daemon.html.
Building project 'core' with Scala version 2.10.1
:clients:compileJava
Download http://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.1.6/snappy-java-1.1.1.6.pom
Download http://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.1.6/snappy-java-1.1.1.6.jar
Note: Some input files use unchecked or unsafe operations.
Note: Recompile with -Xlint:unchecked for details.
:clients:processResources UP-TO-DATE
:clients:classes
:clients:jar
:contrib:compileJava UP-TO-DATE
:contrib:processResources UP-TO-DATE
:contrib:classes UP-TO-DATE
:contrib:jar
:core:compileJava UP-TO-DATE
:core:compileScala
/opt/apache_kafka/KAFKA-1781/core/src/main/scala/kafka/admin/AdminUtils.scala:259: non-variable type argument String in type pattern scala.collection.Map[String,_] is unchecked since it is eliminated by erasure
        case Some(map: Map[String, _]) => 
                       ^
/opt/apache_kafka/KAFKA-1781/core/src/main/scala/kafka/admin/AdminUtils.scala:262: non-variable type argument String in type pattern scala.collection.Map[String,String] is unchecked since it is eliminated by erasure
            case Some(config: Map[String, String]) =>
                              ^
/opt/apache_kafka/KAFKA-1781/core/src/main/scala/kafka/server/KafkaServer.scala:168: a pure expression does nothing in statement position; you may be omitting necessary parentheses
    ControllerStats.uncleanLeaderElectionRate
                    ^
/opt/apache_kafka/KAFKA-1781/core/src/main/scala/kafka/server/KafkaServer.scala:169: a pure expression does nothing in statement position; you may be omitting necessary parentheses
    ControllerStats.leaderElectionTimer
                    ^
/opt/apache_kafka/KAFKA-1781/core/src/main/scala/kafka/utils/Utils.scala:81: a pure expression does nothing in statement position; you may be omitting necessary parentheses
    daemonThread(name, runnable(fun))
                                ^
/opt/apache_kafka/KAFKA-1781/core/src/main/scala/kafka/network/SocketServer.scala:361: Visited SCOPE_EXIT before visiting corresponding SCOPE_ENTER. SI-6049
      maybeCloseOldestConnection
      ^
/opt/apache_kafka/KAFKA-1781/core/src/main/scala/kafka/network/SocketServer.scala:381: Visited SCOPE_EXIT before visiting corresponding SCOPE_ENTER. SI-6049
      try {
      ^
there were 12 feature warning(s); re-run with -feature for details
8 warnings found
:core:processResources UP-TO-DATE
:core:classes
:core:copyDependantLibs
:core:jar
:examples:compileJava
:examples:processResources UP-TO-DATE
:examples:classes
:examples:jar
:contrib:hadoop-consumer:compileJava
Note: Some input files use or override a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
Note: Some input files use unchecked or unsafe operations.
Note: Recompile with -Xlint:unchecked for details.
:contrib:hadoop-consumer:processResources UP-TO-DATE
:contrib:hadoop-consumer:classes
:contrib:hadoop-consumer:jar
:contrib:hadoop-producer:compileJava
:contrib:hadoop-producer:processResources UP-TO-DATE
:contrib:hadoop-producer:classes
:contrib:hadoop-producer:jar

BUILD SUCCESSFUL

Total time: 2 mins 34.612 secs
new-host:KAFKA-1781 joestein$ 

{code};;;","18/Nov/14 03:18;jfim;It is weird! This is what I get:

{quote}
$ git clone https://git-wip-us.apache.org/repos/asf/kafka.git KAFKA-1781
Cloning into 'KAFKA-1781'...
remote: Counting objects: 21794, done.
remote: Compressing objects: 100% (7216/7216), done.
remote: Total 21794 (delta 12925), reused 19667 (delta 11330)
Receiving objects: 100% (21794/21794), 15.17 MiB | 2.57 MiB/s, done.
Resolving deltas: 100% (12925/12925), done.
$ cd KAFKA-1781
$ git checkout -b 0.8.2 origin/0.8.2
Branch 0.8.2 set up to track remote branch 0.8.2 from origin.
Switched to a new branch '0.8.2'
$ gradle --version

------------------------------------------------------------
Gradle 1.8
------------------------------------------------------------

Build time:   2013-09-24 07:32:33 UTC
Build number: none
Revision:     7970ec3503b4f5767ee1c1c69f8b4186c4763e3d

Groovy:       1.8.6
Ant:          Apache Ant(TM) version 1.9.2 compiled on July 8 2013
Ivy:          2.2.0
JVM:          1.8.0_05 (Oracle Corporation 25.5-b02)
OS:           Linux 2.6.32-358.6.2.el6.x86_64 amd64

$ gradle
To honour the JVM settings for this build a new JVM will be forked. Please consider using the daemon: http://gradle.org/docs/1.8/userguide/gradle_daemon.html.
Building project 'core' with Scala version 2.10.1

FAILURE: Build failed with an exception.

* Where:
Build file '/home/jfim/projects/KAFKA-1781/build.gradle' line: 199

* What went wrong:
A problem occurred evaluating root project 'KAFKA-1781'.
> Could not create task of type 'ScalaDoc'.

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED

Total time: 10.612 secs
{quote}

The differences between our setups seem to be JDK version (1.7.0_25 for you, 1.8.0_05 on my end) and OS (Mac OS X vs Linux). 2.0 seems to work fine with the commands you use.

{quote}
$ rm -rf KAFKA-1781/
$ git clone https://git-wip-us.apache.org/repos/asf/kafka.git KAFKA-1781
Cloning into 'KAFKA-1781'...
remote: Counting objects: 21794, done.
remote: Compressing objects: 100% (7216/7216), done.
remote: Total 21794 (delta 12924), reused 19668 (delta 11330)
Receiving objects: 100% (21794/21794), 15.17 MiB | 2.74 MiB/s, done.
Resolving deltas: 100% (12924/12924), done.
$ cd KAFKA-1781
$ git checkout -b 0.8.2 origin/0.8.2
Branch 0.8.2 set up to track remote branch 0.8.2 from origin.
Switched to a new branch '0.8.2'
$ gradle --version

------------------------------------------------------------
Gradle 2.0
------------------------------------------------------------

Build time:   2014-07-01 07:45:34 UTC
Build number: none
Revision:     b6ead6fa452dfdadec484059191eb641d817226c

Groovy:       2.3.3
Ant:          Apache Ant(TM) version 1.9.3 compiled on December 23 2013
JVM:          1.8.0_05 (Oracle Corporation 25.5-b02)
OS:           Linux 2.6.32-358.6.2.el6.x86_64 amd64

$ gradle
To honour the JVM settings for this build a new JVM will be forked. Please consider using the daemon: http://gradle.org/docs/2.0/userguide/gradle_daemon.html.
Building project 'core' with Scala version 2.10.1
:downloadWrapper

BUILD SUCCESSFUL

Total time: 11.341 secs
$ ./gradlew
To honour the JVM settings for this build a new JVM will be forked. Please consider using the daemon: http://gradle.org/docs/2.0/userguide/gradle_daemon.html.
Building project 'core' with Scala version 2.10.1
:downloadWrapper UP-TO-DATE

BUILD SUCCESSFUL

Total time: 7.159 secs
{quote}

I don't mind amending the patch to reflect a lower version, but 2.0 and 2.2 both appear to work on my end, while 1.8 and 1.12 don't.;;;","18/Nov/14 03:27;joestein;I think your issue is related to your JVM being 8 instead of 7 which has some more info here KAFKA-1624 and not gradle versions ;;;","18/Nov/14 03:28;jfim;It seems to work with 1.8 and 1.12 if I switch the JDK to 1.7.0_51. Is JDK 8 supported by Kafka?;;;","18/Nov/14 03:30;joestein;JDK 8 related support information is captured here KAFKA-1624;;;","18/Nov/14 03:56;jfim;I think the two are related to JDK 8, but distinct issues. For example, running with JDK 8, gradle 1.8 and scala version 2.11:

{quote}
$ gradle -version

------------------------------------------------------------
Gradle 1.8
------------------------------------------------------------

Build time:   2013-09-24 07:32:33 UTC
Build number: none
Revision:     7970ec3503b4f5767ee1c1c69f8b4186c4763e3d

Groovy:       1.8.6
Ant:          Apache Ant(TM) version 1.9.2 compiled on July 8 2013
Ivy:          2.2.0
JVM:          1.8.0_05 (Oracle Corporation 25.5-b02)
OS:           Linux 2.6.32-358.6.2.el6.x86_64 amd64

$ gradle -PscalaVersion=2.11
To honour the JVM settings for this build a new JVM will be forked. Please consider using the daemon: http://gradle.org/docs/1.8/userguide/gradle_daemon.html.
Building project 'core' with Scala version 2.11

FAILURE: Build failed with an exception.

* Where:
Build file '/home/jfim/projects/KAFKA-1781/build.gradle' line: 199

* What went wrong:
A problem occurred evaluating root project 'KAFKA-1781'.
> Could not create task of type 'ScalaDoc'.

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED

Total time: 7.725 secs
{quote}

I think the takeaway for the wrapper download is that 2.0 is required if running on JDK 8 and that 1.8 (and potentially lower) work on JDK 7. The rest of the build is still broken with scala 2.10.1 on JDK 8, even when on gradle 2.0.

I'm not sure what the proper resolution to this issue would be. Requiring 2.0 seems rather safe but is only required on JDK 8 and does not fix KAFKA-1624. Perhaps adding a note that JDK 8 is not supported at this point in time is the proper resolution?;;;","18/Nov/14 03:58;jfim;Also, see https://issues.gradle.org/browse/GRADLE-3094 which has been fixed in Gradle 2.0.;;;","27/Nov/14 09:03;junrao;We can probably just double commit KAFKA-1624 to 0.8.2 and add the gradle version requirement for JDK 8 in README.;;;","29/Nov/14 13:11;joestein;+1 to double commit KAFKA-1624 and add the gradle version requirement for JDK 8 in README;;;","30/Dec/14 07:21;nehanarkhede;[~charmalloc]. Just checking to see if you had a chance to double commit and make the README changes. This is marked as a blocker for 0.8.2;;;","30/Dec/14 08:02;joestein;[~nehanarkhede] done;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Corrupt index found on clean startup,KAFKA-1554,12728622,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Duplicate,mgharat,alexismidon,alexismidon,22/Jul/14 01:06,08/Oct/16 00:59,22/Mar/23 15:10,15/Oct/15 10:51,0.8.1,,,,,,,,,,,,,core,,,,5,,,,,,"On a clean start up, corrupted index files are found.
After investigations, it appears that some pre-allocated index files are not ""compacted"" correctly and the end of the file is full of zeroes.
As a result, on start up, the last relative offset is zero which yields an offset equal to the base offset.

The workaround is to delete all index files of size 10MB (the size of the pre-allocated files), and restart. Index files will be re-created.

{code}
find $your_data_directory -size 10485760c -name *.index #-delete
{code}

This is issue might be related/similar to https://issues.apache.org/jira/browse/KAFKA-1112

{code}
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,696 INFO main kafka.server.KafkaServer.info - [Kafka Server 847605514], starting
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,698 INFO main kafka.server.KafkaServer.info - [Kafka Server 847605514], Connecting to zookeeper on zk-main0.XXX:2181,zk-main1.XXX:2181,zk-main2.XXXX:2181/production/kafka/main
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,708 INFO ZkClient-EventThread-14-zk-main0.XXX.com:2181,zk-main1.XXX.com:2181,zk-main2.XXX.com:2181,zk-main3.XXX.com:2181,zk-main4.XXX.com:2181/production/kafka/main org.I0Itec.zkclient.ZkEventThread.run - Starting ZkClient event thread.
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,714 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:zookeeper.version=3.3.3-1203054, built on 11/17/2011 05:47 GMT
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,714 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:host.name=i-6b948138.inst.aws.airbnb.com
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,714 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.version=1.7.0_55
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,715 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.vendor=Oracle Corporation
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,715 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.home=/usr/lib/jvm/jre-7-oracle-x64/jre
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,715 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.class.path=libs/snappy-java-1.0.5.jar:libs/scala-library-2.10.1.jar:libs/slf4j-api-1.7.2.jar:libs/jopt-simple-3.2.jar:libs/metrics-annotation-2.2.0.jar:libs/log4j-1.2.15.jar:libs/kafka_2.10-0.8.1.jar:libs/zkclient-0.3.jar:libs/zookeeper-3.3.4.jar:libs/metrics-core-2.2.0.jar
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,715 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,716 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.io.tmpdir=/tmp
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,716 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:java.compiler=<NA>
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,716 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:os.name=Linux
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,716 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:os.arch=amd64
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,717 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:os.version=3.2.0-61-virtual
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,717 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:user.name=kafka
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,717 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:user.home=/srv/kafka
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,717 INFO main org.apache.zookeeper.ZooKeeper.logEnv - Client environment:user.dir=/srv/kafka/kafka_2.10-0.8.1
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,718 INFO main org.apache.zookeeper.ZooKeeper.<init> - Initiating client connection, connectString=zk-main0.XXX.com:2181,zk-main1.XXX.com:2181,zk-main2.XXX.com:2181,zk-main3.XXX.com:2181,zk-main4.XXX.com:2181/production/kafka/main sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4758af63
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,733 INFO main-SendThread() org.apache.zookeeper.ClientCnxn.startConnect - Opening socket connection to server zk-main1.XXX.com/10.12.135.61:2181
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,738 INFO main-SendThread(zk-main1.XXX.com:2181) org.apache.zookeeper.ClientCnxn.primeConnection - Socket connection established to zk-main1.XXX.com/10.12.135.61:2181, initiating session
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,745 INFO main-SendThread(zk-main1.XXX.com:2181) org.apache.zookeeper.ClientCnxn.readConnectResult - Session establishment complete on server zk-main1.XXX.com/10.12.135.61:2181, sessionid = 0x646838f07761601, negotiated timeout = 6000
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,747 INFO main-EventThread org.I0Itec.zkclient.ZkClient.processStateChanged - zookeeper state changed (SyncConnected)
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,961 INFO main kafka.log.LogManager.info - Found clean shutdown file. Skipping recovery for all logs in data directory '/mnt/kafka_logs'
2014-07-11T00:53:17+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:17,962 INFO main kafka.log.LogManager.info - Loading log 'flog-30'
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg 2014-07-11 - 00:53:18,349 FATAL main kafka.server.KafkaServerStartable.fatal - Fatal error during KafkaServerStable startup. Prepare to shutdown
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg java.lang.IllegalArgumentException: - requirement failed: Corrupt index found, index file (/mnt/kafka_logs/flog-30/00000000000121158146.index) has non-zero size but the last offset is 121158146 and the base offset is 121158146
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.Predef$.require(Predef.scala:233)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.OffsetIndex.sanityCheck(OffsetIndex.scala:352)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:159)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:158)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.Iterator$class.foreach(Iterator.scala:727)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.Log.loadSegments(Log.scala:158)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.Log.<init>(Log.scala:64)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager$$anonfun$loadLogs$1$$anonfun$apply$4.apply(LogManager.scala:118)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager$$anonfun$loadLogs$1$$anonfun$apply$4.apply(LogManager.scala:113)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:105)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:113)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:105)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager.loadLogs(LogManager.scala:105)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.log.LogManager.<init>(LogManager.scala:57)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:275)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.server.KafkaServer.startup(KafkaServer.scala:72)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:34)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.Kafka$.main(Kafka.scala:46)
2014-07-11T00:53:18+00:00 i-6b948138 local3.emerg  -    at kafka.Kafka.main(Kafka.scala)
2014-07-11T00:53:18+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:18,351 INFO main kafka.server.KafkaServer.info - [Kafka Server 847605514], shutting down
2014-07-11T00:53:18+00:00 i-6b948138 local3.info 2014-07-11 - 00:53:18,353 INFO ZkClient-EventThread-14-zk-main0.XXX.com:2181,zk-main1.XXX.com:2181,zk-main2.XXX.com:2181,zk-main3.XXX.com:2181,zk-main4.XXX.com:2181/production/kafka/main org.I0Itec.zkclient.ZkEventThread.run - Terminate ZkClient event thread.
{code}","ubuntu 12.04, oracle jdk 1.7",alexismidon,eidi,ggriffin,gwenshap,h_o,hongyu.bi,jerry@apache.org,jjkoshy,jkreps,jonbringhurst,junrao,mazhar.shaikh.in,mgharat,pbaclace,rberdeen,stevemil00,steven.aerts,tnorden,vanyatka,wangbo23,xavji,zhiwei,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2012,,KAFKA-2012,,,,,,,,,,,,,,,,"24/Mar/15 08:47;mgharat;KAFKA-1554.patch;https://issues.apache.org/jira/secure/attachment/12706782/KAFKA-1554.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,406697,,,Fri Apr 08 18:33:59 UTC 2016,,,,,,,,,,"0|i1xzhr:",406717,,,,,,,,,,,,,,,,,,,,"23/Jul/14 06:59;junrao;Is this easily reproducible? Thanks,;;;","30/Aug/14 02:35;tnorden;We experienced this today, it happened when we upgraded from java 1.6 to 1.7.

kafka 0.8.1
CentOS release 5.9 (Final)
java version ""1.7.0_65""
OpenJDK Runtime Environment (rhel-2.5.1.2.el5_10-x86_64 u65-b17)
OpenJDK 64-Bit Server VM (build 24.65-b04, mixed mode);;;","30/Aug/14 03:09;jkreps;And just to confirm this is after a clean shutdown?;;;","30/Aug/14 03:19;tnorden;The shut down was clean but the reason we were shutting down was because we started seeing errors in the logs and one of our partitions was not being used.

{code}
[2014-08-29 14:11:07,877]  5469485 [kafka-request-handler-12] ERROR kafka.server.KafkaApis  - [KafkaApi-0] Error processing ProducerRequest with correlation id 1484684 from client
on partition [topic,53]
kafka.common.KafkaException: Trying to roll a new log segment for topic partition topic-53 with start offset 128157859 while it already exists.
        at kafka.log.Log.roll(Log.scala:481)
        at kafka.log.Log.maybeRoll(Log.scala:448)
        at kafka.log.Log.append(Log.scala:246)
        at kafka.cluster.Partition.appendMessagesToLeader(Partition.scala:354)
        at kafka.server.KafkaApis$$anonfun$appendToLocalLog$2.apply(KafkaApis.scala:376)
        at kafka.server.KafkaApis$$anonfun$appendToLocalLog$2.apply(KafkaApis.scala:366)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:233)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:233)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
        at scala.collection.Iterator$class.foreach(Iterator.scala:772)
        at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
        at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:45)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:95)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:233)
        at scala.collection.mutable.HashMap.map(HashMap.scala:45)
        at kafka.server.KafkaApis.appendToLocalLog(KafkaApis.scala:366)
        at kafka.server.KafkaApis.handleProducerRequest(KafkaApis.scala:292)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:185)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:42)
        at java.lang.Thread.run(Thread.java:745)
{code}

Deleting the 10MB indexes fixed the issue for us.;;;","14/Mar/15 07:25;mgharat;So in this case we should be deleting the index file and allow it to be rebuilt.
The sanity check should be done before we try to load the Log Segments. That way we can delete the corrupted index files and allow it to be rebuilt.;;;","14/Mar/15 07:28;mgharat;I can take a shot at this one.;;;","14/Mar/15 09:10;jjkoshy;That would be a work-around, but ideally we should figure out why it happened in the first place.;;;","24/Mar/15 08:47;mgharat;Created reviewboard https://reviews.apache.org/r/32422/diff/
 against branch origin/trunk;;;","08/Apr/15 08:27;gwenshap;Perhaps its better to rename and keep the index files instead of deleting? We may need them for troubleshooting later.
;;;","09/Apr/15 09:06;junrao;Yes, I am not sure if auto fixing the index is better. People then may not realize if there is an issue. It would be better to figure out what's causing this.;;;","12/May/15 18:14;stevemil00;I just ran into this.  In my case, we'd tried to load some metrics class that we hadn't actually installed, so Kafka blew up pretty early in its initialization sequence.

If anything causes Kafka to bomb out at startup, it creates all these corrupt index files.  I can remove them all, then start things up again, and if Kafka crashes (e.g., if I somehow missed removing one of these files, or if in an earlier attempt I'd renamed some topic partition directory from foo-5 to foo-5.old and Kafka didn't like parsing ""5.old"" as a number, just to pick an example :) ) they're all present again.

Is there some startup-related index-file thing it's doing where it temporarily cranks the file size up to 10485760 (or it seeks out to that spot in the file, maybe)?;;;","12/May/15 22:28;jjkoshy;That is useful to know - it might help reproducing this. Do you by any chance have stack traces of the ClassNotFound or equivalent?
Yes we create new segment indexes with that size but compact it when the segment rolls.
;;;","12/May/15 23:08;stevemil00;Hm, that seems to have rolled out of the logs at this point -- sorry.  I don't think that specific error was an issue: I think that anything that makes Kakfa exit after it's created the new segment index but before it's compacted it is an issue.

I think that if you do the following, you can reproduce the issue:

* create a new, empty topic, and don't publish anything to it.  For each partition in that topic, you should end up with the usual topicname-partition# directory somewhere (e.g., 'junk-2'), which will have an empty log file and an index file of size 10485760.
* copy the whole junk-2 directory somewhere safe (e.g., /var/tmp/junk-2).
* stop kafka
* cp -pr /var/tmp/junk-2 /whatever/kafka/log/junk-2.old
* start kafka

When you do that, Kafka will fail to start properly, with an error like:

{code}
[2015-05-12 15:00:55,661] FATAL [Kafka Server 1], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.lang.NumberFormatException: For input string: ""6.old""
        at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
        at java.lang.Integer.parseInt(Integer.java:492)
        at java.lang.Integer.parseInt(Integer.java:527)
        at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:247)
        at scala.collection.immutable.StringOps.toInt(StringOps.scala:30)
        at kafka.log.Log$.parseTopicPartitionName(Log.scala:833)
        at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$7$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:138)
        at kafka.utils.Utils$$anon$1.run(Utils.scala:54)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
{code}

and you'll also now have many index files of size 10485760.

Note that after a clean shutdown, you don't have any index files of that size, so I think what's happening here is something like:

* the code runs that replaces the working index file in any log directory with the 10485760-sized files, which Kafka uses (presumably) for the current log segment
* something blows up
* the usual code that would run at clean execution to replace the current, 10485760-sized files with their compacted versions doesn't run because of the blowup

leaving these files on disk.  And then at startup Kafka panics because it considers them corrupted.

I was able to use these steps on a spare broker we had and I could get this to repeat at will. :);;;","13/May/15 01:20;mgharat;This sounds interesting. We may try to reproduce this and check.;;;","13/May/15 03:03;jjkoshy;Thanks Steve - sorry I misread your earlier comment. The issue that you are raising is different - i.e., renaming a directory to foo-<n>.old (for e.g.,) - yes that is a restriction. You have to delete the corrupt index to get past this (and you presumably don't want to lose the actual log segments with the data anyway).

We are looking for a way to reproduce the original index corruption or a reasonable hypothesis on how it happens.
;;;","13/May/15 03:14;stevemil00;The foo-<n>.old thing was just a way I knew I could reproduce the failure.

I'm suggesting that if Kafka ever restarts and has an issue on its way up, and it exits before it's fully up and running, it'll leave a ton of corrupted index files as a result.  That is, anything strange that happens in someone's environment, that causes a restart that isn't happy, will ultimately cause index corruption of this sort.

Maybe the original poster didn't end up in this state because of an unexpected restart of the sort I'm describing, but the current behavior seems worth fixing.  I'm betting there was an unexpected startup issue in that person's case but I admit I might be wrong. :)

Did that help?;;;","14/Oct/15 17:39;wangbo23;@ Jun Rao, @Mayuresh Gharat  , I don't think this patch is available.
The method given in patch appears to be useless, because the sanityCheck() for loop in advance, then logSegments is empty, so the code useless.
;;;","15/Oct/15 10:50;mgharat;[~wangbo23] thanks for the review.
We did not iterate on this patch. This was resolved in https://issues.apache.org/jira/browse/KAFKA-2012. 
;;;","09/Apr/16 02:33;pbaclace;So it is fixed in 0.9.0 with KAFKA-2012; I can confirm seeing this issue occur in 0.8.1.1 for unused topics. 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Make signing artifacts optional, setting maven repository possible from command line",KAFKA-2199,12830814,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,ewencp,ewencp,ewencp,19/May/15 04:24,18/Aug/16 14:00,22/Mar/23 15:10,18/Aug/16 14:00,,,,,,,,,,,,,,build,,,,0,,,,,,"Currently it's annoying to work with snapshot builds if you want to install them rather than just build & test. There are a couple of problems. First, if you try to install (any of the upload* tasks), then you are required to sign the artifacts with a GPG key. Second, the way the variables are defined in gradle.properties seems to make it impossible to override them from the command line. You're required to edit your ~/.gradle/gradle.properties file (which is shared by all gradle projects).",,ewencp,jkreps,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jun/15 00:58;ewencp;KAFKA-2199.patch;https://issues.apache.org/jira/secure/attachment/12741647/KAFKA-2199.patch","19/May/15 04:26;ewencp;KAFKA-2199.patch;https://issues.apache.org/jira/secure/attachment/12733613/KAFKA-2199.patch","30/May/15 02:00;ewencp;KAFKA-2199_2015-05-29_11:00:44.patch;https://issues.apache.org/jira/secure/attachment/12736200/KAFKA-2199_2015-05-29_11%3A00%3A44.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jul 06 18:04:44 UTC 2015,,,,,,,,,,"0|i2ew5r:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"19/May/15 04:26;ewencp;Created reviewboard https://reviews.apache.org/r/34369/diff/
 against branch origin/trunk;;;","30/May/15 02:00;ewencp;Updated reviewboard https://reviews.apache.org/r/34369/diff/
 against branch origin/trunk;;;","30/May/15 05:53;jkreps;Committed.;;;","25/Jun/15 00:37;omkreddy; ./gradlew build is failing with below error.  isVerificationRequired() gradle task is removed in this patch.

{code}
FAILURE: Build failed with an exception.

* Where:
Build file '/safe/KAFKA/kafkaTrunk/build.gradle' line: 55

* What went wrong:
Could not evaluate onlyIf predicate for task ':clients:licenseTest'.
> Could not find method isVerificationRequired() for arguments [project ':clients'] on root project 'kafkaTrunk'.
{code};;;","25/Jun/15 00:58;ewencp;Created reviewboard https://reviews.apache.org/r/35832/diff/
 against branch origin/trunk;;;","25/Jun/15 01:02;ewencp;[~omkreddy] Sorry about that, ./gradlew build isn't one that I run normally. Submitted a new patch that just removes the licenseTest. We shouldn't really commit this until KAFKA-2248 is committed, but 2248 is more general since it doesn't just apply to source files, so I think it's the preferable solution.;;;","07/Jul/15 02:04;ewencp;Needs followup patch applied.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Failed to load class ""org.slf4j.impl.StaticLoggerBinder""",KAFKA-1354,12705825,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,rakeshacharya,rakeshacharya,01/Apr/14 08:14,27/Nov/21 16:33,22/Mar/23 15:10,13/Sep/17 20:36,0.8.1,,,,,,,,,,,,,log,,,,1,newbie,patch,usability,,,"Getting below errors during Kafka startup

SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[2014-03-31 18:55:36,488] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)",RHEL,daisuke.kobayashi,guozhang,jjkoshy,junrao,omkreddy,rakeshacharya,RakeshManiyoor@fico.com,saden1,spuder,srikrishna,tnachen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2419200,2419200,,0%,2419200,2419200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Nov/21 16:32;srikrishna;image-2021-11-27-14-02-14-795.png;https://issues.apache.org/jira/secure/attachment/13036686/image-2021-11-27-14-02-14-795.png","27/Nov/21 16:33;srikrishna;image-2021-11-27-14-03-52-371.png;https://issues.apache.org/jira/secure/attachment/13036687/image-2021-11-27-14-03-52-371.png",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,384149,,,Sat Nov 27 08:10:00 UTC 2021,,,,,,,,,,"0|i1u6iv:",384417,,,,,,,,,,,,,,,,,,,,"03/Apr/14 00:51;rakeshacharya;Any update?;;;","03/Apr/14 14:49;tnachen;Hi Rakesh, this is actually a very common message you get usually when Kafka doesn't find a log4j.properties file to configure a logger to use. How did you start the broker and do you have log4j.properties in the config folder where you read your server.properties?;;;","03/Apr/14 21:44;rakeshacharya;Yes the log4j.properties file is in same folder as server. Properties.

I have replaced the LOG_DIR in the kafka run class file to a location where I want logs to be stored, the same value exists in the log4j.properties file too.

;;;","03/Apr/14 21:50;rakeshacharya;Also when I start I am seeing the correct log directory being picked up along with log4j.properties

-Dlog4j.configuration, -Dkafka.logs.dir,-Xloggc

;;;","05/Apr/14 01:09;junrao;The issue is related to slf4j. slf4j only provides the api. The user is expected to provide the actual binding implementation. You can include either slf4j-simple.jar or slf4j-log4j12.jar in the classpath. Then the warning will go away.;;;","10/Apr/14 02:04;jjkoshy;Should we include a default binding that can be overridden through an environment variable in our start-up scripts?;;;","10/Apr/14 09:36;junrao;I am not sure. The problem is that you can't put more than one bindings in the classpath. Otherwise, slf4j is confused. If we include a default binding and a user's environment includes another binding, we will introduce a new problem.;;;","29/Apr/14 11:32;saden1;Kafka should definitely avoid forcing end-users to mess with logging libraries.  Currently Kafka distributes log4j and slf4j-api so it stands to reason to also include log4j binding in the distribution! ;;;","29/Apr/14 11:35;RakeshManiyoor@fico.com;hi

I will be out of the office until July 10th , with little access to E-mail or voicemail. I will respond to any queries upon my return.If there is crtical issues then please contact Rivera Jose.

Thanks.
Rakesh
This email and any files transmitted with it are confidential, proprietary and intended solely for the individual or entity to whom they are addressed. If you have received this email in error please delete it immediately.
;;;","29/Apr/14 12:03;junrao;This probably makes sense for Kafka brokers. However, the client dependency will be a tricky. I am wondering how other projects using slf4j specify their dependencies.;;;","29/Apr/14 23:55;saden1;As long as the client library uses slf4j api to log messages it only needs to include the slf4j-api jar. This way the user has the freedom to choose their own logging framework and add their slf4j bridges or bindings to their classpath.

Broker Dependencies:
slf4j-api.jar
slf4j-log4j12.jar
log4j.jar

Client Dependencies:
slf4j-api

For third party dependencies that use other logging frameworks the client and the broker will also need to include slf4j bridge dependencies. For example, if a third party library broker/client dependency uses commons logging then you should also distribute jcl-over-slf4j.jar.

;;;","30/Apr/14 01:20;junrao;That makes sense. The problem is that currently the kafka jar is for both the sever and the client. We are creating the new clients in a separate jar. Perhaps we can revisit this when the old clients are phased out.;;;","05/Sep/14 06:12;guozhang;Moving to 0.9 for tracking.;;;","23/Jan/17 09:15;RakeshManiyoor@fico.com;HI

I am currently OOO and have limited access to mails , So will respond once am back.


Cheers

Rakesh

This email and any files transmitted with it are confidential, proprietary and intended solely for the individual or entity to whom they are addressed. If you have received this email in error please delete it immediately.
;;;","13/Sep/17 20:36;omkreddy;This was fixed in 0.8.2  by adding slf4j-log4j12 binding to Kafka libs.;;;","27/Nov/21 16:10;srikrishna;slf4j-log4j12-1.7.30 version is already present in the libs.

What is the solution for this issue?

!image-2021-11-27-14-03-52-371.png!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Log warnings when client is disconnected from bootstrap brokers,KAFKA-2998,12922444,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,hachikuji,fhussonnois,fhussonnois,17/Dec/15 01:25,14/May/16 16:22,22/Mar/23 15:10,05/Apr/16 12:29,0.9.0.0,,,,,,0.10.0.0,,,,,,,clients,,,,0,,,,,,"If no broker from bootstrap.servers is available consumer retries indefinitely with debug log message :
 
DEBUG 17:16:13 Give up sending metadata request since no node is available
DEBUG 17:16:13 Initialize connection to node -1 for sending metadata request
DEBUG 17:16:13 Initiating connection to node -1 at localhost:9091.

At least, an ERROR message should be log after a number of retries.
In addition, maybe the consumer should fail in a such case ? This behavior could be set by a configuration property ?",,fhussonnois,githubbot,guozhang,hachikuji,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3468,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat May 14 08:22:33 UTC 2016,,,,,,,,,,"0|i2pzon:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"17/Dec/15 01:30;ijuma;Thanks for the report. Is this a duplicate of KAFKA-1894?;;;","12/Jan/16 09:24;hachikuji;[~ijuma] Maybe we can treat this as a separate issue. It seems common to accidentally point the bootstrap brokers to zookeeper, for example, and the current behavior is to silently retry forever. Maybe we can address the common misconfiguration problem here without needing the full patch for KAFKA-1894? A simple approach might be to log disconnects to any of the bootstrap brokers at the error level.;;;","12/Jan/16 09:48;ijuma;Sounds like a good plan.;;;","14/Jan/16 06:16;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/769

    KAFKA-2998: log warnings when client is disconnected from bootstrap brokers

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-2998

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/769.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #769
    
----
commit 079587a59c3bc1847618d8315e07483793c5ce7d
Author: Jason Gustafson <jason@confluent.io>
Date:   2016-01-13T22:14:46Z

    KAFKA-2998: log warnings when client is disconnected from bootstrap brokers

----
;;;","26/Mar/16 00:58;granthenke;[~hachikuji] I opened KAFKA-3468 before finding this jira. I linked it for now, but it may in fact be a duplicate. Feel free to mark it as a duplicate if your patch handles that scenario too. ;;;","05/Apr/16 12:29;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/769
;;;","05/Apr/16 12:29;guozhang;Issue resolved by pull request 769
[https://github.com/apache/kafka/pull/769];;;","14/May/16 16:22;ijuma;I updated the title to match what was actually implemented.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka integration tests fail on a fresh checkout,KAFKA-147,12525755,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,05/Oct/11 09:28,06/Oct/11 09:59,22/Mar/23 15:10,06/Oct/11 09:59,0.7,,,,,,0.7,,,,,,,,,,,0,,,,,,"On a fresh checkout and with an empty .ivy2 and .m2 cache, if you execute ./sbt update test, the integration tests will fail with this error - 

java.lang.NoSuchMethodError: junit.framework.TestSuite.<init>([Ljava/lang/Class;)V
	at org.scalatest.junit.JUnit3Suite.run(JUnit3Suite.scala:309)
	at org.scalatest.tools.ScalaTestFramework$ScalaTestRunner.run(ScalaTestFramework.scala:40)
	at sbt.TestRunner.run(TestFramework.scala:53)
	at sbt.TestRunner.runTest$1(TestFramework.scala:67)
	at sbt.TestRunner.run(TestFramework.scala:76)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11.runTest$2(TestFramework.scala:194)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)
	at sbt.NamedTestTask.run(TestFramework.scala:92)
	at sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)
	at sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)
	at sbt.TaskManager$Task.invoke(TaskManager.scala:62)
	at sbt.impl.RunTask.doRun$1(RunTask.scala:77)
	at sbt.impl.RunTask.runTask(RunTask.scala:85)
	at sbt.impl.RunTask.sbt$impl$RunTask$$runIfNotRoot(RunTask.scala:60)
	at sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)
	at sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)
	at sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)
	at sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)
	at sbt.Control$.trapUnit(Control.scala:19)
	at sbt.Distributor$Run$Worker.run(ParallelRunner.scala:131)

The reason being 2 versions of the junit jar on the test classpath that SBT uses to run the ""test"" command. The KafkaProject.scala file corrects defines one of the test dependencies to be junit-4.1, since it uses a JUnit api in some of the tests. The problem is that there is another junit jar (v3.8.1) which gets downloaded as a transitive dependency on Scala 2.8.0. The cause of the above error is an incorrect test classpath, that includes both v4.1 as well as v3.8.1.

One of the possible fixes is to override the ""testClasspath"" variable in SBT to explicitly exclude junit from directories other than core/lib_managed/test
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-92,,,,,,"06/Oct/11 09:44;nehanarkhede;KAFKA-147.patch;https://issues.apache.org/jira/secure/attachment/12497936/KAFKA-147.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,46280,,,Thu Oct 06 01:59:39 UTC 2011,,,,,,,,,,"0|i15z5z:",242997,,,,,,,,,,,,,,,,,,,,"06/Oct/11 09:44;nehanarkhede;Reverting the checkin (r1178669) for KAFKA-92 to resolve this bug.;;;","06/Oct/11 09:46;junrao;+1. We can upgrade to sbt 10.0 later.;;;","06/Oct/11 09:59;nehanarkhede;Thanks. Committed the patch;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZK consumer may lose a chunk worth of message during rebalance in some rare cases,KAFKA-154,12526693,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,12/Oct/11 01:34,15/Oct/11 15:33,22/Mar/23 15:10,12/Oct/11 03:12,0.7,,,,,,0.7,,,,,,,core,,,,0,,,,,,"Occasionally, we have see errors with the following message in the consumer log after a rebalance happens.
   consumed offset: xxx doesn't match fetch offset: yyy for topicz

The consumer offset xxx should always match the fetch offset yyy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/11 01:46;junrao;KAFKA-154.patch;https://issues.apache.org/jira/secure/attachment/12498631/KAFKA-154.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,59338,,,Sat Oct 15 07:33:38 UTC 2011,,,,,,,,,,"0|i15z7j:",243004,,,,,,,,,,,,,,,,,,,,"12/Oct/11 01:44;junrao;This problem is caused by a very subtle bug. When a fetcher calls PartitionTopicInfo.enqueue, we first advance the fetch offset and then enqueue the fetched chunk into a blocking queue. When the fetcher thread is interrupted (because we are shutting down the fetcher after a rebalance), it can happen that we just advanced the fetch offset to xxx, but got interrupted while trying to add the fetched chunk into the queue (so the chunk is not added to the queue). Then a new fetcher gets created to start fetching from xxx. This causes a chunk worth of data just before xxx to be lost to the consumer.  ;;;","12/Oct/11 01:48;junrao;Patch is ready for review.

We just need to make sure that we enqueue first and then advance the fetch offset. This way, if the enqueue operation gets interrupted, the fetch offset is not advanced. If the enqueue operation succeeds, the offset is guaranteed to be advanced since it can't be interrupted.;;;","12/Oct/11 03:06;nehanarkhede;+1. Good catch !;;;","12/Oct/11 03:12;junrao;Thanks for the review. Committed the patch.;;;","15/Oct/11 15:27;jjkoshy;While looking at this area of the code, I was wondering about this patch: wouldn't it permit the mirror issue of enqueue and not advancing the offset, since the interrupt could occur just before the fetch offset update? So the new fetcher may fetch the same offset again. It seems to me that the interrupt and PartitionTopicInfo's enqueue method itself should be mutually exclusive - or perhaps provide suitable handling for chunks with the same fetch offset in the consumer iterator. Or I must be missing something obvious :);;;","15/Oct/11 15:33;jjkoshy;Ok nm - it's late.. I see that the queues are cleared out.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Trim whitespaces from user specified configs,KAFKA-1057,12669037,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,omkreddy,nehanarkhede,nehanarkhede,17/Sep/13 23:59,03/Sep/15 08:04,22/Mar/23 15:10,05/Oct/14 07:35,,,,,,,0.9.0.0,,,,,,,config,,,,2,newbie,,,,,Whitespaces in configs are a common problem that leads to config errors. It will be nice if Kafka can trim the whitespaces from configs automatically,,gmaas,guozhang,nehanarkhede,omkreddy,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/14 20:20;omkreddy;KAFKA-1057.patch;https://issues.apache.org/jira/secure/attachment/12672931/KAFKA-1057.patch","04/Oct/14 22:48;omkreddy;KAFKA-1057_2014-10-04_20:15:32.patch;https://issues.apache.org/jira/secure/attachment/12672938/KAFKA-1057_2014-10-04_20%3A15%3A32.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,348969,,,Sat Oct 04 23:35:04 UTC 2014,,,,,,,,,,"0|i1o67z:",349267,,,,,,,,,,,,,,,,,,,,"08/May/14 08:15;sriharsha;[~nehanarkhede] can you please give me a bit of background on this bug. 
I tried adding white spaces to the kafka configs they are read properly
for ex:
broker.id =  1   
 port =  9092  
etc..
Let me know if I am looking at the wrong place.;;;","25/Aug/14 21:16;gmaas;Here's an example that has costed me a good day of work:
{code}
14/08/25 12:40:06 WARN kafka.consumer.ConsumerFetcherManager$LeaderFinderThread: [abc.private-1408970387063-6283475b-leader-finder-thread], Failed to find leader for Set([dev,0], [dev,1])
kafka.common.KafkaException: fetching topic metadata for topics [Set(dev)] from broker [ArrayBuffer(id:0,host:172.17.0.91 ,port:9092)] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:67)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:88)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:66)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:127)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:644)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.producer.SyncProducer.connect(SyncProducer.scala:141)
	at kafka.producer.SyncProducer.getOrMakeConnection(SyncProducer.scala:156)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:68)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:53)
{code}

This exception is thrown b/c the configured ip address contains a space:
{code}
advertised.host.name=172.17.0.91  
{code}

(BTW, this ip address is configured by a script using 'hostname -I' which adds a space after the address)

+1 for this bug;;;","05/Sep/14 06:03;guozhang;Moving out of 0.8.2 for now.;;;","15/Sep/14 00:19;nehanarkhede;[~sriharsha] The example used by [~maasg] above is reproducible, though I may not get a chance to take a stab at this anytime soon.;;;","04/Oct/14 20:20;omkreddy;Created reviewboard https://reviews.apache.org/r/26341/diff/
 against branch origin/trunk;;;","04/Oct/14 22:48;omkreddy;Updated reviewboard https://reviews.apache.org/r/26341/diff/
 against branch origin/trunk;;;","05/Oct/14 07:35;nehanarkhede;Thanks for the patch, pushed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make log segment delete asynchronous,KAFKA-636,12617922,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,jkreps,jkreps,28/Nov/12 11:51,12/Dec/12 03:47,22/Mar/23 15:10,12/Dec/12 03:47,,,,,,,,,,,,,,,,,,0,,,,,,"We have a few corner-case bugs around delete of segment files:
1. It is possible for delete and truncate to kind of cross streams and end up with a case where you have no segments.
2. Reads on the log have no locking (which is good) but as a result deleting a segment that is being read will result in some kind of I/O exception.
3. We can't easily fix the synchronization problems without deleting files inside the log's write lock. This can be a problem as deleting a 2GB segment can take a couple of seconds even on an unloaded system.

The proposed fix for these problems is to make file removal asynchronous using the following scheme as the new delete scheme:
1. Immediately remove the file from segment map and rename the~ file from X to X.deleted (e.g. 0000000.log to 000000.log.deleted. We think renaming a file will not impact reads since the file is already open and hence the name is irrelevant. This will always be O(1) and can be done inside the write lock.
2. Schedule a future operation to delete the file. The time to wait would be configurable but we would just default it to 60 seconds and probably no one would ever change it.
3. On startup we would delete any files with the .deleted suffix as they would have been pending deletes that didn't take place.

I plan to do this soon working against the refactored log (KAFKA-521). We can opt to back port the patch for 0.8 if we are feeling daring.",,jkreps,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Dec/12 07:32;jkreps;KAFKA-636-v1.patch;https://issues.apache.org/jira/secure/attachment/12559981/KAFKA-636-v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,292502,,,Tue Dec 11 19:47:41 UTC 2012,,,,,,,,,,"0|i0s39z:",162007,,,,,,,,,,,,,,,,,,,,"08/Dec/12 07:32;jkreps;This patch implements asynchronous delete in the log.

To do this Log.scala now requires a scheduler to be used for scheduling the deletions.

The deletion works as described above.

The locking for segment deletion can now be more aggressive since the file renames are assumed to be fast they can be inside the lock.

As part of testing this I also found a problem with MockScheduler, namely that it does not reentrant. That is, if scheduled tasks themselves create scheduled tasks it misbehaves. To fix this I rewrote MockScheduler to use a priority queue. The code is simpler and more correct since it now performs all executions in the correct order too.;;;","12/Dec/12 01:25;junrao;Thanks for the patch. +1. Just one minor comment:

1. Log.deleteSegment(): In asyncDeleteFiles(), is it better to log the deleting of a log segment in info instead of debug?
;;;","12/Dec/12 03:03;nehanarkhede;+1. Minor comments -

- Typos in the description of the deleteSegment API in Log.scala. 
- I agree with Jun on the info log level for the delete messages.;;;","12/Dec/12 03:47;jkreps;Checked in with the suggested changes.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Get gradle build to work with Java 8,KAFKA-2203,12831162,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,gwenshap,gajukbhat,gajukbhat,20/May/15 04:50,13/Oct/15 04:32,22/Mar/23 15:10,13/Oct/15 04:32,0.8.1.1,,,,,,0.9.0.0,,,,,,,build,,,,1,,,,,,"The gradle build halts because javadoc in java 8 is a lot stricter about valid html.

It might be worthwhile to special case java 8 as described [here|http://blog.joda.org/2014/02/turning-off-doclint-in-jdk-8-javadoc.html].",,aw,becket_qin,ewencp,gajukbhat,githubbot,guozhang,gwenshap,ijuma,jeff.maxwell,jghoman,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2294,,,,,,,,"20/May/15 04:52;gajukbhat;0001-Special-case-java-8-and-javadoc-handling.patch;https://issues.apache.org/jira/secure/attachment/12733950/0001-Special-case-java-8-and-javadoc-handling.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,Patch,,,,,,,,,9223372036854775807,,,Mon Oct 12 20:32:03 UTC 2015,,,,,,,,,,"0|i2eyaf:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"20/May/15 11:33;ewencp;+1 Double checked against JDK6 and JDK8 just to sanity check.;;;","24/Jun/15 23:13;jeff.maxwell;The KAFKA-2294 patch allows java 8 builds to compile error (not warning) free for later versions of scala (>=2.10.4) without disabling doclint.
Should this issue be closed or should the coding guide (http://kafka.apache.org/coding-guide.html) be updated with regard to javadoc comments?;;;","25/Jun/15 00:18;ewencp;The drawback is that I don't think we have good enough automated testing right now to catch issues across all the JDK versions and we still support JDK6+. We're likely to keep breaking things -- people who compile with < JDK8 will miss doc errors and people with > JDK6 can easily introduce non-JDK6 compatible code. The latter is somewhat alleviated by the fact that I think many committers check the build with JDK6.

Probably a better solution than this patch would be to get the testing infrastructure to properly test the entire matrix (JDK versions, scala versions, etc.) so we would catch issues like this quickly, but that's probably a bigger project and I think is currently hampered by the fact that the Apache infrastructure has high enough latency that the feedback is too disconnected from commits to be useful anyway.;;;","25/Jun/15 00:27;gwenshap;This should be done pre-commit and nearly every Apache project does it.

Just finish this:
https://issues.apache.org/jira/browse/KAFKA-1856

Every time we attach a patch (or we can modify this to work with pull requests) - Apache Jenkins will run all the tests / builds we need and post results on the JIRA. Our review cycle is long enough that Apache infra latency shouldn't be a major concern, and committers will be able to know when a patch passes.;;;","25/Jun/15 01:20;ewencp;[~gwenshap] Agreed that precommit is the ideal solution. Not sure that the setup in KAFKA-1856 works for this though -- can we get all the configurations we'd want, i.e. does a single jenkins job have access to all the jdk versions we'd need here? 

Also, if the entire test matrix was run, at current rates it'd take something like 20min * 2 JDK versions (min and max versions, at a minimum) * 4 scala versions = 2.66 hrs minimum for feedback since I don't think we can parallelize those unless we spread across multiple jenkins jobs? Or maybe it just requires a more complex Jenkins job to parameterize? Long turn around time is bad for submitters too...

For the precommit stuff, if we're switching to Github PRs, we could also possibly use Travis, which ASF supports in some fashion since they pay for capacity instead of relying on the ""fair use"" servers. Not sure how that integrates with JIRA though.
;;;","25/Jun/15 01:37;jeff.maxwell;FWIW Spring's solution appears to be dedicated CI builds: https://build.spring.io/browse/BOOT-JOJ8.
;;;","25/Jun/15 01:50;gwenshap;Having pre-commit comments on a JIRA will be significantly better than what we have at the moment.

I agree that there are additional concerns:
* Speed / parallelism (I think Hive and Sqoop solved it by running tests themselves in parallel)
* We need a good way to test with multiple jdk versions - possibly with multiple Jenkins jobs
* Integration of Travis with JIRA (IMO thats the biggest concern at the moment)

However, none of those seem unsolvable, and even a partial solution will be very useful. I really miss the pre-commit comments I get with other projects.  It just seems to me that we can get cool improvements with very little effort. KAFKA-1856 is waiting for someone to create a jenkins job and set up the precommit trigger.;;;","25/Jun/15 04:29;jghoman;A couple data points:
* Samza has a script that runs tests against all supported JDKs and Scala versions: https://github.com/apache/samza/blob/master/bin/check-all.sh  It's expected to be run before commits, both by the contributor and committer.  However, Samza's tests aren't as long as a Kafka's.
* Samza tried Travis, but eventually disabled it (SAMZA-642).  The parallel, multiconfiguration testing matrix was awesome, but we were seeing so many false positive test failures and the fact that it ran as a post-commit test (rather than pre) meant the most committers ignored it.;;;","16/Jul/15 23:14;sslavic;Kafka trunk still doesn't build with JDK 8.;;;","17/Jul/15 05:00;becket_qin;Is it true? We have been building and run Kafka in Java 8 for a while and did not see problems. What was the issue you saw?;;;","17/Jul/15 07:34;ewencp;[~becket_qin] I think only certain commands will fail. Common stuff like gradlew jar work. I think gradlew build or gradlew uploadArchivesAll fails, but I can't recall the particular build task that causes the failure.;;;","17/Jul/15 16:58;ijuma;I just did a `gradlew build` with JDK 8u60 EA and it succeeded (even though there were a number of warnings).;;;","17/Jul/15 17:44;sslavic;On a clean clone of trunk, with gradle 2.5 and JDK 8u45, when I run {{gradle clean jarAll}} build fails. Here is relevant build output fragment:
{noformat}
...
:kafka:core:compileScala
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0
error: error while loading CharSequence, class file '/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar(java/lang/CharSequence.class)' is broken
(bad constant pool tag 18 at byte 10)
error: error while loading AnnotatedElement, class file '/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar(java/lang/reflect/AnnotatedElement.class)' is broken
(bad constant pool tag 18 at byte 76)
error: error while loading Arrays, class file '/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar(java/util/Arrays.class)' is broken
(bad constant pool tag 18 at byte 765)
error: error while loading Comparator, class file '/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar(java/util/Comparator.class)' is broken
(bad constant pool tag 18 at byte 20)
/var/folders/lf/rbfblwvx6rx3xhm68yksmqjwdv1dsf/T/sbt_d6110328/xsbt/ExtractAPI.scala:479: error: java.util.Comparator does not take type parameters
  private[this] val sortClasses = new Comparator[Symbol] {
                                      ^
5 errors found
:kafka:core:compileScala FAILED
:jar_core_2_9_1 FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':core:compileScala'.
> org.gradle.messaging.remote.internal.PlaceholderException (no error message)

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED
{noformat}

Related issue from past: KAFKA-1624

And related discussion from dev mailing list: http://mail-archives.apache.org/mod_mbox/kafka-dev/201507.mbox/%3CCAHwHRrU75Of4ErxSr9-%3D4EEB_jCmcA4PL4S4hP2P-6peaUOfZA%40mail.gmail.com%3E

Is there a ticket to drop scala 2.9.x support? I couldn't find one.;;;","17/Jul/15 17:46;ijuma;Stevo, Scala 2.9.x doesn't support Java 8. That's your issue as far as I can see.;;;","17/Jul/15 17:55;ijuma;I was planning to start a [VOTE] thread in the mailing list today. If the vote passes, I'll create the issue and make the necessary change.;;;","29/Jul/15 17:00;ijuma;[~sslavic], does it work for you now that we no longer build against Scala 2.9?;;;","18/Aug/15 09:07;githubbot;GitHub user gwenshap opened a pull request:

    https://github.com/apache/kafka/pull/147

    KAFKA-2203: Getting Java8 to relax about javadoc and let our build pass

    This patch is different than the one attached to the JIRA - I'm applying the new javadoc rules to all subprojects while the one in the JIRA applies only to ""clients"". We need this since Copycat  has the same issues.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/gwenshap/kafka KAFKA-2203

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/147.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #147
    
----
commit 4f925d96457314bd42157dae8c8c40c5c08eda39
Author: Gwen Shapira <cshapi@gmail.com>
Date:   2015-08-18T01:05:13Z

    KAFKA-2203: Getting Java8 to relax about javadoc and let our build pass

----
;;;","18/Aug/15 12:46;aw;FYI, the precommit code that we're putting in front of the board as a potential TLP (see HADOOP-12111) already has support to do tests under multiple JDKs.  I'm currently in the process of adding gradle support, so hopefully in the future it will cover the exact concerns mentioned here.;;;","18/Aug/15 23:00;gwenshap;Thanks [~aw]. The report in HADOOP-12129 looks great. 
Is there any documentation on how projects can incorporate the new TLP? Anything we can do to help you validate gradle support?;;;","19/Aug/15 00:00;aw;We've got a ways to go before we do a release and one of those things is guidance on how projects should best incorporate it. That said, there is some usage documentation already there: https://github.com/apache/hadoop/tree/HADOOP-12111/dev-support/docs ... so we're not exactly starting from scratch.

I'm doing most of the gradle work in HADOOP-12257 with my dev code currently sitting in https://github.com/aw-altiscale/hadoop/tree/h12257 (in the dev-support dir).  It's going through a LOT of major changes still (with the occasional forced update) but feel free to mess around with it.  As soon as it gets more stable, I'll likely ping some folks from the projects I'm currently playing with (bigtop, samza, kafka) to have a look over since my knowledge of gradle isn't great.

The biggest thing I need right now are patches that are known to break or otherwise have bad behavior to see if the code catches it.  I've already did one test against a kafka patch that was out there that caused unit test failures. Due to junit being used, test-patch picked that up with no code changes required.  Same with bash code changes.   It's the scala bits that I definitely need help with: ""this has a scala compile error!""  ""this has a scala warning we should flag!"" etc. The multiple scala support is a bigger issue that maybe we'll tackle in the future.  I'd want to clean up HADOOP-12337 first though so that we have a better idea of how to matrix builds.

Thanks!;;;","22/Sep/15 20:27;ijuma;Jun, maybe you can review the patch from Gwen.;;;","13/Oct/15 04:32;guozhang;Issue resolved by pull request 147
[https://github.com/apache/kafka/pull/147];;;","13/Oct/15 04:32;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/147
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
offset request reply racing with segment rolling,KAFKA-2236,12834469,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,jhspaybar,alfred_landrum,alfred_landrum,02/Jun/15 12:39,13/Oct/17 12:00,22/Mar/23 15:10,05/May/16 05:56,0.8.2.0,,,,,,0.10.0.0,,,,,,,core,,,,0,newbie,,,,,"My use case with kafka involves an aggressive retention policy that rolls segment files frequently. My librdkafka based client sees occasional errors to offset requests, showing up in the broker log like:

[2015-06-02 02:33:38,047] INFO Rolled new log segment for 'receiver-93b40462-3850-47c1-bcda-8a3e221328ca-50' in 1 ms. (kafka.log.Log)
[2015-06-02 02:33:38,049] WARN [KafkaApi-0] Error while responding to offset request (kafka.server.KafkaApis)
java.lang.ArrayIndexOutOfBoundsException: 3
        at kafka.server.KafkaApis.fetchOffsetsBefore(KafkaApis.scala:469)
        at kafka.server.KafkaApis.fetchOffsets(KafkaApis.scala:449)
        at kafka.server.KafkaApis$$anonfun$17.apply(KafkaApis.scala:411)
        at kafka.server.KafkaApis$$anonfun$17.apply(KafkaApis.scala:402)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:109)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at kafka.server.KafkaApis.handleOffsetRequest(KafkaApis.scala:402)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:61)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
        at java.lang.Thread.run(Thread.java:745)




quoting Guozhang Wang's reply to my query on the users list:

""I check the 0.8.2 code and may probably find a bug related to your issue.
Basically, segsArray.last.size is called multiple times during handling
offset requests, while segsArray.last could get concurrent appends. Hence
it is possible that in line 461, if(segsArray.last.size > 0) returns false
while later in line 468, if(segsArray.last.size > 0) could return true.""


http://mail-archives.apache.org/mod_mbox/kafka-users/201506.mbox/%3CCAHwHRrUK-3wdoEAaFbsD0E859Ea0gXixfxgDzF8E3%3D_8r7K%2Bpw%40mail.gmail.com%3E
","Linux x86_64, java.1.7.0_72, discovered using librdkafka based client.",alfred_landrum,antonymayi,githubbot,hariprasad kuppuswamy,jhspaybar,rmetzger,wangchen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FLINK-2735,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Oct 13 04:00:08 UTC 2017,,,,,,,,,,"0|i2fhrz:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"21/Jul/15 00:05;jhspaybar;https://github.com/apache/kafka/pull/86;;;","22/Sep/15 23:28;rmetzger;I've seen this error as well in the integration tests of Flink (We are starting a Kafka Broker with the test to test our Kafka connectors):
{code}
14:43:03,328 INFO  kafka.network.Processor                                       - Closing socket connection to /127.0.0.1.
14:43:03,334 WARN  kafka.server.KafkaApis                                        - [KafkaApi-0] Error while responding to offset request
java.lang.ArrayIndexOutOfBoundsException: 1
	at kafka.server.KafkaApis.fetchOffsetsBefore(KafkaApis.scala:469)
	at kafka.server.KafkaApis.fetchOffsets(KafkaApis.scala:449)
	at kafka.server.KafkaApis$$anonfun$17.apply(KafkaApis.scala:411)
	at kafka.server.KafkaApis$$anonfun$17.apply(KafkaApis.scala:402)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:109)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.server.KafkaApis.handleOffsetRequest(KafkaApis.scala:402)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:61)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
	at java.lang.Thread.run(Thread.java:745)
{code}

on the client side, we are seeing a {{kafka.common.UnknownException}}:
{code}
Caused by: java.lang.RuntimeException: Unable to get last offset for topic customPartitioningTestTopic and partitions [FetchPartition {partition=2, offset=-915623761776}]. 
Exception for partition 2: kafka.common.UnknownException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at java.lang.Class.newInstance(Class.java:438)
	at kafka.common.ErrorMapping$.exceptionFor(ErrorMapping.scala:86)
	at kafka.common.ErrorMapping.exceptionFor(ErrorMapping.scala)
	at org.apache.flink.streaming.connectors.kafka.internals.LegacyFetcher$SimpleConsumerThread.getLastOffset(LegacyFetcher.java:521)
	at org.apache.flink.streaming.connectors.kafka.internals.LegacyFetcher$SimpleConsumerThread.run(LegacyFetcher.java:370)
{code}

Here is the log of the travis build: https://s3.amazonaws.com/archive.travis-ci.org/jobs/81584444/log.txt
this is the archive containing the full logs at INFO level: https://flink-logs-us.s3.amazonaws.com/travis-artifacts/rmetzger/flink/1123/1123.4.tar.gz (see 2.log)

It would be nice if you could address the issue with the next release.;;;","17/Feb/16 12:01;githubbot;Github user jhspaybar closed the pull request at:

    https://github.com/apache/kafka/pull/86
;;;","04/May/16 17:31;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/1318

    KAFKA-2236; Offset request reply racing with segment rolling

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka KAFKA-2236-offset-request-reply-segment-rolling-race

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1318.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1318
    
----
commit 7d6d50cd377de82215856e22fc09e137a724acfc
Author: William Thurston <wthurston@linkedin.com>
Date:   2015-07-19T02:54:05Z

    Addresses Jira Kafka-2236 to eliminate an array index out of bounds exception when segments are appended between checks

----
;;;","05/May/16 05:27;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1318
;;;","13/Oct/17 12:00;wangchen;Today,I used   kafka_2.10_0.9.0.1 find the same issue. 

[2017-10-11 23:01:11,230] ERROR [KafkaApi-1] Error while responding to offset request (kafka.server.KafkaApis)
java.lang.ArrayIndexOutOfBoundsException: 93
        at kafka.server.KafkaApis.fetchOffsetsBefore(KafkaApis.scala:532)
        at kafka.server.KafkaApis.fetchOffsets(KafkaApis.scala:512)
        at kafka.server.KafkaApis$$anonfun$18.apply(KafkaApis.scala:472)
        at kafka.server.KafkaApis$$anonfun$18.apply(KafkaApis.scala:463)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:109)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at kafka.server.KafkaApis.handleOffsetRequest(KafkaApis.scala:463)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:70)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
        at java.lang.Thread.run(Thread.java:745)
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Topic creation fails on large values,KAFKA-196,12530541,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,pyritschard,pyritschard,07/Nov/11 17:08,17/Aug/17 19:38,22/Mar/23 15:10,17/Aug/17 19:38,,,,,,,,,,,,,,core,,,,0,,,,,,"Since topic logs are stored in a directory holding the topic's name, creation of the directory might fail for large strings.
This is not a problem per-se but the exception thrown is rather cryptic and hard to figure out for operations.

I propose fixing this temporarily with a hard limit of 200 chars for topic names, it would also be possible to hash the topic name.

Another concern is that the exception raised stops the broker, effectively creating  a simple DoS vector, I'm concerned about how tests or wrong client library usage can take down the whole broker.",,omkreddy,promiseu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/11 17:09;pyritschard;0001-Set-a-hard-limit-on-topic-width-this-fixes-KAFKA-196.patch;https://issues.apache.org/jira/secure/attachment/12502738/0001-Set-a-hard-limit-on-topic-width-this-fixes-KAFKA-196.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,216279,,,Thu Aug 17 11:38:50 UTC 2017,,,,,,,,,,"0|i029zr:",11220,,,,,,,,,,,,,,,,,,,,"07/Nov/11 22:23;tgautier;There are a lot of things that do this. In particular lots of different characters can cause problems but especially filesystem ones like '/' and ' ' etc.;;;","07/Nov/11 22:36;pyritschard;Yep, the thing is, I think the message makes it hard to figure out what just happened, at lest I thought so.;;;","08/Nov/11 00:11;junrao;Thanks for the patch. Where is the limit 200 coming from? Is that the file name limit in most file systems?;;;","08/Nov/11 00:16;pyritschard;I tried coming up with a sensible and not limitative number which will
not clash with MAXPATHLEN when prefixing with the log directory. Some
old systems are rumored to have it as low as 256, but I don't see many
use cases where very large topic strings are relevant. It could safely
be bumped to 1000 (which would leave 23 chars for the prefix path).

Java has no way of accessing MAXPATHLEN unfortunately, since it is OS-specific

On Mon, Nov 7, 2011 at 5:12 PM, Jun Rao (Commented) (JIRA)
;;;","08/Nov/11 00:28;junrao;Do you think we can make it configurable and default it to 200? Also, can we create a method like verifyTopicName and put all the checkings there?;;;","08/Nov/11 00:34;pyritschard;You're taking me away from one-liner territory, but i'll take a look
at it. as for configurable, a property in server.properties is enough
?

On Mon, Nov 7, 2011 at 5:28 PM, Jun Rao (Commented) (JIRA)
;;;","08/Nov/11 00:37;junrao;Yes, a new server property should work.;;;","08/Nov/11 00:39;tgautier;Not sure if you will try to address my comment, but verifyTopicName wouldn't suffice - topic names should either be encoded to protect against special characters causing problems, or hashed as Ritschard suggests.;;;","08/Nov/11 00:49;junrao;Yes, we can use verifyTopicName to capture all constraints on topic names. We probably don't want to make it too complicated. How big is the character list that we should disallow?;;;","08/Nov/11 01:15;junrao;Not sure why the server would hang when it couldn't create a log directory. Our socket server processors capture all throwable. So this shouldn't kill any of the processors. Could you take a thread dump and see why the server hangs?;;;","08/Nov/11 07:42;jkreps;I think it would be good just to fully think through escaping and validating topic names. Currently we do essentially nothing, and we could potentially file infinite number of bugs against all the individual corner cases. If that is out of scope for what you are trying to do Pierre-Yves we can open a separate ticket, but I think we need to define the acceptable set of strings in a topic name and check that. For example, should we allow spaces? slashes? semicolons? etc. We need to do this escaping against both the unix fs and zookeeper. We are super permissive now, which leads to all kinds of corner cases. The larger solution might just be to make a KafkaTopic class that has the validation logic in the constructor and includes an escapedForFs() and escapedForZk() methods. We probably won't use this everywhere up front, but at least it begins to centralize the logic and makes it easy to reason if a name has already been escaped or not.;;;","11/Nov/11 05:26;cburroughs;'/' is particularly complicated since we want to eventually have support for  hierarchical topics, in which case '/' (or whatever we choose) will have special meaning to us, ZK, and the local filesystem.  I'd also prefer to have one way to represent topics as strings and not have separate ZK and local fs escaping schemes.

That said, unless Pierre-Yves feels like biting off a big patch lets keep this one for a configurable max topic length so that the problem users are running into now is fixed.;;;","17/Aug/17 19:38;omkreddy;Topic MAX_NAME_LENGTH is set to 249 is newer Kafka verions.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Existing directories under the Kafka data directory without any data cause process to not start,KAFKA-742,12629756,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,singhashish,chriscurtin,chriscurtin,30/Jan/13 03:27,21/May/16 05:23,22/Mar/23 15:10,17/Dec/14 12:34,0.8.0,,,,,,0.9.0.0,,,,,,,config,,,,0,,,,,,"I incorrectly setup the configuration file to have the metrics go to /var/kafka/metrics while the logs were in /var/kafka. On startup I received the following error then the daemon exited:

30   [main] INFO  kafka.log.LogManager  - [Log Manager on Broker 0] Loading log 'metrics'
32   [main] FATAL kafka.server.KafkaServerStartable  - Fatal error during KafkaServerStable startup. Prepare to shutdown
java.lang.StringIndexOutOfBoundsException: String index out of range: -1
        at java.lang.String.substring(String.java:1937)
        at kafka.log.LogManager.kafka$log$LogManager$$parseTopicPartitionName(LogManager.scala:335)
        at kafka.log.LogManager$$anonfun$loadLogs$1$$anonfun$apply$3.apply(LogManager.scala:112)
        at kafka.log.LogManager$$anonfun$loadLogs$1$$anonfun$apply$3.apply(LogManager.scala:109)
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)
        at scala.collection.mutable.ArrayOps.foreach(ArrayOps.scala:34)
        at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:109)
        at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:101)
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)
        at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:32)
        at kafka.log.LogManager.loadLogs(LogManager.scala:101)
        at kafka.log.LogManager.<init>(LogManager.scala:62)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:59)
        at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:34)
        at kafka.Kafka$.main(Kafka.scala:46)
        at kafka.Kafka.main(Kafka.scala)
34   [main] INFO  kafka.server.KafkaServer  - [Kafka Server 0], shutting down

This was on a brand new cluster so no data or metrics logs existed yet.

Moving the metrics to their own directory (not a child of the logs) allowed the daemon to start.

Took a few minutes to figure out what was wrong.",,chriscurtin,dbtucker,gwenshap,jkreps,nehanarkhede,noslowerdna,qwertymaniac,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Dec/14 02:29;singhashish;KAFKA-742.1.patch;https://issues.apache.org/jira/secure/attachment/12687528/KAFKA-742.1.patch","15/Dec/14 03:36;singhashish;KAFKA-742.patch;https://issues.apache.org/jira/secure/attachment/12687132/KAFKA-742.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,310252,,,Fri May 20 21:23:00 UTC 2016,,,,,,,,,,"0|i1hjkv:",310597,,,,,,,,,,,,,,,,,,,,"30/Jan/13 03:34;jkreps;Getting an error is not really bad since we assume we have control of everything under the log directory (it is obviously hard for us to distinguish a log directory from a non-log directory and silently ignoring could be worse than an error). So I think there are two problems here:
1. Are we enabling metrics logging by default? Are we creating the metrics dir even if metrics logging is not enabled. This needs to be sanity checked...
2. If there are bogus directories under the log directory I think the right thing to do is to give a better error message (something like ""Found directory /x/y/z, 'z' is not in the form topic-partition"").

 If you agree with those fixes I will take this on.;;;","30/Jan/13 03:43;chriscurtin;Thanks Jay, a better error is a good idea for this. ;;;","02/Dec/14 08:11;singhashish;[~jkreps], [~chriscurtin], I would like to take a stab at this. Assigning it to myself.;;;","12/Dec/14 03:44;singhashish;[~jkreps] Now that I actually started to work on this. I re-read your comment above and realized you mentioned that you intend to work on this. I missed the line when I assigned the JIRA to myself. My apologies for the same. Kindly feel free to take it on and assign it to yourself. However, if you are not planning to work on this, then let me know and then I can work on this. My apologies for the confusion.;;;","12/Dec/14 06:10;jkreps;No, I said that but then never did any work. Definitely take it!;;;","12/Dec/14 08:56;singhashish;[~jkreps] ok, I am on it then :);;;","15/Dec/14 03:33;singhashish;Created RB: https://reviews.apache.org/r/29030/

bq. Are we enabling metrics logging by default? Are we creating the metrics dir even if metrics logging is not enabled. This needs to be sanity checked...

metrics dir is created by a metrics reporter during its init, which is called by {{KafkaMetricsReporter}} only if the reported is registered.

bq. If there are bogus directories under the log directory I think the right thing to do is to give a better error message (something like ""Found directory /x/y/z, 'z' is not in the form topic-partition"")

{{parseTopicPartitionName}} only gets log directory name and not the path. I can make changes for it to receive directory path rather than just the name. However, I think just specifying that dir ""some_dir"" is not in the form topic-partition should be good enough. Let me know if you guys think otherwise. Other possible solution is I can catch the exception thrown by {{parseTopicPartitionName}} in the caller, which has the path for dir, and throw exception with full path of the dir.;;;","16/Dec/14 01:40;gwenshap;I think we need to print the full path to the directory we can't parse - I've met at least two customers who installed Kafka through a distribution and had no idea where their Kafka log directory is.

Also, I'd add something to the error message along lines of ""If a directory does not contain Kafka topic data it should not exist in Kafka's log directory. Please move it elsewhere.""

;;;","17/Dec/14 02:29;singhashish;Makes sense. Updated patch.;;;","17/Dec/14 12:34;nehanarkhede;Thanks for the patch, [~singhashish]. Pushed to trunk;;;","31/Dec/14 04:08;noslowerdna;Just a side note, we've seen this problem on Redhat Linux when the OS creates a special directory named ""lost+found"" in a mounted filesystem.;;;","21/May/16 05:23;dbtucker;And the ""lost+found"" issue still exists in Kafka 0.9 even when a non-root user is given ownership of the mount point.   There is a workaround : create a single sub-directory and point to that.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Explicit offset assignment in Log.append can corrupt the log,KAFKA-3047,12924690,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,mmakowski,mmakowski,29/Dec/15 22:28,05/Jul/16 17:26,22/Mar/23 15:10,13/Mar/16 16:32,0.9.0.0,,,,,,0.10.0.0,,,,,,,log,,,,0,,,,,,"{{Log.append()}} has {{assignOffsets}} parameter, which, when set to false, should cause Kafka to use the offsets specified in the {{ByteBufferMessageSet}} and not recalculate them based on {{nextOffsetMetadata}}. However, in that function, {{appendInfo.firstOffset}} is unconditionally set to {{nextOffsetMetadata.messageOffset}}. This can cause corruption of the log in the following scenario:

* {{nextOffsetMetadata.messageOffset}} is 2001
* {{append(messageSet, assignOffsets = false)}} is called, where {{messageSet}} contains offsets 1001...1500 
* after {{val appendInfo = analyzeAndValidateMessageSet(messages)}} call, {{appendInfo.fistOffset}} is 1001 and {{appendInfo.lastOffset}} is 1500
* after {{appendInfo.firstOffset = nextOffsetMetadata.messageOffset}} call, {{appendInfo.fistOffset}} is 2001 and {{appendInfo.lastOffset}} is 1500
* consistency check {{if(!appendInfo.offsetsMonotonic || appendInfo.firstOffset < nextOffsetMetadata.messageOffset)}} succeeds (the second condition can never fail due to unconditional assignment) and writing proceeds
* the message set is appended to current log segment starting at offset 2001, but the offsets in the set are 1001...1500
* the system shuts down abruptly
* on restart, the following unrecoverable error is reported: 

{code}
Exception in thread ""main"" kafka.common.InvalidOffsetException: Attempt to append an offset (1001) to position 12345 no larger than the last offset appended (1950) to xyz/00000000000000000000.index.
  at kafka.log.OffsetIndex$$anonfun$append$1.apply$mcV$sp(OffsetIndex.scala:207)
  at kafka.log.OffsetIndex$$anonfun$append$1.apply(OffsetIndex.scala:197)
  at kafka.log.OffsetIndex$$anonfun$append$1.apply(OffsetIndex.scala:197)
  at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
  at kafka.log.OffsetIndex.append(OffsetIndex.scala:197)
  at kafka.log.LogSegment.recover(LogSegment.scala:188)
  at kafka.log.Log$$anonfun$loadSegments$4.apply(Log.scala:188)
  at kafka.log.Log$$anonfun$loadSegments$4.apply(Log.scala:160)
  at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
  at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
  at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
  at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
  at kafka.log.Log.loadSegments(Log.scala:160)
  at kafka.log.Log.<init>(Log.scala:90)
  at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$10$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:150)
  at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
  at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
  at java.util.concurrent.FutureTask.run(FutureTask.java:166)
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
  at java.lang.Thread.run(Thread.java:722)
{code} 

*Proposed fix:* the assignment {{appendInfo.firstOffset = nextOffsetMetadata.messageOffset}} should only happen in {{if (assignOffsets)}} branch of code.",,githubbot,guozhang,ijuma,josephfrancis,mmakowski,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jul 05 09:20:25 UTC 2016,,,,,,,,,,"0|i2qdgv:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"08/Mar/16 16:12;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/1029

    KAFKA-3047: Explicit offset assignment in Log.append can corrupt the log

    This fix was suggested by Maciek Makowski, who also reported the problem.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka KAFKA-3047-log-append-can-corrupt-the-log

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1029.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1029
    
----
commit 58d098c589697259482207631f5cfe1d8271a186
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-03-08T08:10:17Z

    Only set `firstOffset` again if `assignOffsets` is true

----
;;;","08/Mar/16 16:13;ijuma;Thanks for the report and suggested fix Maciek.;;;","12/Mar/16 03:27;guozhang;Hi [~mmakowski], thanks for reporting this. I'm curious how you encountered this issue, since currently {{append(messageSet, assignOffsets = false}} is only called by the replica fetcher thread, in which {{nextOffsetMetadata.messageOffset}} and {{messageSet}}'s offset should be usually consistent. Just trying to see if it some other scenarios to lead to this issue?;;;","12/Mar/16 06:18;mmakowski;[~ijuma]: thanks for the fix!

[~guozhang]: I discovered it when I attempted to use the {{Log}} component on its own -- I wanted a library that would do reliable logging and housekeeping, but without the networking. So no, nothing in Kafka proper that I'm aware of would expose it.;;;","12/Mar/16 06:55;guozhang;Good to know, thanks for explanation!;;;","13/Mar/16 16:32;ijuma;Guozhang merged this, but JIRA was down so he could not close the issue. I downgraded the priority because this doesn't affect Kafka's usage of `Log`.;;;","15/Mar/16 19:09;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/1071

    MINOR: Add test that verifies fix for KAFKA-3047

    Also clean-up `LogTest` a little.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-3047-explicit-offset-assignment-corrupt-log-test

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1071.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1071
    
----
commit aab8f78cee26b869f14b6f3652cbac2245362076
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-03-15T11:08:21Z

    Add test that verifies fix for KAFKA-3047

----
;;;","16/Mar/16 03:15;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1071
;;;","05/Jul/16 17:20;josephfrancis;Hi [~guozhang], 
We were running kafka 0.9 in production and encountered this issue while restarting a slow broker.
{code:java}
[2016-06-24 10:04:47,546] ERROR There was an error in one of the threads during logs loading: kafka.common.InvalidOffsetException: Attempt to append an offset (36392155) to position 32437 no larger than the last offset appended (36392171) to /xyz.index. (kafka.log.LogManager)
[2016-06-24 10:04:47,550] FATAL Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.InvalidOffsetException: Attempt to append an offset (36392155) to position 32437 no larger than the last offset appended (36392171) to /xyz.index.
{code}
Just mentioning this as this happened to us in a working production cluster.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"URI scheme in ""listeners"" property should not be case-sensitive",KAFKA-3132,12933370,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,granthenke,jakerobb,jakerobb,22/Jan/16 23:45,27/Jan/16 12:03,22/Mar/23 15:10,27/Jan/16 12:03,0.9.0.0,,,,,,0.10.0.0,,,,,,,config,,,,0,newbie,,,,,"I configured my Kafka brokers as follows:

{{listeners=plaintext://kafka01:9092,ssl://kafka01:9093}}

With this config, my Kafka brokers start, print out all of the config properties, and exit quietly. No errors, nothing in the log. No indication of a problem whatsoever, let alone the nature of said problem.

Then, I changed my config as follows:
{{listeners=PLAINTEXT://kafka01:9092,SSL://kafka01:9093}}

Now they start and run just fine.

Per [RFC-3986|https://tools.ietf.org/html/rfc3986#section-6.2.2.1]:

{quote}
When a URI uses components of the generic syntax, the component
syntax equivalence rules always apply; namely, that the scheme and
host are case-insensitive and therefore should be normalized to
lowercase.  For example, the URI <HTTP://www.EXAMPLE.com/> is
equivalent to <http://www.example.com/>.
{quote}",,githubbot,gwenshap,jakerobb,vahid,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jan 27 04:03:33 UTC 2016,,,,,,,,,,"0|i2rulb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"23/Jan/16 05:40;vahid;When I use the lowercase ""plaintext"" and start the broker I get this error after the parameter printout:

java.lang.IllegalArgumentException: Error creating broker listeners from 'plaintext://:9092': No enum constant org.apache.kafka.common.protocol.SecurityProtocol.plaintext
	at kafka.server.KafkaConfig.validateUniquePortAndProtocol(KafkaConfig.scala:894)
	at kafka.server.KafkaConfig.getListeners(KafkaConfig.scala:913)
	at kafka.server.KafkaConfig.<init>(KafkaConfig.scala:866)
	at kafka.server.KafkaConfig$.fromProps(KafkaConfig.scala:698)
	at kafka.server.KafkaConfig$.fromProps(KafkaConfig.scala:695)
	at kafka.server.KafkaServerStartable$.fromProps(KafkaServerStartable.scala:28)
	at kafka.Kafka$.main(Kafka.scala:58)
	at kafka.Kafka.main(Kafka.scala);;;","26/Jan/16 13:39;githubbot;GitHub user granthenke opened a pull request:

    https://github.com/apache/kafka/pull/811

    KAFKA-3132: URI scheme in ""listeners"" property should not be case-sen…

    …sitive

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka listeners-case

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/811.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #811
    
----
commit 894996bcd202d15845a864e22c6b687f73339735
Author: Grant Henke <granthenke@gmail.com>
Date:   2016-01-26T05:38:32Z

    KAFKA-3132: URI scheme in ""listeners"" property should not be case-sensitive

----
;;;","27/Jan/16 01:20;githubbot;Github user granthenke closed the pull request at:

    https://github.com/apache/kafka/pull/811
;;;","27/Jan/16 01:20;githubbot;GitHub user granthenke reopened a pull request:

    https://github.com/apache/kafka/pull/811

    KAFKA-3132: URI scheme in ""listeners"" property should not be case-sen…

    …sitive

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka listeners-case

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/811.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #811
    
----
commit 45fa9e3d14afdb982fecb9cff644572a6757942b
Author: Grant Henke <granthenke@gmail.com>
Date:   2016-01-26T05:38:32Z

    KAFKA-3132: URI scheme in ""listeners"" property should not be case-sensitive

----
;;;","27/Jan/16 08:47;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/811
;;;","27/Jan/16 12:03;gwenshap;Issue resolved by pull request 811
[https://github.com/apache/kafka/pull/811];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The existing perf tools are buggy,KAFKA-172,12528929,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,nehanarkhede,nehanarkhede,nehanarkhede,27/Oct/11 01:53,14/Jun/13 12:02,22/Mar/23 15:10,14/Jun/13 12:02,,,,,,,0.8.1,,,,,,,,,,,0,,,,,,"The existing perf tools - ProducerPerformance.scala, ConsumerPerformance.scala and SimpleConsumerPerformance.scala are buggy. It will be good to -

1. move them to a perf directory, along with helper scripts
2. fix the bugs, so that they measure throughput correctly",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,214789,,,Wed Oct 26 18:16:04 UTC 2011,,,,,,,,,,"0|i09mcn:",54054,,,,,,,,,,,,,,,,,,,,"27/Oct/11 02:16;junrao;What bugs are you seeing?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka server returns UnknownServerException for inherited exceptions,KAFKA-3189,12935823,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,becket_qin,becket_qin,02/Feb/16 10:24,10/Feb/16 02:17,22/Mar/23 15:10,10/Feb/16 02:17,,,,,,,0.10.0.0,,,,,,,core,,,,1,,,,,,"This issue was introduced in KAFKA-2929. The problem is that we are using o.a.k.common.protocol.Errors.forException() while some exceptions thrown by the broker are still using old scala exception. This cause Errors.forException() always return UnknownServerException.

InvalidMessageException is inherited from CorruptRecordException. But it seems Errors.forException() needs the exception class to be the exact class, so it does not map the subclass InvalidMessageException to the correct error code. Instead it returns -1 which is UnknownServerException.",,becket_qin,ewencp,githubbot,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Feb 09 18:17:31 UTC 2016,,,,,,,,,,"0|i2s9p3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"02/Feb/16 10:29;becket_qin;[~junrao] Would like to see if you have any concern on moving all the exceptions to client exception class? It looks a simple replacement.;;;","02/Feb/16 15:18;ijuma;Changed the fix version to 0.9.1.0 as it doesn't affect the 0.9.0 branch. The aim of KAFKA-2929 was to switch the broker to the Java exceptions indeed (at least for code that wasn't shared with the old clients). Sounds like cases were missed. cc [~granthenke];;;","02/Feb/16 22:08;granthenke;[~becket_qin] Could you be more specific how/when you are seeing the issue? Most of the server side exceptions were migrated to the new clients exception classes and the ones that weren't inherit from them so they can still be caught. There could be a place that was missed. I will look through the code to try and find any gaps.;;;","03/Feb/16 02:29;becket_qin;[~granthenke] The exception I saw was InvalidMessageException. I saw it is inherited from CorruptRecordException. But it seems Errors.forException() needs the exception class to be the exact class, so it does not map the subclass InvalidMessageException to the correct error code. Instead it returns -1 which is UnknownServerException.;;;","03/Feb/16 11:04;granthenke;[~becket_qin] [~ijuma] I updated the jira description to match the exact scenario. I will open a PR shortly.;;;","03/Feb/16 11:15;githubbot;GitHub user granthenke opened a pull request:

    https://github.com/apache/kafka/pull/856

    KAFKA-3189: Kafka server returns UnknownServerException for inherited…

    … exceptions

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka inherited-errors

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/856.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #856
    
----
commit 4de1cce990d3df283f9688d4b91d7a6582b55853
Author: Grant Henke <granthenke@gmail.com>
Date:   2016-02-03T03:10:30Z

    KAFKA-3189: Kafka server returns UnknownServerException for inherited exceptions

----
;;;","10/Feb/16 02:17;ewencp;Issue resolved by pull request 856
[https://github.com/apache/kafka/pull/856];;;","10/Feb/16 02:17;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/856
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to rename replication offset checkpoint in windows,KAFKA-1036,12666189,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,,tnachen,tnachen,30/Aug/13 05:02,15/Dec/18 00:35,22/Mar/23 15:10,16/Oct/13 06:59,0.8.1,,,,,,0.8.1,,,,,,,,,,,0,windows,,,,,"Although there was a fix for checkpoint file renaming in windows that tries to delete the existing checkpoint file if renamed failed, I'm still seeing renaming errors on windows even though the destination file doesn't exist.

A bit investigation shows that it wasn't able to rename the file since the kafka jvm still holds a fie lock on the tmp file and wasn't able to rename it. 

Attaching a patch that calls a explict writer.close so it can release the lock and can able to rename it.",windows,davidlao,jantxu,jkreps,junrao,nehanarkhede,tnachen,trjianjianjiao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-7575,,,,,,,,,,,,,,,,,,"08/Nov/13 19:20;jantxu;filelock.patch.diff;https://issues.apache.org/jira/secure/attachment/12612813/filelock.patch.diff",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,346128,,,Thu Dec 05 17:46:37 UTC 2013,,,,,,,,,,"0|i1norb:",346429,,,,,,,,,,,,,,,,,,,,"05/Sep/13 22:55;junrao;Hi, Tim,

Do you still want to provide a patch? I saw a patch attached and then deleted.

Thanks,;;;","10/Sep/13 01:18;tnachen;Hi Jun, I just realized I don't have clearance to provide a patch yet. It will be much easier if you can help fix this since it's just a one line fix.;;;","13/Sep/13 23:29;junrao;Hmm, not sure how to patch this since we close the writer before renaming the file.;;;","21/Sep/13 06:28;jkreps;I'm a little confused. I don't see any file locking happening in our code. The lock I see is just an in-memory lock and should prevent the file from being deleted.

So perhaps the problem you are describing is that we don't close the file until after the file move? This is legit in unix but perhaps not in windows.;;;","08/Oct/13 07:51;junrao;This seems to be only affecting trunk. So, moving to 0.8.1.;;;","16/Oct/13 06:59;jkreps;Checked in fix on trunk. Note that I don't have access to a windows box so I can't actually validate the fix if anyone who does have access gave this a spin that would be great.;;;","25/Oct/13 18:51;jantxu;Hi Jay, 

I just stumbled upon this issue, since I am on Windows. I just checked out the trunk since I had this problem with the current beta due to this issue. But I still face the same issue:
[2013-10-25 12:43:43,422] FATAL [Replica Manager on Broker 0]: Error writing to
highwatermark file:  (kafka.server.ReplicaManager)
java.io.IOException: File rename from D:\Databases\Kafka\kafka-logs\replication-
offset-checkpoint.tmp to D:\Databases\Kafka\kafka-logs\replication-offset-checkpoint failed.

I also tried to use nio move functionality to see if that solved the problem, but fails for the same reason

Thanks a lot and regards

Jan
;;;","08/Nov/13 03:23;davidlao;Hi Jay, Can you provide a patch for 0.8 as well?  I'm running into similar issue on Windows.;;;","08/Nov/13 03:39;tnachen;Hi Jay,

The code isn't doing any locking, but looks like in Windows if you don't close the writer there is still a pending file lock on the file itself in Windows looking via the file monitor.

That's why I needed to add a extra writer.close after the rename fails.

Tim;;;","08/Nov/13 19:19;jantxu;Hi all,

I think the problem is that the second check for renameTo == true fails although the rename was executed properly. When I remove the second check, it works without problems and the file gets renamed properly (see the attached patch). I guess the root cause of this problem is the platform dependency of the old File API:
Many aspects of the behavior of this method are inherently platform-dependent: The rename operation might not be able to move a file from one filesystem to another, it might not be atomic, and it might not succeed if a file with the destination abstract pathname already exists

Maybe it would be a solution to use NIO instead?

Best regards

Jan;;;","08/Nov/13 19:20;jantxu;The second check for renaming fails on windows, although the renaming worked. ;;;","03/Dec/13 01:16;nehanarkhede;[~jantxu] Are you sure this is required? If we always delete the destination file and then execute renameTo, it should work in all cases, no? [~sriramsub] What do you think?;;;","06/Dec/13 01:46;junrao;We are relying on file renaming being an atomic operation. So, if supported, we should still do rename, instead of deletion followed by creation. The issue with the latter is that if the broker crashes btw the two operations, the broker is left with no checkpoint file.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor some new components introduced for replication ,KAFKA-351,12558227,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,nehanarkhede,nehanarkhede,26/May/12 10:26,30/Oct/17 20:18,22/Mar/23 15:10,22/Aug/12 01:25,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,optimization,,,,,Jay had some good refactoring suggestions as part of the review for KAFKA-46. I'd like to file this umbrella JIRA with individual sub tasks to cover those suggestions,,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,259200,259200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Aug/12 01:07;junrao;kafka-351_v1.patch;https://issues.apache.org/jira/secure/attachment/12540699/kafka-351_v1.patch","16/Aug/12 01:26;junrao;kafka-351_v2.patch;https://issues.apache.org/jira/secure/attachment/12541091/kafka-351_v2.patch","17/Aug/12 14:07;junrao;kafka-351_v3.patch;https://issues.apache.org/jira/secure/attachment/12541330/kafka-351_v3.patch","18/Aug/12 09:29;junrao;kafka-351_v4.patch;https://issues.apache.org/jira/secure/attachment/12541457/kafka-351_v4.patch","18/Aug/12 09:38;junrao;kafka-351_v5.patch;https://issues.apache.org/jira/secure/attachment/12541459/kafka-351_v5.patch","21/Aug/12 13:01;junrao;kafka-351_v6.patch;https://issues.apache.org/jira/secure/attachment/12541713/kafka-351_v6.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,299091,,,Tue Aug 21 17:25:50 UTC 2012,,,,,,,,,,"0|i15zjj:",243058,,,,,,,,,,,,,,,,,,,,"26/Jul/12 04:07;nehanarkhede;From KAFKA-405 -

ReplicaManager:

This class has a very odd public interface. Instead of managing replicas it has a bunch of passive calls--addLocalReplica(), addRemoteReplica(), etc. Who calls these? KafkaServer seems to have its own wrapper for these. Then it passes these methods on as arguments to KafkaZookeeper. Does this make sense? I think it would be good if ReplicaManager handled replica management, even if that means it depends on zookeeper.
;;;","14/Aug/12 01:07;junrao;Attach patch v1. An overview of the patch.
A. Use synchronized instead of lock for synchronization. The latter has more functionality, but more overhead. See
http://blog.rapleaf.com/dev/2011/06/16/java-performance-synchronized-vs-lock/

B. Partition: Consolidated all reads/writes to leader/ISR in Partition and all accessed are synchronized. This makes sure that leader/ISR values don't change while doing the following operations.
- makeLeader
- makerFollower
- maybeShrinkISR
- updateLeaderHWAndMaybeExpandISR (for maintaining remote replicas)
- checkEnoughReplicasReachAnOffset (for checking if a produce request is satisfied)
This means that Partition has to access ReplicaManager. In some sense, Partition probably should be a nested class under ReplicaManager since it needs to access several members of ReplicaManager. However, this will make ReplicaManager too big.

C. RepicaManager:
- Moved most per partition operations to Partition.
- Cleaned up public methods and added a few helper methods for getting partition and replica.
- Use ConcurrentHashMap for managing all partitions.

D. KafkaApis: Removed callbacks in the constructer. Instead, call methods in ReplicaManager directly.

E. Replica:
- Changed to the new getter/setter style for logEndOffset and highWatermark.
- Local replica doesn't need to set logEndOffset anymore since the logEndOffsetUpdateTime for local replica is never used.

F. BrokerPartitionInfo: Partition is now a complex structure and is supposed to be used only on the server side. Create a simpler PartitionAndLeader class for client usage.

G. KafkaZookeeper: Removed ensurePartitionLeaderOnThisBroker(). The checking of the existence of a leader is now done by replicaManager.leaderReplicaIfLocalOrException(), which is cheaper since it doesn't access ZK.

H. ISRExpirationTest: Remove the test testISRExpirationForMultiplePartitions. It doesn't seem to add additional value since ISR expiration is always done on a per partition basis.

I. SyncProducerTest: Remove the test testProducRequestForUnknowTopic since the logic is always covered by #1 in testProduceCorrectlyReceivesResponse.

J. TestUtils: Added a helper method leaderLocalOnBroker() that more reliably ensures that a leader exists on a broker.

K. TopicCounTest: removed since it's not doing any useful test.

L. ZookeeperConsumerConnectorTest.testCompressionSetConsumption(): removed the part that tests consumer timeout since it's covered in testBasic already.
;;;","14/Aug/12 01:13;junrao;I still see some transient failures in unit tests, most of which seem to be due to leader not ready. I will probably wait until kafka-369 is committed since it fixes some of those issues.;;;","14/Aug/12 02:24;junrao;Another change in the patch:
M. Currently, on leaderAndISR request, the broker gets and creates all assigned replicas. In this patch, the broker only creates replicas in ISR (since they are required in the logic for shrinking ISR). Other remote replicas are created on demand during the handling for follower fetch requests. This will make implementing kafka-42 a bit easier since newly bootstrapped replicas can be added on demand.;;;","15/Aug/12 01:40;nehanarkhede;Jun, The patch didn't apply cleanly on a fresh checkout of the 0.8 branch. Do you mind uploading another patch after rebasing ?;;;","16/Aug/12 01:26;junrao;Attach patch v2 after rebase. Made one more change:
N. Make logEndOffset and highWaterMark in replica atomic long. This is because java doesn't guarantee consistency of long value if not synchronized. ;;;","17/Aug/12 14:07;junrao;Attach patch v3. Just a rebase.;;;","18/Aug/12 04:20;nehanarkhede;Thanks for the patch! Overall, this refactoring is a good change. Here are a few review comments -

1. TestUtils. How about renaming leaderLocalOnBroker to isLeaderLocalOnBroker ?

2. LogOffsetTest:
2.1. The change in testGetOffsetsForUnknownTopic doesn't look right. Since the topic ""foo"" doesn't exist, the client should get back UnknownTopicException. The partition is not invalid, it doesn't even exist.

3. SyncProducerTest
3.1 Same here, client should get back UnknownTopicException, not InvalidPartitionException

4. ISRExpirationTest
4.1 getLogWithLogEndOffset expected 6 calls for log.logEndOffset since the test exercised that API 6 times during correct operation. If you change it to anyTimes, it will hide problems with either the test or the code. Was it changed to
get rid of some transient test failure ?
4.2 Minor formatting: For consistency, you might want to change to first letter caps for error messages. So far, I don't think everyone quite followed this. So some log statements have first letter caps, others don't. I personally prefer
 first letter caps for all log statements.

5. Replica
5.1 Is there a reason why logEndOffsetUpdateTimeMs is not AtomicLong ? It's access is not protected by a lock.
5.2 What is the difference between private[this] var and private var ?
5.3 It's great that you changed logEndOffset to use the new getter/setter API convention. I think there is only one drawback to using that. I don't know a way to search the code to list all places that use the setter. Do you ?

6. Partition
6.1 Rename addReplicaIfNotExist to addReplicaIfNotExists.
6.2 In getOrCreateLog, it is better to use case match, since in Scala case match always evaluates to some value. Since this API needs to return the Replica object, using case match will protect against code bugs. Instead of if-else that checks isDefined, case-match handles Options naturally, since it forces you to handle all the cases. Same for makeLeader, makeFollower, checkEnoughReplicasReachAnOffset since they also return some value.
6.3 Looks like assignedReplicaMap is meant to be a map of replica_id->Replica. It might be a good idea to change Pool to handle Options. Options are much easier to use than handling null values. For example, getReplica can reduce to just returning assignedReplicaMap.get(replicaId), instead of the if-else checking for nulls.
6.5 Minor formatting comment same as 4.2
6.6. maybeIncrementLeaderHW: Since you are trying to access inSyncReplicas here, this method should be synchronized on the leaderAndIsrUpdateLock
6.7 getOutOfSyncReplicas, updateISR: Same as 6.6
6.8 checkEnoughReplicasReachAnOffset: 
6.8.1 We should probably rename this to checkEnoughReplicasReachOffset. 

7. ReplicaManager
7.1 I think leaderReplicas was a poorly chosen name by me in the past. It should be renamed to leaderPartitions since it is the set of partitions with their leader hosted on the local broker. Also, that would mean we should rename leaderReplicasLock to leaderPartitionsLock
7.2 Same as 6.3 for allPartitions. This will greatly simplify getOrCreatePartition
7.3 Same as 4.2 for some of the APIs
7.4 Fix typo: shuttedd down 
7.5 Fix identation and parenthesis style for checkpointHighWatermarks. 
7.6 Same as 6.2 for becomeLeaderOrFollower 
7.7 I wonder if it is better to rename leaderReplicaIfLocalOrException to getLeaderReplicaIfLocal ?
;;;","18/Aug/12 09:29;junrao;Thanks for the review. 

2,3. The difficulty is that a broker currently doesn't cache all topic/partitions (only controller does that). It only knows about topic/partitions assigned to itself. So, it's hard for a broker distinguish between a missing topic and a missing partition. We could cache all topic/partitions in all brokers, but we need to add additional ZK logic in each broker. So, in this patch, just combined UnknownTopicException and InvailidPartitionException into a more general UnknowTopicPartitionException. It's not ideal, but probably not too painful for the user to understand.

5.1 That's a good point. Moved the update (which updates logEndOffsetUpdateTimeMs) of logEndOffset into Partition.updateLeaderHWAndMaybeExpandISR(). This way, both the reader and the writer of logEndOffsetUpdateTimeMs is synchronized by leaderISRUpdateLock. So, there is no need to make it an AtomicLong.

6.3 Just not to make this patch too large. I will create a separate jira for changing the Pool api to use Option.

6.6 and 6.7 Both methods are only called in Partition and the caller already synchronizes on leaderISRUpdateLock.

The rest of the comments have been addressed.;;;","18/Aug/12 09:38;junrao;Upload patch v5 to fix an svn rename issue.;;;","21/Aug/12 00:40;nehanarkhede;Thanks for incorporating review suggestions!

2.3 Agreed that it is a bit of work to get meaningful error codes in the client. Often this is ignored, but client contract should be very well thought out and easy to understand. It is best if we give the most descriptive error code, but if we feel it takes significant amount of work, we can start with a simple solution. We went through a pretty detailed review of the new request formats, but not error codes. It will be good to go through this before the release.

5.1 That change is correct. However, in Replica.scala, highWatermarkValue and logEndOffsetValue are synchronized via AtomicLong, but not logEndOffsetUpdateTime. Right now, like you said, there is only one API that updates/reads logEndOffsetUpdateTime and it synchronizes those accesses. But since these are Replica APIs, I'm pretty sure there will be more places in the code that will either update or read the logEndOffset/logEndOffsetUpdateTime and each of those APIs would have to synchronize those accesses. For what it's worth, changing it to AtomicLong actually protects us from future synchronization errors and is not much of a performance hit as well. 

8. HighwatermarkPersistenceTest. Fix fail error message to say KafkaException instead of IllegalStateException. I forgot to do this in my patch when I added this test, it will be great if you can include this minor change.

9. Minor comment - Probably better to rename UnknownTopicPartition to UnknownTopicOrPartitionException.
;;;","21/Aug/12 13:01;junrao;Thanks for the review. Attach patch v6.

5.1 Changed logEndOffsetUpdateTime to AtomicLong.

8,9: Fixed.

Optimized Replica.getOutOfSyncReplicas() a bit to avoid the unnecessary check for leader replica.

Rebased.;;;","22/Aug/12 00:56;nehanarkhede;+1 

Minor comments before checking it in - 

1. Fix comment in UnknownTopicOrPartitionException.scala. Right now it describes InvalidPartitionException
2. Replica - Fix error message ""shouldn't set logEndOffset for replica %d topic %s partition %d since it's local"" to first letter capital
;;;","22/Aug/12 01:25;junrao;Thanks for the review. Addressed the issues in the last review and committed to 0.8.

Create kafka-476 to track using Option in Pool.

For priviate[this] var, it restricts the usage of a member field to only this instance of the class. This way, one is always forced to use the public api to access the member field in other instances of the class. 

Yes, Intellij seems to have an issue finding references of x_=(), which is inconvenient. Not sure if it has been addressed in a new version.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka-run-class.sh is broken,KAFKA-1081,12673281,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,fsaintjacques,fsaintjacques,11/Oct/13 02:11,16/Oct/13 05:08,22/Mar/23 15:10,16/Oct/13 05:08,0.8.0,,,,,,,,,,,,,,,,,0,,,,,,"Please apply this patch, this is why log4j exists. Rerunning at non-deterministic command twice to catch error message is extremely dangerous.

diff --git a/bin/kafka-run-class.sh b/bin/kafka-run-class.sh
index eb6ff1b..2f2d8b5 100755
--- a/bin/kafka-run-class.sh
+++ b/bin/kafka-run-class.sh
@@ -102,19 +102,3 @@ if [ ""$1"" = ""daemon"" ] && [ -z ""$KAFKA_GC_LOG_OPTS""] ; then
 fi

 $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS ""$@""
-
-exitval=$?
-
-if [ $exitval -eq ""1"" ] ; then
-       $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS ""$@"" >& exception.txt
-       exception=`cat exception.txt`
-       noBuildMessage='Please build the project using sbt. Documentation is available at http://kafka.apache.org/'
-       pattern=""(Could not find or load main class)|(java\.lang\.NoClassDefFoundError)""
-       match=`echo $exception | grep -E ""$pattern""`
-       if [[ -n ""$match"" ]]; then
-               echo $noBuildMessage
-       fi
-       rm exception.txt
-fi
-
-",,charmalloc,fanatoly,fsaintjacques,jkreps,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/13 06:29;jkreps;KAFKA-1081-v1.patch;https://issues.apache.org/jira/secure/attachment/12608092/KAFKA-1081-v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,352904,,,Tue Oct 15 21:08:23 UTC 2013,,,,,,,,,,"0|i1oudr:",353191,,,,,,,,,,,,,,,,,,,,"11/Oct/13 02:28;charmalloc;please can you put together reproducible steps for the issue, thanks!;;;","11/Oct/13 02:35;fsaintjacques;Look for the 3 last lines, not the usage error.

$ cd /
$ /opt/kafka/bin/kafka-list-topic.sh
Missing required argument ""[zookeeper]""
Option                                  Description
------                                  -----------
--topic <topic>                         REQUIRED: The topic to be listed.
                                          Defaults to all existing topics.
                                          (default: )
--unavailable-partitions                if set, only show partitions whose
                                          leader is not available
--under-replicated-partitions           if set, only show under replicated
                                          partitions
--zookeeper <urls>                      REQUIRED: The connection string for
                                          the zookeeper connection in the form
                                          host:port. Multiple URLS can be
                                          given to allow fail-over.
/opt/kafka/bin/kafka-run-class.sh: line 72: exception.txt: Permission denied
cat: exception.txt: No such file or directory
rm: cannot remove 'exception.txt': No such file or directory;;;","11/Oct/13 02:47;charmalloc;I don't see removing that function as a solution, we could re work it so that it communicates the error that you need to build the project.

i don't have permission issue writing exception.txt but could see another way of fixing the function to not use a file and keep it all in vars if you wanted to rework your patch or chmod a+rw in your folder maybe not sure how you are running things but you should build first (see README)

Joes-MacBook-Air:kafka joestein$ bin/kafka-list-topic.sh 
Missing required argument ""[zookeeper]""
Option                                  Description                            
------                                  -----------                            
--topic <topic>                         REQUIRED: The topic to be listed.      
                                          Defaults to all existing topics.     
                                          (default: )                          
--unavailable-partitions                if set, only show partitions whose     
                                          leader is not available              
--under-replicated-partitions           if set, only show under replicated     
                                          partitions                           
--zookeeper <urls>                      REQUIRED: The connection string for    
                                          the zookeeper connection in the form 
                                          host:port. Multiple URLS can be      
                                          given to allow fail-over.            
Joes-MacBook-Air:kafka joestein$ 
;;;","11/Oct/13 03:14;fsaintjacques;Look, this is an ugly hack. The real problem here is not the directory permission or using a temp file but RERUNNING the first java command. 

I'm not even trying to build it, I'm trying to correctly package kafka on a production server. Whenever I run any command (bin/*) that doesn't return properly, it borks if kafka-run-class.sh is called within a directory where the user don't have write permission.

I understand that these lines are there to help new users who checkout the project and forget to build before running any command, but we're talking of deploying quality code in production.;;;","11/Oct/13 03:28;charmalloc;We have binary release http://kafka.apache.org/downloads.html since 0.8.0-beta1 and moving forward, you could use that since it is already packaged.  I would go so far as to even bootstrap the sbt launcher but that is a lot more changes than just a consistent error when not compiling source before run.;;;","11/Oct/13 03:32;fsaintjacques;I know you guys have a binary release, this is what I'm deploying. My point is, this specific snippet should never go in production release.;;;","12/Oct/13 02:48;jkreps;Yeah I agree, rerunning the command to get the error is really weird. Given that we have a binary release do we need to retain this behavior? I.e. if you download the source release and try to run without building then it won't work but this shouldn't be as confusing as it was when we only had a source release and didn't really label the download as such.;;;","12/Oct/13 04:17;fanatoly;There is another reason why removing this behavior would be beneficial.

Currently, the run-class script spawns a subprocess. This makes running it under supervisor more difficult than it needs to be. This likely applies to other process monitoring systems. I maintain an internal patch on top of kafka that prepends the java invocation in run-class with exec and removes the error reporting. In production, the error is not very useful.;;;","12/Oct/13 06:29;jkreps;Here is a proposed patch that uses exec for all the main commands and removes the re-execution for errors.;;;","12/Oct/13 11:50;charmalloc;+1 on KAFKA-1081-v1.patch;;;","14/Oct/13 05:27;junrao;Thanks for the patch. +1. Could you patch for trunk as well?;;;","16/Oct/13 05:08;jkreps;Checked in on both 0.8 and trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Can not delete Topic index on Windows,KAFKA-1757,12753416,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,sriharsha,Lucky-V,Lucky-V,06/Nov/14 23:15,24/Feb/15 12:43,22/Mar/23 15:10,24/Feb/15 12:43,0.8.2.0,,,,,,0.9.0.0,,,,,,,log,,,,0,,,,,,"When running the Kafka 0.8.2-Beta (Scala 2.10) on Windows, an attempt to delete the Topic throwed an error:

ERROR [KafkaApi-1] error when handling request Name: StopReplicaRequest; Version: 0; CorrelationId: 38; ClientId: ; DeletePartitions: true; ControllerId: 0; ControllerEpoch: 3; Partitions: [test,0] (kafka.server.KafkaApis)
kafka.common.KafkaStorageException: Delete of index 00000000000000000000.index failed.
        at kafka.log.LogSegment.delete(LogSegment.scala:283)
        at kafka.log.Log$$anonfun$delete$1.apply(Log.scala:608)
        at kafka.log.Log$$anonfun$delete$1.apply(Log.scala:608)
        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
        at kafka.log.Log.delete(Log.scala:608)
        at kafka.log.LogManager.deleteLog(LogManager.scala:375)
        at kafka.cluster.Partition$$anonfun$delete$1.apply$mcV$sp(Partition.scala:144)
        at kafka.cluster.Partition$$anonfun$delete$1.apply(Partition.scala:139)
        at kafka.cluster.Partition$$anonfun$delete$1.apply(Partition.scala:139)
        at kafka.utils.Utils$.inLock(Utils.scala:535)
        at kafka.utils.Utils$.inWriteLock(Utils.scala:543)
        at kafka.cluster.Partition.delete(Partition.scala:139)
        at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:158)
        at kafka.server.ReplicaManager$$anonfun$stopReplicas$3.apply(ReplicaManager.scala:191)
        at kafka.server.ReplicaManager$$anonfun$stopReplicas$3.apply(ReplicaManager.scala:190)
        at scala.collection.immutable.Set$Set1.foreach(Set.scala:74)
        at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:190)
        at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:96)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
        at java.lang.Thread.run(Thread.java:744)



When I have investigated the issue I figured out that the index file (in my environment it was C:\tmp\kafka-logs\00000000-0000-0000-0000-000000000014-0\00000000000000000000.index) was locked by the kafka process and the OS did not allow to delete that file.

I tried to fix the problem in source codes and when I added close() method call into LogSegment.delete(), the Topic deletion started to work.

I will add here (not sure how to upload the file during issue creation) a diff with the changes I have made so You can take a look on that whether it is reasonable or not. It would be perfect if it could make it into the product...

In the end I would like to say that on Linux the deletion works just fine...",,junrao,Lucky-V,nehanarkhede,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/15 04:16;sriharsha;KAFKA-1757.patch;https://issues.apache.org/jira/secure/attachment/12691515/KAFKA-1757.patch","06/Nov/14 23:17;Lucky-V;lucky-v.patch;https://issues.apache.org/jira/secure/attachment/12679855/lucky-v.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Feb 24 04:43:08 UTC 2015,,,,,,,,,,"0|i2227b:",9223372036854775807,,jkreps,,,,,,,,,,,,,,,,,,"06/Nov/14 23:17;Lucky-V;A patch that looks like a fix for the issue.;;;","15/Nov/14 10:22;junrao;Thanks for the patch. It's not clear to me if this really fixes the problem. OffsetIndex.close() doesn't really close any channels or handlers. It simply remaps the memory mapped file.;;;","30/Dec/14 06:23;nehanarkhede;I'm leaning towards pushing this out of 0.8.2. Let me know if anyone has concerns with this.;;;","11/Jan/15 04:16;sriharsha;Created reviewboard https://reviews.apache.org/r/29794/diff/
 against branch origin/trunk;;;","11/Jan/15 04:18;sriharsha;[~junrao] On windows MappedByteBuffer needs to be unmapped before deleting the file. The above patch tested on windows 8. ;;;","12/Feb/15 00:21;sriharsha;[~junrao] Can you please review the patch. Thanks.;;;","24/Feb/15 12:43;sriharsha;patch merged by [~jkreps] closing this as fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Release artifact expects a git repository for the release audit tool (RAT),KAFKA-2797,12911888,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,ewencp,fpj,fpj,11/Nov/15 00:08,11/Nov/15 02:17,22/Mar/23 15:10,11/Nov/15 02:17,0.9.0.0,,,,,,0.9.0.0,,,,,,,build,,,,0,,,,,,"When running gradle on the RC0 for 0.9, we get an error because the build expects to find a git repo here:

{noformat}
	line 68 of build.gradle: def repo = Grgit.open(project.file('.'))
{noformat}

and we get this error message:

{noformat}
	FAILURE: Build failed with an exception.

	* Where:
	Build file 'kafka-0.9.0.0-src/build.gradle' line: 68

	* What went wrong:
	A problem occurred evaluating root project 'kafka-0.9.0.0-src'.
	> repository not found: kafka-0.9.0.0-src

{noformat}

The definitions for rat make sense when working on a git branch, but not for the release artifact. One way around this is to disable rat by commenting out the corresponding lines, but that isn't what the README file says.",,fpj,githubbot,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Nov 10 18:17:49 UTC 2015,,,,,,,,,,"0|i2o773:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"11/Nov/15 01:49;githubbot;GitHub user ewencp opened a pull request:

    https://github.com/apache/kafka/pull/485

    KAFKA-2797: Only run rat when in the .git repository since it require s the .gitignore to generate the list of files to ignore

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ewencp/kafka kafka-2797-disable-rat-when-git-missing

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/485.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #485
    
----
commit 79c6cac66644b458eff8141e13dacd0b859f5c3c
Author: Ewen Cheslack-Postava <me@ewencp.org>
Date:   2015-11-10T17:33:45Z

    KAFKA-2797: Only run rat when in the .git repository since it requires the .gitignore to generate the list of files to ignore

----
;;;","11/Nov/15 02:17;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/485
;;;","11/Nov/15 02:17;gwenshap;Issue resolved by pull request 485
[https://github.com/apache/kafka/pull/485];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OffsetCommitRequest API - timestamp field is not versioned,KAFKA-1841,12764968,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,junrao,dana.powers,dana.powers,06/Jan/15 04:17,19/Mar/15 00:16,22/Mar/23 15:10,13/Jan/15 14:34,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Timestamp field was added to the OffsetCommitRequest wire protocol api for 0.8.2 by KAFKA-1012 .  The 0.8.1.1 server does not support the timestamp field, so I think the api version of OffsetCommitRequest should be incremented and checked by the 0.8.2 kafka server before attempting to read a timestamp from the network buffer in OffsetCommitRequest.readFrom (core/src/main/scala/kafka/api/OffsetCommitRequest.scala)

It looks like a subsequent patch (KAFKA-1462) added another api change to support a new constructor w/ params generationId and consumerId, calling that version 1, and a pending patch (KAFKA-1634) adds retentionMs as another field, while possibly removing timestamp altogether, calling this version 2.  So the fix here is not straightforward enough for me to submit a patch.

This could possibly be merged into KAFKA-1634, but opening as a separate Issue because I believe the lack of versioning in the current trunk should block 0.8.2 release.",wire-protocol,dana.powers,joestein,junrao,parth.brahmbhatt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1634,,,,,,,,,,,,,,,,,,,,"08/Jan/15 09:54;junrao;kafka-1841.patch;https://issues.apache.org/jira/secure/attachment/12690694/kafka-1841.patch","09/Jan/15 07:08;junrao;kafka-1841_2015-01-08_15:07:57.patch;https://issues.apache.org/jira/secure/attachment/12690966/kafka-1841_2015-01-08_15%3A07%3A57.patch","10/Jan/15 06:37;junrao;kafka-1841_2015-01-09_14:36:50.patch;https://issues.apache.org/jira/secure/attachment/12691414/kafka-1841_2015-01-09_14%3A36%3A50.patch","13/Jan/15 06:30;junrao;kafka-1841_2015-01-12_14:30:24.patch;https://issues.apache.org/jira/secure/attachment/12691768/kafka-1841_2015-01-12_14%3A30%3A24.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jan 13 06:34:21 UTC 2015,,,,,,,,,,"0|i23yqf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"06/Jan/15 15:39;joestein;In addition to the issue you bring up, the functionality as a whole has changed.. when you call OffsetFetchRequest the version = 0 needs to preserve the old functionality https://github.com/apache/kafka/blob/0.8.1/core/src/main/scala/kafka/server/KafkaApis.scala#L678-L700 and version = 1 the new https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/server/KafkaApis.scala#L153-L223. Also the OffsetFetchRequest functionality even though the wire protocol is the same after the 0.8.2 upgrade for OffsetFetchRequest if you were using 0.8.1.1 OffsetFetchRequest https://github.com/apache/kafka/blob/0.8.1/core/src/main/scala/kafka/server/KafkaApis.scala#L705-L728 will stop going to zookeeper and start going to Kafka storage https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/server/KafkaApis.scala#L504-L519 so more errors will happen and things break too.  ;;;","08/Jan/15 04:21;junrao;Thinking about this a bit more. We can revert the wire format of version 0 to what's in 0.8.1. However, I don't think that we need to preserve the behavior of writing to ZK though. Kafka managed offset will be the future since we want to reduce the load on ZK. The offset topic should be highly available. If there is any error due to bugs, we should just fix those.;;;","08/Jan/15 08:26;parth.brahmbhatt;@junrao If noone plans to take this one, please assign to me.;;;","08/Jan/15 08:51;junrao;Parth,

Thanks for offering. I have a patch that's almost ready. Will upload soon.;;;","08/Jan/15 09:54;junrao;Created reviewboard https://reviews.apache.org/r/29692/diff/
 against branch origin/0.8.2;;;","08/Jan/15 09:57;junrao;[~dana.powers], could you try this patch on 0.8.2 and see if it works with the 0.8.1 client? The implementation on the server uses a special Kafka topic, instead of ZK. You may see a transient error when the special topic is created for the first time.;;;","09/Jan/15 07:08;junrao;Updated reviewboard https://reviews.apache.org/r/29692/diff/
 against branch origin/0.8.2;;;","09/Jan/15 07:37;junrao;This is actually a bit tricky to fix. To make this really backward compatible, we have to make sure that version 0 of OffsetCommitRequest only writes to ZK. However, this doesn't quite work together with OffsetFetchRequest since in 0.8.2, it only has one version and it always reads offsets from Kafka. To address this issue, I bumped up the version of OffsetFetchRequest in 0.8.2 (with same wire protocol). Then, version 0 of OffsetFetchRequest will read from ZK and version 1 of OffsetFetchRequest will read from Kafka. This works as long as people are only using released final version. However, since this introduces an incompatible change of OffsetFetchRequest in 0.8.2-beta and trunk, this will create problems for people (assuming that they are using this api) who have a deployment of 0.8.2-beta and want to upgrade to 0.8.2 final, or a deployment from trunk and want to upgrade to a later version of trunk in the future. In either case, the upgrade of the broker will cause the old client to behave differently and incorrectly.;;;","10/Jan/15 06:37;junrao;Updated reviewboard https://reviews.apache.org/r/29692/diff/
 against branch origin/0.8.2;;;","13/Jan/15 06:30;junrao;Updated reviewboard https://reviews.apache.org/r/29692/diff/
 against branch origin/0.8.2;;;","13/Jan/15 14:34;junrao;Thanks for the review. Committed to 0.8.2.

Since we are evolving the protocol of OffsetCommitRequest in KAFKA-1634, will let KAFKA-1634 merge in the changes in this jira to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Embedded consumer doesn't shut down if the server can't start,KAFKA-197,12530895,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,10/Nov/11 00:45,13/Dec/11 11:04,22/Mar/23 15:10,13/Dec/11 11:04,0.7,,,,,,0.7.1,,,,,,,,,,,0,,,,,,"If a broker embeds a consumer and the broker itself doesn't start (e.g., conflicting broker id in ZK), the embedded consumer is still running. In this case, we should probably shut down the embedded consumer too.

To do this, we need to either throw an exception or return an error in KafkaServer.startup and act accordingly in KafkaServerStartable.startup.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Dec/11 07:15;junrao;KAFKA-197.patch;https://issues.apache.org/jira/secure/attachment/12505942/KAFKA-197.patch","06/Dec/11 02:55;junrao;KAFKA-197_v2.patch;https://issues.apache.org/jira/secure/attachment/12506138/KAFKA-197_v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,216633,,,Tue Dec 13 03:04:19 UTC 2011,,,,,,,,,,"0|i0l3sf:",121264,,,,,,,,,,,,,,,,,,,,"03/Dec/11 07:15;junrao;Patch attached.;;;","05/Dec/11 11:55;jkreps;I don't think we want to call halt(), that is like kill -9 the process. I think we want the logs to flush and shutdown gracefully. Can't we just do a graceful shutdown on both the server and the embedded consumer?;;;","05/Dec/11 12:39;nehanarkhede;Would it be reasonable to have KafkaServerStartable register a callback with KafkaServer, and have the shutdown API of KafkaServer invoke that callback ? That way, we can ensure that KafkaServerStartable can cleanly shutdown the embedded consumer when the server is shutdown for some reason.;;;","05/Dec/11 13:37;jkreps;A less invasive way would just be to have the embedded consumer register a shutdown hook and use System.exit.

I am a little concerned about this whole embedded consumer thing, though. The original approach where we wrote to the local log in process was pretty fool proof. I think sending to a remote broker is actually riddled with issues. The producer send buffer is vulnerable to quite a large loss on any unclean shutdown or indeed any shutdown bugs. And also any condition that leads to a broker being unable to take requests but still registered in zk will lead to unbounded data loss. I wonder if this issue isn't just a special case of many many bad things that could happen.

With the current approach I actually don't see any benefits at all to bundling the replication process with the kafka broker. It would actually be better to have that run independently it seems to me.;;;","06/Dec/11 02:25;junrao;The main reason that we moved away from writing to local log is to pick up the compression support in the high level producer. Decoupling the embedded consumer from the broker may not be a bad idea. There is one more service/process that one has to manage. However, it's probably more flexible (to support things like consuming from multiple sources and plugging in logic for consumer-side auditing) and is less intrusive to the core Kafka code.;;;","06/Dec/11 02:55;junrao;Attach patch v2. Consolidate all error handling in KafkaServerStarble.;;;","13/Dec/11 10:15;nehanarkhede;+1 on v2;;;","13/Dec/11 11:04;junrao;Just committed this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Partition reassignment of a nonexistent topic prevents future reassignments,KAFKA-2234,12834240,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,omkreddy,rthalley,rthalley,01/Jun/15 21:46,19/Jun/15 08:02,22/Mar/23 15:10,19/Jun/15 07:37,0.8.2.1,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"The results of this bug are like those of KAFKA-822.  If I erroneously list a non-existent topic in a partition reassignment request, then it will never complete and it becomes impossible to do reassignments until the admin/reassign-partitions node is deleted by hand from zookeeper.

Note too the incoherent messaging in the bad command.  First it says ERROR what I'm trying to do is bad, and then it says it has successfully started it (which indeed it has, at least in the sense of writing an empty list to to zookeeper :)).

# reassignment.json is bad, it refers to the non-existent topic ""bad-foo""

$ cat reassignment.json
 {""partitions"":                         
  [{""topic"": ""bad-foo"",                     
    ""partition"": 0,                     
    ""replicas"": [2] }],             
  ""version"":1                            
 }    

$ kafka-reassign-partitions.sh --reassignment-json-file reassignment.json --zookeeper localhost:2181/kafka --execute
Current partition replica assignment

{""version"":1,""partitions"":[]}

Save this to use as the --reassignment-json-file option during rollback
[2015-06-01 06:34:26,275] ERROR Skipping reassignment of partition [bad-foo,0] since it doesn't exist (kafka.admin.ReassignPartitionsCommand)
Successfully started reassignment of partitions {""version"":1,""partitions"":[{""topic"":""bad-foo"",""partition"":0,""replicas"":[2]}]}

$ zkCli
Connecting to localhost:2181
Welcome to ZooKeeper!
JLine support is enabled

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
[zk: localhost:2181(CONNECTED) 2] get /kafka/admin/reassign_partitions
{""version"":1,""partitions"":[]}
cZxid = 0x5d
ctime = Mon Jun 01 06:34:26 PDT 2015
mZxid = 0x5d
mtime = Mon Jun 01 06:34:26 PDT 2015
pZxid = 0x5d
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 29
numChildren = 0

^C

# Fix reassignment.json

$kafka-reassign-partitions.sh --reassignment-json-file reassignment.json --zookeeper localhost:2181/kafka --executetions
Current partition replica assignment

{""version"":1,""partitions"":[{""topic"":""good-foo"",""partition"":0,""replicas"":[2]}]}

Save this to use as the --reassignment-json-file option during rollback
Partitions reassignment failed due to Partition reassignment currently in progress for Map(). Aborting operation
kafka.common.AdminCommandFailedException: Partition reassignment currently in progress for Map(). Aborting operation
	at kafka.admin.ReassignPartitionsCommand.reassignPartitions(ReassignPartitionsCommand.scala:216)
	at kafka.admin.ReassignPartitionsCommand$.executeAssignment(ReassignPartitionsCommand.scala:133)
	at kafka.admin.ReassignPartitionsCommand$.main(ReassignPartitionsCommand.scala:47)
	at kafka.admin.ReassignPartitionsCommand.main(ReassignPartitionsCommand.scala)",,junrao,omkreddy,rthalley,yunfanfighting@foxmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jun/15 20:33;omkreddy;KAFKA-2234.patch;https://issues.apache.org/jira/secure/attachment/12739418/KAFKA-2234.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jun 19 00:02:11 UTC 2015,,,,,,,,,,"0|i2fgh3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"13/Jun/15 20:33;omkreddy;Created reviewboard https://reviews.apache.org/r/35424/diff/
 against branch origin/trunk;;;","19/Jun/15 07:37;junrao;Thanks for the patch. +1 and committed to trunk.;;;","19/Jun/15 08:02;junrao;The patch introduced a unit test failure. Checked in a trivial fix.

kafka.admin.AdminTest > testReassigningNonExistingPartition FAILED
    junit.framework.AssertionFailedError: Partition reassignment failed for test, 0
        at junit.framework.Assert.fail(Assert.java:47)
        at junit.framework.Assert.assertTrue(Assert.java:20)
        at kafka.admin.AdminTest.testReassigningNonExistingPartition(AdminTest.scala:245)
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka LZ4 framing code miscalculates header checksum,KAFKA-3160,12934556,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,dana.powers,dana.powers,dana.powers,28/Jan/16 03:43,10/May/16 01:52,22/Mar/23 15:10,08/May/16 02:36,0.8.2.0,0.8.2.1,0.8.2.2,0.9.0.0,0.9.0.1,,0.10.0.0,,,,,,,compression,,,,1,compatibility,compression,lz4,,,"KAFKA-1493 partially implements the LZ4 framing specification, but it incorrectly calculates the header checksum. This causes KafkaLZ4BlockInputStream to raise an error [IOException(DESCRIPTOR_HASH_MISMATCH)] if a client sends *correctly* framed LZ4 data. It also causes KafkaLZ4BlockOutputStream to generate incorrectly framed LZ4 data, which means clients decoding LZ4 messages from kafka will always receive incorrectly framed data.

Specifically, the current implementation includes the 4-byte MagicNumber in the checksum, which is incorrect.
http://cyan4973.github.io/lz4/lz4_Frame_format.html

Third-party clients that attempt to use off-the-shelf lz4 framing find that brokers reject messages as having a corrupt checksum. So currently non-java clients must 'fixup' lz4 packets to deal with the broken checksum.

Magnus first identified this issue in librdkafka; kafka-python has the same problem.",,dana.powers,edenhill,githubbot,guozhang,ijuma,martinboyleie,qwertymaniac,vchekan,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon May 09 17:52:11 UTC 2016,,,,,,,,,,"0|i2s1vr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"28/Jan/16 07:51;ijuma;[~edenhill], you're working on this, right? You should probably assign the issue to yourself to avoid duplicated work.;;;","11/Apr/16 01:45;dana.powers;Magnus: have you made any progress on this? The more I think about it, the more I think this needs to get included w/ KIP-31. If the goal of KIP-31 is to avoid recompression, and the goal of this JIRA is to fix the compression format, and in all cases we need to maintain compatibility with old clients, then I think the only way to solve all conditions is to make the pre-KIP-31 FetchRequest / ProduceRequest versions use the broken LZ4 format, and require the fixed format in the new FetchRequest / ProduceRequest version:

Old 0.8/0.9 clients (current behavior): produce messages w/ broken checksum; consume messages w/ incorrect checksum only
New 0.10 clients (proposed behavior): produce messages in ""new KIP-31 format"" w/ correct checksum; consume messages in ""new KIP-31 format"" w/ correct checksum only

Proposed behavior for 0.10 broker:
 - convert all ""old format"" messages to ""new KIP-31 format"" + fix checksum to correct value
 - require incoming ""new KIP-31 format"" messages to have correct checksum, otherwise throw error
 - when serving requests for ""old format"", fixup checksum to be incorrect when converting ""new KIP-31 format"" messages to old format

Thoughts?;;;","11/Apr/16 02:33;edenhill;[~dana.powers] My broker patch adds a new Attribute bit to specify the fixed LZ4F framing but still relies on clients being backwards compatible with the broken framing format, but that was before KIP-31 was a thing..

Your proposed solution with reusing the KIP-31 behaviour is much better, I'd definately like to see this in broker 0.10.
This will also formally add LZ4 support to the protocol (it is not even mentioned in the Kafka protocol docs) and be compatible with KIP-35 (e.g., ProduceRequest >= v2 supports LZ4).

I'm a strong +1 on this.;;;","11/Apr/16 06:26;guozhang;One thing with serving old format consume request is that now we need to modify the bytes and hence cannot do zero-copy anymore, but since for 0.10.0 upgrade there will be a temporary performance degradation anyways this may be just fine.;;;","11/Apr/16 13:41;githubbot;GitHub user dpkp opened a pull request:

    https://github.com/apache/kafka/pull/1212

    KAFKA-3160: Fix LZ4 Framing

    This contribution is my original work and I license the work under Apache 2.0.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/dpkp/kafka KAFKA-3160

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1212.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1212
    
----
commit b64e5f9f054131ae7bf6b9a10be861f5fb0caeab
Author: Dana Powers <dana.powers@gmail.com>
Date:   2016-04-11T04:35:43Z

    Update KafkaLZ4Block* implementation to 1.5.1 framing spec
    
     - update spec to 1.5.1; remove dictID
     - fix frame descriptor HC check (dont include magic bytes)
     - dont require HC validation on input by default
     - add useBrokenHC boolean for output compatibility
     - nominal support for contentChecksum / contentSize flags

commit f1380d0e5f6e1e9d7b48a9cff3fbcd13b7a5fe3f
Author: Dana Powers <dana.powers@gmail.com>
Date:   2016-04-11T05:35:31Z

    KAFKA-3160: use LZ4 v1.5.1 framing for all v1 messages; keep old framing for v0 messages

----
;;;","11/Apr/16 14:54;ijuma;[~guozhang], this proposal doesn't seem to affect when we lose zero-copy. That depends on the fetch request version (<= 1), topic message format configuration (v0) and whether we have messages stored with format v1. This proposal just changes the LZ4 format for message format 1. Do I understand correctly [~dana.powers]?;;;","11/Apr/16 15:22;edenhill;[~ijuma] It needs to go through slow-path to ""fix-down"" (i.e., break the checksum) for older clients connecting to a newer broker.
But yeah, the plan is to bundle this functionality with Message format 1, so that Message format v0 attribute flag LZ4 has a broken checksum, while Message format 1 with attribute flag LZ4 has a correct checksum.;;;","24/Apr/16 00:21;ijuma;[~edenhill], yeah, I understand that, but we do the slow path for that case already.;;;","24/Apr/16 00:33;ijuma;[~dana.powers], I asked Jun about this and he mentioned that we would need a KIP for this change as it touches the file format. Would you be able so submit one?;;;","08/May/16 02:36;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1212
;;;","08/May/16 02:36;ijuma;Issue resolved by pull request 1212
[https://github.com/apache/kafka/pull/1212];;;","09/May/16 09:59;githubbot;GitHub user dpkp opened a pull request:

    https://github.com/apache/kafka/pull/1344

    Fixup KAFKA-3160: catch decompression errors in constructor

    After testing KAFKA-3160 a bit more, I found that the error code was not being set properly in ProduceResponse. This happened because the validation error is raised in the CompressionFactory constructor, which was not wrapped in a try / catch.
    
    @ijuma @junrao 
    
    (This contribution is my original work and I license the work under Apache 2.0.)

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/dpkp/kafka decompress_error_code

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1344.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1344
    
----
commit bac92e133cb80aa13ee155a1200bf085947376b7
Author: Dana Powers <dana.powers@gmail.com>
Date:   2016-05-09T01:54:22Z

    Fixup to KAFKA-3160: catch decompression errors in constructor; return CorruptMessageError

----
;;;","10/May/16 01:52;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1344
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsoleConsumer should not hang infinitely upon exception,KAFKA-2585,12896702,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,lindong,lindong,lindong,28/Sep/15 13:34,29/Sep/15 05:41,22/Mar/23 15:10,29/Sep/15 05:41,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Due to imcompatibility beween Java 1.7 and Java 1.8, if Kafka ConsoleConsumer was compiled by Java 1.8 but run by Java 1.7, and if ConsoleConsumer has consumer.timeout.ms in the consumer.properties, then when it timesout, it will throw the following exception and hang infinitely.

This will cause problem for e.g. Ducktape system test, which currently runs consumer with Java 1.7 and waits for consumer to timeout. This bug causes the Ducktape to hang for a long time.

To prevent ConsoleConsumer to hang in case of such exception, we can wrap try/catch around run() and do System.exit(0) at the end of main() in ConsoleConsumer.



[2015-09-28 05:41:31,499] ERROR Error processing message, stopping consumer:  (kafka.tools.ConsoleConsumer$)
kafka.consumer.ConsumerTimeoutException
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:69)
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:33)
	at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)
	at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:38)
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)
	at kafka.consumer.OldConsumer.receive(BaseConsumer.scala:70)
	at kafka.tools.ConsoleConsumer$.process(ConsoleConsumer.scala:94)
	at kafka.tools.ConsoleConsumer$.run(ConsoleConsumer.scala:57)
	at kafka.tools.ConsoleConsumer$.main(ConsoleConsumer.scala:41)
	at kafka.tools.ConsoleConsumer.main(ConsoleConsumer.scala)
Processed a total of 78 messages
Exception in thread ""main"" java.lang.NoSuchMethodError: java.util.concurrent.ConcurrentHashMap.keySet()Ljava/util/concurrent/ConcurrentHashMap$KeySetView;
	at kafka.utils.Pool.keys(Pool.scala:77)
	at kafka.consumer.FetchRequestAndResponseStatsRegistry$.removeConsumerFetchRequestAndResponseStats(FetchRequestAndResponseStats.scala:69)
	at kafka.metrics.KafkaMetricsGroup$.removeAllConsumerMetrics(KafkaMetricsGroup.scala:189)
	at kafka.consumer.ZookeeperConsumerConnector.shutdown(ZookeeperConsumerConnector.scala:202)
	at kafka.consumer.OldConsumer.stop(BaseConsumer.scala:75)
	at kafka.tools.ConsoleConsumer$.process(ConsoleConsumer.scala:98)
	at kafka.tools.ConsoleConsumer$.run(ConsoleConsumer.scala:57)
	at kafka.tools.ConsoleConsumer$.main(ConsoleConsumer.scala:41)
	at kafka.tools.ConsoleConsumer.main(ConsoleConsumer.scala)




",,githubbot,gwenshap,lindong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Sep 28 21:41:57 UTC 2015,,,,,,,,,,"0|i2lm6v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"28/Sep/15 13:39;githubbot;GitHub user lindong28 opened a pull request:

    https://github.com/apache/kafka/pull/247

    KAFKA-2585; ConsoleConsumer should not hang infinitely upon exception

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/lindong28/kafka KAFKA-2585

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/247.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #247
    
----
commit ccd6826e8ab257c56e0994414c3cffc9aca387a9
Author: Dong Lin <lindong28@gmail.com>
Date:   2015-09-28T05:38:27Z

    KAFKA-2585; ConsoleConsumer should not hang infinitely upon exception

----
;;;","29/Sep/15 05:41;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/247
;;;","29/Sep/15 05:41;gwenshap;Issue resolved by pull request 247
[https://github.com/apache/kafka/pull/247];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
IndexOutOfBoundsException while fetching data from leader,KAFKA-861,12641925,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriramsub,sriramsub,sriramsub,11/Apr/13 05:20,16/Apr/13 09:12,22/Mar/23 15:10,16/Apr/13 09:12,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"2013-04-09 16:36:50,051] ERROR [ReplicaFetcherThread-0-261], Error due to  (kafka.server.ReplicaFetcherThread)
kafka.common.KafkaException: error processing data for topic firehoseUpdates partititon 14 offset 53531364
        at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$4.apply(AbstractFetcherThread.scala:136)
        at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$4.apply(AbstractFetcherThread.scala:113)
        at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:125)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:344)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:344)
        at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:113)
        at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:89)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)
Caused by: java.lang.IndexOutOfBoundsException
        at java.nio.Buffer.checkIndex(Buffer.java:512)
        at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:121)
        at kafka.message.Message.compressionCodec(Message.scala:202)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNextOuter(ByteBufferMessageSet.scala:174)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:197)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:145)
        at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:61)
        at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:53)
        at scala.collection.IterableLike$class.isEmpty(IterableLike.scala:92)
        at kafka.message.MessageSet.isEmpty(MessageSet.scala:67)
        at scala.collection.TraversableLike$class.lastOption(TraversableLike.scala:512)
        at kafka.message.MessageSet.lastOption(MessageSet.scala:67)",,junrao,nehanarkhede,sriramsub,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Apr/13 08:33;sriramsub;KAFKA-861-v2.patch;https://issues.apache.org/jira/secure/attachment/12578846/KAFKA-861-v2.patch","16/Apr/13 04:48;sriramsub;KAFKA-861.patch;https://issues.apache.org/jira/secure/attachment/12578813/KAFKA-861.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,322340,,,Tue Apr 16 01:12:55 UTC 2013,,,,,,,,,,"0|i1jm5r:",322685,,,,,,,,,,,,,,,,,,,,"12/Apr/13 05:23;sriramsub;This happens when an existing follower becomes the new leader and the current leader starts following the new leader. 

The existing follower closes the fetcher thread and transitions to become a leader
The current leader truncates its log to high water mark and starts following the new leader

The messageset that is received by the old follower during this transition contains only zero bytes. When we try to iterate through this messageset, we fail and throw the above exception.

What causes these zero bytes to be present in the messageset? It looks like when the old leader truncated its log, it was also trying to send bytes to the follower. These bytes were outside the truncated region. Somehow, the bytes after the highwatermark all became zeros. 

It turns out that in jdk 1.6 there is a bug in truncateTo that truncates the file but does not update the postion of the file. This is fixed in kafka by explicitly setting the position after the truncate call. However, a simple program below verifies that reading the file channel after the truncated region (without setting the position) is totally fine and does not return any bytes

1.
    // create a channel for a file
    val path = ""/home/myid/outfile1""
    val fileAccess = new RandomAccessFile(path, ""rw"")
    val fc = fileAccess.getChannel

2. 
    // create random buffer
    val b = ByteBuffer.allocate(100)
    new Random().nextBytes(b.array())
   
    // write the buffer to the channel
    fc.write(b)
    var pos = fc.position() // position is 100
    var size = fc.size() // size is 100

3.
    // truncate the channel
    fc.truncate(50)
    size = fc.size() // size is 50
    pos = fc.position() // position is 100

4. 
    // transfer the truncated portition to a channel
    val path1 = ""/home/myid/outfile2""
    val f2 = new RandomAccessFile(path1, ""rw"")
    val fc1 = f2.getChannel
    val transferred = fc.transferTo(50, 50, fc1) // transferred is 0

Further, if we add the 3"" step below after step 3 above, it can be seen that step 4 does return non zero bytes and they all contain 0 bytes.

3""

   // write more bytes
    b.rewind()
    fc.write(b)
    pos = fc.position() // position is 200
    size = fc.size() // size is 200

The code above shows that appending to a file without setting the position after truncate does expose the zero bytes to the reader. But in kafka, truncate/set position and append are all synchronized. This means we should not hit the issue above. 

This could mean there is a race condition in FileChannelImpl that could somehow cause this. The code snippet below from transferTo method from FileChannelImpl might explain what we see. 

        long sz = size();   -- > checks size. size() is synchronized with other FileChannelImpl methods
        if (position > sz)
            return 0; --> This is what is returned in step 4 above in the first case. The size is smaller than the position requested. However, truncate can happen after this line.
        int icount = (int)Math.min(count, Integer.MAX_VALUE);
        if ((sz - position) < icount)
            icount = (int)(sz - position);

        long n;

        // Attempt a direct transfer, if the kernel supports it
        if ((n = transferToDirectly(position, icount, target)) >= 0) // the size check above could have been good above but at this point the size is smaller than the requested 
            return n;                                                                 // position. transferToDirectly calls transferTo0 which could just read the zero bytes written by truncate.


Few open questions
1. Does truncate zero out the bytes synchronously or lazily? If it is lazy, we could also get junk bytes instead of zeros
2. How to fix it in kafka. One possible fix is to ensure that the MessageSet iterator throws invalid message when it encounters 0 byte size or if crc does not match the message. The follower can then try to refetch the offset for that topic partition or just fail (atleast we know the cause). 

    

   ;;;","16/Apr/13 04:48;sriramsub;Fixes the size = 0 in the iterator.The fetcher thread logs and does not update the offset and retries again in the next loop for that topic partition.;;;","16/Apr/13 07:56;junrao;Thanks for the patch. A couple of comments:

1. ByteBufferMessageSet: Instead of check for size <= 0, it's probably better to check for size < Message.MinHeaderSize.

2. AbstractFetcher: Could we add a comment when we catch InvalidMessageException to explain the particular problem that we have seen and why refetching the data will likely solve the issue?;;;","16/Apr/13 08:17;nehanarkhede;Thanks for the patch. Good catch!

1. AbstractFetcherThread -
1.1 Let's change the logging to ""[%s,%d]"" for printing the topic partition. This is what most of the code is standardized upon right now. It will make it easier to grep through the logs.
1.2 While you're in there, do you mind fixing this typo - ""partititon""

2 ByteBufferMessageSet: +1 on Jun's suggestion above.

;;;","16/Apr/13 08:41;nehanarkhede;+1 on v2;;;","16/Apr/13 09:12;junrao;Thanks for patch v2. We should do ""size < Message.MinHeaderSize"" instead of ""size <= Message.MinHeaderSize"" in ByteBufferMessagesSet since it's possible to have a valid message whose size is exactly Message.MinHeaderSize. Committed to 0.8 with the change.

Great investigation.

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in unit test for new consumer,KAFKA-1969,12776362,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,nehanarkhede,nehanarkhede,20/Feb/15 13:40,12/Mar/15 12:03,22/Mar/23 15:10,11/Mar/15 02:21,,,,,,,0.9.0.0,,,,,,,,,,,0,newbie,,,,,"{code}
kafka.api.ConsumerTest > testConsumptionWithBrokerFailures FAILED
    java.lang.NullPointerException
        at org.apache.kafka.clients.consumer.KafkaConsumer.ensureCoordinatorReady(KafkaConsumer.java:1238)
        at org.apache.kafka.clients.consumer.KafkaConsumer.initiateCoordinatorRequest(KafkaConsumer.java:1189)
        at org.apache.kafka.clients.consumer.KafkaConsumer.commit(KafkaConsumer.java:777)
        at org.apache.kafka.clients.consumer.KafkaConsumer.commit(KafkaConsumer.java:816)
        at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:704)
        at kafka.api.ConsumerTest.consumeWithBrokerFailures(ConsumerTest.scala:167)
        at kafka.api.ConsumerTest.testConsumptionWithBrokerFailures(ConsumerTest.scala:152)
{code}",,guozhang,jkreps,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1910,,,,,,,,,,"21/Feb/15 23:50;junrao;stack.out;https://issues.apache.org/jira/secure/attachment/12700042/stack.out",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Feb 23 06:09:28 UTC 2015,,,,,,,,,,"0|i25udb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Feb/15 23:50;junrao;Also, saw the test fail occasionally. Attached is the stack trace.;;;","22/Feb/15 03:05;nehanarkhede;[~junrao] Did you mean this JIRA or KAFKA-1975;;;","22/Feb/15 05:09;guozhang;[~nehanarkhede], [~junrao] I have started looking at both issues yesterday and have a solution to them. There are more issues in the new consumer and I am still working on them. I could upload a patch of just these two if they are urgent.;;;","22/Feb/15 05:38;jkreps;Cool. Hey [~guozhang] let me know if I can be helpful. These are probably my fault so I feel bad. :-);;;","23/Feb/15 14:09;guozhang;Thanks Jay. I am working on some of those issues as part of KAFKA-1910 and will definitely let you know if I got something.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prevent HW from going back during leader failover ,KAFKA-2334,12845078,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,mumrah,guozhang,guozhang,15/Jul/15 05:03,09/Jan/19 05:05,22/Mar/23 15:10,15/Dec/18 05:55,0.8.2.1,,,,,,2.2.0,,,,,,,replication,,,,1,reliability,,,,,"Consider the following scenario:

0. Kafka use replication factor of 2, with broker B1 as the leader, and B2 as the follower. 
1. A producer keep sending to Kafka with ack=-1.
2. A consumer repeat issuing ListOffset request to Kafka.

And the following sequence:

0. B1 current log-end-offset (LEO) 0, HW-offset 0; and same with B2.
1. B1 receive a ProduceRequest of 100 messages, append to local log (LEO becomes 100) and hold the request in purgatory.
2. B1 receive a FetchRequest starting at offset 0 from follower B2, and returns the 100 messages.
3. B2 append its received message to local log (LEO becomes 100).
4. B1 receive another FetchRequest starting at offset 100 from B2, knowing that B2's LEO has caught up to 100, and hence update its own HW, and satisfying the ProduceRequest in purgatory, and sending the FetchResponse with HW 100 back to B2 ASYNCHRONOUSLY.
5. B1 successfully sends the ProduceResponse to the producer, and then fails, hence the FetchResponse did not reach B2, whose HW remains 0.

From the consumer's point of view, it could first see the latest offset of 100 (from B1), and then see the latest offset of 0 (from B2), and then the latest offset gradually catch up to 100.

This is because we use HW to guard the ListOffset and Fetch-from-ordinary-consumer.",,abraithwaite,bobrik,BrickXu,cmccabe,elevy,fullung,githubbot,guozhang,hai_lin,ijuma,jinxing6042@126.com,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Dec 14 21:53:06 UTC 2018,,,,,,,,,,"0|i2h94v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"15/Jul/15 05:06;guozhang;One possible solution to this issue is to let the new leader only become available (i.e. start accepting Produce / Fetch requests for the partition) after its HW caught up with its LEO. This will likely increase the unavailability latency a bit, in practice it should not cause much performance implication since most of the time its HW == LEO, and even not it will quickly catch up. The tricky part is how to implement it without introducing too much logic complexity on the broker side.;;;","18/Nov/15 03:47;fullung;Hitting this issue in production with 0.8.2.1 on a large cluster. Fix appreciated. :);;;","23/Nov/15 21:59;jinxing6042@126.com;after receiving LeaderAndIsrRequest, Broker B2 will finally call "" Partition::makeLeader"", part of code is as below:
...
     zkVersion = leaderAndIsr.zkVersion
      leaderReplicaIdOpt = Some(localBrokerId)
      // construct the high watermark metadata for the new leader replica
      val newLeaderReplica = getReplica().get
      newLeaderReplica.convertHWToLocalOffsetMetadata()
      // reset log end offset for remote replicas
      assignedReplicas.foreach(r => if (r.brokerId != localBrokerId) r.logEndOffset = LogOffsetMetadata.UnknownOffsetMetadata)
      // we may need to increment high watermark since ISR could be down to 1
      maybeIncrementLeaderHW(newLeaderReplica)
      if (topic == OffsetManager.OffsetsTopicName)
        offsetManager.loadOffsetsFromLog(partitionId)
...
I can tell Broker B2 will first set 'leaderReplicaIdOpt = Some(localBrokerId)', and then try to update high watermark;
by setting leaderReplicaIdOpt, Broker B2 will be available for consumer(if the consumer send fetchReqeust, there will be no NotLeaderForPartitionException);
In the short interval which after 'leaderReplicaIdOpt = Some(localBrokerId)' and before setting up hw, what the consumer get is the ""gone back"" hw;
If my understanding is wright, just reverse the order of setting up leaderReplicaIdOpt and updating high watermark will fix this issue;
am I wrong ?;;;","01/Dec/15 06:46;guozhang;[~jinxing6042@126.com] The problem with this scenario is not related to LeaderAndISRRequest but in follower's FetchResponse, which will make the follower to update HW according to the returned value:

https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala#L120

If the Fetch Response is not returned from the previous leader, then this follower will not update its HW and when itself becoming the new leader, the HW will effectively ""go back"" from the consumer point of view.;;;","31/May/17 15:28;ijuma;Is this still an issue?;;;","27/Jan/18 12:21;guozhang;This is fixed in another approach: KIP-101.;;;","01/Feb/18 03:18;cmccabe;[~guozhang]: The fix here is not KIP-101, but KIP-207.  KIP-207 was accepted, but not implemented yet.  There's some discussion here: https://www.mail-archive.com/dev@kafka.apache.org/msg81074.html;;;","04/Jul/18 07:33;elevy;I think we may hit this in our cluster while running a Flink application.  One broker became disconnected from ZK but recovered in 20 seconds or so.  But during this period a single subtask in a Flink job consuming from Kafka came to believe that its fetch offset was out-of-range:
{noformat}
June 30th 2018, 09:35:01.711 Fetch offset 2340400514 is out of range for partition topic-124, resetting offset{noformat}
As the Kafka consumer was configured with {{auto.offsets.reset}} set to {{earliest}}, that caused that single partition to be reprocessed from the earliest offset.;;;","04/Jul/18 08:40;guozhang;[~cmccabe] Is KIP-207 already implemented? I saw the vote passes and it is targeted for 2.0.0 but did not saw the corresponding PR.;;;","04/Dec/18 02:11;githubbot;mumrah opened a new pull request #5991: KAFKA-2334 Guard against non-monotonic offsets in the client
URL: https://github.com/apache/kafka/pull/5991
 
 
   After a recent leader election, the leaders high-water mark might lag behind the offset at the beginning of the new epoch (as well as the previous leader's HW). This can lead to offsets going backwards from a client perspective, which is confusing and leads to strange behavior in some clients.
   
   This change causes Partition#fetchOffsetForTimestamp to throw an exception to indicate the offsets are not yet available from the leader. For new clients, a new OFFSET_NOT_AVAILABLE error is added. For existing clients, a LEADER_NOT_AVAILABLE is thrown.
   
   
   ### Committer Checklist (excluded from commit message)
   - [ ] Verify design and implementation 
   - [ ] Verify test coverage and CI build status
   - [ ] Verify documentation (including upgrade notes)
   

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;","15/Dec/18 05:53;githubbot;hachikuji closed pull request #5991: KAFKA-2334 Guard against non-monotonic offsets in the client
URL: https://github.com/apache/kafka/pull/5991
 
 
   

This is a PR merged from a forked repository.
As GitHub hides the original diff on merge, it is displayed below for
the sake of provenance:

As this is a foreign pull request (from a fork), the diff is supplied
below (as it won't show otherwise due to GitHub magic):

diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java
index 265fc99721d..180fbba7d04 100644
--- a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java
@@ -811,7 +811,9 @@ private void handleListOffsetResponse(Map<TopicPartition, ListOffsetRequest.Part
                         ""is before 0.10.0"", topicPartition);
             } else if (error == Errors.NOT_LEADER_FOR_PARTITION ||
                        error == Errors.REPLICA_NOT_AVAILABLE ||
-                       error == Errors.KAFKA_STORAGE_ERROR) {
+                       error == Errors.KAFKA_STORAGE_ERROR ||
+                       error == Errors.OFFSET_NOT_AVAILABLE ||
+                       error == Errors.LEADER_NOT_AVAILABLE) {
                 log.debug(""Attempt to fetch offsets for partition {} failed due to {}, retrying."",
                         topicPartition, error);
                 partitionsToRetry.add(topicPartition);
diff --git a/clients/src/main/java/org/apache/kafka/common/errors/OffsetNotAvailableException.java b/clients/src/main/java/org/apache/kafka/common/errors/OffsetNotAvailableException.java
new file mode 100644
index 00000000000..97de3b3d64e
--- /dev/null
+++ b/clients/src/main/java/org/apache/kafka/common/errors/OffsetNotAvailableException.java
@@ -0,0 +1,29 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.common.errors;
+
+/**
+ * Indicates that the leader is not able to guarantee monotonically increasing offsets
+ * due to the high watermark lagging behind the epoch start offset after a recent leader election
+ */
+public class OffsetNotAvailableException extends RetriableException {
+    private static final long serialVersionUID = 1L;
+
+    public OffsetNotAvailableException(String message) {
+        super(message);
+    }
+}
diff --git a/clients/src/main/java/org/apache/kafka/common/protocol/Errors.java b/clients/src/main/java/org/apache/kafka/common/protocol/Errors.java
index bd0815df538..51a78f578e8 100644
--- a/clients/src/main/java/org/apache/kafka/common/protocol/Errors.java
+++ b/clients/src/main/java/org/apache/kafka/common/protocol/Errors.java
@@ -66,6 +66,7 @@
 import org.apache.kafka.common.errors.NotEnoughReplicasException;
 import org.apache.kafka.common.errors.NotLeaderForPartitionException;
 import org.apache.kafka.common.errors.OffsetMetadataTooLarge;
+import org.apache.kafka.common.errors.OffsetNotAvailableException;
 import org.apache.kafka.common.errors.OffsetOutOfRangeException;
 import org.apache.kafka.common.errors.OperationNotAttemptedException;
 import org.apache.kafka.common.errors.OutOfOrderSequenceException;
@@ -290,7 +291,10 @@
     UNSUPPORTED_COMPRESSION_TYPE(76, ""The requesting client does not support the compression type of given partition."",
             UnsupportedCompressionTypeException::new),
     STALE_BROKER_EPOCH(77, ""Broker epoch has changed"",
-            StaleBrokerEpochException::new);
+            StaleBrokerEpochException::new),
+    OFFSET_NOT_AVAILABLE(78, ""The leader high watermark has not caught up from a recent leader "" +
+            ""election so the offsets cannot be guaranteed to be monotonically increasing"",
+            OffsetNotAvailableException::new);
 
     private static final Logger log = LoggerFactory.getLogger(Errors.class);
 
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java b/clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java
index 5107c4e9140..e9fe942e858 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java
@@ -118,9 +118,12 @@
             ISOLATION_LEVEL,
             TOPICS_V4);
 
+    // V5 bump to include new possible error code (OFFSET_NOT_AVAILABLE)
+    private static final Schema LIST_OFFSET_REQUEST_V5 = LIST_OFFSET_REQUEST_V4;
+
     public static Schema[] schemaVersions() {
         return new Schema[] {LIST_OFFSET_REQUEST_V0, LIST_OFFSET_REQUEST_V1, LIST_OFFSET_REQUEST_V2,
-            LIST_OFFSET_REQUEST_V3, LIST_OFFSET_REQUEST_V4};
+            LIST_OFFSET_REQUEST_V3, LIST_OFFSET_REQUEST_V4, LIST_OFFSET_REQUEST_V5};
     }
 
     private final int replicaId;
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/ListOffsetResponse.java b/clients/src/main/java/org/apache/kafka/common/requests/ListOffsetResponse.java
index 188571b7002..769c850e22c 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/ListOffsetResponse.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/ListOffsetResponse.java
@@ -52,6 +52,8 @@
  * - {@link Errors#UNKNOWN_TOPIC_OR_PARTITION} If the broker does not have metadata for a topic or partition
  * - {@link Errors#KAFKA_STORAGE_ERROR} If the log directory for one of the requested partitions is offline
  * - {@link Errors#UNKNOWN_SERVER_ERROR} For any unexpected errors
+ * - {@link Errors#LEADER_NOT_AVAILABLE} The leader's HW has not caught up after recent election (v4 protocol)
+ * - {@link Errors#OFFSET_NOT_AVAILABLE} The leader's HW has not caught up after recent election (v5+ protocol)
  */
 public class ListOffsetResponse extends AbstractResponse {
     public static final long UNKNOWN_TIMESTAMP = -1L;
@@ -125,9 +127,11 @@
             THROTTLE_TIME_MS,
             TOPICS_V4);
 
+    private static final Schema LIST_OFFSET_RESPONSE_V5 = LIST_OFFSET_RESPONSE_V4;
+
     public static Schema[] schemaVersions() {
         return new Schema[] {LIST_OFFSET_RESPONSE_V0, LIST_OFFSET_RESPONSE_V1, LIST_OFFSET_RESPONSE_V2,
-            LIST_OFFSET_RESPONSE_V3, LIST_OFFSET_RESPONSE_V4};
+            LIST_OFFSET_RESPONSE_V3, LIST_OFFSET_RESPONSE_V4, LIST_OFFSET_RESPONSE_V5};
     }
 
     public static final class PartitionData {
diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java
index 52b78e3de62..134cbed6e48 100644
--- a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java
+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java
@@ -1126,6 +1126,45 @@ public void testUpdateFetchPositionResetToLatestOffset() {
         assertEquals(5, subscriptions.position(tp0).longValue());
     }
 
+    /**
+     * Make sure the client behaves appropriately when receiving an exception for unavailable offsets
+     */
+    @Test
+    public void testFetchOffsetErrors() {
+        subscriptions.assignFromUser(singleton(tp0));
+        subscriptions.requestOffsetReset(tp0, OffsetResetStrategy.LATEST);
+
+        // Fail with OFFSET_NOT_AVAILABLE
+        client.prepareResponse(listOffsetRequestMatcher(ListOffsetRequest.LATEST_TIMESTAMP),
+                listOffsetResponse(Errors.OFFSET_NOT_AVAILABLE, 1L, 5L), false);
+        fetcher.resetOffsetsIfNeeded();
+        consumerClient.pollNoWakeup();
+        assertFalse(subscriptions.hasValidPosition(tp0));
+        assertTrue(subscriptions.isOffsetResetNeeded(tp0));
+        assertFalse(subscriptions.isFetchable(tp0));
+
+        // Fail with LEADER_NOT_AVAILABLE
+        time.sleep(retryBackoffMs);
+        client.prepareResponse(listOffsetRequestMatcher(ListOffsetRequest.LATEST_TIMESTAMP),
+                listOffsetResponse(Errors.LEADER_NOT_AVAILABLE, 1L, 5L), false);
+        fetcher.resetOffsetsIfNeeded();
+        consumerClient.pollNoWakeup();
+        assertFalse(subscriptions.hasValidPosition(tp0));
+        assertTrue(subscriptions.isOffsetResetNeeded(tp0));
+        assertFalse(subscriptions.isFetchable(tp0));
+
+        // Back to normal
+        time.sleep(retryBackoffMs);
+        client.prepareResponse(listOffsetRequestMatcher(ListOffsetRequest.LATEST_TIMESTAMP),
+                listOffsetResponse(Errors.NONE, 1L, 5L), false);
+        fetcher.resetOffsetsIfNeeded();
+        consumerClient.pollNoWakeup();
+        assertTrue(subscriptions.hasValidPosition(tp0));
+        assertFalse(subscriptions.isOffsetResetNeeded(tp0));
+        assertTrue(subscriptions.isFetchable(tp0));
+        assertEquals(subscriptions.position(tp0).longValue(), 5L);
+    }
+
     @Test
     public void testListOffsetsSendsIsolationLevel() {
         for (final IsolationLevel isolationLevel : IsolationLevel.values()) {
diff --git a/core/src/main/scala/kafka/api/ApiVersion.scala b/core/src/main/scala/kafka/api/ApiVersion.scala
index cf360926122..a68bcf0c70b 100644
--- a/core/src/main/scala/kafka/api/ApiVersion.scala
+++ b/core/src/main/scala/kafka/api/ApiVersion.scala
@@ -84,7 +84,9 @@ object ApiVersion {
     KAFKA_2_1_IV2,
     // Introduced broker generation (KIP-380), and
     // LeaderAdnIsrRequest V2, UpdateMetadataRequest V5, StopReplicaRequest V1
-    KAFKA_2_2_IV0
+    KAFKA_2_2_IV0,
+    // New error code for ListOffsets when a new leader is lagging behind former HW (KIP-207)
+    KAFKA_2_2_IV1
   )
 
   // Map keys are the union of the short and full versions
@@ -289,6 +291,13 @@ case object KAFKA_2_2_IV0 extends DefaultApiVersion {
   val id: Int = 20
 }
 
+case object KAFKA_2_2_IV1 extends DefaultApiVersion {
+  val shortVersion: String = ""2.2""
+  val subVersion = ""IV1""
+  val recordVersion = RecordVersion.V2
+  val id: Int = 21
+}
+
 object ApiVersionValidator extends Validator {
 
   override def ensureValid(name: String, value: Any): Unit = {
diff --git a/core/src/main/scala/kafka/cluster/Partition.scala b/core/src/main/scala/kafka/cluster/Partition.scala
index 1f52bd769cf..ca3abbbc973 100755
--- a/core/src/main/scala/kafka/cluster/Partition.scala
+++ b/core/src/main/scala/kafka/cluster/Partition.scala
@@ -817,17 +817,36 @@ class Partition(val topicPartition: TopicPartition,
       case None => localReplica.logEndOffset.messageOffset
     }
 
-    if (timestamp == ListOffsetRequest.LATEST_TIMESTAMP) {
-      Some(new TimestampAndOffset(RecordBatch.NO_TIMESTAMP, lastFetchableOffset, Optional.of(leaderEpoch)))
+    val epochLogString = if(currentLeaderEpoch.isPresent) {
+      s""epoch ${currentLeaderEpoch.get}""
     } else {
-      def allowed(timestampOffset: TimestampAndOffset): Boolean =
-        timestamp == ListOffsetRequest.EARLIEST_TIMESTAMP || timestampOffset.offset < lastFetchableOffset
+      ""unknown epoch""
+    }
 
-      val fetchedOffset = logManager.getLog(topicPartition).flatMap { log =>
-        log.fetchOffsetByTimestamp(timestamp)
-      }
+    // Only consider throwing an error if we get a client request (isolationLevel is defined) and the start offset
+    // is lagging behind the high watermark
+    val maybeOffsetsError: Option[ApiException] = leaderEpochStartOffsetOpt
+      .filter(epochStart => isolationLevel.isDefined && epochStart > localReplica.highWatermark.messageOffset)
+      .map(epochStart => Errors.OFFSET_NOT_AVAILABLE.exception(s""Failed to fetch offsets for "" +
+        s""partition $topicPartition with leader $epochLogString as this partition's "" +
+        s""high watermark (${localReplica.highWatermark.messageOffset}) is lagging behind the "" +
+        s""start offset from the beginning of this epoch ($epochStart).""))
+
+    def getOffsetByTimestamp: Option[TimestampAndOffset] = {
+      logManager.getLog(topicPartition).flatMap(log => log.fetchOffsetByTimestamp(timestamp))
+    }
 
-      fetchedOffset.filter(allowed)
+    // If we're in the lagging HW state after a leader election, throw OffsetNotAvailable for ""latest"" offset
+    // or for a timestamp lookup that is beyond the last fetchable offset.
+    timestamp match {
+      case ListOffsetRequest.LATEST_TIMESTAMP =>
+        maybeOffsetsError.map(e => throw e)
+          .orElse(Some(new TimestampAndOffset(RecordBatch.NO_TIMESTAMP, lastFetchableOffset, Optional.of(leaderEpoch))))
+      case ListOffsetRequest.EARLIEST_TIMESTAMP =>
+        getOffsetByTimestamp
+      case _ =>
+        getOffsetByTimestamp.filter(timestampAndOffset => timestampAndOffset.offset < lastFetchableOffset)
+          .orElse(maybeOffsetsError.map(e => throw e))
     }
   }
 
diff --git a/core/src/main/scala/kafka/server/KafkaApis.scala b/core/src/main/scala/kafka/server/KafkaApis.scala
index 08d03c751fd..389d59cd4f1 100644
--- a/core/src/main/scala/kafka/server/KafkaApis.scala
+++ b/core/src/main/scala/kafka/server/KafkaApis.scala
@@ -827,9 +827,19 @@ class KafkaApis(val requestChannel: RequestChannel,
           ListOffsetResponse.UNKNOWN_OFFSET,
           Optional.empty()))
       } else {
+
+        def buildErrorResponse(e: Errors): (TopicPartition, ListOffsetResponse.PartitionData) = {
+          (topicPartition, new ListOffsetResponse.PartitionData(
+            e,
+            ListOffsetResponse.UNKNOWN_TIMESTAMP,
+            ListOffsetResponse.UNKNOWN_OFFSET,
+            Optional.empty()))
+        }
+
         try {
           val fetchOnlyFromLeader = offsetRequest.replicaId != ListOffsetRequest.DEBUGGING_REPLICA_ID
-          val isolationLevelOpt = if (offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID)
+          val isClientRequest = offsetRequest.replicaId == ListOffsetRequest.CONSUMER_REPLICA_ID
+          val isolationLevelOpt = if (isClientRequest)
             Some(offsetRequest.isolationLevel)
           else
             None
@@ -859,16 +869,19 @@ class KafkaApis(val requestChannel: RequestChannel,
                     _ : UnsupportedForMessageFormatException) =>
             debug(s""Offset request with correlation id $correlationId from client $clientId on "" +
                 s""partition $topicPartition failed due to ${e.getMessage}"")
-            (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e),
-              ListOffsetResponse.UNKNOWN_TIMESTAMP,
-              ListOffsetResponse.UNKNOWN_OFFSET,
-              Optional.empty()))
+            buildErrorResponse(Errors.forException(e))
+
+          // Only V5 and newer ListOffset calls should get OFFSET_NOT_AVAILABLE
+          case e: OffsetNotAvailableException =>
+            if(request.header.apiVersion >= 5) {
+              buildErrorResponse(Errors.forException(e))
+            } else {
+              buildErrorResponse(Errors.LEADER_NOT_AVAILABLE)
+            }
+
           case e: Throwable =>
             error(""Error while responding to offset request"", e)
-            (topicPartition, new ListOffsetResponse.PartitionData(Errors.forException(e),
-              ListOffsetResponse.UNKNOWN_TIMESTAMP,
-              ListOffsetResponse.UNKNOWN_OFFSET,
-              Optional.empty()))
+            buildErrorResponse(Errors.forException(e))
         }
       }
     }
diff --git a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala b/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala
index 4452d89b494..4a09ebeffb9 100644
--- a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala
+++ b/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala
@@ -19,6 +19,7 @@ package kafka.server
 
 import java.util.Optional
 
+import kafka.api
 import kafka.api._
 import kafka.cluster.BrokerEndPoint
 import kafka.log.LogAppendInfo
@@ -80,7 +81,8 @@ class ReplicaFetcherThread(name: String,
 
   // Visible for testing
   private[server] val listOffsetRequestVersion: Short =
-    if (brokerConfig.interBrokerProtocolVersion >= KAFKA_2_1_IV1) 4
+    if (brokerConfig.interBrokerProtocolVersion >= KAFKA_2_2_IV1) 5
+    else if (brokerConfig.interBrokerProtocolVersion >= KAFKA_2_1_IV1) 4
     else if (brokerConfig.interBrokerProtocolVersion >= KAFKA_2_0_IV1) 3
     else if (brokerConfig.interBrokerProtocolVersion >= KAFKA_0_11_0_IV0) 2
     else if (brokerConfig.interBrokerProtocolVersion >= KAFKA_0_10_1_IV2) 1
diff --git a/core/src/test/scala/unit/kafka/api/ApiVersionTest.scala b/core/src/test/scala/unit/kafka/api/ApiVersionTest.scala
index 1ffa695f48c..3bd86f55483 100644
--- a/core/src/test/scala/unit/kafka/api/ApiVersionTest.scala
+++ b/core/src/test/scala/unit/kafka/api/ApiVersionTest.scala
@@ -17,10 +17,13 @@
 
 package kafka.api
 
+import org.apache.commons.collections.CollectionUtils
 import org.apache.kafka.common.record.RecordVersion
 import org.junit.Test
 import org.junit.Assert._
 
+import scala.collection.JavaConverters
+
 class ApiVersionTest {
 
   @Test
@@ -84,6 +87,21 @@ class ApiVersionTest {
     assertEquals(KAFKA_2_1_IV0, ApiVersion(""2.1-IV0""))
     assertEquals(KAFKA_2_1_IV1, ApiVersion(""2.1-IV1""))
     assertEquals(KAFKA_2_1_IV2, ApiVersion(""2.1-IV2""))
+
+    assertEquals(KAFKA_2_2_IV1, ApiVersion(""2.2""))
+    assertEquals(KAFKA_2_2_IV0, ApiVersion(""2.2-IV0""))
+    assertEquals(KAFKA_2_2_IV1, ApiVersion(""2.2-IV1""))
+  }
+
+  @Test
+  def testApiVersionUniqueIds(): Unit = {
+    val allIds: Seq[Int] = ApiVersion.allVersions.map(apiVersion => {
+      apiVersion.id
+    })
+
+    val uniqueIds: Set[Int] = allIds.toSet
+
+    assertEquals(allIds.size, uniqueIds.size)
   }
 
   @Test
diff --git a/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala b/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala
index cfaa147f407..4b9f656a5a2 100644
--- a/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala
+++ b/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala
@@ -29,7 +29,7 @@ import kafka.server._
 import kafka.utils.{CoreUtils, MockScheduler, MockTime, TestUtils}
 import kafka.zk.KafkaZkClient
 import org.apache.kafka.common.TopicPartition
-import org.apache.kafka.common.errors.ReplicaNotAvailableException
+import org.apache.kafka.common.errors.{ApiException, LeaderNotAvailableException, OffsetNotAvailableException, ReplicaNotAvailableException}
 import org.apache.kafka.common.metrics.Metrics
 import org.apache.kafka.common.protocol.Errors
 import org.apache.kafka.common.record.FileRecords.TimestampAndOffset
@@ -382,6 +382,172 @@ class PartitionTest {
     assertEquals(Optional.of(leaderEpoch), timestampAndOffset.leaderEpoch)
   }
 
+  /**
+    * This test checks that after a new leader election, we don't answer any ListOffsetsRequest until
+    * the HW of the new leader has caught up to its startLogOffset for this epoch. From a client
+    * perspective this helps guarantee monotonic offsets
+    *
+    * @see <a href=""https://cwiki.apache.org/confluence/display/KAFKA/KIP-207%3A+Offsets+returned+by+ListOffsetsResponse+should+be+monotonically+increasing+even+during+a+partition+leader+change"">KIP-207</a>
+    */
+  @Test
+  def testMonotonicOffsetsAfterLeaderChange(): Unit = {
+    val controllerEpoch = 3
+    val leader = brokerId
+    val follower1 = brokerId + 1
+    val follower2 = brokerId + 2
+    val controllerId = brokerId + 3
+    val replicas = List[Integer](leader, follower1, follower2).asJava
+    val isr = List[Integer](leader, follower2).asJava
+    val leaderEpoch = 8
+    val batch1 = TestUtils.records(records = List(
+      new SimpleRecord(10, ""k1"".getBytes, ""v1"".getBytes),
+      new SimpleRecord(11,""k2"".getBytes, ""v2"".getBytes)))
+    val batch2 = TestUtils.records(records = List(new SimpleRecord(""k3"".getBytes, ""v1"".getBytes),
+      new SimpleRecord(20,""k4"".getBytes, ""v2"".getBytes),
+      new SimpleRecord(21,""k5"".getBytes, ""v3"".getBytes)))
+    val batch3 = TestUtils.records(records = List(
+      new SimpleRecord(30,""k6"".getBytes, ""v1"".getBytes),
+      new SimpleRecord(31,""k7"".getBytes, ""v2"".getBytes)))
+
+    val partition = Partition(topicPartition, time, replicaManager)
+    assertTrue(""Expected first makeLeader() to return 'leader changed'"",
+      partition.makeLeader(controllerId, new LeaderAndIsrRequest.PartitionState(controllerEpoch, leader, leaderEpoch, isr, 1, replicas, true), 0))
+    assertEquals(""Current leader epoch"", leaderEpoch, partition.getLeaderEpoch)
+    assertEquals(""ISR"", Set[Integer](leader, follower2), partition.inSyncReplicas.map(_.brokerId))
+
+    // after makeLeader(() call, partition should know about all the replicas
+    val leaderReplica = partition.getReplica(leader).get
+    val follower1Replica = partition.getReplica(follower1).get
+    val follower2Replica = partition.getReplica(follower2).get
+
+    // append records with initial leader epoch
+    val lastOffsetOfFirstBatch = partition.appendRecordsToLeader(batch1, isFromClient = true).lastOffset
+    partition.appendRecordsToLeader(batch2, isFromClient = true)
+    assertEquals(""Expected leader's HW not move"", leaderReplica.logStartOffset, leaderReplica.highWatermark.messageOffset)
+
+    // let the follower in ISR move leader's HW to move further but below LEO
+    def readResult(fetchInfo: FetchDataInfo, leaderReplica: Replica): LogReadResult = {
+      LogReadResult(info = fetchInfo,
+        highWatermark = leaderReplica.highWatermark.messageOffset,
+        leaderLogStartOffset = leaderReplica.logStartOffset,
+        leaderLogEndOffset = leaderReplica.logEndOffset.messageOffset,
+        followerLogStartOffset = 0,
+        fetchTimeMs = time.milliseconds,
+        readSize = 10240,
+        lastStableOffset = None)
+    }
+
+    def fetchOffsetsForTimestamp(timestamp: Long, isolation: Option[IsolationLevel]): Either[ApiException, Option[TimestampAndOffset]] = {
+      try {
+        Right(partition.fetchOffsetForTimestamp(
+          timestamp = timestamp,
+          isolationLevel = isolation,
+          currentLeaderEpoch = Optional.of(partition.getLeaderEpoch),
+          fetchOnlyFromLeader = true
+        ))
+      } catch {
+        case e: ApiException => Left(e)
+      }
+    }
+
+    // Update follower 1
+    partition.updateReplicaLogReadResult(
+      follower1Replica, readResult(FetchDataInfo(LogOffsetMetadata(0), batch1), leaderReplica))
+    partition.updateReplicaLogReadResult(
+      follower1Replica, readResult(FetchDataInfo(LogOffsetMetadata(2), batch2), leaderReplica))
+
+    // Update follower 2
+    partition.updateReplicaLogReadResult(
+      follower2Replica, readResult(FetchDataInfo(LogOffsetMetadata(0), batch1), leaderReplica))
+    partition.updateReplicaLogReadResult(
+      follower2Replica, readResult(FetchDataInfo(LogOffsetMetadata(2), batch2), leaderReplica))
+
+    // At this point, the leader has gotten 5 writes, but followers have only fetched two
+    assertEquals(2, partition.localReplica.get.highWatermark.messageOffset)
+
+    // Get the LEO
+    fetchOffsetsForTimestamp(ListOffsetRequest.LATEST_TIMESTAMP, None) match {
+      case Right(Some(offsetAndTimestamp)) => assertEquals(5, offsetAndTimestamp.offset)
+      case Right(None) => fail(""Should have seen some offsets"")
+      case Left(e) => fail(""Should not have seen an error"")
+    }
+
+    // Get the HW
+    fetchOffsetsForTimestamp(ListOffsetRequest.LATEST_TIMESTAMP, Some(IsolationLevel.READ_UNCOMMITTED)) match {
+      case Right(Some(offsetAndTimestamp)) => assertEquals(2, offsetAndTimestamp.offset)
+      case Right(None) => fail(""Should have seen some offsets"")
+      case Left(e) => fail(""Should not have seen an error"")
+    }
+
+    // Get a offset beyond the HW by timestamp, get a None
+    assertEquals(Right(None), fetchOffsetsForTimestamp(30, Some(IsolationLevel.READ_UNCOMMITTED)))
+
+    // Make into a follower
+    assertTrue(partition.makeFollower(controllerId,
+      new LeaderAndIsrRequest.PartitionState(controllerEpoch, follower2, leaderEpoch + 1, isr, 1, replicas, false), 1))
+
+    // Back to leader, this resets the startLogOffset for this epoch (to 2), we're now in the fault condition
+    assertTrue(partition.makeLeader(controllerId,
+      new LeaderAndIsrRequest.PartitionState(controllerEpoch, leader, leaderEpoch + 2, isr, 1, replicas, false), 2))
+
+    // Try to get offsets as a client
+    fetchOffsetsForTimestamp(ListOffsetRequest.LATEST_TIMESTAMP, Some(IsolationLevel.READ_UNCOMMITTED)) match {
+      case Right(Some(offsetAndTimestamp)) => fail(""Should have failed with OffsetNotAvailable"")
+      case Right(None) => fail(""Should have seen an error"")
+      case Left(e: OffsetNotAvailableException) => // ok
+      case Left(e: ApiException) => fail(s""Expected OffsetNotAvailableException, got $e"")
+    }
+
+    // If request is not from a client, we skip the check
+    fetchOffsetsForTimestamp(ListOffsetRequest.LATEST_TIMESTAMP, None) match {
+      case Right(Some(offsetAndTimestamp)) => assertEquals(5, offsetAndTimestamp.offset)
+      case Right(None) => fail(""Should have seen some offsets"")
+      case Left(e: ApiException) => fail(s""Got ApiException $e"")
+    }
+
+    // If we request the earliest timestamp, we skip the check
+    fetchOffsetsForTimestamp(ListOffsetRequest.EARLIEST_TIMESTAMP, Some(IsolationLevel.READ_UNCOMMITTED)) match {
+      case Right(Some(offsetAndTimestamp)) => assertEquals(0, offsetAndTimestamp.offset)
+      case Right(None) => fail(""Should have seen some offsets"")
+      case Left(e: ApiException) => fail(s""Got ApiException $e"")
+    }
+
+    // If we request an offset by timestamp earlier than the HW, we are ok
+    fetchOffsetsForTimestamp(11, Some(IsolationLevel.READ_UNCOMMITTED)) match {
+      case Right(Some(offsetAndTimestamp)) =>
+        assertEquals(1, offsetAndTimestamp.offset)
+        assertEquals(11, offsetAndTimestamp.timestamp)
+      case Right(None) => fail(""Should have seen some offsets"")
+      case Left(e: ApiException) => fail(s""Got ApiException $e"")
+    }
+
+    // Request an offset by timestamp beyond the HW, get an error now since we're in a bad state
+    fetchOffsetsForTimestamp(100, Some(IsolationLevel.READ_UNCOMMITTED)) match {
+      case Right(Some(offsetAndTimestamp)) => fail(""Should have failed"")
+      case Right(None) => fail(""Should have failed"")
+      case Left(e: OffsetNotAvailableException) => // ok
+      case Left(e: ApiException) => fail(""Should have seen OffsetNotAvailableException, saw $e"")
+    }
+
+
+    // Next fetch from replicas, HW is moved up to 5 (ahead of the LEO)
+    partition.updateReplicaLogReadResult(
+      follower1Replica, readResult(FetchDataInfo(LogOffsetMetadata(5), MemoryRecords.EMPTY), leaderReplica))
+    partition.updateReplicaLogReadResult(
+      follower2Replica, readResult(FetchDataInfo(LogOffsetMetadata(5), MemoryRecords.EMPTY), leaderReplica))
+
+    // Error goes away
+    fetchOffsetsForTimestamp(ListOffsetRequest.LATEST_TIMESTAMP, Some(IsolationLevel.READ_UNCOMMITTED)) match {
+      case Right(Some(offsetAndTimestamp)) => assertEquals(5, offsetAndTimestamp.offset)
+      case Right(None) => fail(""Should have seen some offsets"")
+      case Left(e: ApiException) => fail(s""Got ApiException $e"")
+    }
+
+    // Now we see None instead of an error for out of range timestamp
+    assertEquals(Right(None), fetchOffsetsForTimestamp(100, Some(IsolationLevel.READ_UNCOMMITTED)))
+  }
+
+
   private def setupPartitionWithMocks(leaderEpoch: Int,
                                       isLeader: Boolean,
                                       log: Log = logManager.getOrCreateLog(topicPartition, logConfig)): Partition = {
diff --git a/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala b/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala
index f04c70fbf88..9b4210ed59e 100644
--- a/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala
+++ b/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala
@@ -373,9 +373,13 @@ class KafkaApisTest {
     val isolationLevel = IsolationLevel.READ_UNCOMMITTED
     val currentLeaderEpoch = Optional.of[Integer](15)
 
-    EasyMock.expect(replicaManager.fetchOffsetForTimestamp(tp, ListOffsetRequest.EARLIEST_TIMESTAMP,
-      Some(isolationLevel), currentLeaderEpoch, fetchOnlyFromLeader = true))
-      .andThrow(error.exception)
+    EasyMock.expect(replicaManager.fetchOffsetForTimestamp(
+      EasyMock.eq(tp),
+      EasyMock.eq(ListOffsetRequest.EARLIEST_TIMESTAMP),
+      EasyMock.eq(Some(isolationLevel)),
+      EasyMock.eq(currentLeaderEpoch),
+      fetchOnlyFromLeader = EasyMock.eq(true))
+    ).andThrow(error.exception)
 
     val capturedResponse = expectNoThrottling()
     EasyMock.replay(replicaManager, clientRequestQuotaManager, requestChannel)
@@ -462,9 +466,13 @@ class KafkaApisTest {
     val latestOffset = 15L
     val currentLeaderEpoch = Optional.empty[Integer]()
 
-    EasyMock.expect(replicaManager.fetchOffsetForTimestamp(tp, ListOffsetRequest.LATEST_TIMESTAMP,
-      Some(isolationLevel), currentLeaderEpoch, fetchOnlyFromLeader = true))
-      .andReturn(Some(new TimestampAndOffset(ListOffsetResponse.UNKNOWN_TIMESTAMP, latestOffset, currentLeaderEpoch)))
+    EasyMock.expect(replicaManager.fetchOffsetForTimestamp(
+      EasyMock.eq(tp),
+      EasyMock.eq(ListOffsetRequest.LATEST_TIMESTAMP),
+      EasyMock.eq(Some(isolationLevel)),
+      EasyMock.eq(currentLeaderEpoch),
+      fetchOnlyFromLeader = EasyMock.eq(true))
+    ).andReturn(Some(new TimestampAndOffset(ListOffsetResponse.UNKNOWN_TIMESTAMP, latestOffset, currentLeaderEpoch)))
 
     val capturedResponse = expectNoThrottling()
     EasyMock.replay(replicaManager, clientRequestQuotaManager, requestChannel)


 

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make Kafka 0.8 depend on metrics 2.2.0 instead of 3.x,KAFKA-826,12638970,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,dragosm,nehanarkhede,nehanarkhede,26/Mar/13 05:19,03/Feb/16 07:09,22/Mar/23 15:10,18/Apr/13 12:20,0.8.0,,,,,,0.8.0,,,,,,,core,,,,0,build,kafka-0.8,metrics,,,"In order to mavenize Kafka 0.8, we have to depend on metrics 2.2.0 since metrics 3.x is a huge change as well as not an officially supported release.",,brugidou,clehene,dragosm,githubbot,jjkoshy,junrao,nehanarkhede,nikore,otis,rektide,scott_carey,swapnilghike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-133,KAFKA-833,,,,,,,,,,,,,KAFKA-960,,,,,,,,,,"09/Apr/13 02:05;dragosm;kafka-fix-for-826-complete.patch;https://issues.apache.org/jira/secure/attachment/12577577/kafka-fix-for-826-complete.patch","02/Apr/13 05:07;dragosm;kafka-fix-for-826-take2.patch;https://issues.apache.org/jira/secure/attachment/12576434/kafka-fix-for-826-take2.patch","30/Mar/13 04:36;dragosm;kafka-fix-for-826.patch;https://issues.apache.org/jira/secure/attachment/12576156/kafka-fix-for-826.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,319440,,,Tue Feb 02 23:09:20 UTC 2016,,,,,,,,,,"0|i1j48n:",319781,,,,,,,,,,,,,,,,,,,,"26/Mar/13 05:47;scott_carey;Thank you!  We will be able to test and validate this quickly once there is a patch.

Metrics 3.0.x has hit its first snapshot recently:
https://groups.google.com/forum/#!topic/metrics-user/c4sPUhLjHEQ

However, it looks like it won't be done in time for Kafka 0.8.  It now at least does not conflict  with a copy of 2.2.x as badly as it did a couple months ago.;;;","26/Mar/13 06:36;dragosm;Good to see this pop on your radar screen... I looked at what it would take to move from 3.0.0-c0c8be71 to SNAPSHOT and there were quite a few changes. I've just forked the project, if I make progress I'll send a pull request.;;;","29/Mar/13 02:14;nehanarkhede;We need to remove the dependency on the custom metrics jar in order to mavenize kafka;;;","29/Mar/13 05:39;dragosm;diff --git a/core/lib/metrics-annotation-3.0.0-c0c8be71.jar b/core/lib/metrics-annotation-3.0.0-c0c8be71.jar
deleted file mode 100644
index dba9d2b..0000000
Binary files a/core/lib/metrics-annotation-3.0.0-c0c8be71.jar and /dev/null differ
diff --git a/core/lib/metrics-core-3.0.0-c0c8be71.jar b/core/lib/metrics-core-3.0.0-c0c8be71.jar
deleted file mode 100644
index 529a69b..0000000
Binary files a/core/lib/metrics-core-3.0.0-c0c8be71.jar and /dev/null differ
diff --git a/core/src/main/scala/kafka/cluster/Partition.scala b/core/src/main/scala/kafka/cluster/Partition.scala
index 367ccd5..7788b30 100644
--- a/core/src/main/scala/kafka/cluster/Partition.scala
+++ b/core/src/main/scala/kafka/cluster/Partition.scala
@@ -60,7 +60,7 @@ class Partition(val topic: String,
   newGauge(
     topic + ""-"" + partitionId + ""-UnderReplicated"",
     new Gauge[Int] {
-      def getValue = {
+      def value = {
         if (isUnderReplicated) 1 else 0
       }
     }
diff --git a/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala b/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
index 972d33d..51b9c35 100644
--- a/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
+++ b/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
@@ -653,7 +653,7 @@ private[kafka] class ZookeeperConsumerConnector(val config: ConsumerConfig,
       newGauge(
         config.clientId + ""-"" + config.groupId + ""-"" + topicThreadId._1 + ""-"" + topicThreadId._2 + ""-FetchQueueSize"",
         new Gauge[Int] {
-          def getValue = q.size
+          def value = q.size
         }
       )
     })
diff --git a/core/src/main/scala/kafka/controller/KafkaController.scala b/core/src/main/scala/kafka/controller/KafkaController.scala
index 48eae7e..9c4c8d1 100644
--- a/core/src/main/scala/kafka/controller/KafkaController.scala
+++ b/core/src/main/scala/kafka/controller/KafkaController.scala
@@ -95,7 +95,7 @@ class KafkaController(val config : KafkaConfig, zkClient: ZkClient) extends Logg
   newGauge(
     ""ActiveControllerCount"",
     new Gauge[Int] {
-      def getValue() = if (isActive) 1 else 0
+      def value() = if (isActive) 1 else 0
     }
   )
 
diff --git a/core/src/main/scala/kafka/log/Log.scala b/core/src/main/scala/kafka/log/Log.scala
index 631953f..b7b266e 100644
--- a/core/src/main/scala/kafka/log/Log.scala
+++ b/core/src/main/scala/kafka/log/Log.scala
@@ -77,10 +77,10 @@ class Log(val dir: File,
   debug(""Completed load of log %s with log end offset %d"".format(name, logEndOffset))
 
   newGauge(name + ""-"" + ""NumLogSegments"",
-           new Gauge[Int] { def getValue = numberOfSegments })
+           new Gauge[Int] { def value = numberOfSegments })
 
   newGauge(name + ""-"" + ""LogEndOffset"",
-           new Gauge[Long] { def getValue = logEndOffset })
+           new Gauge[Long] { def value = logEndOffset })
 
   /** The name of this log */
   def name  = dir.getName()
diff --git a/core/src/main/scala/kafka/network/RequestChannel.scala b/core/src/main/scala/kafka/network/RequestChannel.scala
index 209fdfa..c0e0dfc 100644
--- a/core/src/main/scala/kafka/network/RequestChannel.scala
+++ b/core/src/main/scala/kafka/network/RequestChannel.scala
@@ -99,7 +99,7 @@ class RequestChannel(val numProcessors: Int, val queueSize: Int) extends KafkaMe
   newGauge(
     ""RequestQueueSize"",
     new Gauge[Int] {
-      def getValue = requestQueue.size
+      def value = requestQueue.size
     }
   )
 
diff --git a/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala b/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala
index 6691147..090400d 100644
--- a/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala
+++ b/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala
@@ -36,7 +36,7 @@ class ProducerSendThread[K,V](val threadName: String,
 
   newGauge(clientId + ""-ProducerQueueSize"",
           new Gauge[Int] {
-            def getValue = queue.size
+            def value = queue.size
           })
 
   override def run {
diff --git a/core/src/main/scala/kafka/server/AbstractFetcherThread.scala b/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
index a7d39b1..006d573 100644
--- a/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
+++ b/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
@@ -203,7 +203,7 @@ class FetcherLagMetrics(metricId: ClientIdBrokerTopicPartition) extends KafkaMet
   newGauge(
     metricId + ""-ConsumerLag"",
     new Gauge[Long] {
-      def getValue = lagVal.get
+      def value = lagVal.get
     }
   )
 
diff --git a/core/src/main/scala/kafka/server/ReplicaManager.scala b/core/src/main/scala/kafka/server/ReplicaManager.scala
index 765d3cb..e1d5bd8 100644
--- a/core/src/main/scala/kafka/server/ReplicaManager.scala
+++ b/core/src/main/scala/kafka/server/ReplicaManager.scala
@@ -56,19 +56,19 @@ class ReplicaManager(val config: KafkaConfig,
   newGauge(
     ""LeaderCount"",
     new Gauge[Int] {
-      def getValue = leaderPartitions.size
+      def value = leaderPartitions.size
     }
   )
   newGauge(
     ""PartitionCount"",
     new Gauge[Int] {
-      def getValue = allPartitions.size
+      def value = allPartitions.size
     }
   )
   newGauge(
     ""UnderReplicatedPartitions"",
     new Gauge[Int] {
-      def getValue = {
+      def value = {
         leaderPartitionsLock synchronized {
           leaderPartitions.count(_.isUnderReplicated)
         }
diff --git a/core/src/main/scala/kafka/server/RequestPurgatory.scala b/core/src/main/scala/kafka/server/RequestPurgatory.scala
index afe9e22..c064c5c 100644
--- a/core/src/main/scala/kafka/server/RequestPurgatory.scala
+++ b/core/src/main/scala/kafka/server/RequestPurgatory.scala
@@ -72,14 +72,14 @@ abstract class RequestPurgatory[T <: DelayedRequest, R](brokerId: Int = 0, purge
   newGauge(
     ""PurgatorySize"",
     new Gauge[Int] {
-      def getValue = watchersForKey.values.map(_.numRequests).sum + expiredRequestReaper.numRequests
+      def value = watchersForKey.values.map(_.numRequests).sum + expiredRequestReaper.numRequests
     }
   )
 
   newGauge(
     ""NumDelayedRequests"",
     new Gauge[Int] {
-      def getValue = expiredRequestReaper.unsatisfied.get()
+      def value = expiredRequestReaper.unsatisfied.get()
     }
   )
 
diff --git a/core/src/test/scala/unit/kafka/metrics/KafkaTimerTest.scala b/core/src/test/scala/unit/kafka/metrics/KafkaTimerTest.scala
index a3f85cf..fe5bc09 100644
--- a/core/src/test/scala/unit/kafka/metrics/KafkaTimerTest.scala
+++ b/core/src/test/scala/unit/kafka/metrics/KafkaTimerTest.scala
@@ -35,20 +35,20 @@ class KafkaTimerTest extends JUnit3Suite {
     timer.time {
       clock.addMillis(1000)
     }
-    assertEquals(1, metric.getCount())
-    assertTrue((metric.getMax() - 1000).abs <= Double.Epsilon)
-    assertTrue((metric.getMin() - 1000).abs <= Double.Epsilon)
+    assertEquals(1, metric.count())
+    assertTrue((metric.max() - 1000).abs <= Double.Epsilon)
+    assertTrue((metric.min() - 1000).abs <= Double.Epsilon)
   }
 
   private class ManualClock extends Clock {
 
     private var ticksInNanos = 0L
 
-    override def getTick() = {
+    override def tick() = {
       ticksInNanos
     }
 
-    override def getTime() = {
+    override def time() = {
       TimeUnit.NANOSECONDS.toMillis(ticksInNanos)
     }
 
diff --git a/project/Build.scala b/project/Build.scala
index facca79..bc3bc0c 100644
--- a/project/Build.scala
+++ b/project/Build.scala
@@ -17,7 +17,6 @@
 
 import sbt._
 import Keys._
-import java.io.File
 
 import scala.xml.{Node, Elem}
 import scala.xml.transform.{RewriteRule, RuleTransformer}
@@ -35,7 +34,9 @@ object KafkaBuild extends Build {
       ""log4j""                 % ""log4j""        % ""1.2.15"",
       ""net.sf.jopt-simple""    % ""jopt-simple""  % ""3.2"",
       ""org.slf4j""             % ""slf4j-simple"" % ""1.6.4"",
-      ""com.101tec""            % ""zkclient""     % ""0.2""
+      ""com.101tec""            % ""zkclient""     % ""0.2"",
+      ""com.yammer.metrics"" % ""metrics-core"" % ""2.2.0"",
+      ""com.yammer.metrics"" % ""metrics-annotation"" % ""2.2.0""
     ),
     // The issue is going from log4j 1.2.14 to 1.2.15, the developers added some features which required
     // some dependencies on various sun and javax packages.
diff --git a/project/build/KafkaProject.scala b/project/build/KafkaProject.scala
index 1660fb8..853a45c 100644
--- a/project/build/KafkaProject.scala
+++ b/project/build/KafkaProject.scala
@@ -74,7 +74,7 @@ class KafkaProject(info: ProjectInfo) extends ParentProject(info) with IdeaProje
       <dependency>
         <groupId>com.yammer.metrics</groupId>
         <artifactId>metrics-core</artifactId>
-        <version>3.0.0-c0c8be71</version>
+        <version>2.2.0</version>
         <scope>compile</scope>
       </dependency>
 
@@ -82,7 +82,7 @@ class KafkaProject(info: ProjectInfo) extends ParentProject(info) with IdeaProje
       <dependency>
         <groupId>com.yammer.metrics</groupId>
         <artifactId>metrics-annotation</artifactId>
-        <version>3.0.0-c0c8be71</version>
+        <version>2.2.0</version>
         <scope>compile</scope>
       </dependency>
 
;;;","29/Mar/13 07:12;jjkoshy;Thank you for looking into this. Metrics 2.x had a few minor issues with the CsvReporter (which we use in the system tests) and this is why we
used 3.x.

The fixes that I'm aware of are:
- https://github.com/codahale/metrics/pull/225
- https://github.com/codahale/metrics/pull/290
- If a CSV file already exists, metrics throws an IOException and does not resume CSV reporting. This would be the case on a broker bounce for example. Someone put out a patch for this (https://github.com/adagios/metrics/compare/2.x-maintenance...2.x-epoch-in-csv) but I'd have to check if that was pulled into metrics-3.x

Unfortunately, although the above are small fixes, if we want to use the official 2.x metrics release we would need to copy over
the code of the metrics CsvReporter (i.e., into a new implementation of metrics' AbstractReporter), patch in those fixes and plug
that into KafkaMetricsCsvReporter. I don't think it is difficult, but a bit clunky (which is why at the time we preferred using 3.x).
;;;","30/Mar/13 01:26;scott_carey;The only real trouble with 3.0.x is if:
* it conflicts with 2.2.x if in the same classloader
* there is no released artifact in a public maven repo to provide repeatable builds.

We might be able to find out when a 3.0-alpha may be available and pushed to a public maven repo.  It does  not appear that a final version is due out in time.
;;;","30/Mar/13 03:42;swapnilghike;[~dragosm]: Could you upload a patch using the attach files options above? I tried applying your patch using ""patch -p1"", but it could not be applied. Thanks.;;;","30/Mar/13 04:36;dragosm;Alternatively this code is checked into my fork of the project, https://github.com/polymorphic/kafka, the metrics2 branch;;;","30/Mar/13 06:27;swapnilghike;Hi Dragos, I am still not able to cleanly apply the patch. Is it created off 0.8 HEAD? Could you rebase in case it helps? Thanks.

sghike@machine:~/kafka-local/kafka$ patch -p1 --dry-run < ../kafka-fix-for-826.patch 
patching file core/src/main/scala/kafka/cluster/Partition.scala
patching file core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
Hunk #1 succeeded at 650 (offset -3 lines).
patching file core/src/main/scala/kafka/controller/KafkaController.scala
Hunk #1 succeeded at 97 (offset 2 lines).
patching file core/src/main/scala/kafka/log/Log.scala
Hunk #1 succeeded at 130 with fuzz 2 (offset 53 lines).
patching file core/src/main/scala/kafka/network/RequestChannel.scala
patching file core/src/main/scala/kafka/producer/async/ProducerSendThread.scala
patching file core/src/main/scala/kafka/server/AbstractFetcherThread.scala
Hunk #1 succeeded at 195 (offset -8 lines).
patching file core/src/main/scala/kafka/server/ReplicaManager.scala
Hunk #1 FAILED at 56.
1 out of 1 hunk FAILED -- saving rejects to file core/src/main/scala/kafka/server/ReplicaManager.scala.rej
patching file core/src/main/scala/kafka/server/RequestPurgatory.scala
patching file core/src/test/scala/unit/kafka/metrics/KafkaTimerTest.scala
patching file project/Build.scala
Hunk #2 FAILED at 34.
1 out of 2 hunks FAILED -- saving rejects to file project/Build.scala.rej
patching file project/build/KafkaProject.scala
Hunk #1 FAILED at 74.
Hunk #2 FAILED at 82.
2 out of 2 hunks FAILED -- saving rejects to file project/build/KafkaProject.scala.rej;;;","02/Apr/13 04:32;dragosm;Let's try this again, I have another patch ready.;;;","02/Apr/13 04:37;dragosm;diff --git a/core/src/main/scala/kafka/cluster/Partition.scala b/core/src/main/scala/kafka/cluster/Partition.scala
index 2ca7ee6..e49bdae 100644
--- a/core/src/main/scala/kafka/cluster/Partition.scala
+++ b/core/src/main/scala/kafka/cluster/Partition.scala
@@ -60,7 +60,7 @@ class Partition(val topic: String,
   newGauge(
     topic + ""-"" + partitionId + ""-UnderReplicated"",
     new Gauge[Int] {
-      def getValue = {
+      def value = {
         if (isUnderReplicated) 1 else 0
       }
     }
diff --git a/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala b/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
index 9a5fbfe..398618f 100644
--- a/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
+++ b/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
@@ -650,7 +650,7 @@ private[kafka] class ZookeeperConsumerConnector(val config: ConsumerConfig,
       newGauge(
         config.clientId + ""-"" + config.groupId + ""-"" + topicThreadId._1 + ""-"" + topicThreadId._2 + ""-FetchQueueSize"",
         new Gauge[Int] {
-          def getValue = q.size
+          def value = q.size
         }
       )
     })
diff --git a/core/src/main/scala/kafka/controller/KafkaController.scala b/core/src/main/scala/kafka/controller/KafkaController.scala
index 74614d8..5f6eb3c 100644
--- a/core/src/main/scala/kafka/controller/KafkaController.scala
+++ b/core/src/main/scala/kafka/controller/KafkaController.scala
@@ -97,14 +97,14 @@ class KafkaController(val config : KafkaConfig, zkClient: ZkClient) extends Logg
   newGauge(
     ""ActiveControllerCount"",
     new Gauge[Int] {
-      def getValue() = if (isActive) 1 else 0
+      def value() = if (isActive) 1 else 0
     }
   )
 
   newGauge(
     ""OfflinePartitionsCount"",
     new Gauge[Int] {
-      def getValue: Int = {
+      def value(): Int = {
         controllerContext.controllerLock synchronized {
           controllerContext.partitionLeadershipInfo.count(p => !controllerContext.liveBrokerIds.contains(p._2.leaderAndIsr.leader))
         }
diff --git a/core/src/main/scala/kafka/log/Log.scala b/core/src/main/scala/kafka/log/Log.scala
index 7d71451..451775b 100644
--- a/core/src/main/scala/kafka/log/Log.scala
+++ b/core/src/main/scala/kafka/log/Log.scala
@@ -130,10 +130,10 @@ private[kafka] class Log(val dir: File,
   debug(""Completed load of log %s with log end offset %d"".format(name, logEndOffset))
 
   newGauge(name + ""-"" + ""NumLogSegments"",
-           new Gauge[Int] { def getValue = numberOfSegments })
+           new Gauge[Int] { def value = numberOfSegments })
 
   newGauge(name + ""-"" + ""LogEndOffset"",
-           new Gauge[Long] { def getValue = logEndOffset })
+           new Gauge[Long] { def value = logEndOffset })
 
   /* The name of this log */
   def name  = dir.getName()
diff --git a/core/src/main/scala/kafka/network/RequestChannel.scala b/core/src/main/scala/kafka/network/RequestChannel.scala
index 209fdfa..c0e0dfc 100644
--- a/core/src/main/scala/kafka/network/RequestChannel.scala
+++ b/core/src/main/scala/kafka/network/RequestChannel.scala
@@ -99,7 +99,7 @@ class RequestChannel(val numProcessors: Int, val queueSize: Int) extends KafkaMe
   newGauge(
     ""RequestQueueSize"",
     new Gauge[Int] {
-      def getValue = requestQueue.size
+      def value = requestQueue.size
     }
   )
 
diff --git a/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala b/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala
index 6691147..090400d 100644
--- a/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala
+++ b/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala
@@ -36,7 +36,7 @@ class ProducerSendThread[K,V](val threadName: String,
 
   newGauge(clientId + ""-ProducerQueueSize"",
           new Gauge[Int] {
-            def getValue = queue.size
+            def value = queue.size
           })
 
   override def run {
diff --git a/core/src/main/scala/kafka/server/AbstractFetcherThread.scala b/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
index 087979f..2e026e6 100644
--- a/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
+++ b/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
@@ -195,7 +195,7 @@ class FetcherLagMetrics(metricId: ClientIdBrokerTopicPartition) extends KafkaMet
   newGauge(
     metricId + ""-ConsumerLag"",
     new Gauge[Long] {
-      def getValue = lagVal.get
+      def value = lagVal.get
     }
   )
 
diff --git a/core/src/main/scala/kafka/server/ReplicaManager.scala b/core/src/main/scala/kafka/server/ReplicaManager.scala
index 68e712c..44ad562 100644
--- a/core/src/main/scala/kafka/server/ReplicaManager.scala
+++ b/core/src/main/scala/kafka/server/ReplicaManager.scala
@@ -57,7 +57,7 @@ class ReplicaManager(val config: KafkaConfig,
   newGauge(
     ""LeaderCount"",
     new Gauge[Int] {
-      def getValue = {
+      def value = {
         leaderPartitionsLock synchronized {
           leaderPartitions.size
         }
@@ -67,13 +67,13 @@ class ReplicaManager(val config: KafkaConfig,
   newGauge(
     ""PartitionCount"",
     new Gauge[Int] {
-      def getValue = allPartitions.size
+      def value = allPartitions.size
     }
   )
   newGauge(
     ""UnderReplicatedPartitions"",
     new Gauge[Int] {
-      def getValue = {
+      def value = {
         leaderPartitionsLock synchronized {
           leaderPartitions.count(_.isUnderReplicated)
         }
diff --git a/core/src/main/scala/kafka/server/RequestPurgatory.scala b/core/src/main/scala/kafka/server/RequestPurgatory.scala
index afe9e22..c064c5c 100644
--- a/core/src/main/scala/kafka/server/RequestPurgatory.scala
+++ b/core/src/main/scala/kafka/server/RequestPurgatory.scala
@@ -72,14 +72,14 @@ abstract class RequestPurgatory[T <: DelayedRequest, R](brokerId: Int = 0, purge
   newGauge(
     ""PurgatorySize"",
     new Gauge[Int] {
-      def getValue = watchersForKey.values.map(_.numRequests).sum + expiredRequestReaper.numRequests
+      def value = watchersForKey.values.map(_.numRequests).sum + expiredRequestReaper.numRequests
     }
   )
 
   newGauge(
     ""NumDelayedRequests"",
     new Gauge[Int] {
-      def getValue = expiredRequestReaper.unsatisfied.get()
+      def value = expiredRequestReaper.unsatisfied.get()
     }
   )
 
diff --git a/core/src/test/scala/unit/kafka/metrics/KafkaTimerTest.scala b/core/src/test/scala/unit/kafka/metrics/KafkaTimerTest.scala
index a3f85cf..fe5bc09 100644
--- a/core/src/test/scala/unit/kafka/metrics/KafkaTimerTest.scala
+++ b/core/src/test/scala/unit/kafka/metrics/KafkaTimerTest.scala
@@ -35,20 +35,20 @@ class KafkaTimerTest extends JUnit3Suite {
     timer.time {
       clock.addMillis(1000)
     }
-    assertEquals(1, metric.getCount())
-    assertTrue((metric.getMax() - 1000).abs <= Double.Epsilon)
-    assertTrue((metric.getMin() - 1000).abs <= Double.Epsilon)
+    assertEquals(1, metric.count())
+    assertTrue((metric.max() - 1000).abs <= Double.Epsilon)
+    assertTrue((metric.min() - 1000).abs <= Double.Epsilon)
   }
 
   private class ManualClock extends Clock {
 
     private var ticksInNanos = 0L
 
-    override def getTick() = {
+    override def tick() = {
       ticksInNanos
     }
 
-    override def getTime() = {
+    override def time() = {
       TimeUnit.NANOSECONDS.toMillis(ticksInNanos)
     }
 
diff --git a/project/Build.scala b/project/Build.scala
index 4bbdfee..b8b476b 100644
--- a/project/Build.scala
+++ b/project/Build.scala
@@ -17,7 +17,6 @@
 
 import sbt._
 import Keys._
-import java.io.File
 
 import scala.xml.{Node, Elem}
 import scala.xml.transform.{RewriteRule, RuleTransformer}
@@ -34,7 +33,10 @@ object KafkaBuild extends Build {
     libraryDependencies ++= Seq(
       ""log4j""                 % ""log4j""        % ""1.2.15"",
       ""net.sf.jopt-simple""    % ""jopt-simple""  % ""3.2"",
-      ""org.slf4j""             % ""slf4j-simple"" % ""1.6.4""
+      ""org.slf4j""             % ""slf4j-simple"" % ""1.6.4"",
+      ""com.101tec""            % ""zkclient""     % ""0.2"",
+      ""com.yammer.metrics""    % ""metrics-core"" % ""2.2.0"",
+      ""com.yammer.metrics""    % ""metrics-annotation"" % ""2.2.0""
     ),
     // The issue is going from log4j 1.2.14 to 1.2.15, the developers added some features which required
     // some dependencies on various sun and javax packages.
diff --git a/project/build/KafkaProject.scala b/project/build/KafkaProject.scala
index fac723a..853a45c 100644
--- a/project/build/KafkaProject.scala
+++ b/project/build/KafkaProject.scala
@@ -74,7 +74,7 @@ class KafkaProject(info: ProjectInfo) extends ParentProject(info) with IdeaProje
       <dependency>
         <groupId>com.yammer.metrics</groupId>
         <artifactId>metrics-core</artifactId>
-        <version>3.0.0-SNAPSHOT</version>
+        <version>2.2.0</version>
         <scope>compile</scope>
       </dependency>
 
@@ -82,7 +82,7 @@ class KafkaProject(info: ProjectInfo) extends ParentProject(info) with IdeaProje
       <dependency>
         <groupId>com.yammer.metrics</groupId>
         <artifactId>metrics-annotation</artifactId>
-        <version>3.0.0-SNAPSHOT</version>
+        <version>2.2.0</version>
         <scope>compile</scope>
       </dependency>
 
;;;","02/Apr/13 04:39;dragosm;I'm sorry you've had problems with this patch. You should be good to go:

seac02jh0rjdkq4 ~/Repos/kafka% git status                                                                                                                                  [92]
# On branch 0.8
# Untracked files:
#   (use ""git add <file>..."" to include in what will be committed)
#
#	.idea_modules/
nothing added to commit but untracked files present (use ""git add"" to track)
mseac02jh0rjdkq4 ~/Repos/kafka% patch -p1 --dry-run < ../kafka-fix-for-826-take2.patch                                                                                      [93]
patching file core/src/main/scala/kafka/cluster/Partition.scala
patching file core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
patching file core/src/main/scala/kafka/controller/KafkaController.scala
patching file core/src/main/scala/kafka/log/Log.scala
patching file core/src/main/scala/kafka/network/RequestChannel.scala
patching file core/src/main/scala/kafka/producer/async/ProducerSendThread.scala
patching file core/src/main/scala/kafka/server/AbstractFetcherThread.scala
patching file core/src/main/scala/kafka/server/ReplicaManager.scala
patching file core/src/main/scala/kafka/server/RequestPurgatory.scala
patching file core/src/test/scala/unit/kafka/metrics/KafkaTimerTest.scala
patching file project/Build.scala
patching file project/build/KafkaProject.scala;;;","02/Apr/13 04:57;swapnilghike;Hi Dragos, sorry for bugging you again. I think if I copy paste your new patch, I am not able to apply it again. Do you mind attaching it as a file? Thanks for the help Dragos!;;;","02/Apr/13 05:07;dragosm;Here it is, attached. Please LMK if you still have problems.;;;","02/Apr/13 05:15;swapnilghike;The take2 patch applies quite smoothly! Thanks a ton, will check today how it works out.;;;","02/Apr/13 11:21;otis;Ah, what timing!  Metrics 3.0.0 BETA1 has just been pushed to Maven Central with goodies:
Coda Hale <coda.hale@gmail.com> Apr 01 02:02PM -0700  

Metrics 3.0.0-BETA1 is on its way to Maven Central! It includes the following changes:
 
• Total overhaul of most of the core Metrics classes:
• Metric names are now just dotted paths like com.example.Thing, allowing for very flexible scopes, etc.
• Meters and timers no longer have rate or duration units; those are properties of reporters.
• Reporter architecture has been radically simplified, fixing many bugs.
• Histograms and timers can take arbitrary reservoir implementations.
• Added sliding window reservoir implementations.
• Added MetricSet for sets of metrics.
• Changed package names to be OSGi-compatible and added OSGi bundling.
• Extracted JVM instrumentation to metrics-jvm.
• Extracted Jackson integration to metrics-json.
• Removed metrics-guice, metrics-scala, and metrics-spring.
• Renamed metrics-servlet to metrics-servlets.
• Renamed metrics-web to metrics-servlet.
• Renamed metrics-jetty to metrics-jetty8.
• Many more small changes!

Wouldn't it make sense to invest the effort into moving to 3.0.0 instead now?  Otherwise, if the gap between 0.8 and post-0.8 release is as big as the gap between 0.7.2 and 0.8 it will be a while before moving to this new metrics package.
;;;","03/Apr/13 06:35;junrao;Otis,

The reason that we want to downgrade metrics to 2.x is because quite a few people feel this is the most stable version that they can depend on. Do you know how stable is this beta release? Will there be any API or bean name change btw the final 3.x release and this beta release?

In general, do people feel comfortable about using the metrics 3.0 beta release?;;;","03/Apr/13 08:06;swapnilghike;Dragos, thanks for the input. We can definitely use your patch if we decide to downgrade metrics to 2.2.0. Could you please address the following comments and re-submit the patch?

1. Could you move the metrics-core, metrics-annotations and zkclient library dependences to core/build.sbt? You will need to replace the old organization and version number of zkclient there with the one you added to KafkaBuild.
2. Could you append the corresponding paths to class path in bin/kafka-run-class.sh? Also please remove core/lib/*.jar from class path since we are moving the three jars there to ivy.
3. git rm core/lib for the same reason mentioned in 2.

Apart from your patch, we will need to fix the csv reporter separately.;;;","03/Apr/13 11:34;otis;[~junrao] - I'm on the ML for that metrics lib and a few weeks (1-2 months?) ago Coda wrote an email saying he was not happy with a number of things in 2.x that he completely reworked in 3.x.  I don't recall the details, but I recall feeling like 3.x is the version I'd use if I had to pick between 2.x and 3.x.  Unless Kafka 0.8 is going to be released within the next week or two, I'd personally go with 3.x, unless you are open moving from 2.x to 3.x in the near future in 0.8.1.

;;;","04/Apr/13 06:19;scott_carey;My main complaint prior to this was two-fold:

* Early versions of metrics 3.x had classpath collisions with 2.2.x , so we would be unable to have both in the same application and we already use 2.2.
* There was no official version of metrics 3.x published anywhere to consume, no roadmap, and the developer was MIA for months.  Kafka would have had to publish their own artifact version which gets messy fast and would have likely api compatibility issues with any future final metrics 3.0.x release and therefore be very difficult to use kafka 0.8 and the final metrics 3.0 in the same application.

If 3.x is stable enough API wise, I'd be fine with keeping kafka on it.   I believe 3.x no longer collides with 2.2.x in a classpath, but have not tested that recently, meaning we could migrate to 3.x at our own pace and not have to time it to be in sync with use of Kafka 0.8.;;;","04/Apr/13 06:29;scott_carey;Given the volume of work that has been done on metrics 3 between the snapshot on March 12 and the recent BETA1, I am comfortable with it -- a full release is likely to be complete before Kafka 0.8 is through its beta.;;;","04/Apr/13 19:47;brugidou;Yes there has been some work and it breaks when I try to use 3.0.0-BETA1 from 0.8 branch. We need to have a MetricsRegistry (static or injected) and use the new register() method to add gauges/metrics. Also the core namespace has been removed

Anyone working on a patch to get the BETA1 ? (and remove the core/lib/metrics*.jar files? )

By the way I don't think we use metrics-annotation, just metrics-core right?;;;","05/Apr/13 00:07;junrao;I pinged Coda and the following are the answers that I got.

1. How stable is 3.0.0-Beta1?
The code is actually less complicated than Metrics 2 and far better tested: no thread pools, no lifecycles, no static references, just simple objects.

2. Is it true that 3.0.0-Beta1 has no classpath conflict with 2.x? In other words, can an application use both jars in the same JVM?
Many of the classes have changed names and/or packages, but I didn't intend for there to be no classpath conflicts. You might be able to get away with it, but someone somewhere will step on something sharp, I'm sure.

3. Will there be any api change btw 3.0.0-Beta1 and the final 3.0 release?
Probably, yes.

4. Were there any api changes btw 3.0.0-Beta1 and 3.0.0-SNAPSHOT (the one that we are currently using in Kafka 0.8)?
I don't know which snapshot build you're using, but I would imagine there are a lot of changes.

Based on the above, my feeling is that Kafka 0.8 release should use metrics 2.x since (1) it has been stable; (2) people who depend on 2.x have no risk in using Kafka 0.8; (3) the api of 3.x is likely going to change again. In a post 0.8 release, we can upgrade to metrics 3.x when the final version is released and is deemed stable. Any concern with this approach?;;;","05/Apr/13 00:16;dragosm;Thank you Jun for the analysis! From my perspective the approach you suggested is sound. FWIW a couple of weeks ago I ""ported"" the Kafka code to the latest (at the time) metrics 3.0.0 APIs. The code compiled and tests passed, but I don't know the extent that demonstrates that the instrumentation and reporting worked as it should. I'm bringing it up because I feel that once 3.0.0 is released the port is mechanical.;;;","05/Apr/13 00:59;nehanarkhede;I agree with Jun that we should release Kafka 0.8 with metrics 2.x. Let's wait until metrics 3.x APIs are stable.;;;","05/Apr/13 02:47;scott_carey;Sounds good to me. ;;;","05/Apr/13 04:22;nikore;I also like this, allows this to be integrated in with our other metrics we are already collecting under 2.2 and report it all to ganglia. ;;;","05/Apr/13 05:39;swapnilghike;Dragos, it seems like we are headed towards agreeing on using 2.2.0. Do you mind including the review suggestions in your patch? If you are busy, I can finish it up too. Thanks.;;;","06/Apr/13 06:51;dragosm;I'm just starting to work on it, will try to finish it over the weekend.;;;","07/Apr/13 07:28;dragosm;Here's the patch for metrics 2.2.0 with (i) code updates for the metrics API, (ii) build updates to reference zkclient 0.2 and metrics 2.2.0, and (iii) script updates with the appropriate classpaths. I have verified it and all tests pass:


[info] Passed: : Total 175, Failed 0, Errors 0, Passed 175, Skipped 0
[success] Total time: 166 s, completed Apr 6, 2013 4:19:27 PM

Please LMK if you run into problems.;;;","08/Apr/13 15:58;swapnilghike;Thanks, the unit tests were ok. But while trying to boot up a kafka server, I got the following error.

This is what I did, 
rm -rf ~/.ivy2
patch -p1 < kafka-fix-for-826-complete.patch
git rm -r core/lib
./sbt clean
./sbt update
./sbt package
bin/zookeeper-server-start.sh config/zookeeper.properties
bin/kafka-server-start.sh config/server.properties

[2013-04-08 00:48:29,743] FATAL  (kafka.Kafka$)
java.lang.NoClassDefFoundError: com/yammer/metrics/reporting/CsvReporter
	at kafka.metrics.KafkaCSVMetricsReporter.init(KafkaCSVMetricsReporter.scala:53)
	at kafka.metrics.KafkaMetricsReporter$$anonfun$startReporters$1.apply(KafkaMetricsReporter.scala:60)
	at kafka.metrics.KafkaMetricsReporter$$anonfun$startReporters$1.apply(KafkaMetricsReporter.scala:58)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:32)
	at kafka.metrics.KafkaMetricsReporter$.startReporters(KafkaMetricsReporter.scala:58)
	at kafka.Kafka$.main(Kafka.scala:36)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.lang.ClassNotFoundException: com.yammer.metrics.reporting.CsvReporter
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
	... 8 more

I am not currently sure what's causing this issue.;;;","09/Apr/13 02:05;dragosm;Hmm, it looks like for some reason the metrics JARs didn't end up on your CLASSPATH.

Here's the same patch with one additional update that packages the required libraries into a single jar, kafka-assembly-0.8-SNAPSHOT-deps.jar. This change removes ALL references to ~/.ivy2/cache from the script and requires one additional step: execute the ""assembly-package-dependency"" sbt task (provided by the sbt-assembly plugin that was already included).

Here are the steps:

   rm -rf ~/.ivy2/cache/
   find . -name target | xargs rm -rf
   bash sbt update
   bash sbt package
   bash sbt assembly-package-dependency # NEW STEP
   bin/zookeeper-server-start.sh config/zookeeper.properties 
   bin/kafka-server-start.sh config/server.properties

I verified and the server starts up fine. Please LMK if you run into problems.

Here's the output from assembly-package-dependency: 

% bash sbt assembly-package-dependency                                                                                                       
[info] Loading global plugins from /Users/dragos.manolescu/.sbt/plugins
[info] Loading project definition from /Users/dragos.manolescu/Repos/kafka/project
[info] Set current project to Kafka (in build file:/Users/dragos.manolescu/Repos/kafka/)
[info] Including metrics-core-2.2.0.jar
[info] Including scala-compiler.jar
[info] Including zkclient-0.2.jar
[info] Including metrics-annotation-2.2.0.jar
[info] Including snappy-java-1.0.4.1.jar
[info] Including log4j-1.2.15.jar
[info] Including slf4j-api-1.7.2.jar
[info] Including zookeeper-3.3.4.jar
[info] Including jopt-simple-3.2.jar
[info] Including slf4j-simple-1.6.4.jar
[info] Including scala-library.jar
[warn] Merging 'META-INF/NOTICE' with strategy 'rename'
[warn] Merging 'org/xerial/snappy/native/README' with strategy 'rename'
[warn] Merging 'META-INF/maven/org.xerial.snappy/snappy-java/LICENSE' with strategy 'rename'
[warn] Merging 'LICENSE.txt' with strategy 'rename'
[warn] Merging 'META-INF/LICENSE' with strategy 'rename'
[warn] Merging 'META-INF/MANIFEST.MF' with strategy 'discard'
[warn] Strategy 'discard' was applied to a file
[warn] Strategy 'rename' was applied to 5 files
[info] Packaging /Users/dragos.manolescu/Repos/kafka/core/target/scala-2.8.0/kafka-assembly-0.8-SNAPSHOT-deps.jar ...
[info] Done packaging.
[success] Total time: 44 s, completed Apr 8, 2013 10:58:33 AM;;;","09/Apr/13 10:25;scott_carey;Can a committer look at this?  This would be great to get in the 0.8 branch soon and looks good to me. 
I have a cleanup of sbt to significantly simplify it further that I'd like to do as part of KAFKA-854 but it will fail to merge with this change.;;;","09/Apr/13 14:42;nikore;I made my own branch and applyed this patch, in all my testing it seems like its doing great. I would also love to see it committed. ;;;","09/Apr/13 16:16;swapnilghike;Thanks Matt for verifying! This patch works well. Perhaps a committer who is familiar with sbt should take a look. ;;;","10/Apr/13 06:55;nehanarkhede;Thanks a lot for the patches! +1 on the complete patch. In addition to that, I will check in a change that deletes core/lib;;;","10/Apr/13 07:37;dragosm;You're welcome; thank you all for verifying independently.;;;","10/Apr/13 08:13;junrao;Dragos,

Thanks for the patch. It seems that you merged all dependant jars into a fat jar kafka-assembly-0.8-SNAPSHOT-deps.jar. Is it possible to keep individual jars in target/scala-2.8.0? This way, if people want to release the binary, it's clear for them what are the dependant jars and their version.;;;","11/Apr/13 06:13;dragosm;Jun, I understand what you're after. The sbt-assembly task lists the JARs it packages together when executed:

> assembly-package-dependency
[info] Including metrics-core-2.2.0.jar
[info] Including metrics-annotation-2.2.0.jar
[info] Including snappy-java-1.0.4.1.jar
[info] Including slf4j-api-1.7.2.jar
[info] Including log4j-1.2.15.jar
[info] Including zkclient-0.2.jar
[info] Including scala-compiler.jar
[info] Including zookeeper-3.3.4.jar
[info] Including slf4j-simple-1.6.4.jar
[info] Including scala-library.jar
[info] Including jopt-simple-3.2.jar

Following the execution of the update task these JARs will be available from the ivy cache (rather than the target folder, which if my understanding is correct holds only artifacts generated while compiling and building).

I am not aware of a mechanism to have sbt-assembly place the dependencies in the target folder. As plugins like sbt-assembly, sbt-proguard, sbt-onejar and others indicate fat JARs are the typical packaging mechanism for releasing JVM bytecode.;;;","03/Jul/13 21:13;clehene;Now that metrics 3.0 has been released (http://metrics.codahale.com/about/release-notes/) perhaps we should consider upgrading it back?;;;","04/Jul/13 00:55;junrao;Could you file a new jira to track this?;;;","04/Jul/13 01:13;clehene;https://issues.apache.org/jira/browse/KAFKA-960;;;","03/Feb/16 07:09;githubbot;Github user stumped2 closed the pull request at:

    https://github.com/apache/kafka/pull/3
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stop using dashes AND underscores as separators in MBean names,KAFKA-1481,12718028,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,vladimir.tretyakov,otis,otis,03/Jun/14 08:13,19/Mar/15 04:54,22/Mar/23 15:10,20/Nov/14 10:00,0.8.1.1,,,,,,0.8.2.0,0.9.0.0,,,,,,core,,,,0,patch,,,,,"MBeans should not use dashes or underscores as separators because these characters are allowed in hostnames, topics, group and consumer IDs, etc., and these are embedded in MBeans names making it impossible to parse out individual bits from MBeans.

Perhaps a pipe character should be used to avoid the conflict. 

This looks like a major blocker because it means nobody can write Kafka 0.8.x monitoring tools unless they are doing it for themselves AND do not use dashes AND do not use underscores.

See: http://search-hadoop.com/m/4TaT4lonIW",,Bmis13,diederik,guozhang,hakman,jjkoshy,joestein,jonbringhurst,junrao,miguno,nehanarkhede,otis,qwertymaniac,ScottReynolds,vladimir.tretyakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1100,KAFKA-1768,,,,,,,,,"06/Jun/14 18:20;vladimir.tretyakov;KAFKA-1481_2014-06-06_13-06-35.patch;https://issues.apache.org/jira/secure/attachment/12648621/KAFKA-1481_2014-06-06_13-06-35.patch","13/Oct/14 23:28;vladimir.tretyakov;KAFKA-1481_2014-10-13_18-23-35.patch;https://issues.apache.org/jira/secure/attachment/12674516/KAFKA-1481_2014-10-13_18-23-35.patch","15/Oct/14 03:08;vladimir.tretyakov;KAFKA-1481_2014-10-14_21-53-35.patch;https://issues.apache.org/jira/secure/attachment/12674821/KAFKA-1481_2014-10-14_21-53-35.patch","15/Oct/14 15:55;vladimir.tretyakov;KAFKA-1481_2014-10-15_10-23-35.patch;https://issues.apache.org/jira/secure/attachment/12674949/KAFKA-1481_2014-10-15_10-23-35.patch","21/Oct/14 04:31;vladimir.tretyakov;KAFKA-1481_2014-10-20_23-14-35.patch;https://issues.apache.org/jira/secure/attachment/12675934/KAFKA-1481_2014-10-20_23-14-35.patch","21/Oct/14 14:42;vladimir.tretyakov;KAFKA-1481_2014-10-21_09-14-35.patch;https://issues.apache.org/jira/secure/attachment/12676039/KAFKA-1481_2014-10-21_09-14-35.patch","31/Oct/14 02:44;vladimir.tretyakov;KAFKA-1481_2014-10-30_21-35-43.patch;https://issues.apache.org/jira/secure/attachment/12678267/KAFKA-1481_2014-10-30_21-35-43.patch","31/Oct/14 19:14;vladimir.tretyakov;KAFKA-1481_2014-10-31_14-35-43.patch;https://issues.apache.org/jira/secure/attachment/12678454/KAFKA-1481_2014-10-31_14-35-43.patch","03/Nov/14 21:43;vladimir.tretyakov;KAFKA-1481_2014-11-03_16-39-41_doc.patch;https://issues.apache.org/jira/secure/attachment/12678927/KAFKA-1481_2014-11-03_16-39-41_doc.patch","03/Nov/14 22:05;vladimir.tretyakov;KAFKA-1481_2014-11-03_17-02-23.patch;https://issues.apache.org/jira/secure/attachment/12678930/KAFKA-1481_2014-11-03_17-02-23.patch","11/Nov/14 02:14;vladimir.tretyakov;KAFKA-1481_2014-11-10_20-39-41_doc.patch;https://issues.apache.org/jira/secure/attachment/12680615/KAFKA-1481_2014-11-10_20-39-41_doc.patch","11/Nov/14 02:14;vladimir.tretyakov;KAFKA-1481_2014-11-10_21-02-23.patch;https://issues.apache.org/jira/secure/attachment/12680614/KAFKA-1481_2014-11-10_21-02-23.patch","14/Nov/14 21:48;vladimir.tretyakov;KAFKA-1481_2014-11-14_16-33-03.patch;https://issues.apache.org/jira/secure/attachment/12681538/KAFKA-1481_2014-11-14_16-33-03.patch","14/Nov/14 21:48;vladimir.tretyakov;KAFKA-1481_2014-11-14_16-39-41_doc.patch;https://issues.apache.org/jira/secure/attachment/12681539/KAFKA-1481_2014-11-14_16-39-41_doc.patch","17/Nov/14 19:36;vladimir.tretyakov;KAFKA-1481_2014-11-17_14-33-03.patch;https://issues.apache.org/jira/secure/attachment/12681882/KAFKA-1481_2014-11-17_14-33-03.patch","19/Nov/14 21:10;vladimir.tretyakov;KAFKA-1481_2014-11-19_16-03-03_trunk.patch;https://issues.apache.org/jira/secure/attachment/12682416/KAFKA-1481_2014-11-19_16-03-03_trunk.patch","15/Oct/14 03:08;vladimir.tretyakov;KAFKA-1481_IDEA_IDE_2014-10-14_21-53-35.patch;https://issues.apache.org/jira/secure/attachment/12674822/KAFKA-1481_IDEA_IDE_2014-10-14_21-53-35.patch","15/Oct/14 15:55;vladimir.tretyakov;KAFKA-1481_IDEA_IDE_2014-10-15_10-23-35.patch;https://issues.apache.org/jira/secure/attachment/12674948/KAFKA-1481_IDEA_IDE_2014-10-15_10-23-35.patch","21/Oct/14 01:30;vladimir.tretyakov;KAFKA-1481_IDEA_IDE_2014-10-20_20-14-35.patch;https://issues.apache.org/jira/secure/attachment/12675877/KAFKA-1481_IDEA_IDE_2014-10-20_20-14-35.patch","21/Oct/14 04:31;vladimir.tretyakov;KAFKA-1481_IDEA_IDE_2014-10-20_23-14-35.patch;https://issues.apache.org/jira/secure/attachment/12675933/KAFKA-1481_IDEA_IDE_2014-10-20_23-14-35.patch","07/Nov/14 08:02;jjkoshy;alternateLayout1.png;https://issues.apache.org/jira/secure/attachment/12680011/alternateLayout1.png","07/Nov/14 08:02;jjkoshy;alternateLayout2.png;https://issues.apache.org/jira/secure/attachment/12680012/alternateLayout2.png","07/Nov/14 08:02;jjkoshy;diff-for-alternate-layout1.patch;https://issues.apache.org/jira/secure/attachment/12680010/diff-for-alternate-layout1.patch","07/Nov/14 08:02;jjkoshy;diff-for-alternate-layout2.patch;https://issues.apache.org/jira/secure/attachment/12680009/diff-for-alternate-layout2.patch","24/Dec/14 16:43;vladimir.tretyakov;logflushes.png;https://issues.apache.org/jira/secure/attachment/12689019/logflushes.png","07/Nov/14 08:02;jjkoshy;originalLayout.png;https://issues.apache.org/jira/secure/attachment/12680008/originalLayout.png",,26.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,396230,,,Wed Mar 18 20:54:05 UTC 2015,,,,,,,,,,"0|i1w7un:",396353,,jjkoshy,,,,,,,,,,,,,,,,,,"03/Jun/14 08:21;otis;KAFKA-1100 is similar in the sense that it points out a problem with embedding stuff in MBean names that makes it difficult to parse those MBeans.;;;","06/Jun/14 18:19;vladimir.tretyakov;I've made some modifications (cloned 0.8.1 branch), now Kafka use ""|"" instead of ""\-"" or ""\_"" in JMX Bean names where they prevented make parsing (I didn't replace all '\-' and '\_', just replaced in places which were critical for parsing point of view).

I've also noticed that these names Kafka uses not only for JMX Bean names, but for directory names and other things (my changes can be dangerous by this reason). 

I've tested Broker/Producer/Consumer locally, it works, but will be perfect if somebody check everything I am not 100% sure about my changes (I am new in Kafka code).

Best Regards, Vladimir.;;;","20/Jun/14 20:01;otis;Nice and simple patch.  Question about this:
{code}
   def validateChars(prop: String, value: String) {
-    val legalChars = ""[a-zA-Z0-9\\._\\-]""
+    val legalChars = ""[a-zA-Z0-9\\._\\-\\|]
{code}

I didn't check the source code to understand the bigger context, but the above looks like ""|"" is now a valid character, but should it really be valid/allowed?
;;;","20/Jun/14 22:30;junrao;Thanks for the patch. I agree that the current jmx bean names are not ideal. I do have the following concerns.

1. While this may help some users, it may equally affect some other users who now would need to change their parsing of the jmx names.
2. I am not sure how wide-spread the separator issue. If it only helps a small number of users, I'd prefer that we only do that on the new consumer.
3. Other than the separator issue, there are other things that are not ideal. For example, the bean name is just unnecessarily too long. If we do want to change the bean names, perhaps we should fix other problems together as well.
 ;;;","23/Jun/14 19:42;otis;Hi Jun, thanks for having a look.

bq. 1. While this may help some users, it may equally affect some other users who now would need to change their parsing of the jmx names.

Won't they have to do that sooner or later anyway, because dashes as separators obviously can't stay?

bq. 2. I am not sure how wide-spread the separator issue. If it only helps a small number of users, I'd prefer that we only do that on the new consumer.

Nobody knows one way or the other though.  So in absence of info I think it makes sense to at least make a move in the right direction.

bq. Other than the separator issue, there are other things that are not ideal. For example, the bean name is just unnecessarily too long. If we do want to change the bean names, perhaps we should fix other problems together as well.

Long bean names may not be pretty, but they are not blockers.  The dashes are likely blockers for some portion of users and definitely blockers for any Kafka monitoring tool makers.  If long bean names are a problem (are they?) let's open a separate issue, ha?

;;;","11/Aug/14 14:33;otis;Looks like 0.9 has been pushed to December 2014.  Any chance this can go into 0.8.2 then?  It's a blocker for us :(
;;;","11/Aug/14 23:14;junrao;I am wondering if you can get around the problem by just parsing the mbean names a bit differently. For example, for an mbean like the following in which ""topic-1"" is the topic name. When parsing the name part, you can find the last ""-"" to break the name into two parts.

""kafka.server"":type=""BrokerTopicMetrics"",name=""topic-1-BytesInPerSec"";;;","11/Aug/14 23:53;vladimir.tretyakov;Hi Jun Rao, look at http://search-hadoop.com/m/4TaT4lonIW

Example:

kafka.consumer:type=""ZookeeperConsumerConnector"",name=""af_servers-af_servers-spm_new_cluster_topic-af_servers_wawanawna-Dell-1401353748289-fcaaea29-0-FetchQueueSize""

Look at part: ""spm_new_cluster_topic-af_servers_wawanawna-Dell"", what is
host name here ""servers_wawanawna-Dell"" or ""wawanawna-Dell"" ?;;;","12/Aug/14 12:22;junrao;I am not sure exactly what your use cases are, but I was thinking of the following. For the AllTopics metric like below, you can figure out the clientId. Then, you can use that info to parse other beans more reliably.

""kafka.consumer"":type=""ConsumerTopicMetrics"",name=""test-consumer-group-AllTopicsBytesPerSec""

I understand that this is still painful. However, my concern is that this patch may fix the issues for some users, but may force other users to change the way they extract mbeans. ;;;","12/Aug/14 15:01;vladimir.tretyakov;Hi Jun Rao, I understood what you suggest, thx, but I am afraid it will not work everywhere or I've missed something. Look at example from my local env:

1) ""kafka.producer"":type=""ProducerRequestMetrics"",name=""af-servers-AllBrokersProducerRequestRateAndTimeMs""

2) ""kafka.consumer"":type=""ZookeeperConsumerConnector"",name=""af-servers-af-servers-spm-new-cluster-topic-af-servers-wawanawna-Dell-1401353748289-fcaaea29-0-FetchQueueSize""

From 1 I can parse ""af-servers"" as clientId, ok.

From 2 I have to parse: topic ,groupId, consumer host, timestamp, uuid, num_streams.

If I remove ""af-servers"" from 2 I will get ""spm-new-cluster-topic-af-servers-wawanawna-Dell-1401353748289-fcaaea29-0-FetchQueueSize"".

I can extract ""timestamp, uuid, num_streams"" without problems, now let me talk about this part ""spm-new-cluster-topic-af-servers-wawanawna-Dell"" I see ""af-servers""  in the middle but can I be sure that ""clientId"" will be always here?

Why initial bean name contains ""af-servers"" 3 times? I have a feeling sometimes all these 3 parts may be different and I will not able to parse everything in right way. 

It is painful in general as you mentioned above because we have to remember ""context"" for parse each line, I am pretty sure nobody like it.
Even if somebody parse names in way you have described I think they will glad to change its parse mechanism with  more easiest.;;;","12/Aug/14 15:10;joestein;[~junrao] If this patch is going to cause existing users that are not having a problem issues and it is causing existing users issues by not patching it then can we introduce a configuration so we can accommodate both (default to how it is working now)? Then we can get it in 0.8.2. Thoughts?;;;","12/Aug/14 23:13;junrao;The name of ""FetchQueueSize"" is of the following format. If the clientId is not explicitly specified, the groupId will be used. So if you know the clientId, you can parse the rest of the string. You probably don't need to figure out every part of the mbean name. The most important ones are clientId, groupId and topic. 

config.clientId + ""-"" + config.groupId + ""-"" + topicThreadId._1 + ""-"" + topicThreadId._2 + ""-FetchQueueSize""

Joe,

I am not sure having a config is necessarily better. If we want to fix the mbean names, I'd rather that we fix them once into the end state that we want, instead of patching little by little and changing the names multiple times.;;;","28/Aug/14 18:30;otis;bq. if you know the clientId, you can parse the rest of the string. 

I think this makes parsers unnecessarily difficult to write and probably harder to maintain.  Parsers have to remember things this way.

bq. If this patch is going to cause existing users that are not having a problem issues 

I think it won't cause them issues.  I *think* they would just need to change which delimiter character they use to break MBean names into parts.

bq. If it is causing existing users issues by not patching it

I think it is causing issues to anyone who has any of the multiple characters Kafka uses as delimiters in their hostnames or topic names.  So I think these people have issues when they first try parsing stuff from JMX, and then they have to go modify their hostnames, topic names and such.
;;;","05/Sep/14 05:47;guozhang;[~junrao] do you think we can check in this ticket in time for 0.8.2?;;;","10/Sep/14 09:38;otis;Here is a Kafka user who said:

{quote}
 I have topic name with “.”  So, it is hard to distinguish metric name and topic
{quote}
c.f. http://search-hadoop.com/m/4TaT4IRD0t1

That's the sort of problem this patch solves.;;;","12/Sep/14 11:51;nehanarkhede;This issue has popped up enough times on the mailing list that we should pay attention to it and fix it. [~junrao], what plan would you suggest for fixing this so that the change works for everyone?;;;","15/Sep/14 23:54;junrao;Ok, I am fine with taking this patch as a stop-gap solution. Since this is going to affect how people monitor Kafka, we probably should have a discussion in the mailing list.

Otis/Vladimir,
Do you want to start a discussion thread in our dev and user mailing list that describes the problem, the solution and the impact? If there are no serious concerns, we can commit the patch.

Thanks,;;;","23/Sep/14 01:40;otis;This is [~junrao]'s new suggestion for dealing with the problem this issue is meant to address: http://search-hadoop.com/m/4TaT4aHH1S;;;","13/Oct/14 23:28;vladimir.tretyakov;Added another patch which introduce metrics name like pairs (key=value), examples:
{code}
""kafka.consumer"":type=""ConsumerTopicMetrics"",name=""clientId=af_servers,AllTopics,BytesPerSec""
""kafka.cluster"":type=""Partition"",name=""topic=spm_alerts_topic,partitionId=0,UnderReplicated""
""kafka.network"":type=""SocketServer"",name=""NetworkProcessorNum=1,IdlePercent""
""kafka.server"":type=""BrokerTopicMetrics"",name=""topic=spm_topic,MessagesInPerSec""

""kafka.server"":type=""FetcherStats"",name=""clientId=af_servers,ConsumerFetcherThread,groupId=af_servers,consumerHostName=wawanawna,timestamp=1413199781501,uuid=58a5cc70,fetcherId=0,sourceBrokerId=0,brokerHost=wawanawna,brokerPort=9092,BytesPerSec""
""kafka.server"":type=""FetcherLagMetrics"",name=""clientId=af_servers,ConsumerFetcherThread,groupId=af_servers,consumerHostName=wawanawna,timestamp=1413199781501,uuid=58a5cc70,fetcherId=0,sourceBrokerId=0,brokerHost=wawanawna,brokerPort=9092,topic=spm_topic,partitionId=0,ConsumerLag""
""kafka.consumer"":type=""FetchRequestAndResponseMetrics"",name=""clientId=af_servers,ConsumerFetcherThread,groupId=af_servers,consumerHostName=wawanawna,timestamp=1413199781501,uuid=58a5cc70,fetcherId=0,sourceBrokerId=0,brokerHost=wawanawna,brokerPort=9092,FetchResponseSize""
{code};;;","14/Oct/14 08:10;junrao;Vladimir,

Thanks for the patch. My suggestion is actually slightly different from what you did. Instead of using

""kafka.consumer"":type=""ConsumerTopicMetrics"",name=""clientId=af_servers,AllTopics,BytesPerSec""

I was suggesting

""kafka.consumer"":type=""ConsumerTopicMetrics"",clientId=""af_servers"",topic=""AllTopics"",name=""BytesPerSec""

This is probably the more standard mbean name.

We can do that by using the following method to create MetricName and pass in the mBeanName that we want.
    public MetricName(String group, String type, String name, String scope, String mBeanName).

We also need to extend KafkaMetricsGroup by adding new helper functions that take a MetricName explicitly.
  def newMeter(name: MetricName, eventType: String, timeUnit: TimeUnit)

Also, your patch doesn't seem to apply to latest trunk.
git apply ~/Downloads/KAFKA-1481_2014-10-13_18-23-35.patch 
error: core/src/main/scala/kafka/common/ClientIdTopic.scala: No such file or directory



;;;","15/Oct/14 03:07;vladimir.tretyakov;Hi, Jun, 

Thx that you found a time to look at patch, I've added another regarding your suggestion, now in JMX you will see (hope it is what you need):
{code}
""kafka.server"":type=""FetcherStats"",name=""RequestsPerSec"",clientId=""af_servers"",threadName=""ConsumerFetcherThread"",groupId=""af_servers"",consumerHostName=""wawanawna"",timestamp=""1413306414731"",uuid=""4624cb0f"",fetcherId=""0"",sourceBrokerId=""0"",brokerHost=""wawanawna"",brokerPort=""9092""
""kafka.server"":type=""FetcherLagMetrics"",name=""ConsumerLag"",clientId=""af_servers"",threadName=""ConsumerFetcherThread"",groupId=""af_servers"",consumerHostName=""wawanawna"",timestamp=""1413306414731"",uuid=""4624cb0f"",fetcherId=""0"",sourceBrokerId=""0"",brokerHost=""wawanawna"",brokerPort=""9092"",topic=""spm_topic"",partitionId=""0""
""kafka.consumer"":type=""ZookeeperConsumerConnector"",name=""OwnedPartitionsCount"",clientId=""af_servers"",groupId=""af_servers"",topic=""spm_topic""
""kafka.consumer"":type=""FetchRequestAndResponseMetrics"",name=""FetchResponseSize"",clientId=""af_servers"",threadName=""ConsumerFetcherThread"",groupId=""af_servers"",consumerHostName=""wawanawna"",timestamp=""1413306414731"",uuid=""4624cb0f"",fetcherId=""0"",sourceBrokerId=""0"",allBrokers=""true""
{code}

{quote}
Also, your patch doesn't seem to apply to latest trunk.
git apply ~/Downloads/KAFKA-1481_2014-10-13_18-23-35.patch 
error: core/src/main/scala/kafka/common/ClientIdTopic.scala: No such file or directory
{quote}
Interesting...
1. I've worked with 0.8.2 branch, not trunk
2. ClientIdTopic.scala - I've added this file (must be in patch). 

Added 2 equal patches (created them in different way):
1. 'git diff' (KAFKA-1481_2014-10-14_21-53-35.patch)
2. With help from IDEA IDE. (KAFKA-1481_IDEA_IDE_2014-10-14_21-53-35.patch)

Try please, maybe one of them will work

Thx again.
;;;","15/Oct/14 16:00;vladimir.tretyakov;Added 2 patches (created with git diff and from IDEA IDE) with a small refactoring in KafkaMetricsGroup.

Jun can you please double check and change part related to metrics removing (KAFKA-1567) I can't easily test this code locally, thx a lot.

PS: all tests passed after this patch for me locally.;;;","16/Oct/14 07:50;junrao;Thanks for the patch. The IDEA one applies successfully for me. However, it seems to cause compilation failure since in a few cases, two lines are incorrectly merged into a single one. Do you think you can try our patch review tool (https://cwiki.apache.org/confluence/display/KAFKA/Patch+submission+and+review)? Some comments.

1. KafkaMetricsGroup:
1.1 We now have 2
       new MetricName(""kafka.consumer"", ""ConsumerTopicMetrics"", ""MessagesPerSec""),
    and 2
       new MetricName(""kafka.consumer"", ""ConsumerTopicMetrics"", ""BytesPerSec""),
1.2 Could we combine the following two methods
  def newGauge[T](name: String, mBeanName: String, metric: Gauge[T])
 
  def newGauge[T](name: String, metric: Gauge[T]) : Gauge[T]
 
  to
  def newGauge[T](name: String, metric: Gauge[T], tags: Map[String, String] = Map.empty)? We can then general the metric name based on name and the tags. This will consolidate the metric name generation in a single place. In this patch, we have too many places generating the key/value string for the metric name.

2. AbstractFetcherThread: 
2.1 name in this class should be just used for the thread name and it shouldn't be included in the metric name.
2.2. The way that we get the metric name in classes like ClientIdAndBroker, ClientIdBrokerTopicPartition and ClientIdAndTopic is not consistently. Sometimes, we generate the key/value in the toString(). Some other times, we rely on the key/value string to be passed in. It's easier to understand if those classes are constructed by just passing in the clientId string, the broker object, the topic string and the partition number, etc. We can generate the metric name by using what's described in 1.2.
2.3 FetcherLagStats just needs to take clientId, instead of ClientIdAndBroker since the per partition lag metric is unique per client id.
2.4 The metric name for a Broker can just use the brokerId, instead of its host and port.

3. Throttler: Do we need to add mBeanName to the constructor? It seems that nobody is using it at the moment.

4. KafkaMetricsGroup: We need to change the way how removeAllMetricsInList() works. We need to do equal comparison on group, type and name and do regex matching with clientId on MetricName.mBeanName.
;;;","16/Oct/14 14:26;vladimir.tretyakov;Hi Jun, thx for juicy feedback, few comments fro me:

1-2. Did it in this way because I didn't want to change existing code a lot, tried got what we need based on current method signatures. I've thought about your approach with Map too, reject it because of larger changes. Now I see that I will do it.

3. Removed 'mBeanName' param, was legacy code.
4. As I've understood from code this method must be called before shutdown in hook, right? We have to remove only metrics related to particular clientId and we shouldn't touch others, right?;;;","16/Oct/14 22:16;junrao;4. removeAllMetricsInList() will be called when a producer/consumer instance is closed to remove metrics related to a specific client id.;;;","21/Oct/14 01:29;vladimir.tretyakov;Hi, fuf:), created new patch (for 0.8.2 branch).

re 2.1, 2.3 - didn't change this part because we use this part in our monitoring, it is more handy for user to see something like 'localhost:9092' instead of '2 (where 2 is broker id)'. For us it is easiest to see/have this information directly in mBean.

With this patch mBeanNames look like:
{code}
kafka.producer:type=ProducerTopicMetrics,name=MessagesPerSec,topic=spm_alerts_topic
kafka.producer:type=ProducerTopicMetrics,name=MessagesPerSec,allTopics=true
kafka.log:type=Log,name=LogEndOffset,topic=spm_alerts_topic,partitionId=0
kafka.consumer:type=ZookeeperConsumerConnector,name=FetchQueueSize,timestamp=1413817796508,clientId=af_servers,uuid=9f99df40,groupId=af_servers,topicThreadId=spm_topic,consumerHostName=wawanawna,threadId=0
kafka.consumer:type=FetchRequestAndResponseMetrics,name=FetchRequestRateAndTimeMs,clientId=af_servers,threadName=ConsumerFetcherThread,fetcherId=0,sourceBrokerId=0,groupId=af_servers,consumerHostName=wawanawna,timestamp=1413817796508,uuid=9f99df40,brokerHost=wawanawna,brokerPort=9092
{code}

There is not everything clear for me in code, so I've tried to avoid deep refactoring. All tests passed for me locally.

PS: note that if 'value' part is empty (in key->value structure) we will not see this part in attributes.
example: ""key1""->""value1"",""key2""->null,""key3""->""value3"" will be converted to ""key1=value1,key3=value3"".





;;;","21/Oct/14 02:24;junrao;Thanks for the patch. It doesn't seem to apply. Could you rebase?

git apply -p0 ~/Downloads/KAFKA-1481_IDEA_IDE_2014-10-20_20-14-35.patch 
error: core/src/main/scala/kafka/common/ClientIdTopic.scala: No such file or directory
error: patch failed: core/src/main/scala/kafka/server/KafkaApis.scala:285
error: core/src/main/scala/kafka/server/KafkaApis.scala: patch does not apply
error: patch failed: core/src/test/scala/integration/kafka/api/ProducerCompressionTest.scala:74
error: core/src/test/scala/integration/kafka/api/ProducerCompressionTest.scala: patch does not apply
error: patch failed: core/src/main/scala/kafka/consumer/PartitionAssignor.scala:101
error: core/src/main/scala/kafka/consumer/PartitionAssignor.scala: patch does not apply
error: patch failed: core/src/test/scala/integration/kafka/api/ProducerFailureHandlingTest.scala:17
error: core/src/test/scala/integration/kafka/api/ProducerFailureHandlingTest.scala: patch does not apply;;;","21/Oct/14 04:30;vladimir.tretyakov;Hi, thx for quick reply, did rebase, added new patches (1 was created by git, 1 by IDEA IDE).;;;","21/Oct/14 08:38;junrao;It still doesn't apply.

git apply -p0 ~/Downloads/KAFKA-1481_IDEA_IDE_2014-10-20_23-14-35.patch 
/Users/junrao/Downloads/KAFKA-1481_IDEA_IDE_2014-10-20_23-14-35.patch:311: trailing whitespace.
           })  
error: core/src/main/scala/kafka/common/TopicInfo.scala: No such file or directory

Does the patch apply on a fresh checkout for you?;;;","21/Oct/14 14:48;vladimir.tretyakov;Hi, added last patch (KAFKA-1481_2014-10-21_09-14-35.patch). Worked for me locally (previous worked too:( ).
There are commands I've used:
{code}
PATCH CREATION
wawanawna@wawanawna:/home/storage/sematext/src/kfk2/kafka$ git status
On branch 0.8.2
Your branch is up-to-date with 'origin/0.8.2'.

Changes to be committed:
  (use ""git reset HEAD <file>..."" to unstage)

	new file:   core/src/main/scala/kafka/common/BrokerInfo.scala
	new file:   core/src/main/scala/kafka/common/ClientIdTopic.scala
	new file:   core/src/main/scala/kafka/common/Taggable.scala
	renamed:    core/src/main/scala/kafka/common/ClientIdAndTopic.scala -> core/src/main/scala/kafka/common/TopicInfo.scala
	new file:   core/src/main/scala/kafka/consumer/ConsumerFetcherThreadId.scala
	new file:   core/src/main/scala/kafka/consumer/ConsumerId.scala

Changes not staged for commit:
  (use ""git add <file>..."" to update what will be committed)
  (use ""git checkout -- <file>..."" to discard changes in working directory)

	modified:   core/src/main/scala/kafka/admin/AdminUtils.scala
	modified:   core/src/main/scala/kafka/api/HeartbeatRequestAndHeader.scala
	modified:   core/src/main/scala/kafka/api/HeartbeatResponseAndHeader.scala
	modified:   core/src/main/scala/kafka/api/JoinGroupRequestAndHeader.scala
	modified:   core/src/main/scala/kafka/api/JoinGroupResponseAndHeader.scala
	modified:   core/src/main/scala/kafka/api/RequestKeys.scala
	modified:   core/src/main/scala/kafka/cluster/Partition.scala
...
...
...
wawanawna@wawanawna:/home/storage/sematext/src/kfk2/kafka$ git commit -a -m 'kafka-1481; JMX renaming'
[0.8.2 a232af6] kafka-1481; JMX renaming
 73 files changed, 666 insertions(+), 435 deletions(-)
 create mode 100644 core/src/main/scala/kafka/common/BrokerInfo.scala
 create mode 100644 core/src/main/scala/kafka/common/ClientIdTopic.scala
 create mode 100644 core/src/main/scala/kafka/common/Taggable.scala
 rename core/src/main/scala/kafka/common/{ClientIdAndTopic.scala => TopicInfo.scala} (68%)
 create mode 100644 core/src/main/scala/kafka/consumer/ConsumerFetcherThreadId.scala
 create mode 100644 core/src/main/scala/kafka/consumer/ConsumerId.scala
wawanawna@wawanawna:/home/storage/sematext/src/kfk2/kafka$ git log | head -n 20
commit a232af63b8a1f43054994a74520b31ef7b9b347c
Author: wawanawna <sematex@mail.com>
Date:   Tue Oct 21 09:29:31 2014 +0300

    kafka-1481; JMX renaming

commit eb7ac9eb7eebc4e0655b65e07cae594e61a6c05e
Author: Jun Rao <junrao@gmail.com>
Date:   Mon Oct 20 11:09:31 2014 -0700

    kafka-1717; remove netty dependency through ZK 3.4.x; patched by Jun Rao; reviewed by Sriharsha Chintalapani and Neha Narkhede


wawanawna@wawanawna:/home/storage/sematext/src/kfk2/kafka$ git diff eb7ac9eb7eebc4e0655b65e07cae594e61a6c05e a232af63b8a1f43054994a74520b31ef7b9b347c > /tmp/KAFKA-1481_2014-10-21_09-14-35.patch

PATCH APPLYING

wawanawna@wawanawna:/home/storage/sematext/src/kfk3$ git clone https://github.com/apache/kafka.git


wawanawna@wawanawna:/home/storage/sematext/src/kfk3/kafka$ git checkout -b 0.8.2 origin/0.8.2
Branch 0.8.2 set up to track remote branch 0.8.2 from origin.
Switched to a new branch '0.8.2'


wawanawna@wawanawna:/home/storage/sematext/src/kfk3/kafka$ git apply /tmp/KAFKA-1481_2014-10-21_09-14-35.patch
/tmp/KAFKA-1481_2014-10-21_09-14-35.patch:1410: trailing whitespace.
           })  
warning: 1 line adds whitespace errors.
{code}

There is warning, but everything works (compilation/tests passed without errors)

PS: please tell me what I am doing wrong.
wawanawna@wawanawna:/home/storage/sematext/src/kfk3/kafka$ git --version
git version 1.9.1
;;;","22/Oct/14 00:28;otis;[~joestump] can we pleeeeeease have this back in 0.8.2?  The patch is ready, just needs to be merged in.  We've been working very, very hard to get this into 0.8.2.;;;","22/Oct/14 01:53;junrao;Otis,

Yes, we can include this in the 0.8.2 final release. Does that sound good? Thanks,;;;","22/Oct/14 02:42;vladimir.tretyakov;Hi, Jun, will be perfect!;;;","22/Oct/14 04:57;Bmis13;Hi [~junrao],

Can you please let me know if this will also address the [New Java Producer] metrics() method and which client.id or topic has special chars ?  So we have consistent naming across all JMX name bean or metrics() methods ?

Here is background on this:

{code}
Bhavesh,

Yes, allowing dot in clientId and topic makes it a bit harder to define the
JMX bean names. I see a couple of solutions here.

1. Disable dot in clientId and topic names. The issue is that dot may
already be used in existing deployment.

2. We can represent the JMX bean name differently in the new producer.
Instead of
  kafka.producer.myclientid:type=mytopic
we could change it to
  kafka.producer:clientId=myclientid,topic=mytopic

I felt that option 2 is probably better since it doesn't affect existing
users.

Otis,

We probably can also use option 2 to address KAFKA-1481. For topic/clientid
specific metrics, we could explicitly specify the metric name so that it
contains ""topic=mytopic,clientid=myclientid"". That seems to be a much
cleaner way than having all parts included in a single string separated by
'|'.

Thanks,

Jun
{code}

Thanks,

Bhavesh ;;;","22/Oct/14 05:08;junrao;Thanks for the patch. Some comments below.

20. KafkaMetricsGroup:
20.1 In the following, instead of doing map(kv => ), could we do map { case(key, value) => }?
        .filter(_._2 != """").map(kv => ""%s=%s"".format(kv._1, kv._2))
20.2 In the following, shouldn't the pattern be ("".*"" + ""clientId="" + clientId + "".*"").r
      val pattern = ("".*"" + clientId + "".*"").r

21. TaggableInfo: tags should be an immutable hashmap, right?
case class TaggableInfo(tags: mutable.LinkedHashMap[String, String]) extends Taggable {

22. New files:
22.1 The license header should be at the very beginning, before the package and import.
22.2 I am not sure if we really need to have the Taggable trait. For example, in ConsumerTopicMetrics, we can just take the original clientIdAndTopic and explicitly create the tag for clientId and topic when creating those metrics. The tags are really specific to the metrics. So, we probably don't need to expose them in places other than where the metrics are created.

23. ReplicaFetcherManager: The first statement in shutdown() is on the same line as the method. A similar issue happens in a few other classes like RequestChannel and ConsumerFetcherManager. Perhaps you can follow the patch creation process in https://cwiki.apache.org/confluence/display/KAFKA/Patch+submission+and+review#Patchsubmissionandreview-Simplecontributorworkflow

24. FetchRequestAndResponseStatsRegistry.removeConsumerFetchRequestAndResponseStats(): Should we use ""clientId="" + clientId in pattern?

25. SimpleConsumer: Ideally, we shouldn't change the constructor since this will be an api change.

26. Could you add a unit test to make sure that after a producer/consumer is closed, all metrics specific to the producer/consumer are removed?;;;","22/Oct/14 05:22;junrao;Bhavesh,

Created a subtask to track the metric name in the new producer. Thanks,;;;","22/Oct/14 22:08;otis;[~junrao] - in interest of getting this into 0.8.2 can we please just make sure the MBeans look good ""on the outside"", commit that, and then iterate on improving the internals?;;;","22/Oct/14 23:34;junrao;Otis,

I expect that we will have about another 4 weeks before 0.8.2 final is released. That should give us enough time to iterate on this, right? Since the patch touches many files, I'd prefer that we get a clean version upfront.;;;","24/Oct/14 19:05;vladimir.tretyakov;Hi Jun, thx for your feedback again, attached new patch.

20.1 done.
20.2 ""clientId"" is ""Taggable"" here, it will convert to something like ""clientId=XXX"" automatically
21 tags should be Map which iterators iterate in the same order elements were inserted (final string must be stable): from LinkedHashMap docs ""The iterator and all traversal methods of this class visit elements in the order they were inserted."". I am new in scala, if you know better candidate with predictable iterators please let me know
22.1 done
22.2 clientId is not always just ""clientId=XXX"", look at:
{code}
class ConsumerFetcherThread(consumerFetcherThreadId: ConsumerFetcherThreadId,
                            val config: ConsumerConfig,
                            sourceBroker: Broker,
                            partitionMap: Map[TopicAndPartition, PartitionTopicInfo],
                            val consumerFetcherManager: ConsumerFetcherManager)
        extends AbstractFetcherThread(name = consumerFetcherThreadId,
                                      clientId = new TaggableInfo(new TaggableInfo(""clientId"" -> config.clientId), consumerFetcherThreadId),  
                                      sourceBroker = sourceBroker,
                                      socketTimeout = config.socketTimeoutMs,
                                      socketBufferSize = config.socketReceiveBufferBytes,
                                      fetchSize = config.fetchMessageMaxBytes,
                                      fetcherBrokerId = Request.OrdinaryConsumerId,
                                      maxWait = config.fetchWaitMaxMs,
                                      minBytes = config.fetchMinBytes,
                                      isInterruptible = true) {
{code}


this ""clientId = new TaggableInfo(new TaggableInfo(""clientId"" -> config.clientId), consumerFetcherThreadId)"" part was in code before my changes (was manipulation with strings, not ""Taggable"" of course). Yeah, somewhere in code we can use string instead of ""Taggable"", but maybe it is better to has ""Taggable"" everywhere what is related to metrics. At least it was not easy to me decide where I have to use ""Taggable"", but where I can leave string. I'd prefer ""Taggable"" everywhere in this case, sorry:).

23. done everything as described by link, checked how it works/applies on 'origin/0.8.2' from scratch.
24. see 22.2
25. agree, added second constructor with 'String' as clientId, can't remove constructor with ""Taggable"" as clientId because as you can see in 22.2 sometimes clientId is not just ""clientId"" but something more complex.
26. added 'MetricsLeakTest', basic idea is start/stop many producers/consumes and observe count of metrics in Metrics.defaultRegistry(), count should not grow.;;;","28/Oct/14 08:35;junrao;Vladimir,

Thanks for the patch. Really appreciate your help. I realized that this is one of the biggest technical debt that we have accumulated over time. So, it may take some time to sort this out. So, bear with me. Some more comments.

30. About Taggable, I still have mixed feelings. I can see why you created it. However, my reasoning is that for a lot of the case classes (ClientIdTopic, CliendIdAndBroker) that we create, it's weird that some of them are taggable and some of them are not, depending whether they are used for tagging metric names or not. Those classes have no direct relationships with the metrics. Similarly, we only need to be aware of tags when creating metrics. Also, because of this, we change the constructor of SimpleConsumer. Since this is an API change, we should really try to avoid it. 

My feeling is that it's probably simpler if we just create regular case classes as before and generate metric tags explicitly when we create the metric. For example, in AbstractFetcherThread, we can do

class FetcherStats(clientIdAndBroker: ClientIdAndBroker) extends KafkaMetricsGroup {
  val requestRate = newMeter(""RequestsPerSec"", ""requests"", TimeUnit.SECONDS,
                                                Map(""cliendId"" -> clientIdAndBroker.clientId,
                                                        ""brokerHost"" -> clientIdAndBroker.host,
                                                        ""brokerPort"" -> clientIdAndBroker.port))

and just have ClientIdAndBroker be the following case class.

case class ClientIdAndBroker(clientId: String, host: String, port: Int)

This way, the code is a bit cleaner since all the metric tag related stuff are isolated to those places when the metrics are created. So, I'd suggest that we remove Taggable.

31. AbstractFetcherThread:
31.1 You changed the meaning of clientId. clientId is used in the fetch request and we want to leave it as just the clientId string. Since the clientId should be uniquely representing a particular consumer client, we just need to include the clientId in the metric name. We don't need to include the consumer id in either the fetch request or the metric name since it's too long and has redundant info. 
31.2 FetcherLagStats: This is an existing problem. FetcherLagMetrics shouldn't be keyed off ClientIdBrokerTopicPartition. It should be keyed off ClientIdTopicPartition. This way, the metric name remains the same independent of the current leader of those partitions.

32. ZookeeperConsumerConnector:
32.1 FetchQueueSize: I agree that the metric name just needs to be tagged with clientId, topic and threadId. We don't need to include the consumerId since it's too long (note that topicThread._2 includes both the consumerId and the threadId).

33. KafkaMetricsGroup: Duplicate entries.
    // kafka.consumer.ConsumerTopicStats <-- kafka.consumer.{ConsumerIterator, PartitionTopicInfo}
    explicitMetricName(""kafka.consumer"", ""ConsumerTopicMetrics"", ""MessagesPerSec""),
    explicitMetricName(""kafka.consumer"", ""ConsumerTopicMetrics"", ""MessagesPerSec""),

    // kafka.consumer.ConsumerTopicStats
    explicitMetricName(""kafka.consumer"", ""ConsumerTopicMetrics"", ""BytesPerSec""),
    explicitMetricName(""kafka.consumer"", ""ConsumerTopicMetrics"", ""BytesPerSec""),

    // kafka.consumer.FetchRequestAndResponseStats <-- kafka.consumer.SimpleConsumer
    explicitMetricName(""kafka.consumer"", ""FetchRequestAndResponseMetrics"", ""FetchResponseSize""),
    explicitMetricName(""kafka.consumer"", ""FetchRequestAndResponseMetrics"", ""FetchRequestRateAndTimeMs""),
    explicitMetricName(""kafka.consumer"", ""FetchRequestAndResponseMetrics"", ""FetchResponseSize""),
    explicitMetricName(""kafka.consumer"", ""FetchRequestAndResponseMetrics"", ""FetchRequestRateAndTimeMs""),

    /**
     * ProducerRequestStats <-- SyncProducer
     * metric for SyncProducer in fetchTopicMetaData() needs to be removed when consumer is closed.
     */
    explicitMetricName(""kafka.producer"", ""ProducerRequestMetrics"", ""ProducerRequestRateAndTimeMs""),
    explicitMetricName(""kafka.producer"", ""ProducerRequestMetrics"", ""ProducerRequestSize""),
    explicitMetricName(""kafka.producer"", ""ProducerRequestMetrics"", ""ProducerRequestRateAndTimeMs""),
    explicitMetricName(""kafka.producer"", ""ProducerRequestMetrics"", ""ProducerRequestSize"")

34. AbstractFetcherManager: Could you put the followings in 2 separate lines? Similar things happen in a few other files. Perhaps you need to change the formatting in your IDE?

   }, metricPrefix.toTags

  private def getFetcherId(topic: String, partitionId: Int) : Int = {    Utils.abs(31 * topic.hashCode() + partitionId) % numFetchers

;;;","30/Oct/14 00:46;vladimir.tretyakov;Hi Jun, thx for juicy feedback again, one question:
{quote}
31. AbstractFetcherThread:
31.1 You changed the meaning of clientId. clientId is used in the fetch request and we want to leave it as just the clientId string. Since the clientId should be uniquely representing a particular consumer client, we just need to include the clientId in the metric name. We don't need to include the consumer id in either the fetch request or the metric name since it's too long and has redundant info. 
{quote}

I didn't change meaning of clientId here, look (all code without my changes):

consumerIdString string is:
{code}
val consumerIdString = {
    var consumerUuid : String = null
    config.consumerId match {
      case Some(consumerId) // for testing only
      => consumerUuid = consumerId
      case None // generate unique consumerId automatically
      => val uuid = UUID.randomUUID()
      consumerUuid = ""%s-%d-%s"".format(
        InetAddress.getLocalHost.getHostName, System.currentTimeMillis,
        uuid.getMostSignificantBits().toHexString.substring(0,8))
    }
    config.groupId + ""_"" + consumerUuid
  }
{code}

thread name is (consumerIdString + fetcherId + sourceBroker.id):
{code}
 override def createFetcherThread(fetcherId: Int, sourceBroker: Broker): AbstractFetcherThread = {
    new ConsumerFetcherThread(
      ""ConsumerFetcherThread-%s-%d-%d"".format(consumerIdString, fetcherId, sourceBroker.id),
      config, sourceBroker, partitionMap, this)
  }
{code}

clientId inside AbstractFetcherThread is: config.clientId + consumerIdString + fetcherId + sourceBroker.id
{code}
class ConsumerFetcherThread(name: String,
                            val config: ConsumerConfig,
                            sourceBroker: Broker,
                            partitionMap: Map[TopicAndPartition, PartitionTopicInfo],
                            val consumerFetcherManager: ConsumerFetcherManager)
        extends AbstractFetcherThread(name = name, 
                                      clientId = config.clientId + ""-"" + name,
                                      sourceBroker = sourceBroker,
                                      socketTimeout = config.socketTimeoutMs,
                                      socketBufferSize = config.socketReceiveBufferBytes,
                                      fetchSize = config.fetchMessageMaxBytes,
                                      fetcherBrokerId = Request.OrdinaryConsumerId,
                                      maxWait = config.fetchWaitMaxMs,
                                      minBytes = config.fetchMinBytes,
                                      isInterruptible = true) {
{code}

As you see there is no clean clientId inside AbstractFetcherThread class and it is not unique situation, and this is main goal why I added Taggable.
Now I am trying to remove Taggable, but I have no idea what to do with such cases I've described. Can I add new 'clientId' parameter to all these classes and use only this new/clean clientId as part of matric name? Any other suggestions? Thx.

PS: there is no way t get 'clean' parameters in such classes and build map for metrics just here, I must stretching parameters during all classes as Taggable. 
PSS: Can we use more interactive way for communication, Jira is not a bets way for discussion/explanation, not fast at least:)
;;;","31/Oct/14 02:40;vladimir.tretyakov;Hi Jun, added new patch, removed Taggable, did everything as you have suggested.;;;","31/Oct/14 08:42;junrao;Thanks for the patch. Looks good overall. Some minor comments below.

40. KafkaMetricsGroup:
40.1 Since we already match the metric name directly, shouldn't the following pattern
           val pattern = ("".*"" + metric.getName + "".*"" + clientId + "".*"").r
       be
           val pattern = ("".*clientId="" + clientId + "".*"").r
40.2 Can we make toMBeanName() private?
40.3 According to http://docs.oracle.com/javase/7/docs/api/javax/management/ObjectName.html,  the key properties in an Mbean objectname are a set of unordered keys. So, we don't need the toMap() method. The caller can just create the Map using Map(""tag1""->""val1"", ""tag1""->va2""). 

41. FetchRequestAndResponseMetrics: The following two lines should be in the same line.
  val tags = metricId
  match {

42. Log, Partition,AbstractFetcherThread,ProducerRequestPurgatory: ""partitionId"" => ""partition""

43. TopicPartitionRequestKey: We don't need keyLabel() any more. Instead, we can override the toString() method to get the string in the same way as that in TopicAndPartition.toString().

44. RequestChannel: Lower case ""processor"" in the following.
      toMap(""Processor"" -> i.toString)

45. SocketServer: ""NetworkProcessor"" =>  ""networkProcessor""

46. ZookeeperConsumerConnector: Could we put the new Gauge and the toMap() into a separate line?
    newGauge(""OwnedPartitionsCount"", new Gauge[Int] {
      def value() = allTopicsOwnedPartitionsCount
    }, toMap(""clientId"" -> config.clientId, ""groupId"" -> config.groupId, ""allTopics"" -> ""true""))

              newGauge(""OwnedPartitionsCount"", new Gauge[Int] {
                def value() = partitionThreadPairs.size
              }, ownedPartitionsCountMetricName(topic));;;","31/Oct/14 19:16;vladimir.tretyakov;Hi Jun, added new one, changed according to your last comments.;;;","01/Nov/14 00:44;junrao;Thanks for the patch. A few more comments.

50. ClientIdBroker: Instead of having 2 subclasses, would it be better to have just one class
  case class ClientIdAndBroker(clientId: String, brokerHost: Option[String], brokerPort: Option[Int])?
Ditto to ClientIdTopic.

51. TopicPartitionRequestKey: Can this just be TopicAndPartition?

52. MetricsTest:
52.1 Could we remove the extra empty lines after the class?
52.2 remove unnecessary {} in the following (a few other files have a similar issue)
import java.util.{Properties}
52.3 In testMetricsLeak(), you don't need to create a new zkClient. You can get one from the base class in ZooKeeperTestHarness.
52.4 Instead of duplicating the createAndShutdownStep() calls, could we use a loop instead?
52.5 Instead of duplicating sendMessages() and getMessages() from ZookeeperConsumerConnectorTest, could we extract those methods to TestUtils and add comments to describe what they do? Then, we can reuse those methods.

53. Could you also include a patch to the 0.8.2 doc (https://svn.apache.org/repos/asf/kafka/site/082/ops.html) with the metric name changes?




;;;","03/Nov/14 22:08;vladimir.tretyakov;Hi, added new patch

50. I think it is better to have separate case class for 'all' things. It is real 'other' case.
51. Done
52.1 Done
52.2 Done
52.3 Done
52.4 Done
52.5 Done
53. https://issues.apache.org/jira/secure/attachment/12678927/KAFKA-1481_2014-11-03_16-39-41_doc.patch;;;","04/Nov/14 09:46;junrao;Thanks for the patch. Just some minor comments below. Otherwise, +1 from me.

60. AbstractFetcherManager: In the following, we don't need to wrap new Gauge in {}.
  ""MinFetchRate"", {
    new Gauge[Double] {
      // current min fetch rate across all fetchers/topics/partitions
      def value = {
        val headRate: Double =
          fetcherThreadMap.headOption.map(_._2.fetcherStats.requestRate.oneMinuteRate).getOrElse(0)

        fetcherThreadMap.foldLeft(headRate)((curMinAll, fetcherThreadMapEntry) => {
          fetcherThreadMapEntry._2.fetcherStats.requestRate.oneMinuteRate.min(curMinAll)
        })
      }
    }
  },

61. AbstractFetcherThread: Could we align ""topic"" and ""partition"" to the same column as ""clientId""? Ditto in a few other places.
    Map(""clientId"" -> metricId.clientId,
      ""topic"" -> metricId.topic,
      ""partition"" -> metricId.partitionId.toString)
  )

62. FetchRequestAndResponseMetrics: In the following, could we put Map in a separate line?
  val tags = metricId match {
    case ClientIdAndBroker(clientId, brokerHost, brokerPort) => Map(""clientId"" -> clientId, ""brokerHost"" -> brokerHost,
      ""brokerPort"" -> brokerPort.toString)
    case ClientIdAllBrokers(clientId) => Map(""clientId"" -> clientId, ""allBrokers"" -> ""true"")
  }

62. TestUtils: It's a bit weird that sendMessagesToBrokerPartition() has both a config and configs. We actually don't need the config any more. When sending a message to a partition, we actually don't know which broker the partition is on. So, the message can just be of the form test + ""-"" + partition + ""-"" + x. We can also rename the method to sendMessagesToPartition().
;;;","04/Nov/14 09:47;junrao;[~jjkoshy], do you want to take another look at the patch?;;;","04/Nov/14 10:08;jjkoshy;Yes thanks - I'll take a look at this tomorrow.;;;","05/Nov/14 10:53;jjkoshy;Sorry I ran out of time - will look tomorrow.;;;","07/Nov/14 08:02;jjkoshy;Can you rebase? Sorry I know you have rebased a couple times already. 
Hopefully this should be the last time as these are minor comments.

KafkaMetricsGroup: 64: foreach

KafkaMetricsGroup: toMbeanName: 150/153: can you use filter { case(tagKey, tagValue) =>
...}


For aggregate topic metrics, since allTopics=true appears at the end it is a 
bit weird when browsing mbeans in jvisualvm/other tools. i.e., the mbean is
listed as ""true"". I understand why - it is just a bit weird. I'm referring 
to (for example)
kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec,allTopics=true
See the attached originalLayout.png

Personally I prefer aggregate=true to allTopics=true. A further improvement 
with aggregate=true is the following: in KafkaMetricsGroup.metricName you
can check in the tags map if aggregate=true. If so, then modify the typeName 
by pre-pending Aggregate to it and then strip off the aggregate=true tag. So
you will end up with:
kafka.server:type=BrokerTopicMetrics,name=AggregateBytesOutPerSec 

See alternateLayout1.png 

Another alternative is to modify the name (not the typeName). See 
alternateLayout2.png
                                                                 
The aggregate=true approach seems generic enough to apply to any other
all-topic, all-request, or all-broker level mbeans. What do you think?
;;;","10/Nov/14 15:37;vladimir.tretyakov;Hi [~jjkoshy] thx for your feedback, will change, one question from me:

What if I include Kafka version in any of the MBeans?  It will easy for external tools to detect Kafka version and use parsing rules for particular version. Something like Elasticsearch provides by http (Kafka will provide by JMX).

{code}
curl localhost:9200 
{
...
  ""version"" : {
    ""number"" : ""1.3.2"",
    ""build_hash"" : ""dee175dbe2f254f3f26992f5d7591939aaefd12f"",
    ""build_timestamp"" : ""2014-08-13T14:29:30Z""
....
  }
}
{code}

Maybe you can point out code place where I can get current Kafka version? ;;;","11/Nov/14 02:16;vladimir.tretyakov;Hi again, added new patches (for code and for docs). New patch was done according to 'Alternative 1'.
How about Kafka version publishing in JMX?
Thx!;;;","11/Nov/14 12:34;junrao;[~vladimir.tretyakov], we could probably just add a new MBean to expose the Kafka version number. Any value in exposing other things like build hash and build timestamp?

Also, could you address my last few comments? For example, it seem #62 is still not addressed. A few more comments on the new patch.

64. ConsumerTopicMetrics: Could you merge the following into a single line?
  val tags = metricId
  match {

65. About the change to the aggregate metric name. It seems that we now have the following MBean name. A couple of comments on this.
kafka.consumer:type=AggregateFetchRequestAndResponseMetrics,name=FetchRequestRateAndTimeMs,clientId=console-consumer-50964
65.1 We only include the following in KafkaMetricsGroup.consumerMetricNameList. That won't match the above aggregate metric's name. So, I am not sure how this metric is removed when closing the consumer. The unit test does pass. So, I am not sure if it's testing the right thing.
    new MetricName(""kafka.consumer"", ""FetchRequestAndResponseMetrics"", ""FetchResponseSize""),
65.1 I think adding Aggregate in front of the class name is a bit weird. The way that we add it in KafkaMetricsGroup is also a bit hacky since it essentially changed the typeName for aggregate metrics w/o actually changing it. I was thinking for aggregate metrics, would it be simpler just to have the following? The fact that it doesn't have any broker level labels is enough an indication that it's an aggregate across all brokers.
kafka.consumer:type=FetchRequestAndResponseMetrics,name=FetchRequestRateAndTimeMs,clientId=console-consumer-50964
;;;","11/Nov/14 19:13;vladimir.tretyakov;Hi [~junrao], 
{quote}
Vladimir Tretyakov, we could probably just add a new MBean to expose the Kafka version number. Any value in exposing other things like build hash and build timestamp?
{quote}
Version will be ok I think, but my question was also about where I can get this Version? Should I hardcoded this Version in MBean? What is the best place for such information? Maybe you already have some special property file?;;;","11/Nov/14 19:41;vladimir.tretyakov;Hi again, 
65. Honestly I'd prefer allBrokers=true and allTopics=true or maybe brokers=aggregated, topics=aggregated.
From first view user will not know what this is about:
{code}
kafka.consumer:type=FetchRequestAndResponseMetrics,name=FetchRequestRateAndTimeMs,clientId=console-consumer-50964
{code}

and only after user will see something like:

{code}
kafka.consumer:type=FetchRequestAndResponseMetrics,name=FetchRequestRateAndTimeMs,clientId=console-consumer-50964, broker=0
kafka.consumer:type=FetchRequestAndResponseMetrics,name=FetchRequestRateAndTimeMs,clientId=console-consumer-50964, broker=1
{code}

user can understand (not sure) that name without 'broker=..' is aggregated value, I'd prefer explicit definition.

[~jjkoshy] what do you think about:
""brokers=aggregated, topics=aggregated"" ? In jconsole user will see ""aggregated"" instead of ""true"", handy from my point of view.
;;;","13/Nov/14 01:22;vladimir.tretyakov;Maybe somebody can answer my last questions? Have to finish with this patch and moving forward! Thx.

Will extract Kafka version like ""Gwen Shapira
"" has suggested in http://search-hadoop.com/m/4TaT4xtk36/Programmatic+Kafka+version+detection%252Fextraction&subj=Programmatic+Kafka+version+detection+extraction+ 

{quote}
So it looks like we can use Gradle to add properties to manifest file and
then use getResourceAsStream to read the file and parse it.

The Gradle part would be something like:
jar.manifest {
            attributes('Implementation-Title': project.name,
            'Implementation-Version': project.version,
            'Built-By': System.getProperty('user.name'),
            'Built-JDK': System.getProperty('java.version'),
            'Built-Host': getHostname(),
            'Source-Compatibility': project.sourceCompatibility,
            'Target-Compatibility': project.targetCompatibility
            )
        }

The code part would be:
this.getClass().getClassLoader().getResourceAsStream(""/META-INF/MANIFEST.MF"")

Does that look like the right approach?
{quote}

What do you think?

What about 65?
{quote}
{quote};;;","13/Nov/14 03:19;junrao;
65. The following are some of the choices that we have.
(1) kafka.server:type=BrokerTopicMetrics,name=AggregateBytesOutPerSec
(2) kafka.server:type=AggregateBrokerTopicMetrics,name=BytesOutPerSec
(3) kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec
(4) kafka.server:type=BrokerTopicMetrics,name=AllTopicsBytesOutPerSec
(5) kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec,allTopics=true
(6) kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec,topics=aggregate
The following is my take. The issue with (1), (2) and (3) is that it's not obvious which dimension is being aggregated upon. I also don't quite like (2) since it breaks the convention that type is the class name. If we do go with this route, I'd prefer that we explicitly create an AggregateBrokerTopicMetrics class instead of sneaking in the prefix in KafkaMetricsGroup. (4), (5) and (6) will all make it clear which dimension is being aggregated upon. (4) is a bit weird now that we support tags since the main purpose of tags is that we don't have to squeeze everything into a single name. So, either (5) and (6) looks reasonable to me. Also, I am not sure how jconsole displays mbeans, but the key/value pairs in the mbean name are supposed to be unordered.

[~jjkoshy], what's your take?

As for the mbean for the Kafka version, could we do that in a separate jira? The approach seems reasonable.;;;","13/Nov/14 09:22;jjkoshy;(1) and (4) seem equivalent (i.e., AllTopics vs Aggregate) - or are you saying that (4) will be AllTopics or AllBrokers as appropriate?

I'm +0 on (5) for the reason I stated above. i.e., it is odd to see ""true"" when browsing mbeans

I'm +0 on (6) as well as ""topics=aggregate"" is a bit odd. The field name suggests it is a list of topics but it is more like a boolean. Between this and (5) I prefer (5).

(3) seems reasonable to me although it is not as clear as having an explicit aggregate term in the type. However, I think (1), (2) and (3) do make it clear enough what is being aggregated: i.e., bytes-out-per-sec aggregated on topic. I actually think ""Broker"" should not be there since this is a broker-side mbean already. i.e., if we had kafka.server:type=TopicMetrics,name=BytesOutPerSec (wouldn't it be clear that the dimension of aggregation is across topics?) i.e., I think we can just make the dimension clear from the typename.

Likewise, it should be clear (for consumers) that FetchRequestAndResponseMetrics is really a broker-level aggregation.
;;;","14/Nov/14 02:50;junrao;Thinking about his a bit more, I agree with [~jjkoshy] that (3) is probably the best choice. It's the simplest. Also, if you look at a metric like the following, it should be clear that the request rate is for a particular client, aggregated. There are different ways that this metrics can be broken down. However, that information shouldn't need to be included in the aggregate metrics.

kafka.consumer:type=FetchRequestAndResponseMetrics,name=FetchRequestRateAndTimeMs,clientId=console-consumer-50964

We can probably keep the name BrokerTopicMetrics so that it can be distinguished from ConsumerTopicMetrics and ProducerTopicMetrics.

[~vladimir.tretyakov], are you ok with this approach?;;;","14/Nov/14 05:44;jjkoshy;Re: BrokerTopicMetrics so that it can be distinguished from ConsumerTopicMetrics and ProducerTopicMetrics

Why do we need to distinguish it? i.e., BrokerTopicMetrics would only be on the server right? Or are you concerned about the possibility of a producer or consumer that happens to run in the same VM as a broker?;;;","14/Nov/14 08:15;junrao;My concern is that in the code, if you have a class TopicMetrics, it's not clear what it is for (broker, consumer or producer). Also, if you have a centralized monitoring system that pulls all Kafka metrics (for both the client and the broker), TopicMetrics will be a bit out of context.;;;","14/Nov/14 21:55;vladimir.tretyakov;Hi, added new patches (code + doc), go by way 3:
(3) kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec


Also added Kafka version MBean, it exposes only Kafka version now (from gradle.properties file). I didn't find easy way where I can get build hash, so only version for now.

I hope it will be my last patches, it is a time consumption to change things many times and test everything each time and prepare patched, so I really hope these patches are good enough and I will not do additional iterations, thx.;;;","15/Nov/14 01:49;junrao;Thanks for the patch. Appreciate your persistence. A few comments below.

80. AppInfo.registerInfo()
80.1 On the server side, this needs to be called in KafkaServerStartable.startup(). Some users will start up a Kafka broker using KafkaServerStartable in a container and not from the command line. 
80.2 On the client side, if there are multiple instances of clients running in the same jvm, registerInfo() will be called multiple times. It would be good if we make sure registerInfo() only register the mbean once no matter how many times it's called. We can maintain an isRegistered flag internally and only register the mbean if the flag is not set. We can also make this a synchronized method.
80.3 There is no need to call registerInfo() in ConsoleConsumer and ProducerPerformance since the mbean will be registered by the consumer/producer client.
80.4 We will need to add the same version mbean in the new java client. We don't need to do that in this jira. Could you file a separate jira to track that?

81. KafkaServer: remove unused import AppInfo

82. TestUtils: Could you fix the indentation in the following?
  def sendMessagesToPartition(configs: Seq[KafkaConfig],
                                    topic: String,
                                    partition: Int,
                                    numMessages: Int,
                                    compression: CompressionCodec = NoCompressionCodec): List[String] = {

83. As I was reviewing KAFKA-1684, I realized that in the future, a broker may have multiple ports: plain text, SSL, SASL, etc. In this patch, the broker-specific mbeans have the tag of brokerHost and brokerPort. This is going to be inconvenient once the broker has more than one port. I was thinking it's simpler if we just add the brokerId tag or both the brokerId and the brokerHost tag. What do you think?;;;","15/Nov/14 02:09;junrao;83. On another thought, the port tag may be ok since a client is only going to connect to one port any way.;;;","15/Nov/14 02:36;vladimir.tretyakov;Thx Jun, will try to fix everything according your last comments.
re 83, yeah host:port is unique pair, so it will work even with KAFKA-1684;;;","15/Nov/14 05:38;jjkoshy;[~junrao] For 80.2, I believe the additional registration will not create any new mbeans. i.e., it should be a no-op.
For 83, we could have one set of mbeans per port right? Or do you think that would be too much? Your suggestion is to drop the port and just unify right? That should also be good.

Also, [~vladimir.tretyakov] your patch needs a rebase as mentioned earlier.;;;","15/Nov/14 06:39;junrao;[~jjkoshy], yes, re-registering an existing mbean is a no-op. However, it would probably be good not to depend on this and to avoid the unnecessary checks on resources.

For 83, chances are a given application is going to use one type of port. So, we can leave this as it is.

The patch is actually intended for 0.8.2 and it applies.;;;","15/Nov/14 14:18;otis;bq. 80.4 We will need to add the same version mbean in the new java client. We don't need to do that in this jira. Could you file a separate jira to track that?

I created KAFKA-1768 a few days ago and have linked it to this issue.;;;","17/Nov/14 19:40;vladimir.tretyakov;Hi, provided new patch, last one?:)


80.1 Done
80.2 Done
80.3 Done
80.4 Do you mean 'new producer'? Can I just reformulate KAFKA-1768? Something like: ""Expose version via JMX in new client""?
81. Done
82. Done
83. Left as is.

PS: I'll be traveling for 3 week starting 19.11 (Wednesday) and won't Internet access.  Can we get this committed before I go pleaase?;;;","18/Nov/14 06:26;junrao;Thanks for the patch. +1 from me. Just a few minor comments from me.

90. Kafka: No need to call AppInfo.registerInfo().

91. ZookeeperConsumerConnector: Could we rename the following method to ownedPartitionsCountMetricTags?
def ownedPartitionsCountMetricName

Could you also provide a patch for trunk?

[~jjkoshy], do you want to look at the patch again?;;;","18/Nov/14 07:19;jjkoshy;+1  (for 0.8.2);;;","18/Nov/14 10:39;junrao;[~vladimir.tretyakov], thanks a lot for your work. Committed to 0.8.2 after fixing 90 and 91.

Will leave the jira open until trunk is patched too.;;;","18/Nov/14 16:05;vladimir.tretyakov;Thx a lot guys, will try prepare patch for trunk today.;;;","19/Nov/14 21:17;vladimir.tretyakov;Added patch for trunk - KAFKA-1481_2014-11-19_16-03-03_trunk.patch;;;","20/Nov/14 10:00;junrao;Thanks for the patch for trunk. +1 and committed to trunk.;;;","22/Dec/14 21:27;vladimir.tretyakov;Hi guys, maybe it is not a best place for this question, but it is related to metric, so I will try:

In code ( ""kafka/core/src/main/scala/kafka/log/FileMessageSet.scala"" ) I see:
 {code}
object LogFlushStats extends KafkaMetricsGroup {
  val logFlushTimer = new KafkaTimer(newTimer(""LogFlushRateAndTimeMs"", TimeUnit.MILLISECONDS, TimeUnit.SECONDS))
}
 {code}

But I don't see this metric in JMX when I attach JConsole to my broker.

Is it ok?
What I have to do to see this metric?
Maybe this bean/metric exists short time and recreates each time after/during log flushes?
Can somebody explain me?

Best regards. Vladimir.
;;;","22/Dec/14 23:41;junrao;The JMX will be registered the first time that the flush stat is recorded. So, try producing some messages to a topic.;;;","23/Dec/14 00:06;vladimir.tretyakov;Hi Jun, thx for answer, already did (added many messages), waited more than 1 day (on our test env), nothing, no bean with such name is in broker process.
;;;","23/Dec/14 01:28;junrao;Ok, the metric does show up. By default, the flush is only done in a background thread and it only flushes old log segments. So, a flush is only called when a new log segment is rolled. If you want to see the metric quicker, you can try setting log.flush.interval.messages to a small value.;;;","24/Dec/14 16:40;vladimir.tretyakov;Hi Jun, thx for answer, it helps (""log.flush.interval.messages"" property), I see data on charts
!https://issues.apache.org/jira/secure/attachment/12689019/logflushes.png!

Maybe you also have a receipt how to force displaying of these metrics kafka.log.LogCleaner:
{code}
newGauge(""max-buffer-utilization-percent"", 
           new Gauge[Int] {
             def value: Int = cleaners.map(_.lastStats).map(100 * _.bufferUtilization).max.toInt
           })
  /* a metric to track the recopy rate of each thread's last cleaning */
  newGauge(""cleaner-recopy-percent"", 
           new Gauge[Int] {
             def value: Int = {
               val stats = cleaners.map(_.lastStats)
               val recopyRate = stats.map(_.bytesWritten).sum.toDouble / math.max(stats.map(_.bytesRead).sum, 1)
               (100 * recopyRate).toInt
             }
           })
  /* a metric to track the maximum cleaning time for the last cleaning from each thread */
  newGauge(""max-clean-time-secs"",
           new Gauge[Int] {
             def value: Int = cleaners.map(_.lastStats).map(_.elapsedSecs).max.toInt
           })
{code}

?

Thx again.;;;","10/Jan/15 07:23;junrao;Also committed the doc change to 0.8.2 documentation.;;;","19/Mar/15 04:54;guozhang;We hit an issue related to this ticket, which adds the ""brokerHost"" / ""brokerPort"" into FetchRequestAndResponseMetrics. The root cause is that when server starts up, it gets local host string by calling:

{code}
InetAddress.getLocalHost.getCanonicalHostName
{code}

which, will possibly just return the textual representation of the IP address if somehow accessing local hostname is not allowed:

http://docs.oracle.com/javase/7/docs/api/java/net/InetAddress.html#getCanonicalHostName%28%29

In our case, the IPV6 address string is returned, which is registered in ZK, read by controller and propogated to brokers through metadata update, and eventually read by consumers. And when that happens, we got the following error:

{code}
2015-03-18 09:46:30 JmxReporter [WARN] Error processing kafka.consumer:type=FetchRequestAndResponseMetrics,name=FetchRequestRateAndTimeMs,clientId=samza_checkpoint_manager-wikipedia_parser-1-1426697189628-0,brokerHost=fe80:0:0:0:7ed1:c3ff:fee0:c60f%4,brokerPort=9092
javax.management.MalformedObjectNameException: Invalid character ':' in value part of property
at javax.management.ObjectName.construct(ObjectName.java:618)
at javax.management.ObjectName.<init>(ObjectName.java:1382)
at com.yammer.metrics.reporting.JmxReporter.onMetricAdded(JmxReporter.java:395)
at com.yammer.metrics.core.MetricsRegistry.notifyMetricAdded(MetricsRegistry.java:516)
at com.yammer.metrics.core.MetricsRegistry.getOrAdd(MetricsRegistry.java:491)
at com.yammer.metrics.core.MetricsRegistry.newTimer(MetricsRegistry.java:320)
at kafka.metrics.KafkaMetricsGroup$class.newTimer(KafkaMetricsGroup.scala:85)
at kafka.consumer.FetchRequestAndResponseMetrics.newTimer(FetchRequestAndResponseStats.scala:26)
at kafka.consumer.FetchRequestAndResponseMetrics.<init>(FetchRequestAndResponseStats.scala:35)
at kafka.consumer.FetchRequestAndResponseStats$$anonfun$1.apply(FetchRequestAndResponseStats.scala:44)
at kafka.consumer.FetchRequestAndResponseStats$$anonfun$1.apply(FetchRequestAndResponseStats.scala:44)
at kafka.utils.Pool.getAndMaybePut(Pool.scala:61)
at kafka.consumer.FetchRequestAndResponseStats.getFetchRequestAndResponseStats(FetchRequestAndResponseStats.scala:51)
at kafka.consumer.SimpleConsumer.fetch(SimpleConsumer.scala:108)
at org.apache.samza.checkpoint.kafka.KafkaCheckpointManager$$anonfun$readLog$1.apply(KafkaCheckpointManager.scala:283)
at org.apache.samza.checkpoint.kafka.KafkaCheckpointManager$$anonfun$readLog$1.apply(KafkaCheckpointManager.scala:256)
at org.apache.samza.util.ExponentialSleepStrategy.run(ExponentialSleepStrategy.scala:82)
at org.apache.samza.checkpoint.kafka.KafkaCheckpointManager.readLog(KafkaCheckpointManager.scala:255)
at org.apache.samza.checkpoint.kafka.KafkaCheckpointManager.readChangeLogPartitionMapping(KafkaCheckpointManager.scala:242)
at org.apache.samza.coordinator.JobCoordinator$.buildJobModel(JobCoordinator.scala:136)
at org.apache.samza.coordinator.JobCoordinator.buildJobModel(JobCoordinator.scala)
at org.apache.samza.job.standalone.controller.StandaloneZkCoordinatorController.refreshOwnership(StandaloneZkCoordinatorController.java:161)
at org.apache.samza.job.standalone.controller.StandaloneZkCoordinatorController.access$900(StandaloneZkCoordinatorController.java:49)
at org.apache.samza.job.standalone.controller.StandaloneZkCoordinatorController$ContainerPathListener.handleChildChange(StandaloneZkCoordinatorController.java:256)
at org.I0Itec.zkclient.ZkClient$7.run(ZkClient.java:568)
at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
{code}

I think the right solution here is that BrokerHost string should also be canonized before adding to sensor tags. [~vladimir.tretyakov] [~junrao] what do you think?;;;",,,
Kafka consumer 0.9.0.0  client poll is very CPU intensive under certain conditions,KAFKA-3159,12934536,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,hachikuji,rajiv@signalfx.com,rajiv@signalfx.com,28/Jan/16 02:17,24/May/17 17:27,22/Mar/23 15:10,10/Feb/16 06:58,0.9.0.0,,,,,,0.9.0.1,,,,,,,clients,,,,0,,,,,,"We are using the new kafka consumer with the following config (as logged by kafka)

metric.reporters = []

        metadata.max.age.ms = 300000

        value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

        group.id = myGroup.id

        partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]

        reconnect.backoff.ms = 50

        sasl.kerberos.ticket.renew.window.factor = 0.8

        max.partition.fetch.bytes = 2097152

        bootstrap.servers = [myBrokerList]

        retry.backoff.ms = 100

        sasl.kerberos.kinit.cmd = /usr/bin/kinit

        sasl.kerberos.service.name = null

        sasl.kerberos.ticket.renew.jitter = 0.05

        ssl.keystore.type = JKS

        ssl.trustmanager.algorithm = PKIX

        enable.auto.commit = false

        ssl.key.password = null

        fetch.max.wait.ms = 1000

        sasl.kerberos.min.time.before.relogin = 60000

        connections.max.idle.ms = 540000

        ssl.truststore.password = null

        session.timeout.ms = 30000

        metrics.num.samples = 2

        client.id = 

        ssl.endpoint.identification.algorithm = null

        key.deserializer = class sf.kafka.VoidDeserializer

        ssl.protocol = TLS

        check.crcs = true

        request.timeout.ms = 40000

        ssl.provider = null

        ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]

        ssl.keystore.location = null

        heartbeat.interval.ms = 3000

        auto.commit.interval.ms = 5000

        receive.buffer.bytes = 32768

        ssl.cipher.suites = null

        ssl.truststore.type = JKS

        security.protocol = PLAINTEXT

        ssl.truststore.location = null

        ssl.keystore.password = null

        ssl.keymanager.algorithm = SunX509

        metrics.sample.window.ms = 30000

        fetch.min.bytes = 512

        send.buffer.bytes = 131072

        auto.offset.reset = earliest


We use the consumer.assign() feature to assign a list of partitions and call poll in a loop.  We have the following setup:

1. The messages have no key and we use the byte array deserializer to get byte arrays from the config.

2. The messages themselves are on an average about 75 bytes. We get this number by dividing the Kafka broker bytes-in metric by the messages-in metric.

3. Each consumer is assigned about 64 partitions of the same topic spread across three brokers.

4. We get very few messages per second maybe around 1-2 messages across all partitions on a client right now.

5. We have no compression on the topic.

Our run loop looks something like this

while (isRunning()) {

ConsumerRecords<Void, byte[]> records = null;
        try {
            // Here timeout is about 10 seconds, so it is pretty big.
            records = consumer.poll(timeout);
        } catch (Exception e) {
           // This never hits for us
            logger.error(""Exception polling Kafka "", e);
            records = null;
        }

        if (records != null) {
            for (ConsumerRecord<Void, byte[]> record : records) {
               // The handler puts the byte array on a very fast ring buffer so it barely takes any time.
                handler.handleMessage(ByteBuffer.wrap(record.value()));
            }
        }
}


With this setup our performance has taken a horrendous hit as soon as we started this one thread that just polls Kafka in a loop.

I profiled the application using Java Mission Control and have a few insights.

1. There doesn't seem to be a single hotspot. The consumer just ends up using a lot of CPU for handing such a low number of messages. Our process was using 16% CPU before we added a single consumer and it went to 25% and above after. That's an increase of over 50% from a single consumer getting a single digit number of small messages per second. Here is an attachment of the cpu usage breakdown in the consumer (the namespace is different because we shade the kafka jar before using it) - http://imgur.com/BxWs9Q0 So 20.54% of our entire process CPU is used on polling these 64 partitions (across 3 brokers) with single digit number of 70-80 byte odd messages.  We've used bigger timeouts (100 seconds odd) and that doesn't seem to make much of a difference either.

2. It also seems like Kafka throws a ton of EOFExceptions. I am not sure whether this is expected but this seems like it would completely kill performance. Here is the exception tab of Java mission control. http://imgur.com/X3KSn37 That is 1.8 mn exceptions over a period of 3 minutes which is about 10 thousand exceptions per second! The exception stack trace shows that it originates from the poll call. I don't understand how it can throw so many exceptions given I call poll it with a timeout of 10 seconds and get a single digit number of messages per second. The exception seems to be thrown from here: https://github.com/apache/kafka/blob/0.9.0/clients/src/main/java/org/apache/kafka/common/record/MemoryRecords.java#L236

3. The single thread seems to allocate a lot too. The single thread is responsible for 17.87% of our entire JVM allocation rate. During other runs it has gone up to 20% of our entire JVM allocation rate. Most of what it allocates seems to be those same EOFExceptions. Here is a chart showing the single thread's allocation proportion: http://imgur.com/GNUJQsz Here is a chart that shows a breakdown of the allocations: http://imgur.com/YjCXljE About 20% of the allocations are for the EOFExceptions. But given that the 20% of the allocations (exceptions) is around 10k/second, the thread itself is allocating about 50k objects/second which seems excessive given how we are getting very few messages.

As a comparison, we also run a wrapper over the old SimpleConsumer that gets a lot more data (30 thousand 70 byte messages/sec on a different topic) and it is able to handle that load without much trouble. At this moment we are completely puzzled by this performance. At least some part of that seems to be due to the crazy volumes of exceptions but the CPU profiling breakdown seems to suggest that there are plenty of other causes including the Fetcher.initFetches() call and the ConsumerNetworkClient.poll() call. Note: Our messages seem to all be making through. We haven't measured the end to end latency. The exceptions are caught by Kafka's stack and never bubble up to us.","Linux, Oracle JVM 8.",dana.powers,githubbot,hachikuji,ijuma,junrao,kchudinov,mgrover,rajiv@signalfx.com,ScottReynolds,timurb,wushujames,xiaotao183,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Feb/16 03:29;rajiv@signalfx.com;Memory-profile-patched-client.png;https://issues.apache.org/jira/secure/attachment/12785580/Memory-profile-patched-client.png","02/Feb/16 03:18;rajiv@signalfx.com;Screen Shot 2016-02-01 at 11.09.32 AM.png;https://issues.apache.org/jira/secure/attachment/12785572/Screen+Shot+2016-02-01+at+11.09.32+AM.png",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed May 24 09:27:38 UTC 2017,,,,,,,,,,"0|i2s1rb:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"29/Jan/16 06:43;hachikuji;[~rajiv@signalfx.com] Looks like these EOFExceptions are avoidable by checking whether the underlying buffer has data remaining. However, I'm still a bit puzzled by the number reported. In the current implementation, I would expect to see at most one EOFException for each partition in every fetch response. If there are about 64 partitions and ""fetch.max.wait.ms"" is 1000, then we should see about 64 exceptions raised each second (when there is not much data to fetch). Perhaps most of the exceptions occurred during a load spike or maybe when it was catching up initially?;;;","29/Jan/16 07:19;hachikuji;However, I do see significantly more exceptions when the topic has been compressed (I tried snappy locally). Are you sure that the topic is not compressed?;;;","29/Jan/16 08:20;rajiv@signalfx.com;I don't enable compression on the topic. However the producer (0.8.2) might just decide to compress all the same. How can I tell?;;;","29/Jan/16 08:29;hachikuji;You can use the DumpLogSegmentsTool. The output should show you if the messages are compressed or not. Sample usage below:

{code}
bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka/foo-0/00000000000000000000.log
{code};;;","29/Jan/16 08:31;rajiv@signalfx.com;Actually I managed to dig through the logs and find the producer config logs from the producer:
2016-01-26T02:53:31.497Z INFO  [PathChildrenCache-0                ] [s.o.a.k.c.producer.ProducerConfig   ] {}: ProducerConfig values: 
        compression.type = none
        metric.reporters = []
        metadata.max.age.ms = 300000
        metadata.fetch.timeout.ms = 60000
        acks = 1
        batch.size = 10240
        reconnect.backoff.ms = 10
        bootstrap.servers = [our-kafka-brokers]
        receive.buffer.bytes = 32768
        retry.backoff.ms = 100
        buffer.memory = 2097152
        timeout.ms = 30000
        key.serializer = class sf.disco.kafka.VoidSerializer
        retries = 0
        max.request.size = 1048576
        block.on.buffer.full = false
        value.serializer = class sf.org.apache.kafka.common.serialization.ByteArraySerializer
        metrics.sample.window.ms = 30000
        send.buffer.bytes = 131072
        max.in.flight.requests.per.connection = 5
        metrics.num.samples = 2
        linger.ms = 100
        client.id = 

I don't explicitly set compression and it appears from the config that no compression was set.;;;","29/Jan/16 08:47;hachikuji;[~rajiv@signalfx.com] Here's a patch I've been messing with: https://github.com/hachikuji/kafka/commit/69485add2119d523a1b3c93373eb20923a98320e. Any chance you could give it a try? You only need to update the client. This should address the cause of the EOFs reported above, but it's tough to know for sure since I haven't seen anywhere near the number of exceptions reported.;;;","29/Jan/16 08:57;rajiv@signalfx.com;Thanks Jason. I can try to do that early next week. Have a lot of deadlines this week so might not get the chance to get on it.;;;","02/Feb/16 03:18;rajiv@signalfx.com;CPU break down of the patched client. Some notes:
1. 40.58% of the process' CPU profile is on these poll calls which are done with a timeout of 5 seconds.
2. A lot of cpu is spent on hash map operations.
3. The rest of the cpu seems to be spent mostly in NetworkClient.poll().;;;","02/Feb/16 03:29;rajiv@signalfx.com;Memory profile of the patched client. Notes:

1.A lot of it is in clients.consumer.internals.Fetcher.createFetchRequests(). Again quite a bit of hash map allocations.
2. The majority of the rest of allocations seems to be in NetworkClient.poll().;;;","02/Feb/16 03:34;rajiv@signalfx.com;[~hachikuji] I tried your patch. The Exceptions are now gone, but the CPU has remained high (25% + from 17% before the new client was added). I have attached the CPU breakdown and the allocation break down screen shots and comments.
Some notes:
1. The exceptions seem to be gone completely. The overall CPU has gone down to 25% odd from the 27% before. So it has gotten a bit better. But the percentage of CPU used by the Kafka part of the code has gone up to 40.58% of the total used by my process. Most of the CPU is now spent on hash map code. Again I don't understand why there is so much CPU being used to get single digit 60 byte messages per second (64 partitions striped across 3 brokers).

2. The allocations % has believe it or not gone up even more at about 31.26% of my entire processes allocation. Again it is baffling that it allocates so much to get so few messages. The total sum allocations from the TLAB in the 5 minute period has gone up to 14.05 GB from the 6.95 GB done by the client which threw a lot of exceptions. Again that seems to be a staggering amount of allocations for something that does 1 message odd a second.

My poll timings are done with a 5 second timeout which seems high enough.

Let me know if I can do more profiling or provide other info.;;;","03/Feb/16 07:08;hachikuji;[~rajiv@signalfx.com] I think we'll probably need some more information to investigate this further. It appears that the EOFExceptions were only symptoms of some other problem which is causing high CPU utilization. It might be helpful to see some of the logs so we know what the consumer was doing during that time. Can you turn on TRACE level logging and attach a sample to this ticket?;;;","06/Feb/16 01:49;rajiv@signalfx.com;I think I've found the underlying issue (might not be the only one in play). It turns out that when I don't have any messages in the log, the Kafka broker sends back a reply with no messages immediately instead of respecting the fetch_max_wait_ms or the fetch_min_bytes. The EOFExceptions were probably just raised from parsing empty message sets. I can reproduce this consistently. Steps:
1. Create a topic with a small retention say 5 minutes or wait for said topic to have all its logs cleaned.
2. Start consuming on the topic without any messages being sent to the topic.
3. Observe that Kafka sends back an empty reply to every fetch request almost immediately. This can be observed with tcp-dump, or monitoring the networking-in/out or ngrep etc. I also verified it by writing my own client and observing that my requests get immediate replies when the log is empty.
4. As soon as you start sending messages to the topic, the problem goes away.

We've actually hit this problem in the past (seeing massive number of network traffic) when we were subscribed to a single topic that gets no messages. We didn't know the underlying issue then but I am pretty sure it is this problem.

This is a problem if any consumer is sending fetch requests to at least one broker that is a leader for the partitions being queried but has no messages retained in its log. In real life it can also be a problem. Here are a few use cases:
i) Metadata like topics that are always consumed but very rarely ever written to. We've run into this in the past like I said.
ii) During feature development one can switch on the consumers, and put the producers behind a feature flag. This was the problem we ran into. The consumer code went ahead before the producer code was integrated/switched on and we had to roll back because of the massive regression.

Moreover it goes against all intuition that doing fetch requests against an empty topic-partition should not be more expensive than actually getting data.;;;","06/Feb/16 03:19;granthenke;Could this be related to KAFKA-3003? A fix for KAFKA-3003 just got committed. ;;;","06/Feb/16 03:24;rajiv@signalfx.com;It does seem like it is related if not the same problem.;;;","06/Feb/16 03:34;hachikuji;[~granthenke] Thanks for the suggestion, but appears to be unrelated. I've been able to reproduce the problem off of trunk with that patch included.;;;","06/Feb/16 03:36;rajiv@signalfx.com;Though I should mention that I've seen the same issue in older brokers 0.8.2.x etc too if I remember so it doesn't seem exclusive to 0.9.x.;;;","06/Feb/16 05:05;hachikuji;Talked with [~junrao] offline about this. It seems the fix for KAFKA-3003 may have been incomplete. It doesn't appear to handle the case where there is only 1 replica in the ISR set. If the high watermark doesn't get updated when the segment is rolled, then the fetch would return immediately.;;;","06/Feb/16 05:13;ijuma;For reference, Jun also added a comment to the original PR:

https://github.com/apache/kafka/pull/688#issuecomment-180551456

It may be worth adding a comment to that PR if we are looking to fix the remaining issue as part of this JIRA (to avoid duplicated work).;;;","06/Feb/16 08:45;hachikuji;[~rajiv@signalfx.com] We're still discussing the best way to address this issue, but for now, would you mind trying this patch: https://github.com/hachikuji/kafka/commit/34158c835668f9780f65ab527ade160d9e19c87c? As far as what I've been able to reproduce locally, this does fix the problem.;;;","06/Feb/16 12:48;rajiv@signalfx.com;Thanks Jason. I'll try to apply this patch early next week. Should I build trunk + patch or 0.9.0 + patch?;;;","07/Feb/16 08:20;hachikuji;Either should work, but perhaps it would be most useful at the moment to try against 0.9.0.;;;","09/Feb/16 01:53;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/884

    KAFKA-3159: stale high watermark segment offset causes early fetch return

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka K3159

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/884.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #884
    
----
commit b23447db22aa5eaf6992d37f11ae31627598175b
Author: Jason Gustafson <jason@confluent.io>
Date:   2016-02-06T00:38:00Z

    KAFKA-3159: stale high watermark segment offset causes early fetch return

----
;;;","09/Feb/16 07:56;ijuma;[~rajiv@signalfx.com], when you get a chance to try this, try the following branch: https://github.com/hachikuji/kafka/tree/K3159

It would be great if you could try it soon as this is the only blocker left before we can release 0.9.0.1.;;;","09/Feb/16 07:58;rajiv@signalfx.com;I'll try it tomorrow for sure.;;;","10/Feb/16 06:58;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/884
;;;","10/Feb/16 06:58;junrao;Issue resolved by pull request 884
[https://github.com/apache/kafka/pull/884];;;","10/Feb/16 08:09;rajiv@signalfx.com;I am running a patched broker with a consumer consuming partitions that have no messages and it seems to be working fine. So it looks good so far. I'll run it for longer and then finally run it with real messages to make sure there is no regression. Thanks every one!;;;","10/Feb/16 08:13;ijuma;Good news [~rajiv@signalfx.com], thanks for reporting back.;;;","20/Oct/16 23:30;kchudinov;Hi everyone. We use kafka-10.0.0 (in which current bug should be fixed), but we've faced with the same problem - high CPU usage (close to 50% for dummy consumer without any code in it), tons of EOFException during polling the topic without any data in it.
We use AWS m3.medium instance for testing (1 core) .
Our parameters of consumer: 
metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 10485760
	bootstrap.servers = [server1:6667, server2:6667, server3.aws:6667]
	ssl.keystore.type = JKS
	enable.auto.commit = false
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 50
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 10485760
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 10485760
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = context-facade-consumer
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 1
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest;;;","23/May/17 20:36;githubbot;GitHub user felixgborrego opened a pull request:

    https://github.com/apache/kafka/pull/3127

    Add sleep between empty polls to avoid burning CPU

    Workaround for  https://issues.apache.org/jira/browse/KAFKA-3159

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/Nitro/kafka 0.9.0.2-NITRO

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/3127.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #3127
    
----
commit 88cfff0660bd726ab5cd11ceee79c5cc35ddce18
Author: Felix <fborrego@gonitro.com>
Date:   2017-05-23T12:35:14Z

    Add sleep between empty polls to avoid burning CPU

----
;;;","24/May/17 17:27;githubbot;Github user felixgborrego closed the pull request at:

    https://github.com/apache/kafka/pull/3127
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsumerRebalanceListener.onPartitionsRevoked() is not called on consumer close,KAFKA-2674,12906242,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,hachikuji,turek@avast.com,turek@avast.com,20/Oct/15 21:47,10/Nov/15 03:11,22/Mar/23 15:10,10/Nov/15 03:11,0.9.0.0,,,,,,0.9.0.0,,,,,,,consumer,,,,0,,,,,,"Hi, I'm investigating and testing behavior of new consumer from the planned release 0.9 and found an inconsistency in calling of rebalance callbacks.

I noticed that ConsumerRebalanceListener.onPartitionsRevoked() is NOT called during consumer close and application shutdown. It's JavaDoc contract says:

- ""This method will be called before a rebalance operation starts and after the consumer stops fetching data.""
- ""It is recommended that offsets should be committed in this callback to either Kafka or a custom offset store to prevent duplicate data.""

I believe calling consumer.close() is a start of rebalance operation and even the local consumer that is actually closing should be notified to be able to process any rebalance logic including offsets commit (e.g. if auto-commit is disabled).

There are commented logs of current and expected behaviors.

{noformat}
// Application start
2015-10-20 15:14:02.208 INFO  o.a.k.common.utils.AppInfoParser    [TestConsumer-worker-0]: Kafka version : 0.9.0.0-SNAPSHOT (AppInfoParser.java:82)
2015-10-20 15:14:02.208 INFO  o.a.k.common.utils.AppInfoParser    [TestConsumer-worker-0]: Kafka commitId : 241b9ab58dcbde0c (AppInfoParser.java:83)

// Consumer started (the first one in group), rebalance callbacks are called including empty onPartitionsRevoked()
2015-10-20 15:14:02.333 INFO  c.a.e.kafka.newapi.TestConsumer     [TestConsumer-worker-0]: Rebalance callback, revoked: [] (TestConsumer.java:95)
2015-10-20 15:14:02.343 INFO  c.a.e.kafka.newapi.TestConsumer     [TestConsumer-worker-0]: Rebalance callback, assigned: [testB-1, testA-0, testB-0, testB-3, testA-2, testB-2, testA-1, testA-4, testB-4, testA-3] (TestConsumer.java:100)

// Another consumer joined the group, rebalancing
2015-10-20 15:14:17.345 INFO  o.a.k.c.c.internals.Coordinator     [TestConsumer-worker-0]: Attempt to heart beat failed since the group is rebalancing, try to re-join group. (Coordinator.java:714)
2015-10-20 15:14:17.346 INFO  c.a.e.kafka.newapi.TestConsumer     [TestConsumer-worker-0]: Rebalance callback, revoked: [testB-1, testA-0, testB-0, testB-3, testA-2, testB-2, testA-1, testA-4, testB-4, testA-3] (TestConsumer.java:95)
2015-10-20 15:14:17.349 INFO  c.a.e.kafka.newapi.TestConsumer     [TestConsumer-worker-0]: Rebalance callback, assigned: [testB-3, testA-4, testB-4, testA-3] (TestConsumer.java:100)

// Consumer started closing, there SHOULD be onPartitionsRevoked() callback to commit offsets like during standard rebalance, but it is missing
2015-10-20 15:14:39.280 INFO  c.a.e.kafka.newapi.TestConsumer     [main]: Closing instance (TestConsumer.java:42)
2015-10-20 15:14:40.264 INFO  c.a.e.kafka.newapi.TestConsumer     [TestConsumer-worker-0]: Worker thread stopped (TestConsumer.java:89)
{noformat}

Workaround is to call onPartitionsRevoked() explicitly and manually just before calling consumer.close() but it seems dirty and error prone for me. It can be simply forgotten be someone without such experience.",,becket_qin,githubbot,guozhang,hachikuji,jkreps,turek@avast.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Nov 09 19:11:43 UTC 2015,,,,,,,,,,"0|i2n8kf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Oct/15 02:38;hachikuji;[~onurkaraman] Maybe this issue can be addressed when we update the client-side code for the LeaveGroup request?;;;","21/Oct/15 05:17;becket_qin;[~hachikuji] I am reviewing KAFKA-2464 and also noticed this. I am actually wondering if rebalance listener should be invoked when consumer shuts down. It seems to me that when consumer shuts down, it should simply commit offsets then send a leave group request. It is not actually participating the rebalance any more. Only the rest of the members in the group are doing rebalance.;;;","21/Oct/15 05:25;hachikuji;[~becket_qin] I think the only problem with that is that some users might be doing their own offset management, in which case they might not even be using Kafka to store offsets. Currently, we only commit on close if auto-commit is enabled. I guess we could also depend on the user to manually do commits prior to close, but it seems like they'd probably already have their commit logic in the revoke callback. What do you think?;;;","21/Oct/15 06:14;becket_qin;I think it would be clearer if rebalance callback is only called when rebalance occurred, but not on consumer closure. 

If auto commit is turned off, and users are committing offset on there own, the following code looks clean to me when user close a consumer.
{code}
if (!failure)
  consumer.commitOffsetSync();
consumer.close();
{code}

And this is what we do in mirror maker. I prefer this because it is not complex and we are not re-purposing rebalance listener for something else. I can imagine some logic that only makes sense for actual rebalance, say holding a lock and release it when onPartitionAssigned() is called.

Thoughts?

;;;","21/Oct/15 06:46;guozhang;Today we are already calling ```commitOffsetSync``` upon consumer closing in the coordinator if auto commit is turned on. In addition, we also call ```commitOffsetSync``` before we call ```onPartitionsRevoked``` during the rebalance if auto commit is turned on. So I think the question is really whether we should also call ```onPartitionsRevoked``` upon closing after we call ```commitOffsetSync``` as well.

I prefer adding the ```onPartitionsRevoked``` call since it may be used not only for manual offset management. 

BTW there is a discrepancy between the old and new consumer in MirrorMaker, that with the old consumer we use a rebalance listener that returns the global assignment in ```onPartitionsAssigned``` whereas in the new consumer it only returns its own assignment. We need to think about how it can be resolved.;;;","21/Oct/15 07:04;hachikuji;Since LeaveGroup will cause a group rebalance, it doesn't seem inconsistent to call the revocation callback prior to closing, but I don't have a strong preference either way as long as the documentation is clear. ;;;","21/Oct/15 08:05;becket_qin;[~guozhang] The original reason we add consumer rebalance listener was because rebalance can be triggered without user awareness. But when rebalance occurs, user might want to do something. This is different from consumer closure case. When users close the consumer, they know what they are doing, and likely they will do some cleanup and necessary state checkpoint before closing the consumer. I am not sure how valuable it is to put some pre-closure tasks to onPartitionRevoked(). To me it is a little confusing. Also user might need to add some check to see if the rebalance is caused by close() or it is an actual rebalance.(for example the grabbing a lock as I mentioned before).

Good point about the Mirror Maker. The reason we have global assignment for mirror maker during rebalance listener is because we want to allow mirror maker to do some administrative logic when rebalance is triggered. (e.g. when rebalance is triggered because of a new topic is created in source cluster, we want to create the topic in target cluster with the same number of partitions). In order to let the rebalance listener to perform such action we need a global knowledge of topic so we know which topics changed. This global topic information is part of global assignment (global topic info + owners).

With the new client-side assignment patch, at least the leader has global assignment knowledge, so I think for that use case we should be fine. Although letting the leader to do everything is not ideal if the administrative work is heavy, but it is still doable.

;;;","22/Oct/15 02:46;guozhang;This is a good point, especially if the user DOES NOT want to do some logic upon shutting down that is included in the callback. One edge case though is that upon closing the consumer which tries to close the coordinator, it will likely try to finish all in-flight requests by calling ""maybeAutoCommitOffsetsSync"", hence users' behavior before calling close() may not be on the final state of the consumer. Do we have any ideas about resolving this? [~becket_qin] [~hachikuji];;;","22/Oct/15 09:45;becket_qin;[~guozhang] That is a valid concern, I haven't think it through before. The question is what states could change and whether the changes matter. From consumer's point of view, there are only two states that matter: 1)Partition Assignment 2)Consumer Offsets.

In most cases, user would not care about partition assignment. In cases where user care about the partition assignment, the assignment after close would be empty. So it seems users do not really lose anything from here.

If user are using auto commit, that means user do not really care about the offset commit timing as long as the correct offset is committed. When consumer closes, the correct offsets to commit are the consumed offsets, and consumed offsets will not change unless user call poll(). If user don't want committed offset to change before and after consumer closes, they can either call commitOffsetSync() before closing consumer by themselves or disable auto commit, depending on the use cases.

On the other hand, if users are not using auto commit, we will not commit the offsets, so the state won't change.

So I think we are OK here. Do you have some specific use case that breaks?;;;","22/Oct/15 10:53;hachikuji;I agree with [~becket_qin] that this is probably not a problem. One thing that may be unintuitive, and perhaps the reason we're having this discussion, is that the callback names suggest a different invocation order. From a user's perspective, I would expect that each invocation of onPartitionsAssigned() gets a corresponding invocation of onPartitionsRevoked(), not the other way around (doesn't assignment come before revocation after all?). In that case, it's natural to expect that onPartitionsRevoked() is invoked on close(). However, the actual contract is exactly the opposite: onPartitionsRevoked() is always called prior to rebalance, and onPartitionsAssigned() is called after. So I wonder if we should make this clearer by renaming the methods. For example:
{code}
void beforeRebalance(List<TopicPartition> oldAssignment);
void afterRebalance(List<TopicPartition> newAssignment);
{code}
In this case, the invocation order is clear even without reading the documentation. It also seems clear then that close() would not call beforeRebalance(). Any thoughts?;;;","22/Oct/15 11:49;becket_qin;[~hachikuji] I agree the name is a little misleading. People tends to ignore the class name which is ConsumerRebalanceListener.

The reason we had onPartitionsRevoked and onPartitionsAssigned was because in old consumer during rebalance there are multiple steps (commit offsets, release partition ownership, assign partitions, claim partition ownership, etc). We wanted to make it clear when those methods are called. However some of the steps might not applicable to new consumer anymore. 

WRT the name change. One thing is when we say beforeRebalance(), it sounds like before committing offsets, while actually it is not. For example, if user call committed() in rebalance listener, they might get staled result. Personally I think this is fine as long as we document the behavior clearly.

Another way to think about this is that in the future is it possible we add a beforeCommittingOffset() that get called before committing offset. If there is such possibility I would prefer to keep the current names but document them clearly.

;;;","27/Oct/15 02:28;hachikuji;[~becket_qin] [~guozhang] What would you guys think of the following change to ConsumerRebalanceListener? Basically the objective is to make the calling order clear.

{code}
interface RebalanceListener {
  /* Invoked prior to rebalance, offsets committed here */
  void onPrepare(List<TopicPartition> oldAssignment);

  /* Invoked after rebalance, set initial offset here */
  void onComplete(List<TopicPartition> newAssignment)
}
{code}

Might also be nice to get feedback from [~jkreps].;;;","27/Oct/15 04:51;guozhang;Personally I prefer the old function names since the new proposed names seem not very related to the old partitions as its parameter and hence its effort in resolving confusion seems overwhelmed by the new confusions it introduced. I would suggest we only document clearly that the callback will not be triggered upon consumer closure.;;;","28/Oct/15 08:29;becket_qin;I don't have a strong opinion on this. I agree with [~guozhang] that the argument name is a little bit weird. If we change the function name perhaps we can use currentAssignment instead of oldAssignment?;;;","29/Oct/15 07:04;jkreps;[~hachikuji] I don't have a ton to add. I think I added that class, but it was mostly a placeholder not something with a well-thought-out rationale--I agree that the way it calls revoke prior to assign is a bit odd.;;;","29/Oct/15 13:02;hachikuji;[~guozhang] In the context of rebalancing, I think the meaning of onPrepare/onComplete should be fairly clear to the user, and the benefit is that these names suggest the semantics that we actually implement. Maybe oldAssignment is a bad argument name, but we could use currentAssignment as Becket suggests, or we could also use the revoked/assigned names, as below:
{code}
interface RebalanceListener {
  void onPrepare(List<TopicPartition> revokedPartitions);
  void onComplete(List<TopicPartition> assignedPartitions);
}
{code}
Haha, I've been working on this code a little too much, so it's hard for me to see whether this would be more intuitive to users.;;;","30/Oct/15 00:39;becket_qin;[~hachikuji] I am wondering do we want to avoid use *assign* here? Because we have used it for explicit partition management.;;;","03/Nov/15 09:36;hachikuji;[~guozhang] [~becket_qin] Since none of the alternatives seem clearly better, maybe we should just keep the current names. I can add a patch to try and clarify the behavior.;;;","03/Nov/15 10:33;becket_qin;Yes, I agree documenting it clearly is probably sufficient.;;;","10/Nov/15 03:03;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/467

    KAFKA-2674: clarify onPartitionsRevoked behavior

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-2674

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/467.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #467
    
----
commit 7922adfe74278f7f003d4053c7b6e06f618ab1a6
Author: Jason Gustafson <jason@confluent.io>
Date:   2015-11-09T19:02:44Z

    KAFKA-2674: clarify onPartitionsRevoked behavior

----
;;;","10/Nov/15 03:06;hachikuji;[~guozhang] [~becket_qin] I added a commit to clarify the behavior. I think the documentation was already fairly clear, so I just added a comment to emphasize that onPartitionsRevoked() is not called before close(). I also reordered the methods to try to suggest the order they are actually invoked. I don't think this is a blocker for 0.9.0.;;;","10/Nov/15 03:11;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/467
;;;","10/Nov/15 03:11;guozhang;Issue resolved by pull request 467
[https://github.com/apache/kafka/pull/467];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SyncProducer sends messages to invalid partitions without complaint,KAFKA-73,12514816,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Duplicate,dpnchl,hermanjl,hermanjl,21/Jul/11 03:19,27/Aug/16 06:47,22/Mar/23 15:10,27/Aug/16 06:47,0.6,,,,,,,,,,,,,,,,,0,,,,,,"The SyncProducer class will send messages to invalid partitions without throwing an exception or otherwise alerting the user.

Reproduction:
Run the kafka-simple-consumer-shell.sh script with an invalid partition number. An exception will be thrown and displayed. Run the kafka-producer-shell.sh with the same partition number. You will be able to send messages without any errors.",Mac OSX 10.6.7,dpnchl,felixgv,lanzaa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-49,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,67307,,,Fri Aug 26 22:46:46 UTC 2016,,,,,,,,,,"0|i15yt3:",242939,,,,,,,,,,,,,,,,,,,,"21/Jul/11 09:23;junrao;This is because SyncProducer doesn't get any ACK from the broker right now. This will change as part of https://issues.apache.org/jira/browse/KAFKA-49.;;;","27/Aug/16 06:46;dpnchl;Marking this JIRA closed as the bug was solved with KAFKA-49.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cleaner can generate unindexable log segments,KAFKA-2024,12782429,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,rsivaram,gian,gian,17/Mar/15 08:45,09/Mar/16 00:22,22/Mar/23 15:10,05/Apr/15 06:57,0.8.2.0,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"It's possible for log cleaning to generate segments that have a gap of more than Int.MaxValue between their base offset and their last offset. It's not possible to index those segments since there's only 4 bytes available to store that difference. The broker will end up writing overflowed ints into the index, and doesn't detect that there is a problem until restarted, at which point you get one of these:

2015-03-16 20:35:49,632 FATAL [main] kafka.server.KafkaServerStartable - Fatal error during KafkaServerStartable startup. Prepare to shutdown
java.lang.IllegalArgumentException: requirement failed: Corrupt index found, index file (/mnt/persistent/kafka-logs/topic/00000000000000000000.index) has non-zero size but the last offset is -1634293959 and the base offset is 0
        at scala.Predef$.require(Predef.scala:233)
        at kafka.log.OffsetIndex.sanityCheck(OffsetIndex.scala:352)
        at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:204)
        at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:203)
        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
        at kafka.log.Log.loadSegments(Log.scala:203)
        at kafka.log.Log.<init>(Log.scala:67)
        at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$7$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:142)
        at kafka.utils.Utils$$anon$1.run(Utils.scala:54)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)",,gian,jkreps,mgharat,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Mar/15 19:39;rsivaram;KAFKA-2024.patch;https://issues.apache.org/jira/secure/attachment/12705899/KAFKA-2024.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Apr 21 09:15:11 UTC 2015,,,,,,,,,,"0|i26ue7:",9223372036854775807,,jkreps,,,,,,,,,,,,,,,,,,"20/Mar/15 19:39;rsivaram;Created reviewboard https://reviews.apache.org/r/32300/diff/
 against branch origin/trunk;;;","20/Mar/15 19:44;rsivaram;The attached patch stops grouping of segments in LogCleaner if the difference between the first offset in the group and last offset in the next segment is greater than Int.MaxValue. Unit test for border cases included in the patch. 
Also ran a manual test to recreate the reported failure in Kafka restart after a large range of offsets were grouped together. Reran the test with the fix to check that it fixes the issue;;;","05/Apr/15 06:57;jkreps;Nice catch and nice patch. Applied.;;;","21/Apr/15 02:45;mgharat;Shouldn't the offsetIndex.scala should have a map of 
long -> Int ?

The append() should do
 this.mmap.putInt((offset - baseOffset).toLong)
 this.mmap.putInt(position)

instead of :
 this.mmap.putInt((offset - baseOffset).toInt)
 this.mmap.putInt(position)
       ;;;","21/Apr/15 17:15;rsivaram;[~mgharat] 32-bit relative offsets are stored as explained in the javadoc for OffsetIndex.scala:

{quote}

The file format is a series of entries. The physical format is a 4 byte ""relative"" offset and a 4 byte file location for the 
message with that offset. The offset stored is relative to the base offset of the index file. So, for example,
if the base offset was 50, then the offset 55 would be stored as 5. Using relative offsets in this way let's us use
only 4 bytes for the offset.

{quote}

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MemoryRecords.Iterator needs to handle partial reads from compressed stream,KAFKA-1735,12750934,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,guozhang,guozhang,28/Oct/14 07:55,17/May/16 22:15,22/Mar/23 15:10,02/Jul/15 07:20,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Found a bug in the MemoryRecords.Iterator implementation, where 

{code}
stream.read(recordBuffer, 0, size)
{code}

can read less than size'ed bytes, and rest of the recordBuffer would set to ""\0"".",,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Oct/14 07:59;guozhang;KAFKA-1735.patch;https://issues.apache.org/jira/secure/attachment/12677464/KAFKA-1735.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jul 01 23:20:23 UTC 2015,,,,,,,,,,"0|i21n5z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"28/Oct/14 07:59;guozhang;Created reviewboard https://reviews.apache.org/r/27256/diff/
 against branch origin/trunk;;;","30/Oct/14 03:04;guozhang;Updated reviewboard https://reviews.apache.org/r/27256/diff/
against branch origin/trunk;;;","02/Jul/15 07:20;guozhang;This bug has been resolved in another ticket, closing.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ReplicaFetcherThread: data loss on unknown exception,KAFKA-2165,12826749,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,aozeritsky,aozeritsky,03/May/15 04:19,14/Mar/16 17:12,22/Mar/23 15:10,14/Mar/16 17:10,0.8.2.1,,,,,,,,,,,,,,,,,3,,,,,,"Sometimes in our cluster some replica gets out of the isr. Then broker redownloads the partition from the beginning. We got the following messages in logs:
{code}
# The leader:
[2015-03-25 11:11:07,796] ERROR [Replica Manager on Broker 21]: Error when processing fetch request for partition [topic,11] offset 54369274 from follower with correlation id 2634499. Possible cause: Request for offset 54369274 but we only have log segments in the range 49322124 to 54369273. (kafka.server.ReplicaManager)
{code}

{code}
# The follower:
[2015-03-25 11:11:08,816] WARN [ReplicaFetcherThread-0-21], Replica 31 for partition [topic,11] reset its fetch offset from 49322124 to current leader 21's start offset 49322124 (kafka.server.ReplicaFetcherThread)
[2015-03-25 11:11:08,816] ERROR [ReplicaFetcherThread-0-21], Current offset 54369274 for partition [topic,11] out of range; reset offset to 49322124 (kafka.server.ReplicaFetcherThread)
{code}

This occures because we update fetchOffset [here|https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/server/AbstractFetcherThread.scala#L124] and then try to process message. 
If any exception except OffsetOutOfRangeCode occures we get unsynchronized fetchOffset and replica.logEndOffset.
On next fetch iteration we can get fetchOffset>replica.logEndOffset==leaderEndOffset and OffsetOutOfRangeCode.

",,akirillov,aozeritsky,bugzmanov,ijuma,jay.kim,jiang tao,junrao,mazhar.shaikh.in,octo47,ovgolovin,sriharsha,suninside,yuyang08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2143,,,,,,KAFKA-2164,,,,,,,,,,"03/May/15 04:20;aozeritsky;KAFKA-2165.patch;https://issues.apache.org/jira/secure/attachment/12729975/KAFKA-2165.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,Patch,,,,,,,,,9223372036854775807,,,Mon Mar 14 09:12:33 UTC 2016,,,,,,,,,,"0|i2e7sf:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"03/Jun/15 14:59;yuyang08;We have also seen this issue in our kafka 0.8.2.1 cluster. ;;;","13/Jun/15 09:59;junrao;Thanks for reporting this. A couple of comments.

1. Currently, if we get any exception other than OffsetOutOfRangeException, we won't move the fetchOffset and won't append the data to the log. So, the fetchOffset and replica.logEndOffset should still be consistent, right? Also, do you know what kind of exception you got?
2. I am not sure if the check added in the patch is necessary. When the replica fetcher thread gets an OffsetOutOfRangeException, it either overflows or underflows. The additional test that you added tests for underflow in the branch that handles underflow.
;;;","12/Aug/15 17:57;akirillov;We experience the same issue on our production cluster built on Kafka 0.8.2.1.

But why this was resolved as not a problem? I can't imagine situation when during normal work replica is getting ahead leader. It's possible only if leader loses some messages already replicated by replica.;;;","14/Mar/16 16:54;jiang tao;@Jun Rao  Recently,our production cluster have suddenly high network flow,increased 50M/s. after some days analyse, I find is the replication flow.

the cause is the follower replica offset is larger than master,and the follower replica offset  have been reset of the most begin,then the follower send another fetch request with the new offset,cause the follower out of ISR. and because the partition is also 100G,the follower make almost 1 hour to catch up,during the replication, the broker network load is very high,almost saturated.;;;","14/Mar/16 17:12;ijuma;I changed the resolution to duplicate of KAFKA-2143, which was fixed in 0.9.0.1. If you are seeing this with 0.9.0.1, then it's probably best to file a new issue with as much detail as possible.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Leader is not set to -1 when it is shutdown if followers are down,KAFKA-3096,12929863,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,ijuma,ijuma,14/Jan/16 00:11,15/Nov/19 10:59,22/Mar/23 15:10,15/Nov/19 10:59,0.9.0.0,,,,,,,,,,,,,,,,,0,reliability,,,,,"Assuming a cluster with 2 brokers with unclear leader election disabled:

1. Start brokers 0 and 1
2. Perform partition assignment
3. Broker 0 is elected leader
4. Produce message and wait until metadata is propagated
6. Shutdown follower
7. Produce message
8. Shutdown leader
9. Start follower
10. Wait for leader election

Expected: leader is -1
Actual: leader is 0

We have a test for this, but a bug in `waitUntilLeaderIsElectedOrChanged` means that `newLeaderOpt` is not being checked.",,boniek,damianguy,githubbot,guozhang,ijuma,jthakrar,mjsax,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue May 21 14:15:44 UTC 2019,,,,,,,,,,"0|i2r8yv:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"14/Jan/16 00:21;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/765

    KAFKA-3096; Leader is not set to -1 when it is shutdown if followers are down

    * Update leader to -1 before throwing `NoReplicaOnlineException` in `OfflinePartitionLeaderSelector` as suggested by Guozhang. This fixes the test, which is great, but it seems a bit out of place. Would it be better to change the code somewhere else?
    
    * Fix bug in `waitUntilLeaderIsElectedOrChanged` and simplify result type. The bug was for the following case:
    
    ```scala
    leader.isDefined && oldLeaderOpt.isEmpty && newLeaderOpt.isDefined && newLeaderOpt.get != leader.get
    ```
    
    We would consider it a successful election even though we should not. I also changed the result type as we never return `None` (we throw an exception instead). Fixing this bug is what uncovered the leader issue being solved in this PR.
    
    Also included:
    * Various mechanical clean-ups found while trying to understand the code (as usual, this is in separate commits, so I can submit them separately if desired).
    * Make logging more regular in `PartitionLeaderSelector.scala`

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-3096-leader-should-be-set-to--1

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/765.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #765
    
----
commit a8cbf88b37665c9669f0e9beae608794d82a810c
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-01-08T16:48:47Z

    Fix bug in `waitUntilLeaderIsElectedOrChanged` and simplify result type
    
    The bug was for the following case:
    
    `leader.isDefined && oldLeaderOpt.isEmpty && newLeaderOpt.isDefined && newLeaderOpt.get != leader.get`
    
    We would consider it a successful election even though we should not.
    
    I also changed the result type is we never return `None` (we throw an exception instead).

commit f2266e42b1d3fc7058574f16b0c0d8de08b3a3f6
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-01-13T15:23:19Z

    Update leader to -1 before throwing `NoReplicaOnlineException`
    
    Suggested by Guozhang.

commit 21568618d8ac82d3f801307b0145baa75240b0a4
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-01-13T14:25:40Z

    Various mechanical clean-ups

commit 7b608c44f17536274606654f6faa2cc45d890c3c
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-01-13T15:46:50Z

    Make logging more regular in `PartitionLeaderSelector.scala` and other minor clean-ups

----
;;;","12/May/17 17:17;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/3031

    MINOR: Fix bug in `waitUntilLeaderIsElectedOrChanged` and simplify result type

    Also disable a couple of tests that were passing incorrectly until KAFKA-3096 is fixed.
    
    The bug was for the following case:
    
    `leader.isDefined && oldLeaderOpt.isEmpty && newLeaderOpt.isDefined && newLeaderOpt.get != leader.get`
    
    We would consider it a successful election even though we should not.
    
    I also changed the result type as we never return `None` (we throw an exception instead).

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka fix-wait-until-leader-is-elected

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/3031.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #3031
    
----
commit 75a441087f4bbac973afe1198fd382df790552f6
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-01-08T16:48:47Z

    MINOR: Fix bug in `waitUntilLeaderIsElectedOrChanged` and simplify result type
    
    Also disable a couple of tests that were passing incorrectly until KAFKA-3096 is fixed.
    
    The bug was for the following case:
    
    `leader.isDefined && oldLeaderOpt.isEmpty && newLeaderOpt.isDefined && newLeaderOpt.get != leader.get`
    
    We would consider it a successful election even though we should not.
    
    I also changed the result type as we never return `None` (we throw an exception instead).

----
;;;","16/May/17 07:09;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/3031
;;;","23/Sep/17 12:49;guozhang;*Reminder to the contributor / reviewer of the PR*: please note that the code deadline for 1.0.0 is less than 2 weeks away (Oct. 4th). Please re-evaluate your JIRA and see if it still makes sense to be merged into 1.0.0 or it could be pushed out to 1.1.0, or be closed directly if the JIRA itself is not valid any more, or re-assign yourself as contributor / committer if you are no longer working on the JIRA.;;;","05/Feb/18 04:37;damianguy;[~ijuma] is this still an issue? Can i move it out of 1.1? The PR referenced was closed a long time ago;;;","05/Feb/18 04:58;ijuma;Done.;;;","18/Feb/19 03:19;mjsax;Moving all major/minor/trivial tickets that are not merged yet out of 2.2 release.;;;","21/May/19 22:15;githubbot;ijuma commented on pull request #765: KAFKA-3096; Leader is not set to -1 when it is shutdown if followers are down
URL: https://github.com/apache/kafka/pull/765
 
 
   
 
----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka should respond gracefully rather than crash when unable to write due to ENOSPC,KAFKA-600,12614599,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,polarbearcold,polarbearcold,03/Nov/12 06:54,14/Dec/12 22:56,22/Mar/23 15:10,14/Dec/12 22:56,,,,,,,,,,,,,,core,,,,0,,,,,,"problem:
user starts kafka with log.dir value set to a small partition and begins writing data to the mq.  when the disk partition is full, kafka crashes.  given that this product is used for both reading and writing operations, crashing seems rather drastic even if the error message is helpful.   something more robust would be appreciated.  perhaps, logging an error and rejecting additional write requests while accepting additional read requests?  perhaps, sending an email alert to Operations?  at least shutdown gracefully so the user is aware that received messages were saved with a helpful message providing some details of the last message received.  when tens or hundreds of thousands of messages can be processed in a second, it isn't helpful to merely log a timestamp and crash.

steps to reproduce:
1) download and install kafka
2) modify server.properties
    # vi /opt/kafka-0.7.2-incubating-src/config/server.properties
    set log.dir=""/var/log/kafka""
3) modify log4j
    # vi /opt/kafka-0.7.2-incubating-src/config/log4j.properties
    set fileAppender.File=/var/log/kafka/kafka-request.log
4) start kafka service
    $ sudo bash
    # ulimit -c unlimited
    # /opt/kafka-0.7.2-incubating-src/bin/kafka-server-start.sh /opt/kafka-0.7.2-incubating-src/config/server.properties &
6) begin writing data to hostname:9092
7) review /var/log/kafka-request.log

results:
$ grep log.dir /opt/kafka-0.7.2-incubating-src/config/server.properties
log.dir=/var/log/kafka
$ df -h /var/log/kafka
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda1       4.0G  4.0G     0 100% /
$ tail /var/log/kafka/kafka-request.log
17627442 [ZkClient-EventThread-14-10.0.20.242:2181] INFO  kafka.server.KafkaZooKeeper  - Begin registering broker topic /brokers/topics/raw/0 with 1 partitions
17627444 [ZkClient-EventThread-14-10.0.20.242:2181] INFO  kafka.server.KafkaZooKeeper  - End registering broker topic /brokers/topics/raw/0
17627445 [ZkClient-EventThread-14-10.0.20.242:2181] INFO  kafka.server.KafkaZooKeeper  - done re-registering broker
18337676 [kafka-processor-3] ERROR kafka.network.Processor  - Closing socket for /10.0.20.138 because of error
java.io.IOException: Connection reset by peer
        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:218)
        at sun.nio.ch.IOUtil.read(IOUtil.java:191)
        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
        at kafka.utils.Utils$.read(Utils.scala:538)
        at kafka.network.BoundedByteBufferReceive.readFrom(BoundedByteBufferReceive.scala:54)
        at kafka.network.Processor.read(SocketServer.scala:311)
        at kafka.network.Processor.run(SocketServer.scala:214)
        at java.lang.Thread.run(Thread.java:722)
18391974 [kafka-processor-4] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.138.
18422004 [kafka-processor-5] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.138.
18434563 [kafka-processor-6] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.138.
18485005 [kafka-processor-7] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.138.
18497083 [kafka-processor-0] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.138.
18525720 [kafka-processor-1] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.138.
18543843 [kafka-processor-2] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.138.
18563230 [kafka-processor-4] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.138.
18575613 [kafka-processor-5] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.138.
18677568 [kafka-processor-6] ERROR kafka.network.Processor  - Closing socket for /10.0.20.138 because of error
java.io.IOException: Connection reset by peer
        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:218)
        at sun.nio.ch.IOUtil.read(IOUtil.java:191)
        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
        at kafka.utils.Utils$.read(Utils.scala:538)
        at kafka.network.BoundedByteBufferReceive.readFrom(BoundedByteBufferReceive.scala:54)
        at kafka.network.Processor.read(SocketServer.scala:311)
        at kafka.network.Processor.run(SocketServer.scala:214)
        at java.lang.Thread.run(Thread.java:722)
18828016 [kafka-processor-7] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.248.
18844274 [kafka-processor-0] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.248.
18849691 [kafka-processor-1] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.248.
18896883 [kafka-processor-2] INFO  kafka.network.Processor  - Closing socket connection to /10.0.20.248.
22383195 [kafka-processor-2] FATAL kafka.log.Log  - Halting due to unrecoverable I/O error while handling producer request
java.io.IOException: No space left on device
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:59)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:89)
        at sun.nio.ch.IOUtil.write(IOUtil.java:60)
        at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:195)
        at kafka.message.ByteBufferMessageSet.writeTo(ByteBufferMessageSet.scala:76)
        at kafka.message.FileMessageSet.append(FileMessageSet.scala:159)
        at kafka.log.LogSegment.append(Log.scala:105)
        at kafka.log.Log.liftedTree1$1(Log.scala:246)
        at kafka.log.Log.append(Log.scala:242)
        at kafka.server.KafkaRequestHandlers.kafka$server$KafkaRequestHandlers$$handleProducerRequest(KafkaRequestHandlers.scala:69)
        at kafka.server.KafkaRequestHandlers.handleProducerRequest(KafkaRequestHandlers.scala:53)
        at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$1.apply(KafkaRequestHandlers.scala:38)
        at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$1.apply(KafkaRequestHandlers.scala:38)
        at kafka.network.Processor.handle(SocketServer.scala:296)
        at kafka.network.Processor.read(SocketServer.scala:319)
        at kafka.network.Processor.run(SocketServer.scala:214)
        at java.lang.Thread.run(Thread.java:722)
",,jkreps,polarbearcold,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,255015,,,Fri Dec 14 14:56:47 UTC 2012,,,,,,,,,,"0|i0eohz:",83731,,,,,,,,,,,,,,,,,,,,"03/Nov/12 08:06;jkreps;This seems sensible but the problem is this. If you get ENOSPC, you likely accepted a partial write, which means the log itself is corrupt. To fix this we need to run recovery on the log (which checks each message in the last segment and truncates off any invalid partitial writes). This happens automatically when the server is restarted. Theoretically this could be done automatically but since the recovery process can be slow (minutes) and we can't accept writes during that time we felt the best course of action is to have the node shoot itself in the head and let other healthy nodes take over.;;;","14/Dec/12 22:56;jkreps;Since there don't seem to be any objections I am closing out this issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Topics marked for delete in Zookeeper may become undeletable,KAFKA-2937,12917797,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,mgharat,rsivaram,rsivaram,03/Dec/15 07:46,07/Jan/16 06:17,22/Mar/23 15:10,07/Jan/16 06:17,0.9.0.0,,,,,,0.9.0.1,,,,,,,core,,,,1,,,,,,"In our clusters, we occasionally see topics marked for delete, but never actually deleted. It may be due to brokers being restarted while tests were running, but further restarts of Kafka dont fix the problem. The topics remain marked for delete in Zookeeper.

Topic describe shows:
{quote}
Topic:testtopic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: testtopic	Partition: 0	Leader: none	Replicas: 3,4,0	Isr: 
{quote}

Kafka logs show:
{quote}
2015-12-02 15:53:30,152] ERROR Controller 2 epoch 213 initiated state change of replica 3 for partition [testtopic,0] from OnlineReplica to OfflineReplica failed (state.change.logger)
kafka.common.StateChangeFailedException: Failed to change state of replica 3 for partition [testtopic,0] since the leader and isr path in zookeeper is empty
        at kafka.controller.ReplicaStateMachine.handleStateChange(ReplicaStateMachine.scala:269)
        at kafka.controller.ReplicaStateMachine$$anonfun$handleStateChanges$2.apply(ReplicaStateMachine.scala:114)
        at kafka.controller.ReplicaStateMachine$$anonfun$handleStateChanges$2.apply(ReplicaStateMachine.scala:114)
        at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
        at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
        at kafka.controller.ReplicaStateMachine.handleStateChanges(ReplicaStateMachine.scala:114)
        at kafka.controller.TopicDeletionManager$$anonfun$startReplicaDeletion$2.apply(TopicDeletionManager.scala:342)
        at kafka.controller.TopicDeletionManager$$anonfun$startReplicaDeletion$2.apply(TopicDeletionManager.scala:334)
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
        at kafka.controller.TopicDeletionManager.startReplicaDeletion(TopicDeletionManager.scala:334)
        at kafka.controller.TopicDeletionManager.kafka$controller$TopicDeletionManager$$onPartitionDeletion(TopicDeletionManager.scala:367)
        at kafka.controller.TopicDeletionManager$$anonfun$kafka$controller$TopicDeletionManager$$onTopicDeletion$2.apply(TopicDeletionManager.scala:313)
        at kafka.controller.TopicDeletionManager$$anonfun$kafka$controller$TopicDeletionManager$$onTopicDeletion$2.apply(TopicDeletionManager.scala:312)
        at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
        at kafka.controller.TopicDeletionManager.kafka$controller$TopicDeletionManager$$onTopicDeletion(TopicDeletionManager.scala:312)
        at kafka.controller.TopicDeletionManager$DeleteTopicsThread$$anonfun$doWork$1$$anonfun$apply$mcV$sp$4.apply(TopicDeletionManager.scala:431)
        at kafka.controller.TopicDeletionManager$DeleteTopicsThread$$anonfun$doWork$1$$anonfun$apply$mcV$sp$4.apply(TopicDeletionManager.scala:403)
        at scala.collection.immutable.Set$Set2.foreach(Set.scala:111)
        at kafka.controller.TopicDeletionManager$DeleteTopicsThread$$anonfun$doWork$1.apply$mcV$sp(TopicDeletionManager.scala:403)
        at kafka.controller.TopicDeletionManager$DeleteTopicsThread$$anonfun$doWork$1.apply(TopicDeletionManager.scala:397)
        at kafka.controller.TopicDeletionManager$DeleteTopicsThread$$anonfun$doWork$1.apply(TopicDeletionManager.scala:397)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
        at kafka.controller.TopicDeletionManager$DeleteTopicsThread.doWork(TopicDeletionManager.scala:397)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
{quote}                      
 ",,Andrew M,gabbi,githubbot,hpihkala,ijuma,junrao,mgharat,rsivaram,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jan 06 22:17:30 UTC 2016,,,,,,,,,,"0|i2p7kf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Dec/15 02:06;mgharat;I ran a test with few commits behind trunk HEAD : 

1) Started the kafka cluster.
2) Produced data to topic T for quite some time so that enough data is accumulated on kafka brokers.
3) Delete a topic and immediately shutdown the cluster.
4) I could see the topic T under /admin/delete_topics.
5) After I restarted the cluster, the topic T was deleted.


There might be a race condition here, were controller might have gone down after it wrote to zookeeper but under removed the topic under /admin/deleted_topics. I will have to investigate more on this.
[~rsivaram]What is the version of kafka that you are running?;;;","21/Dec/15 22:34;rsivaram;[~mgharat] We are running kafka 0.9.0.0.;;;","24/Dec/15 07:04;mgharat;[~rsivaram] This can occur if during delete topic, the controller writes the updated LeaderISR to zookeeper and dies and a new controller is elected and since the  /admin/delete_topics/ path contains the topic, the deleteTopic is retried and when the controller tries to send the stopReplicaRequest with deletePartition = false when it tries to remove ReplicafromISR and since there is no LeaderISR, the above exception is thrown. 

I am thinking if while deleting a topic, is it necessary for the check :
if (leaderAndIsrIsEmpty)
            throw new StateChangeFailedException(
              ""Failed to change state of replica %d for partition %s since the leader and isr path in zookeeper is empty""
              .format(replicaId, topicAndPartition))

I am planning to check if the topic is being deleted and if YES, we do not throw the exception if the LeaderISR info in zookeeper is empty.

On a side note did you see a log line ""Retrying delete topic for topic ....since replicas....were not successfully deleted"".

;;;","30/Dec/15 01:19;hpihkala;I ran into this issue as well on 0.9.0.0. I had a bunch of topics in this state, all related to an integration test I had, which tests topic creation and topic deletion immediately after that. Could it be that a newly-created topic has a higher chance of ending up in this state? (For example, if the deletion process starts before a leader is elected for the new topic, etc);;;","05/Jan/16 00:53;mgharat;[~djh] does your integration test check if the topic is created successfully before attempting a delete?;;;","05/Jan/16 01:20;hpihkala;[~mgharat] Yes, like this:

AdminUtils.createTopic(...)
assert AdminUtils.topicExists(...)
AdminUtils.deleteTopic(...)
Thread.sleep(...)
assert !AdminUtils.topicExists(...)

When this test one day suddenly started failing (on the last line), I first suspected that my sleep wasn't long enough anymore. However, digging deeper showed that topics created by my test were ending up in the undeleteable state described in this JIRA.;;;","05/Jan/16 06:16;mgharat;Yes, that might be possible but it should be rare. The AdminUtils.topicExists(topicName) call checks only if the the entry /brokers/topics/topicName exist in the zookeeper. The createTopic() should write to the path : /brokers/topic/topicName and also update the replicaAssignment for the topic in Zookeeper.

If somehow the second part got messed up, the above error can occur. ;;;","05/Jan/16 07:05;githubbot;GitHub user MayureshGharat opened a pull request:

    https://github.com/apache/kafka/pull/729

    KAFKA-2937 : Disable the leaderIsr check if the topic is to be deleted.

    The check was implemented in KAFKA-340 : If we are shutting down a broker when the ISR of a partition includes only that broker, we could lose some messages that have been previously committed. For clean shutdown, we need to guarantee that there is at least 1 other broker in ISR after the broker is shut down.
    
    When we are deleting the topic, this check can be avoided.


You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/MayureshGharat/kafka kafka-2937

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/729.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #729
    
----
commit 9d5afd0f29f2f4311e534eb375e1c9ddb23b33dd
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2016-01-04T22:56:01Z

    Disable the leaderIsr check if the topic is to be deleted.

----
;;;","06/Jan/16 04:45;ijuma;There's a PR so updating the status.;;;","07/Jan/16 06:14;junrao;The situation that [~mgharat] described can indeed happen. In that case, the isr in ZK would be empty. It would be great to verify that if we see the same issue again.;;;","07/Jan/16 06:17;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/729
;;;","07/Jan/16 06:17;junrao;Issue resolved by pull request 729
[https://github.com/apache/kafka/pull/729];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Controlled shutdown deadlock when trying to send state updates,KAFKA-1447,12713799,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,,smeder,smeder,13/May/14 08:28,01/Sep/17 01:01,22/Mar/23 15:10,01/Sep/17 01:01,0.8.0,,,,,,,,,,,,,controller,,,,1,newbie++,,,,,"We're seeing controlled shutdown indefinitely stuck on trying to send out state change messages to the other brokers:

[2014-05-03 04:01:30,580] INFO [Socket Server on Broker 4], Shutdown completed (kafka.network.SocketServer)
[2014-05-03 04:01:30,581] INFO [Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)

and stuck on:

""kafka-request-handler-12"" daemon prio=10 tid=0x00007f1f04a66800 nid=0x6e79 waiting on condition [0x00007f1ad5767000]
java.lang.Thread.State: WAITING (parking)
at sun.misc.Unsafe.park(Native Method)
parking to wait for <0x000000078e91dc20> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:349)
at kafka.controller.ControllerChannelManager.sendRequest(ControllerChannelManager.scala:57)
locked <0x000000078e91dc38> (a java.lang.Object)
at kafka.controller.KafkaController.sendRequest(KafkaController.scala:655)
at kafka.controller.ControllerBrokerRequestBatch$$anonfun$sendRequestsToBrokers$2.apply(ControllerChannelManager.scala:298)
at kafkler.ControllerBrokerRequestBatch$$anonfun$sendRequestsToBrokers$2.apply(ControllerChannelManager.scala:290)
at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
at scala.collection.Iterator$class.foreach(Iterator.scala:772)
at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:45)
at scala.collection.mutable.HashMap.foreach(HashMap.scala:95)
at kafka.controller.ControllerBrokerRequestBatch.sendRequestsToBrokers(ControllerChannelManager.scala:290)
at kafka.controller.ReplicaStateMachine.handleStateChanges(ReplicaStateMachine.scala:97)
at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:269)
at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:253)
at scala.Option.foreach(Option.scala:197)
at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:253)
at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:253)
at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:253)
at kafka.utils.Utils$.inLock(Utils.scala:538)
at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:252)
at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:249)
at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:130)
at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:275)
at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:275)
at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:275)
at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:249)
locked <0x000000078b495af0> (a java.lang.Object)
at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:264)
at kafka.server.KafkaApis.handle(KafkaApis.scala:192)
at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:42)
at java.lang.Thread.run(Thread.java:722)",,becket_qin,guozhang,jjkoshy,jkreps,jozi-k,junrao,nehanarkhede,omkreddy,rudolf.sima,smeder,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,392115,,,Thu Aug 31 17:01:45 UTC 2017,,,,,,,,,,"0|i1vj1j:",392309,,,,,,,,,,,,,,,,,,,,"13/May/14 23:32;guozhang;Hi Sam, which version are you using?;;;","14/May/14 00:05;smeder;0.8.0;;;","14/May/14 04:41;guozhang;This may be due a known issue in 0.8.0, could you try with 0.8.1.1?;;;","14/May/14 21:04;smeder;We'll be rolling out 0.8.1.1 soon, but since we can't reproduce this easily it is going to be hard to validate. I did look through any of the Jira issues related to controlled shutdown to see if this was already addressed and didn't see any that seemed to match this situation. I'll report back once we have run with 0.8.1.1 for a while.;;;","16/May/14 06:17;jjkoshy;Do you still have the preceding log and see if controlled shutdown actually succeeded or it ran out of retries?
Was broker 4 the controller at the time it was shut down? It could be that it did not finish sending all the state change requests to itself and will never finish because the socket server has been shut down.
Also, do you have the full stack trace?;;;","20/May/14 03:00;smeder;I don't have those logs anymore, should have grabbed all of it - my bad.

I do believe broker 4 was the controller at the time and yes, my guess is that it had something to do with sending requests to itself.

That is the full stack trace (from the thread dump), there were no stack-traces in the logs.;;;","27/Aug/14 23:57;rudolf.sima;The bug seems to be still present in 0.8.2. We ran into the issue when bouncing 18 brokers at once with controlled shutdown enabled, which led to this kind of deadlock. As a workaround, we have increased controller.message.queue.size to 10000 (10 is default). Are there any pitfalls of using large controller message queue sizes?;;;","15/Sep/14 09:58;nehanarkhede;[~rudolf.sima], It would help immensely if you can share the controller logs and the entire thread dump when you observe this issue. ;;;","16/Sep/14 12:58;junrao;Rudolf,

Controlled shutdown is designed for rolling bounces. ;;;","08/Feb/15 05:56;jkreps;Does this problem still exist?;;;","09/Feb/15 06:38;becket_qin;I think KAFKA-1305 solved this issue.;;;","01/Sep/17 01:01;omkreddy; Pl reopen if you think the issue still exists
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Performance Regression post SSL implementation,KAFKA-2517,12861815,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,benstopford,benstopford,04/Sep/15 19:46,03/Oct/15 05:46,22/Mar/23 15:10,03/Oct/15 05:46,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"It would appear that we incurred a performance regression on submission of the SSL work affecting the performance of the new Kafka Consumer. 

Running with 1KB messages. Macbook 2.3 GHz Intel Core i7, 8GB, APPLE SSD SM256E. Single server instance. All local. 

kafka-consumer-perf-test.sh ... --messages 3000000  --new-consumer

Pre-SSL changes (commit 503bd36647695e8cc91893ffb80346dd03eb0bc5)
Steady state throughputs = 234.8 MB/s
(2861.5913, 234.8261, 3000596, 246233.0543)

Post-SSL changes (commit 13c432f7952de27e9bf8cb4adb33a91ae3a4b738) 
Steady state throughput =  178.1 MB/s  
(2861.5913, 178.1480, 3000596, 186801.7182)

Implication is a 25% reduction in consumer throughput for these test conditions. 

This appears to be caused by the use of PlaintextTransportLayer rather than SocketChannel in FileMessageSet.writeTo() meaning a zero copy transfer is not invoked.

Switching to the use of a SocketChannel directly in FileMessageSet.writeTo()  yields the following result:
Steady state throughput =  281.8 MB/s
(2861.5913, 281.8191, 3000596, 295508.7650)

",,benstopford,chaitanyap,githubbot,ijuma,junrao,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Oct 02 21:46:30 UTC 2015,,,,,,,,,,"0|i2jsdj:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"04/Sep/15 20:26;ijuma;Performance improves over the baseline then?;;;","04/Sep/15 20:33;benstopford;That would be the implication but I am suspicious of that result in isolation. The key point for this jira is that there is a problem which we need to fix, and there is a potential solution. ;;;","04/Sep/15 20:37;ijuma;Yes, sure.;;;","09/Sep/15 05:40;sriharsha;[~benstopford] it looks like transport layer needs to implement SelChImpl methods and delegate those to socketChannel for the zero-copy to work. Are you working on these changes?;;;","09/Sep/15 06:01;ijuma;Implementing `SelChImpl` is undesirable as it's an internal implementation class in the JDK. A better alternative, in my opinion, is to pass the underlying `SocketChannel` to `transferTo`; Ben verified that this fixes the problem before filing this ticket. I suggest we add a transfer-like method to `TransportLayer`. In the `PlaintextTransportLayer` implementation, it should use the underlying `socketChannel` instead of itself.;;;","09/Sep/15 06:26;benstopford;Yes - what Ismael said. I'll take a look at getting a PR out for this now. ;;;","15/Sep/15 10:19;benstopford;Retesting I've not been able to reproduce this result to statistical significance. I will retest on linux but I suspect this is not a bug. ;;;","17/Sep/15 03:58;ijuma;Even if we can't measure the difference under simple benchmarks like the ones we have, it's important that we restore the zero-copy behaviour as it reduces GC pressure and CPU usage (which should help in production workloads).

It would be better if we could show these benefits in our benchmarks, of course.;;;","02/Oct/15 18:16;ijuma;Talked to Ben about this and he said it was OK for me to pick this up as he's busy at the moment.;;;","02/Oct/15 18:21;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/273

    KAFKA-2517; Performance Regression post SSL implementation (zero copy)

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-2517-ssl-zero-copy-regression

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/273.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #273
    
----
commit fb88692a9e4f62677b91069db017c12ba5b42edd
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2015-10-02T10:10:12Z

    Introduce `TransportLayer.transferFrom` and use it from `FileMessageSet`

----
;;;","02/Oct/15 18:22;ijuma;[~junrao], can you please review?;;;","03/Oct/15 05:46;junrao;Issue resolved by pull request 273
[https://github.com/apache/kafka/pull/273];;;","03/Oct/15 05:46;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/273
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka-acl doesn't allow space in principal name,KAFKA-3152,12934143,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,junrao,junrao,27/Jan/16 00:03,29/Jan/16 17:17,22/Mar/23 15:10,29/Jan/16 08:48,0.9.0.0,,,,,,0.9.0.1,,,,,,,core,,,,0,,,,,,"When running the following,
kafka-acls --authorizer kafka.security.auth.SimpleAclAuthorizer --authorizer-properties zookeeper.connect=localhost:2181 --topic test --add --producer --allow-host=* --allow-principal ""User:CN=xxx,O=My Organization""

the acl is set as the following. The part after space is ignored.
Following is list of acls for resource: Topic:test 
 	User:CN=xxx,O=My has Allow permission for operations: Describe from hosts: *
	User:CN=xxx,O=My has Allow permission for operations: Write from hosts: * 
",,githubbot,ijuma,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jan 29 09:17:53 UTC 2016,,,,,,,,,,"0|i2rzbz:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"27/Jan/16 09:10;ijuma;This is a trivial bug in the kafka-acls shell script. Many other shell scripts have the same problem. Will post a PR tomorrow.;;;","27/Jan/16 19:17;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/818

    KAFKA-3152; kafka-acl doesn't allow space in principal name

    * Add quotes to `$@` in shell scripts
    This is necessary for correct processing of quotes in the
    user command.
    
    * Minor improvements to AclCommand messages
    
    * Use a principal with a space in `SslEndToEndAuthorizationTest`
    This passed without any other changes, but good avoid regressions.
    
    * Clean-up `TestSslUtils`:
    Remove unused methods, fix unnecessary verbosity and don't set security.protocol (it should be done at a higher-level).

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-3152-kafka-acl-space-in-principal

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/818.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #818
    
----
commit 376b537f48dd593c68da7b296554b1ffb857ab98
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-01-27T09:09:40Z

    Add quotes to `$@` in shell scripts
    
    This is necessary for correct processing of quotes in the
    user command.

commit 24ca26bd32f763ce3945e0561ded05312594b3b3
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-01-27T09:19:19Z

    Minor improvements to AclCommand messages

commit 98cd852bb5ecfd4eece25737f1c27f89fdb48c65
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-01-27T09:30:50Z

    Use a principal with a space in `SslEndToEndAuthorizationTest`
    
    Also clean-up `TestSslUtils`:
    * Remove unused methods
    * Fix unnecessary verbosity
    * Don't set security.protocol (it should be done at a higher-level)

----
;;;","28/Jan/16 00:23;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/818
;;;","28/Jan/16 03:25;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/820

    KAFKA-3152; kafka-acl doesn't allow space in principal name (backport to 0.9.0)

    This is a backport of the trunk PR and it excludes the test
    changes due to conflicts and the fact that the changes
    were not directly related to the bug in the end
    (it was something we did not test for, but the non-shell code
    was already correct).
    
    Details:
    
    * Add quotes to `$` in shell scripts
    This is necessary for correct processing of quotes in the
    user command.
    
    * Minor improvements to AclCommand messages

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-3152-backport-kafka-acl-space-in-principal-name

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/820.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #820
    
----
commit 20adaf6677c39865b3a288d112079f12f3842737
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-01-27T16:23:25Z

    KAFKA-3152; kafka-acl doesn't allow space in principal name
    
    This is a backport of the trunk PR and it excludes the test
    changes due to conflicts and the fact that the changes
    were not directly related to the bug in the end
    (it was something we did not test for, but the non-shell code
    was already correct).
    
    Details:
    
    * Add quotes to `$` in shell scripts
    This is necessary for correct processing of quotes in the
    user command.
    
    * Minor improvements to AclCommand messages

----
;;;","29/Jan/16 08:48;junrao;Issue resolved by pull request 820
[https://github.com/apache/kafka/pull/820];;;","29/Jan/16 17:17;githubbot;Github user ijuma closed the pull request at:

    https://github.com/apache/kafka/pull/820
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka-console-consumer throws NoSuchElementException on not specifying topic,KAFKA-2734,12910163,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,singhashish,singhashish,singhashish,04/Nov/15 06:41,07/Nov/15 05:36,22/Mar/23 15:10,07/Nov/15 05:36,0.9.0.0,,,,,,0.9.0.0,,,,,,,tools,,,,0,,,,,,"The logic of argument checking is flawed for kafka-console-consumer. Throws below mentioned exception when topic is not specified. Users wont have a clue what went wrong.

{code}
Exception in thread ""main"" java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:337)
	at scala.collection.immutable.Nil$.head(List.scala:334)
	at kafka.tools.ConsoleConsumer$ConsumerConfig.<init>(ConsoleConsumer.scala:244)
	at kafka.tools.ConsoleConsumer$.main(ConsoleConsumer.scala:40)
	at kafka.tools.ConsoleConsumer.main(ConsoleConsumer.scala)
{code}",,githubbot,guozhang,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 06 21:36:42 UTC 2015,,,,,,,,,,"0|i2nwpr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"04/Nov/15 06:42;githubbot;GitHub user SinghAsDev opened a pull request:

    https://github.com/apache/kafka/pull/412

    KAFKA-2734: kafka-console-consumer throws NoSuchElementException on n…

    …ot specifying topic

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/SinghAsDev/kafka KAFKA-2734

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/412.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #412
    
----
commit 1b8522773d2ff799bb2228c5003d8fce5dcd4e86
Author: Ashish Singh <asingh@cloudera.com>
Date:   2015-11-03T22:42:21Z

    KAFKA-2734: kafka-console-consumer throws NoSuchElementException on not specifying topic

----
;;;","07/Nov/15 05:36;guozhang;Issue resolved by pull request 412
[https://github.com/apache/kafka/pull/412];;;","07/Nov/15 05:36;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/412
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Snappy compression of message batches less efficient in 0.8.2.1,KAFKA-2189,12829259,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,ijuma,AOLSON1@CERNER.COM,AOLSON1@CERNER.COM,13/May/15 01:27,09/Oct/15 01:01,22/Mar/23 15:10,29/May/15 01:16,0.8.2.1,,,,,,0.8.2.2,0.9.0.0,,,,,,build,compression,log,,0,trivial,,,,,"We are using snappy compression and noticed a fairly substantial increase (about 2.25x) in log filesystem space consumption after upgrading a Kafka cluster from 0.8.1.1 to 0.8.2.1. We found that this is caused by messages being seemingly recompressed individually (or possibly with a much smaller buffer or dictionary?) instead of as a batch as sent by producers. We eventually tracked down the change in compression ratio/scope to this [1] commit that updated the snappy version from 1.0.5 to 1.1.1.3. The Kafka client version does not appear to be relevant as we can reproduce this with both the 0.8.1.1 and 0.8.2.1 Producer.

Here are the log files from our troubleshooting that contain the same set of 1000 messages, for batch sizes of 1, 10, 100, and 1000. f9d9b was the last commit with 0.8.1.1-like behavior prior to f5ab8 introducing the issue.

{noformat}
-rw-rw-r-- 1 kafka kafka 404967 May 12 11:45 /var/kafka2/f9d9b-batch-1-0/00000000000000000000.log
-rw-rw-r-- 1 kafka kafka 119951 May 12 11:45 /var/kafka2/f9d9b-batch-10-0/00000000000000000000.log
-rw-rw-r-- 1 kafka kafka  89645 May 12 11:45 /var/kafka2/f9d9b-batch-100-0/00000000000000000000.log
-rw-rw-r-- 1 kafka kafka  88279 May 12 11:45 /var/kafka2/f9d9b-batch-1000-0/00000000000000000000.log

-rw-rw-r-- 1 kafka kafka 402837 May 12 11:41 /var/kafka2/f5ab8-batch-1-0/00000000000000000000.log
-rw-rw-r-- 1 kafka kafka 382437 May 12 11:41 /var/kafka2/f5ab8-batch-10-0/00000000000000000000.log
-rw-rw-r-- 1 kafka kafka 364791 May 12 11:41 /var/kafka2/f5ab8-batch-100-0/00000000000000000000.log
-rw-rw-r-- 1 kafka kafka 380693 May 12 11:41 /var/kafka2/f5ab8-batch-1000-0/00000000000000000000.log
{noformat}

[1] https://github.com/apache/kafka/commit/f5ab8e1780cf80f267906e3259ad4f9278c32d28 ",,AOLSON1@CERNER.COM,gw4722,ijuma,jbrosenberg@gmail.com,jshaw86,junrao,noslowerdna,ottomata,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/May/15 08:37;ijuma;KAFKA-2189.patch;https://issues.apache.org/jira/secure/attachment/12732439/KAFKA-2189.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Oct 08 17:01:39 UTC 2015,,,,,,,,,,"0|i2emr3:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"13/May/15 01:57;AOLSON1@CERNER.COM;I have verified that the issue [1] was introduced in snappy-java 1.1.1.2 and has already been fixed [2], in snappy-java 1.1.1.7.

[1] https://github.com/xerial/snappy-java/issues/100
[2] https://github.com/xerial/snappy-java/commit/dc2dd27f85e5167961883f71ac2681b73b33e5df;;;","13/May/15 08:37;ijuma;Created reviewboard https://reviews.apache.org/r/34144/diff/
 against branch upstream/trunk;;;","13/May/15 22:12;AOLSON1@CERNER.COM;Everything looks good so far in our development environment, the log file sizes were returned back to the 0.8.1.1 baseline when we replaced 1.1.1.6 with 1.1.1.7 in the broker libs. Producer/broker performance was the same or in some cases better.

Should be moving this change into production within the next couple of days to free up some disk space, will update again once we have been running 1.1.1.7 in prod for a few days.;;;","20/May/15 03:54;AOLSON1@CERNER.COM;We've been running with snappy-java 1.1.1.7 in production for four days now with no issues.;;;","28/May/15 16:11;ijuma;Given the positive feedback, it seems like it would be good to get this merged so that more people can test it before the final release?;;;","29/May/15 01:16;junrao;Thanks for the patch. +1 and committed to trunk.;;;","14/Aug/15 01:13;ottomata;Hi all,

The Wikimedia Foundation had a serious production issue when we upgraded to 0.8.2.1 because of this bug.  Snappy compression doesn't work at scale in 0.8.2.1.  I know 0.8.3 is slated for release soon, maybe you should consider doing a 0.8.2.2 release just to get this out there in a stable tag, so that others don't run into this issue.
;;;","26/Sep/15 03:30;jshaw86;Hi all,
I was wondering if this affects only 0.8.2.1 or also 0.8.2? We are on 0.8.2 and just did a complete rebalance across our brokers and some brokers are at 70% disk utilization and some are at 30%. Thanks.;;;","26/Sep/15 06:27;junrao;0.8.2.0 has the same problem since it depends on snappy-java 1.1.1.6.;;;","09/Oct/15 00:43;jbrosenberg@gmail.com;quick question, I assume there should be no issues with upgrading brokers and/or producers/consumers independently with this change?  E.g. can snappy 1.1.1.6 and 1.1.1.7 interoperate without any compatibility issues?;;;","09/Oct/15 01:01;noslowerdna;[~jbrosenberg@gmail.com] Yes your assumption is correct, this was only an efficiency/chunking issue and not any protocol incompatibility.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Looks like its possible to delete _consumer_offsets topic,KAFKA-1961,12775499,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ted.m,gwenshap,gwenshap,17/Feb/15 12:27,04/Apr/15 07:30,22/Mar/23 15:10,04/Apr/15 02:44,0.8.2.0,,,,,,,,,,,,,,,,,0,newbie,,,,,"Noticed that kafka-topics.sh --delete can successfully delete internal topics (__consumer_offsets).

I'm pretty sure we want to prevent that, to avoid users shooting themselves in the foot.

Topic admin command should check for internal topics, just like ReplicaManager does and not let users delete them.",,gwenshap,jjkoshy,jkreps,junrao,nehanarkhede,ted.m,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Apr/15 00:56;ted.m;KAFKA-1961-6.patch;https://issues.apache.org/jira/secure/attachment/12709263/KAFKA-1961-6.patch","23/Feb/15 01:44;ted.m;KAFKA-1961.3.patch;https://issues.apache.org/jira/secure/attachment/12700105/KAFKA-1961.3.patch","23/Feb/15 05:17;ted.m;KAFKA-1961.4.patch;https://issues.apache.org/jira/secure/attachment/12700117/KAFKA-1961.4.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Apr 03 23:30:41 UTC 2015,,,,,,,,,,"0|i25p9b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"18/Feb/15 01:27;nehanarkhede;That's a good catch [~gwenshap]. Seems like a bug.;;;","18/Feb/15 01:43;jkreps;This would be hard to do accidentally, right, you have to type out the name of the topic you want to delete? Is there ever a valid reason to do this, e.g. you want to clean up all the offsets so you delete and recreate. Does that actually work or would something terrible happen (since state in broker wouldn't get reset)?;;;","18/Feb/15 03:19;gwenshap;[~jkreps] - by ""accidentally"" I mean, ""I don't know what this topic is, so I probably don't need it. Lets delete!"". 
I've seen this happen twice in the last few weeks. I wrote off the first incident, but two is a trend :)

We have utility for cleaning offsets per consumer group or topic in the consumer tool (or at least I think we have them? or planning to have them?). I think deleting an entire topic is pretty extreme. Perhaps we can allow it with a code-level flag (if someone calls the object directly) but hide the capability in the CLI? 
I think we do something similar in producing to internal topics.

;;;","18/Feb/15 03:55;jkreps;Makes sense.

[~jjkoshy] Deleting the topic would leave the broker in an inconsistent state, right? If this is the case I think we should just prevent it as Gwen suggests.;;;","18/Feb/15 05:26;jjkoshy;Yes it would be inconsistent in that you would lose offsets but we don't actually purge from the offsets cache if that happens. I agree that we should prevent this from happening in the first place.

We could expose a broker-side config to allow deleting internal topics but I think the better approach would be a combination of KIP-4 (topic command RPC) with authorization.
;;;","18/Feb/15 05:30;jkreps;Yeah I think since the cache would be totally out of sync it is basically an error--you can't use this as a way to reset offsets. Let's just disable it in the command line tool, that is probably good enough, right?;;;","21/Feb/15 07:05;nehanarkhede;Yes, that's what I was thinking. +1 on removing it from the tool only.;;;","23/Feb/15 01:43;ted.m;Hey Gwen,

Thank you for the help here is the link to Review Board.

https://reviews.apache.org/r/31271/

I will add this to the jira and mark the Jira as patch available ;;;","23/Feb/15 01:46;ted.m;The change makes it so the user can not delete topics that are contained in Topic.InternalTopics.

If they do they will be notified.

Patch also included unit tests;;;","23/Feb/15 01:49;gwenshap;Thank you [~ted.m].

Patch and test looks good to me.

[~nehanarkhede], [~jkreps] or [~jjkoshy] - can one of you take a look and see if its read for commit?;;;","23/Feb/15 05:17;ted.m;Changed action from print statement to exception.  Also updated unit test;;;","26/Feb/15 00:05;ted.m;Let me know if there are any other changes I need to make before this can get committed.

Thanks;;;","18/Mar/15 03:36;gwenshap;ping [~nehanarkhede] :)

I think this is ready for commit?;;;","01/Apr/15 05:05;gwenshap;pinging for review again [~nehanarkhede]...;;;","02/Apr/15 22:38;ted.m;Hey there,

This jira and 2016 have been hanging around for some time.  Is there anything I can do to get them committed or are there changes I need to do.  Let me know.

It would mean a lot to me to get my first Kafka patch.  Thanks

Ted Malaska;;;","03/Apr/15 09:23;junrao;[~ted.m], thanks for the patch. Just added a minor comment to the RB. Once it's addressed, we can commit it.;;;","04/Apr/15 00:56;ted.m;Updated based on comments;;;","04/Apr/15 02:31;nehanarkhede;+1. Checking it in...;;;","04/Apr/15 02:44;nehanarkhede;Thanks for the patch, Ted! Pushed to trunk.;;;","04/Apr/15 07:30;ted.m;Thank you Neha for the final review.

Thank you also Jun and Gwen.  I will work with Gwen to try to find another jira in the next couple of weeks.

Thank you again.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a flush() call to the new producer API,KAFKA-1865,12767631,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,jkreps,jkreps,15/Jan/15 10:17,12/Mar/15 12:06,22/Mar/23 15:10,01/Mar/15 07:52,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"The postconditions of this would be that any record enqueued prior to flush() would have completed being sent (either successfully or not).

An open question is whether you can continue sending new records while this call is executing (on other threads).

We should only do this if it doesn't add inefficiencies for people who don't use it.",,becket_qin,criccomini,guozhang,jkreps,junrao,navina,nehanarkhede,norden.tom,otis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SAMZA-524,,,,,,,,,,,,,,SAMZA-227,,KAFKA-1863,,,,,,,,"08/Feb/15 04:59;jkreps;KAFKA-1865.patch;https://issues.apache.org/jira/secure/attachment/12697291/KAFKA-1865.patch","22/Feb/15 07:37;jkreps;KAFKA-1865_2015-02-21_15:36:54.patch;https://issues.apache.org/jira/secure/attachment/12700064/KAFKA-1865_2015-02-21_15%3A36%3A54.patch","23/Feb/15 08:26;jkreps;KAFKA-1865_2015-02-22_16:26:46.patch;https://issues.apache.org/jira/secure/attachment/12700125/KAFKA-1865_2015-02-22_16%3A26%3A46.patch","24/Feb/15 10:29;jkreps;KAFKA-1865_2015-02-23_18:29:16.patch;https://issues.apache.org/jira/secure/attachment/12700315/KAFKA-1865_2015-02-23_18%3A29%3A16.patch","26/Feb/15 09:15;jkreps;KAFKA-1865_2015-02-25_17:15:26.patch;https://issues.apache.org/jira/secure/attachment/12700927/KAFKA-1865_2015-02-25_17%3A15%3A26.patch","27/Feb/15 02:37;jkreps;KAFKA-1865_2015-02-26_10:37:16.patch;https://issues.apache.org/jira/secure/attachment/12701140/KAFKA-1865_2015-02-26_10%3A37%3A16.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Feb 26 19:18:04 UTC 2015,,,,,,,,,,"0|i24e6v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"07/Feb/15 15:04;jkreps;A key aspect of this that isn't obvious is that flush() has to disable linger.

That is say I have linger.ms=3000
If I do 
{code}
for(int i = 0; i < 1000; i++)
   producer.send(new ProducerRecord(""topic"", Integer.toString(i));
producer.flush();
{code}

The flush call isn't as simple as just blocking on the record accumulator draining since that would mean waiting an extra 3 seconds during which of course no other records will be written. So flush should trigger immediate send just as close and memory exhaustion do in the record accumulator.;;;","08/Feb/15 04:59;jkreps;Created reviewboard https://reviews.apache.org/r/30763/diff/
 against branch trunk;;;","22/Feb/15 07:37;jkreps;Updated reviewboard https://reviews.apache.org/r/30763/diff/
 against branch trunk;;;","22/Feb/15 12:46;jkreps;Actually this approach is fundamentally flawed. This patch waits on the completion of all requests in the record accumulator but not any requests that have already been sent. To be correct we need to wait on both.

I think the right approach is to keep a set of all the ProduceRequestResults that are currently incomplete. We would add to this set as soon as a new batch is created and remote it once it is completed. Then flush would just wait on all these.

I'll redo this but not tonight.;;;","22/Feb/15 16:58;becket_qin;Yes you are right, Jay. This approach sounds good. Thanks.;;;","23/Feb/15 08:26;jkreps;Updated reviewboard https://reviews.apache.org/r/30763/diff/
 against branch trunk;;;","23/Feb/15 08:28;jkreps;Uploaded a new patch that tracks all incomplete RecordBatch's in the RecordAccumulator and uses these to block on for flush.

I was having trouble with test hangs, but I'm not sure if they are related to this patch or not so I haven't yet validated the tests.

I also improved the producer javadoc while in there since I was adding docs for flush.;;;","23/Feb/15 08:43;guozhang;Does it hang on ConsumerTest? Maybe we can disable it for now while I work on fixing the test.;;;","24/Feb/15 00:34;nehanarkhede;+1 :-);;;","24/Feb/15 10:29;jkreps;Updated reviewboard https://reviews.apache.org/r/30763/diff/
 against branch trunk;;;","26/Feb/15 09:15;jkreps;Updated reviewboard https://reviews.apache.org/r/30763/diff/
 against branch trunk;;;","27/Feb/15 02:37;jkreps;Updated reviewboard https://reviews.apache.org/r/30763/diff/
 against branch trunk;;;","27/Feb/15 03:18;junrao;The KIP (https://cwiki.apache.org/confluence/display/KAFKA/KIP-8+-+Add+a+flush+method+to+the+producer+API) still says one flush at a time. We will need to change that.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Yet another deadlock in controller shutdown,KAFKA-1429,12711037,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,dmitrybugaychenko,dmitrybugaychenko,29/Apr/14 05:35,01/Dec/16 00:13,22/Mar/23 15:10,24/Nov/16 00:40,0.8.1,,,,,,,,,,,,,controller,,,,0,reliability,,,,,"Found one more case of deadlock in controller during shutdown:

{code}
ZkClient-EventThread-57-192.168.41.148:2181,192.168.36.250:2181,192.168.41.207:2181 id=57 state=TIMED_WAITING
    - waiting on <0x288a66ec> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    - locked <0x288a66ec> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at sun.misc.Unsafe.park(Native Method)
    at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)
    at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1468)
    at kafka.utils.KafkaScheduler.shutdown(KafkaScheduler.scala:88)
    at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply$mcV$sp(KafkaController.scala:339)
    at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply(KafkaController.scala:337)
    at kafka.controller.KafkaController$$anonfun$onControllerResignation$1.apply(KafkaController.scala:337)
    at kafka.utils.Utils$.inLock(Utils.scala:538)
    at kafka.controller.KafkaController.onControllerResignation(KafkaController.scala:337)
    at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1068)
    at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1067)
    at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1067)
    at kafka.utils.Utils$.inLock(Utils.scala:538)
    at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1067)
    at org.I0Itec.zkclient.ZkClient$4.run(ZkClient.java:472)
    at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)

    Locked synchronizers: count = 1
      - java.util.concurrent.locks.ReentrantLock$NonfairSync@22b9b31a

kafka-scheduler-0 id=172 state=WAITING
    - waiting on <0x22b9b31a> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
    - locked <0x22b9b31a> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
     owned by ZkClient-EventThread-57-192.168.41.148:2181,192.168.36.250:2181,192.168.41.207:2181 id=57
    at sun.misc.Unsafe.park(Native Method)
    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:867)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1197)
    at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:214)
    at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:290)
    at kafka.utils.Utils$.inLock(Utils.scala:536)
    at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$17.apply(KafkaController.scala:1110)
    at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$17.apply(KafkaController.scala:1108)
    at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
    at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
    at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
    at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
    at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
    at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1108)
    at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1087)
    at scala.collection.immutable.Map$Map4.foreach(Map.scala:181)
    at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1087)
    at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:323)
    at kafka.utils.KafkaScheduler$$anon$1.run(KafkaScheduler.scala:100)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    at java.lang.Thread.run(Thread.java:744)

    Locked synchronizers: count = 1
      - java.util.concurrent.ThreadPoolExecutor$Worker@7d6e8aba
{code}

Just before the shutdown broker entered a state where it was not able to update ISR and replication was not progressing (this was the reason for restart):

{code}
Apr 29 01:09:52 srvd2229 odnoklassniki-databus[5571]: 2014-04-29 01:09:52,189  INFO [kafka-scheduler-1] Partition - Partition [stabilityTestSecond,9] on broker 4: Shrinking ISR for partition [stabilityTe
stSecond,9] from 4,2 to 4
Apr 29 01:09:52 srvd2229 odnoklassniki-databus[5571]: 2014-04-29 01:09:52,210 ERROR [kafka-scheduler-1] ZkUtils$ - Conditional update of path /brokers/topics/stabilityTestSecond/partitions/9/state with d
ata {""controller_epoch"":20,""leader"":4,""version"":1,""leader_epoch"":38,""isr"":[4]} and expected version 134 failed due to org.apache.zookeeper.KeeperException$BadVersionException: KeeperErrorCode = BadVersio
n for /brokers/topics/stabilityTestSecond/partitions/9/state
Apr 29 01:09:52 srvd2229 odnoklassniki-databus[5571]: 2014-04-29 01:09:52,210  INFO [kafka-scheduler-1] Partition - Partition [stabilityTestSecond,9] on broker 4: Cached zkVersion [134] not equal to that
 in zookeeper, skip updating ISR
{code}

Right before the broker entered this state there was a temporary connection loss to ZK due to GC fo 5 seconds.",,dmitrybugaychenko,githubbot,hongyu.bi,junrao,nehanarkhede,pengwei,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-4360,,,,,,,,,,,,,,,,,,"18/Jun/16 09:22;pengwei;kafka_0.9.0.0_controller_dead_lock.patch;https://issues.apache.org/jira/secure/attachment/12811501/kafka_0.9.0.0_controller_dead_lock.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,389358,,,Thu Nov 24 00:45:10 UTC 2016,,,,,,,,,,"0|i1v2g7:",389604,,,,,,,,,,,,,,,,,,,,"29/Apr/14 06:12;nehanarkhede;Could you try this on 0.8.1.1? We fixed a bunch of deadlock related issues in 0.8.1.1;;;","29/Apr/14 21:42;dmitrybugaychenko;Updated libs to 0.8.1.1, will see how it goes.;;;","29/Apr/14 23:08;junrao;Did you have auto.leader.rebalance.enable set to true? If so, there is known bug https://issues.apache.org/jira/browse/KAFKA-1305 that may be related to this.;;;","30/Apr/14 17:08;dmitrybugaychenko;Yes, we have auto.leader.rebalance.enable set to true. What is the estimated release date for 0.8.2 with the fixes?;;;","30/Apr/14 22:12;junrao;Probably in a month or two.;;;","15/Jun/16 18:47;pengwei;I can still reproduce this issue in 0.9.0.0 or 0.9.0.1,  Controller session expire and holding the controllerLock lock and try to wait the autoRebalanceScheduler thread to shutdown,  but 
the autoRebalanceScheduler is running for the parttion rebalance and this thread want the controllerLock : 

""ZkClient-EventThread-18-9.94.1.21:2181,9.94.1.22:2181,9.94.1.23:2181/oms-cluster-1"" #18 daemon prio=5 os_prio=0 tid=0x0000000000c3f800 nid=0x49be waiting on condition [0x00007f466603d000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000000d9eaace0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1465)
	at kafka.utils.KafkaScheduler.shutdown(KafkaScheduler.scala:98)
	at kafka.controller.KafkaController.onControllerResignation(KafkaController.scala:370)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1171)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1170)
	at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:734)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)


""kafka-scheduler-12"" #143 daemon prio=5 os_prio=0 tid=0x00007f465c4cc000 nid=0x566f waiting on condition [0x00007f466260e000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000000c0a9a480> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199)
	at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:209)
	at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:260)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1198)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745);;;","18/Jun/16 09:22;pengwei;upload file is the patch to fix this bug, can somebody review it ?;;;","22/Jun/16 13:06;junrao;[~pengwei], yes, it's a real bug. Thanks for finding and reporting this. It seems that we will also need to fix SessionExpirationListener in KafkaController. For easy review, is it convenient for you to submit the patch through a pull request (see https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes)?;;;","10/Jul/16 09:32;githubbot;GitHub user pengwei-li opened a pull request:

    https://github.com/apache/kafka/pull/1603

     KAFKA-1429: Yet another deadlock in controller shutdown

     Author: pengwei <pengwei.li@huawei.com>
    
     Reviewers: NA

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/pengwei-li/kafka trunk

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1603.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1603
    
----
commit a920d4e9807add634cc44e4b7cf9e156edd515cf
Author: pengwei-li <pengwei.li@huawei.com>
Date:   2016-07-10T00:31:56Z

     KAFKA-1429: Yet another deadlock in controller shutdown
    
     Author: pengwei <pengwei.li@huawei.com>
    
     Reviewers: NA

----
;;;","24/Jul/16 09:10;pengwei;hi Jun, I have open a PR for this issue. Can you review it? thanks~;;;","24/Nov/16 00:40;junrao;This is already fixed by KAFKA-4360.;;;","24/Nov/16 08:45;githubbot;Github user pengwei-li closed the pull request at:

    https://github.com/apache/kafka/pull/1603
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Partition reassignment resets clock for time-based retention,KAFKA-1379,12707581,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,jjkoshy,jjkoshy,10/Apr/14 06:25,12/Aug/17 05:20,22/Mar/23 15:10,12/Aug/17 05:20,,,,,,,0.10.1.0,,,,,,,log,,,,5,,,,,,"Since retention is driven off mod-times reassigned partitions will result in
data that has been on a leader to be retained for another full retention
cycle. E.g., if retention is seven days and you reassign partitions on the
sixth day then those partitions will remain on the replicas for another
seven days.

",,elevy,elukey,jeffwidman,jjkoshy,Karolis,kzakee,moritz,noslowerdna,r.vonmassow,xvrl,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3802,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,385904,,,Fri Aug 11 21:20:49 UTC 2017,,,,,,,,,,"0|i1uhan:",386168,,,,,,,,,,,,,,,,,,,,"23/Feb/15 22:21;moritz;This also happens when a broker dies and loses it's data. 

When the broker comes back without any data it will use more and more disk space until it doubles the used disk space until the retention kicks in and the usage drops to normal.

IMHO this is pretty bad for disaster scenarios, so I would like to see a higher prio on this.
;;;","24/Feb/15 10:05;jjkoshy;We have been thinking through various alternatives and this is included in a proposal here: https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Enriched+Message+Metadata;;;","23/Sep/15 02:55;xvrl;This is a huge issue for us as well, since it requires we keep double the disk capacity on hand, in case one of our brokers or disks fails, which happens relatively often at our scale.

Alternatively, we have to go in and remove expired segments by hand, by comparing replicated segments with the partition leader, before disks run out of space.
;;;","26/May/16 18:54;moritz;From the user-mailinglist:

{quote}
We’ve recently upgraded to 0.9.  In 0.8, when we restarted a broker, data
log file mtimes were not changed.  In 0.9, any data log file that was on
disk before the broker has it’s mtime modified to the time of the broker
restart.
{quote}

A workaround can be to set {{retention.bytes}} on a topic level, like this:

{noformat}
./bin/kafka-topics.sh --zookeeper X.X.X.X:2181/kafka -alter --config retention.bytes=5000000 –topic my_topic
{noformat}

The settings controls the max size in bytes of a partition oft he specified topic. So you can find a good size by checking the size of a partition with {{du -b}} and use this value.;;;","01/Jun/16 18:08;elukey;Hi Moritz,

thanks a lot for pointing us to this Jira in users@. At the moment we use a similar trick to resolve disk partitions filling up (retention.ms):
https://wikitech.wikimedia.org/wiki/Analytics/Cluster/Kafka/Administration#Temporarily_Modify_Per_Topic_Retention_Settings

I also opened a Phabricator task to track this problem https://phabricator.wikimedia.org/T136690

retention.bytes is definitely worth to try, but is there anything else that can mitigate this issue?;;;","21/Jan/17 01:38;noslowerdna;[~jjkoshy] / [~becket_qin] should this Jira now be closed as a duplicate of KAFKA-3163?

https://cwiki.apache.org/confluence/display/KAFKA/KIP-33+-+Add+a+time+based+log+index#KIP-33-Addatimebasedlogindex-Enforcetimebasedlogretention;;;","28/Jun/17 05:11;noslowerdna;[~hachikuji] Jason, could you confirm if this bug has been fixed? According to http://kafka.apache.org/documentation.html#upgrade_10_1_breaking it appears so.;;;","12/Aug/17 05:20;noslowerdna;Marking this bug as resolved in 0.10.1.0 based on the statement ""The log retention time is no longer based on last modified time of the log segments. Instead it will be based on the largest timestamp of the messages in a log segment."" in http://kafka.apache.org/documentation.html#upgrade_10_1_breaking;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsumerIterator implemented by KafkaStream doesn't follow Java practices,KAFKA-520,12608015,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,parantumaton,parantumaton,18/Sep/12 14:56,01/Oct/14 06:18,22/Mar/23 15:10,01/Oct/14 06:18,0.7,0.7.1,,,,,,,,,,,,,,,,1,,,,,,"As a foreword, this only applies to Java conventions - if things are different on the Scala side, then so be it and that's fine.

As mentioned in the summary, ConsumerIterator doesn't follow proper Java practices, to be exact it doesn't follow them in its functionality. The biggest offender is the #hasNext() method which blocks until ConsumerTimeoutException is thrown. While it is obvious that this is because the targeted use-case is infinite consuming of a given topic, it did confuse me as an API integration programmer since the documentation was severely lacking and I only started to observe this problem in our staging environment.

There are multiple ways that I find appropriate to fix this:
- Instead of implementing java.util.Iterator, make the class an implementation of BlockingQueue. Since BlockingQueue is in the java.util.concurrent package, it should nudge the user's mind to correct tracks about the class' semantics immediately.
- Get rid of the concept of internal infinite iteration and instead make the Iterator represent one fetched block of data; that way the infinite loop for consuming can be something like
while (!Thread.interrupted) {
    Iterator it = ks.readMore(...);
    while (iterator.hasNext()) {
        /* consume messages */
    }
}
In addition to clearer Java API, this also gets rid of the exception being used for flow control which, once again, doesn't fit to Java best practices.
- Update the documentation (both API and quickstart) to explain how to recover from such failure.",,jkreps,mumrah,parantumaton,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,299154,,,Tue Sep 30 22:18:30 UTC 2014,,,,,,,,,,"0|i15zxj:",243121,,,,,,,,,,,,,,,,,,,,"13/Mar/13 22:34;mumrah;This has bitten me as well. Under the covers ConsumerIterator is polling a BlockingQueue anyways, so maybe it does make sense to expose this API to users.;;;","01/Oct/14 05:31;jwartes;This is still true two years later. 

Something that implements Iterator but cannot return false is clearly a broken implementation. 
Blocking here requires extensive gymnastics to handle correctly in a concurrent architecture like akka.

Is this deprecated? Is there a more preferred method of consumption?;;;","01/Oct/14 06:18;jkreps;This is being fixed in the new consumer implementation.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Consumer doesn't receive all data if there are multiple segment files,KAFKA-372,12595466,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,jfung,jfung,22/Jun/12 02:30,27/Jun/12 00:24,22/Mar/23 15:10,26/Jun/12 23:47,0.8.0,,,,,,,,,,,,,core,,,,0,,,,,,"This issue happens inconsistently but could be reproduced by following the steps below (repeat step 4 a few times to reproduce it):

1. Check out 0.8 branch (currently reproducible with rev. 1352634)

2. Apply kafka-306-v4.patch

3. Please note that the log.file.size is set to 10000000 in system_test/broker_failure/config/server_*.properties (small enough to trigger multi segment files)

4. Under the directory <kafka home>/system_test/broker_failure, execute command:
$ bin/run-test.sh 20 0

5. After the test is completed, the result will probably look like the following:

========================================================
no. of messages published            : 14000
producer unique msg rec'd            : 14000
source consumer msg rec'd            : 7271
source consumer unique msg rec'd     : 7271
mirror consumer msg rec'd            : 6960
mirror consumer unique msg rec'd     : 6960
total source/mirror duplicate msg    : 0
source/mirror uniq msg count diff    : 311
========================================================

6. By checking the kafka log files, the sum of the sizes of the source cluster segments files are equal to those in the target cluster.

[/tmp] $  find kafka* -name *.kafka -ls

18620155 9860 -rw-r--r--   1 jfung    eng      10096535 Jun 21 11:09 kafka-source3-logs/test01-0/00000000000000000000.kafka
18620161 9772 -rw-r--r--   1 jfung    eng      10004418 Jun 21 11:11 kafka-source3-logs/test01-0/00000000000020105286.kafka
18620160 9776 -rw-r--r--   1 jfung    eng      10008751 Jun 21 11:10 kafka-source3-logs/test01-0/00000000000010096535.kafka
18620162 4708 -rw-r--r--   1 jfung    eng       4819067 Jun 21 11:11 kafka-source3-logs/test01-0/00000000000030109704.kafka
19406431 9920 -rw-r--r--   1 jfung    eng      10157685 Jun 21 11:10 kafka-target2-logs/test01-0/00000000000010335039.kafka
19406429 10096 -rw-r--r--   1 jfung    eng      10335039 Jun 21 11:09 kafka-target2-logs/test01-0/00000000000000000000.kafka
19406432 10300 -rw-r--r--   1 jfung    eng      10544850 Jun 21 11:11 kafka-target2-logs/test01-0/00000000000020492724.kafka
19406433 3800 -rw-r--r--   1 jfung    eng       3891197 Jun 21 11:12 kafka-target2-logs/test01-0/00000000000031037574.kafka

7. If the log.file.size in target cluster is configured to a very large value such that there is only 1 data file, the result would look like this:

========================================================
no. of messages published            : 14000
producer unique msg rec'd            : 14000
source consumer msg rec'd            : 7302
source consumer unique msg rec'd     : 7302
mirror consumer msg rec'd            : 13750
mirror consumer unique msg rec'd     : 13750
total source/mirror duplicate msg    : 0
source/mirror uniq msg count diff    : -6448
========================================================

8. The log files are like these:

[/tmp] $ find kafka* -name *.kafka -ls

18620160 9840 -rw-r--r--   1 jfung    eng      10075058 Jun 21 11:24 kafka-source2-logs/test01-0/00000000000010083679.kafka
18620155 9848 -rw-r--r--   1 jfung    eng      10083679 Jun 21 11:23 kafka-source2-logs/test01-0/00000000000000000000.kafka
18620162 4484 -rw-r--r--   1 jfung    eng       4589474 Jun 21 11:26 kafka-source2-logs/test01-0/00000000000030269045.kafka
18620161 9876 -rw-r--r--   1 jfung    eng      10110308 Jun 21 11:25 kafka-source2-logs/test01-0/00000000000020158737.kafka
19406429 34048 -rw-r--r--   1 jfung    eng      34858519 Jun 21 11:26 kafka-target3-logs/test01-0/00000000000000000000.kafka
",,jfung,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/12 08:56;junrao;kafka-372_v1.patch;https://issues.apache.org/jira/secure/attachment/12533416/kafka-372_v1.patch","25/Jun/12 12:11;jfung;multi_seg_files_data_loss_debug.patch;https://issues.apache.org/jira/secure/attachment/12533252/multi_seg_files_data_loss_debug.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,248186,,,Tue Jun 26 16:24:14 UTC 2012,,,,,,,,,,"0|i09m4f:",54017,,,,,,,,,,,,,,,,,,,,"25/Jun/12 12:11;jfung;** Uploaded a patch with a simplified scenario to reproduce the data loss in multi segment files. 

** This patch provides a script ""run-test-debug.sh"" to do the following:
1. Start 1 broker
2. Start a modified version of Producer to send 300 messages with user specified message string length (500 chars will reproduce the issue while 50 chars will not). This producer produces messages with sequence ID and send the messages in sequence starting from 1, 2, 3, … Etc.
3. Start ConsoleConsumer to receive data

** To reproduce the issue, under <kafka home>/system_test/broker_failure, execute the following command:

$ bin/run-test-debug.sh 500 (which means each message string is 500 chars long)

The consumer only receives the first 120 messages. (This is verified by checking kafka.tools.DumpLogSegments.
========================================================
no. of messages published            : 300
producer unique msg rec'd            : 300
source consumer msg rec'd            : 120
source consumer unique msg rec'd     : 120
========================================================

The number of segment files are 

$ ls -l /tmp/kafka-source1-logs/test01-0/
-rw-r--r--   1 jfung  wheel  10431 Jun 24 20:59:21 2012 00000000000000000000.kafka
-rw-r--r--   1 jfung  wheel  10440 Jun 24 20:59:22 2012 00000000000000010431.kafka
-rw-r--r--   1 jfung  wheel  10440 Jun 24 20:59:23 2012 00000000000000020871.kafka
-rw-r--r--   1 jfung  wheel  10440 Jun 24 20:59:24 2012 00000000000000031311.kafka
-rw-r--r--   1 jfung  wheel  10441 Jun 24 20:59:26 2012 00000000000000041751.kafka
-rw-r--r--   1 jfung  wheel  10460 Jun 24 20:59:27 2012 00000000000000052192.kafka
-rw-r--r--   1 jfung  wheel  10460 Jun 24 20:59:28 2012 00000000000000062652.kafka
-rw-r--r--   1 jfung  wheel  10460 Jun 24 20:59:29 2012 00000000000000073112.kafka
-rw-r--r--   1 jfung  wheel  10460 Jun 24 20:59:31 2012 00000000000000083572.kafka
-rw-r--r--   1 jfung  wheel  10460 Jun 24 20:59:32 2012 00000000000000094032.kafka
-rw-r--r--   1 jfung  wheel  10460 Jun 24 20:59:33 2012 00000000000000104492.kafka
-rw-r--r--   1 jfung  wheel  10460 Jun 24 20:59:34 2012 00000000000000114952.kafka
-rw-r--r--   1 jfung  wheel  10460 Jun 24 20:59:35 2012 00000000000000125412.kafka
-rw-r--r--   1 jfung  wheel  10460 Jun 24 20:59:37 2012 00000000000000135872.kafka
-rw-r--r--   1 jfung  wheel  10460 Jun 24 20:59:38 2012 00000000000000146332.kafka
-rw-r--r--   1 jfung  wheel      0 Jun 24 20:59:38 2012 00000000000000156792.kafka
-rw-r--r--   1 jfung  wheel      8 Jun 24 21:00:08 2012 highwatermark


** However, if the length of each message string is changed to a lower value 50, the issue won't be showing:

$ bin/run-test-debug.sh 50

The consumer receives all data:
========================================================
no. of messages published            : 300
producer unique msg rec'd            : 300
source consumer msg rec'd            : 300
source consumer unique msg rec'd     : 300
========================================================

The number of segment files are

$  ls -l /tmp/kafka-source1-logs/test01-0
total 64
-rw-r--r--  1 jfung  wheel  10039 Jun 24 20:29:26 2012 00000000000000000000.kafka
-rw-r--r--  1 jfung  wheel  10001 Jun 24 20:29:34 2012 00000000000000010039.kafka
-rw-r--r--  1 jfung  wheel   1752 Jun 24 20:29:36 2012 00000000000000020040.kafka
-rw-r--r--  1 jfung  wheel      8 Jun 24 20:30:06 2012 highwatermark
;;;","26/Jun/12 08:56;junrao;There were several issues that caused the problem.

1. Log.nextAppendOffset() calls flush each time. Since this method is called for every produce request, we force a disk flush for every produce request independent of the flush interval in the broker config. This makes producers very slow.

2. The default value for MaxFetchWaitMs in consumer config is 3 secs, which is too long.

3. The script runs console consumer in background and only waits for 20 secs, which is too short. What we should do is to run console consumer in foreground and wait until it finishes (since it has consumer timeout).

Attach patch v1 that fixes items 1 and 2. The test now passes. However, we should address item 3 in the script too.;;;","26/Jun/12 23:47;jfung;Thanks Jun. It is working correctly after applying kafka-372-v1.patch.;;;","27/Jun/12 00:24;junrao;Thanks John for reviewing the patch. Committed to 0.8.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make KafkaStreams debugging friendly,KAFKA-3262,12941251,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,enothereska,yasuhiro.matsuda,yasuhiro.matsuda,23/Feb/16 09:04,01/Feb/17 10:16,22/Mar/23 15:10,11/Nov/16 22:50,0.10.0.0,,,,,,,,,,,,,streams,,,,0,user-experience,,,,,"Current KafkaStreams polls records in the same thread as the data processing thread. This makes debugging user code, as well as KafkaStreams itself, difficult. When the thread is suspended by the debugger, the next heartbeat of the consumer tie to the thread won't be send until the thread is resumed. This often results in missed heartbeats and causes a group rebalance. So it may will be a completely different context then the thread hits the break point the next time.
We should consider using separate threads for polling and processing.",,boniek,enothereska,guozhang,jkreps,nehanarkhede,yasuhiro.matsuda,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3338,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 11 14:50:00 UTC 2016,,,,,,,,,,"0|i2t6vr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"24/Feb/16 03:57;jkreps;This is a good catch, I ran into this issue too. Another issue is that the clients default to debug logging which is not ideal for development (it can be kind of confusing whether something is happening or not since all the action is in the event loop).

I'm a little reticent about fixing this issue by background threading though. A few things to be careful of:
1. The complexity of orchestration back and forth from the thread is complicated
2. If we use a blocking queue to pass data it will be really important to batch actions to not kill performance (or at least that was our finding before).
3. Having a single thread and having the debugging step into the consumer itself is actually more transparent (I think) and will make various failure scenarios work the way we want (e.g. the contract in the consumer is if there is a fatal error to throw an exception which should propagate and not just kill the bg thread).

I suppose an alternative to changing the threading model would be just to set the timeout really high in development. It occurs to me there are several things you might want in development:
1. Large or infinite session timeout
2. More logging
3. Single threaded?
4. Re-start from the beginning of the inputs?
5. Recreate intermediate topics?

Dunno, maybe there should be some kind of overall ""dev-mode"" for all of this? Just thinking out loud...;;;","30/Mar/16 06:06;guozhang;I agree that for development cycle we should enforce ""single thread"".

[~jkreps] What do you mean by ""Another issue is that the clients default to debug logging""?;;;","07/Apr/16 09:49;guozhang;One more thing that we have observed: currently Kafka Streams will decide whether or not to trigger poll() purely based on the size of its buffered data, but not considering the heartbeat intervals. As a result for complex topology, it is likely to get false positive failure detection with small session.timeout.ms. cc [~norwood];;;","11/Nov/16 22:50;enothereska;This is now fixed with KIP-62;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zookeeper-shell does not work,KAFKA-2385,12850312,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,fpj,becket_qin,becket_qin,31/Jul/15 01:26,28/Aug/18 15:20,22/Mar/23 15:10,28/Aug/18 15:20,,,,,,,,,,,,,,tools,,,,1,,,,,,"The zookeeper shell shipped with Kafka does not work because jline jar is missing.

[jqin@jqin-ld1 bin]$ ./zookeeper-shell.sh localhost:2181
Connecting to localhost:2181
Welcome to ZooKeeper!
JLine support is disabled

WATCHER::

WatchedEvent state:SyncConnected type:None path:null",,becket_qin,ewencp,fpj,jlaskowski,joaobreis,omkreddy,pbharaj,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Aug 28 07:20:06 UTC 2018,,,,,,,,,,"0|i2i4tb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"31/Jul/15 15:50;ewencp;What exactly doesn't work here? It complains that JLine support is disabled, but if I run some commands they work (e.g. help or ls /). Is the issue that editing commands isn't as pleasant since it doesn't have jline?

Quick scan of https://issues.apache.org/jira/browse/ZOOKEEPER-1655 suggests jline should be required until 3.5.0, but it seems to function ok for me. Maybe [~fpj] can shed some light since he was involved in the ZK bug.;;;","31/Jul/15 23:41;fpj;I'm also unclear on what the problem is here. You're getting a SyncConnected event, so you should be good to go, [~becket_qin].
;;;","01/Aug/15 00:57;becket_qin;[~ewencp] [~fpj], Ah, you are right. It actually works. I saw from mailing list that some user said it does not show connected as zkCli does. I tried myself and saw the same thing and did not try any further command. I'll close it as not a problem. Thanks.;;;","18/Aug/15 22:03;pbharaj;I had reported the shell does not appear, if I dont use the jline jar

jline jar is not present as a part of the tarball. So, as a new user, if I want to explore kafka data structures in zookeeper, I can not do that until I have the jline jar with me

Hope this explains;;;","18/Aug/15 22:06;fpj;Ok, I'll check, and in the meanwhile, you can just get a copy of the zk distribution directly and use the CLI from the distribution, it should work fine.;;;","25/Aug/15 19:05;joaobreis;Hi guys, 

Maybe is not related with this issue, but what is not working is the feature of passing args to the shell like this:

#> ./zookeeper-shell.sh localhost:2181 ls /kafka

On the previous kafka version 0.8.1.1 by passing comands like 'ls' or 'get' worked. On 0.8.2.1 seems it does not work.

;;;","25/Aug/15 23:30;joaobreis;It seems to be a Zookeeper problem as stated here: https://issues.apache.org/jira/browse/ZOOKEEPER-1897

Sorry about this comment.;;;","28/Aug/18 15:20;omkreddy;Fixed in new zookeeper (3.4.7 +)  versions;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
 testPartitionReassignmentCallback hangs occasionally,KAFKA-1964,12775999,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,junrao,junrao,19/Feb/15 05:50,12/Mar/15 12:04,22/Mar/23 15:10,11/Mar/15 02:21,0.9.0.0,,,,,,0.9.0.0,,,,,,,admin,,,,0,newbie++,,,,,,,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1910,,,,,,,,,,"19/Feb/15 05:52;junrao;stack.out;https://issues.apache.org/jira/secure/attachment/12699546/stack.out",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Feb 23 17:09:47 UTC 2015,,,,,,,,,,"0|i25s7z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Feb/15 05:52;junrao;Saw the test hang once in trunk. Attached is the full stacktrace.

""Test worker"" prio=5 tid=7ffeb4105000 nid=0x116acd000 runnable [116aca000]
   java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
        at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:136)
        at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:69)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
        - locked <7f548be50> (a sun.nio.ch.Util$2)
        - locked <7f548be38> (a java.util.Collections$UnmodifiableSet)
        - locked <7f5420990> (a sun.nio.ch.KQueueSelectorImpl)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)
        at org.apache.kafka.common.network.Selector.select(Selector.java:375)
        at org.apache.kafka.common.network.Selector.poll(Selector.java:220)
        at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:209)
        at org.apache.kafka.clients.consumer.KafkaConsumer.awaitMetadataUpdate(KafkaConsumer.java:956)
        at org.apache.kafka.clients.consumer.KafkaConsumer.listOffset(KafkaConsumer.java:1353)
        at org.apache.kafka.clients.consumer.KafkaConsumer.resetOffset(KafkaConsumer.java:1423)
        at org.apache.kafka.clients.consumer.KafkaConsumer.fetchMissingPositionsOrResetThem(KafkaConsumer.java:1305)
        at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:700)
        - locked <7f548d990> (a org.apache.kafka.clients.consumer.KafkaConsumer)
        at kafka.api.ConsumerTest.testPartitionReassignmentCallback(ConsumerTest.scala:239)
;;;","24/Feb/15 00:11;guozhang;I think this is related to KAFKA-1948, and my submitted patch does not fully solve the problem. We should really create the topic with replication so shutting down the hosting broker of the topic will not block the test. I will try to fix this as part of KAFKA-1910.;;;","24/Feb/15 01:09;guozhang;Another reason for this issue is that the IllegalGeneration error is not implemented, and hence when coordinator migrates, the new heartbeat sent to the new coordinator will not return this error, and hence not triggering a new rebalance.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missing synchronization and improperly handled InterruptException in WorkerSourceTask,KAFKA-2867,12914737,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,ewencp,ewencp,ewencp,20/Nov/15 13:17,21/Nov/15 02:05,22/Mar/23 15:10,21/Nov/15 02:05,,,,,,,0.9.0.0,,,,,,,KafkaConnect,,,,0,,,,,,"In WorkerSourceTask, finishSuccessfulFlush() is not synchronized. In one case (if the flush didn't even have to be started), this is ok because we are already in a synchronized block. However, the other case is outside the synchronized block.

The result of this was transient failures of the system test for clean bouncing copycat nodes. The bug doesn't cause exceptions because finishSuccessfulFlush() only does a swap of two maps and sets a flag to false. However, because of the swapping of the two maps that maintain outstanding messages, we could by chance also be starting to send a message. If the message accidentally gets added to the backlog queue, then the flushing flag is toggled, we can ""lose"" that message temporarily into the backlog queue. Then we'll get a callback that will log an error because it can't find a record of the acked message (which, if it ever appears, should be considered a critical issue since it shouldn't be possible), and then on the next commit, it'll be swapped *back into place*. On the subsequent commit, the flush will never be able to complete because the message will be in the outstanding list, but will already have been acked. This, in turn, makes it impossible to commit offsets, and results in duplicate messages even under clean bounces where we should be able to get exactly once delivery assuming no network delays or other issues.

As a result of seeing this error, it became apparent that handling of WorkerSourceTaskThreads that do not complete quickly enough was not working properly. The ShutdownableThread should get interrupted if it does not complete quickly enough, but logs like this would happen:

{quote}
[2015-11-18 01:02:13,897] INFO Stopping task verifiable-source-0 (org.apache.kafka.connect.runtime.Worker)
[2015-11-18 01:02:13,897] INFO Starting graceful shutdown of thread WorkerSourceTask-verifiable-source-0 (org.apache.kafka.connect.util.ShutdownableThread)
[2015-11-18 01:02:13,897] DEBUG WorkerSourceTask{id=verifiable-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask)
[2015-11-18 01:02:17,901] DEBUG Submitting 1 entries to backing store (org.apache.kafka.connect.storage.OffsetStorageWriter)
[2015-11-18 01:02:18,897] INFO Forcing shutdown of thread WorkerSourceTask-verifiable-source-0 (org.apache.kafka.connect.util.ShutdownableThread)
[2015-11-18 01:02:18,897] ERROR Graceful stop of task WorkerSourceTask{id=verifiable-source-0} failed. (org.apache.kafka.connect.runtime.Worker)
[2015-11-18 01:02:18,897] ERROR Failed to flush WorkerSourceTask{id=verifiable-source-0}, timed out while waiting for producer to flush outstanding messages (org.apache.kafka.connect.runtime.WorkerSourceTask)
[2015-11-18 01:02:18,898] DEBUG Submitting 1 entries to backing store (org.apache.kafka.connect.storage.OffsetStorageWriter)
[2015-11-18 01:02:18,898] INFO Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
{quote}

Actions in the background thread performing the commit continue to occur after it is supposedly interrupted. This is because InterruptedExceptions during the flush were being ignored (some time ago they were not even possible). Instead, any interruption by the main thread trying to shut down the thread in preparation for a rebalance should be handled by failing the commit operation and returning so the thread can exit cleanly.",,ewencp,githubbot,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 20 18:05:04 UTC 2015,,,,,,,,,,"0|i2ooov:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"20/Nov/15 13:20;githubbot;GitHub user ewencp opened a pull request:

    https://github.com/apache/kafka/pull/566

    KAFKA-2867: Fix missing WorkerSourceTask synchronization and handling of InterruptException.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ewencp/kafka kafka-2867-fix-source-sync-and-interrupt

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/566.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #566
    
----
commit 3a610d4f24f9e102458f335d98c420a563c08aad
Author: Ewen Cheslack-Postava <me@ewencp.org>
Date:   2015-11-19T21:37:17Z

    KAFKA-2867: Fix missing WorkerSourceTask synchronization and handling of InterruptException.

----
;;;","21/Nov/15 02:05;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/566
;;;","21/Nov/15 02:05;junrao;Issue resolved by pull request 566
[https://github.com/apache/kafka/pull/566];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ControlledShutdownResponse always serialises `partitionsRemaining` as empty,KAFKA-2972,12920486,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,ijuma,ijuma,10/Dec/15 01:02,10/Dec/15 04:03,22/Mar/23 15:10,10/Dec/15 03:57,0.9.0.0,,,,,,0.9.0.1,,,,,,,network,,,,0,,,,,,"This only affects the Java response class which is not used for serialisation in 0.9.0, but will be in 0.9.1.",,githubbot,guozhang,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Dec 09 19:57:45 UTC 2015,,,,,,,,,,"0|i2po53:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"10/Dec/15 01:05;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/649

    KAFKA-2972; Add missing `partitionsRemaingList.add` in `ControlledShutdownResponse` constructor

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka KAFKA-2972-controlled-shutdown-response-bug

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/649.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #649
    
----
commit 82eb116122637e05221a8afbceae12d97cc1463d
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2015-12-09T16:57:56Z

    Add missing `partitionsRemaingList.add` in `ControlledShutdownResponse` constructor

----
;;;","10/Dec/15 03:54;ijuma;Changed fix version as the Java instance of the response is not used to serialise the data in 0.9.0 and the problem is at serialisation time.;;;","10/Dec/15 03:57;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/649
;;;","10/Dec/15 03:57;guozhang;Issue resolved by pull request 649
[https://github.com/apache/kafka/pull/649];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Broker stuck due to leader election race ,KAFKA-1451,12714147,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,omkreddy,mmakowski,mmakowski,14/May/14 18:52,20/Nov/15 01:43,22/Mar/23 15:10,30/Jul/14 23:15,0.8.1.1,,,,,,0.8.2.0,,,,,,,core,,,,2,newbie,,,,,"h3. Symptoms

The broker does not become available due to being stuck in an infinite loop while electing leader. This can be recognised by the following line being repeatedly written to server.log:

{code}
[2014-05-14 04:35:09,187] INFO I wrote this conflicted ephemeral node [{""version"":1,""brokerid"":1,""timestamp"":""1400060079108""}] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
{code}

h3. Steps to Reproduce

In a single kafka 0.8.1.1 node, single zookeeper 3.4.6 (but will likely behave the same with the ZK version included in Kafka distribution) node setup:

# start both zookeeper and kafka (in any order)
# stop zookeeper
# stop kafka
# start kafka
# start zookeeper

h3. Likely Cause

{{ZookeeperLeaderElector}} subscribes to data changes on startup, and then triggers an election. if the deletion of ephemeral {{/controller}} node associated with previous zookeeper session of the broker happens after subscription to changes in new session, election will be invoked twice, once from {{startup}} and once from {{handleDataDeleted}}:

* {{startup}}: acquire {{controllerLock}}
* {{startup}}: subscribe to data changes
* zookeeper: delete {{/controller}} since the session that created it timed out
* {{handleDataDeleted}}: {{/controller}} was deleted
* {{handleDataDeleted}}: wait on {{controllerLock}}
* {{startup}}: elect -- writes {{/controller}}
* {{startup}}: release {{controllerLock}}
* {{handleDataDeleted}}: acquire {{controllerLock}}
* {{handleDataDeleted}}: elect -- attempts to write {{/controller}} and then gets into infinite loop as a result of conflict

{{createEphemeralPathExpectConflictHandleZKBug}} assumes that the existing znode was written from different session, which is not true in this case; it was written from the same session. That adds to the confusion.

h3. Suggested Fix

In {{ZookeeperLeaderElector.startup}} first run {{elect}} and then subscribe to data changes.",,aseychell,becket_qin,chrisbeach,dude9527,fpj,joestein,junrao,kenmacd,laxpio,longtimer,marcusai,mazhar.shaikh.in,mmakowski,nehanarkhede,noxis,omkreddy,rusty@2211,sinewy,xavji,zcox,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1585,KAFKA-1387,,,,,,,"26/Jul/14 17:48;omkreddy;KAFKA-1451.patch;https://issues.apache.org/jira/secure/attachment/12657983/KAFKA-1451.patch","28/Jul/14 23:00;omkreddy;KAFKA-1451_2014-07-28_20:27:32.patch;https://issues.apache.org/jira/secure/attachment/12658141/KAFKA-1451_2014-07-28_20%3A27%3A32.patch","29/Jul/14 12:46;omkreddy;KAFKA-1451_2014-07-29_10:13:23.patch;https://issues.apache.org/jira/secure/attachment/12658354/KAFKA-1451_2014-07-29_10%3A13%3A23.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,392460,,,Thu Nov 19 17:43:57 UTC 2015,,,,,,,,,,"0|i1vl5b:",392645,,,,,,,,,,,,,,,,,,,,"17/Jul/14 22:47;kenmacd;This can also be caused by restarting Kafka quickly after a sigkill. I had a supervisord config file with 'stopwaitsecs=1' and it would pretty reliably create a hung Kafka process.;;;","18/Jul/14 00:04;junrao;Thanks for reporting this. Very interesting. That does sound like a potential problem. The problem is that ZookeeperLeaderElector.elect assumes that no controller exists. However, this may not be true. One possible solution is to first check the existence of the controller from ZK before creating the ephemeral node. ;;;","18/Jul/14 23:46;nehanarkhede;Just checking the existence is not enough since there is a risk of not electing a controller at all if all brokers do the same and the node disappears. Following will work
1. Register watch
2. Check existence and elect if one does not exist

#1 ensures that if the node disappears, an election will take place;;;","21/Jul/14 12:40;junrao;Neha, I am not sure if #1 is need. We can get into elect from two paths (1) from startup or (2) from handleDeleted. If it's from startup, we already register the watcher before calling elect. If it's from handleDeleted, it means that the watcher must have already been registered. So, once in elect, we know the watcher is already registered. So if after we check the existence of the controller node and the controller node goes away immediately afterward, the watcher is guaranteed to be triggered.;;;","26/Jul/14 17:48;omkreddy;Created reviewboard https://reviews.apache.org/r/23962/diff/
 against branch origin/trunk;;;","26/Jul/14 18:02;omkreddy;Uploaded a patch which checks controller existence in leader election process.
With this patch i am not able to reproduce the issue.
;;;","28/Jul/14 22:51;omkreddy;Updated reviewboard https://reviews.apache.org/r/23962/diff/
 against branch origin/trunk;;;","28/Jul/14 22:57;omkreddy;Created reviewboard https://reviews.apache.org/r/23983/diff/
 against branch origin/trunk;;;","28/Jul/14 23:00;omkreddy;Updated reviewboard https://reviews.apache.org/r/23962/diff/
 against branch origin/trunk;;;","29/Jul/14 12:46;omkreddy;Updated reviewboard https://reviews.apache.org/r/23962/diff/
 against branch origin/trunk;;;","30/Jul/14 23:15;junrao;Thanks for the latest patch. +1 and committed to trunk.;;;","10/Aug/14 16:09;joestein;Hi, two issues so far where found with leader election https://issues.apache.org/jira/browse/KAFKA-1387?focusedCommentId=14087063&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14087063 I don't know if the issues are related to each other or even to this just yet... the issues found were not happening on the 0.8.1 branch.... could be another 0.8.2 patch I supose but before I started trying to test on a 0.8.2 version without this patch (to isolate the root cause) I wanted to see if this type of scenario was tested or what thoughts were in general to this patch and how it might be affecting either of the two issues found in 0.8.2 trunk?  ;;;","11/Aug/14 06:46;junrao;Joe,

KAFKA-1387 seems to be related to broker registration and this jira only fixes how the controller is registered in ZK. So, I am not sure if they are related.;;;","05/Feb/15 14:49;sinewy;I think the patch dose not RESOLVE the problem,it will be happen again when zk event notification request arrive long after the /controller   has  deleted.
kafkaController.onControllerResignation method has executed,but elect action is return when it find that ""/controller"" znode has already been created;;;","04/Mar/15 18:47;aseychell;I just encountered this issue on version 0.8.2.0 after a period of slow PC performance and perhaps zookeeper and kafka were slow to communicate between each other (possibly the same issue highlighted by [~sinewy].  This resulted in an infinite loop in attempting to created the ephemeral node.  The logs that were continously being written are as follows:

[2015-03-03 13:48:19,831] INFO conflict in /brokers/ids/0 data: {""jmx_port"":-1,""timestamp"":""1425386833617"",""host"":""MTDKP119.ix.com"",""version"":1,""port"":9092} stored data: {""jmx_port"":-1,""timestamp"":""1425380575230"",""host"":""MTDKP119.ix.com"",""version"":1,""port"":9092} (kafka.utils.ZkUtils$)

[2015-03-03 13:48:19,832] INFO I wrote this conflicted ephemeral node [{""jmx_port"":-1,""timestamp"":""1425386833617"",""host"":""MTDKP119.ix.com"",""version"":1,""port"":9092}] at /brokers/ids/0 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)

[2015-03-03 13:48:25,844] INFO conflict in /brokers/ids/0 data: {""jmx_port"":-1,""timestamp"":""1425386833617"",""host"":""MTDKP119.ix.com"",""version"":1,""port"":9092} stored data: {""jmx_port"":-1,""timestamp"":""1425380575230"",""host"":""MTDKP119.ix.com"",""version"":1,""port"":9092} (kafka.utils.ZkUtils$);;;","28/Apr/15 14:48;marcusai;I have also hit this issue on version 0.8.2.0. It occurred directly after Zookeeper got restarted:

[2015-04-27 03:47:03,291] INFO conflict in /brokers/ids/2 data: {""jmx_port"":-1,""timestamp"":""1430038275477"",""host"":""ams5mdppdmsbacmq01b.markit.partners"",""version"":1,""port"":9092} stored data: {""jmx_port"":-1,""timestamp"":""1430036480690"",""host"":""ams5mdppdmsbacmq01b.markit.partners"",""version"":1,""port"":9092} (kafka.utils.ZkUtils$)
[2015-04-27 03:47:03,292] INFO I wrote this conflicted ephemeral node [{""jmx_port"":-1,""timestamp"":""1430038275477"",""host"":""ams5mdppdmsbacmq01b.markit.partners"",""version"":1,""port"":9092}] at /brokers/ids/2 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$);;;","19/Jun/15 23:26;rusty@2211;Hit this issue on version 0.8.2.1 when twiiterstream generate the large data i have one topic with two broker and two partition


[2015-06-19 20:35:10,141] INFO I wrote this conflicted ephemeral node [{""jmx_port"":10000,""timestamp"":""1434726183806"",""host"":""localhost.localdomain"",""version"":1,""port"":9093}] at /brokers/ids/2 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2015-06-19 20:35:16,246] INFO conflict in /brokers/ids/2 data: {""jmx_port"":10000,""timestamp"":""1434726183806"",""host"":""localhost.localdomain"",""version"":1,""port"":9093} stored data: {""jmx_port"":10000,""timestamp"":""1434726044184"",""host"":""localhost.localdomain"",""version"":1,""port"":9093} (kafka.utils.ZkUtils$)
[2015-06-19 20:35:16,796] INFO I wrote this conflicted ephemeral node [{""jmx_port"":10000,""timestamp"":""1434726183806"",""host"":""localhost.localdomain"",""version"":1,""port"":9093}] at /brokers/ids/2 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2015-06-19 20:35:22,965] INFO conflict in /brokers/ids/2 data: {""jmx_port"":10000,""timestamp"":""1434726183806"",""host"":""localhost.localdomain"",""version"":1,""port"":9093} stored data: {""jmx_port"":10000,""timestamp"":""1434726044184"",""host"":""localhost.localdomain"",""version"":1,""port"":9093} (kafka.utils.ZkUtils$)
[2015-06-19 20:35:22,967] INFO I wrote this conflicted ephemeral node [{""jmx_port"":10000,""timestamp"":""1434726183806"",""host"":""localhost.localdomain"",""version"":1,""port"":9093}] at /brokers/ids/2 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2015-06-19 20:35:29,159] INFO conflict in /brokers/ids/2 data: {""jmx_port"":10000,""timestamp"":""1434726183806"",""host"":""localhost.localdomain"",""version"":1,""port"":9093} stored data: {""jmx_port"":10000,""timestamp"":""1434726044184"",""host"":""localhost.localdomain"",""version"":1,""port"":9093} (kafka.utils.ZkUtils$)
[2015-06-19 20:35:29,161] INFO I wrote this conflicted ephemeral node [{""jmx_port"":10000,""timestamp"":""1434726183806"",""host"":""localhost.localdomain"",""version"":1,""port"":9093}] at /brokers/ids/2 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2015-06-19 20:35:35,219] INFO conflict in /brokers/ids/2 data: {""jmx_port"":10000,""timestamp"":""1434726183806"",""host"":""localhost.localdomain"",""version"":1,""port"":9093} stored data: {""jmx_port"":10000,""timestamp"":""1434726044184"",""host"":""localhost.localdomain"",""version"":1,""port"":9093} (kafka.utils.ZkUtils$)
[2015-06-19 20:35:35,221] INFO I wrote this conflicted ephemeral node [{""jmx_port"":10000,""timestamp"":""1434726183806"",""host"":""localhost.localdomain"",""version"":1,""port"":9093}] at /brokers/ids/2 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
[2015-06-19 20:35:41,338] INFO conflict in /brokers/ids/2 data: {""jmx_port"":10000,""timestamp"":""1434726183806"",""host"":""localhost.localdomain"",""version"":1,""port"":9093} stored data: {""jmx_port"":10000,""timestamp"":""1434726044184"",""host"":""localhost.localdomain"",""version"":1,""port"":9093} (kafka.utils.ZkUtils$)
[2015-06-19 20:35:42,208] INFO I wrote this conflicted ephemeral node [{""jmx_port"":10000,""timestamp"":""1434726183806"",""host"":""localhost.localdomain"",""version"":1,""port"":9093}] at /brokers/ids/2 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)
;;;","26/Aug/15 21:27;longtimer;I too am seeing this issue in 0.8.2.1.;;;","17/Sep/15 16:15;dude9527;Also occurred in 3 node kafka 0.8.2.1 cluster;;;","06/Oct/15 16:50;laxpio;also hit in 0.8.2.1,and the /controller node in zk is lost.;;;","07/Oct/15 01:15;becket_qin;[~laxpio] May be related to KAFKA-2437.;;;","07/Oct/15 01:18;fpj;Maybe related to KAFKA-1387?;;;","20/Nov/15 01:01;zcox;We experienced this yesterday on a 3-node 0.8.2.1 cluster, which caused a major outage for several hours. Restarting Kafka brokers several times, along with restarting Zookeeper nodes, did not resolve the issue. We identified one of the brokers that seemed to be going in/out of ISRs repeatedly, and ended up deleting all of its state on disk & restarting it. This was the only thing that finally resolved the issue. Maybe there was some corrupt state on that broker's disk? We still have that broker's state (moved its data dir, didn't actually delete) if that is helpful at all.;;;","20/Nov/15 01:33;fpj;[~zcox] if you observed messages like the ones in this comment above

https://issues.apache.org/jira/browse/KAFKA-1451?focusedCommentId=14593515&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14593515

then I suspect this will be resolved with the fix of KAFKA-1387, which will be available in 0.9.;;;","20/Nov/15 01:43;zcox;[~fpj] Yes we saw the ""I wrote this conflicted ephemeral node"" error messages, we saw lots of partitions in/out of ISRs and a lot of this too:

{code}
[2015-11-19 01:05:51,685] INFO Opening socket connection to server ip-10-10-1-35.ec2.internal/10.10.1.35:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2015-11-19 01:05:51,685] INFO Socket connection established to ip-10-10-1-35.ec2.internal/10.10.1.35:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2015-11-19 01:05:51,687] INFO Unable to reconnect to ZooKeeper service, session 0x54a0e5799a8195d has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2015-11-19 01:05:51,687] INFO zookeeper state changed (Expired) (org.I0Itec.zkclient.ZkClient)
[2015-11-19 01:05:51,687] INFO Initiating client connection, connectString=zookeeper1.production.redacted.com:2181,zookeeper2.production.redacted.com:2181,zookeeper3.production.redacted.com:2181/kafka sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@ace1333 (org.apache.zookeeper.ZooKeeper)
[2015-11-19 01:05:51,701] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[2015-11-19 01:05:51,701] ERROR Error handling event ZkEvent[New session event sent to kafka.controller.KafkaController$SessionExpirationListener@2261adb8] (org.I0Itec.zkclient.ZkEventThread)
java.lang.IllegalStateException: Kafka scheduler has not been started
  at kafka.utils.KafkaScheduler.ensureStarted(KafkaScheduler.scala:114)
  at kafka.utils.KafkaScheduler.shutdown(KafkaScheduler.scala:86)
  at kafka.controller.KafkaController.onControllerResignation(KafkaController.scala:350)
  at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1108)
  at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1107)
  at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1107)
  at kafka.utils.Utils$.inLock(Utils.scala:535)
  at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1107)
  at org.I0Itec.zkclient.ZkClient$4.run(ZkClient.java:472)
  at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2015-11-19 01:05:51,701] INFO re-registering broker info in ZK for broker 3 (kafka.server.KafkaHealthcheck)
[2015-11-19 01:05:51,701] INFO Opening socket connection to server ip-10-10-1-104.ec2.internal/10.10.1.104:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2015-11-19 01:05:51,702] INFO Socket connection established to ip-10-10-1-104.ec2.internal/10.10.1.104:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2015-11-19 01:05:51,713] INFO Session establishment complete on server ip-10-10-1-104.ec2.internal/10.10.1.104:2181, sessionid = 0x64a0e57972a1a85, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2015-11-19 01:05:51,713] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2015-11-19 01:05:51,718] INFO Registered broker 3 at path /brokers/ids/3 with address mesos-slave3.production.redacted.com:9092. (kafka.utils.ZkUtils$)
[2015-11-19 01:05:51,718] INFO done re-registering broker (kafka.server.KafkaHealthcheck)
[2015-11-19 01:05:51,718] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck)
[2015-11-19 01:05:51,721] INFO New leader is 1 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NullPointerException in new Consumer API on broker restart,KAFKA-3041,12924157,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Duplicate,hachikuji,eolivelli,eolivelli,24/Dec/15 15:47,04/Jan/16 23:08,22/Mar/23 15:10,04/Jan/16 23:08,0.9.0.0,,,,,,,,,,,,,consumer,,,,0,,,,,,"I 'm unning a brand new Kafka cluster (version 0.9.0.0). During my tests I noticed this error at Consumer.partitionsFor during a full cluster restart.
My DEV cluster is made of 4 brokers

I cannot reproduce the problem consistently but it heppens sometimes during the restart of the brokers

This is my code:

       this.properties = new Properties();
        properties.put(""bootstrap.servers"", ""list of servers""));
        properties.put(""acks"", ""all"");
        properties.put(""retries"", 0);
        properties.put(""batch.size"", 16384);
        properties.put(""linger.ms"", 1);
        properties.put(""buffer.memory"", 33554432);
        properties.put(""group.id"", ""test"");
        properties.put(""session.timeout.ms"", ""30000"");
        properties.put(""key.deserializer"", ""org.apache.kafka.common.serialization.ByteArrayDeserializer"");
        properties.put(""value.deserializer"", ""org.apache.kafka.common.serialization.ByteArrayDeserializer"");

       String topic = ""xxx”;
        try (KafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(properties);) {
            List<PartitionInfo> partitions = consumer.partitionsFor(topic);
             ….
        }

This is the error:
java.lang.NullPointerException
                at org.apache.kafka.common.requests.MetadataResponse.<init>(MetadataResponse.java:130)
                at org.apache.kafka.clients.consumer.internals.Fetcher.getTopicMetadata(Fetcher.java:203)
                at org.apache.kafka.clients.consumer.KafkaConsumer.partitionsFor(KafkaConsumer.java:1143)
                at magnews.datastream.KafkaDataStreamConsumer.fetchNewData(KafkaDataStreamConsumer.java:44
",,eolivelli,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2880,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,2015-12-24 07:47:49.0,,,,,,,,,,"0|i2qa6f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Client Selector can drop connections on InvalidReceiveException without notifying NetworkClient,KAFKA-2298,12839900,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,lindong,lindong,lindong,24/Jun/15 01:35,10/Jul/15 01:47,22/Mar/23 15:10,10/Jul/15 01:47,,,,,,,,,,,,,,,,,,0,quotas,,,,,"I run into the problem described in KAFKA-2266 when testing quota. I was told the bug was fixed in KAFKA-2266 after I figured out the problem.

But the patch provided in KAFKA-2266 probably doesn't solve all related problems. From reading the code there is still one edge case where the client selector can close connection in poll() without notifying NetworkClient.",,lindong,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jun/15 01:41;lindong;KAFKA-2298.patch;https://issues.apache.org/jira/secure/attachment/12741332/KAFKA-2298.patch","24/Jun/15 09:48;lindong;KAFKA-2298_2015-06-23_18:47:54.patch;https://issues.apache.org/jira/secure/attachment/12741428/KAFKA-2298_2015-06-23_18%3A47%3A54.patch","25/Jun/15 04:00;lindong;KAFKA-2298_2015-06-24_13:00:39.patch;https://issues.apache.org/jira/secure/attachment/12741686/KAFKA-2298_2015-06-24_13%3A00%3A39.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jul 08 17:58:06 UTC 2015,,,,,,,,,,"0|i2ge93:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"24/Jun/15 01:41;lindong;Created reviewboard https://reviews.apache.org/r/35791/diff/
 against branch origin/trunk;;;","24/Jun/15 09:48;lindong;Updated reviewboard https://reviews.apache.org/r/35791/diff/
 against branch origin/trunk;;;","25/Jun/15 04:00;lindong;Updated reviewboard https://reviews.apache.org/r/35791/diff/
 against branch origin/trunk;;;","07/Jul/15 04:46;lindong;Joel, could you please review this patch when you have time?;;;","08/Jul/15 23:53;sriharsha;[~lindong] [~jjkoshy] I've lot of changes in Selector for KAFKA-1690 and others. If you don't mind can I send this as part of the KAFKA-1690 changes saves me merge issues :).;;;","09/Jul/15 01:56;lindong;[~sriharsha] Sorry for the inconvenience. But the patch is already committed yesterday. What should we do to put this in your patch to save the merge issue?;;;","09/Jul/15 01:58;sriharsha;[~lindong] ahh never mind than :). I'll do the merge . Thanks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Slow controlled shutdowns can result in stale shutdown requests,KAFKA-1342,12703878,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,jjkoshy,jjkoshy,jjkoshy,27/Mar/14 09:35,31/Dec/19 06:19,22/Mar/23 15:10,31/Dec/19 06:19,0.8.1,,,,,,,,,,,,,,,,,3,newbie++,reliability,,,,"I don't think this is a bug introduced in 0.8.1., but triggered by the fact
that controlled shutdown seems to have become slower in 0.8.1 (will file a
separate ticket to investigate that). When doing a rolling bounce, it is
possible for a bounced broker to stop all its replica fetchers since the
previous PID's shutdown requests are still being shutdown.

- 515 is the controller
- Controlled shutdown initiated for 503
- Controller starts controlled shutdown for 503
- The controlled shutdown takes a long time in moving leaders and moving
  follower replicas on 503 to the offline state.
- So 503's read from the shutdown channel times out and a new channel is
  created. It issues another shutdown request.  This request (since it is a
  new channel) is accepted at the controller's socket server but then waits
  on the broker shutdown lock held by the previous controlled shutdown which
  is still in progress.
- The above step repeats for the remaining retries (six more requests).
- 503 hits SocketTimeout exception on reading the response of the last
  shutdown request and proceeds to do an unclean shutdown.
- The controller's onBrokerFailure call-back fires and moves 503's replicas
  to offline (not too important in this sequence).
- 503 is brought back up.
- The controller's onBrokerStartup call-back fires and moves its replicas
  (and partitions) to online state. 503 starts its replica fetchers.
- Unfortunately, the (phantom) shutdown requests are still being handled and
  the controller sends StopReplica requests to 503.
- The first shutdown request finally finishes (after 76 minutes in my case!).
- The remaining shutdown requests also execute and do the same thing (sends
  StopReplica requests for all partitions to
  503).
- The remaining requests complete quickly because they end up not having to
  touch zookeeper paths - no leaders left on the broker and no need to
  shrink ISR in zookeeper since it has already been done by the first
  shutdown request.
- So in the end-state 503 is up, but effectively idle due to the previous
  PID's shutdown requests.

There are some obvious fixes that can be made to controlled shutdown to help
address the above issue. E.g., we don't really need to move follower
partitions to Offline. We did that as an ""optimization"" so the broker falls
out of ISR sooner - which is helpful when producers set required.acks to -1.
However it adds a lot of latency to controlled shutdown. Also, (more
importantly) we should have a mechanism to abort any stale shutdown process.
",,adenysenko,antigremlin,boniek,cotedm,donnchadh,eidi,futtre,guozhang,hachikuji,ijuma,jazemek,jeffwidman,jjkoshy,junrao,khsibr,mrlabbe,toddpalino,umesh9794@gmail.com,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-4207,,,,KAFKA-7235,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,382212,,,Sat Jul 07 06:11:02 UTC 2018,,,,,,,,,,"0|i1tulb:",382483,,,,,,,,,,,,,,,,,,,,"29/Mar/14 07:55;jjkoshy;KAFKA-1350 is what triggered this issue. Although we will fix that, we
should note that controlled shutdowns can take time to complete if there are
several partitions.  It is unsafe to increase the number of shutdown retries
on the broker because each retry will hold up a request-handler thread on
the controller.  i.e., it is better to set a very high shutdown timeout. (It
is right now hard-coded to 30 seconds, but it really should be
configurable.) It may also help to add a controlled shutdown request
purgatory in the controller.

;;;","10/Apr/14 06:04;jjkoshy;Moving this out to 0.8.2 since the slow shutdown regression has been resolved. The socket timeout is in fact configurable (via controller.socket.timeout.ms);;;","30/Apr/14 22:59;junrao;If it's just a matter of configuring the timeout, could we just bump up the default timeout?;;;","01/May/14 03:05;jjkoshy;We could, but I think the underlying issue is serious. i.e., if we allow concurrent (and redundant) shutdown request we tie up request handlers. We should allow max one shutdown request per broker (or even across the cluster).;;;","05/Sep/14 05:50;guozhang;Moving out of 0.8.2 for now.;;;","08/Apr/15 06:56;toddpalino;Bump

I think we need to revive this. We have a ""safe shutdown"" bit of wrapper code we use which relies on an external resource that we should eliminate. It would be better to provide a safe shutdown option within Kafka itself without that wrapper (i.e. do not shut down unless your under replicated count is 0). However, this is not possible without serialized shutdown at the controller level. We can't allow a second broker to shut down until the first broker has completed its shutdown process. Then the second broker can check the URP count and be allowed to proceed.;;;","27/Sep/16 06:24;junrao;A similar incident was reported in https://issues.apache.org/jira/browse/KAFKA-4207.;;;","27/Sep/16 12:21;hachikuji;Downgrading this to ""Critical"" since it has not actually blocked the previous few releases and after discussion with [~junrao], it seems unlikely to be fixed for 0.10.1.;;;","25/Feb/17 15:10;wushujames;[~jjkoshy], [~toddpalino], is it still true that it is unsafe to increase the number of controlled shutdown requests? We currently have brokers with 10,000 partitions each, and there is no way they can effectively shutdown within the shutdown timeout of 30 seconds, even with the current default of controlled.shutdown.max.retries=3. If the brokers aren't able to shutdown within the 90 seconds (30 seconds * 3), then when we bounce them and they start back up too quickly, we end up with a broker with all of its replica fetchers stopped (as described in this JIRA). This also seems like a specific instance of KAFKA-1120

We have increased that to 40 or so, to allow brokers up to 20 minutes to shutdown. Usually, it takes them 8 minutes.

Is it better to increase the value of controller.socket.timeout.ms? If we increase this to 25 minutes for example, doesn't that impact much more than just the shutdown request? Won't normal controller->broker communication like LeaderAndIsr and MetadataUpdate requests also be subject to an 25 minute timeout?
;;;","03/Mar/17 12:30;toddpalino;[~wushujames], I'm not sure about increasing the number of requests, but a lot of this should have been resolved recently with some updates that I believe [~becket_qin] made. To make it better, we had bumped controller.socket.timeout.ms significantly (to 300000). We didn't see any side effects from doing that.;;;","07/Jul/18 12:22;jazemek;[~wushujames] do you have TRACE logging enabled on the controller? (Apparently that's the default??) We noticed that turning this off allowed shutdown to happen much more quickly. We were running into the same issue you described with ~6k partitions per broker, but after turning off TRACE logging, we are able to shutdown cleanly;;;","07/Jul/18 13:16;ijuma;[~jazemek] in what Kafka version did you see that?;;;","07/Jul/18 13:21;jazemek;[~ijuma] We're running 0.10.2;;;","07/Jul/18 13:24;ijuma;If you upgrade to 0.11.0.3 or newer, you shouldn't have to disable the trace logging in the Controller. 1.1.1, in particular, has a number of optimizations.;;;","07/Jul/18 13:27;jazemek;[~ijuma] Would you be able to provide some details around the changes in those versions which would remove the need to disable trace logging? Thanks!;;;","07/Jul/18 14:08;wushujames;In an older release, there was a logging “bug” in the controller where upon any leadership change in a single partition, it would log the state of *all partitions in the cluster*. That was probably the cause of the slowness you were seeing.

It got fixed at one point. I don’t remember which release it was fixed in, but I’m pretty sure that the “bug” existed in 0.10.2;;;","07/Jul/18 14:11;wushujames;Found it: 

https://github.com/apache/kafka/pull/4075

And

https://issues.apache.org/jira/browse/KAFKA-6116



;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KafkaProducer does not honor the retry backoff time.,KAFKA-2138,12822807,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,becket_qin,becket_qin,becket_qin,22/Apr/15 05:27,12/May/16 18:36,22/Mar/23 15:10,25/Apr/15 03:44,,,,,,,,,,,,,,,,,,0,,,,,,"In KafkaProducer, we only check the batch.lastAttemptMs in ready. But we are not checking it in drain() as well.
The problem is that if we have two partitions both on the same node, suppose Partition 1 should backoff while partition 2 should not. Currently partition 1's backoff time will be ignored.
We should check the lastAttemptMs in drain() as well.",,becket_qin,jjkoshy,jonbringhurst,kzakee,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2868,,,,,,,,,,,,,,,,"22/Apr/15 06:51;becket_qin;KAFKA-2138.patch;https://issues.apache.org/jira/secure/attachment/12727017/KAFKA-2138.patch","23/Apr/15 08:19;becket_qin;KAFKA-2138_2015-04-22_17:19:33.patch;https://issues.apache.org/jira/secure/attachment/12727481/KAFKA-2138_2015-04-22_17%3A19%3A33.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Apr 24 19:44:07 UTC 2015,,,,,,,,,,"0|i2dkc7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"22/Apr/15 06:51;becket_qin;Created reviewboard https://reviews.apache.org/r/33417/diff/
 against branch origin/trunk;;;","22/Apr/15 07:27;becket_qin;[~junrao] [~jjkoshy] Do you think we should also check this into 0.8.2.2?;;;","23/Apr/15 08:19;becket_qin;Updated reviewboard https://reviews.apache.org/r/33417/diff/
 against branch origin/trunk;;;","25/Apr/15 03:44;jjkoshy;Discussed offline with [~becket_qin] - KAFKA-2142 has been filed to do further improvements including fixing a pre-existing bug where we may prematurely send (before batch-full or linger time thresholds).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TopicMetadataRequest creates topic if it does not exist,KAFKA-2887,12915892,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,,AWinterman,AWinterman,25/Nov/15 02:59,13/Sep/17 10:17,22/Mar/23 15:10,13/Sep/17 10:17,0.8.2.0,,,,,,,,,,,,,clients,,,,0,,,,,,"We wired up a probe http endpoint to make TopicMetadataRequests with a possible topic name. If no topic was found, we expected an empty response. However if we asked for the same topic twice, it would exist the second time!

I think this is a bug because the purpose of the TopicMetadaRequest is to provide  information about the cluster, not mutate it. I can provide example code if needed.","Centos6, Java 1.7.0_75",AWinterman,hachikuji,mgharat,nickpan47,omkreddy,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Sep 12 21:01:00 UTC 2017,,,,,,,,,,"0|i2ovtb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"25/Nov/15 05:27;hachikuji;This is actually intentional. You can disable this behavior by setting ""auto.create.topics.enable"" to false in the broker config. I think the plan in the future (KIP-4) is to have a separate API to create topics, which will probably make auto.create false by default, but that hasn't been completed yet. ;;;","25/Nov/15 05:48;AWinterman;In that case, shouldn't it be mentioned in the documentation for the request? We were looking at https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-TopicMetadataRequest when we wrote it.;;;","25/Nov/15 05:58;hachikuji;[~AWinterman] Agreed. I added a note on the wiki just now. Can you close the ticket?;;;","25/Nov/15 06:02;AWinterman;ah, I see that is is. Thanks!;;;","25/Nov/15 06:14;AWinterman;Reopening because the auto.create.topics.enable configuration parameter also controls whether or not a topic is created by attempts to produce to it. It seems like producing is a write operation, while consuming or asking for metadata is a read. I maintain that creating topics in response to read operations is surprising.;;;","25/Nov/15 08:25;nickpan47;Agree with [~AWinterman]. As a stop-gap before KIP-4 is fully completed, shouldn't we add a simple read-only flag to this TopicMetadataRequest?;;;","25/Nov/15 08:30;AWinterman;I'd be plus one on that. The alternative we're looking at involves reaching into kafka's zk instance, which feels like a violation of separation of concerns.;;;","25/Nov/15 08:41;sriharsha;[~yipan] [~AWinterman] This issue is solved here in this jira https://issues.apache.org/jira/browse/KAFKA-1507 .  It provides create topic request and makes it producer side request for creating topic.  If there is enough interest I can rebase against the master and send a new patch.;;;","25/Nov/15 08:44;nickpan47;HI, [~harsha_ch], thanks for the quick reply. I saw that KAFKA-1507 is not resolved yet. When can we expect a fix?;;;","25/Nov/15 08:47;sriharsha;[~nickpan47] already have a patch on that JIRA. I'll rebase send against this JIRA in a day or two.;;;","25/Nov/15 10:59;hachikuji;There is probably wide agreement that auto-creation of topics on metadata requests is not a good idea. However, the problem with adding a flag to the topic metadata request is that future versions would have to continue to support it. Seems that leaves unneeded baggage in the request API, especially if the plan is ultimately to deprecate this feature. Since 0.9 has already been cut, my own preference for the next release would be to finish the CreateTopic request in KIP-4, disable auto-creation by default, and leave the metadata request unchanged. Then hopefully in a future release, we could remove auto-creation entirely.;;;","26/Nov/15 02:48;AWinterman;my only complaint with this approach is that it leaves people on 0.8 in a lurch. If we make the configuration values for the broker more fine grained, meaning have one configuration value for ""creates topics on produce request"" and one for ""creates topics on consume/metadata request"" then that both preserves api continuity (or are configuration values a part of the API?) and solves the problem we're facing.;;;","01/Dec/15 02:52;AWinterman;Mind linking to KIP-4?;;;","18/Dec/15 08:01;mgharat;[~hachikuji] just wanted to be sure what you meant by leaving the current TopicMetadataRequest unchanged, is that it will not be creating the topic in future if the topic is not present and this would require code change on server. Am I right?
This is very important when we are dealing with deleting topics in a pipeline.;;;","18/Dec/15 08:17;hachikuji;[~mgharat] Yes, that is what I meant. I was basically saying that I don't think adding a flag to the TopicMetadataRequest to make creation explicit is a great idea since we'd be stuck supporting it in the future. I assumed the plan was to either deprecate auto-creation or at least turn it off by default once we have the CreateTopics API (the patch for this is available, by the way).;;;","07/Jan/16 07:16;mgharat;[~hachikuji] just wanted to know if we have ticket for which the above patch is available. ;;;","12/Sep/17 20:19;omkreddy;As of  0.11.0.0,  We added a ""allow_auto_topic_creation"" flag to the topic meta data request (MetadataRequest) in KAFKA-5291. Also AdminCleint supports createTopic APIs. If this covers the JIRA requirement, then we can close this issue.;;;","13/Sep/17 05:01;AWinterman;It does, thank you!


;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replicas spuriously deleting all segments in partition,KAFKA-2477,12858972,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,hakon,hakon,26/Aug/15 20:59,15/Oct/15 04:05,22/Mar/23 15:10,08/Oct/15 12:59,0.8.2.1,,,,,,0.9.0.0,,,,,,,,,,,1,,,,,,"We're seeing some strange behaviour in brokers: a replica will sometimes schedule all segments in a partition for deletion, and then immediately start replicating them back, triggering our check for under-replicating topics.

This happens on average a couple of times a week, for different brokers and topics.

We have per-topic retention.ms and retention.bytes configuration, the topics where we've seen this happen are hitting the size limit.",,aih1013,becket_qin,bobrik,cpsoman,ewencp,githubbot,hakon,junrao,kzadorozhny-tubemogul,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2621,,,,,,,,,,,,,,,,,,,"11/Oct/15 09:47;cpsoman;Screen Shot 2015-10-10 at 6.54.44 PM.png;https://issues.apache.org/jira/secure/attachment/12766003/Screen+Shot+2015-10-10+at+6.54.44+PM.png","26/Aug/15 21:04;hakon;kafka_log.txt;https://issues.apache.org/jira/secure/attachment/12752473/kafka_log.txt","08/Sep/15 22:47;hakon;kafka_log_trace.txt;https://issues.apache.org/jira/secure/attachment/12754651/kafka_log_trace.txt",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Oct 14 20:05:00 UTC 2015,,,,,,,,,,"0|i2jefb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"26/Aug/15 21:04;hakon;Attached example log from a broker;;;","27/Aug/15 02:22;becket_qin;Maybe related to KAFKA-2143.;;;","27/Aug/15 05:08;hakon;Thanks for the reply. Checking the logs, we did get the ""Error when processing fetch request"" error in the leader mentioned in KAFKA-2143, so it could be the same issue.

I don't see anything in our logs about a leader change, so I don't think it is caused by an unclean election, like some of the comments suggest.;;;","27/Aug/15 06:03;becket_qin;What is the partition replication factor?
Also, can you search for ""start offset"" in the server log of the broker who truncates its log?;;;","27/Aug/15 07:33;hakon;We use a replication factor of 3.
The only line with ""start offset"" that day is the one in the attached log:
[2015-08-24 18:32:32,299] WARN [ReplicaFetcherThread-3-0], Replica 3 for partition [log.event,3] reset its fetch offset from 10200597616 to current leader 0's start offset 10200597616 (kafka.server.ReplicaFetcherThread)

e: the leader error reads:
[2015-08-24 18:32:32,145] ERROR [Replica Manager on Broker 0]: Error when processing fetch request for partition [log.event,3] offset 10349592111 from follower with correlation id 141609587. Possible cause: Request for offset 10349592111 but we only have log segments in the range 10200597616 to 10349592109. (kafka.server.ReplicaManager);;;","29/Aug/15 03:10;junrao;[~hakon], the leader changes will be logged in the controller log. Do you see anything there? Also, we have a jmx metrics kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec
 that tells you if there is any unclean leader election.;;;","31/Aug/15 17:26;hakon;""kafka.controller:name=UncleanLeaderElectionsPerSec,type=ControllerStats"" has Count = 0 on all brokers.

There is nothing in any controller.log from that day except for one broker checking leader imbalance.
([2015-08-24 00:02:32,650] TRACE [Controller 0]: checking need to trigger partition rebalance (kafka.controller.KafkaController)
[2015-08-24 00:02:32,684] DEBUG [Controller 0]: preferred replicas by broker Map([...]) (kafka.controller.KafkaController)
[2015-08-24 00:02:32,684] DEBUG [Controller 0]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[2015-08-24 00:02:32,685] TRACE [Controller 0]: leader imbalance ratio for broker 2 is 0.000000 (kafka.controller.KafkaController)
, etc.);;;","01/Sep/15 09:40;junrao;Interesting, so there is nothing in broker 0's log about truncating the log for partition [log.event,3]? 

It seems that this is reproducible. Would it be possible for you to enable TRACE level logging for class kafka.log.Log on every broker. This will log the new log end offset after each message append. When this issue happens again, we can verify if it is indeed that the follower uses a fetch offset that's larger than the leader's log end offset.;;;","03/Sep/15 04:07;hakon;I don't think enabling trace logging would be practical in our production environment, unfortunately.

We see the error regularly in production, but I haven't been able to reproduce it locally.;;;","04/Sep/15 08:33;junrao;Could you then try the following? In the above situation, go to broker 0's log dir for partition [log.event,3]. Get the name of the last log segment (the .log file). Then run the following
bin/kafka-run-class.sh kafka.tools.DumpLogSegments [logsegmentname]

This will print out the offset of each message. In the normal case, those offsets should be monotonically increasing. Could you check if there is any out of sequence offsets in the output especially close to 10349592109?
;;;","04/Sep/15 20:24;hakon;I don't see any out of sequence offsets.
Here are a couple of recent examples.
If I run with --deep-iteration, all offsets are present and sequential.
The result on the replica is identical to the leader.
---
[2015-09-02 23:43:03,379] ERROR [Replica Manager on Broker 0]: Error when processing fetch request for partition [log.event,3] offset 10591627212 from follower with correlation id 391785394. Possible cause: Request for offset 10591627212 but we only have log segments in the range 10444248800 to 10591627211. (kafka.server.ReplicaManager)

offset: 10591627210 position: 994954613 isvalid: true payloadsize: 674 magic: 0 compresscodec: SnappyCompressionCodec crc: 4144791071
offset: 10591627211 position: 994955313 isvalid: true payloadsize: 1255 magic: 0 compresscodec: SnappyCompressionCodec crc: 1011806998
offset: 10591627213 position: 994956594 isvalid: true payloadsize: 1460 magic: 0 compresscodec: SnappyCompressionCodec crc: 4145284502
offset: 10591627215 position: 994958080 isvalid: true payloadsize: 1719 magic: 0 compresscodec: SnappyCompressionCodec crc: 444418110

----

[2015-09-03 11:44:02,483] ERROR [Replica Manager on Broker 3]: Error when processing fetch request for partition [log.count,5] offset 69746066284 from follower with correlation id 239821628. Possible cause: Request for offset 69746066284 but we only have log segments in the range 68788206610 to 69746066280. (kafka.server.ReplicaManager)

offset: 69746066278 position: 464897345 isvalid: true payloadsize: 674 magic: 0 compresscodec: SnappyCompressionCodec crc: 3013732329
offset: 69746066279 position: 464898045 isvalid: true payloadsize: 234 magic: 0 compresscodec: SnappyCompressionCodec crc: 3286064200
offset: 69746066283 position: 464898305 isvalid: true payloadsize: 486 magic: 0 compresscodec: SnappyCompressionCodec crc: 747917524
offset: 69746066285 position: 464898817 isvalid: true payloadsize: 342 magic: 0 compresscodec: SnappyCompressionCodec crc: 4283754786
offset: 69746066286 position: 464899185 isvalid: true payloadsize: 233 magic: 0 compresscodec: SnappyCompressionCodec crc: 2129213572;;;","05/Sep/15 02:34;junrao;Thanks. Then the log looks normal. The only thing that I can recommend now is to try reproducing the issue locally and apply the trace level logging.

Also, since you are using snappy, you may want to apply the fixes in 0.8.2.2 (https://people.apache.org/~junrao/kafka-0.8.2.2-candidate1/RELEASE_NOTES.html) once it's out. They may not be related to the issue that you are seeing here though.;;;","08/Sep/15 22:47;hakon;Attached trace log from leader. Filtered to only lines for the relevant partition.;;;","08/Sep/15 22:51;hakon;I was able to enable trace logging on a production server, and have captured logs from the leader when the error happens.

It looks like the attempted read happens right before the log is actually appended. I don't see any other abnormal behaviour.

Looking at the code in question, I think I have an idea of how it might happen:

kafka.log.Log uses a lock to synchronize writes, but not reads.

Assume a write W1 has gotten as far as FileMessageSet.append() and has just executed _size.getAndAdd(written)

Now a concurrent read R1 comes in. In FileMessageSet.read(), it can get a new message set with end = math.min(this.start + position + size, sizeInBytes()). This includes the message that was just written in W1.

The read finishes, and a new read R2 starts. R2 tries to continue from W1, but in Log.read() it finds that startOffset is larger than nextOffsetMetadata.messageOffset and throws an exception.
(By the way, Log.read() can potentially read nextOffsetMetadata multiple times, with no guarantee that it hasn't changed. It's not obvious to me that this is correct.)

Finally, W1 updates nextOffsetMetadata in Log.updateLogEndOffset(), too late for R2 which has already triggered a log truncation on the replica.

Some possible solutions:
- Synchronize access to nextOffsetMetadata in Log.read()
- Clamp reads in Log.read() to never go beyond the current message offset.;;;","08/Sep/15 23:41;becket_qin;[~hakon] Yes, that's correct.

The log appending does the following two things:
1. Append message to log
2. Update Log.nextOffsetMetadata.messageOffset.
If two follower reads come between 1 and 2. There will be a out of range exception. I think the fix is to read up to Log.nextOffsetMetadata.messageOffset for replicas instead of max size.

Are you interested in submitting a patch?;;;","09/Sep/15 00:49;hakon;I don't think I can provide a patch at the moment, I would appreciate if someone more familiar with the code fixed it.;;;","09/Sep/15 00:57;becket_qin;No worries. I can do that :);;;","12/Sep/15 02:11;githubbot;Github user becketqin closed the pull request at:

    https://github.com/apache/kafka/pull/204
;;;","12/Sep/15 02:11;githubbot;GitHub user becketqin reopened a pull request:

    https://github.com/apache/kafka/pull/204

    KAFKA-2477: Fix a race condition between log append and fetch that causes OffsetOutOfRangeException.

    Tried two fixes. I prefer the second approach because it saves an additional offset search.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/becketqin/kafka KAFKA-2477

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/204.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #204
    
----
commit e7610fb69a4007ae661a768635e930355c8caa76
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2015-09-11T02:17:12Z

    KAFKA-2477: Fix a race condition between log append and fetch that causes OffsetOutOfRangeException

commit 45364d76e756fc6075924b3a07651b7fbbcc391a
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2015-09-11T03:06:35Z

    A second fix that avoids an addition offset search

----
;;;","15/Sep/15 06:23;becket_qin;[~junrao] I just marked this ticket for 0.9. The patch is small. Will you be able to take a look? ;;;","03/Oct/15 08:35;junrao;[~hakon], thanks a lot for the update. This seems like a real issue. Also, the point that you made on  ""Log.read() can potentially read nextOffsetMetadata multiple times"" is also relevant. In Log.read(), we have the following code:

    // check if the offset is valid and in range
    val next = nextOffsetMetadata.messageOffset
    if(startOffset == next)
      return FetchDataInfo(nextOffsetMetadata, MessageSet.Empty)

This seems wrong. If nextOffsetMetadata changes after the if test, we could return a larger fetchOffsetMetadata in FetchDataInfo that we should. This will potentially affect the computation of things like isr. In this case, we should get a reference of nextOffsetMetadata first and use that to do the if test and as the return value.

Log.read() also references nextOffsetMetadata again in the last line. I am not sure if the comment is correct. The last message will never be deleted, so it seems that we can never reach the last statement.

    // okay we are beyond the end of the last segment with no data fetched although the start offset is in range,
    // this can happen when all messages with offset larger than start offsets have been deleted.
    // In this case, we will return the empty set with log end offset metadata
    FetchDataInfo(nextOffsetMetadata, MessageSet.Empty)

[~becket_qin], do you want to fix nextOffsetMetadata in your patch too?;;;","06/Oct/15 10:03;becket_qin;[~junrao] I'll fix the nexOffsetMetadata in the patch.

Would the following case be what the last line was trying to address?

1. Leader is on broker 1, HW=X, LEO=Y, Y > X
2. A fetch request from follower goes to broker 1 to fetch from offset Z. Assume X < Z < Y.
3. Broker 1 proceeds with fetch request and enters Log.read()
4. Leader migration occurs, log on broker 1 got truncated to X.

In this case, because the FetchRequest has passed the leader check before leader migration, no NotLeaderForPartitionException would be thrown. Also because the read does not grab any lock, the log truncation might occur before the actual message search occur.
;;;","08/Oct/15 12:59;junrao;Issue resolved by pull request 204
[https://github.com/apache/kafka/pull/204];;;","08/Oct/15 12:59;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/204
;;;","08/Oct/15 13:01;junrao;[~Håkon Hitland], the fix is committed in trunk. Do you think you can test this out in a test environment?;;;","11/Oct/15 08:00;cpsoman;We're hitting this issue quite often (every 15-20 mins) and is a problem since its eating up the already scarce disk / Network resource. At the moment we're running 0.8.2.0. Is there any plan to backport this patch given the severity of the issue ?;;;","11/Oct/15 08:49;ewencp;[~cpsoman] Interesting, the only other org I had heard this affecting was seeing it at approximately the same frequency as the original report -- maybe once or twice a week. It seemed random, so the events could sometimes clump together (e.g. see two in one day), but the average rate was pretty low. It was an annoyance rather than a serious issue.

The patch does seem to apply trivially to 0.8.2.2.;;;","11/Oct/15 09:47;cpsoman;[~ewencp] I'm attaching the screenshot of Max lag observed for the different brokers which describes the behaviour. 

Also here's the pertinent log:

========
[2015-10-10 22:17:17,759] 3171793337 [kafka-request-handler-0] WARN  kafka.server.ReplicaManager  - [Replica Manager on Broker 70]: Error when processing fetch request for partition [...topic...,62] offset 91963211 from follower with correlation id 176614372. Possible cause: Request for offset 91963211 but we only have log segments in the range 55923986 to 91963210.

[2015-10-10 22:17:17,759] 3171793337 [kafka-request-handler-4] WARN  kafka.server.ReplicaManager  - [Replica Manager on Broker 70]: Error when processing fetch request for partition [...topic...,62] offset 91963211 from follower with correlation id 152788081. Possible cause: Request for offset 91963211 but we only have log segments in the range 55923986 to 91963210.

[2015-10-10 22:17:20,256] 3171795834 [kafka-scheduler-4] INFO  kafka.cluster.Partition  - Partition [...topic...,62] on broker 70: Shrinking ISR for partition [hp.event.user.driver_app.experiment,62] from 70,69,71 to 70
========
;;;","11/Oct/15 09:50;cpsoman;Btw, this doesn't happen everywhere but is definitely seen in our biggest cluster (with way more partitions / node). Maybe it has something to do with scale ?;;;","12/Oct/15 12:15;becket_qin;[~cpsoman] I think the likelihood of the issue is related to the scale as you observed, because there would be potentially more threads trying to read/write from the same log segment.

It looks there are a few other patches on the files touched by this patch since 0.8.2.0. However, I checked the code of 0.8.2.0, it seems the code blocks related to this patch are still the same as the latest trunk. So you should be able to patch 0.8.2.0 easily although the patch itself may not apply.;;;","13/Oct/15 14:56;ewencp;[~cpsoman] Beyond applying to 0.8.2.0 with the patch, any reason not to update to 0.8.2.2 and apply the patch on top of that, where it definitely applies cleanly? It looks like 8 patches, and some of the patches on top of 0.8.2.0 are likely to be useful if you might have a large number of partitions or use snappy compression, among other key fixes. Maybe you're not hitting any of the critical fixes in those releases, but since they're low risk maybe catching up with the latest release and only having a minor patch would simplify things?;;;","15/Oct/15 04:05;cpsoman;[~ewencp] Totally agree. Its just that the current 0.8.2.0 version we're using : has been ""tampered"" with. I see a lot of commits from our previous team here and I need to be careful not to break anything. At the moment, I've applied the patch on top of our current version and tested in staging. I'll be rolling it out on our biggest cluster soon to validate whether it works.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New producer hangs in a loop detecting metadata for auto created topics,KAFKA-1238,12692756,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,jkreps,nehanarkhede,nehanarkhede,03/Feb/14 08:10,22/Jul/14 22:38,22/Mar/23 15:10,11/Feb/14 13:01,,,,,,,0.8.2.0,,,,,,,producer ,,,,0,,,,,,"New producer hangs in a loop detecting metadata for auto created topics -

java.lang.IllegalStateException: No known nodes.
	at kafka.common.Cluster.nextNode(Cluster.java:97)
	at kafka.clients.producer.internals.Sender.maybeMetadataRequest(Sender.java:154)
	at kafka.clients.producer.internals.Sender.run(Sender.java:120)
	at kafka.clients.producer.internals.Sender.run(Sender.java:84)
	at java.lang.Thread.run(Thread.java:695)
java.lang.IllegalStateException: No known nodes.
	at kafka.common.Cluster.nextNode(Cluster.java:97)
	at kafka.clients.producer.internals.Sender.maybeMetadataRequest(Sender.java:154)
	at kafka.clients.producer.internals.Sender.run(Sender.java:120)
	at kafka.clients.producer.internals.Sender.run(Sender.java:84)
	at java.lang.Thread.run(Thread.java:695)
java.lang.IllegalStateException: No known nodes.
	at kafka.common.Cluster.nextNode(Cluster.java:97)
	at kafka.clients.producer.internals.Sender.maybeMetadataRequest(Sender.java:154)
	at kafka.clients.producer.internals.Sender.run(Sender.java:120)
	at kafka.clients.producer.internals.Sender.run(Sender.java:84)
	at java.lang.Thread.run(Thread.java:695)
java.lang.IllegalStateException: No known nodes.
	at kafka.common.Cluster.nextNode(Cluster.java:97)
	at kafka.clients.producer.internals.Sender.maybeMetadataRequest(Sender.java:154)
	at kafka.clients.producer.internals.Sender.run(Sender.java:120)
	at kafka.clients.producer.internals.Sender.run(Sender.java:84)
	at java.lang.Thread.run(Thread.java:695)
java.lang.IllegalStateException: No known nodes.
	at kafka.common.Cluster.nextNode(Cluster.java:97)
	at kafka.clients.producer.internals.Sender.maybeMetadataRequest(Sender.java:154)
	at kafka.clients.producer.internals.Sender.run(Sender.java:120)
	at kafka.clients.producer.internals.Sender.run(Sender.java:84)
	at java.lang.Thread.run(Thread.java:695)
java.lang.IllegalStateException: No known nodes.
	at kafka.common.Cluster.nextNode(Cluster.java:97)
	at kafka.clients.producer.internals.Sender.maybeMetadataRequest(Sender.java:154)
	at kafka.clients.producer.internals.Sender.run(Sender.java:120)
	at kafka.clients.producer.internals.Sender.run(Sender.java:84)
	at java.lang.Thread.run(Thread.java:695)

The producer needs to be restarted to start sending data to the auto created topic",,guozhang,jkreps,junrao,nehanarkhede,tcollinsworth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/14 01:24;jkreps;KAFKA-1238-v1.patch;https://issues.apache.org/jira/secure/attachment/12627654/KAFKA-1238-v1.patch","04/Feb/14 02:28;jkreps;KAFKA-1238.patch;https://issues.apache.org/jira/secure/attachment/12626705/KAFKA-1238.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,371351,,,Fri May 23 04:00:28 UTC 2014,,,,,,,,,,"0|i1s007:",371654,,,,,,,,,,,,,,,,,,,,"04/Feb/14 02:28;jkreps;Fix attached.;;;","04/Feb/14 03:05;nehanarkhede;Thanks for the patch, Jay! 

Review comments-

        // the server can give back an empty metadata response (!) if the topic doesn't exist and that is our only
        // topic, don't use that

The comment is a bit misleading. The server returns the LeaderNotAvailable error code in the response. The handleMetadataResponse doesn't seem to check for error codes and retry based on that. But retries based on cluster.nodes().size() > 0? ;;;","04/Feb/14 09:54;jkreps;Ack, this is clearly the wrong fix, I was misinterpreting the response. Right one is to check the error code as you say. That will require some refactoring.;;;","08/Feb/14 01:24;jkreps;Here is an updated patch that has the safety check but also breaks the metadata parsing into a separate class to retain errors. This refactoring didn't end up being strictly necessary but is still good.;;;","08/Feb/14 01:48;nehanarkhede;Thanks for the patch. Few review comments

1. Using review board saves review time. Please can we use it :)
2. Sender.handleMetadataResponse
I'm not sure if I understand how the metadata retry happens based on error codes in the metadata response. Also, the comment here is confusing. We do return the list of all brokers even if the topic is being auto created. During auto creation, we create the topic and return the LeaderNotAvailable error code back. In this case, we should retry getting topic metadata, similar to when any error code is received in the response
3. MetadataResponse
Is there a way to define the fields in a central place instead of hardcoding it in 2 places - one where the fields are defined (Protocol) and the other where those will be parsed?;;;","08/Feb/14 02:59;jkreps;1. Yeah I have been but due to git accident this ended up on the wrong branch so the tool doesn't work. I figured this was a pretty trivial one.
2. Actually after considering it I think the error code is irrelevant. The logic is ""always update the cluster metadata unless doing so would remove all known nodes"". For any topic we don't get metadata retry will occur automatically after the backoff. This makes sense as the set of topics may contain multiple new topics, some of these may have metadata and some may not (because creation is in process). So the correct logic is to update with whatever you get, but in the special case where there are no brokers don't update.
3. I would rather have the name be the contract rather than a variable. My rationale is that if we define 300 static variables in the protocol definition it becomes very hard to read (and obviously the protocol can't refer to the request object).;;;","10/Feb/14 07:52;jkreps;Hey Neha, can you let me know if you agree with my rationale on these?;;;","10/Feb/14 14:06;nehanarkhede;Regarding #2, I'm not so sure I understood the logic behind updating metadata only where there are no brokers. When do you expect topic metadata to return no brokers? Also, if the metadata request doesn't have an error code (which means it succeeded for all topics it asked for), then why would we retry? Also, if it failed only for a subset of topics, why not just retry with the subset of topics that failed instead of all topics. And, the bug is still not fixed with the latest patch, still hangs in an infinite loop for a new topic that is auto created. Will go through the code in more detail, as I may be missing something obvious here.;;;","11/Feb/14 01:22;jkreps;The way metadata works is the following:
1. When someone requests metadata using Metadata.java that we don't have we we flag that we need to update metadata.
2. Once that flag is set the sender will update metadata until the flag is unset. The flag is unset whenever the cluster is updated. There is a metadata fetch backoff to prevent polling too quickly.
3. The metadata update described in (1) and (2) will repeat until we get metadata for the topic we requested or we time out.

So if we don't update the cluster metadata then the metadata request just repeats as soon as the backoff expires.

So that is why it works. But why is this the right logic? Why don't we check the error code? The reason is simple, if we ever remove ALL the nodes from the cluster metadata then we lose the ability to continue to update metadata because we update metadata using a random node in our metadata. So if we update our metadata to have no nodes, then we have no one to update metadata with.

The server's behavior is that it will always include whatever brokers are referenced by the metadata in the response. So if you give a single topic and that topic doesn't exist you will get no brokers back and an error code for that topic. But regardless of the reason if the cluster metadata comes back with no brokers we should not use it (the only reason I know this can happen is an error, but it basically doesn't matter what error and perhaps there are other conditions).;;;","11/Feb/14 08:40;guozhang;Added a testcase in integration test for auto-created topic and it passed. I think the patch works.

My understanding is that without the patch we can ran into the deadend where the cluster is updated to have zero brokers, and hence loop indefinitely there. I think longer-term we should probably return all the brokers in the cluster no matter of the TopicMetadataRequest content.

A few comments besides my non-committer +1 :

1. The ""throw new IllegalStateException(""No known nodes."");"" in nextNode should be fatal since once we got here there would be not way out. Shall we make this exception a special one and force producer to stop?

2. The re-factoring seems much like the Request Object, if we are going to live with it shall we have a RequestOrResponse interface with toStruct and fromStruct APIs?

Guozhang;;;","11/Feb/14 08:46;jkreps;Yeah arguably the server should just return all the brokers. I think the only argument against that was supporting very very large clusters.

1. I guess I meant that more as a ""this should not happen"" exception, rather than handle it I kind of just want to proceed with the testing and fix these cases.

2. Yeah I was going to wait on the outcome of the discussion on request protocol serialization to establish a pattern there. Not many people chimed in on that one.;;;","11/Feb/14 09:23;nehanarkhede;Got it. Thanks for the explanation. +1;;;","23/May/14 04:05;tcollinsworth;What release is this expected to be included in? The patch is not applied to 0.8.1.1. Don't see where any release info is stated on the bug for what it applies to or which it is scheduled.

I'm trying out 0.8.1.1 and when I try to publish to a new non-existent partition the publisher ends up in a loop logging exceptions. If the test/publisher is stopped and restarted it works fine since it successfully created the partition, but couldn't detect it until restarted.

java.lang.IllegalStateException: No known nodes.
	at org.apache.kafka.common.Cluster.nextNode(Cluster.java:135)
	at org.apache.kafka.clients.producer.internals.Sender.maybeMetadataRequest(Sender.java:171)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:137)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:101)
	at java.lang.Thread.run(Thread.java:745);;;","23/May/14 12:00;junrao;The new producer is only stable in trunk and we expect to release in the next release 0.8.2.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fetch Response contains messages prior to the requested offset,KAFKA-1744,12752178,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,eapache,eapache,01/Nov/14 20:47,07/Nov/14 10:01,22/Mar/23 15:10,07/Nov/14 10:01,0.8.1.1,,,,,,,,,,,,,core,,,,0,,,,,,"As reported in https://github.com/Shopify/sarama/issues/166 there are cases where a FetchRequest for a particular offset returns some messages prior to that offset.

The spec does not seem to indicate that this is possible; it does state that ""As an optimization the server is allowed to return a partial message at the end of the message set."" but otherwise implies that a request for offset X will only return complete messages starting at X. 

The scala consumer does seem to handle this case gracefully though, if I am reading it correctly (my scala is not the best): https://github.com/apache/kafka/blob/0.8.1/core/src/main/scala/kafka/consumer/ConsumerIterator.scala#L96-L99

So is this a bug or just a case that needs to be added to the spec? Something like ""As an optimization the server is allowed to return some messages in the message set prior to the requested offset. Clients should handle this case.""? Although I can't imagine why sending extra data would be faster than only sending the necessary messages...",,eapache,junrao,melraidin,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 07 02:00:26 UTC 2014,,,,,,,,,,"0|i21upj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"07/Nov/14 09:21;nehanarkhede;[~eapache] I'm assuming that you are referring to a non-java consumer right? We would always want to do this in the java consumer, so it's worth fixing the docs. Can you point me to the spec where you found this?;;;","07/Nov/14 09:28;eapache;[~nehanarkhede] this was discovered in the golang consumer I maintain - the scala consumer (as I linked) seems to handle this case already. I have not checked the java consumer.

The [spec for the fetch API|https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-FetchAPI] implies (though it does not explicitly state) that if I perform a fetch request for offset X, the fetch response will contain messages whose offset is strictly >= X. If this is not true (in practice I have seen messages with offsets < X) I would suggest explicitly noting this in the spec to avoid confusion.

Alternatively it may be a real bug in the broker, in which case the spec is fine and the broker should be fixed. I don't have enough information to say for sure.;;;","07/Nov/14 09:41;nehanarkhede;The broker sends data to the consumer using zero-copy, so it cannot filter the extra messages out. The spec already says Clients should handle this case. Should we close this JIRA?;;;","07/Nov/14 09:59;junrao;Evan,

I added the following explanation to the wiki.

""In general, the return messages will have offsets larger than or equal to the starting offset. However, with compressed messages, it's possible for the returned messages to have offsets smaller than the starting offset. The number of such messages is typically small and the caller is responsible for filter out those messages."";;;","07/Nov/14 10:00;eapache;[~junrao] thanks for the clarification, that's what I was looking for, this ticket can be closed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve ISR change propagation,KAFKA-2722,12909521,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,becket_qin,becket_qin,becket_qin,02/Nov/15 06:19,04/Nov/15 21:52,22/Mar/23 15:10,04/Nov/15 21:52,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Currently the ISR change propagation interval is hard coded to 5 seconds, this might still create a lot of ISR change propagation for a large cluster in cases such as rolling bounce. The patch uses a dynamic propagation interval and fixed a performance bug in IsrChangeNotificationListener on controller.",,becket_qin,githubbot,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Nov 04 13:52:36 UTC 2015,,,,,,,,,,"0|i2nsov:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"03/Nov/15 02:22;githubbot;Github user becketqin closed the pull request at:

    https://github.com/apache/kafka/pull/402
;;;","03/Nov/15 02:22;githubbot;GitHub user becketqin reopened a pull request:

    https://github.com/apache/kafka/pull/402

    KAFKA-2722: Improve ISR change propagation.

    The patch has two changes:
    1. fixed a bug in controller that it sends UpdateMetadataRequest of all the partitions in the cluster.
    2. Uses the following rules to propagate ISR change: 1) if there are ISR changes pending propagation and the last ISR change is more than five seconds ago, propagate the changes. 2) if there is ISR change at T in the recent five seconds, delay the propagation until T + 5s. 3) if the last propagation is more than 1 min ago, ignore rule No.2 and propagate ISR change if there are changes pending propagation.
    
    This algorithm avoids a fixed configuration of ISR propagation interval as we discussed about in KIP-29.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/becketqin/kafka KAFKA-2722

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/402.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #402
    
----
commit 13892856d806183536657f0c3ea2aa63b1f1c4f2
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2015-11-02T01:26:27Z

    Improve ISR change propagation.

----
;;;","04/Nov/15 21:52;junrao;Issue resolved by pull request 402
[https://github.com/apache/kafka/pull/402];;;","04/Nov/15 21:52;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/402
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Handle null values in Message payload,KAFKA-739,12629629,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,jkreps,jkreps,29/Jan/13 11:14,03/Jul/13 12:02,22/Mar/23 15:10,03/Jul/13 12:02,,,,,,,0.8.1,,,,,,,,,,,0,,,,,,"Add tests for null message payloads in producer, server, and consumer.
Ensure log cleaner treats these as deletes.
Test that null keys are rejected on dedupe logs.",,jkreps,junrao,nehanarkhede,sriramsub,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-741,,,,,,,,,,,,,,,,,,"05/Mar/13 06:55;jkreps;KAFKA-739-v1.patch;https://issues.apache.org/jira/secure/attachment/12571977/KAFKA-739-v1.patch","09/Mar/13 03:21;jkreps;KAFKA-739-v2.patch;https://issues.apache.org/jira/secure/attachment/12572801/KAFKA-739-v2.patch","09/Mar/13 07:31;jkreps;KAFKA-739-v3.patch;https://issues.apache.org/jira/secure/attachment/12572856/KAFKA-739-v3.patch","09/Mar/13 12:44;jkreps;KAFKA-739-v4.patch;https://issues.apache.org/jira/secure/attachment/12572892/KAFKA-739-v4.patch","13/Mar/13 00:46;jkreps;KAFKA-739-v5.patch;https://issues.apache.org/jira/secure/attachment/12573365/KAFKA-739-v5.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,310125,,,Tue Mar 12 17:38:58 UTC 2013,,,,,,,,,,"0|i1hisn:",310470,,,,,,,,,,,,,,,,,,,,"05/Mar/13 06:55;jkreps;This patch is more extensive than I expected because I found a hole in the logic when handling deletes in the log compactor. The changes are as follows:

1. Handle null properly in Message.scala and miscellaneous other places.
2. Fix the logic for handling deletes. Previously we guaranteed that we would retain delete records only in the dirty section of the log. This is not sufficient, because a bootstrapping consumer might see a message, but the subsequent delete message might be gc'd before the consumer sees it.
3. OffsetMap.scala: make the map exact using a probing scheme. This means that the tail of the log is actually now fully deduplicated. The motivation for this is making delete-handling easier since to remove a delete tombstone you need to ensure that there are no prior occurrences of that message. Also added a counter on the number of collisions, just to help with any debugging.
4. Added a new configuration log.cleaner.delete.retention.ms that controls the length of time for which delete records are retained. This is implicitly a limit on the amount of time the consumer can spend bootstrapping and still get a consistent bootstrap. Once the topic-level config patch goes in, this will be made available at the topic level and can be set with the create topic tool
5. Added a peek() method to iterator template. Didn't end up using it, but it is a useful feature
6. Changed the integration test tool to issue deletes and changed the verification to handle delete records properly. Redid testing now with deletes included.
7. Added a variety of unit tests for null messages
;;;","05/Mar/13 14:37;sriramsub;I am not able to apply this patch using git apply. Was this created using git format-patch?;;;","06/Mar/13 00:09;jkreps;No, actually it is just git diff against the base revision.;;;","07/Mar/13 03:26;nehanarkhede;There was a conflict on DefaultEventHandler, but I reviewed the patch. 

1. KafkaConfig
Should the default for log.cleaner.delete.retention.ms be 24 hours instead of 1 hour ?

2. LogCleaner
2.1 Should the check for dedup buffer be 
config.dedupeBufferSize / config.numThreads > Int.MaxValue

3. DefaultEventHandler (There was a conflict, maybe you already handled this)
Need to check for null payload in the following trace- 
              trace(""Successfully sent message: %s"".format(Utils.readString(message.message.payload)))))

4. DumpLogSegments
Should this be reading message.key instead ?
          print("" key: "" + Utils.readString(messageAndOffset.message.payload, ""UTF-8""))

5. SimpleKafkaETLMapper
Should probably check for null here in getData well -
                ByteBuffer buf = message.payload();

6. OffsetMap6.1 If I understand correctly from getPosition(), it seems that the probe length will change arbitrarily each time. What is the advantage of doing this VS picking a fixed probe length that is relatively prime to the total number of entries that the hash table can fit in ? The purpose of this property is so that every slot in the hash table can be eventually traversed.
6.2 Why does attempts increment by 1 and not by 4 ?

7. TestLogCleaning
The purpose of dumpLogs config is not clear from the command line option description.;;;","09/Mar/13 03:21;jkreps;New patch rebased to trunk and addresses Neha's comments:

1. Changed delete retention to 24 hours
2. Fixed broken logic in warning statement so it warns when your buffer is too big.
3. Yes, that was in the patch, just got lost in the conflict?
4. Dump log segments was printing the value as the key, fixed.
5. SimpleKafkaETLMapper didn't handle null. This isn't an easy fix since the text format doesn't have an out of range marker to represent null. Returning empty string which is ambiguous but better than crashing.
6. Linear probing has the problem that it tends to lead to ""runs"". I.e. if you have a fixed probing step size of N then if you have a collision the probability that the spot M slots over is full is going to be higher. So the ideal probing approach would be a sequence of fully random hashes which were completely uncorrelated with one another. That is the motivation for using the rest of the md5 before degrading to linear probing since we have already computed 16 bytes of random hash. The second question is wether it is legit to increment byte by byte or not since this effectively reuses bytes of the hash. I agree it is a little sketchy, though it does seem to work.
7. Clarified the purpose of dump logs.;;;","09/Mar/13 07:31;jkreps;Patch version V3:
1. Rebased to include the dynamic config change.
2. Made delete retention a per-topic config ;;;","09/Mar/13 09:02;sriramsub;1. OffsetMap
    a. The way the probe is calculated, we could end up having the same probe multiple times. Starting with attempt = hashSize - 4 to attempt = hashSize the probe would be the same. 
    val probe = Utils.readInt(hash, math.min(attempt, hashSize-4)) + math.max(0, attempt - hashSize)

2. LogCleaner
    a. Cleaner doc comments need to be updated
   
Will look at the test changes and provide comments if any.
;;;","09/Mar/13 12:44;jkreps;Nice catch Sriram, that actually drops the collision rate by 7%.

Here is a new patch that fixes that bug, fixes the docs, exposes the cleaner buffer load factor as a configuration parameter.;;;","12/Mar/13 00:02;nehanarkhede;+1 on patch v4;;;","12/Mar/13 05:29;junrao;Thanks for patch v4. Looks good. Some minor comments:

40. IteratorTemplate: Not sure that I understand how peek() is different from next(). If both cases, they call hasNext() and therefore move nextItem to the next item, right?

41. LogCleaner:
41.1 Could you add some comments in the header to describe how delete retention works?
41.2 cleanSegments(): val now not used.

42. Decoder:
42.1 Could we add a comment in the trait saying that bytes can be null?
42.2 We need to fix StringDecoder to return null if input is null.
;;;","13/Mar/13 00:46;jkreps;Jun, attached v5 patch to address your comments.
40. This is actually right, both peek, hasNext, and next will all call makeNext() if there isn't an item ready. But peek and hasNext are idempotent and next() isn't--it advances the iterator. I wrote a unit test that demonstrates this.
41. Added the comment and removed the stray variable.
42. Actually the handling of nulls is not done in the serializers, it is done in Kafka. That is no matter what serializer you use, null always deserializes to null. You could argue either way whether this is a good thing. The downside to pushing it isn't the serializer is that all serializers have to remember to handle null. The advantage is that the serializer could yield a different value for null if it wanted. Couldn't think of a use for the later so I went with the simple thing.;;;","13/Mar/13 01:38;junrao;Thanks for patch v5. +1.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka-console-producer does not take in customized values of --batch-size or --timeout,KAFKA-279,12543270,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,junrao,milindparikh,milindparikh,20/Feb/12 03:04,21/Mar/12 08:25,22/Mar/23 15:10,21/Mar/12 08:25,0.7,,,,,,0.7.1,,,,,,,contrib,,,,0,,,,,,"1. While the default console-producer, console-consumer paradigm works great, when I try modiying the batch size

bin/kafka-console-producer.sh --batch-size 300   --zookeeper localhost:2181 --topic test1

it gives me a

Exception in thread ""main"" java.lang.NumberFormatException: null
    at java.lang.Integer.parseInt(Integer.java:443)
    at java.lang.Integer.parseInt(Integer.java:514)
    at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:207)
    at scala.collection.immutable.StringOps.toInt(StringOps.scala:31)
    at kafka.utils.Utils$.getIntInRange(Utils.scala:189)
    at kafka.utils.Utils$.getInt(Utils.scala:174)
    at kafka.producer.async.AsyncProducerConfigShared$class.$init$(AsyncProducerConfig.scala:45)
    at kafka.producer.ProducerConfig.<init>(ProducerConfig.scala:25)
    at kafka.producer.ConsoleProducer$.main(ConsoleProducer.scala:108)
    at kafka.producer.ConsoleProducer.main(ConsoleProducer.scala)

I have looked at the code and can't figure out what's wrong

2. When I do bin/kafka-console-producer.sh --timeout 30000   --zookeeper localhost:2181 --topic test1

I would think that console-producer would wait for 30s if the batch size (default 200) is not full. It doesn't. It takes the same time without the timeout parameter (default 1000) and dumps whatever the batch size.


Resolution from Jun

1. The code does the following to set batch size
     props.put(""batch.size"", batchSize)
Instead, it should do
     props.put(""batch.size"", batchSize.toString)

2. It sets the wrong property name for timeout. Instead of doing
   props.put(""queue.enqueueTimeout.ms"", sendTimeout.toString)
it should do
   props.put(""queue.time"", sendTimeout.toString)
","Ubuntu 10.04, openjdk1.6 with default installation of 0.7",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Feb/12 06:33;junrao;kafka-279.patch;https://issues.apache.org/jira/secure/attachment/12515291/kafka-279.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,228516,,,Wed Mar 21 00:25:38 UTC 2012,,,,,,,,,,"0|i0l37j:",121170,,,,,,,,,,,,,,,,,,,,"21/Feb/12 06:33;junrao;Milind, 

Attached is a patch to trunk. Could you try it out and see if it fixes your problem?;;;","28/Feb/12 00:48;archs;I tried the patch and issuing the same command get the following stack trace part-way through an import of a 100000 line file (--batchsize 300):
[2012-02-27 16:44:37,911] ERROR Event queue is full of unsent messages, could not send event: 7300043|103|60|1329080400|en|1987973|269118099490000000000000103153898086 (kafka.producer.async.AsyncProducer)
Exception in thread ""main"" kafka.producer.async.QueueFullException: Event queue is full of unsent messages, could not send event: 7300043|103|60|1329080400|en|1987973|269118099490000000000000103153898086
        at kafka.producer.async.AsyncProducer.send(AsyncProducer.scala:121)
        at kafka.producer.ProducerPool$$anonfun$send$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$2.apply(ProducerPool.scala:131)
        at kafka.producer.ProducerPool$$anonfun$send$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$2.apply(ProducerPool.scala:131)
        at scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:61)
        at scala.collection.immutable.List.foreach(List.scala:45)
        at kafka.producer.ProducerPool$$anonfun$send$1$$anonfun$apply$mcVI$sp$1.apply(ProducerPool.scala:131)
        at kafka.producer.ProducerPool$$anonfun$send$1$$anonfun$apply$mcVI$sp$1.apply(ProducerPool.scala:130)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:130)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:102)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:102)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:102)
        at kafka.producer.Producer.zkSend(Producer.scala:143)
        at kafka.producer.Producer.send(Producer.scala:105)
        at kafka.producer.ConsoleProducer$.main(ConsoleProducer.scala:120)
        at kafka.producer.ConsoleProducer.main(ConsoleProducer.scala)
;;;","28/Feb/12 01:51;junrao;That typically means that you are sending data at a rate faster than the broker can persist. Try increasing flush.interval to sth like 10000 on the broker to increase server throughput.;;;","03/Mar/12 07:31;nehanarkhede;Milind, does the attached patch fix your problem ?;;;","20/Mar/12 01:07;ers81239;I tested this and verified that this fixes the error for --batch-size.  ;;;","21/Mar/12 08:25;junrao;Edward,

Thanks for the review. Just committed the patch to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Compilation in trunk is failing due to https://github.com/apache/kafka/commit/845514d62329be8382e6d02b8041fc858718d534,KAFKA-2538,12863580,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,parth.brahmbhatt,parth.brahmbhatt,parth.brahmbhatt,12/Sep/15 10:28,13/Sep/15 12:56,22/Mar/23 15:10,13/Sep/15 12:56,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Getting /Users/pbrahmbhatt/repo/kafka/core/src/main/scala/kafka/tools/EndToEndLatency.scala:82: value commit is not a member of org.apache.kafka.clients.consumer.KafkaConsumer[Array[Byte],Array[Byte]]
      consumer.commit(CommitType.SYNC)
               ^

Which I believe was missed when committing KAFKA-2389 which replaces all occurrences of commit(mode) with commit(Sync/Async). This is resulting in other PRS reporting as bad by jenkins like https://github.com/apache/kafka/pull/195 where 2 failures were reported by jenkins https://builds.apache.org/job/kafka-trunk-git-pr/410/ and https://builds.apache.org/job/kafka-trunk-git-pr/411/ ",,githubbot,parth.brahmbhatt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Sep 13 04:55:49 UTC 2015,,,,,,,,,,"0|i2k32f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"12/Sep/15 10:33;githubbot;GitHub user Parth-Brahmbhatt opened a pull request:

    https://github.com/apache/kafka/pull/208

    KAFKA-2538: Fixing a compilation error in trunk.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/Parth-Brahmbhatt/kafka KAFKA-2538

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/208.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #208
    
----
commit 24b4e01c251c51e0896887dbf65d92d101750b45
Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>
Date:   2015-09-12T02:33:08Z

    KAFKA-2538: Fixing a compilation error in trunk.

----
;;;","13/Sep/15 12:55;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/208
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Topic partition is not sometimes consumed after rebalancing of consumer group,KAFKA-2978,12920802,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,hachikuji,turek@avast.com,turek@avast.com,11/Dec/15 00:01,15/Dec/15 06:54,22/Mar/23 15:10,15/Dec/15 06:54,0.9.0.0,,,,,,0.9.0.1,,,,,,,consumer,core,,,0,,,,,,"Hi there, we are evaluating Kafka 0.9 to find if it is stable enough and ready for production. We wrote a tool that basically verifies that each produced message is also properly consumed. We found the issue described below while stressing Kafka using this tool.

Adding more and more consumers to a consumer group may result in unsuccessful rebalancing. Data from one or more partitions are not consumed and are not effectively available to the client application (e.g. for 15 minutes). Situation can be resolved externally by touching the consumer group again (add or remove a consumer) which forces another rebalancing that may or may not be successful.

Significantly higher CPU utilization was observed in such cases (from about 3% to 17%). The CPU utilization takes place in both the affected consumer and Kafka broker according to htop and profiling using jvisualvm. 

Jvisualvm indicates the issue may be related to KAFKA-2936 (see its screenshots in the GitHub repo below), but I'm very unsure. I don't also know if the issue is in consumer or broker because both are affected and I don't know Kafka internals.

The issue is not deterministic but it can be easily reproduced after a few minutes just by executing more and more consumers. More parallelism with multiple CPUs probably gives the issue more chances to appear.

The tool itself together with very detailed instructions for quite reliable reproduction of the issue and initial analysis are available here:

- https://github.com/avast/kafka-tests
- https://github.com/avast/kafka-tests/tree/issue1/issues/1_rebalancing
- Prefer fixed tag {{issue1}} to branch {{master}} which may change.
- Note there are also various screenshots of jvisualvm together with full logs from all components of the tool.

My colleague was able to independently reproduce the issue according to the instructions above. If you have any questions or if you need any help with the tool, just let us know. This issue is blocker for us.",,githubbot,guozhang,hachikuji,ijuma,turek@avast.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2936,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,Important,,,,,,,,,9223372036854775807,,,Mon Dec 14 22:54:46 UTC 2015,,,,,,,,,,"0|i2pq3b:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"11/Dec/15 00:28;ijuma;Thanks for the report Michal. Is there any chance you could test the latest code in the 0.9.0 branch instead of the 0.9.0.0 release? The branch contains a number of important fixes that were found and fixed after the release (and will be included in 0.9.0.1).;;;","11/Dec/15 00:31;turek@avast.com;Sure, I will try that and let you know the results.;;;","11/Dec/15 00:38;ijuma;Thanks! cc [~hachikuji];;;","11/Dec/15 01:36;turek@avast.com;Ismael, I afraid I have reproduced the issue using code from the 0.9.0 branch, the behavior is exactly the same as with official 0.9.0.0 release. The following is just for repeatability...

{noformat}
git pull https://github.com/apache/kafka.git
cd kafka
git checkout 0.9.0

git log | head -n3
commit a5fa661227b0b0b7da86b10b48e94bfb87d0b71d
Author: Edward Ribeiro <edward.ribeiro@gmail.com>
Date:   Wed Dec 9 20:34:09 2015 -0800

gradle
./gradlew clean
./gradlew releaseTarGz -x signArchives
# ./core/build/distributions/kafka_2.10-0.9.0.0.tgz

# Install the JARs locally to ~/.m2/repository/...
mvn install:install-file -Dfile=clients/build/libs/kafka-clients-0.9.0.0.jar -DgroupId=org.apache.kafka -DartifactId=kafka-clients -Dversion=0.9.0.0-localbuild -Dpackaging=jar
mvn install:install-file -Dfile=clients/build/libs/kafka-clients-0.9.0.0-sources.jar -DgroupId=org.apache.kafka -DartifactId=kafka-clients -Dversion=0.9.0.0-localbuild -Dclassifier=sources -Dpackaging=jar
mvn install:install-file -Dfile=clients/build/libs/kafka-clients-0.9.0.0-javadoc.jar -DgroupId=org.apache.kafka -DartifactId=kafka-clients -Dversion=0.9.0.0-localbuild -Dclassifier=javadoc -Dpackaging=jar

        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>0.9.0.0-localbuild</version>
        </dependency>
{noformat};;;","11/Dec/15 01:46;ijuma;Thanks for checking Michal.;;;","11/Dec/15 02:56;hachikuji;[~turek@avast.com] Thanks for the report. I'll assign this to myself and take a look. Out of curiosity, how large were the groups generally before you started seeing this problem?;;;","11/Dec/15 06:26;hachikuji;[~turek@avast.com] I was able to reproduce this on the 0.9.0 branch (the detailed instructions are really helpful by the way). Interestingly, I tried several runs against trunk and could not reproduce. Would you mind trying against trunk as well? ;;;","11/Dec/15 08:41;hachikuji;I think I see what's going on and the problem will affect trunk just as well. There is a window when a rebalance completes where a pending fetch can cause the consumed position to get out of sync with the fetched position. Here's the sequence:

1. Fetch is sent at offset 0: (fetched: 0, consumed: 0)
2. Rebalance is triggered: (fetched: 0, consumed: 0)
3. Fetch returns and is buffered. We set the next fetch position: (fetched: 25, consumed: 0)
4. Rebalance finishes and all offsets are reset: (fetched: 0, consumed: 0)
5. Buffered fetch is returned to the user and we update the consumed position: (fetched: 0, consumed: 25)

This can only happen if we get assigned the same partition in the rebalance. But when it does happen, we stop fetching against that partition since fetches are only sent if the fetched position matches the consumed position. This should be straightforward to fix, but I want to check if there are any other implications of a pending fetch which we haven't considered.;;;","11/Dec/15 11:19;guozhang;Thanks for the investigation, this makes sense.;;;","11/Dec/15 12:32;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/666

    KAFKA-2978: consumer stops fetching when consumed and fetch positions get out of sync

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-2978

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/666.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #666
    
----
commit 8a441def79cc8fa21da97759068c0caf7b7b425a
Author: Jason Gustafson <jason@confluent.io>
Date:   2015-12-11T04:30:43Z

    KAFKA-2978: consumer stops fetching when consumed and fetch positions get out of sync

----
;;;","11/Dec/15 21:48;turek@avast.com;Jason, I have just tried to break the updated consumer code from your https://github.com/hachikuji/kafka/tree/KAFKA-2978 repository and all my tests passed. The testing took about one hour and more than 1 million of messages were produced and properly consumed by both consumer groups. I have started and stopped consumers and producers many times, there was no unexpected delay in message flow. I believe your changes fix the bug, great work, thank you!

Do you have any idea when will be 0.9.0.1 ready and released?;;;","12/Dec/15 02:53;hachikuji;[~turek@avast.com] Thanks for confirming that the fix worked. I'm not sure about the release timeline for 0.9.0.1, but my guess is that they'll probably give it a few more weeks to shake out any other critical bugs. What do you think, [~guozhang]?;;;","15/Dec/15 06:54;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/666
;;;","15/Dec/15 06:54;guozhang;Issue resolved by pull request 666
[https://github.com/apache/kafka/pull/666];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
java.lang.NullPointerException in commitOffsets ,KAFKA-824,12638781,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,parth.brahmbhatt,yozhao,yozhao,25/Mar/13 13:59,02/Dec/15 00:42,22/Mar/23 15:10,03/Sep/15 04:48,0.7.2,0.8.2.0,,,,,0.9.0.0,,,,,,,consumer,,,,6,newbie,,,,,"Neha Narkhede

""Yes, I have. Unfortunately, I never quite around to fixing it. My guess is
that it is caused due to a race condition between the rebalance thread and
the offset commit thread when a rebalance is triggered or the client is
being shutdown. Do you mind filing a bug ?""


2013/03/25 12:08:32.020 WARN [ZookeeperConsumerConnector] [] 0_lu-ml-test10.bj-1364184411339-7c88f710 exception during commitOffsets
java.lang.NullPointerException
        at org.I0Itec.zkclient.ZkConnection.writeData(ZkConnection.java:111)
        at org.I0Itec.zkclient.ZkClient$10.call(ZkClient.java:813)
        at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
        at org.I0Itec.zkclient.ZkClient.writeData(ZkClient.java:809)
        at org.I0Itec.zkclient.ZkClient.writeData(ZkClient.java:777)
        at kafka.utils.ZkUtils$.updatePersistentPath(ZkUtils.scala:103)
        at kafka.consumer.ZookeeperConsumerConnector$$anonfun$commitOffsets$2$$anonfun$apply$4.apply(ZookeeperConsumerConnector.scala:251)
        at kafka.consumer.ZookeeperConsumerConnector$$anonfun$commitOffsets$2$$anonfun$apply$4.apply(ZookeeperConsumerConnector.scala:248)
        at scala.collection.Iterator$class.foreach(Iterator.scala:631)
        at scala.collection.JavaConversions$JIteratorWrapper.foreach(JavaConversions.scala:549)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
        at scala.collection.JavaConversions$JCollectionWrapper.foreach(JavaConversions.scala:570)
        at kafka.consumer.ZookeeperConsumerConnector$$anonfun$commitOffsets$2.apply(ZookeeperConsumerConnector.scala:248)
        at kafka.consumer.ZookeeperConsumerConnector$$anonfun$commitOffsets$2.apply(ZookeeperConsumerConnector.scala:246)
        at scala.collection.Iterator$class.foreach(Iterator.scala:631)
        at kafka.utils.Pool$$anon$1.foreach(Pool.scala:53)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
        at kafka.utils.Pool.foreach(Pool.scala:24)
        at kafka.consumer.ZookeeperConsumerConnector.commitOffsets(ZookeeperConsumerConnector.scala:246)
        at kafka.consumer.ZookeeperConsumerConnector.autoCommit(ZookeeperConsumerConnector.scala:232)
        at kafka.consumer.ZookeeperConsumerConnector$$anonfun$1.apply$mcV$sp(ZookeeperConsumerConnector.scala:126)
        at kafka.utils.Utils$$anon$2.run(Utils.scala:58)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:722)


",,adenysenko,danehammer,eidi,guozhang,junrao,lishuming,noslowerdna,oae,parth.brahmbhatt,rmetzger,techwhizbang,w00te,yozhao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2169,,,,,,,,,,,,,,,,,,FLINK-3067,,,,,,,,"24/Apr/14 11:43;adenysenko;ZkClient.0.3.txt;https://issues.apache.org/jira/secure/attachment/12641643/ZkClient.0.3.txt","24/Apr/14 11:43;adenysenko;ZkClient.0.4.txt;https://issues.apache.org/jira/secure/attachment/12641644/ZkClient.0.4.txt","05/May/14 13:01;adenysenko;screenshot-1.jpg;https://issues.apache.org/jira/secure/attachment/12643326/screenshot-1.jpg",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,319256,,,Wed Sep 02 20:48:14 UTC 2015,,,,,,,,,,"0|i1j33z:",319597,,,,,,,,,,,,,,,,,,,,"24/Apr/14 03:52;adenysenko;I have it as well. No special test case - but it fails periodically ~1 in 10 cases.
My configuration:
- zkclient: 0.4
- kafka: 2.9.2-0.8.1
- zookeeper: 3.4.5
;;;","24/Apr/14 06:50;guozhang;Currently we are only using zkclient 0.3. Could you check if this problem still persists in that version?

Guozhang;;;","24/Apr/14 11:43;adenysenko;It fails for both zkclient 0.3 and 0.4. Please see attached files.;;;","24/Apr/14 12:10;junrao;Do you see ZK session expiration around that time?;;;","24/Apr/14 13:28;adenysenko;I think it's a case then ""_connection"" is null for some reason: https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkClient.java#L308
Without going deep into hardcore I would override ""ZkClient.create"" with my method checking ""_connection"" for null:

{code:java}
public class KafkaZkClient extends ZkClient{
    public String create(final String path, Object data, final CreateMode mode) throws ZkInterruptedException, IllegalArgumentException, ZkException, RuntimeException {
        if (path == null) {
            throw new NullPointerException(""path must not be null."");
        }
        final byte[] bytes = data == null ? null : serialize(data);

        return retryUntilConnected(new Callable<String>() {

            @Override
            public String call() throws Exception {
                if(_connection==null) throw new ConnectionLossException(); // FIX HERE <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
                return _connection.create(path, bytes, mode);
            }
        });
    }
}
{code} ;;;","24/Apr/14 13:44;adenysenko;The root of the problem is here: https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkClient.java#L690
The first ""return callable.call();"" potentially can be called  even before ""_connection""  is initialized.

So it's better to fix the root.;;;","24/Apr/14 22:46;junrao;Hmm, not sure if this can happen. The following is what happens in the constructor. _connection is set there and the underlying _zk in ZkConnection is also set.

    public ZkClient(IZkConnection zkConnection, int connectionTimeout, ZkSerializer zkSerializer) {
        _connection = zkConnection;
        _zkSerializer = zkSerializer;
        connect(connectionTimeout, this);
    };;;","24/Apr/14 23:22;adenysenko;Could it be by re-using closed ZkClient? https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkClient.java#L941
It happens in some way.;;;","24/Apr/14 23:47;junrao;ZkClient is only closed when shutdown the consumer connector.;;;","05/May/14 13:01;adenysenko;Any progress?
Have a look: !screenshot-1.jpg!;;;","06/Jun/14 05:09;noslowerdna;We are seeing a similar NPE in our application's direct usage of the ZkClient, unrelated to commitOffsets.

Here are a couple example stack traces.
{noformat}
Caused by: java.lang.NullPointerException
	at org.I0Itec.zkclient.ZkConnection.create(ZkConnection.java:87)
	at org.I0Itec.zkclient.ZkClient$1.call(ZkClient.java:308)
	at org.I0Itec.zkclient.ZkClient$1.call(ZkClient.java:304)
	at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
	at org.I0Itec.zkclient.ZkClient.create(ZkClient.java:304)
	at org.I0Itec.zkclient.ZkClient.createPersistent(ZkClient.java:213)
{noformat}

{noformat}
Caused by: java.lang.NullPointerException
	at org.I0Itec.zkclient.ZkConnection.writeDataReturnStat(ZkConnection.java:115)
	at org.I0Itec.zkclient.ZkClient$10.call(ZkClient.java:817)
	at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
	at org.I0Itec.zkclient.ZkClient.writeDataReturnStat(ZkClient.java:813)
	at org.I0Itec.zkclient.ZkClient.writeData(ZkClient.java:808)
	at org.I0Itec.zkclient.ZkClient.writeData(ZkClient.java:777)
{noformat}

ZkClient implements the org.apache.zookeeper.Watcher interface, so the process() callback can be invoked at any time by the background ZK event thread [1]. This callback method is not synchronized against the other ZkClient public methods, however. So if a state change event occurs that requires a reconnection [2], the internal ZkConnection is closed while reconnecting [3] which sets its org.apache.zookeeper.ZooKeeper to null [4] resulting in the NullPointerException if the process is concurrently using the ZkClient to read or write data.

[1] http://zookeeper.apache.org/doc/r3.3.4/zookeeperProgrammers.html#Java+Binding
[2] https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkClient.java#L457
[3] https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkClient.java#L953-954
[4] https://github.com/sgroschupf/zkclient/blob/master/src/main/java/org/I0Itec/zkclient/ZkConnection.java#L79;;;","06/Jun/14 05:16;noslowerdna;Here's another example stack trace that we have seen.

{noformat}
java.lang.NullPointerException
	at org.I0Itec.zkclient.ZkConnection.exists(ZkConnection.java:95)
	at org.I0Itec.zkclient.ZkClient$3.call(ZkClient.java:439)
	at org.I0Itec.zkclient.ZkClient$3.call(ZkClient.java:436)
	at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
	at org.I0Itec.zkclient.ZkClient.exists(ZkClient.java:436)
	at org.I0Itec.zkclient.ZkClient$12.call(ZkClient.java:846)
	at org.I0Itec.zkclient.ZkClient$12.call(ZkClient.java:843)
	at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
	at org.I0Itec.zkclient.ZkClient.watchForChilds(ZkClient.java:843)
	at org.I0Itec.zkclient.ZkClient.subscribeChildChanges(ZkClient.java:114)
	at kafka.consumer.ZookeeperConsumerConnector.kafka$consumer$ZookeeperConsumerConnector$$reinitializeConsumer(ZookeeperConsumerConnector.scala:713)
	at kafka.consumer.ZookeeperConsumerConnector$WildcardStreamsHandler.(ZookeeperConsumerConnector.scala:756)
	at kafka.consumer.ZookeeperConsumerConnector.createMessageStreamsByFilter(ZookeeperConsumerConnector.scala:145)
	at kafka.javaapi.consumer.ZookeeperConsumerConnector.createMessageStreamsByFilter(ZookeeperConsumerConnector.scala:96)
{noformat};;;","07/Jun/14 01:24;noslowerdna;I have reported this issue to the zkclient project: https://github.com/sgroschupf/zkclient/issues/25;;;","30/Apr/15 22:48;w00te;Has any progress been made on this, or do any workarounds exist yet?  Has anyone determined what causes it in particular?

We're getting it fairly regularly and I would love to know how to mitigate the issue.;;;","30/Apr/15 23:47;oae;Hi guys,

just had a look at this.
Think there are only 2 possibilities that such an exception can occur:
- 1) a null zkConnection is passed in
- 2) a retryUntilConnected action wakes up and the client was closed in meantime

I could reproduce the NPE for case 2 and changed the code to throw an clear exception instead of risking unclear follow up exception like the NPE's.
See https://github.com/sgroschupf/zkclient/commit/0630c9c6e67ab49a51e80bfd939e4a0d01a69dfe

HTH

PS: this is part of the zkclient-0.5 release which should be online in a few hours!;;;","01/May/15 00:28;w00te;Awesome, thank you for the quick follow-up :).;;;","18/Jul/15 04:05;techwhizbang;Can someone confirm that upgrading to zkclient-0.5 did fix the NPE?;;;","21/Jul/15 00:23;parth.brahmbhatt;[~techwhizbang] I upgraded to zkClient-0.5 so I will verify this is fixed and update the jira.;;;","21/Jul/15 08:25;parth.brahmbhatt;[~junrao] Looked at the fix code and ensure that it was part of 0.5 release. The fix also had a unit test so I believe this is ok to resolve. ;;;","03/Sep/15 04:48;junrao;[~parth.brahmbhatt], thanks for confirming this. Resolving this jira.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Broker should automatically handle corrupt index files,KAFKA-2012,12780590,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,omkreddy,toddpalino,toddpalino,10/Mar/15 03:48,08/Oct/16 00:58,22/Mar/23 15:10,20/Jun/15 00:34,0.8.1.1,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"We had a bunch of unclean system shutdowns (power failure), which caused corruption on our disks holding log segments in many cases. While the broker is handling the log segment corruption properly (truncation), it is having problems with corruption in the index files. Additionally, this only seems to be happening on some startups (while we are upgrading).

The broker should just do what I do when I hit a corrupt index file - remove it and rebuild it.

2015/03/09 17:58:53.873 FATAL [KafkaServerStartable] [main] [kafka-server] [] Fatal error during KafkaServerStartable startup. Prepare to shutdown
java.lang.IllegalArgumentException: requirement failed: Corrupt index found, index file (/export/content/kafka/i001_caches/__consumer_offsets-39/00000000000000000000.index) has non-zero size but the last offset is -2121629628 and the base offset is 0
	at scala.Predef$.require(Predef.scala:233)
	at kafka.log.OffsetIndex.sanityCheck(OffsetIndex.scala:352)
	at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:185)
	at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:184)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at kafka.log.Log.loadSegments(Log.scala:184)
	at kafka.log.Log.<init>(Log.scala:82)
	at kafka.log.LogManager$$anonfun$loadLogs$2$$anonfun$3$$anonfun$apply$7$$anonfun$apply$1.apply$mcV$sp(LogManager.scala:141)
	at kafka.utils.Utils$$anon$1.run(Utils.scala:54)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)",,junrao,mazhar.shaikh.in,mgharat,omkreddy,toddpalino,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1554,,KAFKA-1554,,,,,,,,,,,,,,,,"16/Jun/15 17:57;omkreddy;KAFKA-2012.patch;https://issues.apache.org/jira/secure/attachment/12739834/KAFKA-2012.patch","19/Jun/15 21:28;omkreddy;KAFKA-2012_2015-06-19_18:55:11.patch;https://issues.apache.org/jira/secure/attachment/12740646/KAFKA-2012_2015-06-19_18%3A55%3A11.patch","19/Jun/15 23:42;omkreddy;KAFKA-2012_2015-06-19_21:09:22.patch;https://issues.apache.org/jira/secure/attachment/12740666/KAFKA-2012_2015-06-19_21%3A09%3A22.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Jun 20 05:56:13 UTC 2015,,,,,,,,,,"0|i26j9r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"16/Jun/15 17:57;omkreddy;Created reviewboard https://reviews.apache.org/r/35503/diff/
 against branch origin/trunk;;;","19/Jun/15 21:28;omkreddy;Updated reviewboard https://reviews.apache.org/r/35503/diff/
 against branch origin/trunk;;;","19/Jun/15 23:09;junrao;The latest patch looks good to me. Could you rebase since we just committed KAFKA-1646? Thanks,;;;","19/Jun/15 23:42;omkreddy;Updated reviewboard https://reviews.apache.org/r/35503/diff/
 against branch origin/trunk;;;","20/Jun/15 00:34;junrao;Thanks for the latest patch. +1 and committed to trunk.;;;","20/Jun/15 03:10;mgharat;Discussed this with [~jjkoshy]. This patch seems like a workaround and does not actually tell us why the file got corrupted in first place. We can probably have a config that can turn this code path ON or OFF, so that we can actually investigate when this happens. 
Let me know, I can open another ticket or use this : https://issues.apache.org/jira/browse/KAFKA-1554 to add that config.

This was discussed in KAFKA-1554 :

Joel Koshy added a comment - 14/Mar/15 01:10
That would be a work-around, but ideally we should figure out why it happened in the first place.

 Jun Rao added a comment - 09/Apr/15 02:06
Yes, I am not sure if auto fixing the index is better. People then may not realize if there is an issue. It would be better to figure out what's causing this.


Thanks,

Mayuresh
;;;","20/Jun/15 05:00;junrao;I am not sure if it's better to add another config. Perhaps, we can just save the corrupted file as Gwen suggested in KAFKA-1554 for trouble shooting.;;;","20/Jun/15 13:56;omkreddy;I am not sure if we can find out the reason after file corruption. i,e  What we can infer from a corrupted file? 
instead we should  add some defensive code/logs before and after index reads/writes. looks like KAFKA-1554 got some steps to reproduce the issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Verify that metric names will not collide when creating new topics,KAFKA-2337,12845363,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,gwenshap,gwenshap,16/Jul/15 03:11,01/Aug/15 00:30,22/Mar/23 15:10,21/Jul/15 08:31,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"When creating a new topic, convert the proposed topic name to the name that will be used in metrics and validate that there are no collisions with existing names.

See this discussion for context: http://s.apache.org/snW



",,gwenshap,junrao,neelesh77,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2393,,,,,,,,,,"17/Jul/15 23:27;granthenke;KAFKA-2337.patch;https://issues.apache.org/jira/secure/attachment/12745827/KAFKA-2337.patch","18/Jul/15 00:17;granthenke;KAFKA-2337_2015-07-17_11:17:30.patch;https://issues.apache.org/jira/secure/attachment/12745834/KAFKA-2337_2015-07-17_11%3A17%3A30.patch","21/Jul/15 01:37;granthenke;KAFKA-2337_2015-07-20_12:36:41.patch;https://issues.apache.org/jira/secure/attachment/12746137/KAFKA-2337_2015-07-20_12%3A36%3A41.patch","21/Jul/15 05:48;granthenke;KAFKA-2337_2015-07-20_16:48:25.patch;https://issues.apache.org/jira/secure/attachment/12746189/KAFKA-2337_2015-07-20_16%3A48%3A25.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jul 31 16:23:44 UTC 2015,,,,,,,,,,"0|i2hasv:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"17/Jul/15 23:27;granthenke;Created reviewboard https://reviews.apache.org/r/36570/diff/
 against branch origin/trunk;;;","17/Jul/15 23:30;granthenke;This patch:
- Checks all topic creation including auto-create
- Fails with InvalidTopicException when topics collide (periods and underscores in the same position)
- Warns when a topic with a period or underscore is created via kafka-topics.sh;;;","18/Jul/15 00:17;granthenke;Updated reviewboard https://reviews.apache.org/r/36570/diff/
 against branch origin/trunk;;;","21/Jul/15 01:37;granthenke;Updated reviewboard https://reviews.apache.org/r/36570/diff/
 against branch origin/trunk;;;","21/Jul/15 05:48;granthenke;Updated reviewboard https://reviews.apache.org/r/36570/diff/
 against branch origin/trunk;;;","21/Jul/15 07:18;gwenshap;Pushed to trunk.

Thanks for the patch [~granthenke] and for reviews [~eribeiro] and [~singhashish].;;;","01/Aug/15 00:19;junrao;Sorry for the late comment. It seems that in KafkaApis.getTopicMetadata(), we need to handle InvalidTopicException explicitly when calling AdminUtils.createTopic (by returning the corresponding error code for that topic). Otherwise, we may not be able to get the metadata for other valid topics. This seems to be an existing problem, but this jira makes InvalidTopicException more likely to happen. We can either fix this as a followup in this jira and in a new jira.;;;","01/Aug/15 00:23;granthenke;Since this is already committed, lets create a new Jira and I can get it done quickly.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RecordAccumulator request timeout not enforced when all brokers are gone,KAFKA-2805,12912047,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,mgharat,hachikuji,hachikuji,11/Nov/15 09:51,12/Nov/15 10:42,22/Mar/23 15:10,12/Nov/15 10:42,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"When no brokers are left in the cluster, the producer seems not to enforce the request timeout as expected.

From the user mailing list, the null check in batch expiration in RecordAccumulator seems questionable: https://github.com/apache/kafka/blob/ae5a5d7c08bb634576a414f6f2864c5b8a7e58a3/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java#L220. 

If this is correct behavior, it is probably worthwhile clarifying the purpose of the check in a comment.
",,githubbot,hachikuji,junrao,lukesteensen,mgharat,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 12 02:42:46 UTC 2015,,,,,,,,,,"0|i2o86f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"11/Nov/15 09:52;hachikuji;[~mgharat] [~becket_qin] Do you have any thoughts?;;;","11/Nov/15 10:23;junrao;From the RB, that's the explanation from Mayuresh.

In this case :"" Second, let's say the producer can't connect to any broker. The producer can't refresh the metdata. So the leader will still be the old one and may not be null. In this case, it seems that we should still expire the records."", the request will eventually fail due to requestTimeout and retry exhaustion, when trying to send to broker.

What he is saying is that if the leader is not null, we will be keep resending to the leader broker that may not be reachable and eventually the request will error out when all retries are exhausted.;;;","11/Nov/15 10:41;mgharat;Yes. That was the thinking. Also from the KIP-19 discussion it was decided that Request timeout will also be used when the batches in the accumulator that are ready but not drained due to metadata missing - we are reusing request timeout to timeout the batches in accumulator. When we say metadata is missing, it means that we don't have information about the leader.
 ;;;","11/Nov/15 10:59;hachikuji;I was able to reproduce this following the steps from Luke Steensen's initial e-mail:
{code}
# in separate terminals
$ ./bin/zookeeper-server-start.sh config/zookeeper.properties
$ ./bin/kafka-server-start.sh config/server.properties

# set request timeout
$ cat producer.properties
request.timeout.ms=1000

# run the verifiable producer, for example
$ ./bin/kafka-verifiable-producer.sh --broker-list localhost:9092 --topic
testing --throughput 5 --producer.config producer.properties
{code}

{quote}
If you then kill the kafka server process, you will see the producer hang
indefinitely. This is a very simple case, but the behavior is surprising.
We have also found it easy to reproduce this behavior in more realistic
environments with multiple brokers, custom producers, etc. The end result
is that we're not sure how to safely decommission a broker without
potentially leaving a producer with a permanently stuck request.
{quote};;;","11/Nov/15 11:29;mgharat;I did this experiment :

1) I created a topic called ""kip-19-followup"" on one of our test cluster with 1 partition and replication factor 1.

2) started the producer class :
./kafka-verifiable-producer.sh --topic kip-19-followup --broker-list (BROKER LIST) --max-messages 92233736 --acks 1

3) The producer started producing  and I could see : 
{""partition"":0,""offset"":3164368,""time_ms"":1447212192651,""name"":""producer_send_success"",""topic"":""kip-19-followup"",""class"":""class org.apache.kafka.tools.VerifiableProducer"",""value"":""9547"",""key"":null}

4) Then I killed the broker that was hosting this topic and I could see :
{""exception"":""class org.apache.kafka.common.errors.TimeoutException"",""time_ms"":1447212028704,""name"":""producer_send_error"",""topic"":""kip-19-followup"",""message"":""Batch Expired"",""class"":""class org.apache.kafka.tools.VerifiableProducer"",""value"":""107100"",""key"":null}

The producer did not hang. My broker is not on trunk though.

Thanks,

Mayuresh
;;;","11/Nov/15 11:58;hachikuji;[~mgharat] I was on trunk when I reproduced the problem. Perhaps something changed affecting the retry logic? It still seems a little puzzling to me that these cases are handled differently. If the timeout has expired before the batch could be sent, seems like you'd want to expire regardless of the reason.;;;","11/Nov/15 12:16;mgharat;[~hachikuji] My producer was on trunk when I ran this test. But my request timeout was set to 30 seconds instead of 1 sec. I will test this tomorrow again and keep a patch ready if required.

Thanks,

Mayuresh;;;","12/Nov/15 00:41;junrao;[~mgharat], I am not sure if the current logic works. If the leader is not null and is for a broker not connectable, in Sender.run(), the partitions for this leader will be ready, but are drainable since the leader is not connectable. So, messages in those partitions will never timeout in the current logic. 

In Jason's test, you can get into the above situation when the only broker is killed since metadata won't be refreshed after the broker is down. In your test, if you provided multiple brokers in broker list, things are a bit different. The producer will be able to refresh metadata from other brokers and see the leader is gone. In this case, the producer will see a null leader. That's probably why you don't see the issue in your test. In both case, the effect is pretty much the same---we can't send the partitions' data. So, the simplest solution is probably to remove the null check on leader in abortExpiredBatches(). If the leader can't be connected for a long period of time, the partitions are guaranteed to be drained. If the leader is connectable, but the send fails (e.g., due to NotLeader), lastAttemptMs will be updated and we will go through the retries. Does that sound reasonable?
;;;","12/Nov/15 00:43;junrao;Marking this as an 0.9.0.0 blocker for now.;;;","12/Nov/15 00:49;lukesteensen;[~mgharat] To answer your question from the mailing list, I was only running one broker in the cluster for this case. My intention was to do a simple test of the new behavior before pushing the new version to one of our deployed environments. 

It's worth noting that you can get this same behavior with the following producer config:
{code}
retries=0
max.block.ms=1000
{code}

I will continue testing, but it does seem that the configs are respected when running more than one broker. 

Thanks for taking a look!
Luke;;;","12/Nov/15 02:55;junrao;[~mgharat], since this blocks the 0.9.0.0 release, do you think you can look at this in the next few hours?;;;","12/Nov/15 04:14;hachikuji;Went ahead and assigned to myself to try and unblock the release. [~mgharat] If you're already working on it, feel free to assign it back to you.;;;","12/Nov/15 04:24;mgharat;Hi Jason,

I was debugging to find exactly what is happening. Is it ok if I can get back with a patch ( if necessary ) by EOD.
If I am not able to finish this today, you can go ahead with this jira. Is it ok?

Thanks,

Mayuresh;;;","12/Nov/15 04:31;hachikuji;Works for me. I'll assign back to you.;;;","12/Nov/15 10:04;githubbot;GitHub user MayureshGharat opened a pull request:

    https://github.com/apache/kafka/pull/503

    KAFKA-2805

    Removed the check for only those expiring batches whose metadata is unavailable. Now the batches will be expired irrespective of whether the leader is available or not, as soon as it reaches the requestimeout threshold.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/MayureshGharat/kafka kafka-2805

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/503.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #503
    
----
commit 573c68b9ee3107a50c96d383e22dd415fc39b96f
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2015-11-12T01:42:46Z

    Removed the check for only those expiring batches whose metadata is unavailable. Now the batches will be expired irrespective of whether the leader is available or not, as soon as it reaches the requestimeout threshold

----
;;;","12/Nov/15 10:14;mgharat;Yes. That s right. The check was put in place because the KIP-19 explicitly mentioned that it should timeout the batches only if the metadata is unavailable. I debugged this today and found the same reasoning. I was going to write the same explanation before I read this comment. 

My bad, I should have considered that accumulator will not drain the batches for NOT ready nodes and the batches will not be expired since the metadata is stale and has the leader present. I have uploaded a patch for removing the check. ;;;","12/Nov/15 10:42;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/503
;;;","12/Nov/15 10:42;junrao;Issue resolved by pull request 503
[https://github.com/apache/kafka/pull/503];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FetcherThread backoff need to grab lock before wait on condition.,KAFKA-2150,12823969,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriharsha,becket_qin,becket_qin,25/Apr/15 15:48,13/Nov/15 23:33,22/Mar/23 15:10,12/May/15 08:43,,,,,,,,,,,,,,,,,,0,newbie++,,,,,"Saw the following error: 
kafka.api.ProducerBounceTest > testBrokerFailure STANDARD_OUT
    [2015-04-25 00:40:43,997] ERROR [ReplicaFetcherThread-0-0], Error due to  (kafka.server.ReplicaFetcherThread:103)
    java.lang.IllegalMonitorStateException
    	at java.util.concurrent.locks.ReentrantLock$Sync.tryRelease(ReentrantLock.java:127)
    	at java.util.concurrent.locks.AbstractQueuedSynchronizer.release(AbstractQueuedSynchronizer.java:1239)
    	at java.util.concurrent.locks.AbstractQueuedSynchronizer.fullyRelease(AbstractQueuedSynchronizer.java:1668)
    	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2107)
    	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:95)
    	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)
    [2015-04-25 00:40:47,064] ERROR [ReplicaFetcherThread-0-1], Error due to  (kafka.server.ReplicaFetcherThread:103)
    java.lang.IllegalMonitorStateException
    	at java.util.concurrent.locks.ReentrantLock$Sync.tryRelease(ReentrantLock.java:127)
    	at java.util.concurrent.locks.AbstractQueuedSynchronizer.release(AbstractQueuedSynchronizer.java:1239)
    	at java.util.concurrent.locks.AbstractQueuedSynchronizer.fullyRelease(AbstractQueuedSynchronizer.java:1668)
    	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2107)
    	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:95)
    	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)
We should grab the lock before waiting on the condition.",,becket_qin,guozhang,nehanarkhede,ralph.tice,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1461,,,,,,,,,,"25/Apr/15 22:48;sriharsha;KAFKA-2150.patch;https://issues.apache.org/jira/secure/attachment/12728152/KAFKA-2150.patch","26/Apr/15 04:14;sriharsha;KAFKA-2150_2015-04-25_13:14:05.patch;https://issues.apache.org/jira/secure/attachment/12728172/KAFKA-2150_2015-04-25_13%3A14%3A05.patch","26/Apr/15 04:18;sriharsha;KAFKA-2150_2015-04-25_13:18:35.patch;https://issues.apache.org/jira/secure/attachment/12728174/KAFKA-2150_2015-04-25_13%3A18%3A35.patch","26/Apr/15 04:35;sriharsha;KAFKA-2150_2015-04-25_13:35:36.patch;https://issues.apache.org/jira/secure/attachment/12728175/KAFKA-2150_2015-04-25_13%3A35%3A36.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 13 15:33:39 UTC 2015,,,,,,,,,,"0|i2dr5z:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"25/Apr/15 15:51;becket_qin;This is introduced in KAFKA-1461. Fix should be straight forward.;;;","25/Apr/15 22:48;sriharsha;Created reviewboard https://reviews.apache.org/r/33551/diff/
 against branch origin/trunk;;;","26/Apr/15 04:14;sriharsha;Updated reviewboard https://reviews.apache.org/r/33551/diff/
 against branch origin/trunk;;;","26/Apr/15 04:18;sriharsha;Updated reviewboard https://reviews.apache.org/r/33551/diff/
 against branch origin/trunk;;;","26/Apr/15 04:35;sriharsha;Updated reviewboard https://reviews.apache.org/r/33551/diff/
 against branch origin/trunk;;;","27/Apr/15 03:24;nehanarkhede;[~guozhang] This was introduced in KAFKA-1461, so assigning to you for review since you reviewed that one :);;;","07/May/15 07:39;sriharsha;[~guozhang] Can you please take a look at this patch . Thanks.;;;","12/May/15 08:43;guozhang;My bad on missing this but while reviewing. +1 and committed to trunk.;;;","13/May/15 04:33;sriharsha;Thanks for merging it [~guozhang] and sorry about sending bad patch :).;;;","13/Nov/15 23:33;ralph.tice;linking so it's clear on both issues 1461 raised a bug;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve the high water mark maintenance to store high watermarks for all partitions in a single file on disk,KAFKA-405,12599038,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,17/Jul/12 05:10,02/Aug/12 02:10,22/Mar/23 15:10,26/Jul/12 07:42,0.8.0,,,,,,,,,,,,,,,,,0,,,,,,KAFKA-46 introduced per partition leader high watermarks. But it stores those in one file per partition. A more performant solution would be to store all high watermarks in a single file on disk,,fxbing,jkreps,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-355,,,,,,,,,,,,,,,,,,"18/Jul/12 14:20;nehanarkhede;kafka-405-v1.patch;https://issues.apache.org/jira/secure/attachment/12536958/kafka-405-v1.patch","21/Jul/12 08:38;nehanarkhede;kafka-405-v2.patch;https://issues.apache.org/jira/secure/attachment/12537431/kafka-405-v2.patch","26/Jul/12 04:09;nehanarkhede;kafka-405-v3.patch;https://issues.apache.org/jira/secure/attachment/12537887/kafka-405-v3.patch","26/Jul/12 07:29;nehanarkhede;kafka-405-v4.patch;https://issues.apache.org/jira/secure/attachment/12537921/kafka-405-v4.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,248175,,,Wed Aug 01 18:10:55 UTC 2012,,,,,,,,,,"0|i09m0n:",54000,,,,,,,,,,,,,,,,,,,,"18/Jul/12 14:20;nehanarkhede;This patch improves the high watermark persistence strategy to store the high watermark values for all partitions in a single file.

The changes include -

1. Log.scala
1.1 Moved the highwatermark file out of the Log. Since highwatermark is related to replication state and not log persistence, it makes sense for it to not be part of kafka.log
1.2 Since the log recovery logic requires to modify log segments, recoverUptoLastCheckpointedHighWatermark() API stays in Log.scala. It is passed in the last checkpointed high watermark from ReplicaManager during make follower state change

2. ReplicaManager
2.1 Added a startup API to ReplicaManager to be consistent with all other components.
2.2 Added a scheduler that will checkpoint high watermarks at defaultFlushIntervalMs rate. I didn't think it was useful to introduce another config to control the rate at which high watermarks are flushed to disk, so I reused the one we have for flushing log segments
2.3 Added a checkpointHighwaterMark() API that will iterate through all the local replicas for each partition and write the high watermark file in the following format
number of entries  (4 bytes)
topic              (UTF)
partition          (4 bytes)
highwatermark      (8 bytes)
2.4 Added a readCheckpointedHighWatermark() API that reads the high watermark file to get the latest high watermark for a particular topic/partition. This method is called once per partition on startup, and during every make follower state change.

3. HighWatermarkPersistenceTest
Added a couple of unit tests to verify that the new high watermark persistence code is working.
This will further get tested during system testing, once KAFKA-350 is checked in
;;;","19/Jul/12 08:49;jkreps;Some of these comments are not directly related to this change but this is just the first time I have looked at this code in detail

- I think Log.recoverUptoLastCheckpointedHighWatermark(lastKnownHW: Long) is misnamed. I don't think the log should know anything about hw marks, and it also isn't doing recovery (e.g. checking the validity of the log), I think it is just blindly truncating the log. Can we change it to Log.truncateTo
- Is it possible that we need to truncate more than one segment? I.e. couldn't the segment to be truncated not be the last segment (unlikely with 1gb segments, but still a problem)
- Can we change the api in MessageSet.truncateUpto should be truncateUpTo or truncateTo
- Can you make a wrapper for the RandomAccessFile called HighwaterMarkCheckpoint and put the logic related to that there. Intuitively the logic for serializing a checkpoint shouldn't be mixed into ReplicaManager. Can you also document the file format? Is there a reason this can't be plain text? Also I think a better approach to the updates would be to create a new file, write to it, and then move it over the old one; this will make the update atomic. Not sure if that is needed...
- It would be good to have a test that covered the HighwaterMarkCheckpoint file read and write. Just basic reading/writing, nothing fancy.
- Do we need to version the hw mark checkpoint file format? I.e. maybe the first line of the file is version=x or something... Not sure if that is needed but I am paranoid about persistent formats after blowing that and being stuck. This would let format changes be handled automatically.
- Can we fix the setters/getters in Replica.scala and make changes to the leo update the leoUpdateTime. Currently I think it is encumbant on the caller to do these two things together which is odd...
- I think the use of KafkaScheduler is not quite right. This is a thread pool meant to execute many tasks. There should really only be one for all of kafka, not one per background thread. You should probably pass in a central instance as an argument rather than making two new ones.
- Also I notice that ReplicaManager.getReplica returns an Option. But then everyone who calls it needs to check the option and return an exception if it is not found. Can we just have getReplica either return the Replica or throw the exception?
- I think abbreviations should be in the form updateLeo not updateLEO and updateIsr not updateISR. Let's standardize that.;;;","20/Jul/12 10:39;nehanarkhede;1. Good point. Changed the name to Log.truncateTo(targetOffset)
2. It is possible to truncate multiple segments. The truncateTo API handles that. It deletes segments that have start offset > targetOffset. Only one segment will ever need to be truncated. Rest will have to be deleted.
3. Changed FileMessageSet.truncateUpto to truncateTo to make it consistent with Log.truncateTo
4. Created wrapper HighwatermarkCheckpoint. Documented the file format here. I had thought about atomic updates but there is only one thread that serializes the checkpoints, so didn't think swapping the old file with the new one would be required, no ?
5. As for unit testing, I've added a new test HighwatermarkPersistenceTest that tests the writing/reading high watermark values for single as well as multiple partitions.
6. I think it is a good idea to version the high watermark file, just in case we didn't cover something that we need to in the future
7. We have a JIRA open for fixing all getters/setters, so I'll defer that change. The logEndOffset logic is a little tricky. It seems correct to not expose a separate API to set the logEndOffsetUpdateTime and just let the logEndOffset setter API do it. But, here is the problem. The leader needs to record its own log end offset update time while appending messages to local log. However, since the Log doesn't know anything about logEndOffsetUpdateTime, its append API cannot set the udpate time. Also, the leader cannot use the logEndOffset setter API since its log end offset is recorded by its local Log object. The logEndOffset setter API is meant only to record the follower's log end offset. But since it makes sense for the update time to be updated while setting the logEndOffset, I've fixed it. Basically, the logEndOffset() setter API updates only the logEndOffset time when a local log exists for the replica. For all other cases, it updates both the logEndOffset as well as the logEndOffsetUpdateTime 
8. Yeah, there are several callers that use the getReplica() API and don't always re-throw an exception. Some are re-throwing an error while others are using the Option to return some default value for some state of the Replica (highwatermark). And case match in Scala is good for that since it always evaluates to a value, a try catch block doesn't. But if all the callers throw an exception, then it makes sense to have getReplica throw it instead. 
9. You have a valid point about KafkaScheduler usage. However, we name the thread appropriately with every instance of the scheduler. Ideally, if there was a way to override the base thread name independently with the same scheduler, it would be possible to use a single scheduler.
10. Good point about abbreviations. Fixed that. Let's standardize on this.

Also, changed the name to updateLEO to updateLeo
;;;","24/Jul/12 00:02;jkreps;4. The concern I have is that fs writes are not atomic unless they are < 1 block. What happens if the broker fails in the middle of a write? Also is there a reason we can't just have a plain text file? That will be a little bulkier, but the good thing is you can cat it and see what is there. I think that will be a lot nicer operationally then another binary format...
5. Can we do that without the Thread.sleeps? For example it would seem this would be accomplished by not using a time based flush interval. Also
9. Can you add that facility then to KafkaScheduler? Use Thread.setName() with a wrapper runnable. I think making lots of single-threaded thread pools is too hacky.

Also
- FileChannel.truncateTo sets the size to whatever is given and calls truncate, it would be good to be a little more defensive. If the offset given is larger than size we should handle that gracefully (throw illegalargumentexception or something). Currently it would call truncate() on the filechannel which would have no effect but it would set the size to the new size which would not match the size of the file, which might cause odd things to happen.
- HighwaterMarkCheckpoint.scala: new RandomAccessFile(path + ""/"" + HighwaterMarkCheckpoint.highWatermarkFileName. Should use new File(path, filename) for portability.
- Can you mark any method not in the public interface for ReplicaManager as private? It is currently really hard to tell what the capabilities it provides...
;;;","24/Jul/12 00:09;jkreps;Also, ReplicaManager:

This class has a very odd public interface. Instead of managing replicas it has a bunch of passive calls--addLocalReplica(), addRemoteReplica(), etc. Who calls these? KafkaServer seems to have its own wrapper for these. Then it passes these methods on as arguments to KafkaZookeeper. Does this make sense? I think it would be good if ReplicaManager handled replica management, even if that means it depends on zookeeper.

;;;","24/Jul/12 09:30;junrao;Thanks for patch v2. Some comments:
20. Log.truncateTo(): The following code seems to be used just for getting the first segment. Can we just use segmentToBeTruncated(0)?
      segmentToBeTruncated match {
        case Some(segment) =>
          val truncatedSegmentIndex = segments.view.indexOf(segment)
          segments.truncLast(truncatedSegmentIndex)
        case None =>
      }

21. FileMessageSet: Do we need setHighWaterMark? It seems it's always the same as setSize.

22. ReplicaManager:
22.1 recordLeaderLogUpdate(): Could we rename it to recordLeaderLogEndOffset()?
22.2 close(): Could we rename it to shutdown to map startup()?
22.3 readCheckpointedHighWatermark(): We should just read the HW from memory. The on-disk version is only useful on broker startup when we populate the in-memory HW using the on disk version.

23. HighwaterMarkCheckpoint: Is it better to name the file "".highwaterMark"" so that it's hidden?
;;;","26/Jul/12 04:09;nehanarkhede;Jay's comments

4. Changed the write operation for highwatermark file to be atomic.
5. The sleep is in place to allow the follower to send another fetch request to the leader to allow the leader to tell it the latest leader high watermark. It cannot be fixed by flushing more frequently

9. Added the ability to set the name of a thread in KafkaScheduler. Also, saw that the KafkaScheduler took in a isDaemon variable, but didn't really use it. Refactored KafkaScheduler to create daemon/non-daemon threads with different names.

10. There was an assertion that protects against this in the only API that called FileMessageSet.truncateTo. Moved that to FileMessageSet instead and changed it to throw KafkaException. Also, handled all exceptions in the become follower/become leader state change API to log an error stating that the state change failed. This will make debugging easier.

11. Have marked methods not in the public interface for ReplicaManager as private? Agree that there is some room for refactoring. Added your suggestion to KAFKA-351 that we have filed to cover the refactoring of ReplicaManager and KafkaZookeeper. Currently, with the controller patch, KafkaZookeeper is going to look very different. So I'd rather wait until controller patch is in.

Jun's comments

20. There will only be one segment that will fit this criteria => segment.start >= hw && segment.endOffset < hw. That code truncates the one and only segment that matches this criteria

21. The setHighwatermark variable and its references are deleted as part of KAFKA-350

22. 
1. Changed to recordLeaderLogEndOffset()
2. Changed close() to shutdown() for LogManager, ReplicaManager and KafkaZookeeper
3. Good point. Fixed it to read from the file only on startup

23. Yes, it might be ok to have the file hidden.

Other fixes -

Log.scala
1. truncateTo() had bugs in that it used the size() API on the FileMessageSet of the segment to get the absolute end offset. Fixed it to use the absoluteEndOffset() API of LogSegment instead.
;;;","26/Jul/12 07:10;jkreps;+1 ;;;","26/Jul/12 07:29;nehanarkhede;Removed the sleeps in LogRecoveryTest. Will probably checkin this version of the patch;;;","26/Jul/12 07:42;nehanarkhede;Thanks a lot for the timely reviews ! Checked in v4 ;;;","02/Aug/12 02:10;junrao;Just had a look of v4. A couple of minor comments:

40. HighwaterMarkCheckpoint:
40.1 If tempHwFile already exists, we can just overwrite it since we know hwFile is always safe.
40.2 There is no need to delete hwFile first and then rename tempHwFile to it. Rename should do the deletion. Currently, if we fail at the bad time, we could end up without a hwFile.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Crash during log recovery can cause full recovery to never run,KAFKA-980,12658612,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,blakesmith,blakesmith,19/Jul/13 03:20,08/Sep/17 01:59,22/Mar/23 15:10,08/Sep/17 01:59,0.7.1,,,,,,,,,,,,,,,,,0,,,,,,"After an unclean shutdown of the Kafka server, if the broker throws an unhandled exception during log recovery, the broker can get in a state where recovery never runs on a log file.

We saw this problem manifest in production and is summarized on the mailing list here: http://mail-archives.apache.org/mod_mbox/kafka-users/201307.mbox/%3CCAKSpikjgp2sW2ycuf86JrjtAPxWBp92OOEmigVed=u=JFoPvTA@mail.gmail.com%3E

Because recovery state is not tracked explicitly, our kafka broker started writing data even when the log files were not fully recovered. It feels to me like a separate state flag for recovery should also be tracked in cases where recovery does not fully run. What do you guys think?

Steps to reproduce:

1. Shutdown the kafka broker
2. Create a directory named 'bogus' under the kafka log directory (won't parse since it has no partition number)
3. Remove .kafka_cleanshutdown from the log directory to force a recovery
4. Start the kafka broker, observe:
    - Recovery will run on partition segments until it reaches the bogus directory
    - Exception will be thrown during log loading from the bogus directory
    - Kafka will initiate a clean shutdown after the exception is thrown
5. Once the Kafka server is cleanly shutdown, start it again, observe:
    - Recovery will not try to run, since kafka was shutdown cleanly
    - Some partition log files have never been recovered
6. Remove the bogus log directory
7. Start Kafka broker, observe:
    - Recovery will not run
    - Kafka will start cleanly and begin accepting writes again, even though recovery has never run and logs might be in a corrupt state
",,blakesmith,jkreps,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,338806,,,Thu Jul 18 23:33:06 UTC 2013,,,,,,,,,,"0|i1mfr3:",339126,,,,,,,,,,,,,,,,,,,,"19/Jul/13 04:10;jkreps;Yeah this is a bug. You put down that it effects 0.8, where you able to reproduce it on 0.8?;;;","19/Jul/13 07:33;blakesmith;My mistake, I was not able to repro on 0.8 - it looks like the CleanShutdown logic was moved into the LogManager itself, which will be null if startup failed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rename ZkConfig properties,KAFKA-871,12644034,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,swapnilghike,swapnilghike,swapnilghike,23/Apr/13 09:31,26/Apr/13 09:58,22/Mar/23 15:10,26/Apr/13 09:58,,,,,,,0.8.0,,,,,,,,,,,0,kafka-0.8,p1,,,,For clarity. Renaming these properties should help in migration from 0.7 to 0.8.,,jfung,junrao,swapnilghike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Apr/13 09:33;swapnilghike;kafka-871-v1.patch;https://issues.apache.org/jira/secure/attachment/12579956/kafka-871-v1.patch","24/Apr/13 09:39;swapnilghike;kafka-871-v2.patch;https://issues.apache.org/jira/secure/attachment/12580210/kafka-871-v2.patch","25/Apr/13 10:39;swapnilghike;kafka-871-v3.patch;https://issues.apache.org/jira/secure/attachment/12580454/kafka-871-v3.patch","26/Apr/13 07:02;swapnilghike;kafka-871-v4.patch;https://issues.apache.org/jira/secure/attachment/12580611/kafka-871-v4.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,324401,,,Fri Apr 26 01:58:30 UTC 2013,,,,,,,,,,"0|i1jyvb:",324746,,,,,,,,,,,,,,,,,,,,"23/Apr/13 09:33;swapnilghike;Unit tests pass.;;;","23/Apr/13 09:33;swapnilghike;[~jfung]: Could you take a look at this patch? Since it touches a lot of the system test files.;;;","24/Apr/13 01:05;junrao;Thanks for the patch. For clarity, should we rename broker.list in ProducerConfig to sth like bootstrap.broker.list? In 0.8, broker.list is only used by the metadata request for bootstrapping, not for the actual produce requests.;;;","24/Apr/13 02:23;swapnilghike;How about using metadata.broker.list or metadata.brokers? ;;;","24/Apr/13 02:31;junrao;metadata.broker.list is fine.;;;","24/Apr/13 02:45;jfung;Hi Swapnil,

In system_test/migration_tool_testsuite, the source cluster are running in 0.7. It is necessary to distinguish between 0.7 & 0.8 config in the testcase_xxxx_properties.json file. Let's walk through the changes needed.;;;","24/Apr/13 09:39;swapnilghike;Renamed broker.list to metadata.broker.list. 

Discussed the system test changes with John, they are included in this patch. Unfortunately I could not run the sanity test locally, because it kept prompting for password. I will work with John tomorrow to solve this issue. 

As a by product of the discussion with John, we have filed KAFKA-874 and KAFKA-875.

Testing: All unit tests pass.;;;","24/Apr/13 14:20;swapnilghike;We should hold off checking this patch in until we have verified that the system test works. I will also include a little JSON parsing related bug fix in v3.;;;","24/Apr/13 23:53;junrao;Some comments on patch v2. There are a few places that we changed ""--brokerinfo broker.list"" or ""--brokerinfo zk.connect"" in the 0.7 kafka.perf.ProducerPerformance to use the new 0.8 property name (the ""--brokerinfo"" option is only available in 0.7). These include
system_test/producer_perf/bin/run-compression-test.sh
system_test/producer_perf/bin/run-test.sh
system_test/broker_failure/bin/run-test.sh
system_test/mirror_maker/bin/run-test.sh 

It's weird that we include the 0.7 ProducerPerformance in system_test/broker_failure/bin/run-test.sh and system_test/mirror_maker/bin/run-test.sh since they are supposed to only test 0.8.;;;","25/Apr/13 01:18;swapnilghike;According to [~jfung], anything under system_test that does not have ""_testsuite"" at the end is not being used currently. So, I did not take the pains to clean up the changes that you mentioned, I believe those directories should be deleted as part of KAFKA-875 anyways.;;;","25/Apr/13 01:18;swapnilghike;I will exclude them from v3 to reduce the noise in the patch.;;;","25/Apr/13 01:45;jfung;The following are older system testing scripts in bash before system test is ported to Python. It is probably safe to be removed from the branch to avoid confusion.

1. system_test/broker_failure
2. system_test/mirror_maker  (NOT mirror_maker_testsuite)
3. system_test/producer_perf
4. system_test/common;;;","25/Apr/13 10:38;swapnilghike;1. Removed the aforementioned noise from patch v3.
2. The additional interesting change is a one character fix to JSON parsing in seqToJson in Utils.scala. We were not building the comma separated string correctly earlier, and this bug was not exposed because that particular condition was not exercised.
3. Added zookeeper.connect and zookeeper.connection.timeout.ms to migration_tool_testsuite/config/server.properties, because we are currently using only 1 server.properties file for both kafka 0.7 and 0.8 brokers. KAFKA-874 will create two separate config files for 0.7 and 0.8 brokers.

Testing:
1. Unit tests pass.
2. As [~jfung] suggested, tested migration tool test case 9001. It passed:

_test_case_name  :  testcase_9001
_test_class_name  :  MigrationToolTest
arg : bounce_migration_tool  :  false
arg : message_producing_free_time_sec  :  30
arg : num_iteration  :  1
arg : num_messages_to_produce_per_producer_call  :  50
arg : num_partition  :  1
arg : replica_factor  :  3
arg : sleep_seconds_between_producer_calls  :  1
validation_status  : 
     Unique messages from consumer on [test_1]  :  0
     Unique messages from producer on [test_1]  :  0

Total failures count : 0

;;;","26/Apr/13 00:47;junrao;Thanks for patch v3. Looks good. The following config is weird. It seems to be an 0.7 producer config. However, in 0.7, the broker list format is brokerid:host:port. Is it still being used?

./system_test/migration_tool_testsuite/config/migration_producer.properties:broker.list=localhost:9094,localhost:9095,localhost:9096
;;;","26/Apr/13 01:15;jfung;[~swapnilghike] : The test result is showing 0 messages for both producer & consumer. There may be some settings which are configured incorrectly.

[~junrao] : The broker.list property line is also used in the Hudson nightly job.;;;","26/Apr/13 07:02;swapnilghike;Attached patch v4. 

I think v4 fixes the system test. Ran 3 test cases according to [~jfung]'s advice:

_test_case_name  :  testcase_5001
_test_class_name  :  MirrorMakerTest
arg : bounce_leader  :  false
arg : bounce_mirror_maker  :  false
arg : message_producing_free_time_sec  :  15
arg : num_iteration  :  1
arg : num_messages_to_produce_per_producer_call  :  50
arg : num_partition  :  1
arg : replica_factor  :  3
arg : sleep_seconds_between_producer_calls  :  1
validation_status  :-
     Unique messages from consumer on [test_1]  :  500
     Unique messages from producer on [test_1]  :  500
     Validate for data matched on topic [test_1]  :  PASSED
     Validate for merged log segment checksum in cluster [source]  :  PASSED
     Validate for merged log segment checksum in cluster [target]  :  PASSED

_test_case_name  :  testcase_0001
_test_class_name  :  ReplicaBasicTest
arg : bounce_broker  :  false
arg : broker_type  :  leader
arg : message_producing_free_time_sec  :  15
arg : num_iteration  :  1
arg : num_messages_to_produce_per_producer_call  :  50
arg : num_partition  :  1
arg : replica_factor  :  3
arg : sleep_seconds_between_producer_calls  :  1
validation_status  :-
     Leader Election Latency MAX  :  None
     Leader Election Latency MIN  :  None
     No. of messages from consumer on [test_1] at simple_consumer_test_1-0_r1.log  :  500
     No. of messages from consumer on [test_1] at simple_consumer_test_1-0_r2.log  :  500
     No. of messages from consumer on [test_1] at simple_consumer_test_1-0_r3.log  :  500
     Unique messages from consumer on [test_1]  :  500
     Unique messages from producer on [test_1]  :  500
     Validate for data matched on topic [test_1]  :  PASSED
     Validate for data matched on topic [test_1] across replicas  :  PASSED
     Validate for merged log segment checksum in cluster [source]  :  PASSED
     Validate index log in cluster [source]  :  PASSED

_test_case_name : testcase_9001
_test_class_name : MigrationToolTest
validation_status : 
     Unique messages from consumer on [test_1] : 10500
     Unique messages from producer on [test_1] : 10500

Unit tests pass.
;;;","26/Apr/13 09:58;junrao;Thanks for the patch. Committed to 0.8.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Consumer could make multiple concurrent metadata requests,KAFKA-2129,12821754,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,timbrooks,timbrooks,timbrooks,17/Apr/15 11:17,07/Jul/15 12:30,22/Mar/23 15:10,07/Jul/15 12:30,,,,,,,,,,,,,,clients,,,,0,,,,,,"The NetworkClient's metadataFetchInProgress is neither volatile nor atomic. This protects against multiple metadata requests being made and is read on poll() on the NetworkClient. It is written to when a request is initiated.

This is fine for the producer. Which seems to have one thread writing. The KafkaConsumer's poll()  method is synchronized, so there will not be more than one writer entering from there. However, the NetworkClient's poll() method is also accessed on the Consumer's partitionsFor() method. Which could be access by a separate thread.",,guozhang,timbrooks,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Apr/15 02:12;timbrooks;KAFKA-2129.patch;https://issues.apache.org/jira/secure/attachment/12728861/KAFKA-2129.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jul 07 03:59:14 UTC 2015,,,,,,,,,,"0|i2ddtr:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"29/Apr/15 02:10;timbrooks;It kind of looks like this is a larger issue than maybe I realized when I first opened this ticket. Let's say that thread 1 is calling poll() on the KafkaClient. And then thread 2 calls partionsFor() a topic that is not locally known on the KafkaClient.

Both threads will make it into the poll() method on the Selector since partitionsFor() is not synchronized. If Thread 1 is in the middle of a poll(), tons of intermediate state will be lost when Thread 2 calls the clear() method on the selector:

this.completedSends.clear();
this.completedReceives.clear();
this.connected.clear();
this.disconnected.clear();
this.disconnected.addAll(this.failedSends);
this.failedSends.clear();

I can generate a number of failing integration tests by adding:

scala.concurrent.future {
      Thread.sleep(30)
      consumer.partitionsFor(""weird-topic"")
    }

in consumeRecords() in the ConsumerTest right before the call is made to poll().

If I add the synchronize keyword to the partionsFor() method these errors go away. Is this the correct approach to this ticket? Obviously those errors are an issue since the KafkaConsumer documentation indicates that the class is threadsafe.

But adding synchronize to the method means that calling partitionsFor() will be blocked on a poll() that is in progress. And hopefully, the majority of the time partitionsFor() will not require a network call.

Anyway, I added a patch to synchronize that method. But if the we are interested in a non synchronized method to get locally-known partitions for that topic, we will need a different change.;;;","29/Apr/15 02:12;timbrooks;Created reviewboard https://reviews.apache.org/r/33634/diff/
 against branch origin/trunk;;;","30/Jun/15 10:14;guozhang;[~timbrooks], sorry for the long-late reply to this ticket.. I agree this is a big problem, and someone has attempted to solve it in a large re-factoring way (KAFKA-2168). Could you take a look at that patch and see if it solved your problem or there are some other corner cases?;;;","07/Jul/15 11:59;timbrooks;Since post-2168 it seems to be explicitly documented that the consumer is not thread safe, and every public method (besides wakeup) requires a thread to gain ownership before entering the consumer, this ticket seems to be resolved.

- Tim;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JsonConverter mangles schema during serialization (fromConnectData),KAFKA-3055,12925164,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,ksenji,ksenji,01/Jan/16 09:40,18/May/16 09:37,22/Mar/23 15:10,05/Jan/16 00:48,0.9.0.0,,,,,,0.10.0.0,0.9.0.1,,,,,,KafkaConnect,,,,0,,,,,,"Test case is here: https://github.com/ksenji/kafka-connect-test/tree/master/src/test/java/org/apache/kafka/connect/json

If Caching is disabled, it behaves correctly and JsonConverterWithNoCacheTest runs successfully. Otherwise the test JsonConverterTest fails.

The reason is that the JsonConverter has a bug where it mangles the schema as it assigns all String fields with the same name (and similar for all Int32 fields)

This is how the schema & payload gets serialized for the Person Struct (with caching disabled):
{code}
{""schema"":{""type"":""struct"",""fields"":[{""type"":""string"",""optional"":false,""field"":""firstName""},{""type"":""string"",""optional"":false,""field"":""lastName""},{""type"":""string"",""optional"":false,""field"":""email""},{""type"":""int32"",""optional"":false,""field"":""age""},{""type"":""int32"",""optional"":false,""field"":""weightInKgs""}],""optional"":false,""name"":""Person""},""payload"":{""firstName"":""Eric"",""lastName"":""Cartman"",""email"":""eric.cartman@southpark.com"",""age"":10,""weightInKgs"":40}}
{code}
where as when caching is enabled the same Struct gets serialized as (with caching enabled) :
{code}
{""schema"":{""type"":""struct"",""fields"":[{""type"":""string"",""optional"":false,""field"":""email""},{""type"":""string"",""optional"":false,""field"":""email""},{""type"":""string"",""optional"":false,""field"":""email""},{""type"":""int32"",""optional"":false,""field"":""weightInKgs""},{""type"":""int32"",""optional"":false,""field"":""weightInKgs""}],""optional"":false,""name"":""Person""},""payload"":{""firstName"":""Eric"",""lastName"":""Cartman"",""email"":""eric.cartman@southpark.com"",""age"":10,""weightInKgs"":40}}
{code}
As we can see all String fields became ""email"" and all int32 fields became ""weightInKgs"". 
",,ceposta,ewencp,githubbot,ksenji,vtsarva78@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2884,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed May 18 01:37:44 UTC 2016,,,,,,,,,,"0|i2qfzz:",9223372036854775807,,ewencp,,,,,,,,,,,,,,,,,,"01/Jan/16 10:05;githubbot;GitHub user ksenji opened a pull request:

    https://github.com/apache/kafka/pull/722

    Fix for KAFKA-3055

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ksenji/kafka trunk

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/722.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #722
    
----
commit 60a5b5cecd39ccdd4ff2f977a6bfdef123cadb44
Author: ksenji <ksenji@ebay.com>
Date:   2016-01-01T02:01:44Z

    Fix for KAFKA-3055

----
;;;","01/Jan/16 10:05;ksenji;PR: https://github.com/apache/kafka/pull/722;;;","05/Jan/16 00:48;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/722
;;;","05/Jan/16 00:48;ewencp;Issue resolved by pull request 722
[https://github.com/apache/kafka/pull/722];;;","03/Feb/16 03:49;vtsarva78@gmail.com;Hi Kishore

I am facing this same problem and trying to see if we can handle without
updating the patch fix done already. Can you please let me know how to
disable cache as you mentioned this works fine when cache is disabled.

regards
Saravanan
;;;","09/Feb/16 09:00;ewencp;There's a config schemas.cache.size. Since it's an LRU cache, setting the size to 1 would presumably work.;;;","09/Feb/16 23:16;ksenji;Please look here: https://github.com/ksenji/kafka-connect-test/blob/master/src/test/java/org/apache/kafka/connect/json/JsonConverterWithNoCacheTest.java;;;","18/May/16 09:37;ceposta;the correct config for the worker to change the cache size is 

value.converter.schemas.cache.size

Need to have this fixed before you can use it though: 
https://issues.apache.org/jira/browse/KAFKA-3723;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
System Tests that use bootstrap.servers embedded in jinja files are not working,KAFKA-2915,12917270,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,benstopford,benstopford,01/Dec/15 23:10,02/Dec/15 03:48,22/Mar/23 15:10,02/Dec/15 03:48,,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,Regression due to changes in the way the tests handle security. ,,benstopford,githubbot,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Dec 01 19:48:37 UTC 2015,,,,,,,,,,"0|i2p4bb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"02/Dec/15 02:14;githubbot;GitHub user benstopford opened a pull request:

    https://github.com/apache/kafka/pull/608

    KAFKA-2915: Fix problem with System Tests that use bootstrap.servers embedded in jinja files

    Fixes problems in mirror maker and consumer tests
    http://jenkins.confluent.io/job/kafka_system_tests_branch_builder/290/
    http://jenkins.confluent.io/job/kafka_system_tests_branch_builder/289/

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/benstopford/kafka KAFKA-2915-jinja-bug

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/608.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #608
    
----
commit 640532b7ca10298d545e523e291e6f6fe82843c6
Author: Ben Stopford <benstopford@gmail.com>
Date:   2015-12-01T15:27:46Z

    KAFKA-2915: Added call security protocol to bootstrap servers call in jinja file

commit 192d96c6a53481db5b8dc428f0a2eb6d401862ea
Author: Ben Stopford <benstopford@gmail.com>
Date:   2015-12-01T16:40:56Z

    KAFKA-2915: fixed string formatting

----
;;;","02/Dec/15 03:48;guozhang;Issue resolved by pull request 608
[https://github.com/apache/kafka/pull/608];;;","02/Dec/15 03:48;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/608
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SimpleConsumer swallowing ClosedByInterruptException,KAFKA-1886,12768796,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,aauradkar,auradkar,auradkar,21/Jan/15 05:12,05/May/15 02:55,22/Mar/23 15:10,05/May/15 02:55,,,,,,,,,,,,,,producer ,,,,0,,,,,,"This issue was originally reported by a Samza developer. I've included an exchange of mine with Chris Riccomini. I'm trying to reproduce the problem on my dev setup.

From: criccomi
Hey all,
Samza's BrokerProxy [1] threads appear to be wedging randomly when we try to interrupt its fetcher thread. I noticed that SimpleConsumer.scala catches Throwable in its sendRequest method [2]. I'm wondering: if blockingChannel.send/receive throws a ClosedByInterruptException
when the thread is interrupted, what happens? It looks like sendRequest will catch the exception (which I
think clears the thread's interrupted flag), and then retries the send. If the send succeeds on the retry, I think that the ClosedByInterruptException exception is effectively swallowed, and the BrokerProxy will continue
fetching messages as though its thread was never interrupted.
Am I misunderstanding how things work?
Cheers,
Chris
[1] https://github.com/apache/incubator-samza/blob/master/samza-kafka/src/main/scala/org/apache/samza/system/kafka/BrokerProxy.scala#L126
[2] https://github.com/apache/kafka/blob/0.8.1/core/src/main/scala/kafka/consumer/SimpleConsumer.scala#L75",,aauradkar,auradkar,criccomini,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SAMZA-513,,,,,,,,,,"03/Feb/15 05:42;auradkar;KAFKA-1886.patch;https://issues.apache.org/jira/secure/attachment/12696008/KAFKA-1886.patch","23/Jan/15 06:33;auradkar;KAFKA-1886.patch;https://issues.apache.org/jira/secure/attachment/12694023/KAFKA-1886.patch","03/Feb/15 05:57;auradkar;KAFKA-1886_2015-02-02_13:57:23.patch;https://issues.apache.org/jira/secure/attachment/12696014/KAFKA-1886_2015-02-02_13%3A57%3A23.patch","29/Apr/15 01:27;auradkar;KAFKA-1886_2015-04-28_10:27:39.patch;https://issues.apache.org/jira/secure/attachment/12728847/KAFKA-1886_2015-04-28_10%3A27%3A39.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon May 04 18:55:30 UTC 2015,,,,,,,,,,"0|i24kzz:",9223372036854775807,,nehanarkhede,,,,,,,,,,,,,,,,,,"21/Jan/15 09:15;auradkar;Did a good bit of poking around. Basically, I wrote a test that runs a SimpleConsumer inside a thread and interrupts that thread from the main thread. This forces a ClosedByInterruptException that we catch in the SimpleConsumer:sendRequest method. Catching this exception does not reset the interrupt status of the Thread. The returned exception is a ClosedChannelException and the original exception is swallowed.

I can't spot any bug in Kafka here. I can suggest a couple of improvements:
- Don't retry inside SimpleConsumer if we catch a ClosedByInterruptException. Seems like extra work for nothing.
- Inspect code to check if we are catching InterruptedException somewhere. Based on a cursory inspection, I couldn't find anything.;;;","21/Jan/15 09:16;auradkar;If interested, I hacked an existing test for this.

{code}
def testConsumerEmptyTopic() {
      val newTopic = ""new-topic""
      TestUtils.createTopic(zkClient, newTopic, numPartitions = 1, replicationFactor = 1, servers = servers)
      val thread = new Thread {
        override def run {
          System.out.println(""Starting the fetch"")
          val start = System.currentTimeMillis()
          try
          {
            val fetchResponse = consumer.fetch(new FetchRequestBuilder().minBytes(100000).maxWait(3000).addFetch(newTopic, 0, 0, 10000).build())
          }
          catch {
          case e: Throwable =>{
            val  end = System.currentTimeMillis()
            System.out.println(""Caught exception"" + e + "". Took "" + (end - start));
            System.out.println(""Fetch interrupted "" + Thread.currentThread().isInterrupted)
          }
          }
        }
      }

     thread.start()
      Thread.sleep(1000)
      thread.interrupt()
      thread.join()
      System.out.println(""Ending test"")
  }
{code};;;","22/Jan/15 05:19;auradkar;[~junrao] any thoughts?;;;","22/Jan/15 05:39;criccomini;IMO, the SimpleConsumer should at least throw the proper exception.;;;","23/Jan/15 06:33;auradkar;Created reviewboard https://reviews.apache.org/r/30196/diff/
 against branch origin/trunk;;;","03/Feb/15 05:42;auradkar;Created reviewboard https://reviews.apache.org/r/30527/diff/
 against branch origin/trunk;;;","03/Feb/15 05:57;auradkar;Updated reviewboard https://reviews.apache.org/r/30196/diff/
 against branch origin/trunk;;;","27/Apr/15 01:40;nehanarkhede;[~aauradkar] Took a quick look at your patch again. Are you planning on fixing it so we can merge? Realize that the simple consumer changes are going to matter less as we make more progress on the new consumer.;;;","29/Apr/15 01:27;auradkar;Updated reviewboard https://reviews.apache.org/r/30196/diff/
 against branch origin/trunk;;;","29/Apr/15 01:32;aauradkar;[~nehanarkhede] I've updated the patch. This is a pretty trivial but relatively useful bug fix and for that reason I think we should merge it. Thoughts?;;;","05/May/15 02:55;nehanarkhede;Thanks, pushed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix UncheckedOffset.removeOffset synchronization and trace logging issue in mirror maker,KAFKA-2009,12780282,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,becket_qin,becket_qin,08/Mar/15 03:04,12/Mar/15 12:00,22/Mar/23 15:10,09/Mar/15 06:15,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,This ticket is to fix the mirror maker problem on current trunk which is introduced in KAFKA-1650.,,becket_qin,jkreps,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Mar/15 03:09;becket_qin;KAFKA-2009.patch;https://issues.apache.org/jira/secure/attachment/12703256/KAFKA-2009.patch","12/Mar/15 02:27;becket_qin;KAFKA-2009_2015-03-11_11:26:57.patch;https://issues.apache.org/jira/secure/attachment/12703984/KAFKA-2009_2015-03-11_11%3A26%3A57.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Mar 11 18:30:31 UTC 2015,,,,,,,,,,"0|i26hgn:",9223372036854775807,,jkreps,,,,,,,,,,,,,,,,,,"08/Mar/15 03:09;becket_qin;Created reviewboard https://reviews.apache.org/r/31830/diff/
 against branch origin/trunk;;;","09/Mar/15 06:15;jkreps;Committed, thanks!;;;","12/Mar/15 02:27;becket_qin;Updated reviewboard https://reviews.apache.org/r/31830/diff/
 against branch origin/trunk;;;","12/Mar/15 02:30;becket_qin;Just submitted another small fix patch.
I just realized that I still need to add unacked offset into unacked offsets list before calling producer.send(), because the callback can also be fired in producer.send().
The reason I added the unacked offset after calling producer.send() was that I'm worrying that if something wrong in producer.send() occurs, the offset would never be removed, but since we exiting on any exception in producer thread, it might not cause further problem as the entire mirror maker will exit.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FileRecords.read doesn't handle size > sizeInBytes when start is not zero,KAFKA-2903,12916701,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,pengwei,pengwei,28/Nov/15 09:27,31/Oct/17 02:09,22/Mar/23 15:10,31/Oct/17 02:08,0.10.2.0,0.11.0.0,1.0.0,,,,1.1.0,,,,,,,log,,,,0,,,,,,"now the code is :
def read(position: Int, size: Int): FileMessageSet = {
   ..... 
    new FileMessageSet(file,
                       channel,
                       start = this.start + position,
                       end = math.min(this.start + position + size, sizeInBytes()))
  }

if this.start is not 0, the end is only the FileMessageSet's size, not the actually position of end position.
the end parameter should be:
 end = math.min(this.start + position + size, this.start+sizeInBytes())

*Update* Problem still remains in FileRecords.",,githubbot,hachikuji,junrao,pengwei,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Oct 30 18:09:27 UTC 2017,,,,,,,,,,"0|i2p0sv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"08/Dec/15 13:18;junrao;Yes, the current logic is a bit confusing, but is correct. We create a FileMessageSet in two cases. The first case is when we create a LogSegment. In this case, FileMessageSet.start is always 0. The second case is when we want to generate a response to the fetch request. In this case, we are getting a slice from the FileMessageSet created in case one, which always has FileMessageSet.start as 0. That's why the code works. We never had a case that we need to create a slice from a FileMessageSet created in case (2). To make the code easier to understand, perhaps we can just get rid of this.start all together when calculating end. It would also be good to add a comment above FileMessageSet to make this clear. Do you want to submit a patch?;;;","08/Dec/15 16:16;pengwei;Yes we can also add comment on it. 
But if in the future version, someone need to use this read API will get error when using a slice  FileMessageSet.  so modify this code is better?
Because it is only one line of code, and add comment will use much word on it;;;","10/Dec/15 00:40;junrao;Yes, I think that will be fine too.;;;","30/Oct/17 19:45;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/4158

    KAFKA-2903: FileRecords.read doesn't handle size > sizeInBytes when start is not zero

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-2903-file-records-read-slice-size-greater

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/4158.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #4158
    
----
commit b251038e2c569fda88376b85918a5003927b8152
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2017-10-30T11:45:00Z

    KAFKA-2903: FileRecords.read doesn't handle size > sizeInBytes when start is not zero

----
;;;","31/Oct/17 02:08;hachikuji;Issue resolved by pull request 4158
[https://github.com/apache/kafka/pull/4158];;;","31/Oct/17 02:09;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/4158
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Using GetOffsetShell against non-existent topic creates the topic unintentionally,KAFKA-1507,12723388,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,sriharsha,lukeforehand,lukeforehand,24/Jun/14 23:50,16/Jun/18 01:40,22/Mar/23 15:10,16/Jun/18 01:40,0.8.1.1,,,,,,,,,,,,,,,,,1,newbie,,,,,"A typo in using GetOffsetShell command can cause a
topic to be created which cannot be deleted (because deletion is still in
progress)

./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list
kafka10:9092,kafka11:9092,kafka12:9092,kafka13:9092 --topic typo --time 1

./kafka-topics.sh --zookeeper stormqa1/kafka-prod --describe --topic typo
Topic:typo      PartitionCount:8        ReplicationFactor:1     Configs:
         Topic: typo     Partition: 0    Leader: 10      Replicas: 10
  Isr: 10
...",centos,abraithwaite,bobrik,fullung,gwenshap,jbrosenberg@gmail.com,jkreps,jozi-k,junrao,lukeforehand,nehanarkhede,omkreddy,rmchale,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2410,,,,,,,,,,,,,,,,KAFKA-1462,,"13/Aug/14 08:05;sriharsha;KAFKA-1507.patch;https://issues.apache.org/jira/secure/attachment/12661346/KAFKA-1507.patch","09/Jul/14 00:21;sriharsha;KAFKA-1507.patch;https://issues.apache.org/jira/secure/attachment/12654607/KAFKA-1507.patch","23/Jul/14 01:28;sriharsha;KAFKA-1507_2014-07-22_10:27:45.patch;https://issues.apache.org/jira/secure/attachment/12657145/KAFKA-1507_2014-07-22_10%3A27%3A45.patch","24/Jul/14 08:07;sriharsha;KAFKA-1507_2014-07-23_17:07:20.patch;https://issues.apache.org/jira/secure/attachment/12657495/KAFKA-1507_2014-07-23_17%3A07%3A20.patch","13/Aug/14 09:09;sriharsha;KAFKA-1507_2014-08-12_18:09:06.patch;https://issues.apache.org/jira/secure/attachment/12661360/KAFKA-1507_2014-08-12_18%3A09%3A06.patch","23/Aug/14 02:06;sriharsha;KAFKA-1507_2014-08-22_11:06:38.patch;https://issues.apache.org/jira/secure/attachment/12663702/KAFKA-1507_2014-08-22_11%3A06%3A38.patch","23/Aug/14 02:09;sriharsha;KAFKA-1507_2014-08-22_11:08:51.patch;https://issues.apache.org/jira/secure/attachment/12663703/KAFKA-1507_2014-08-22_11%3A08%3A51.patch",,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,401575,,,Fri Jun 15 17:40:11 UTC 2018,,,,,,,,,,"0|i1x4ev:",401648,,jkreps,,,,,,,,,,,,,,,,,,"27/Jun/14 09:38;sriharsha; [~nehanarkhede] this is the side effect of auto.create.topics.enable set to true by default.
KafkaApis.handleTopicMetadataRequest checks for above config and creates a topic. Do we need to create a topic in TopicMetadataRequest. I don't see anywhere else we are using this but I am not sure if any other outside lib using this api to create a topic.;;;","03/Jul/14 00:11;junrao;Both the produce and the consumer client will issue TopicMetadataRequest. Topics should probably be only auto-created by the writers, not the readers, i.e., it makes sense for topics to be auto-created by the producers, but not by the consumer or offset reader.

One way to do that is to add a field in TopicMetadataRequest to indicate wether topic should be auto-created or not. This will be a wire protocol change though. So, we will have to support both versions on the broker.;;;","09/Jul/14 00:21;sriharsha;Created reviewboard https://reviews.apache.org/r/23339/diff/
 against branch origin/trunk;;;","10/Jul/14 00:28;junrao;Thanks for the patch. I am currently working on KAFKA-1462, which I hope will standardize how we support multiple versions of a request on the server. Perhaps, you can wait until KAFKA-1462 is done, hopefully in a week or so.;;;","23/Jul/14 01:28;sriharsha;Updated reviewboard https://reviews.apache.org/r/23339/diff/
 against branch origin/trunk;;;","24/Jul/14 08:07;sriharsha;Updated reviewboard https://reviews.apache.org/r/23339/diff/
 against branch origin/trunk;;;","29/Jul/14 08:21;jkreps;I kind of feel this is not the right fix.

I think the behavior we have is kind of indefensible. The history was that we previously had an auto-create topic that happened when a message was sent to a broker and that broker didn't host the topic. However when we moved to replication this broke for multiple reasons: the producer needed metadata about the topic to send the message, and not all brokers would have all partitions. However this ""auto-create"" behavior is very useful. So we kind of just grandfathered it in by having the metadata request have the same side effect.

But this is really a silly indefensible behavior. There is no reason that asking for metadata should create topics! This would be like in a database if running DESCRIBE TABLE X would create table X for you if it didn't exist. This just confuses everyone, as it must have confused you.

In any case the auto-creation behavior is very limited because there is no way to specify the number of partitions, the replication factor, or any topic-specific configuration.

Rather than further enshrining this behavior behavior by starting to add topic creation options to the metadata request, I really think we should add a proper create_topic API and have producers use that.

We could even make this a little more general and handle create, alter, and delete. This would give clients full control.

;;;","29/Jul/14 11:40;junrao;Sriharsha,

After thinking about this a bit more, I agree with Jay's points. So, we probably have to abandon the current approach. Sorry for not realizing this earlier.;;;","31/Jul/14 00:16;sriharsha;[~junrao] [~jkreps] Thanks for the details above. Based on the comments by Jay we should be dropping creation of topics from TopicMetaData request and add createTopicRequest to the api along with topic creation properties such partitions , replication etc. 
And in KafkaProducer.send if the metadatarequest comes out empty we should be making a call to createTopic .
In this case should we also have a boolean flag in KafkaProducer for createTopic . If both producer.createTopic and ""auto.create.topics.enable"" on broker set to true we will create a topic with user supplied config or using the defaults.
I think auto creation of topics config should be on the producer side rather than the broker having it on two places might be confusing. 
Please let me know what you think of the above approach. Thanks.;;;","31/Jul/14 00:40;jkreps;Maybe the best plan would be to retain the option we have for compatibility but default it to off, and have the new producer client make use of the new api.;;;","13/Aug/14 08:05;sriharsha;Created reviewboard https://reviews.apache.org/r/24621/diff/
 against branch origin/trunk;;;","13/Aug/14 08:21;sriharsha;[~jkreps] [~junrao] can you please take a look at the latest patch and let me know your thoughts on the approach. I am working on adding more tests. Thanks;;;","13/Aug/14 09:09;sriharsha;Updated reviewboard https://reviews.apache.org/r/24621/diff/
 against branch origin/trunk;;;","14/Aug/14 07:15;nehanarkhede;Reviewed most of the patch, didn't get a chance to look at the changes in NetworkClient closely and the new request formats. Assigning to [~jkreps] for that part of the review. ;;;","23/Aug/14 02:06;sriharsha;Updated reviewboard https://reviews.apache.org/r/24621/diff/
 against branch origin/trunk;;;","23/Aug/14 02:09;sriharsha;Updated reviewboard https://reviews.apache.org/r/24621/diff/
 against branch origin/trunk;;;","03/Sep/14 00:34;sriharsha;2 weeks ping. [~jkreps] [~junrao] Can you please take a look at this patch. Lot of files changed so hard to keep it merge conflict free :).;;;","08/Sep/14 21:36;sriharsha;[~jkreps] [~junrao] [~guozhang] [~nehanarkhede] Could you please review this patch. Thank you.;;;","16/Sep/14 12:48;junrao;Sriharsha,

Sorry for the late reply. Since this patch introduces a new type of request and is relatively big, perhaps it should wait until the 0.8.2 branch is cut.;;;","16/Sep/14 13:02;sriharsha;Thanks [~junrao] sounds good to me.;;;","26/Nov/14 12:38;sriharsha;[~junrao]  I've seen few users request having a create topic ability in producer itself. I can do a up-merge and resend the patch if there is interest in this JIRA.;;;","16/Jan/15 00:32;sriharsha;[~junrao] [~nehanarkhede] Is this JIRA that can be included in 0.8.3 or 0.9.0 . If so I'll do an upmerge and resend the patch. Thanks.;;;","16/Jan/15 00:51;jkreps;I think the right way to do this is have a proper create/delete/alter topic api (which i think is in-flight now). We should make having the get metadata request auto-creating topics optional and disable it by default (e.g. add an option like metadata.requests.auto.create=false). We can retain the auto-create functionality in the producer by having it issue this request in response to errors about a non-existant topic.

I don't think we should change the java api of the producer to expose this (i.e. add a producer.createTopic(name, replication, partitions, etc). Instead I think we should consider a Java admin client that exposes this functionality. This would be where we would expose other operational apis as well. The rationale for this is that creating, deleting, and modifying topics is actually not part of normal application usage so having it directly exposed in the producer is a bit dangerous.

We should definitely do a KIP proposal around this and get the design and API worked out first. I think we could do this in 0.8.3 if you are up to work on it. It would likely depend on some of the changes in KAFKA-1760 so we would want to merge that first.;;;","16/Jan/15 01:51;sriharsha;[~jkreps] thanks for the comments.  
""We should make having the get metadata request auto-creating topics optional and disable it by default (e.g. add an option like metadata.requests.auto.create=false)""
currently meta data request checks for broker config ""auto.create.topics.enable"" . This is disabled in my patch.

""We can retain the auto-create functionality in the producer by having it issue this request in response to errors about a non-existant topic.""
    This is what my current patch does. it sets ""auto.create.topics.enable"" to false on the broker config and when the producer makes TopicMetadataRequest  it returns Unknown_Topic_or_partition.  ProducerConfig has new properties like ""auto.create.topics.enable"" . 
If this property set to true( by default) producer issues a new request for CreateTopicRequest"" upon receiving unknown_topic_or_partition error. which will than issues create topic on broker side with the configured numPartitions and replicationFactor.

""I don't think we should change the java api of the producer to expose this (i.e. add a producer.createTopic(name, replication, partitions, etc). .""

I agree and my patch doesn't change any api of the producer and it doesn't have producer.createTopic but it does introduce createTopicRequest and createTopicResponse.

""Instead I think we should consider a Java admin client that exposes this functionality. This would be where we would expose other operational apis as well. The rationale for this is that creating, deleting, and modifying topics is actually not part of normal application usage so having it directly exposed in the producer is a bit dangerous.""

I am not sure if I understand correctly about the java admin client. We already have AdminUtils , is this about introducing network apis for create/delete/alter topics? . Even in this case I think this patch can be useful as the producer just makes createTopicRequest which I think what you want unless I missed something :). 


;;;","27/Jan/15 02:54;jbrosenberg@gmail.com;I think relegating topic creation to an admin client would be very limitiing.  It's extremely useful to have a self-service system where new applications can just create a new topic on demand (with reasonable defaults), without the need for an admin to come in and prepare topics ahead of a code release (leave that to dba's managing transactional databases!).

I do like the idea of an automatic create topic request from a producer, in response to a topic not found exception, rather than auto-creating topics from meta-data requests (which happens asynchronously and causes the initial meta data request to fail usually!).  Consumers should never create a topic, I should think.;;;","23/Mar/15 23:21;sriharsha;[~jkreps] Since create/update/topic requests are part of KIP-4. Your proposal if the producer is throwing errors like UnknownTopicOrPartition users should catch this error and use AdminClient create a topic?. I still see a benefit of allowing users to pass in their required topic config( partitions, replication etcc) and if there is no topic exists send a createTopicRequest. If this is not desirable as per your suggestion we need to implement AdminClient?. In this case they can use AdminUtils and we should modify the AdminUtils send requests to broker instead of directly sending requests to zookeeper. This will also help KAFKA-1688 as all the create/update/delete requests will go through broker authorizer. Let me know if this what your thinking.;;;","12/Aug/15 06:21;sriharsha;[~jkreps] Since there is interest in the community about moving creation of topics onto client side specifically producer side can this patch be reviewed. There are also other JIRAs filed
https://issues.apache.org/jira/browse/KAFKA-2410 asking for the same feature addressed in the patch here. There is obviously big JIRA to add create topic requests https://issues.apache.org/jira/browse/KAFKA-2229 not sure if this needs to be blocked by that. If there is interest than I can upmerge my patch.;;;","16/Jun/18 01:40;omkreddy;GetOffsetShell to is updated to use java KafkaConsumer. This solves the original problem reported in the JIRA. 

 [https://github.com/apache/kafka/pull/5220];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
controller may not be started when there are multiple ZK session expirations,KAFKA-3215,12937213,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,fpj,junrao,junrao,06/Feb/16 08:22,12/Mar/16 01:47,22/Mar/23 15:10,12/Mar/16 01:47,,,,,,,0.9.0.0,,,,,,,core,,,,0,controller,,,,,"Suppose that broker 1 is the controller and it has 2 consecutive ZK session expirations. In this case, two ZK session expiration events will be fired.

1. When handling the first ZK session expiration event, SessionExpirationListener.handleNewSession() can elect broker 1 itself as the new controller and initialize the states properly.

2. When handling the second ZK session expiration event, SessionExpirationListener.handleNewSession() first calls onControllerResignation(), which will set ReplicaStateMachine.hasStarted to false. It then continues to do controller election in ZookeeperLeaderElector.elect() and try to create the controller node in ZK. This will fail since broker 1 has already registered itself as the controller node in ZK. In this case, we simply ignore the failure to create the controller node since we assume the controller must be in another broker. However, in this case, the controller is broker 1 itself, but the ReplicaStateMachine.hasStarted is still false.
3. Now, if a new broker event is fired, we will be ignoring the event in BrokerChangeListener.handleChildChange since ReplicaStateMachine.hasStarted is false. Now, we are in a situation that a controller is alive, but won't react to any broker change event.",,fpj,ijuma,junrao,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Mar 11 16:03:21 UTC 2016,,,,,,,,,,"0|i2si8v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"11/Mar/16 18:56;fpj;[~junrao] Let me see if I understand this issue correctly.

bq. broker 1 is the controller and it has 2 consecutive ZK session expirations

As I understand it, one possible run that reflects this is the following:

# zkclient creates a session S1
# S1 session expires
# zkclient queues the session expiration event to deliver to the kafka broker
# zkclient creates a new session S2
# S2 expires
# zkclient queues the session expiration for S2 and the event for S1 still hasn't been delivered
# zkclient creates a third session S3
# broker 1 processes the session expiration of S1
# broker 1 successfully elects itself leader/controller in session S3
# broker 1 processes session expiration for S2

After this last step, the broker is messed up because the replica state machine isn't properly initialized. Also, the broker won't give up leadership because the ephemeral has been created in the current session.

I think this was a problem in 0.8.2, but not a problem in 0.9 because we fixed it in KAFKA-1387. With ZKWatchedEphemeral, in the case we get that the znode exists while creating it, we check if the existing znode has the same session owner, in which case the operation returns ok and the controller becomes leader. Does it make sense?;;;","12/Mar/16 00:03;junrao;[~fpj], thanks for the analysis. Yes, it does seems that this issue is fixed in 0.9.0.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Very slow initial high-level consumer startup in low traffic/blocking fetch scenario,KAFKA-1417,12710208,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,smeder,smeder,24/Apr/14 10:44,26/Apr/14 09:21,22/Mar/23 15:10,26/Apr/14 09:21,0.8.0,,,,,,0.8.1,,,,,,,consumer,,,,0,,,,,,"We're seeing very slow startup times when starting a high level consumer in a low traffic/blocking fetch type setup. The example we've come across has a consumer that is set up to use 3 topics and uses a 20s/1 byte fetch timeout. What happens is that the leader finder thread adds partitions one by one and since the offset is not know this causes a call to figure out the offset. This call uses the fetcher threads simple consumer instance and locks around the call. Initially this is not a problem, but as soon as the fetcher thread has some partitions it will start fetching and since this is a low traffic situation the fetch will at least sometimes take up to 20s (again locking around the simple consumer). This leads to behavior like:

# Finder thread adds a partition
# Data thread notices it has partitions to fetch data for, locks the consumer for 20s
# Finder thread tries to add a partition, tries to lock consumer and blocks for 20s
# Rinse, repeat for each partition",,guozhang,junrao,smeder,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,388530,,,Sat Apr 26 01:21:15 UTC 2014,,,,,,,,,,"0|i1uxe7:",388781,,,,,,,,,,,,,,,,,,,,"24/Apr/14 10:45;smeder;The simple, although not the most efficient solution would be to add another simple consumer instance in each fetcher...;;;","24/Apr/14 12:20;junrao;Interesting. The problem is that the leaderFinderThread uses the same SimpleConsumer (used by the fetcher thread) when issuing the OffsetBefore request. We could somehow let them use different SimpleConsumer instances. Not sure if this is the best solution though. 

Also, is there a particular reason that you use a 20s maxwait in the fetch request?;;;","24/Apr/14 12:26;smeder;I think the timeout is somewhat arbitrary, but since we react to any data (1 byte requirement) we don't want to be be doing a whole bunch of unnecessary fetches if there is not data. I'm going to implement the simple second consumer approach and attach a patch.;;;","25/Apr/14 09:12;guozhang;In 0.8.1, the leader finder thread would not add partition one-by-one but in batches. Would this help your case?;;;","25/Apr/14 10:55;smeder;It should, let me take a look at the 0.8.1 code.;;;","26/Apr/14 09:21;smeder;Looks fine in 0.8.1 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The fetch.wait.max.ms is not honored when new log segment rolled for low volume topics.,KAFKA-3003,12922607,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,becket_qin,becket_qin,17/Dec/15 14:20,24/Mar/16 00:57,22/Mar/23 15:10,06/Feb/16 01:07,0.9.0.0,,,,,,0.9.0.1,,,,,,,core,,,,1,,,,,,"The problem we saw can be explained by the example below:

1. Message offset 100 is appended to partition p0, log segment 00000000.log. at time T. After that no message is appended. 
2. This message is replicated, leader replica update its highWatermark.messageOffset=100, highWatermark.segmentBaseOffset=0.
3. At time T + retention.ms, because no message has been appended to current active log segment for retention.ms, the last modified time of the current log segment reaches retention time. 
4. Broker rolls out a new log segment 00000001.log, and deletes the old log segment 00000000.log. The new log segment in this case is empty because there is no message appended. 
5. In Log, the nextOffsetMetadata.segmentBaseOffset will be updated to the new log segment's base offset, but nextOffsetMetadata.messageOffset does not change. so nextOffsetMetadata.messageOffset=1, nextOffsetMetadata.segmentBaseOffset=1.
6. Now a FetchRequest comes and try to fetch from offset 1, fetch.wait.max.ms=1000.
7. In ReplicaManager, because there is no data to return, the fetch request will be put into purgatory. When delayedFetchPurgatory.tryCompleteElseWatch() is called, the DelayedFetch.tryComplete() compares replica.highWatermark and the fetchOffset returned by log.read(), it will see the replica.highWatermark.segmentBaseOffset=0 and fetchOffset.segmentBaseOffset=1. So it will assume the fetch occurs on a later segment and complete the delayed fetch immediately.

In this case, the replica.highWatermark was not updated because the LogOffsetMetadata.preceds() only checks the messageOffset but ignored segmentBaseOffset. The fix is to let LogOffsetMetadata first check the messageOffset then check the segmentBaseOffset. So replica.highWatermark will get updated after the follower fetches from the leader.
",,anthony.roach@gmail.com,becket_qin,githubbot,gnethercutt,guozhang,jonbringhurst,lindong,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Mar 23 16:57:29 UTC 2016,,,,,,,,,,"0|i2q0ov:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"17/Dec/15 14:37;lindong;Great catch!;;;","17/Dec/15 14:53;githubbot;GitHub user becketqin opened a pull request:

    https://github.com/apache/kafka/pull/688

    KAFKA-3003 Update the replica.highWatermark correctly

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/becketqin/kafka KAFKA-3003

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/688.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #688
    
----
commit d3f9edf89ac32f44413edc3d58e227fa2d859ca2
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2015-12-17T06:52:11Z

    KAFKA-3003 Update the replica.highWatermark correctly

----
;;;","06/Feb/16 01:07;guozhang;Issue resolved by pull request 688
[https://github.com/apache/kafka/pull/688];;;","06/Feb/16 01:08;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/688
;;;","23/Mar/16 16:29;wushujames;Would this cause large amounts of interbroker traffic, as the broker's continually fetch from each other and the fetches get completed immediately?;;;","24/Mar/16 00:57;becket_qin;In this particular case, the problem was due to high watermark was not updated correctly. Because high water mark is only used for consumer fetcher, it should not affect replica fetchers.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
java producer may miss an available partition,KAFKA-1984,12777015,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,junrao,junrao,junrao,24/Feb/15 09:35,05/May/15 12:34,22/Mar/23 15:10,25/Feb/15 06:08,0.8.2.0,,,,,,0.8.2.1,,,,,,,producer ,,,,0,,,,,,"In Partitioner, we cycle through each partition to find one whose leader is available. However, since the counter is shared among different caller threads, the logic may not iterate through every partition. The impact is that we could return an unavailable partition to the caller when there are partitions available. If the partition is unavailable for a long time, the producer may block due to bufferpool being full.",,aauradkar,auradkar,junrao,stevenz3wu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/May/15 10:52;auradkar;KAFKA-1984_2015-05-04_19:52:19.patch;https://issues.apache.org/jira/secure/attachment/12730352/KAFKA-1984_2015-05-04_19%3A52%3A19.patch","25/Feb/15 02:16;junrao;kafka-1984.patch;https://issues.apache.org/jira/secure/attachment/12700536/kafka-1984.patch","25/Feb/15 01:43;junrao;kafka-1984.patch;https://issues.apache.org/jira/secure/attachment/12700528/kafka-1984.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue May 05 04:34:47 UTC 2015,,,,,,,,,,"0|i25ycf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"25/Feb/15 01:43;junrao;Created reviewboard https://reviews.apache.org/r/31363/diff/
 against branch origin/trunk;;;","25/Feb/15 01:43;junrao;There are actual two problems.

1. The way that we select an available partition has a bug. We return the index of the partition. However, since partitions are not sorted, the index may not match the actual partition.
for (int i = 0; i < numPartitions; i++) {
    int partition = Utils.abs(counter.getAndIncrement()) % numPartitions;
    if (partitions.get(partition).leader() != null) {
        return partition; --> should be changed to return the actual
2. The way that we use counter in Partitioner may cause an unavailable partition to be selected when there are concurrent threads producing data to the same producer instance.

Attaching a patch.;;;","25/Feb/15 02:16;junrao;Created reviewboard https://reviews.apache.org/r/31367/diff/
 against branch origin/0.8.2;;;","25/Feb/15 02:16;junrao;Attaching a fix for 0.8.2 too.;;;","25/Feb/15 05:46;junrao;Marking this a blocker for 0.8.2.1 since it affects the use case where replication factor is 1.;;;","25/Feb/15 06:08;junrao;Thanks for the reviews. Committed to 0.8.2 and trunk.;;;","05/May/15 10:52;auradkar;Updated reviewboard https://reviews.apache.org/r/33049/diff/
 against branch origin/trunk;;;","05/May/15 12:05;junrao;[~auradkar], did you attach the patch to the wrong jira? This one is already resolved.;;;","05/May/15 12:34;aauradkar;[~junrao] My bad.. I attached to 1984 instead of 2084.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
consumer sometimes don't release partition ownership properly in ZK during rebalance,KAFKA-286,12544143,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,26/Feb/12 06:59,28/Feb/12 03:52,22/Mar/23 15:10,28/Feb/12 03:52,,,,,,,0.7.1,,,,,,,core,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Feb/12 07:01;junrao;kafka-286.patch;https://issues.apache.org/jira/secure/attachment/12516069/kafka-286.patch","27/Feb/12 23:57;junrao;kafka-286_v2.patch;https://issues.apache.org/jira/secure/attachment/12516172/kafka-286_v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,229380,,,Mon Feb 27 19:52:35 UTC 2012,,,,,,,,,,"0|i0l41b:",121304,,,,,,,,,,,,,,,,,,,,"26/Feb/12 07:01;junrao;Patch attached.;;;","27/Feb/12 13:40;nehanarkhede;Wondering if the patch can get the consumer into the following state -

Say, there are 2 consumers in a group, c1 and c2. Both are consuming topic1 with partitions 0-0, 0-1 and 1-0. Say c1 owns 0-0 and 0-1 and c2 owns 1-0. 

1. Broker 1 goes down. This triggers rebalancing attempt in c1 and c2. 
2. c1 releases partition ownership, but fails to rebalance. 
3. Meanwhile, c2 completes rebalancing successfully, and owns partition 0-1 and starts consuming data. 
4. c1 starts next rebalancing attempt and it releases partition 0-1 (since 0-1 is still part of topicRegistry). It owns partition 0-0 again, and starts consuming data. 
5. Effectively, rebalancing has completed successfully, but there is no owner for partition 0-1 registered in Zookeeper. 

I think using the topicRegistry cache is dangerous, since it has to be in sync with the ownership information in zookeeper. How about reading the ownership information from ZK along with the other data and only release that ?
;;;","27/Feb/12 23:57;junrao;That's a good point. What can happen is that we may delete ZK paths that c1 didn't successfully own in step 2, if rebalance fails. Added patch v2 that deletes all temporarily owned ZK paths in reflectPartitionOwnershipDecision, if we can't own everything. I think this fix addresses this issue.;;;","28/Feb/12 02:29;nehanarkhede;That's a good change and will handle the majority of failure cases. There is another failure case, I think still needs to be fixed in the rebalancing -

Say, for the above mentioned scenario, c1 fails to rebalance due to some error/exception that exercises this code path -

          try {
            done = rebalance(cluster)
          }
          catch {
            case e =>
              /** occasionally, we may hit a ZK exception because the ZK state is changing while we are iterating.
               * For example, a ZK node can disappear between the time we get all children and the time we try to get
               * the value of a child. Just let this go since another rebalance will be triggered.
               **/
              info(""exception during rebalance "", e)
          }

After this, c1 only closes its fetcher queues and backs off (0-0 and 0-1 are already released), while c2 owns 0-1.
Then during step 4 above, c1 releases things from its topic registry again which contains 0-0 and 0-1. So it releases 0-1, which it does not own anymore

;;;","28/Feb/12 02:44;junrao;Will this happen? It doesn't seem possible to me. In step 2, when we release 0-0 and 0-1 during rebalance, we clear topicRegistry. Since this rebalance fails, topicRegistry will not be populated. So, in step 4, there is nothing to release for c1.;;;","28/Feb/12 03:02;nehanarkhede;Yes, missed the fact that after releasing the partitions, it also gets deleted from the passed in topic registry. Looks good now, we will have to be careful about keeping this topic registry cache in sync at all times though. I like the idea of refreshing the cache from ZK during each rebalance attempt, but we can look into that later. 

+1 on v2.;;;","28/Feb/12 03:52;junrao;Thanks for the review. Just committed this to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(new) system tests: ConsoleConsumerService occasionally fails to register consumed message,KAFKA-2408,12852344,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granders,granders,granders,06/Aug/15 02:57,12/Aug/15 06:23,22/Mar/23 15:10,12/Aug/15 06:23,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"There have been a few spurious failures in ReplicationTest.test_hard_bounce, where it was reported that a few of the acked messages were not consumed.

Checking the logs, however, it is clear that they were consumed, but ConsoleConsumerService failed to parse.

Lines causing parsing failure looks something like:

779725[2015-08-03 07:25:47,757] ERROR [ConsumerFetcherThread-console-consumer-78957_ip-172-31-5-20-1438586715191-249db71c-0-1], Error for partition [test_topic,0] to broker 1:class kafka.common.NotLeaderForPartitionException (kafka.consumer.ConsumerFetcherThread)

(i.e. the consumed message, and a log message appear on the same line)

ConsoleConsumerService simply tries to strip each line of whitespace and parse as an integer, which will clearly fail in this case.

Solution should either redirect stderr elsewhere or update parsing to handle this.",,githubbot,granders,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Aug 11 22:23:50 UTC 2015,,,,,,,,,,"0|i2idq7:",9223372036854775807,,ewencp,,,,,,,,,,,,,,,,,,"07/Aug/15 14:43;githubbot;GitHub user granders opened a pull request:

    https://github.com/apache/kafka/pull/123

    KAFKA-2408 ConsoleConsumerService direct log output to file

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/confluentinc/kafka KAFKA-2408

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/123.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #123
    
----
commit 521a84b6d529d7f97cbb0e4cd099efdc5b88fe13
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-08-07T01:36:26Z

    Updated console consumer to directo log output directly to file rather than stdout

commit 8f890441aa755e3d79886b9d72bb572d3aa16fbd
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-08-07T02:44:49Z

    Added another lifecycle check. Wait for log file to exist before exmaning contents.

commit af67e01bf0a114701117b069cfde0ba44a43c75c
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-08-07T06:08:55Z

    Merged in upstream trunk

commit e67f55423b8da89ec8592fae314e59bd21e585ee
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-08-07T06:25:53Z

    Changed incorrect license header

commit 66d6f4f2dc37e1d7f3dc348c1e4e2651a3fceaa1
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-08-07T06:40:38Z

    lower -> uperrcase constants

----
;;;","12/Aug/15 06:23;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/123
;;;","12/Aug/15 06:23;guozhang;Issue resolved by pull request 123
[https://github.com/apache/kafka/pull/123];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Missing required configuration ""value.deserializer"" when initializing a KafkaConsumer with a valid ""valueDeserializer""",KAFKA-3134,12933426,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,yying1,yying1,23/Jan/16 03:07,24/Jan/16 17:56,22/Mar/23 15:10,24/Jan/16 17:56,0.9.0.0,,,,,,0.10.0.0,0.9.0.1,,,,,,,,,,0,,,,,,"I tried to initialize a KafkaConsumer object using with a null keyDeserializer and a non-null valueDeserializer:
{code}
public KafkaConsumer(Properties properties, Deserializer<K> keyDeserializer,
                         Deserializer<V> valueDeserializer)
{code}

Then I got an exception as follows:
{code}
Caused by: org.apache.kafka.common.config.ConfigException: Missing required configuration ""value.deserializer"" which has no default value.
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:148)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:49)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:56)
	at org.apache.kafka.clients.consumer.ConsumerConfig.<init>(ConsumerConfig.java:336)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:518)
	.....
{code}

Then I went to ConsumerConfig.java file and found this block of code causing the problem:
{code}
public static Map<String, Object> addDeserializerToConfig(Map<String, Object> configs,
                                                              Deserializer<?> keyDeserializer,
                                                              Deserializer<?> valueDeserializer) {
        Map<String, Object> newConfigs = new HashMap<String, Object>();
        newConfigs.putAll(configs);
        if (keyDeserializer != null)
            newConfigs.put(KEY_DESERIALIZER_CLASS_CONFIG, keyDeserializer.getClass());
        if (keyDeserializer != null)
            newConfigs.put(VALUE_DESERIALIZER_CLASS_CONFIG, valueDeserializer.getClass());
        return newConfigs;
    }

    public static Properties addDeserializerToConfig(Properties properties,
                                                     Deserializer<?> keyDeserializer,
                                                     Deserializer<?> valueDeserializer) {
        Properties newProperties = new Properties();
        newProperties.putAll(properties);
        if (keyDeserializer != null)
            newProperties.put(KEY_DESERIALIZER_CLASS_CONFIG, keyDeserializer.getClass().getName());
        if (keyDeserializer != null)
            newProperties.put(VALUE_DESERIALIZER_CLASS_CONFIG, valueDeserializer.getClass().getName());
        return newProperties;
    }
{code}

Instead of checking valueDeserializer, the code checks keyDeserializer every time. So when keyDeserializer is null but valueDeserializer is not, the valueDeserializer property will never get set. 
",,ewencp,githubbot,yying1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Jan 24 09:56:12 UTC 2016,,,,,,,,,,"0|i2ruxr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"23/Jan/16 03:25;githubbot;GitHub user happymap opened a pull request:

    https://github.com/apache/kafka/pull/803

    KAFKA-3134: Fix missing value.deserializer error during KafkaConsumer…

    … initialization

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/happymap/kafka KAFKA-3134

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/803.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #803
    
----
commit 1afc67d4d944486dc8fb6361922a7e7a8b573ad5
Author: Yifan Ying <yying@fitbit.com>
Date:   2016-01-22T19:24:02Z

    KAFKA-3134: Fix missing value.deserializer error during KafkaConsumer initialization

----
;;;","24/Jan/16 17:56;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/803
;;;","24/Jan/16 17:56;ewencp;Issue resolved by pull request 803
[https://github.com/apache/kafka/pull/803];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Implement optional ""long poll"" support in fetch request",KAFKA-48,12514685,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,junrao,,20/Jul/11 05:32,01/May/12 05:42,22/Mar/23 15:10,01/May/12 05:42,,,,,,,,,,,,,,,,,,0,,,,,,"Currently, the fetch request is non-blocking. If there is nothing on the broker for the consumer to retrieve, the broker simply returns an empty set to the consumer. This can be inefficient, if you want to ensure low-latency because you keep polling over and over. We should make a blocking version of the fetch request so that the fetch request is not returned until the broker has at least one message for the fetcher or some timeout passes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-202,,KAFKA-50,,,,,,,,,,,,,,,,,,,,,,,,"05/Apr/12 02:29;jkreps;KAFKA-48-v2.patch;https://issues.apache.org/jira/secure/attachment/12521353/KAFKA-48-v2.patch","05/Apr/12 02:39;jkreps;KAFKA-48-v3.patch;https://issues.apache.org/jira/secure/attachment/12521358/KAFKA-48-v3.patch","10/Apr/12 04:35;jkreps;KAFKA-48-v4.patch;https://issues.apache.org/jira/secure/attachment/12522016/KAFKA-48-v4.patch","04/Feb/12 06:49;jkreps;KAFKA-48.patch;https://issues.apache.org/jira/secure/attachment/12513197/KAFKA-48.patch","10/Apr/12 04:37;jkreps;kafka-48-v3-to-v4-changes.diff;https://issues.apache.org/jira/secure/attachment/12522017/kafka-48-v3-to-v4-changes.diff",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,63278,,,Mon Apr 30 21:42:45 UTC 2012,,,,,,,,,,"0|i0l46f:",121327,,,,,,,,,,,,,,,,,,,,"15/Aug/11 06:01;jkreps;This latency issue is important for replication because the latency for the producer will now depend on the replication (fetching) on the followers. This means our current polling mechanism is not going to be good, because we have to either back off for a period of time to avoid busy waiting on the server. In addition with replication we need a similar ability to process requests asynchronously--we do not want to block any threads while waiting for acks from followers. This also breaks our simple request/response model.

This is also important for the streaming use cases as they involve a large number of stacked topics, and hence the end-to-end latency is a multiple of the single-hop consumer latency.

Fixing this is slightly tricky.

The first thing I think we would need to do is move the execution of request handling out of the socket server threads. This would generally be a good thing to do anyway, as I/O currently blocks request handling for all sockets sharing a thread. This can add unnecessary latency.

The design for this could be a request BlockingQueue that the SocketServer submits all requests to, and N response BlockingQueues, one for each socket thread. The request processing would happen in a separate threadpool that would feed off the request queue and send responses back to the response queue. For asynchronous requests, no response need be enqueued.

The request handling would now be an ExecutorService with a fixed number of processes. Each process would poll the request queue, process any request it gets, and send back responses.

Long poll requests from fetchers would either be handled immediately, or, if there is no available data, would add themselves to a list of watchers on the topic. When a request comes in on that topic, it would and responses for all watchers. The request would specify a max timeout after which the request would return empty, this could be implemented with a DelayQueue that was checked periodically for expired requests. A generalization of this would be to have the fetch request provide not only a max_wait_time but also a min_data_size, which would make the request block until the given number of bytes of data have accumulated. This would actually enable the opposite of simple long poll--instead of trying to minimize latency the fetcher would be able to ensure they got a good size chunk of data on each request to ensure good throughput and avoid lots of little requests each fetching only a few small messages.

A similar mechanism would be possible for acknowledgements coming from followers. When a produce request occurs with a min_ack_count > 1, the request would go into a list of waiting requests for that topic/partition. When the ack request comes in from followers, we would check the waiting producers and add responses to the response queue for any newly unblocked request.

I would like to do a round of refactoring on the SocketServer anyway, so let me know if anyone has comments on this before i go do anything too crazy. For example, I want someone else to validate the interaction with the replication design.
;;;","16/Aug/11 00:43;junrao;Jay, thanks for carefully thinking ahead. I agree that we will need to decouple the socket processor thread from the handler thread, to make it easy for producers to wait for acks from followers, and for the consumers to block until new data is produced. We probably need 1 request queue and 1 response queue per socket processor thread. That way, we can ensure that the response is always handled by the socket thread that has registered the needed socket key for the response.;;;","31/Oct/11 13:17;jkreps;This is a draft patch that refactors the socket server to make requests and responses asynchronous. No need for a detailed review, it still needs a lot of cleanup, but I wanted to show people the idea in more detail.;;;","31/Oct/11 23:38;tgautier;Hi - please keep in mind the use case where a consumer is interested in more than one topic.

This feature if implemented only for one topic will not be useful for this use case - assuming it's infeasible to open multiple tcp connections.

The first proposal I have is to allow the request to contain a list of topics.  However, upon consideration, this would require the response to also be adjusted such that it would contain the name of the topic, otherwise it would be next to impossible to ascertain which topic the response corresponds to - well it could be done such that the response is returned in the same way as the request was requested, and for topics with no messages, an empty response is given, but this seems pretty bad from a network bandwidth standpoint.

So my final proposal would be to introduce an epoll like request/response.  The consumer would submit a request with a list of interested topics, and the response would be a topic and # of messages available on that topic when the topic(s) have messages.

The advantage to this solution is that it would be entirely backward compatible, since you would simply introduce a new request/response pair and it would also allow the consumer to decide which topics to poll (or pull) from first, so that it could prioritize, if it wanted.  

Finally, I like the idea of allowing the consumer to specify a min # of messages required to trigger the poll, you might want to copy the pattern you already setup for log flushing, e.g. max time and/or min # of messages.  So the request might look like:

list-of :  topic-name:min msgs:max time

and the response might be:

list-of : topic-name:# msgs available


;;;","01/Nov/11 02:31;jkreps;Yes, these are all good points. The work I have done so far just splits request processing into a separate thread pool and enables asynchronous handling. This is a fairly general thing we need for a few different use cases. Perhaps this should be broken into a separate JIRA.

I have thought a little bit about how to do long poll, though. Logically what I want to do is make it possible to give a minimum byte size for the response and a maximum delay in ms; then have the server delay the response until we have at least min_bytes messages in the response OR we hit the maximum delay time. The goal is both to improve latency (by avoiding waiting in between poll requests), to reduce load on the server (by not polling), and to make it possible to improve throughput. If you set min_bytes = 0 or max_delay_ms = 0 you effectively get the current behavior. The throughput improvement comes if you set the min_bytes > 1; this would give a way to artificially increase the response size for requests to the topic (i.e. avoid fetching only a few messages at a time) while still giving hard latency guarantees. We have seen, the request size is one of the important things for network throughput.

As you say, the only case to really consider is the multi-fetch case. The single topic fetch can just be seen as a special case of this. I think your first proposal is closer to what I had in mind. Having the response contain an empty message set for the topics that have no data has very little overhead since it is just positionally indexed, so it is like 4 bytes or something. I don't like doing a poll() style interface that just returns ready topics doesn't seem very useful to me because the only logical thing you can do is then initiate a fetch on those topics, right? So might as well just send back the data and have a single request type to worry about?

One of the tricky questions for multifetch is what does the minimum byte size pertain to? A straight-forward implementation in the current system would be to add the min_bytes and timeout to the fetch request which would effectively bundle it up N times in the multi-fetch (currently multi-fetch is just N fetches glued together). This doesn't really make sense, though. Which of these minimum sizes would cause the single response to be sent? Would it be when all conditions were satisfied or when one was satisfied? I think the only thing that makes sense is to set these things at the request level. Ideally what I would like to do is remove the fetch request entirely because it is redundant and fix multi-fetch to have the following:
   [(topic1, partitions1), (topic2, partitions2),...], max_total_size, max_wait_ms
This also fixes the weird thing in multifetch now where you have to specify the topic with each partition, so a request for 10 partitions on the same topic repeats the topic name 10 times. This is an invasive change, though, since it means request format changes.

I am also not 100% sure how to implement the min_bytes parameter efficiently for multi-fetch. For the single fetch case it is pretty easy, the implementation would be to keep a sort of hybrid priority queue by timeout time (e.g. the unix timestamp at which we owe a response). When a fetch request came in we would try to service it immediately, and if we could meet its requirements we would immediately send a response. If we can't meet its min_bytes requirement then we would calculate the offset for that topic/partition at which the request would be unblocked (e.g. if the current offset is X and the min_bytes is M then the target size is X+M). We would insert new requests into this watchers list maintaining a sort by increasing target size. Each time a produce request is handled we would respond to all the watching requests whose target size is < then new offset, this would just require walking the list until we see a request with a target size greater than the current offset. All the newly unblocked requests would be added to the response queue. So this means the only work added to a produce request is the work of transferring newly unblocked requests to the response queue and at most we only need to examine one blocked request.

The timeout could be implemented by keeping a priority queue of requests based on the unix timestamp of the latest allowable response (i.e. the ts the request came in, plus the max_wait_ms). We could add a background thread to remove items from this as their timeout occurs, and add them to the response queue with an empty response.
 
For the multifetch case, things are harder to do efficiently. The timeouts can still work the same way. However the min_bytes is now over all the topics the request covers. The only way I can see to implement this is to keep a counter associated with each watcher, and have the watcher watch all the requested topics. But now on each produce request we need to increment ALL the watchers on the topic produced to.

Dunno, maybe for practical numbers of blocked requests (a few hundred? a thousand?) this doesn't matter. Or maybe there is a more clever approach. Ideas welcome.
;;;","01/Nov/11 03:02;tgautier;I can see how it would be reasonable to do the first approach.  It does limit one use case I was considering, which is to allow the consumer to decide in which order to fetch the topics after the poll is triggered, however, this can be done at request time when the topics are requested.

As you say, the response is 100% compatible, it's just the request that changes.  Therefore it would make sense I think to go ahead and make a new request type that doesn't yet exist and then the current fetch request remains the same on the wire and the behavior of it is just a degenerate case of this new use case with delay and bytes set to 0.

I think you might consider how useful is it to worry about user specified time/bytes?  It will add a lot of complexity to your implementation, and frankly if I have just the ability to do a multi-fetch that will wait until something has arrived and send me whatever it has at the current moment that will be good enough.  A minimum implementation should also probably provide a simple timeout that will respond with nothing if the timeout expires.

I think the simple implementation by itself a huge win and you might consider -- is that good enough?

For me it is - I would prefer to get the simple thing in the short term and wait for the harder thing in the long-term.;;;","01/Nov/11 03:18;jkreps;Hi Taylor,

Could you give a little more detail on your use case for ordering the fetches? I think you have a use case I haven't thought of, but I don't know if I understand it. Is your motivation some kind of quality of service over the topics?

As you say, this would definitely be a new request type for compatibility, and we would probably try to deprecate the old format over the next few releases as we can get clients updated.

Your point about complexity is valid. I think for our usage since we use kafka very heavily the pain of grandfathering in new APIs is the hardest part, and the socket server refactoring is next, so I was thinking the difficulty of implementing a few internal data structures is not too bad. I suppose it depends on if I work out a concrete plan there or not. If the best we can do is iterate over the full set of watchers it may not be worth it.;;;","01/Nov/11 04:36;tgautier;Actually, I don't have a valid use case for priority fetches, I was just thinking ahead.

I agree that it's painful to have message format upgrades.  On the flip side of course we probably also agree it's bad to have parameters in the message header that don't correspond to real features.  

Can you make a trade-off and reserve some bytes for these two int (or long) parameters and/or a few others but just call the space reserved?;;;","12/Nov/11 07:32;junrao;Just had a chance to look at the patch. Agree in principle this would work. It's probably better to create a separate jira for moving the requesthandler out of socket server. The long poll jira will depend on that jira.;;;","12/Nov/11 11:25;jkreps;Cool, moved it.;;;","21/Nov/11 16:15;tgautier;I've been staring at the code for a while - and I'm not sure I understand why you need KAFKA-202 to implement this feature.

What I am thinking to do is:
1) Every thread has to open a local socket for read/write
2) Each thread puts the socket into the poll set for reading
3) If a read request fails to read any messages, when it comes back to the handler, the handler adds a callback method to the appropriate log and puts the read request into a special queue.  When that log gets messages for write, it calls the callback.  The callback writes a byte into the special thread socket.
4) The byte wakes up the thread, which sees that the special socket had a byte written to it, and so it goes and re-handles the read requests in the special queue as if they had just come in from the network. Thus if there are any messages available in the log for a given request, they are read just like normal and transferred out onto the channel.  If not, they're re-queued as per step 3.

I think there is some pieces I haven't quite got right - in particular, I think there can only be one active response at a time.  Thus there will have to be some sort of response queue built up as each request generates a response, but I think that's simple - the handler just writes responses with non-zero messages into a response queue and the write logic of the socketserver is updated to drain this queue on write events (at the moment, it only deals with one response at a time, but now it may have many to send out queued up).

Some other work that is probably going to be more difficult is that the binary protocol has to change to include the topic name or else there is no way to disambiguate the responses coming back.;;;","03/Jan/12 01:19;junrao;Taylor,

Sorry for the late response. I am not sure that I understand your proposal. 

a. Why do we need a local socket? It seems that the same thing can be achieved by just turning on the write_interesting bit in the socket key corresponding to a client request.

b. It's not clear to me how you correlate a queued client request with the corresponding client socket.;;;","04/Feb/12 06:49;jkreps;This is a very rough draft of long poll support. It appears to work. Here are some remaining issues:
1. I need the updated request objects to properly get the new fields (min_bytes, max_wait). Currently I am just hard-coding some made-up values.
2. This patch is very specific to long poll support for fetch requests, it will require more generalization to support our other async case, namely delaying produce requests until a certain number of slaves are caught up.
3. There are still some unit test problems.
4. Code is a little rough still.

Take a look if interested, I will discuss with a few people and clean up a little more before asking for a real review.;;;","04/Feb/12 07:08;tgautier;Jay - that's great to hear!! Would you mind summarizing the way that the long-poll works?  I know that several different implementations were suggested here on the thread and I wanted to know which one you ultimately decided to go with.;;;","04/Feb/12 07:22;jkreps;Hey Taylor, here are the nitty gritty details:
- When a fetch request comes in we immediately check if we have sufficient data to satisfy it
   - if so we respond immediately
   - If not we add a ""watch"" on the topics that the fetch is for, and add it to a delay queue to expire it after the given timeout
   - There is a background thread that checks the delay queue for expired requests and responds to them with whatever data is available
- When a produce request comes in we update the watchers for all the topics it produces to, and increment their byte count. Any requests that have been satisfied by this produce, are then executed and responses are sent.

So one of the earlier questions was how to support polling on a very large number of topics AND wants very low latency, I think as you described it would be possible to implement this by simply multiplexing the requests on the single socket and letting the server respond to these as possible.;;;","04/Feb/12 07:29;jkreps;Two other issues with this patch, I forgot to mention:
- There is a race condition between checking the available bytes, and adding the watchers for the topics. I *think* this is okay since the min_bytes is a minimum not a maximum, so in the rare case that a produce comes in before the watchers are added we will just wait slightly longer than we should have. I think this is probably better than properly synchronizing and locking out all produces on that partition.
- The other issues is that the delay queue is only emptied right now when the delay expires. If the request is fulfilled before the delay expires, the request is marked completed, but it remains in the delay queue until it expires. This is a problem and needs to be fixed. The problem is that if the client sets a low min_bytes and a high max_wait these requests may accumulate. Currently we would have to do an O(N) walk of the waiting requests to fix this. I am going to try to come up with an improved set of data structures to fix this without requiring that.;;;","21/Feb/12 11:48;junrao;Overall, the patch looks good. Some comments:

1. DelayedItem.compareTo: yourEnd should be delayed.createdMs + delayed.delayMs
2. Suppose that a client issues MultiFetch requests on a hot topic and a cold topic. What can happen is that the watcher list for the cold topic won't be cleaned up for a long time. One solution is to have a cleaner thread that periodically wakes up to remove satisfied items. The cleaner thread can be used to clean up the DelayQueue too.
3. MessageSetSend.empty is not used.
;;;","05/Apr/12 02:29;jkreps;This version of the patch updates the code to work with the new request objects and correctly respect the min_bytes and max_fetch_wait settings.

Please review the new configs and make sure we are happy with the naming.;;;","05/Apr/12 02:39;jkreps;Oops, missing about a bazillion files on that last patch.;;;","06/Apr/12 01:39;junrao;Thanks for patch v3. Some comments:

31. DelayedFetch is keyed off topic. It should be keyed off (topic, partition) since a consumer may be interested in only a subset of partitions within a topic.

32. KafkaApis: The following 3 lines are duplicated in 2 places.
      val topicData = readMessageSets(delayed.fetch.offsetInfo)
      val response = new FetchResponse(FetchRequest.CurrentVersion, delayed.fetch.correlationId, topicData)
      requestChannel.sendResponse(new RequestChannel.Response(delayed.request, new FetchResponseSend(response, ErrorMapping.NoError), -1))
Should we put them in a private method and share the code?

33. ExpiredRequestReaper.purgeExpired(): We need to decrement unsatisfied count here.

34. FetchRequest: Can we have the default constants for correlationId, clientid, etc defined and shared btw the constructor and the request builder?

35. MessageSetSend.empty is unused. Should we remove it?;;;","10/Apr/12 04:35;jkreps;Jun, thanks for the feedback. This patch hopefully addresses your comments:
1. I removed the empty flag, as you suggested from MessageSetSend
2. I would like to leave the ugly duplicate code for now. Making a seperate method for this doesn't really make sense as it isn't really a stand alone piece of code. I think the root problem is that action you do when the request is satisfied can be done either synchronously (if possible), asynchronously when the criteria are satisfied, or asychronously when the request expires. I think the right way to do this is to refactor RequestPurgatory a bit and somehow always use the same callback for all three cases. I would like to address this as a seperate patch because this idea is not fully baked yet.
3. The default values are now shared between the builder and constructor.
4. I changed the key to be (topic, partition) for FetchRequestPurgatory. That was a major oversite.
5. The purgeExpired method is actually misnamed it is really purgeSatisfied, so it doesn't need to decrement the satisfied count. However there is a major bug in that count, it wasn't getting decremented by the processing thread. I added a new method to cover this.;;;","10/Apr/12 04:37;jkreps;I attached a diff that just shows the changes between v3 and v4 for folks who already looked at v3.;;;","11/Apr/12 01:35;junrao;Patch v4 looks good. Just one more comment.

41. RequestPurgatory.update(): if(w == null), could we return a singleton empty array, instead of creating a new one every time?;;;","11/Apr/12 01:54;jkreps;Good point Jun, now it is
    if(w == null)
      Seq.empty
    else
      w.collectSatisfiedRequests(request)

I will wait for more feedback before making a new patch since this is a pretty trivial change.;;;","11/Apr/12 02:20;nehanarkhede;This patch looks very good. Here are a few questions - 

1. I like the way the expired requests are handled by implementing the logic inside the FetchRequestPurgatory. However, can we not do the same for satisfied requests by providing a satisfy() abstract API in RequestPurgatory ? That gets rid of the handling of fetch requests inside handleProducerRequest() in KafkaApis, which is a little awkward to read. When we have the ProduceRequestPurgatory, the same satisfy() operation can send responses for produce requests once the fetch responses for the followers come in. 

2. I gave the RequestPurgatory data structure some thought. Not sure if this buys us anything over the current data structure. How about the following data structure for the RequestPurgatory - 

2.1. The watchers would be a priority heap (PriorityQueue), with the head being the DelayedItem with the least delay value (earliest expiration time). So for each (topic, partition), we have a PQ of watchers. 

2.2. The expiration data structure is another PQ of size n, where n is the number of keys in RequestPurgatory. This expiration PQ has the heads of each of the watcher lists above. 

2.3. The expiration thread will await on a condition variable with a timeout = delay of the head of the expiration PQ. The condition also gets signaled whenever the head of any of the n watcher list changes. 

2.4. When the expiration thread gets signaled, it removes its head element, expires it if its ready, ignores if its satisfied, and adds an element from the watch list it came from. It keeps doing this until its head has expiration time in the future. Then it goes back to awaiting on the condition variable. 

2.5. The item to be expired gets removed from its watch list as well as expiration PQ in O(1). 

2.6. The item that gets satisfied sets a flag and gets removed from its watcher list. If the satisfied item is the head of the watcher list, the expiration thread gets signaled to add new head to its PQ. 

2.7 Pros 
2.7.1. The watcher list doesn't maintain expired items, so doesn't need state-keeping for liveCount and maybePurge() 
2.7.2. During a watch operation, items only enter the expiration PQ if they are the head of the watcher list 
2.7.3. The expiration thread does a more informed get operation, instead of polling the queue in a loop. 

2.8. Cons 
2.8.1. watch operation is O(logn) where n is the number of DelayedItems for a key 
2.8.2 The forcePurge() operation on the expiration data structure still needs to happen in O(n) 

Did I miss something here ? Thoughts ? 

3. On the other hand, this is a huge non-trivial patch and you must be pretty tired of rebasing and working through unit tests. We could just discuss the above changes, and maybe file another JIRA to track it, instead of delaying this patch further. But that is your call.;;;","11/Apr/12 03:25;jkreps;Hey Neha, yes, my hope is to get the patch evaluated as is, and then take another pass at cleaning up the way we handle the satisfaction action as Jun and you requested and try out other approaches to the purgatory data structure asynchronously. That should take these cleanup/polishing items out of the critical path.

I like your idea of the dual priority queues, but I need to work through it more to fully understand it.;;;","18/Apr/12 07:50;jjkoshy;+1 on the patch. I have a few minor comments:

KafkaRequestHandlers :
- requestLogger unused.

ConsumerConfig:
- maxFetchWait -> rename the prop to max.fetch.wait.ms and the val to
  maxFetchWaitMs
- Can we get rid of fetcherBackoffMs? It says it is deprecated, but had a
  reference in FetcherRunnable which you removed.
- May want to have an explicit constraint that consumerTimeoutMs <=
  maxFetchWait

RequestPurgatory:

- Unused import.
- The parameterized types and overall tricky nature of this component make
  it somewhat difficult to follow. I (think) I understood it only after
  looking at its usage in KafkaApis, so the comments and javadocs (including
  class' summary on top) can only go so far.  Even so, I think the comments
  seem slightly out of sync with the code and can be improved a bit. E.g.,
  what is ""given size"" in the update method's comment? current keys in the
  comment for watch == the given request's keys. and so on.
- Also, it may be easier to follow if we do some renaming, but it's a matter
  of taste and I may have misunderstood the code to begin with:
  - I find it confusing that there's a map called watchers which is a map
    from keys to Watcher objects, and the Watcher class itself has a
    linked-list of delayed requests called watchers. May be unwieldy, but
    how about renaming:
    - RequestPurgatory.watchers to watchedRequestsForKey
    - Watchers to WatchedRequests
    - Watchers.watchers to requests
  - Rename DelayedRequest.satisfied to satisfiedOrExpired (I find it weird
    that the reaper marks expired requests as satisfied.)
  - update -> maybeNotify?
- In collectSatisfiedRequests, the comment on ""another thread has satisfied
  this request"". That can only be the ExpiredRequestReaper thread right?
- It is slightly odd that we have to call the reaper's satisfyRequest method
  from Watcher. Would it work to move the unsatisfied counter up to
  RequestPurgatory?
;;;","18/Apr/12 08:23;jkreps;Joel, this is great feedback. I will address these issues in the commit since most are naming/documentation related.;;;","01/May/12 05:42;jkreps;Included most of Joel's comments, and fixed a few lagging unit tests (in particular refactored AutoOffsetResetTest).

Comments on the general structure of request purgatory I am going to put off until we have our second use case ready to implement--the producer acks. When we have that I am going to look at refactoring so that the ""satisfaction action"" is a function included with the DelayedRequest which is executed regardless of whether the request is satsified or times out. But I want to put this off until we can check it against the specifics of the second use case.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
all partitions are using same broker as their leader after broker is down,KAFKA-1503,12722850,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jackiewang518,jackiewang518,jackiewang518,21/Jun/14 03:02,03/Jul/14 12:56,22/Mar/23 15:10,03/Jul/14 12:56,0.8.0,0.8.1.1,,,,,0.8.2.0,,,,,,,controller,,,,0,patch,,,,,"The current leader selection always pick the first live broker in ISR when the current leader broker is down. Since the list of liveBrokerInIsr is not evenly distributed. As time goes on, all the partitions will use only one broker as its leader. 

I figured out a fix which is to use the first live broker in replica list which is also in ISR list. Since the liveAssignedReplicas is evenly distributed across brokers, all the partitions will be evenly distributed in the live brokers in ISR.
The fix is:
kafka-0.8.1.1-src/core/src/main/scala/kafka/controller/PartitionLeaderSelector.scala


71	71
           case false =>
72	 
-            val newLeader = liveBrokersInIsr.head
 	72
+            val liveReplicasInIsr = liveAssignedReplicas.filter(r => liveBrokersInIsr.contains(r))
 	73
+            val newLeader = liveReplicasInIsr.head",0.8.1.1 ,guozhang,jackiewang518,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jun/14 00:57;jackiewang518;kafka1503.patch;https://issues.apache.org/jira/secure/attachment/12651996/kafka1503.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,401037,,,Thu Jul 03 04:56:59 UTC 2014,,,,,,,,,,"0|i1x167:",401121,,,,,,,,,,,,,,,,,,,,"21/Jun/14 05:34;guozhang;Hello Jianwen,

Controller does always pick the first alive broker in the ISR list to be the leader, but since our partition assignment logic is round robin, such that if you have three partitions, three brokers, and a replication factor of three, then you should see the ISR lists are

partition1:   ISR {broker-1, broker-2, broker-3}
partition1:   ISR {broker-2, broker-3, broker-1}
partition1:   ISR {broker-3, broker-1, broker-2}

So the leader should still be distributed evenly.;;;","21/Jun/14 05:49;jackiewang518;Hi Guozhang,
   That is not what I experienced in my real cluster environment:
   Given a cluster contains three brokers, when all brokers are live and running, and there is a topic with 10 partitions:
   I just made a query on my cluster and got the topic info as below right now:

   root@kafka-1:~/kafka-0.8.1.1-src# bin/kafka-topics.sh --zookeeper localhost:2181 --topic ruby-p10 --describe
Topic:ruby-p10	PartitionCount:10	ReplicationFactor:3	Configs:
	Topic: ruby-p10	Partition: 0	Leader: 2	Replicas: 1,2,3	Isr: 2,1,3
	Topic: ruby-p10	Partition: 1	Leader: 2	Replicas: 2,3,1	Isr: 2,1,3
	Topic: ruby-p10	Partition: 2	Leader: 3	Replicas: 3,1,2	Isr: 2,1,3
	Topic: ruby-p10	Partition: 3	Leader: 1	Replicas: 1,3,2	Isr: 2,1,3
	Topic: ruby-p10	Partition: 4	Leader: 2	Replicas: 2,1,3	Isr: 2,1,3
	Topic: ruby-p10	Partition: 5	Leader: 3	Replicas: 3,2,1	Isr: 2,1,3
	Topic: ruby-p10	Partition: 6	Leader: 2	Replicas: 1,2,3	Isr: 2,1,3
	Topic: ruby-p10	Partition: 7	Leader: 2	Replicas: 2,3,1	Isr: 2,1,3
	Topic: ruby-p10	Partition: 8	Leader: 3	Replicas: 3,1,2	Isr: 2,1,3
	Topic: ruby-p10	Partition: 9	Leader: 1	Replicas: 1,3,2	Isr: 2,1,3


As you can see the ISR is not evenly distributed, and since current codes always pick the first one. So if broker 1 is down, partition hosted by broker 1 will be changed to be broker 2 instead of evenly distributed to broker 2 and broker 3.

As times goes on, all the partition will be only hosted on one broker.
;;;","21/Jun/14 05:53;jackiewang518;One way to break this loop is to turn on ""auto.leader.rebalance.enable=true"". But the cluster still will be imbalance between two auto rebalances(I used 60 seconds as the interval).
The fix I provided is to make sure the partitions are even distributed within the live brokers between two auto rebalances.;;;","21/Jun/14 05:55;jackiewang518;Also, I experienced another issue is that auto rebalance sometime does not work for very long time and leave the imbalance (all partition on one broker) for hours. I will file a separate ticket for that.;;;","21/Jun/14 06:23;guozhang;Hi Jianwen,

When the topic is firstly created, the leaders should be balanced. Then when there is, say a soft failure on some brokers, its leading partitions will be migrated to others, and even when this broker resumes these partitions will not be migrated back, causing imbalance. And this is probably what you saw before.

Previously we do rebalance using the partition-reassignment-tool from time to time, then we created the auto-rebalance tool to ease this problem. Unfortunately there is an issue with this tool and we are currently fixing it:

https://issues.apache.org/jira/browse/KAFKA-1305

The fix should be released soon with 0.8.2, will that fully-working tool solve your issue then?;;;","21/Jun/14 06:42;jackiewang518;Hi Guozhang,
   The fully working auto rebalance will surely break that imbalance loop. But I like to have a fix to make sure the leader is evenly distributed within live brokers between two rebalances after one broker is down. As you can see, if the auto rebalance interval is set to 5 minutes, the imbalance case (all partitions on one broker) will stay for <= 5 minutes.

   The fix I provided is to solve that particular case.

   Thanks.

-jianwen;;;","21/Jun/14 06:55;guozhang;Cool, could you upload your patch as a file that is appliable to trunk?;;;","24/Jun/14 00:56;jackiewang518;The first live broker in ISR was used as new leader. Since
 the order of liveBrokersInIsr list is not event distributed within live
 brokers, all partitions will be hosted on one broker as time goes on.

Now use the first live replica broker in ISR (liveAssignedReplicas filtered by liveBrokersInIsr) as the replica order is strictly evenly distributed.
;;;","27/Jun/14 01:12;guozhang;Looks good to me. [~junrao] Could you take a look at this?;;;","03/Jul/14 12:56;junrao;Thanks for the patch. It's a nice fix! +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor server code to remove interdependencies between LogManager and KafkaZooKeeper,KAFKA-307,12546701,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,16/Mar/12 09:14,24/Mar/12 04:20,22/Mar/23 15:10,24/Mar/12 04:20,0.7,0.8.0,,,,,,,,,,,,,,,,0,,,,,,"Currently, LogManager wraps KafkaZooKeeper which is meant for all zookeeper interaction of a Kafka server. With replication, KafkaZookeeper will handle leader election, various state change listeners and then start replicas. Due to interdependency between LogManager and KafkaZookeeper, starting replicas is not possible until LogManager starts up completely. Due to this, we have to separate the broker startup procedures required for replication to get around this problem.

It will be good to refactor and clean up the server code, before diving deeper into replication.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-45,,,,,,,,,,,,,,,,,,,,,,,,"22/Mar/12 07:05;nehanarkhede;kafka-307-draft.patch;https://issues.apache.org/jira/secure/attachment/12519342/kafka-307-draft.patch","23/Mar/12 03:26;nehanarkhede;kafka-307-v2.patch;https://issues.apache.org/jira/secure/attachment/12519491/kafka-307-v2.patch","23/Mar/12 08:09;nehanarkhede;kafka-307-v3.patch;https://issues.apache.org/jira/secure/attachment/12519551/kafka-307-v3.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,231859,,,Fri Mar 23 20:20:08 UTC 2012,,,,,,,,,,"0|i09m9j:",54040,,,,,,,,,,,,,,,,,,,,"22/Mar/12 07:06;nehanarkhede;Attaching a patch for this refactoring. Broadly, it includes the following changes -

1. LogManager and KafkaZooKeeper are decoupled and don't depend on each other

2. KafkaServer maintains replicas, instead of LogManager
;;;","23/Mar/12 00:49;junrao;Overall looks good. Some suggestions:

1. KafkaServer:
Replicas are important data structures on each broker. Could we create a separate class Replicas that manage all replicas needed on a broker? Also, I see 2 different apis for adding a replica data structure. For replicas physically assigned to a broker, they always need a local Log. So, when adding those replicas, we need an api that creates a new log, if it's not there already (e.g. for newly created topics). The rest of replica data structures needed on a broker are not physically assigned to this broker and they are used to track the progress of the replicas in the followers. When adding those replicas, we need another api that doesn't force the creation of a local log.

2. log4j.properties: Do we really want to turn off logging for all kafka during unit tests? How about keeping it at ERROR level. We can probably turn off logging for ZK.;;;","23/Mar/12 03:26;nehanarkhede;Thanks for the review !

1. I like your suggestion. I wasn't quite satisfied with the way replicas were being managed. Incorporated the suggested changes. Looks much better now.

2. Didn't mean to check it in. But yes, I think zookeeper should be on ERROR and so should Kafka.;;;","23/Mar/12 07:30;junrao;Thanks for patch v2. Looks cleaner. A couple of other comments:

3. Is it better for KafkaZooKeeper to call ReplicaManager.addLocalReplica directly, instead of going through KafkaServer? For all replicas added in KafkaZookeeper, we know they are all local and should have a log. We could call LogManager.getOrCreateLog to get the log and pass it to ReplicaManager.

4. There are unused imports in KafkaServer.;;;","23/Mar/12 07:34;nehanarkhede;3. Yeah, I thought about this, but then that requires LogManager to be referenced inside KafkaZooKeeper again. So, thats why it goes through KafkaServer. The point was to have only KafkaServer have access to LogManager, ReplicaManager and KafkaZookeeper, but not have those 3 components have interdependencies. What do you think ?

4. Will clean it up before committing the patch.;;;","23/Mar/12 08:09;nehanarkhede;3. Fixed addReplica logic to use getOrCreateLog instead of getLog
4. Cleaned up the imports;;;","24/Mar/12 00:20;junrao;+1 on patch v3.;;;","24/Mar/12 04:20;nehanarkhede;Thanks for the review ! Committed this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
topic not accessible after deletion even when delete.topic.enable is disabled,KAFKA-3175,12935325,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,mgharat,junrao,junrao,30/Jan/16 10:10,22/Nov/16 20:10,22/Mar/23 15:10,11/Oct/16 05:08,0.9.0.0,,,,,,0.10.2.0,,,,,,,core,,,,0,,,,,,"The can be reproduced with the following steps.

1. start ZK and 1 broker (with default delete.topic.enable=false)
2. create a topic test
bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic test --partition 1 --replication-factor 1
3. delete topic test
bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test
4. restart the broker

Now topic test still shows up during topic description.
bin/kafka-topics.sh --zookeeper localhost:2181 --describe
Topic:test	PartitionCount:1	ReplicationFactor:1	Configs:
	Topic: test	Partition: 0	Leader: 0	Replicas: 0	Isr: 0

However, one can't produce to this topic any more.
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
[2016-01-29 17:55:24,527] WARN Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[2016-01-29 17:55:24,725] WARN Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[2016-01-29 17:55:24,828] WARN Error while fetching metadata with correlation id 2 : {test=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
",,Andrew M,githubbot,ijuma,junrao,mgharat,umesh9794@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-4074,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Nov 22 12:10:13 UTC 2016,,,,,,,,,,"0|i2s6mf:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"30/Jan/16 10:19;junrao;The issue is that during the controller failover, we call KafkaController.initializeTopicDeletion(), which reads the to be deleted topic test from ZK and uses it to initialize initialTopicsToBeDeleted in TopicDeletionManager without checking isDeleteTopicEnabled. Then, when the controller sends an UpdateMetadataRequest, ControllerBrokerRequestBatch.addUpdateMetadataRequestForBrokers() marks the topic as deleted. Then, the broker removes the topic from the metadata cache.

To fix this, we will need to check isDeleteTopicEnabled when initializing TopicDeletionManager.;;;","30/Jan/16 11:03;mgharat;I am just thinking we have that check in the TopicDeletionManager.start() and if the delete topic enable is set to false, DeleteTopicThread should not start.;;;","30/Jan/16 12:25;junrao;It's already doing that. The problem is that initialTopicsToBeDeleted is added to topicsToBeDeleted without checking if delete topic is enabled or not.;;;","01/Feb/16 23:37;junrao;Also, another thing is that if topic deletion is not enabled, the controller doesn't subscribe to the topic deletion path. This means that those to be deleted topics in the topic deletion path never get removed. If people enable topic deletion, those topics will be suddenly removed, which may be surprising. Perhaps we should let controller always subscribe to the topic deletion path, if topic deletion is not enabled, the controller can simply remove those to be deleted topics without doing any real work.;;;","02/Feb/16 02:21;mgharat;I am thinking that once we detect that the delete topic is disabled, onController restart/shift we can remove the entries under /admin/delete_topic/.;;;","02/Feb/16 05:55;githubbot;GitHub user MayureshGharat opened a pull request:

    https://github.com/apache/kafka/pull/846

    KAFKA-3175 : Topic not accessible after deletion even when delete.topic.enable is disabled

    Remove topics under /admin/delete_topics path in zk if deleteTopic is disabled. The topic should never be enqueued for deletion.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/MayureshGharat/kafka kafka-3175

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/846.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #846
    
----
commit 48676b68df0f33c5c095c73002b7cca10b8a1402
Author: MayureshGharat <gharatmayuresh15@gmail.com>
Date:   2016-02-01T21:51:57Z

    Remove topics under /admin/delete_topics path in zk if deleteTopic is disabled. The topic should never be enqueued for deletion

----
;;;","27/Sep/16 11:23;githubbot;GitHub user MayureshGharat opened a pull request:

    https://github.com/apache/kafka/pull/1913

    KAFKA-3175 (Rebased) : topic not accessible after deletion even when delete.topic.enable is disabled

    Rebased the patch with current trunk.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/MayureshGharat/kafka kafka-3175_latest

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1913.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1913
    
----
commit 3b4412eb948318ac8fbea855ff52071bbb6f8fb3
Author: MayureshGharat <gharatmayuresh15@gmail.com>
Date:   2016-02-01T21:51:57Z

    Remove topics under /admin/delete_topics path in zk if deleteTopic is disabled. The topic should never be enqueued for deletion

commit 1bf29ae00da0eaa0044bdc1bb8dc6cc80ee90951
Author: MayureshGharat <gharatmayuresh15@gmail.com>
Date:   2016-03-11T17:25:32Z

    Addressed Jun's comment to clean the zk state for a topic on cluster restart and delete topic disabled

----
;;;","11/Oct/16 05:07;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/846
;;;","22/Nov/16 20:10;ijuma;I think this was only merged to trunk, so updated the fix version to be 0.10.2.0. Please let me know if I missed something.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
broker doesn't start if config defines advertised.host but not advertised.port,KAFKA-2327,12843932,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,granders,granders,granders,10/Jul/15 02:37,10/Jul/15 06:00,22/Mar/23 15:10,10/Jul/15 06:00,0.9.0.0,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"To reproduce locally, in server.properties, define ""advertised.host"" and ""port"", but not ""advertised.port"" 

port=9092
advertised.host.name=localhost

Then start zookeeper and try to start kafka. The result is an error like so:
[2015-07-09 11:29:20,760] FATAL  (kafka.Kafka$)
kafka.common.KafkaException: Unable to parse PLAINTEXT://localhost:null to a broker endpoint
	at kafka.cluster.EndPoint$.createEndPoint(EndPoint.scala:49)
	at kafka.utils.CoreUtils$$anonfun$listenerListToEndPoints$1.apply(CoreUtils.scala:309)
	at kafka.utils.CoreUtils$$anonfun$listenerListToEndPoints$1.apply(CoreUtils.scala:309)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.utils.CoreUtils$.listenerListToEndPoints(CoreUtils.scala:309)
	at kafka.server.KafkaConfig.getAdvertisedListeners(KafkaConfig.scala:728)
	at kafka.server.KafkaConfig.<init>(KafkaConfig.scala:668)
	at kafka.server.KafkaConfig$.fromProps(KafkaConfig.scala:541)
	at kafka.Kafka$.main(Kafka.scala:58)
	at kafka.Kafka.main(Kafka.scala)


Looks like this was changed in 5c9040745466945a04ea0315de583ccdab0614ac

the cause seems to be in KafkaConfig.scala in the getAdvertisedListeners method, and I believe the fix is (starting at line 727)

{code}
...
    } else if (getString(KafkaConfig.AdvertisedHostNameProp) != null || getInt(KafkaConfig.AdvertisedPortProp) != null) {
      CoreUtils.listenerListToEndPoints(""PLAINTEXT://"" +
            getString(KafkaConfig.AdvertisedHostNameProp) + "":"" + getInt(KafkaConfig.AdvertisedPortProp))
...
{code}

->

{code}
    } else if (getString(KafkaConfig.AdvertisedHostNameProp) != null || getInt(KafkaConfig.AdvertisedPortProp) != null) {
      CoreUtils.listenerListToEndPoints(""PLAINTEXT://"" +
            advertisedHostName + "":"" + advertisedPort
{code}




",,eribeiro,githubbot,granders,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jul 09 22:00:07 UTC 2015,,,,,,,,,,"0|i2h2bb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"10/Jul/15 02:41;gwenshap;Oops. My bug :)

Do you have a patch, or shall I fix this?;;;","10/Jul/15 03:04;githubbot;GitHub user granders opened a pull request:

    https://github.com/apache/kafka/pull/73

    KAFKA-2327

    Added unit tests as well. These fail without the fix, but pass with the fix.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/confluentinc/kafka KAFKA-2327

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/73.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #73
    
----
commit 23b3340b91800ff6568ac8f07f9188659358ecc3
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-07-09T19:01:27Z

    Fixes KAFKA-2327

----
;;;","10/Jul/15 03:08;granders;Oh quick reply! Yup I just opened a PR for the patch :);;;","10/Jul/15 04:10;eribeiro;Left some minor review comments, hope you don't mind. :);;;","10/Jul/15 05:58;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/73
;;;","10/Jul/15 06:00;gwenshap;Merged PR.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
inconsistent log levels when consumed offset is reset,KAFKA-1200,12687802,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,jbrosenberg@gmail.com,jbrosenberg@gmail.com,08/Jan/14 12:53,14/Jan/14 10:16,22/Mar/23 15:10,14/Jan/14 10:16,0.8.0,,,,,,0.8.1,,,,,,,consumer,,,,0,,,,,,"I've recently been dealing with the issue where my consumer falls behind and essentially loses data when the broker deletes data, due to it's retention policy.

On the broker, this is logged as an ERROR:

2013-12-23 05:02:08,456 ERROR [kafka-request-handler-2] server.KafkaApis - [KafkaApi-45] Error when processing fetch request for partition [mytopic,0] offset 204243601 from consumer with correlation id 130341
kafka.common.OffsetOutOfRangeException: Request for offset 204243601 but we only have log segments in the range 204343397 to 207423640.

But on the consumer, this same event is logged as a WARN:

2013-12-23 05:02:08,797  WARN [ConsumerFetcherThread-myconsumergroup-1387353494862-7aa0c61d-0-45] consumer.ConsumerFetcherThread - [ConsumerFetcherThread-myconsumergroup-1387353494862-7aa0c61d-0-45], Current offset 204243601 for partition [mytopic,0] out of range; reset offset to 204343397

It seems this should also be an ERROR condition (it would seem the consumer would care more about this than the broker, at least!).

Also, sometimes (but not always) there is also this log message on the consumer, which does log as an ERROR (I'm not sure why this log line doesn't always appear after the above WARN?):

2014-01-08 02:31:47,681 ERROR [myconsumerthread-0]
consumer.ConsumerIterator - consumed offset: 16163904970 doesn't match
fetch offset: 16175326044 for mytopic:0: fetched offset = 16175330598:
consumed offset = 16163904970;
 Consumer may lose data

In this message, there is the ""Consumer may lose data"" message, which makes sense.  Seems the fetcher thread above should also log something like that, and be an ERROR.

This would allow for more consistent alerting, in this case.",,Dima Pekar,jbrosenberg@gmail.com,joestein,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jan/14 20:58;Dima Pekar;KAFKA-1200.patch;https://issues.apache.org/jira/secure/attachment/12622618/KAFKA-1200.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,366806,,,Tue Jan 14 02:16:24 UTC 2014,,,,,,,,,,"0|i1r873:",367117,,,,,,,,,,,,,,,,,,,,"08/Jan/14 23:31;joestein;the consumer should log the error too, yeah.  should be able to patch this too if no one else is already working on it;;;","13/Jan/14 20:58;Dima Pekar;Provided patch that changes log level (several occurrences) to from warn to error inside kafka.server.AbstractFetcherThread#processFetchRequest method.
;;;","14/Jan/14 10:16;joestein;+1, committing to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix ReassignPartitionCommand and improve usability,KAFKA-990,12660544,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriramsub,sriramsub,sriramsub,30/Jul/13 10:01,28/Aug/13 13:24,22/Mar/23 15:10,28/Aug/13 13:24,,,,,,,,,,,,,,,,,,0,,,,,,"1. The tool does not register for IsrChangeListener on controller failover.
2. There is a race condition where the previous listener can fire on controller failover and the replicas can be in ISR. Even after re-registering the ISR listener after failover, it will never be triggered.
3. The input the tool is a static list which is very hard to use. To improve this, as a first step the tool needs to take a list of topics and list of brokers to do the assignment to and then generate the reassignment plan.",,diederik,guozhang,jjkoshy,junrao,nehanarkhede,sriramsub,swapnilghike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Aug/13 01:20;sriramsub;KAFKA-990-v1-rebased.patch;https://issues.apache.org/jira/secure/attachment/12596883/KAFKA-990-v1-rebased.patch","07/Aug/13 04:31;sriramsub;KAFKA-990-v1.patch;https://issues.apache.org/jira/secure/attachment/12596414/KAFKA-990-v1.patch","13/Aug/13 05:56;sriramsub;KAFKA-990-v2.patch;https://issues.apache.org/jira/secure/attachment/12597574/KAFKA-990-v2.patch","28/Aug/13 04:13;sriramsub;KAFKA-990-v3.patch;https://issues.apache.org/jira/secure/attachment/12600230/KAFKA-990-v3.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,340735,,,Wed Aug 28 05:24:02 UTC 2013,,,,,,,,,,"0|i1mrmf:",341053,,,,,,,,,,,,,,,,,,,,"08/Aug/13 07:40;nehanarkhede;Thanks for patch v1. Could you please fix the compilation errors though?;;;","09/Aug/13 02:15;nehanarkhede;Thanks for the rebased patch, Sriram. Overall, the changes look great. +1. One minor suggestion -

ReassignPartitionsCommand

For determining the replication factor for replica assignment, can we just use the first or last partition in the map instead of relying on a partition id 0? That way if we change the assumption that partition id should always start from 0, this will not break. -
topicInfo._2.head._2.size instead of topicInfo._2.get(TopicAndPartition(topicInfo._1, 0)).get.size

If you are ok with this suggestion, I can make it on checkin.

Also, it seems that #2 in the description above was not really a problem. This is because onPartitionReassignment checks areReplicasInIsr and hence restarts the reassignment correctly. This is however not true if we hit #1, which is a real issue.;;;","09/Aug/13 02:53;jjkoshy;- Topics to move json file format seems unnecessarily complicated. Why not just a JSON array?
- Use CommandLineUtils.checkRequiredArgs
- May be helpful to also print out the existing partition assignment and the final assignment.
- ""dryrun"" to ""dry-run"" which I think is the spelling unix tools like patch tend to use.
- line 88: use head instead of assuming 0 exists (start partition id could be != 0)

I did not finish going through all the changes in controller, but thought I would put in my comments so far :)
;;;","10/Aug/13 02:36;jjkoshy;Can you elaborate on the change to shutdownBroker in KafkaController? I
think we need to include shutting down brokers because the previous shutdown
attempt may have been incomplete due to no other brokers in ISR for some
partition which would have prevented leader movement. Subsequent attempts
would now be rejected.

Good catches on the controller failover. Agree with Neha that #2 is not a
problem for replicas that are in ISR, however, we do need to re-register the
ISR change listener for those replicas that are in ISR.

Finally, we should probably open a separate jira to implement a feature to
cancel an ongoing reassignment given that it is a long-running operation.
The dry-run option reduces the need for this but nevertheless I think it's a
good feature to support in the future.

;;;","10/Aug/13 09:17;jjkoshy;Looks like I might have looked at the wrong patch. I'll review this again this weekend.;;;","13/Aug/13 00:36;jjkoshy;The rebased patch looks good - the shutdown changes I was referring to were in v1.

+1 on the rebased patch - we can fix the minor comments either on check-in or in a separate jira.;;;","13/Aug/13 00:40;guozhang;Looks good to me overall. One question though: in shutdownBroker, should we check liveOrShuttingDownBrokerIds or liveBrokerIds? I saw going back and forth, and hence a little confused which criteria should be applied here?;;;","13/Aug/13 00:51;jjkoshy;It should be liveOrShuttingDownBrokerIds. This is required because a controlled shutdown attempt may
fail - if there are no other brokers in ISR for a partition led by the broker being shutdown. In this case we
would want to proceed with a retry (if there are retries left).;;;","13/Aug/13 01:06;junrao;Thanks for the patch. Looks good overall. Some comments.

1. KafkaController:
1.1 onPartitionReassignment(): The comment above the function needs to be updated. For example, we no longer register the ISR listener here.
1.2 initiateReassignPartitionForTopic(): We fail the reassignment if not all brokers in RAR are alive. I am wondering if this is necessary. A broker can go down when the reassignment process is in progress and we still need to handle this case.
1.3 Should watchIsrChangesForReassignedPartition() be private?

2. ReassignPartitionsCommand
2.1 It seems that we don't allow the options ""topics-to-move-json-file"" and ""manual-assignment-json-file"" to co-exist. Could we add an explicit check and output an appropriate message?
2.2 If ""broker-list"" is not specified, it seems that we should default to the current list of live brokers.
2.3 Could we somehow make dryRun the default behavior? In other words, the user has to add another option to disable dry run.

3. Since the reassignment process requires fetching old data and may pollute the pagecache, do you see any performance impact to produce/fetch request latency when the reassignment is in progress?


;;;","13/Aug/13 01:37;nehanarkhede;1.2 If a broker goes down after the reassignment has started, it will not enter the ISR. So the reassignment will not complete. If the replica fails after the 2nd stage of reassignment is complete, it will get handled through the normal logic of handling failed replicas since the reassignment is complete at that point. I'm not sure there is any value in starting an expensive process like reassignment of partitions when the target replicas are not even alive.
3. This is the same problem we have if we replace the broker machine and bring up another broker with the same id. I think the problem is off somehow throttling replica fetches. This is a good idea. Can we file a separate JIRA for this?;;;","13/Aug/13 02:23;swapnilghike;The rebased patch also failed for me on 0.8 HEAD

$patch -p1 --dry-run < ~/Downloads/KAFKA-990-v1-rebased.patch 
patching file core/src/main/scala/kafka/admin/ReassignPartitionsCommand.scala
patching file core/src/main/scala/kafka/utils/ZkUtils.scala
Hunk #1 succeeded at 620 (offset 42 lines).
patching file core/src/main/scala/kafka/admin/ReassignPartitionsCommand.scala
Hunk #1 FAILED at 29.
Hunk #2 FAILED at 81.
;;;","13/Aug/13 02:41;swapnilghike;v1 works with git apply.;;;","13/Aug/13 06:01;sriramsub;Neha - fixed what you suggested

Jun - 

1. KafkaController:
1.1 done 
1.2 we can fail for now. we can revisit this.
1.3 done

2. ReassignPartitionsCommand
2.1 I did not do that as it makes the code ugly and it does not cause any harm. Let me know if you are strong about this.
2.2 i think it is safer to be explicit instead of using the live brokers for the move and causing perf issues
2.3 done
3. polluting the page cache is debatable. We could do the log appends on the follower by-passing the cache but when the follower becomes the leader, it could cause lot of IO. Another option is to throttle the rate at which the appends happen on the follower that reduces the sudden influx of messages at the follower and fetch requests at the leader. Both of these are outside the scope of this JIRA.;;;","13/Aug/13 06:03;swapnilghike;Comments on v1:

I think a much clearer name for this tool would be ReassignReplicasCommand.

Admin tool:
11. I think the tool should also have a verify/validate option that you can run after the replica reassignment has been completed. As of now, the reassignment of a certain partition can fail and the admin won't know without looking at the controller log.
12. It would be good to make dry-run the default behaviour.
13. topics could be a json array, but I don't have a strong opinion one way or the other.
14. we should explicitly check that the options for the manual replica assignment and the assignment using brokerList should not be allowed at the same time. We should also check that the brokerList option is always provided with the topicsToMoveJsonFile option.
15. The ""failed"" messages could probably go to System.err.
16. We should probably not use the partition Id 0 in calling assignReplicasToBrokers, can we instead use { val topicAndPartition = groupedByTopic.get(topicInfo._1).get.get(0); val replicationFactor= topicInfo._2.get(topicAndPartition).get.size} ?
17. dryrun --> dry-run? I just remember seeing the latter more often across other tools.

On the controller:
21. I think a clearer name for initiateReassignPartitionForTopic would be initiateReassignReplicasForTopicPartition; and similar renames if any.
22. We should fix the comment in ReassignPartitionsIsrChangeListener
23. We should update controllerContext.partitionReplicaAssignment only once in KafkaController.updateAssignedReplicasForPartition(). There is an extra over-write as of now.
24. We should batch the requests in KafkaController.StopOldReplicasOfReassignedPartition() 
25. We should call startNewReplicasForReassignedPartition directly in initiateReassignPartitionForTopic instead of calling onPartitionReassignment. As of now, every time areReplicasInIsr returns fals, the controller will call startNewReplicasForReassignedPartition and then log a StateChangeFailedException, because the replicas were already in the new state. This exception will be logged in every call of onPartitionReassignment except for the first call.
26. We should remove the false condition from onPartitionReassignment
27. Currently, for each partition that is reassigned, controller deletes the /admin/reassign_partitions zk path, and populates it with a new list with the reassigned partition removed from the original list. This is probably an overkill, and we can delete the zk path completely once the reassignment of all partitions has completed successfully or in error. Even if there was a controller failover when the reassignment was in progress, the new controller should be able to decide which partitions have already been reassigned and which have not been in initiateReassignPartitionForTopic.;;;","19/Aug/13 23:56;junrao;Thanks for patch v2. A few more comments.

2.1 I think it's better to guard this in the command line. The issue is that if a user provided both options, it's not clear which one takes precedence.
2.2 In that case, we should make sure that brokerList is a mandatory field (like zkConnect).

30. KafkaController.initializeAndMaybeTriggerPartitionReassignment(): The following comment is weird.
    // need to call method

31. Related to Swapnil's comment in #11, currently, the tool finishes after the ZK path is created. It would be useful to add an option to check the state of partition reassignment so that we know either all assignments have completed or the set of partitions that are remaining.
;;;","20/Aug/13 00:06;sriramsub;2.1 will do so.
2.2 We cannot make it mandatory. It is not required when explicit list is specified. In the case when only topics are specified we do make it mandatory.

31. There is already a tool for that. It is called CheckReassignmentStatus.;;;","20/Aug/13 00:33;guozhang;Just one more comment: as for Swapnil's 16, currently partition id 0 is also used for AddPartitionCommand. Shall we change that also?;;;","28/Aug/13 04:19;sriramsub;- made the dry run the default
- added some more input validations for the tool
- some renaming to the controller methods

Swapnil - 

23. We seem to be updating only once. Let me know if that is not the case.
24. It is hard to batch with the way we have the code now. The handleStateChange works per topic partition
25. That would cause us to explicitly invoke startNewReplicasForReassignedPartition in each case outside onPartitionReassignment which is hard to maintain. 
26. Same comment as above
27. This is a lot more than what we want to do in 0.8. The issue is if we do not update, we need to add more checks to ensure it is already done or has failed. We can try to optimize that in trunk.;;;","28/Aug/13 04:19;sriramsub;Guozhang - We have not merged addpartition to trunk yet. We plan to do once we merge the 0.8 code to trunk.;;;","28/Aug/13 13:23;nehanarkhede;+1 on v3. Also, it will be good to file a separate JIRA for Swapnil's suggestion #27;;;","28/Aug/13 13:24;nehanarkhede;Thanks for the patches, committed v3 to 0.8;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
java.lang.OutOfMemoryError: Java heap space,KAFKA-682,12626080,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,rngadam,rngadam,05/Jan/13 02:14,12/Jul/13 06:17,22/Mar/23 15:10,12/Jul/13 06:17,0.8.0,,,,,,,,,,,,,core,,,,0,,,,,,"git pull (commit 32dae955d5e2e2dd45bddb628cb07c874241d856)

...build...

./sbt update
./sbt package

...run...

bin/zookeeper-server-start.sh config/zookeeper.properties
bin/kafka-server-start.sh config/server.properties

...then configured fluentd with kafka plugin...

gem install fluentd --no-ri --no-rdoc
gem install fluent-plugin-kafka
fluentd -c ./fluent/fluent.conf -vv

...then flood fluentd with messages inputted from syslog and outputted to kafka.

results in (after about 10000 messages of 1K each in 3s):

[2013-01-05 02:00:52,087] ERROR Closing socket for /127.0.0.1 because of error (kafka.network.Processor)
java.lang.OutOfMemoryError: Java heap space
    at kafka.api.ProducerRequest$$anonfun$1$$anonfun$apply$1.apply(ProducerRequest.scala:45)
    at kafka.api.ProducerRequest$$anonfun$1$$anonfun$apply$1.apply(ProducerRequest.scala:42)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
    at scala.collection.immutable.Range$ByOne$class.foreach(Range.scala:282)
    at scala.collection.immutable.Range$$anon$1.foreach(Range.scala:274)
    at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)
    at scala.collection.immutable.Range.map(Range.scala:39)
    at kafka.api.ProducerRequest$$anonfun$1.apply(ProducerRequest.scala:42)
    at kafka.api.ProducerRequest$$anonfun$1.apply(ProducerRequest.scala:38)
    at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:227)
    at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:227)
    at scala.collection.immutable.Range$ByOne$class.foreach(Range.scala:282)
    at scala.collection.immutable.Range$$anon$1.foreach(Range.scala:274)
    at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:227)
    at scala.collection.immutable.Range.flatMap(Range.scala:39)
    at kafka.api.ProducerRequest$.readFrom(ProducerRequest.scala:38)
    at kafka.api.RequestKeys$$anonfun$1.apply(RequestKeys.scala:32)
    at kafka.api.RequestKeys$$anonfun$1.apply(RequestKeys.scala:32)
    at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:47)
    at kafka.network.Processor.read(SocketServer.scala:298)
    at kafka.network.Processor.run(SocketServer.scala:209)
    at java.lang.Thread.run(Thread.java:722)
","$ uname -a
Linux rngadam-think 3.5.0-17-generic #28-Ubuntu SMP Tue Oct 9 19:32:08 UTC 2012 i686 i686 i686 GNU/Linux
$ java -version
java version ""1.7.0_09""
OpenJDK Runtime Environment (IcedTea7 2.3.3) (7u9-2.3.3-0ubuntu1~12.04.1)
OpenJDK Server VM (build 23.2-b09, mixed mode)",jjkoshy,jkreps,junrao,nehanarkhede,rngadam,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jan/13 16:14;rngadam;java_pid22281.hprof.gz;https://issues.apache.org/jira/secure/attachment/12563466/java_pid22281.hprof.gz","06/Jan/13 16:14;rngadam;java_pid22281_Leak_Suspects.zip;https://issues.apache.org/jira/secure/attachment/12563467/java_pid22281_Leak_Suspects.zip",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,302663,,,Thu Jul 11 22:17:15 UTC 2013,,,,,,,,,,"0|i174lj:",249713,,,,,,,,,,,,,,,,,,,,"05/Jan/13 03:13;jjkoshy;You might need to increase your heap size. What do you have it set to right now? Would you be able to run the broker with -XX:+HeapDumpOnOutOfMemoryError to get a heap-dump?

In case you are overriding defaults - what's the replication factor for the topic, num-required-acks for the producer requests, and producer request timeout? Are any requests going through or are the produce requests expiring?
;;;","05/Jan/13 07:04;junrao;That commit is in trunk. Could you try the current head in 0.8 (which fixed one OOME issue KAFKA-664)?;;;","05/Jan/13 09:35;jjkoshy;I think that fix was merged into trunk (before 32da) so it should be there in trunk as well.;;;","06/Jan/13 16:12;rngadam;After filing the bug initially, I switched to these settings (and then added the HeapDump directive):

bin/kafka-run-class.sh

KAFKA_OPTS=""-server -Xms1024m -Xmx1024m -XX:NewSize=256m -XX:MaxNewSize=256m -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -Xloggc:logs/gc.log -Djava.awt.headless=true -Dlog4j.configuration=file:$base_dir/config/log4j.properties -XX:+HeapDumpOnOutOfMemoryError""

Shouldn't these be set more aggressively as per the operational suggestions? It's probably better to have the user lower them than to have to make them higher.

I've downloaded MAT for Eclipse and ran it on the hprof. It points out two issues of which this is the more noticeable:

One instance of ""java.nio.HeapByteBuffer"" loaded by ""<system class loader>"" occupies 8,404,016 (58.22%) bytes. The instance is referenced by kafka.network.BoundedByteBufferReceive @ 0x7ad6a038 , loaded by ""sun.misc.Launcher$AppClassLoader @ 0x7ad00d40"". The memory is accumulated in one instance of ""byte[]"" loaded by ""<system class loader>""

;;;","06/Jan/13 16:14;rngadam;the hprof dump;;;","08/Jan/13 05:19;junrao;BoundedByteBufferReceive is used for receiving client requests. Most of the space is likely taken by ProducerRequest. If you are sending many large ProducerRequests, the result in the head dump makes sense. Do you still see OOME with the new JVM setting? You heap size seems small. I would try 3-4GBs.;;;","08/Jan/13 05:30;nehanarkhede;I think this is the cause - https://issues.apache.org/jira/browse/KAFKA-671;;;","09/Jan/13 03:11;jjkoshy;That's why I asked  for the configured ""num-required-acks for the producer requests"". If it is the default (0) then it shouldn't be added to the request purgatory which rule out KAFKA-671 no?;;;","18/Jan/13 13:25;jkreps;Yes, Joel, that makes sense. Ricky, do you know the ""acks"" setting being used in the requests the ruby client is sending?;;;","12/Jul/13 06:17;jkreps;Marking resolved as we fixed a 0.8 bug that impacted memory and improved the default GC settings.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZookeeperConsumerConnector could put multiple shutdownCommand to the same data chunk queue.,KAFKA-1764,12754355,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,becket_qin,becket_qin,11/Nov/14 11:25,15/Nov/14 03:08,22/Mar/23 15:10,15/Nov/14 02:15,,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"In ZookeeperConsumerConnector shutdown(), we could potentially put multiple shutdownCommand into the same data chunk queue, provided the topics are sharing the same data chunk queue in topicThreadIdAndQueues.

From email thread to document:

In ZookeeperConsumerConnector shutdown(), we could potentially put
multiple shutdownCommand into the same data chunk queue, provided the
topics are sharing the same data chunk queue in topicThreadIdAndQueues.

In our case, we only have 1 consumer stream for all the topics, the data
chunk queue capacity is set to 1. The execution sequence causing problem is
as below:
1. ZookeeperConsumerConnector shutdown() is called, it tries to put
shutdownCommand for each queue in topicThreadIdAndQueues. Since we only
have 1 queue, multiple shutdownCommand will be put into the queue.
2. In sendShutdownToAllQueues(), between queue.clean() and
queue.put(shutdownCommand), consumer iterator receives the shutdownCommand
and put it back into the data chunk queue. After that,
ZookeeperConsumerConnector tries to put another shutdownCommand into the
data chunk queue but will block forever.

The thread stack trace is as below:
{code}
""Thread-23"" #58 prio=5 os_prio=0 tid=0x00007ff440004800 nid=0x40a waiting
on condition [0x00007ff4f0124000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x0000000680b96bf0> (a
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at
java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at
java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:350)
        at
kafka.consumer.ZookeeperConsumerConnector$$anonfun$sendShutdownToAllQueues$1.apply(ZookeeperConsumerConnector.scala:262)
        at
kafka.consumer.ZookeeperConsumerConnector$$anonfun$sendShutdownToAllQueues$1.apply(ZookeeperConsumerConnector.scala:259)
        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        at
scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
        at
kafka.consumer.ZookeeperConsumerConnector.sendShutdownToAllQueues(ZookeeperConsumerConnector.scala:259)
        at
kafka.consumer.ZookeeperConsumerConnector.liftedTree1$1(ZookeeperConsumerConnector.scala:199)
        at
kafka.consumer.ZookeeperConsumerConnector.shutdown(ZookeeperConsumerConnector.scala:192)
        - locked <0x0000000680dd5848> (a java.lang.Object)
        at
kafka.tools.MirrorMaker$$anonfun$cleanShutdown$1.apply(MirrorMaker.scala:185)
        at
kafka.tools.MirrorMaker$$anonfun$cleanShutdown$1.apply(MirrorMaker.scala:185)
        at scala.collection.immutable.List.foreach(List.scala:318)
        at kafka.tools.MirrorMaker$.cleanShutdown(MirrorMaker.scala:185)
{code}",,becket_qin,copester,jjkoshy,junrao,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Nov/14 06:59;becket_qin;KAFKA-1764.patch;https://issues.apache.org/jira/secure/attachment/12680932/KAFKA-1764.patch","13/Nov/14 06:05;becket_qin;KAFKA-1764_2014-11-12_14:05:35.patch;https://issues.apache.org/jira/secure/attachment/12681152/KAFKA-1764_2014-11-12_14%3A05%3A35.patch","14/Nov/14 15:57;becket_qin;KAFKA-1764_2014-11-13_23:57:51.patch;https://issues.apache.org/jira/secure/attachment/12681506/KAFKA-1764_2014-11-13_23%3A57%3A51.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 14 18:14:57 UTC 2014,,,,,,,,,,"0|i227rr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"12/Nov/14 06:59;becket_qin;Created reviewboard https://reviews.apache.org/r/27890/diff/
 against branch origin/trunk;;;","13/Nov/14 06:05;becket_qin;Updated reviewboard https://reviews.apache.org/r/27890/diff/
 against branch origin/trunk;;;","14/Nov/14 10:14;jjkoshy;Committed to trunk.

[~junrao] do you think this should be in 0.8.2 as well?;;;","14/Nov/14 10:25;junrao;[~jjkoshy], since the patch is small, I think we can include it in 0.8.2.;;;","14/Nov/14 11:24;copester;Why do builds always break just as I put the kids to sleep and grab a glass of wine?;;;","14/Nov/14 11:26;copester;{code}
/home/bamboo/bamboo-agent-home/xml-data/build-dir/STREAM-KAFKA-JOB1/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala:259: missing parameter type
    for (queue <- topicThreadIdAndQueues.values.toSet) {
         ^
one error found
{code};;;","14/Nov/14 13:00;jjkoshy;That was my bad - I should have double-checked that before check-in. [~copester] thanks for pointing it out. I can't dig into it now so I reverted the checkin. [~becket_qin] please take a look;;;","14/Nov/14 13:16;becket_qin;My bad... I tested the toSet on scala commandLine and assumed it would work. I also realized that there are some unit tests that need change as well. I'll submit a new patch.;;;","14/Nov/14 15:57;becket_qin;Updated reviewboard https://reviews.apache.org/r/27890/diff/
 against branch origin/trunk;;;","14/Nov/14 16:42;sslavic;Is this issue duplicate of KAFKA-1716 ?;;;","14/Nov/14 22:00;copester;This now builds and all 547 tests pass. Thanks!;;;","15/Nov/14 02:14;jjkoshy;Thanks for the fix. Committed to trunk and 0.8.2;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unit tests which dont close producers auto-create topics in Kafka brokers of other tests when port is reused,KAFKA-3217,12937435,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,rsivaram,rsivaram,rsivaram,08/Feb/16 16:16,10/Feb/16 01:50,22/Mar/23 15:10,10/Feb/16 01:49,0.9.0.0,,,,,,0.10.0.0,,,,,,,unit tests,,,,0,,,,,,"Consumer tests occasionally fail the exception:

{quote}
kafka.common.TopicExistsException: Topic ""topic"" already exists.
        at kafka.admin.AdminUtils$.createOrUpdateTopicPartitionAssignmentPathInZK(AdminUtils.scala:261)
        at kafka.admin.AdminUtils$.createTopic(AdminUtils.scala:245)
        at kafka.utils.TestUtils$.createTopic(TestUtils.scala:237)
        at kafka.api.BaseConsumerTest.setUp(BaseConsumerTest.scala:65)
{quote}

Recreated this failure with some additional logging and it turns out that the failure is because a few tests which create a topic named ""topic"" close their Kafka server, but not the producer. When the ephemeral port used by the closed Kafka server gets reused in another Kafka server in a subsequent test, the producer retries of the previous test cause ""topic"" to be recreated using auto-create in the new Kafka server of the subsequent test.  This results in an error in the consumer tests occasionally when the topic is auto-created before the test attempts to create it.

",,ewencp,githubbot,ijuma,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Feb 09 17:50:03 UTC 2016,,,,,,,,,,"0|i2sjlz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"08/Feb/16 16:19;ijuma;Nice find!;;;","08/Feb/16 16:34;githubbot;GitHub user rajinisivaram opened a pull request:

    https://github.com/apache/kafka/pull/882

    KAFKA-3217: Close producers in unit tests

    Producers that are not closed auto-create topics in subsequent tests when Kafka server port is reused. Added missing close().

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/rajinisivaram/kafka KAFKA-3217

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/882.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #882
    
----
commit 30e7ed8e4d228aff9b5dd26ba523ece7cbb565dc
Author: Rajini Sivaram <rajinisivaram@googlemail.com>
Date:   2016-02-08T08:30:03Z

    KAFKA-3217: Close producers in unit tests

----
;;;","10/Feb/16 01:49;ewencp;Issue resolved by pull request 882
[https://github.com/apache/kafka/pull/882];;;","10/Feb/16 01:50;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/882
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka does not compile with sbt,KAFKA-1095,12674824,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,,mailq,mailq,22/Oct/13 00:21,21/Mar/14 05:45,22/Mar/23 15:10,21/Mar/14 05:45,0.10.1.0,,,,,,,,,,,,,packaging,,,,0,,,,,,"Expected behaviour:
After `git pull`, `./sbt update` and `./sbt package` the current snapshot version should compile without errors.

Current behaviour:
It fails with different error messages. This is one possible error log: https://gist.github.com/mumrah/7086356
With `./sbt ""++2.10.1 package""` the errors are different but still results in a failed compile. Other scala versions fail, too.

The responsible commit which leads to the error messages is unknown to me.","Linux 64bit, OpenJDK 1.7",guozhang,jkreps,jobswang,junrao,jvanremoortere,mailq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,354446,,,Thu Mar 20 21:45:02 UTC 2014,,,,,,,,,,"0|i1p3uv:",354736,,,,,,,,,,,,,,,,,,,,"22/Oct/13 00:28;mailq;with `./sbt ""++2.9.2 package""` produces many warnings but finally compiles. But other versions must be repaired.;;;","22/Oct/13 00:35;guozhang;This is due one current jira KAFKA-1042, with the last comment.;;;","22/Oct/13 02:09;jvanremoortere;I added a patch (v3) to KAFKA-1042 to fix this error.;;;","29/Jan/14 22:02;jobswang;Does compiling kafka with sbt support scala 2.9.3? ;;;","29/Jan/14 23:22;junrao;Not sure, could you try adding 2.9.3 to the sbt build file?;;;","05/Feb/14 18:02;jobswang;i add 2.9.3 to sbt build file, but report errors!;;;","21/Mar/14 05:45;jkreps;We moved off sbt so presumably this is no longer valid.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Log Compaction documentation still says compressed messages are not supported,KAFKA-3023,12923525,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,gwenshap,gwenshap,22/Dec/15 03:19,24/Jan/16 18:25,22/Mar/23 15:10,24/Jan/16 18:25,,,,,,,,,,,,,,,,,,0,,,,,,"Looks like we can now compact topics with compressed messages  (https://issues.apache.org/jira/browse/KAFKA-1374) but the docs still say we can't:
http://kafka.apache.org/documentation.html#design_compactionlimitations",,ewencp,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3138,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Jan 24 10:24:50 UTC 2016,,,,,,,,,,"0|i2q6cn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"24/Jan/16 18:24;ewencp;Marking dup of newer bug since KAFKA-3138 has a patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Revisit defaults for the internal offsets topic,KAFKA-1864,12767579,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,junrao,nehanarkhede,nehanarkhede,15/Jan/15 07:12,25/Feb/15 12:28,22/Mar/23 15:10,17/Jan/15 10:57,0.8.2.0,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"Realize this is late, but as I was reviewing the 0.8.2 RC, I found that our defaults for the offsets topic are not ideal. The # of partitions currently default to 1 and the replication factor is 1 as well. Granted that the replication factor is changeable in the future (through the admin tool), changing the # of partitions is a very disruptive change. The concern is that this feature is on by default on the server and will be activated the moment the first client turns on kafka based offset storage. 

My proposal is to change the # of partitions to something large (50 or so) and change the replication factor to min(# of alive brokers, configured replication factor)",,guozhang,gwenshap,junrao,nehanarkhede,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1846,,,,,,KAFKA-1846,,,,,,,,,,"16/Jan/15 08:52;junrao;kafka-1864.patch;https://issues.apache.org/jira/secure/attachment/12692652/kafka-1864.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Feb 25 04:28:10 UTC 2015,,,,,,,,,,"0|i24dvb:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"16/Jan/15 08:52;junrao;Created reviewboard https://reviews.apache.org/r/29952/diff/
 against branch origin/0.8.2;;;","16/Jan/15 08:53;junrao;Attached is a patch. A couple of the unit tests fail because of KAFKA-1867. Fixing KAFKA-1867 is a bit tricky and we probably don't want to do that in 0.8.2. So, patching the unit test by overriding the default value for offsets.topic.replication.factor for now.
;;;","16/Jan/15 09:41;junrao;Also, another impact in this patch is that the offset topic may not be guaranteed to be created with the configured offset replication factor since we take the min btw the configured value and the # of live brokers. An alternative is to use negative values as suggested in KAFKA-1846 as the default. Then we can treat the positive values as the hard requirement. Not sure if this will cause more confusing.;;;","17/Jan/15 10:57;junrao;Thanks for the reviews. Committed to 0.8.2 and trunk.;;;","17/Jan/15 11:01;omkreddy;Will this also fixes KAFKA-1846?;;;","17/Jan/15 11:07;junrao;Yes, thanks for the reminder.;;;","25/Feb/15 04:03;guozhang;I did not realize the change of ""Math.min(config.offsetsTopicReplicationFactor, aliveBrokers.length)"" until encountered some new consumer test failures due to this. 

In practice the __consumer_offsets topic should be created as part of the Kafka cluster starting up process, but today it will only be done so when the first consumer fetch comes and hence it is likely we are not guaranteeing the offset replication factor. 

I think in general we should always honor the offset replication factor, and when there are not enough # of live brokers we should not proceed with the topic creation and return error code to the clients asking metadata, I am OK with negative values indicating soft requirements though. What do you think [~junrao]?;;;","25/Feb/15 12:28;gwenshap;Probably not the right place for this discussion, but negative values indicating various configuration ""magic"" is not very intuitive.

There has to be a better way to do things.  Maybe an extra configuration that will mean ""if not enough brokers exist, create topic anyway on however many brokers we have""? 

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Messages silently Lost by producer,KAFKA-1702,12747623,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,alexismidon,alexismidon,alexismidon,13/Oct/14 07:42,14/Oct/14 07:17,22/Mar/23 15:10,14/Oct/14 07:17,0.8.1.1,,,,,,0.9.0.0,,,,,,,producer ,,,,0,,,,,,"
Hello,

we lost millions of messages because of this {{try/catch}} in  the producer {{DefaultEventHandler}}:
https://github.com/apache/kafka/blob/0.8.1/core/src/main/scala/kafka/producer/async/DefaultEventHandler.scala#L114-L116

If a Throwable is caught by this {{try/catch}}, the retry policy will have no effect and all yet-to-be-sent messages are lost (the error will break the loop over the broker list).
This issue is very hard to detect because: the producer (async or sync) cannot even catch the error, and *all* the metrics are updated as if everything was fine.

Only the abnormal drop in the producers network I/O, or the incoming message rate on the brokers; or the alerting on errors in producer logs could have revealed the issue. 

This behavior was introduced by KAFKA-300. I can't see a good reason for it, so here is a patch that will let the retry-policy do its job when such a {{Throwable}} occurs.

Thanks in advance for your help.

Alexis

ps: you might wonder how could this {{try/catch}} ever caught something? {{DefaultEventHandler#groupMessagesToSet}} looks so harmless. 

Here are the details:
We use Snappy compression. When the native snappy library is not installed on the host, Snappy, during the initialization of class {{org.xerial.snappy.Snappy}}  will [write a C library|https://github.com/xerial/snappy-java/blob/1.1.0/src/main/java/org/xerial/snappy/SnappyLoader.java#L312] in the JVM temp directory {{java.io.tmpdir}}.

In our scenario, {{java.io.tmpdir}} was a subdirectory of {{/tmp}}. After an instance reboot (thank you [AWS|https://twitter.com/hashtag/AWSReboot?src=hash]!), the JVM temp directory was removed. The JVM was then running with a non-existing temp dir. Snappy class would be impossible to initialize and the following message would be silently logged:

{code}
ERROR [2014-10-07 22:23:56,530] kafka.producer.async.DefaultEventHandler: Failed to send messages
! java.lang.NoClassDefFoundError: Could not initialize class org.xerial.snappy.Snappy
{code}

",,alexismidon,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Oct/14 07:45;alexismidon;KAFKA-1702.0.patch;https://issues.apache.org/jira/secure/attachment/12674438/KAFKA-1702.0.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Oct 13 23:17:03 UTC 2014,,,,,,,,,,"0|i21353:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"13/Oct/14 12:15;junrao;Thanks for the patch. Not sure why you want to wrap groupMessagesToSet in try/catch. I thought that's where the NoClassDefFoundError is thrown and you want to propagate it to the caller.

With this patch, the producer in sync mode will get the exception. However, producer in async mode will still silently dropping messages. This is a general limitation and is being fixed in the new java producer through a callback.;;;","13/Oct/14 12:32;alexismidon;I agree. In the async mode, until there is a callback, the best we can do is to make sure all the metrics are updated correctly, in particular ResendsPerSec, FailedSendsPerSec, which is critical for monitoring of async producers.

In the sync mode, producer will get the exception, which is an improvement.

thanks for your review;;;","13/Oct/14 12:35;alexismidon;Also if #groupMessagesToSet is not in a try/catch, the error will break the loop on the broker list. All messages will get dropped, retries ignored, metrics won't get updated, etc.;;;","14/Oct/14 07:17;junrao;Got it. +1 for the patch. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
offsets.topic.segment.bytes and offsets.topic.retention.minutes are ignored,KAFKA-2159,12826302,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,omkreddy,boniek,boniek,30/Apr/15 21:35,17/May/16 20:52,22/Mar/23 15:10,17/May/16 20:52,0.8.2.1,,,,,,,,,,,,,offset manager,,,,0,newbie,,,,,"My broker configuration:

{quote}offsets.topic.num.partitions=20
offsets.topic.segment.bytes=10485760
offsets.topic.retention.minutes=10080{quote}

Describe of __consumer_offsets topic:

{quote}Topic:__consumer_offsets	PartitionCount:20	ReplicationFactor:3	Configs:segment.bytes=104857600,cleanup.policy=compact
	Topic: __consumer_offsets	Partition: 0	Leader: 112	Replicas: 112,212,312	Isr: 212,312,112
	Topic: __consumer_offsets	Partition: 1	Leader: 212	Replicas: 212,312,412	Isr: 212,312,412
	Topic: __consumer_offsets	Partition: 2	Leader: 312	Replicas: 312,412,512	Isr: 312,412,512
	Topic: __consumer_offsets	Partition: 3	Leader: 412	Replicas: 412,512,112	Isr: 412,512,112
	Topic: __consumer_offsets	Partition: 4	Leader: 512	Replicas: 512,112,212	Isr: 512,212,112
	Topic: __consumer_offsets	Partition: 5	Leader: 112	Replicas: 112,312,412	Isr: 312,412,112
	Topic: __consumer_offsets	Partition: 6	Leader: 212	Replicas: 212,412,512	Isr: 212,412,512
	Topic: __consumer_offsets	Partition: 7	Leader: 312	Replicas: 312,512,112	Isr: 312,512,112
	Topic: __consumer_offsets	Partition: 8	Leader: 412	Replicas: 412,112,212	Isr: 412,212,112
	Topic: __consumer_offsets	Partition: 9	Leader: 512	Replicas: 512,212,312	Isr: 512,212,312
	Topic: __consumer_offsets	Partition: 10	Leader: 112	Replicas: 112,412,512	Isr: 412,512,112
	Topic: __consumer_offsets	Partition: 11	Leader: 212	Replicas: 212,512,112	Isr: 212,512,112
	Topic: __consumer_offsets	Partition: 12	Leader: 312	Replicas: 312,112,212	Isr: 312,212,112
	Topic: __consumer_offsets	Partition: 13	Leader: 412	Replicas: 412,212,312	Isr: 412,212,312
	Topic: __consumer_offsets	Partition: 14	Leader: 512	Replicas: 512,312,412	Isr: 512,312,412
	Topic: __consumer_offsets	Partition: 15	Leader: 112	Replicas: 112,512,212	Isr: 512,212,112
	Topic: __consumer_offsets	Partition: 16	Leader: 212	Replicas: 212,112,312	Isr: 212,312,112
	Topic: __consumer_offsets	Partition: 17	Leader: 312	Replicas: 312,212,412	Isr: 312,212,412
	Topic: __consumer_offsets	Partition: 18	Leader: 412	Replicas: 412,312,512	Isr: 412,312,512
	Topic: __consumer_offsets	Partition: 19	Leader: 512	Replicas: 512,412,112	Isr: 512,412,112{quote}

OffsetManager logs:

{quote}2015-04-29 17:58:43:403 CEST DEBUG [kafka-scheduler-3][kafka.server.OffsetManager] Compacting offsets cache.
2015-04-29 17:58:43:403 CEST DEBUG [kafka-scheduler-3][kafka.server.OffsetManager] Found 1 stale offsets (older than 86400000 ms).
2015-04-29 17:58:43:404 CEST TRACE [kafka-scheduler-3][kafka.server.OffsetManager] Removing stale offset and metadata for [drafts,tasks,1]: OffsetAndMetadata[824,consumer_id = drafts, time = 1430322433,0]
2015-04-29 17:58:43:404 CEST TRACE [kafka-scheduler-3][kafka.server.OffsetManager] Marked 1 offsets in [__consumer_offsets,2] for deletion.
2015-04-29 17:58:43:404 CEST DEBUG [kafka-scheduler-3][kafka.server.OffsetManager] Removed 1 stale offsets in 1 milliseconds.{quote}

Parameters are ignored and default values are used instead.",,boniek,jjkoshy,manasvigupta,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3718,,,,,,,,,,,,,,,,,,"15/Jun/15 19:22;omkreddy;KAFKA-2159.patch;https://issues.apache.org/jira/secure/attachment/12739589/KAFKA-2159.patch","17/Jun/15 14:19;omkreddy;KAFKA-2159_2015-06-17_11:44:03.patch;https://issues.apache.org/jira/secure/attachment/12740043/KAFKA-2159_2015-06-17_11%3A44%3A03.patch","10/Jul/15 23:47;omkreddy;KAFKA-2159_2015-07-10_21:14:26.patch;https://issues.apache.org/jira/secure/attachment/12744730/KAFKA-2159_2015-07-10_21%3A14%3A26.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Aug 07 14:53:52 UTC 2015,,,,,,,,,,"0|i2e52f:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"30/Apr/15 21:58;boniek;Possible reasons: offsets.topic.retention.minutes is actually called offsets.retention.minutes (documentation bug?), offsetsTopicSegmentBytes parameter is not passed in KafkaServer.createOffsetManager();;;","15/Jun/15 19:22;omkreddy;Created reviewboard https://reviews.apache.org/r/35454/diff/
 against branch origin/trunk;;;","15/Jun/15 19:29;omkreddy;[~jjkoshy] Currently  ""offsets.topic.compression.codec"" config property is not used. compression type is hard-coded to ""uncompressed"". Do you think we can use this config property now?;;;","17/Jun/15 02:27;jjkoshy;Yes.;;;","17/Jun/15 14:19;omkreddy;Updated reviewboard https://reviews.apache.org/r/35454/diff/
 against branch origin/trunk;;;","10/Jul/15 23:47;omkreddy;Updated reviewboard https://reviews.apache.org/r/35454/diff/
 against branch origin/trunk;;;","07/Aug/15 22:53;omkreddy;[~jjkoshy] pinging for review;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Auto-assign node id,KAFKA-1070,12671970,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriharsha,jkreps,jkreps,02/Oct/13 23:59,19/Dec/15 00:59,22/Mar/23 15:10,13/Jan/15 07:46,,,,,,,0.9.0.0,,,,,,,,,,,3,usability,,,,,"It would be nice to have Kafka brokers auto-assign node ids rather than having that be a configuration. Having a configuration is irritating because (1) you have to generate a custom config for each broker and (2) even though it is in configuration, changing the node id can cause all kinds of bad things to happen.",,amuraru,ancoron,astubbs,clarkhaskins,CpuID,hakman,jkreps,joestein,nehanarkhede,otis,paetling,sriharsha,wangbo23,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3012,,,,,,,,,,"19/Jul/14 08:24;sriharsha;KAFKA-1070.patch;https://issues.apache.org/jira/secure/attachment/12656678/KAFKA-1070.patch","20/Jul/14 07:06;sriharsha;KAFKA-1070_2014-07-19_16:06:13.patch;https://issues.apache.org/jira/secure/attachment/12656763/KAFKA-1070_2014-07-19_16%3A06%3A13.patch","23/Jul/14 02:34;sriharsha;KAFKA-1070_2014-07-22_11:34:18.patch;https://issues.apache.org/jira/secure/attachment/12657155/KAFKA-1070_2014-07-22_11%3A34%3A18.patch","25/Jul/14 11:58;sriharsha;KAFKA-1070_2014-07-24_20:58:17.patch;https://issues.apache.org/jira/secure/attachment/12657765/KAFKA-1070_2014-07-24_20%3A58%3A17.patch","25/Jul/14 12:05;sriharsha;KAFKA-1070_2014-07-24_21:05:33.patch;https://issues.apache.org/jira/secure/attachment/12657767/KAFKA-1070_2014-07-24_21%3A05%3A33.patch","22/Aug/14 01:26;sriharsha;KAFKA-1070_2014-08-21_10:26:20.patch;https://issues.apache.org/jira/secure/attachment/12663433/KAFKA-1070_2014-08-21_10%3A26%3A20.patch","21/Nov/14 02:50;sriharsha;KAFKA-1070_2014-11-20_10:50:04.patch;https://issues.apache.org/jira/secure/attachment/12682709/KAFKA-1070_2014-11-20_10%3A50%3A04.patch","26/Nov/14 12:29;sriharsha;KAFKA-1070_2014-11-25_20:29:37.patch;https://issues.apache.org/jira/secure/attachment/12683762/KAFKA-1070_2014-11-25_20%3A29%3A37.patch","02/Jan/15 09:39;sriharsha;KAFKA-1070_2015-01-01_17:39:30.patch;https://issues.apache.org/jira/secure/attachment/12689762/KAFKA-1070_2015-01-01_17%3A39%3A30.patch","13/Jan/15 02:47;sriharsha;KAFKA-1070_2015-01-12_10:46:54.patch;https://issues.apache.org/jira/secure/attachment/12691693/KAFKA-1070_2015-01-12_10%3A46%3A54.patch","13/Jan/15 10:30;sriharsha;KAFKA-1070_2015-01-12_18:30:17.patch;https://issues.apache.org/jira/secure/attachment/12691827/KAFKA-1070_2015-01-12_18%3A30%3A17.patch",,,,,,,,,,,,,,,,,11.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,351596,,,Tue Sep 08 14:57:59 UTC 2015,,,,,,,,,,"0|i1omd3:",351885,,nehanarkhede,,,,,,,,,,,,,,,,,,"03/Oct/13 00:06;jkreps;I think the right way to do this is to have a sequence in zookeeper that atomically increments and use this for id generation. On startup a node that has no id can generate one for itself and store it.

One tricky bit is that this node id needs to be stored with the data, but we actually partition data up over multiple disks now and hope to be able to survive the destruction of any of them. Which disk should we store the node id on? I would recommend we store it on all of them--if it is missing on some we will add it there, if the id is inconsistent between disks we will error out (this should never happen).

I would recommend adding a properties file named ""meta"" in every data directory containing the ""id=x"" value, we can extend this later with more perminant values. For example, I think it would be nice to add a data format version to help with in-place data upgrades.

On startup the broker would check this value for consistency across directories. If it is not present in any directory it would auto-generate a node id and persist that for future use.

For compatibility we would retain the current id configuration value--if it is present we will use it and ensure the id sequence is larger than this value.;;;","08/May/14 01:06;ancoron;For me, a solution that generates a unique ID by itself would also be fine.

E.g. as a workaround, I currently generate an integer based on the MAC address from the interface that clients are configured to see. However, this is not reliably unique, because a MAC address is 48-bit and the broker-ID is only a signed 32-bit integer, a long would be better fit here.

Going further on standalone generation of unique IDs, within applications I am used to rely on something that does provide me some guarantees. A UUID of Type 1 (MAC/timestamp-based) is exactly that. However, here the problem is even worse, because a UUID is a 128-bit number.

My question here would be (and I am not yet very much into the Kafka code base - so please excuse if this is a very dumb question): what is the brokerId actually being used for? In other words: which requirements does it have to fulfill and what functionality relies on it being unique inside a cluster?

Another question is: why does it have to be a non-negative integer?;;;","18/Jul/14 06:12;sriharsha;[~jkreps] [~nehanarkhede]
I am working on this JIRA. Following the proposed design in the comments. I see there might be a issue  where
one of the broker configs have broker.id defined as 0 and another one doesn't have broker.id. If the second broker started first we fetch a global sequence id from zookeeper that starts with 0 and the next one has already have a defined config we will use that in this case we have two brokers with same id. Should we consider this case in which a kafka cluster's broker might have a inconsistent config interms of broker.id.
Instead of using zookeeper for generating a global sequence number why shouldn't we be using UUID and make brokerId Long type. 
Thanks.;;;","18/Jul/14 06:42;jkreps;Hey [~harsha_ch], that is a great point.

I'd like to avoid changing the type of the id to a long or UUID so as to not have to bump up the protocol format for the metadata request which hands these out to clients (we would need a way to handle compatibility with older clients that don't expect the longer types).

I think we can get around the problem you point out by just defaulting the node id sequence to 1000. This could theoretically conflict but most people number from 0 or 1 and we can discuss this in the release notes. Our plan will be to release with support for both configured node ids and assigned node ids for compatibility. After a couple of releases we will remove the config.

So the behavior would be this:
If there is a node id in the config we will validate it against the node id in the data directory
If it matches that good, we'll use that.
If it doesn't match that is bad, we'll crash with an error.
If there is a node id in the data directory but none in the config, we'll use whatever is in the data directory.
If there is no node id in the data directory yet but there is  one in the config we'll write that to the data directory and use it.
If there is neither a node id in the data directory nor in the config we'll allocate a node id and write it to the data directory.
;;;","19/Jul/14 08:24;sriharsha;Created reviewboard https://reviews.apache.org/r/23702/diff/
 against branch origin/trunk;;;","19/Jul/14 08:25;sriharsha;Thanks [~jkreps];;;","20/Jul/14 07:06;sriharsha;Updated reviewboard https://reviews.apache.org/r/23702/diff/
 against branch origin/trunk;;;","23/Jul/14 02:34;sriharsha;Updated reviewboard https://reviews.apache.org/r/23702/diff/
 against branch origin/trunk;;;","25/Jul/14 03:42;clarkhaskins;We currently have node IDs in the 0-10000 range. I think some better logic for identifying used node IDs is necessary rather than just starting from 1000. ;;;","25/Jul/14 05:14;jonbringhurst;[~clarkhaskins], [~sriharsha], having ReservedBrokerIdMaxValue as a configurable option (perhaps with a default of 1000) would probably solve clark's use case.

-Also, if I'm reading this right, it will ignore the broker ID if it's set in the config but out of the reserved range (set to -1). It will then create a generated broker ID to overwrite the one in the config. It might be nice to have the broker error out on startup if a broker.id is set in the config, but is out of range. A new broker ID should only be generated if an id isn't specified in the config AND the meta.properties doesn't exist (otherwise the config file wouldn't match the actual broker ID).- Edit: nevermind, my Scala reading skills aren't up to par. This isn't the case here.;;;","25/Jul/14 11:58;sriharsha;Updated reviewboard https://reviews.apache.org/r/23702/diff/
 against branch origin/trunk;;;","25/Jul/14 12:05;sriharsha;Updated reviewboard https://reviews.apache.org/r/23702/diff/
 against branch origin/trunk;;;","05/Aug/14 13:04;joestein;This sounds like a very cool and VERY useful feature. Excited to use it myself often.

I know of a few (>10) different clusters that not only use varying sized numbers for their broker.id but do so in what is a seemingly random (but not really when you think about it) way.

so in a cluster there may be broker.id that is 1721632 and another 172164875 and another 172162240 . Making your brokers by replacing ""."" in chef/puppet/salt/ansemble/etc type scripts and sometimes folks get more fancy just doing 2288, 2388, 17, 177 (where just the last two octets get used and ""."" is replaced). 

I am not saying I agree with this approach and I actively advocate away from doing this but in some/many scenarios it is the best/only way to automate their deploys for how things are setup.  It is also what seems to make sense when folks are building their automation scripts since they have no other option without doing more than they should be expected to-do (and the IP replace ""."" is so obvious to them, and it is).

So, for folks in these cases they would just pick the upper bound to be, lets say 17216255256 and then it would auto assign from there?

Is there some better way to go about this where you might have a start increment and and some exclusion list? or a way to see broker.id already had that and not use it?  I think a lot of folks would like to get having broker id be more continious and be easier to communicate but the desire to automate everything will outweigh that.  We could give them some sanity back with brokers 1,2,3,4,5,6,7,8,9,10,11,12 for a 12 node cluster.

not crucial and you may have already accounted for the scenario I brought up, but wanted to bring it up as a real use case for how people automate things.

it might be better for folks to manually migrate their scripts but not sure they would do it and if they did would have to decommission brokers which in a prod environment could take a few weeks/months.  If we let them start at 1 and exclude what they have then they can do it one at a time.  After taking down the first broker and bring it back up (empty) it is broker.id=1, and so on (and if they have a 5 they don't have to take it down), etc.

For new clusters this is a slam dunk and wouldn't want to hold up the feature for existing users that have already decided a work around as I don't know what the intent of this was or not. Some folks might not change knowing broker.id=17216520 sometimes is nice you just login to that box but talking about broker 17216520 over and over again is a pita.

;;;","05/Aug/14 22:37;sriharsha;[~charmalloc] Thanks for the comments. Currently the approach allows users to specify MaxBrokerId and kafka starts generating a sequence from MaxBrokerId + 1. If user specifies brokerId , kafka uses that instead of generating one from zookeeper.  In the current implementation we expect user configured broker.id to be less than MaxBrokerId.
The tricky case here is if the user have a cluster where some of the brokers have broker.id present  in their config and others don't. In this case we use MaxBrokerId (defaults to 1000) and start generating a sequenceId from there.
The issue with brokerId exception list is we do not know from which point to generate a sequenceId. 
In your example "" in a cluster there may be broker.id that is 1721632 and another 172164875 and another 172162240 ""
and user added another broker to the cluster without broker.id in config. If the user specifies that MaxReserveBrokerId is 172164875 than we can assign +1 to that new broker. If we take the approach of looking at brokerIds that exists in the cluster and generate a new one that doesn't exist or taken by a broker already(exclusion list as you suggested) than the problem would be how do we know what are all the broker.ids existed in the cluster one way to look at is zookeeper but a broker registers at zk after it starts. 
For ex: if a broker1 starts with 1721632 and broker2 starts with no broker.id than we generate 1721633 from zk and there is no guarantee that another broker has this same id  in their config. Of course we can have a exclusion list of brokerids in a config file but that feels cumbersome for the user to list out all the brokerids.
;;;","05/Aug/14 23:10;joestein;[~sriharsha] I understand.  What I am struggling with is this for new users or existing users?  For existing users what I have seen them do (at least a dozen times now) is to avoid the conflict of broker.id in the properties file (like you are saying) is to take the IP address, strip out the ""."" and use that (since IP is unique that is what they go with).  They do this in their automation scripts.  I have to imagine it is larger than I have seen as they all did this independently of each other as an intuitive way to make unique broker.id.;;;","06/Aug/14 07:37;sriharsha;[~jkreps] [~junrao] [~nehanarkhede] Can you please review the last patch I sent. Thanks.;;;","22/Aug/14 01:26;sriharsha;Updated reviewboard https://reviews.apache.org/r/23702/diff/
 against branch origin/trunk;;;","22/Aug/14 01:27;sriharsha;[~jkreps] [~junrao] [~nehanarkhede] Can you please review the latest patch. Thanks.;;;","23/Aug/14 07:18;nehanarkhede;In an attempt to keep up with reviews, assigning to [~jkreps] since he has most context on the patch. Feel free to reassign :);;;","08/Sep/14 21:32;sriharsha;[~nehanarkhede] [~junrao] [~jkreps] [~guozhang] Hi All, I am trying to get this patch reviewed. Please let me know if there is anything that need to be fixed with this patch. Thank you.;;;","04/Nov/14 07:21;otis;[~harsha_ch] - it looks like a number of people would really like to use IPs for broker.id.  There is a lot of interest in having that. Please see this thread: http://search-hadoop.com/m/4TaT4dTPKi1
Do you think this is something you could add to this patch, maybe as another broker ID assignment scheme/policy?
;;;","04/Nov/14 07:33;sriharsha;[~otis@apache.org] this patch pending the 0.8.2 release. Since the we have 0.8.2 branched out I'll upmerge this patch and add a configurable option to server.properties where if user prefers IP based broker Id we will generate that or use the seq id that I currently have as a default.
[~jkreps] [~nehanarkhede] [~junrao] please let me know if the above approach looks good to you. Thanks.;;;","04/Nov/14 12:02;otis;bq.  this patch pending the 0.8.2 release

Note this issue doesn't have Fix Version set to 0.8.2.  Maybe that's what you want? +1 from me -- it looks like a number of people would like to see this issue resolved!;;;","04/Nov/14 12:21;sriharsha;[~otis] Sorry I meant pending review after 0.8.2 release. Not planned for 0.8.2 release. I'll update the patch with ip as brokerid option.;;;","05/Nov/14 07:17;nehanarkhede;Sorry for the late review. Expect to get to this shortly.;;;","11/Nov/14 07:01;nehanarkhede;[~sriharsha] Would you mind rebasing your patch? Can help you review it in the next few days.;;;","11/Nov/14 07:04;sriharsha;[~nehanarkhede] will implement the requested ip based broker id as an option and send an updated patch. Try to get it done this week.;;;","21/Nov/14 02:50;sriharsha;Updated reviewboard https://reviews.apache.org/r/23702/diff/
 against branch origin/trunk;;;","21/Nov/14 02:57;sriharsha;[~nehanarkhede] [~charmalloc] [~otis]
Please take a look at the latest patch. I added broker.id.policy as a configurable option with ""ip"" and ""sequence"" .
I've few questions regarding ""ip"" based broker.id.
currently the patch expects /etc/hosts to be properly configured with an ip associated with the hostname.
1) should we ignore loopback ip
    i) if we don't consider loopback ip than on a single node machine with /etc/hosts is not being configured properly it will thrown an error
   ii) if we consider this than there is a same broker id being generate on multiple hosts or multiple brokers on a single host ( this could be the case in non loopback ips too)
2) broker.id is Int and there is a  possibility of  throwing  a NumberFormatException if the ip doesn't fit in Int.MaxValue
3) If a host contains multiple network interfaces which ip should we pick up. Current implementation takes whatever configured for the hostname in /etc/hosts which seems ok to me . 
Please let me know your thoughts on the above. Thanks.;;;","24/Nov/14 04:36;nehanarkhede;[~sriharsha] Reviewed your latest patch. Posted review comments on the rb.;;;","26/Nov/14 12:29;sriharsha;Updated reviewboard https://reviews.apache.org/r/23702/diff/
 against branch origin/trunk;;;","26/Nov/14 12:30;sriharsha;[~nehanarkhede] Thanks for the review. Updated the patch please take a look .;;;","17/Dec/14 02:17;sriharsha;[~nehanarkhede] Can you please take a look at the patch and also reply to your comments. Thanks.;;;","17/Dec/14 13:22;nehanarkhede;Thanks for the updated patch [~sriharsha]. Almost there. Left a few more cleanup comments.;;;","02/Jan/15 09:39;sriharsha;Updated reviewboard https://reviews.apache.org/r/23702/diff/
 against branch origin/trunk;;;","02/Jan/15 09:43;sriharsha;Thanks for the review [~nehanarkhede]. I updated the patch , please take a look when you get a chance . Thanks.;;;","10/Jan/15 07:40;nehanarkhede;[~sriharsha] There are still questions around the broker metadata file serialization. I've reviewed the latest patch and left my comments on the rb.;;;","10/Jan/15 07:49;sriharsha;Thanks [~nehanarkhede] . I'll send an updated patch.;;;","13/Jan/15 02:47;sriharsha;Updated reviewboard https://reviews.apache.org/r/23702/diff/
 against branch origin/trunk;;;","13/Jan/15 02:53;sriharsha;[~nehanarkhede] updated patch addresses 2 of your comments and I've replied to your other comments. Please check and let me know. Thank for the review.;;;","13/Jan/15 07:46;nehanarkhede;[~sriharsha] Thanks for your efforts in getting this patch in shape. Pushed to trunk;;;","13/Jan/15 10:30;sriharsha;Updated reviewboard https://reviews.apache.org/r/23702/diff/
 against branch origin/trunk;;;","19/Aug/15 05:37;paetling;Hello Kafka Geniuses,
     I have a question regarding this PR.  Some context: 
    We have started playing around with kafka 0.8.2.1 to build a data pipeline at the company I work at.  Initially, to get autoscaling with AWS working, we were mapping the IP of our boxes to our broker id.  For a while everything was good.  Today I realized (please correct me if I am wrong) that kafka assigns the replicas to a topic at topic creation time. These replicas are not modified later unless you specifically rebalance the cluster(this is different than ISR which can go from 0 servers to the set of replicas).  This leads to an interesting question on how to cycle in new boxes.  The easiest way seems to be to copy all data from one box to another, kill the old box and start the new box with the same broker.id.  This is not really easy when you do a direct mapping of IP -> broker.id.  
     So now we come to this Jira ticket.  I was wondering if you could enumerate for me how this auto-assign node id would deal with the cycling of a box.  If a bring down a box that was auto-assigned a broker.id of X and bring back up a new box, what will happen.  Will that new box have broker.id X as well?  What if I bring down two boxes with broker.id X and broker.id Y, what is the broker.id of the new box i spin up. 

Thanks for the help,
Alex
     ;;;","19/Aug/15 06:02;sriharsha;[~paetling] Here auto-assign node id is one-time op. Currently users have to declare a broker.id in server.properties and this is unique per broker in a cluster.
Whats this JIRA addressed is to allow users to not to declare broker.id instead kafka when it startsup acquire a sequnce id from zookeeper writes it into meta.properties to use as broker.id
once this is generated and written meta.properties it won't generate a new id. So the problem you are trying solve is not addressed by this JIRA it just allows users not to worry about declaring a broker.id in server.properties.;;;","19/Aug/15 21:55;paetling;Thank you for the help!   I appreciate it.   ;;;","04/Sep/15 21:08;amuraru;[~nehanarkhede] For some reason this patch was not applied correctly in trunk branch, I see an {{.orig}} file in the patch here:
https://github.com/apache/kafka/commit/b1b80860a01cc378cfada3549a3480f0773c3ff8#diff-d0716898c8daed9887ef83500ee0e16e;;;","04/Sep/15 22:38;sriharsha;[~amuraru] Patch is already merged into trunk.;;;","05/Sep/15 19:40;amuraru;Saw it, that's why I raised the flag here, the patch in trunk seems broken with the .orig file added. A new jira issue might be needed to fix it;;;","08/Sep/15 22:43;sriharsha;[~amuraru] I am not sure where you are seeing .orig file in the trunk. Can you paste the link to that file from here https://github.com/apache/kafka;;;","08/Sep/15 22:57;amuraru;[~harsha_ch] I see KAFKA-1973 already fixed that, nw :);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
WorkerSinkTask doesn't catch exceptions from rebalance callbacks,KAFKA-2886,12915861,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,hachikuji,ewencp,ewencp,25/Nov/15 01:36,16/Jan/16 01:29,22/Mar/23 15:10,16/Jan/16 01:29,,,,,,,0.10.0.0,,,,,,,KafkaConnect,,,,0,,,,,,"WorkerSinkTask exposes rebalance callbacks to tasks by invoking onPartitionsRevoked and onPartitionsAssigned on the task. However, these aren't guarded by try/catch blocks, so they can propagate the errors up to the consumer:

{quote}
[2015-11-24 15:52:24,071] ERROR User provided listener org.apache.kafka.connect.runtime.WorkerSinkTask$HandleRebalance failed on partition assignment:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
java.lang.UnsupportedOperationException
	at java.util.Collections$UnmodifiableCollection.clear(Collections.java:1094)
	at io.confluent.connect.hdfs.DataWriter.onPartitionsAssigned(DataWriter.java:207)
	at io.confluent.connect.hdfs.HdfsSinkTask.onPartitionsAssigned(HdfsSinkTask.java:103)
	at org.apache.kafka.connect.runtime.WorkerSinkTask$HandleRebalance.onPartitionsAssigned(WorkerSinkTask.java:369)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete(ConsumerCoordinator.java:189)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:227)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.ensurePartitionAssignment(ConsumerCoordinator.java:306)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:861)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:829)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:171)
	at org.apache.kafka.connect.runtime.WorkerSinkTaskThread.iteration(WorkerSinkTaskThread.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTaskThread.execute(WorkerSinkTaskThread.java:58)
	at org.apache.kafka.connect.util.ShutdownableThread.run(ShutdownableThread.java:82)
[2015-11-24 15:52:24,477] INFO Cannot acquire lease on WAL hdfs://worker4:9000/logs/test/0/log (io.confluent.connect.hdfs.wal.FSWAL)
{quote}

This actually currently works ok for onPartitionsAssigned because the callback is the last thing invoked. For onPartitionsRevoked, it causes offsets to not be committed and the current message batch being processed to not be cleared. Additionally, we may need to do something more to clean up, e.g. the task may need to stop processing data entirely since the task may now be in a bad state.",,ewencp,githubbot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jan 15 17:29:18 UTC 2016,,,,,,,,,,"0|i2ovmf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"14/Jan/16 02:20;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/767

    KAFKA-2886: handle sink task rebalance failures by stopping worker task

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-2886

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/767.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #767
    
----
commit eddfb3afc46ca9b0747ed57aca8dd5b50e4d4519
Author: Jason Gustafson <jason@confluent.io>
Date:   2016-01-13T18:09:10Z

    KAFKA-2886: handle sink task rebalance failures by stopping worker task

----
;;;","16/Jan/16 01:29;ewencp;Issue resolved by pull request 767
[https://github.com/apache/kafka/pull/767];;;","16/Jan/16 01:29;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/767
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Schema cache corruption in JsonConverter,KAFKA-2884,12915839,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,ewencp,jh12z,jh12z,25/Nov/15 00:30,05/Jan/16 04:22,22/Mar/23 15:10,05/Jan/16 04:22,0.9.0.0,,,,,,,,,,,,,KafkaConnect,,,,0,,,,,,"There is an issue with the schema cache in the {{JsonConverter}} class when using Struct types that corrupts its entries.

The schema cache returns an schema object for a given field type which then gets modified setting the field name.

{code}
ObjectNode fieldJsonSchema = asJsonSchema(field.schema());       fieldJsonSchema.put(JsonSchema.STRUCT_FIELD_NAME_FIELD_NAME, field.name());
{code}

The same `fieldJsonSchema` object instance is returned for following fields (of the same type) and the field name attribute ({{JsonSchema.STRUCT_FIELD_NAME_FIELD_NAME}}) is set overwritting the previous value. This causes to serialize a corrupted schema in the message.

{code:title=JsonConverter.java|borderStyle=solid}
private ObjectNode asJsonSchema(Schema schema) {
    if (schema == null)
        return null;

    ObjectNode cached = fromConnectSchemaCache.get(schema);
    if (cached != null)
        return cached;

    // ....

    case STRUCT:
        jsonSchema = JsonNodeFactory.instance.objectNode().put(JsonSchema.SCHEMA_TYPE_FIELD_NAME, JsonSchema.STRUCT_TYPE_NAME);
        ArrayNode fields = JsonNodeFactory.instance.arrayNode();
        for (Field field : schema.fields()) {
            ObjectNode fieldJsonSchema = asJsonSchema(field.schema());
            fieldJsonSchema.put(JsonSchema.STRUCT_FIELD_NAME_FIELD_NAME, field.name());
            fields.add(fieldJsonSchema);
        }
        jsonSchema.set(JsonSchema.STRUCT_FIELDS_FIELD_NAME, fields);
        break;

    // ...
}
{code}","MacBook Pro 15'' mid-2014
Mac OS X 10.11.1",ewencp,jh12z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3055,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jan 04 20:22:30 UTC 2016,,,,,,,,,,"0|i2ovhj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"05/Jan/16 04:22;ewencp;Oops, seems when KAFKA-3055 was filed we missed that we already had this instance of the bug. Marking this one as duplicate since we already applied a patch with KAFKA-3055.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OffsetCommitRequest can commit offset on unknown topic,KAFKA-1852,12765932,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriharsha,junrao,junrao,09/Jan/15 11:07,12/Mar/15 12:06,22/Mar/23 15:10,04/Mar/15 03:49,0.9.0.0,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Currently, we allow an offset to be committed to Kafka, even when the topic/partition for the offset doesn't exist. We probably should disallow that and send an error back in that case.",,jjkoshy,junrao,nehanarkhede,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/15 09:51;sriharsha;KAFKA-1852.patch;https://issues.apache.org/jira/secure/attachment/12692412/KAFKA-1852.patch","20/Jan/15 02:44;sriharsha;KAFKA-1852_2015-01-19_10:44:01.patch;https://issues.apache.org/jira/secure/attachment/12693132/KAFKA-1852_2015-01-19_10%3A44%3A01.patch","13/Feb/15 08:46;sriharsha;KAFKA-1852_2015-02-12_16:46:10.patch;https://issues.apache.org/jira/secure/attachment/12698581/KAFKA-1852_2015-02-12_16%3A46%3A10.patch","17/Feb/15 05:22;sriharsha;KAFKA-1852_2015-02-16_13:21:46.patch;https://issues.apache.org/jira/secure/attachment/12699162/KAFKA-1852_2015-02-16_13%3A21%3A46.patch","19/Feb/15 05:13;sriharsha;KAFKA-1852_2015-02-18_13:13:17.patch;https://issues.apache.org/jira/secure/attachment/12699542/KAFKA-1852_2015-02-18_13%3A13%3A17.patch","28/Feb/15 05:50;sriharsha;KAFKA-1852_2015-02-27_13:50:34.patch;https://issues.apache.org/jira/secure/attachment/12701458/KAFKA-1852_2015-02-27_13%3A50%3A34.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Mar 03 19:49:40 UTC 2015,,,,,,,,,,"0|i243w7:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"10/Jan/15 05:18;junrao;Another weird thing this causes is that we can commit an offset to a non-existing topic, but will get an UnknownTopic error when fetching the offset.;;;","15/Jan/15 09:51;sriharsha;Created reviewboard https://reviews.apache.org/r/29912/diff/
 against branch origin/trunk;;;","20/Jan/15 02:44;sriharsha;Updated reviewboard https://reviews.apache.org/r/29912/diff/
 against branch origin/trunk;;;","26/Jan/15 10:50;nehanarkhede;[~jjkoshy] would you like to take a look at this patch?;;;","12/Feb/15 00:19;sriharsha;[~jjkoshy] pinging for a review. Thanks.;;;","12/Feb/15 02:43;jjkoshy;Thanks for the ping - will take a look.;;;","13/Feb/15 08:46;sriharsha;Updated reviewboard https://reviews.apache.org/r/29912/diff/
 against branch origin/trunk;;;","13/Feb/15 08:47;sriharsha;Thanks [~jjkoshy] for the review. I added your suggestion please take a look when you get a chance.;;;","17/Feb/15 05:22;sriharsha;Updated reviewboard https://reviews.apache.org/r/29912/diff/
 against branch origin/trunk;;;","19/Feb/15 05:13;sriharsha;Updated reviewboard https://reviews.apache.org/r/29912/diff/
 against branch origin/trunk;;;","27/Feb/15 22:23;sriharsha;[~jjkoshy] Updated the patch as per your suggestions can you please take a look.Thanks;;;","28/Feb/15 05:50;sriharsha;Updated reviewboard https://reviews.apache.org/r/29912/diff/
 against branch origin/trunk;;;","04/Mar/15 03:49;jjkoshy;committed to trunk;;;","04/Mar/15 03:49;jjkoshy;(As noted in RB we need a separate jira to handle for commits that occur while deleting topics);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created,KAFKA-2857,12914176,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,vahid,ijuma,ijuma,19/Nov/15 01:17,11/Jun/18 19:33,22/Mar/23 15:10,04/Mar/17 04:04,,,,,,,0.11.0.0,,,,,,,tools,,,,0,,,,,,"If we describe a non-existing group before the offset topic is created, like the following:

{code}
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --new-consumer --describe --group gggg
{code}

We get the following error:

{code}
Error while executing consumer group command The group coordinator is not available.
org.apache.kafka.common.errors.GroupCoordinatorNotAvailableException: The group coordinator is not available.
{code}

The exception is thrown in the `adminClient.describeConsumerGroup` call. We can't interpret this exception as meaning that the group doesn't exist because it could also be thrown f all replicas for a offset topic partition are down (as explained by Jun).

Jun also suggested that we should distinguish if a coordinator is not available from the case where a coordinator doesn't exist.",,githubbot,hachikuji,ijuma,imandhan,sakumar,vahid,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jun 11 11:33:40 UTC 2018,,,,,,,,,,"0|i2ol8v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Nov/15 01:17;ijuma;cc [~junrao] [~hachikuji];;;","11/Jun/16 03:41;imandhan;Working on this with [~vahid] and we aren't sure about what the part about all replicas for a offset topic partition being down means. If all __consumer_offsets partitions are down, wouldn't all the brokers be down as well (meaning that all brokers keep the same copy of __consumer_offsets)?;;;","13/Jun/16 06:00;hachikuji;[~imandhan] The __consumer_offsets topic is a normal topic, so it can happen that all the partition leaders and replicas are down, in which case we'll return an error saying the group coordinator is not available. The cluster has to be pretty big to hit this, but it can happen. It seems like our choices are basically to either let the command retry on this error, or try to give the user a more helpful message. I'd probably favor the latter. Since the most likely scenario for this case is the one mentioned in the description (where the topic hasn't been created yet), I think it would make sense to mention it explicitly in the message and let the user retry. ;;;","14/Jun/16 08:31;vahid;[~hachikuji] Could you also clarify what constitutes the ""coordinator doesn't exist"" case? The JIRA asks that it is distinguished from when ""coordinator is not available"". Thanks.;;;","14/Jun/16 11:09;hachikuji;[~vahid] That's a good question. Maybe we can get clarification from [~ijuma] or [~junrao], but the previous sentence in the description suggests maybe the intent is to distinguish the case of a group not existing? I think it would be fine here to give the user a message which tells them that the offsets topic is unavailable and points out that it takes a little time on a new cluster to create it. But if we can't find the coordinator, then there's really no way to know whether the group ""exists"" or not.;;;","15/Jun/16 16:07;ijuma;I'd be OK with just improving the message as Jason suggested.;;;","24/Jun/16 04:59;imandhan;So it seems like we need to check if the offsets topic exists or not and we can do this check right before a call to findCoordinator() is made in the describeGroup function() here - https://github.com/apache/kafka/blob/404b696bea58aca17fbe528aed03cb3c94516c39/core/src/main/scala/kafka/admin/AdminClient.scala#L125. If the offsets topic doesn’t exist, we can throw an exception and this is the only check we need to do to resolve the jira based on what I understand. Does this seem like the right approach to take? ;;;","24/Jun/16 05:09;hachikuji;[~imandhan] I think maybe it can be even simpler. If the error code returned from the GroupCoordinator request is COORDINATOR_NOT_AVAILABLE, then we can print a message as suggested above. So maybe we just need to change {{findCoordinator}} to return an Option instead of throwing?;;;","24/Jun/16 07:47;githubbot;GitHub user imandhan opened a pull request:

    https://github.com/apache/kafka/pull/1548

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

    Added a check to make sure different cases when offset topic hasn't been created and consumer group describe command is run, are handled appropriately. 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/imandhan/kafka KAFKA-2857

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1548.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1548
    
----
commit c27df5a17a6bbb34a6118bb7b74d6f3e80239612
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-23T23:46:07Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created
    
    Added a check to make sure different cases when offset topic hasn't been created and consumer group describe command is run, are handled appropriately.

----
;;;","24/Jun/16 07:48;imandhan;Thanks [~hachikuji]! I just created a PR for this jira.;;;","01/Jul/16 07:00;githubbot;Github user imandhan closed the pull request at:

    https://github.com/apache/kafka/pull/1548
;;;","01/Jul/16 07:00;githubbot;GitHub user imandhan reopened a pull request:

    https://github.com/apache/kafka/pull/1548

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

    Added a check to make sure different cases when offset topic hasn't been created and consumer group describe command is run, are handled appropriately. 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/imandhan/kafka KAFKA-2857

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1548.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1548
    
----
commit c27df5a17a6bbb34a6118bb7b74d6f3e80239612
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-23T23:46:07Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created
    
    Added a check to make sure different cases when offset topic hasn't been created and consumer group describe command is run, are handled appropriately.

commit 9da78fa08688b691a954da164e6c8d28abc90500
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-24T00:41:12Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created
    
    Added a check to make sure different cases when offset topic hasn't been created and consumer group describe command is run, are handled appropriately.

commit 8d157546152fc063a2aff92a3fade1b6947b5ffb
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-24T00:51:20Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

commit f50c8dce19018e7f689d318795eb797a7d0d0f2d
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-28T00:53:33Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

commit 7815008eeb4c2dabaf96707652f50425ac4d5923
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-28T20:13:51Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

----
;;;","06/Jul/16 01:07;githubbot;Github user imandhan closed the pull request at:

    https://github.com/apache/kafka/pull/1548
;;;","06/Jul/16 01:07;githubbot;GitHub user imandhan reopened a pull request:

    https://github.com/apache/kafka/pull/1548

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

    Added a check to make sure different cases when offset topic hasn't been created and consumer group describe command is run, are handled appropriately. 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/imandhan/kafka KAFKA-2857

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1548.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1548
    
----
commit c27df5a17a6bbb34a6118bb7b74d6f3e80239612
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-23T23:46:07Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created
    
    Added a check to make sure different cases when offset topic hasn't been created and consumer group describe command is run, are handled appropriately.

commit 9da78fa08688b691a954da164e6c8d28abc90500
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-24T00:41:12Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created
    
    Added a check to make sure different cases when offset topic hasn't been created and consumer group describe command is run, are handled appropriately.

commit 8d157546152fc063a2aff92a3fade1b6947b5ffb
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-24T00:51:20Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

commit f50c8dce19018e7f689d318795eb797a7d0d0f2d
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-28T00:53:33Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

commit 7815008eeb4c2dabaf96707652f50425ac4d5923
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-28T20:13:51Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

----
;;;","13/Jul/16 02:36;githubbot;Github user imandhan closed the pull request at:

    https://github.com/apache/kafka/pull/1548
;;;","13/Jul/16 02:36;githubbot;GitHub user imandhan reopened a pull request:

    https://github.com/apache/kafka/pull/1548

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

    Added a check to make sure different cases when offset topic hasn't been created and consumer group describe command is run, are handled appropriately. 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/imandhan/kafka KAFKA-2857

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1548.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1548
    
----
commit c27df5a17a6bbb34a6118bb7b74d6f3e80239612
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-23T23:46:07Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created
    
    Added a check to make sure different cases when offset topic hasn't been created and consumer group describe command is run, are handled appropriately.

commit 9da78fa08688b691a954da164e6c8d28abc90500
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-24T00:41:12Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created
    
    Added a check to make sure different cases when offset topic hasn't been created and consumer group describe command is run, are handled appropriately.

commit 8d157546152fc063a2aff92a3fade1b6947b5ffb
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-24T00:51:20Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

commit f50c8dce19018e7f689d318795eb797a7d0d0f2d
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-28T00:53:33Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

commit 7815008eeb4c2dabaf96707652f50425ac4d5923
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-06-28T20:13:51Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

commit 2f2eca8091ef576e2f9c79859c7404b8d50733d7
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-07-11T22:53:35Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created

----
;;;","02/Dec/16 17:09;githubbot;Github user imandhan closed the pull request at:

    https://github.com/apache/kafka/pull/1548
;;;","02/Dec/16 17:41;githubbot;GitHub user imandhan opened a pull request:

    https://github.com/apache/kafka/pull/2203

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableEx…

    …ception when describing a non-existent group before the offset topic is created #1548 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/imandhan/kafka KAFKA-2857-2

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/2203.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #2203
    
----
commit ea3a0609388d19caf2de6587a5efdbcb851a3224
Author: Ishita Mandhan <imandha@us.ibm.com>
Date:   2016-12-02T09:45:57Z

    KAFKA-2857 ConsumerGroupCommand throws GroupCoordinatorNotAvailableException when describing a non-existent group before the offset topic is created #1548

----
;;;","28/Jan/17 06:18;githubbot;Github user imandhan closed the pull request at:

    https://github.com/apache/kafka/pull/2203
;;;","02/Feb/17 05:43;vahid;[~hachikuji] I am thinking about the two options you suggested earlier ([here|https://issues.apache.org/jira/browse/KAFKA-2857?focusedCommentId=15326653&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15326653]) and am wondering if retrying in case of ""coordinator not available"" would provide a better user experience. IMHO, user's goal is to get the group details and they would probably rather not having to issue the command twice to get it.;;;","07/Feb/17 04:47;hachikuji;[~vahid] Sounds reasonable. At least we should have a timeout which can be overridden though.;;;","07/Feb/17 07:56;vahid;[~hachikuji] Great. I assume you are suggesting adding a consumer config for this timeout. If so, do you think a KIP is required?;;;","07/Feb/17 08:25;hachikuji;Hmm, I thought we used the admin client for this API. Isn't that where the timeout should go? ;;;","07/Feb/17 08:35;vahid;Sorry, you are right. This would become a config option for the consumer group command (for new consumers only).;;;","11/Feb/17 04:08;githubbot;GitHub user vahidhashemian opened a pull request:

    https://github.com/apache/kafka/pull/2538

    KAFKA-2857: Retry querying the consumer group while initializing

    This applies to new-consumer based groups and would avoid scenarios in which user issues a `--describe` query while the group is initializing.
    Example: The following could occur for a newly created group.
    ```
    kafka@kafka:~/workspace/kafka$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group g
    Note: This will only show information about consumers that use the Java consumer API (non-ZooKeeper-based consumers).
    
    Error: Executing consumer group command failed due to The group coordinator is not available.
    ```
    
    With this PR the group is queried repeatedly at specific intervals within a preset (and configurable) timeout `group-init-timeout` to circumvent unfortunate situations like above.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/vahidhashemian/kafka KAFKA-2857

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/2538.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #2538
    
----
commit 1e801041793d47bff2f3a4414b4bb7c3dd27ad04
Author: Vahid Hashemian <vahidhashemian@us.ibm.com>
Date:   2017-02-09T20:48:10Z

    KAFKA-2857: Retry querying the consumer group while the group initializes
    
    This applies to new-consumer based groups and would avoid scenarios in which user issues a `--describe` query while the group is stabilizing.
    Example: The following could occur for a newly created group.
    ```
    kafka@kafka:~/workspace/kafka$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group g
    Note: This will only show information about consumers that use the Java consumer API (non-ZooKeeper-based consumers).
    
    Error: Executing consumer group command failed due to The group coordinator is not available.
    ```
    
    With this PR the group is queried repeatedly at specific intervals within a preset (and configurable) timeout `group-init-timeout` to circumvent unfortunate situations like above.

----
;;;","04/Mar/17 04:04;hachikuji;Issue resolved by pull request 2538
[https://github.com/apache/kafka/pull/2538];;;","04/Mar/17 04:05;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/2538
;;;","04/Mar/17 07:46;githubbot;GitHub user vahidhashemian opened a pull request:

    https://github.com/apache/kafka/pull/2636

    MINOR: Follow up to KAFKA-2857

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/vahidhashemian/kafka minor/kafka-2857-followup

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/2636.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #2636
    
----

----
;;;","04/Mar/17 08:50;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/2636
;;;","11/Jun/18 19:33;sakumar;We are still observing group coordinator not available in https://issues.apache.org/jira/browse/KAFKA-7017 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka Metrics Memory Leak ,KAFKA-936,12651436,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,nehanarkhede,senthilchittibabu,senthilchittibabu,07/Jun/13 04:31,02/Dec/15 13:36,22/Mar/23 15:10,29/Mar/15 00:00,0.8.0,,,,,,,,,,,,,consumer,,,,0,,,,,,"I am using kafka_2.8.0-0.8.0-SNAPSHOT version. I am running into OutOfMemoryError in PermGen Space. I have set the -XX:MaxPermSize=512m, but I still get the same error. I used profiler to trace the memory leak, and found the following kafka classes to be the cause for the memory leak. Please let me know if you need any additional information to debug this issue. 

kafka.server.FetcherLagMetrics
kafka.consumer.FetchRequestAndResponseMetrics
kafka.consumer.FetchRequestAndResponseStats
kafka.metrics.KafkaTimer
kafka.utils.Pool
","centos linux, jdk 1.6, jboss",hechen.gao,jkreps,junrao,omkreddy,senthilchittibabu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,331762,,,Wed Dec 02 05:36:48 UTC 2015,,,,,,,,,,"0|i1l8fz:",332093,,,,,,,,,,,,,,,,,,,,"07/Jun/13 23:28;junrao;Is the OOME on the broker or the consumer? How many topics and partitions do you have? We maintain some stats per partition. So the more partitions you have, the more memory is needed.;;;","08/Jun/13 01:20;senthilchittibabu;The OOME is on the consumer. I have defined around 25 topics and 25 partition per topic. I can increase the memory but sooner or later it's going to crash with OOME, right?;;;","10/Jun/13 23:18;junrao;There is a fixed amount memory needed per topic/partition for metrics. So, if the # partitions consumed in a consumer doesn't change, the memory needed for metrics shouldn't grow. Since you have more than 600 partitions, could you try a larger heap size and see if the problem persists?;;;","11/Jun/13 00:49;senthilchittibabu;The application ramps up within few minutes to consume the message from the queue, I understand if the metrics memory grows during the ramp up, but shouldn't it remain flat after that. But I see the Metrics instance grow steadily. 

I did noticed the kafka_2.8.0-0.8.0-SNAPSHOT downgraded the metrics jars from 3.0 to 2.2.0. I did not have this issue with initial version of kafka 0.8 with metrics_core_3.0.0. Is there any reason this was done?

Anyway, I will increase the maxPermSize to 1g or 2g from 512m and run the test again. 

;;;","11/Jun/13 12:16;junrao;We downgraded metrics to 2.2.0 because that's the most stable released version (see the discussion in KAFKA-826). Let us know how your change goes. We have been running a consumer in (mirrormaker) with thousands of partitions for weeks and haven't seen this memory issue. ;;;","11/Jun/13 23:42;senthilchittibabu;The application did not crash yet after increasing the max PermGen to 2g. However the permGen memory is slowly increasing. I can clearly see the following object instance are created in thousands and ten thousands. And never gets garbage collected even after force garbage collection by using the profiler. I believe since these object size are small, you will not see the application crash for days/weeks if you set the max memory to high number. You will notice the leak if you watch the following objects in the profiler. Can you please run your app and watch the following object in the profiler?

kafka.server.FetcherLagMetrics 
kafka.consumer.FetchRequestAndResponseMetrics 
kafka.consumer.FetchRequestAndResponseStats 
kafka.metrics.KafkaTimer 
kafka.utils.Pool 

BTW, what is your consumer app memory settings?
;;;","12/Jun/13 00:57;senthilchittibabu;The application did not crash yet after increasing the max PermGen to 2g. However the permGen memory is slowly increasing. I can clearly see the following object instance are created in thousands and ten thousands. And never gets garbage collected even after force garbage collection by using the profiler. I believe since these object size are small, you will not see the application crash for days/weeks if you set the max memory to high number. You will notice the leak if you watch the following objects in the profiler. Can you please run your app and watch the following object in the profiler?

kafka.server.FetcherLagMetrics 
kafka.consumer.FetchRequestAndResponseMetrics 
kafka.consumer.FetchRequestAndResponseStats 
kafka.metrics.KafkaTimer 
kafka.utils.Pool 

BTW, what is your consumer app memory settings?
;;;","12/Jun/13 13:16;junrao;This is the heap setting in our MirrorMaker tool.
Xms3g -Xmx3g -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 

BTW, do you see lots of rebalances in your consumer log?;;;","12/Jun/13 21:59;senthilchittibabu;Yes, I see lot of rebalances (can't rebalance after 4 retries) in the log.. And also I see the below the warning often. Not sure is there any relation with memory leak?

2013-06-11 23:59:59,861 WARN  [kafka.consumer.ConsumerFetcherManager$LeaderFinderThread] (UrlWorker-grp_hms.com-1370985065479-bb5e7de1-leader-finder-thread], Failed to find leader for Set([dev--raw-topic,10], [ption
 at org.I0Itec.zkclient.ZkClient$2.call(ZkClient.java:416) [zkclient-0.2.jar:0.2]
 at org.I0Itec.zkclient.ZkClient$2.call(ZkClient.java:413) [zkclient-0.2.jar:0.2]
 at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675) [zkclient-0.2.jar:0.2]
 at org.I0Itec.zkclient.ZkClient.getChildren(ZkClient.java:413) [zkclient-0.2.jar:0.2]
 at org.I0Itec.zkclient.ZkClient.getChildren(ZkClient.java:409) [zkclient-0.2.jar:0.2]
 at kafka.utils.ZkUtils$.getChildrenParentMayNotExist(ZkUtils.scala:438) [kafka_2.8.0-0.8.0-SNAPSHOT.jar:0.8.0
 at kafka.utils.ZkUtils$.getAllBrokersInCluster(ZkUtils.scala:75) [kafka_2.8.0-0.8.0-SNAPSHOT.jar:0.8.0-SNAPSH
 at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:62) [kafka_2.
 at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51) [kafka_2.8.0-0.8.0-SNAPSHOT.jar:0.8.0-SNAP;;;","12/Jun/13 22:47;junrao;Normally, rebalances are rare. The common cause of too many rebalances is GC (see #6 in http://kafka.apache.org/faq.html for details). Not sure if the memory leak issue you reported is related to too many rebalances. Nevertheless, you should try to tune the GC to minimize rebalances.;;;","24/Jun/13 23:16;senthilchittibabu;Finally the memory leak issue resolved after providing ""consumer.id"" property during consumer creation. We found that kafka is not cleaning up all the metrics object during the shutdown process. We read messages based on the interval, so the application open/close consumer frequently. 

By providing the static ""consumer.id"" looks like kafka is reusing the metrics object, hence it stopped creating lots of metrics object. However now we see duplicate message consumption by the consumer within the same group as side effect. Basically we have 10 partition and 10 consumer thread, all reading the same message even though they all have same ""group.id"".

I believe cleaning up all the metrics object during shutdown process is the right fix for this memory leak. If you setup small testcase which open/close consumer frequently, you can see the memory leak immediately. All Metrics object like MetricName, EWMA, Histogram, etc will never gets garbage collected. 

I am not sure why kafka needs unique consumer id to read the message from the stream. Please advice.;;;","08/Feb/15 06:23;jkreps;[~junrao] Does this issue still exist?;;;","08/Feb/15 14:26;omkreddy;After KAFKA-1481,  I am observing one issue. We are not removing the newly added Version/AppInfo Mbean on old producer/consumer close call.  There is no other memory leak. Will submit a patch for this.;;;","02/Dec/15 13:36;hechen.gao;I am using kafka_2.10-0.8.1.1.jar in my project (which depend on metrics-core-2.2.0.jar), and i also ran into this issue recently.
Metrics related object such as ConcurrentSkipListMap<Double, Long> used up to 90.5% of the memory.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
corrupt recovery file prevents startup,KAFKA-1758,12753616,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,omkreddy,jbrosenberg@gmail.com,jbrosenberg@gmail.com,07/Nov/14 12:53,03/Sep/15 08:04,22/Mar/23 15:10,19/Jun/15 09:51,,,,,,,0.9.0.0,,,,,,,log,,,,2,newbie,,,,,"Hi,

We recently had a kafka node go down suddenly. When it came back up, it apparently had a corrupt recovery file, and refused to startup:

{code}
2014-11-06 08:17:19,299  WARN [main] server.KafkaServer - Error starting up KafkaServer
java.lang.NumberFormatException: For input string: ""^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@""
        at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
        at java.lang.Integer.parseInt(Integer.java:481)
        at java.lang.Integer.parseInt(Integer.java:527)
        at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:229)
        at scala.collection.immutable.StringOps.toInt(StringOps.scala:31)
        at kafka.server.OffsetCheckpoint.read(OffsetCheckpoint.scala:76)
        at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:106)
        at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:105)
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
        at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
        at kafka.log.LogManager.loadLogs(LogManager.scala:105)
        at kafka.log.LogManager.<init>(LogManager.scala:57)
        at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:275)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:72)
{code}

And the app is under a monitor (so it was repeatedly restarting and failing with this error for several minutes before we got to it)…

We moved the ‘recovery-point-offset-checkpoint’ file out of the way, and it then restarted cleanly (but of course re-synced all it’s data from replicas, so we had no data loss).

Anyway, I’m wondering if that’s the expected behavior? Or should it not declare it corrupt and then proceed automatically to an unclean restart?

Should this NumberFormatException be handled a bit more gracefully?

We saved the corrupt file if it’s worth inspecting (although I doubt it will be useful!)….

The corrupt files appeared to be all zeroes.",,jbrosenberg@gmail.com,jkreps,junrao,nehanarkhede,omkreddy,otis,panih2o,wangbo23,zhiwei,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Feb/15 02:37;omkreddy;KAFKA-1758.patch;https://issues.apache.org/jira/secure/attachment/12697534/KAFKA-1758.patch","09/May/15 15:02;omkreddy;KAFKA-1758_2015-05-09_12:29:20.patch;https://issues.apache.org/jira/secure/attachment/12731688/KAFKA-1758_2015-05-09_12%3A29%3A20.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jun 19 01:51:19 UTC 2015,,,,,,,,,,"0|i223d3:",9223372036854775807,,nehanarkhede,,,,,,,,,,,,,,,,,,"08/Feb/15 07:12;jkreps;This is actually not a very difficult change--in LogManager.loadLogs we would need to basically handle an error in reading the recovery checkpoint, log it, and then just treat it as though our recovery point was 0 (or something like that) for all logs.;;;","10/Feb/15 02:37;omkreddy;Created reviewboard https://reviews.apache.org/r/30801/diff/
 against branch origin/trunk;;;","10/Feb/15 02:43;omkreddy;Attaching a patch which handles NumberFormatException while reading   recovery checkpoint file. We still fail for other IOExceptions. On NumberFormatException we will set the last recovery point to zero.;;;","18/Apr/15 19:39;omkreddy;[~jkreps] Can I get review for this simple patch?;;;","27/Apr/15 02:54;nehanarkhede;[~omkreddy] I took a quick look and left a few review comments. Should be able to merge once you fix those.;;;","09/May/15 15:02;omkreddy;Updated reviewboard https://reviews.apache.org/r/30801/diff/
 against branch origin/trunk;;;","19/Jun/15 09:51;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
system testcase_0206 fails using the new producer,KAFKA-1301,12699810,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,11/Mar/14 01:38,12/Mar/14 11:58,22/Mar/23 15:10,12/Mar/14 11:58,0.8.2.0,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"The problem is that the producer doesn't drain the unsent data properly on close. The problem is in the following code in Sender.run(). It's possible for this loop to exit with unfinished requests.

        // okay we stopped accepting requests but there may still be
        // requests in the accumulator or waiting for acknowledgment,
        // wait until these are completed.
        int unsent = 0;
        do {
            try {
                unsent = run(time.milliseconds());
            } catch (Exception e) {
                log.error(""Uncaught error in kafka producer I/O thread: "", e);
            }
        } while (unsent > 0 || this.inFlightRequests.totalInFlightRequests() > 0);

Suppose that all produce requests are being sent, but the sender is waiting for responses. Then the broker failed. In handling disconnects, we cleared all inflight requests. When we check the condition in the while clause, there is no unsent data and no in flight requests. However, failed records have been added to RecordAccumulator and are ready to be sent in the next iteration.",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Mar/14 09:50;junrao;KAFKA-1301.patch;https://issues.apache.org/jira/secure/attachment/12634079/KAFKA-1301.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,378156,,,Wed Mar 12 03:58:08 UTC 2014,,,,,,,,,,"0|i1t5sf:",378448,,,,,,,,,,,,,,,,,,,,"12/Mar/14 09:50;junrao;Created reviewboard https://reviews.apache.org/r/19088/
 against branch origin/trunk;;;","12/Mar/14 11:58;junrao;Thanks for the review. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KafkaException was not recorded at the per-topic metrics,KAFKA-1800,12757844,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,guozhang,guozhang,26/Nov/14 07:46,06/Nov/20 03:12,22/Mar/23 15:10,06/Nov/20 03:12,,,,,,,1.0.0,,,,,,,,,,,0,,,,,,"When KafkaException was thrown from producer.send() call, it is not recorded on the per-topic record-error-rate, but only the global error-rate.

Since users are usually monitoring on the per-topic metrics, loosing all dropped message counts at this level that are caused by kafka producer thrown exceptions such as BufferExhaustedException could be very dangerous.",,boniek,guozhang,jkreps,srkandekar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Nov/14 04:21;guozhang;KAFKA-1800.patch;https://issues.apache.org/jira/secure/attachment/12683910/KAFKA-1800.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 05 19:12:07 UTC 2020,,,,,,,,,,"0|i22sdz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"27/Nov/14 04:21;guozhang;Created reviewboard https://reviews.apache.org/r/28479/diff/
 against branch origin/trunk;;;","27/Nov/14 08:23;guozhang;There is still a corner case after this patch that the per-topic metrics cannot be recorded because they are not registered: when KafkaProducer's waitOnMetadata throws a TimeoutException because the topic metadata is not available, this error cannot be recorded at the per-topic metrics because they are only registered at the sender level when the produce requests are being sent (in the patch it is changed to when the it is refreshed).

To solve this issue, one proposal is that:

1. In Metrics.registerMetric() function, when the metric already exists, treat it as a no-op instead of throwing IllegalArgumentException.
2. Expose a registerSenderMetrics() API of sender in kafka producer, which will be triggered before metadata.awaitUpdate(version, remainingWaitMs) in waitForMetadata.

This fix is a little bit hacky though, so I would like to hear opinions from other people? [~jkreps]
;;;","02/Dec/14 01:49;jkreps;Is it important to count this exception at the topic level? Maybe just count it at the global level?;;;","02/Dec/14 02:06;guozhang;It is actually quite important for monitoring topic level error / retry rate for producer thrown exceptions since many users do not monitor global level metrics but only on topics that they are interested in.;;;","04/Dec/14 10:02;guozhang;Copying [~jjkoshy]'s comment on the RB here:

{code}
It would be useful to clarify the comment on why this needed to be moved further up as you explained offline - i.e., since buffer exhaustion (for example) can happen before the sender gets a chance to register the metrics.

Also, we should probably discuss on the jira the additional caveat of failed metadata fetches. i.e., since that happens in the network-client the true record error rate would be higher than what's counted by sendermetrics.

The options that we have are:
* Expose Sender's maybeRegisterTopicMetrics and use that in NetworkClient maybeUpdateMetadata if there are no known partitions for a topic
* Keep it as you have it for now and just accept the above discrepancy - (or we could address that in a separate jira as it is orthogonal).
{code};;;","06/Nov/20 03:12;guozhang;This has been fixed since 1.0.0; closing now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
IO exception on windows when high throughput of messages,KAFKA-1065,12670233,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,junrao,cpa199,cpa199,24/Sep/13 17:26,30/Sep/13 22:42,22/Mar/23 15:10,30/Sep/13 22:42,0.8.0,,,,,,,,,,,,,log,,,,0,,,,,,"When a large number of messages are sent per second to a broker on Windows a memory mapping exception occurs and kills Kafka. The exception follows : 

{code}kafka.common.KafkaStorageException: I/O exception in append to log 'test-0'
	at kafka.log.Log.append(Log.scala:349)
	at kafka.cluster.Partition.appendMessagesToLeader(Partition.scala:340)
	at kafka.server.KafkaApis$$anonfun$appendToLocalLog$2.apply(KafkaApis.scala:236)
	at kafka.server.KafkaApis$$anonfun$appendToLocalLog$2.apply(KafkaApis.scala:228)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)
	at scala.collection.Iterator$class.foreach(Iterator.scala:631)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:161)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:194)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:80)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)
	at scala.collection.mutable.HashMap.map(HashMap.scala:39)
	at kafka.server.KafkaApis.appendToLocalLog(KafkaApis.scala:228)
	at kafka.server.KafkaApis.handleProducerRequest(KafkaApis.scala:162)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:66)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:42)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.IOException: The requested operation cannot be performed on a file with a user-mapped section open
	at java.io.RandomAccessFile.setLength(Native Method)
	at kafka.log.OffsetIndex.liftedTree2$1(OffsetIndex.scala:263)
	at kafka.log.OffsetIndex.resize(OffsetIndex.scala:262)
	at kafka.log.OffsetIndex.trimToValidSize(OffsetIndex.scala:247)
	at kafka.log.Log.rollToOffset(Log.scala:518)
	at kafka.log.Log.roll(Log.scala:502)
	at kafka.log.Log.maybeRoll(Log.scala:484)
	at kafka.log.Log.append(Log.scala:297)
	... 19 more{code}

This seems to have been mentioned in the past on the Kafka mail list and is an issue related to http://bugs.sun.com/view_bug.do?bug_id=4724038.

Unfortunately this means that we cannot use Kafka on Windows.",Windows 7 64bit,cpa199,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1008,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,350062,,,Mon Sep 30 14:42:46 UTC 2013,,,,,,,,,,"0|i1ocxz:",350356,,,,,,,,,,,,,,,,,,,,"25/Sep/13 00:08;junrao;Could you try the patch in https://issues.apache.org/jira/browse/KAFKA-1008? I think it's fixing the same issue on windows.;;;","30/Sep/13 17:58;cpa199;Sorry for the slow reply, I've only just got around to testing this out, and it works a treat! Thanks for the help. ;;;","30/Sep/13 22:42;junrao;Close this since it duplicates kafka-1008.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OutOfMemoryError in System Test,KAFKA-522,12608493,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,jfung,jfung,21/Sep/12 00:58,21/Sep/12 02:28,22/Mar/23 15:10,21/Sep/12 02:28,,,,,,,,,,,,,,,,,,0,,,,,,"A. This is only reproducible in a distributed environment:

1. Modify system_test/cluster_config.json to have all broker entities running in 3 different remote hosts
2. (Optional) Update system_test/system_test_runner.py to log messages at DEBUG level by uncommenting the following line: 
# namedLogger.setLevel(logging.DEBUG)

3. In <kafka_home>/system_test, run “python -B system_test_runner.py”


B. In this specific test session, the error occurred in Broker-3:

[2012-09-20 16:26:25,777] INFO Closing socket connection to /x.x.x.x. (kafka.network.Processor)

[2012-09-20 16:26:25,778] INFO 3 successfully elected as leader (kafka.server.ZookeeperLeaderElector)

[2012-09-20 16:26:25,779] INFO [Controller 3], Broker 3 starting become controller state transition (kafka.controller.KafkaController)

[2012-09-20 16:26:25,950] INFO [Controller-3-to-broker-2-send-thread], Starting  (kafka.controller.RequestSendThread)

[2012-09-20 16:26:25,950] ERROR Error handling event ZkEvent[Data of /controller changed sent to kafka.server.ZookeeperLeaderElector$LeaderChangeListener@75088a1b] (org.I0Itec.zkclient.ZkEventThread)

java.lang.OutOfMemoryError: unable to create new native thread

        at java.lang.Thread.start0(Native Method)

        at java.lang.Thread.start(Thread.java:597)

        at kafka.controller.ControllerChannelManager.kafka$controller$ControllerChannelManager$$startRequestSendThread(ControllerChannelManager.scala:97)

        at kafka.controller.ControllerChannelManager$$anonfun$startup$1.apply(ControllerChannelManager.scala:40)

        at kafka.controller.ControllerChannelManager$$anonfun$startup$1.apply(ControllerChannelManager.scala:40)

        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)

        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)

        at scala.collection.Iterator$class.foreach(Iterator.scala:631)

        at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:161)

        at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:194)

        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)

        at scala.collection.mutable.HashMap.foreach(HashMap.scala:80)

        at kafka.controller.ControllerChannelManager.startup(ControllerChannelManager.scala:40)

        at kafka.controller.KafkaController.startChannelManager(KafkaController.scala:230)

        at kafka.controller.KafkaController.initializeControllerContext(KafkaController.scala:223)

        at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:72)

        at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:47)

        at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:55)

        at kafka.server.ZookeeperLeaderElector$LeaderChangeListener.handleDataDeleted(ZookeeperLeaderElector.scala:94)

        at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:549)

        at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)

[2012-09-20 16:26:31,767] INFO [BrokerChangeListener on Controller 3]: Broker change listener fired for path /brokers/ids with children 3,2,1 (kafka.controller.ReplicaStateMachine$BrokerChangeListener)

[2012-09-20 16:26:31,775] INFO [BrokerChangeListener on Controller 3]: Newly added brokers: 1, deleted brokers: , all brokers: 3,2,1 (kafka.controller.ReplicaStateMachine$BrokerChangeListener)

[2012-09-20 16:26:31,777] ERROR [BrokerChangeListener on Controller 3]: Error while handling broker changes (kafka.controller.ReplicaStateMachine$BrokerChangeListener)

java.lang.OutOfMemoryError: unable to create new native thread

        at java.lang.Thread.start0(Native Method)

        at java.lang.Thread.start(Thread.java:597)

        at kafka.controller.ControllerChannelManager.kafka$controller$ControllerChannelManager$$startRequestSendThread(ControllerChannelManager.scala:97)

        at kafka.controller.ControllerChannelManager.addBroker(ControllerChannelManager.scala:61)

        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$liftedTree1$1$7.apply(ReplicaStateMachine.scala:212)

        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$liftedTree1$1$7.apply(ReplicaStateMachine.scala:212)

        at scala.collection.immutable.Set$Set1.foreach(Set.scala:81)

        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.liftedTree1$1(ReplicaStateMachine.scala:212)

        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply$mcV$sp(ReplicaStateMachine.scala:203)

        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply(ReplicaStateMachine.scala:199)

        at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply(ReplicaStateMachine.scala:199)

        at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)

        at kafka.controller.ReplicaStateMachine$BrokerChangeListener.handleChildChange(ReplicaStateMachine.scala:199)

        at org.I0Itec.zkclient.ZkClient$7.run(ZkClient.java:568)

        at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)

[2012-09-20 16:27:22,821] INFO [BrokerChangeListener on Controller 3]: Broker change listener fired for path /brokers/ids with children 3,2 (kafka.controller.ReplicaStateMachine$BrokerChangeListener)

[2012-09-20 16:27:22,823] INFO [BrokerChangeListener on Controller 3]: Newly added brokers: , deleted brokers: 1, all brokers: 3,2 (kafka.controller.ReplicaStateMachine$BrokerChangeListener)

[2012-09-20 16:27:22,825] INFO [Controller-3-to-broker-1-send-thread], Shutting down (kafka.controller.RequestSendThread)

[2012-09-20 16:27:23,279] INFO Unable to read additional data from server sessionid 0x139e47e2eb00004, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)

[2012-09-20 16:27:23,379] INFO zookeeper state changed (Disconnected) (org.I0Itec.zkclient.ZkClient)



C. At around the same time, the following are the main test output:

2012-09-20 16:26:25,251 - INFO - ======================================================

2012-09-20 16:26:25,252 - INFO - Iteration 2 of 2

2012-09-20 16:26:25,252 - INFO - ======================================================

2012-09-20 16:26:25,252 - INFO - looking up leader... (kafka_system_test_utils)

2012-09-20 16:26:25,252 - DEBUG - executing command [ssh host2 ""grep -i -h 'Completed the leader state transition'  /mnt/u001/kafka_08_replication_system_test/system_test/replication_testsuite/testcase_1/logs/broker-1/kafka_server_9091.log |  sort | tail -1""] (kafka_system_test_utils)

2012-09-20 16:26:25,344 - DEBUG - found the log line : [2012-09-20 16:25:45,195] INFO Replica Manager on Broker 1: Completed the leader state transition for topic test_1 partition 0 (kafka.server.ReplicaManager) (kafka_system_test_utils)

2012-09-20 16:26:25,344 - DEBUG - brokerid: [1] entity_id: [1] (kafka_system_test_utils)

2012-09-20 16:26:25,345 - DEBUG - executing command [ssh host3 ""grep -i -h 'Completed the leader state transition'  /mnt/u001/kafka_08_replication_system_test/system_test/replication_testsuite/testcase_1/logs/broker-2/kafka_server_9092.log |  sort | tail -1""] (kafka_system_test_utils)

2012-09-20 16:26:25,455 - DEBUG - executing command [ssh host3 ""grep -i -h 'Completed the leader state transition'  /mnt/u001/kafka_08_replication_system_test/system_test/replication_testsuite/testcase_1/logs/broker-3/kafka_server_9093.log |  sort | tail -1""] (kafka_system_test_utils)

2012-09-20 16:26:25,540 - INFO - ======================================================

2012-09-20 16:26:25,540 - INFO - validating leader election

2012-09-20 16:26:25,540 - INFO - ======================================================

2012-09-20 16:26:25,540 - INFO - found leader in entity [1] with brokerid [1] for partition [0] (kafka_system_test_utils)

2012-09-20 16:26:25,541 - INFO - ======================================================

2012-09-20 16:26:25,541 - INFO - bounce_leader flag : true

2012-09-20 16:26:25,541 - INFO - ======================================================

2012-09-20 16:26:25,541 - INFO - stopping leader in entity 1 with pid 32679 (kafka_system_test_utils)

2012-09-20 16:26:25,541 - DEBUG - executing command [ssh host2 'pid=32679; prev_pid=""""; echo $pid; while [[ ""x$pid"" != ""x"" ]]; do prev_pid=$pid;   for child in $(ps -o pid,ppid ax | awk ""{ if ( \$2 == $pid ) { print \$1 }}"");     do echo $child; pid=$child;   done;   if [ $prev_pid == $pid ]; then     break;   fi; done' 2> /dev/null (system_test_utils)

2012-09-20 16:26:25,669 - DEBUG - terminating process id: 32679 in host: host2 (kafka_system_test_utils)

2012-09-20 16:26:25,670 - DEBUG - executing command [ssh host2 'kill -15 32681'] (system_test_utils)

2012-09-20 16:26:25,673 - DEBUG - executing command [ssh host2 'kill -15 32679'] (system_test_utils)

2012-09-20 16:26:25,675 - INFO - sleeping for 5s for leader re-election to complete (kafka_system_test_utils)

2012-09-20 16:26:30,681 - INFO - looking up broker shutdown... (kafka_system_test_utils)

2012-09-20 16:26:30,681 - DEBUG - executing command [ssh host2 ""grep -i -h 'shut down completed'  /mnt/u001/kafka_08_replication_system_test/system_test/replication_testsuite/testcase_1/logs/broker-1/kafka_server_9091.log |  sort | tail -1""] (kafka_system_test_utils)

2012-09-20 16:26:30,781 - DEBUG - found the log line : [2012-09-20 16:26:25,776] INFO [Kafka Server 1], shut down completed (kafka.server.KafkaServer) (kafka_system_test_utils)

2012-09-20 16:26:30,781 - DEBUG - brokerid: [1] entity_id: [1] (kafka_system_test_utils)

2012-09-20 16:26:30,781 - DEBUG - unix timestamp of shut down completed: 1348158385.776000 (kafka_system_test_utils)

2012-09-20 16:26:30,781 - DEBUG - looking up new leader (kafka_system_test_utils)
",,jfung,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,299155,,,Thu Sep 20 18:28:21 UTC 2012,,,,,,,,,,"0|i15zxr:",243122,,,,,,,,,,,,,,,,,,,,"21/Sep/12 02:28;jfung;By increasing the max user processes to 4096, the error doesn't show up any more:

ulimit -u 4096

It seems to be related to system resource configuration and not a Kafka issue. So mark this FIXED.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix transient unit test ProducerFailureHandlingTest.testBrokerFailure,KAFKA-1396,12708619,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,junrao,junrao,16/Apr/14 04:55,14/May/14 08:34,22/Mar/23 15:10,14/May/14 08:34,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,Currently disabled after kafka-1390.,,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/14 04:48;guozhang;KAFKA-1396.patch;https://issues.apache.org/jira/secure/attachment/12644694/KAFKA-1396.patch","08/May/14 05:16;guozhang;KAFKA-1396.patch;https://issues.apache.org/jira/secure/attachment/12643847/KAFKA-1396.patch","08/May/14 05:55;guozhang;KAFKA-1396_2014-05-07_14:55:09.patch;https://issues.apache.org/jira/secure/attachment/12643856/KAFKA-1396_2014-05-07_14%3A55%3A09.patch","09/May/14 06:57;guozhang;KAFKA-1396_2014-05-08_15:57:11.patch;https://issues.apache.org/jira/secure/attachment/12644040/KAFKA-1396_2014-05-08_15%3A57%3A11.patch","10/May/14 01:35;guozhang;KAFKA-1396_2014-05-09_10:35:07.patch;https://issues.apache.org/jira/secure/attachment/12644135/KAFKA-1396_2014-05-09_10%3A35%3A07.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,386942,,,Wed May 14 00:34:08 UTC 2014,,,,,,,,,,"0|i1unon:",387206,,,,,,,,,,,,,,,,,,,,"16/Apr/14 05:42;guozhang;1. I tried the test several times but cannot re-produce the hanging locally. So I can only debug based on the stack trace in the comments.

2. Following the stack trace, there is no ""synchronized"" function call along the trace; also it is not clear if a real dead-lock happens during the hanging.

3. It is suggested that the JVM GC could block any threads:

http://stackoverflow.com/questions/7067058/java-thread-dump-blocked-thread-without-waiting-to-lock
http://stackoverflow.com/questions/4016356/java-blocking-issue-why-would-jvm-block-threads-in-many-different-classes-metho

I agree this test takes long, but it is not a unit test but rather an integration test. I am wondering if we are sure there is occasional forever-hangs there or just occasional taking-too-long-due-to-GC? ;;;","16/Apr/14 11:31;junrao;Basically what I did was to disable the rest of the tests in this file and ran it 3 times on a mac laptop, in 2 times, the test didn't finish after more than 1 minute.;;;","17/Apr/14 01:48;guozhang;I did the same on a mac laptop and on a desktop, each for 10 times. All of them finished within 1 minute, some is close to 1 minute. So I think the problem is this integration test being long not having transient failures. One thing we can do is to reduce the number of server failure iterations (currently it is 5).

--- Desktop ---

Total time: 40.028 secs

real    0m40.122s
user    0m48.018s
sys    0m3.791s

Total time: 40.411 secs

real    0m40.501s
user    0m44.771s
sys    0m3.517s

Total time: 41.76 secs

real    0m41.863s
user    0m47.275s
sys    0m3.953s

Total time: 41.096 secs

real    0m41.192s
user    0m47.258s
sys    0m3.942s

Total time: 42.378 secs

real    0m42.478s
user    0m52.630s
sys    0m5.211s

Total time: 41.79 secs

real    0m41.893s
user    0m50.208s
sys    0m4.515s


--- Laptop ---

Total time: 49.44 secs

real    0m49.589s
user    1m6.507s
sys    0m5.650s

Total time: 48.087 secs

real    0m48.264s
user    1m2.772s
sys    0m5.352s

Total time: 48.157 secs

real    0m48.312s
user    1m1.393s
sys    0m5.156s

Total time: 47.686 secs

real    0m47.854s
user    0m57.030s
sys    0m4.664s

Total time: 48.67 secs

real    0m48.862s
user    1m4.015s
sys    0m5.774s

Total time: 48.875 secs

real    0m49.054s
user    1m0.465s
sys    0m5.154s

Total time: 47.233 secs

real    0m47.414s
user    0m59.274s
sys    0m4.835s

Total time: 48.635 secs

real    0m48.826s
user    1m1.937s
sys    0m5.646s

Total time: 49.261 secs

real    0m49.420s
user    1m3.514s
sys    0m5.081s

Total time: 49.883 secs

real    0m50.040s
user    1m4.248s
sys    0m5.244s
 ;;;","29/Apr/14 01:54;junrao;I suggest that we do the following.

1. Reduce the # iterations from 5 to 2 to reduce the execution time.

2. Wait for metadata propagation before start fetching.

3. There could be messages that get committed by the broker, but whose ack to the producer are lost, depending on when the brokers are bounced. So, the test needs to be more resilient. Perhaps we can make sure that uniqueProducedMessageSet is equal to or a subset of uniqueFetchedMessageSet.;;;","29/Apr/14 02:02;guozhang;+1 on 1,2.

I am a little unclear about 3, is this case not covered by only counting uniqueFetchedMessageSet and compare with the sent count on scheduler, which does not include duplicates either?;;;","29/Apr/14 08:09;junrao;On second thought, the existing test does handle #3.;;;","08/May/14 05:16;guozhang;Created reviewboard https://reviews.apache.org/r/21174/
 against branch origin/trunk;;;","08/May/14 05:55;guozhang;Updated reviewboard https://reviews.apache.org/r/21174/
 against branch origin/trunk;;;","09/May/14 06:57;guozhang;Updated reviewboard https://reviews.apache.org/r/21174/
 against branch origin/trunk;;;","10/May/14 01:35;guozhang;Updated reviewboard https://reviews.apache.org/r/21174/
 against branch origin/trunk;;;","14/May/14 04:48;guozhang;Created reviewboard https://reviews.apache.org/r/21406/
 against branch origin/trunk;;;","14/May/14 08:34;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stuck consumer with new consumer API in 0.9,KAFKA-3146,12933853,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,hachikuji,darkjh,darkjh,26/Jan/16 00:03,29/Jan/16 22:23,22/Mar/23 15:10,29/Jan/16 22:11,0.9.0.0,,,,,,,,,,,,,consumer,,,,0,,,,,,"I'm prototyping with the new consumer API of kafka 0.9 and I'm particularly interested in the `ConsumerRebalanceListener`.

My test setup is like the following:
  - 5M messages pre-loaded in one node kafka 0.9
  - 12 partitions, auto offset commit set to false
  - in `onPartitionsRevoked`, commit offset and flush the local state

The test run is like the following:
  - launch one process with 2 consumers and let it consume for a while
  - launch another process with 2 consumers, this triggers a rebalancing, and let these 2 processes run until messages are all consumed

The code is here: https://gist.github.com/darkjh/fe1e5a5387bf13b4d4dd

So at first, the 2 consumers of the first process each got 6 partitions. And after the rebalancing, each consumer got 3 partitions. It's confirmed by logging inside the `onPartitionAssigned` callback.

But after the rebalancing, one of the 2 consumers of the first process stop receiving messages, even if it has partitions assigned to: 

balance-1 pulled 7237 msgs ...
balance-0 pulled 7263 msgs ...
2016-01-22 15:50:37,533 [INFO] [pool-1-thread-2] o.a.k.c.c.i.AbstractCoordinator - Attempt to heart beat failed since the group is rebalancing, try to re-join group.
balance-1 flush @ 536637
balance-1 committed offset for List(balance-11, balance-10, balance-9, balance-8, balance-7, balance-6)
2016-01-22 15:50:37,575 [INFO] [pool-1-thread-1] o.a.k.c.c.i.AbstractCoordinator - Attempt to heart beat failed since the group is rebalancing, try to re-join group.
balance-0 flush @ 543845
balance-0 committed offset for List(balance-5, balance-4, balance-3, balance-2, balance-1, balance-0)
balance-0 got assigned List(balance-5, balance-4, balance-3)
balance-1 got assigned List(balance-11, balance-10, balance-9)
balance-1 pulled 3625 msgs ...
balance-0 pulled 3621 msgs ...
balance-0 pulled 3631 msgs ...
balance-0 pulled 3631 msgs ...
balance-1 pulled 0 msgs ...
balance-0 pulled 3643 msgs ...
balance-0 pulled 3643 msgs ...
balance-1 pulled 0 msgs ...
balance-0 pulled 3622 msgs ...
balance-0 pulled 3632 msgs ...
balance-1 pulled 0 msgs ...
balance-0 pulled 3637 msgs ...
balance-0 pulled 3641 msgs ...
balance-0 pulled 3640 msgs ...
balance-1 pulled 0 msgs ...
balance-0 pulled 3632 msgs ...
balance-0 pulled 3630 msgs ...
balance-1 pulled 0 msgs ...
......

`balance-0` and `balance-1` are the names of the consumer thread. So after the rebalancing, thread `balance-1` continues to poll but no message arrive, given that it has got 3 partitions assigned to after the rebalancing.

Finally other 3 consumers pulls all their partitions' message, the situation is like 

GROUP, TOPIC, PARTITION, CURRENT OFFSET, LOG END OFFSET, LAG, OWNER
balance-test, balance, 9, 417467, 417467, 0, consumer-2_/127.0.0.1
balance-test, balance, 10, 417467, 417467, 0, consumer-2_/127.0.0.1
balance-test, balance, 11, 417467, 417467, 0, consumer-2_/127.0.0.1
balance-test, balance, 6, 180269, 417467, 237198, consumer-2_/127.0.0.1
balance-test, balance, 7, 180036, 417468, 237432, consumer-2_/127.0.0.1
balance-test, balance, 8, 180197, 417467, 237270, consumer-2_/127.0.0.1
balance-test, balance, 3, 417467, 417467, 0, consumer-1_/127.0.0.1
balance-test, balance, 4, 417468, 417468, 0, consumer-1_/127.0.0.1
balance-test, balance, 5, 417468, 417468, 0, consumer-1_/127.0.0.1
balance-test, balance, 0, 417467, 417467, 0, consumer-1_/127.0.0.1
balance-test, balance, 1, 417467, 417467, 0, consumer-1_/127.0.0.1
balance-test, balance, 2, 417467, 417467, 0, consumer-1_/127.0.0.1 

So you can see, partition [6, 7, 8] still has messages, but the consumer can't pull them after the rebalancing. 

I've tried 0.9.0.0 release, trunk and 0.9.0 branch, for both server/broker and client.

One workaround (by Bruno Rassaerts), is to do a manual seek to the current position in the `onPartitionsAssigned` call back.

The corresponding mailing list discussion is here: http://mail-archives.apache.org/mod_mbox/kafka-users/201601.mbox/%3CCA%2BndhHok%3DemRceLuhwGHKwMCVQSmgTUeaxs-ycK-U2nLcc8Uhg%40mail.gmail.com%3E

",,darkjh,hachikuji,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jan 29 14:23:16 UTC 2016,,,,,,,,,,"0|i2rxjz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"26/Jan/16 02:26;hachikuji;[~darkjh] You need to commit offsets regularly for the progress to be updated. In the gist above, you only commit when the consumer is shutdown or rebalanced. I changed the poll loop to the following and ran several times on the 0.9.0 branch without seeing any problems:

{code}
def run(): Unit = {
    while (!Thread.currentThread().isInterrupted) {
      try {
        val records = kafkaConsumer.poll(100)
        println(s""$name pulled ${records.size} msgs ..."")
        Thread.sleep(50)
        for (msg <- records) {
          count += 1
        }
        commitOffset()
      } catch {
        case e: Exception =>
          println(""Error during processing of the message: "" + e)
      }
    }
  }
{code}

Note the call to commitSync() on every iteration of the poll loop. Can you try this change against the 0.9.0 branch and see if you still experience the issue?

Couple more notes from the gist: the commitSync call in the shutdown hook is incorrect. The consumer is not safe for concurrent access. A better way to handle it is to use wakeup() to interrupt the poll loop, and then call commitSync() before closing the consumer (which you should also make sure to do). You also need to make sure that you give the consumer enough time to actually commit the offsets prior to shutting down. Since you're using an executor, the easiest way to do this is to call shutdown() followed by awaitTermination(). Here's a gist which shows what I mean: https://gist.github.com/hachikuji/35023fe424438253ada3.;;;","29/Jan/16 20:42;darkjh;[~hachikuji] Thanks a lot Jason. I've used 0.9.0 branch for both broker and client code, and it indeed solved the problem, even without regularly commit offset.
Thanks also for the tips! I think this can be closed.  ;;;","29/Jan/16 22:23;ijuma;Thanks for reporting back [~darkjh];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replication Broken between Kafka 0.8.2.1 and 0.9 - NetworkClient.java uses wrong protocol version,KAFKA-2756,12910840,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,mbruce@blackberry.com,mbruce@blackberry.com,mbruce@blackberry.com,06/Nov/15 04:50,06/Nov/15 07:46,22/Mar/23 15:10,06/Nov/15 07:46,0.9.0.0,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"During a rolling upgrade from 0.8.2.1 to 0.9.0.0, replication between 0.9.0.0 and 0.8.2.1 fails due to
org.apache.kafka.clients.networkClient:handleCompletedReceives always using the latest version of the API Key available instead of the one specified by inter.broker.protocol.version.

This line should not use ProtoUtils.currentResponseSchema and instead call ProtoUtils.ResponseSchema and specify a version explicitly:
{code}
Struct body = (Struct) ProtoUtils.currentResponseSchema(apiKey).read(receive.payload());
{code}

This results in WARN messages like the following in the server.log file as the responses are decoded with the wrong Schema:
{code}
[2015-11-05 19:13:10,309] WARN [ReplicaFetcherThread-0-182050600], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@6cc18858. Possible cause: org.apache.kafka.common.protocol.types.SchemaException: Error reading field 'responses': Error reading field 'topic': java.nio.BufferUnderflowException (kafka.server.ReplicaFetcherThread)
{code}
{code}
[2015-11-03 16:55:15,178] WARN [ReplicaFetcherThread-1-182050600], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@224388b2. Possible cause: org.apache.kafka.common.protocol.types.SchemaException: Error reading field 'responses': Error reading field 'partition_responses': Error reading field 'record_set': java.lang.IllegalArgumentException (kafka.server.ReplicaFetcherThread)
{code}

",,githubbot,guozhang,leoxlin,mbruce@blackberry.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2750,,,,,,,,"06/Nov/15 06:20;mbruce@blackberry.com;KAFKA-2756.patch;https://issues.apache.org/jira/secure/attachment/12770889/KAFKA-2756.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 05 23:46:11 UTC 2015,,,,,,,,,,"0|i2o0vb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"06/Nov/15 06:19;mbruce@blackberry.com;diff --git a/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java b/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java
index 2c56751..a253e6d 100644
--- a/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java
+++ b/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java
@@ -459,7 +459,8 @@ public class NetworkClient implements KafkaClient {
             ClientRequest req = inFlightRequests.completeNext(source);
             ResponseHeader header = ResponseHeader.parse(receive.payload());
             short apiKey = req.request().header().apiKey();
-            Struct body = (Struct) ProtoUtils.currentResponseSchema(apiKey).read(receive.payload());
+            short apiVer = req.request().header().apiVersion();
+            Struct body = (Struct) ProtoUtils.responseSchema(apiKey,apiVer).read(receive.payload());
             correlate(req.request().header(), header);
             if (!metadataUpdater.maybeHandleCompletedReceive(req, now, body))
                 responses.add(new ClientResponse(req, now, false, body));;;;","06/Nov/15 07:11;guozhang;Thanks for the patch [~mbruce@blackberry.com] LGTM.

Just some background of this issue: the design of the versioning protocol is to recommend a simple client development for any various programming languages (e.g. third-party non-Java clients) such that developers can choose to only support one version in their clients. Therefore the response does not include the version id in its schema, and as a result the recommended upgrading path would be server first, clients later to make sure the servers always understand the request versions from the clients.

Now for inter-server communication during upgrades, which shares the same {code} NetworkClient {code} as the client, we need to let all the servers to stick to an common and older version of the protocol while doing the rounding bounce to upgrade them, as [~granthenke] specified in 

https://kafka.apache.org/090/documentation.html#upgrade 

For either of these cases, the network client should always expect the response version id to be the same as its request id, and hence use the version id of its request to decode the response. However if the clients are upgraded first before the servers and uses a version that the old servers do not recognize, the server has no way to cleanly notify the clients, hence the problem in KAFKA-2750. This issue can probably be fixed in future after KIP-35.;;;","06/Nov/15 07:28;githubbot;GitHub user guozhangwang opened a pull request:

    https://github.com/apache/kafka/pull/438

    KAFKA-2756: Use request version Id instead of latest version Id to parse the corresponding response.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/guozhangwang/kafka K2756

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/438.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #438
    
----
commit 011c0dd896540b5b425b90e83ccc85f5a7cdbc94
Author: Guozhang Wang <wangguoz@gmail.com>
Date:   2015-11-05T23:33:21Z

    v1

----
;;;","06/Nov/15 07:46;guozhang;Issue resolved by pull request 438
[https://github.com/apache/kafka/pull/438];;;","06/Nov/15 07:46;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/438
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stop logging WARN when client disconnects,KAFKA-2504,12861377,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jholoman,gwenshap,gwenshap,03/Sep/15 03:13,15/Sep/15 04:16,22/Mar/23 15:10,15/Sep/15 04:16,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"I thought we fixed this one, but it came back. This can be fill logs and is fairly useless. Should be logged at DEBUG level:

{code}
[2015-09-02 12:05:59,743] WARN Error in I/O with connection to /10.191.0.36 (org.apache.kafka.common.network.Selector)
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.kafka.common.network.PlaintextTransportLayer.read(PlaintextTransportLayer.java:111)
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:81)
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:154)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:135)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:296)
	at kafka.network.Processor.run(SocketServer.scala:405)
	at java.lang.Thread.run(Thread.java:745)
{code}

",,githubbot,gwenshap,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Sep 14 20:16:18 UTC 2015,,,,,,,,,,"0|i2jpqn:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"03/Sep/15 03:27;ijuma;Probably a similar one was fixed, this one has been there since January according to git:

{code}
catch (IOException e) {
    String desc = channel.socketDescription();
    if (e instanceof EOFException || e instanceof ConnectException)
        log.debug(""Connection {} disconnected"", desc);
    else
        log.warn(""Error in I/O with connection to {}"", desc, e);
    close(channel);
    this.disconnected.add(channel.id());
}
{code};;;","14/Sep/15 08:37;githubbot;GitHub user jholoman opened a pull request:

    https://github.com/apache/kafka/pull/211

    KAFKA-2504: Stop logging WARN when client disconnects

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/jholoman/kafka KAFKA-2504

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/211.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #211
    
----
commit d4b7243a24d75af5b809c6cd62549b1f5fd3b57c
Author: jholoman <jeff.holoman@gmail.com>
Date:   2015-09-13T04:15:56Z

    KAFKA-2504

----
;;;","15/Sep/15 04:15;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/211
;;;","15/Sep/15 04:16;gwenshap;Pushed to trunk. Thanks for fixing, [~jholoman].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
UnknownHostError looking for a ZK node crashes the broker,KAFKA-620,12616438,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,rathboma,rathboma,17/Nov/12 00:45,08/Feb/15 14:17,22/Mar/23 15:10,08/Feb/15 14:17,0.7.1,,,,,,,,,,,,,core,,,,0,,,,,,"If you totally kill a zookeeper node so that it's hostname no longer resolves to anything, the broker will die with a java.net.UnknownHostException.

You will then be unable to restart the broker until the unknown host(s) is removed from the server.properties.

We ran into this issue while testing our resilience to widespread AWS outages, if you can point me to the right place, I could have a go at fixing it? Unfortunately, I suspect the issue might be in the non-standard Zookeeper library that kafka uses.


Here's the stack trace:
org.I0Itec.zkclient.exception.ZkException: Unable to connect to [list of zookeepers]
	at org.I0Itec.zkclient.ZkConnection.connect(ZkConnection.java:66)
	at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:872)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:98)
	at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:84)
	at kafka.server.KafkaZooKeeper.startup(KafkaZooKeeper.scala:44)
	at kafka.log.LogManager.<init>(LogManager.scala:87)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:58)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:34)
	at kafka.Kafka$.main(Kafka.scala:50)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.net.UnknownHostException: zk-101
	at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$1.lookupAllHostAddr(InetAddress.java:850)
	at java.net.InetAddress.getAddressFromNameService(InetAddress.java:1201)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1154)
	at java.net.InetAddress.getAllByName(InetAddress.java:1084)
	at java.net.InetAddress.getAllByName(InetAddress.java:1020)
	at org.apache.zookeeper.ClientCnxn.<init>(ClientCnxn.java:387)
	at org.apache.zookeeper.ClientCnxn.<init>(ClientCnxn.java:332)
	at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:383)
	at org.I0Itec.zkclient.ZkConnection.connect(ZkConnection.java:64)
	... 9 more
",linux. Amazon's AMI,diederik,guozhang,joecrobak,junrao,nehanarkhede,rathboma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1082,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,258280,,,Sat Feb 07 16:06:02 UTC 2015,,,,,,,,,,"0|i0kr3j:",119207,,,,,,,,,,,,,,,,,,,,"17/Nov/12 03:41;junrao;Do you have other ZK hosts in your connection string?;;;","18/Nov/12 07:50;nehanarkhede;I would check if the zookeeper connection string has multiple zookeeper hosts specified. AFAIK, the zookeeper client (not zkclient) library has the ability to retry other zookeeper hosts if one is not reachable. I would expect, this exception should be caught within zookeeper client itself and Kafka should get an exception only when none of the zookeeper hosts are reachable. In that case, we probably don't want to start a 0.8 Kafka broker, since the 0.8 logic requires zookeeper to be available.;;;","04/Feb/15 14:36;guozhang;Is this a duplicate of KAFKA-1082?;;;","08/Feb/15 00:06;nehanarkhede;[~guozhang] It does. Feel free to close this as a duplicate so we can track the problem as part of KAFKA-1082.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
high level producer send should return a response,KAFKA-496,12606425,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,jkreps,junrao,junrao,07/Sep/12 00:10,12/Apr/16 07:18,22/Mar/23 15:10,10/Feb/14 07:58,,,,,,,0.9.0.0,,,,,,,core,,,,1,features,,,,,"Currently, Producer.send() doesn't return any value. In 0.8, since each produce request will be acked, we should pass the response back. What we can do is that if the producer is in sync mode, we can return a map of (topic,partitionId) -> (errorcode, offset). If the producer is in async mode, we can just return a null.",,adenysenko,clehene,craigwblake,jkreps,jmcnulty,junrao,matan,nehanarkhede,noslowerdna,steamshon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,259200,259200,,0%,259200,259200,,,,,,,,,,,,,,KAFKA-1227,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,241618,,,Sat Feb 01 19:39:31 UTC 2014,,,,,,,,,,"0|i029br:",11112,,,,,,,,,,,,,,,,,,,,"07/Sep/12 01:13;jkreps;An alternative would be give a Future back which would be immediately satisfied in the case of a synchronous call and would eventually become satisfied in the event of an async call. This is probably slightly harder to implement.;;;","07/Sep/12 01:32;jkreps;A more concrete description would be that we return a ProduceResponse which has an offset and error. Calls to 
  response.offset() or response.error()
would block until the request completed in the case of an async request. We would probably also need 
  response.onComplete(fun)
to register a callback that would be run when the response was done.

One question, though, is whether an error should result in an exception or in an error code when you try to get either field.

The advantage of this is that the semantics of produce would remain the same for both sync and async. Code written to work with sync could be changed to async with only a config change.

It would be worth thinking through if there is a use case for this because it is likely a bit more complicated.;;;","19/Sep/12 01:55;junrao;The following is a straw-man proposal:

Define the following class and trait.

class ProducerCallbackResponse (val response: ProducerResponse) {
}

trait ProducerCallback[V] {
  def onSerializationError(event: V, e: Throwable)
  def onSendResponse(response: ProducerResponse)

  def getCallbackResponse(response: ProducerResponse): Option[ProducerCallbackResponse]
}

1. In Producer, add a new api registerCallBack(callback: ProducerCallback[V]). Change the send api to:
   def send(producerData: ProducerData[K,V]*) : Option[ProducerCallbackResponse]

2. For sync Producer, define the following default callback. Send() will either get an exception or a ProducerCallbackResponse.

class DefaultSyncProducerCallback[V] extends ProducerCallback[V] {
  var response: Option[ProducerCallbackResponse] = none
  def oonSerializationError(event: V, e: Throwable) {
       throw e   
   }
   def onSendResponse(response: ProducerResponse) {
       // instantiate response with a DefaultSyncProducerResponse
       response = Some(new ProducerCallbackResponse(response))
   }

   def getCallbackResponse(): ProducerCallbackResponse = {
      return response
   }
}   

3. For async Producer, define the following default callback that simply ignores the callback.

class DefaultAsyncProducerCallback[V] extends ProducerCallback[V] {
  def onSerializationError(event: V, e: Throwable) {
       // let it go  
   }
   def onSendResponse(response: ProducerResponse) {
       // let it go
   }

   def getCallbackResponse(): ProducerCallbackResponse = {
      return none
   }
}   

4. A user can also define and register it's own customized ProducerCallback.
;;;","19/Sep/12 02:33;jkreps;I would propose we work back from what the user code would look like.

One point I would like to bring up is that the current producer only allows a single request at a time. This is a huge hit on throughput since a single producer can only utilize only one partition on one broker at any given time. For some uses where the # producers is huge compared to the number of brokers this is fine, but this is not universally true. The fix for this is to make the send() call non-blocking and support multiplexing requests over the connection. This is not hard to do--we have the correlation id in the requests so the only change is in the network layer to avoid reordering requests from the same connection. If we made this change that would make the producer request ALWAYS be a sort of future.

The state of futures in java and scala seems to be a little complex. Java has a future but it doesn't allow registering a callback. Fineagle and Akka both have custom versions of Future. There is a proposal to unify all these, though I don't know the status (http://docs.scala-lang.org/sips/pending/futures-promises.html).

For our purpose I recommend we just make our own. It supports two methods
trait Future[T] {
  /* returns true if the result is ready */
  def complete: Boolean
  /* add a function to be called when the result is ready. The function takes the result of the execution--either an exception or a object of type T. Note you can call this more than once to register multiple actions. */
  def onComplete((Either[T, Exception]) => Unit): Future[T]
  /* await completion and return the result or throw the exception */
  def result: T
}

So the function prototype would be
   def send(data: ProduceData*) => Future[ProduceResponse]

In the current code the future would immediately be satisfied for the sync producer. When we have fully implemented the non-blocking client it wouldn't. But this change would be transparent to the user.

I think there are a couple of use cases
1. You don't really care what the result it (basically ""fire and forget""), in which case you use this api as you do today:
     send(...)
2. You want to make sure the send succeeded or do some follow up action but you don't mind blocking the current thread:
    val response = send(...).result
3. You want to do something more complicated. This could be sending out lots of requests without blocking then handling responses or asynchronously handling failures or whatever. In this case you would use
    send(...).onComplete { result: Either[T, Exception] =>
        result match {
          case result: T => .. do something
          case e: Exception => handle exception
     }
      


  ;;;","19/Sep/12 03:13;junrao;Actually, Producer already allows a client to send a list of ProducerData.;;;","05/Dec/12 07:54;junrao;Moving this to 0.8.1.;;;","21/Dec/12 02:22;jkreps;I found this helpful in thinking about futures: http://docs.scala-lang.org/overviews/core/futures.html;;;","06/Mar/13 03:03;matan;I spent some time trying to first-iteration-refactor the producer's sending activity, as a basis for playing around with adding some persistence to it.... I'll probably wait for this item here (KAFKA-496) to be implemented first. 

I'm writing here just to add that it would potentially be nice if the producer's wrappers around sending messages would become simplified in the code through some behavior-maintaining refactoring. The producer internals around managing the queue and around sync/async flows can probably be made much simpler in terms of class and method relationships (or the relationships between producer and producer.async), as part of modifications implied on the previous posts above. I'm writing this as it may seem that KAFKA-496 here may take care of refactoring in this area anyway. It seems this can help future modifications... ;;;","02/Feb/14 03:39;nehanarkhede;Will be fixed as part of the new producer release (0.9);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Consumer doesn't get messages from some partitions after reassign,KAFKA-3120,12932506,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Duplicate,,jakub.neubauer,jakub.neubauer,20/Jan/16 03:52,25/May/16 00:46,22/Mar/23 15:10,25/May/16 00:46,0.9.0.0,,,,,,,,,,,,,,,,,0,,,,,,"I tested some scenario on one-node cluster with this setup:
* A topic with 5 partitions, 1 replica.
* One producer (new java client)
* 2 consumers were started (let's say A and B). Using the new java client. 2 partitions to A, 3 partitions to B were assigned.

Then I stopped one of the consumers (cleanly). The partitions were re-assigned (The consumer got all 5 partitions in the ""ConsumerRebalanceListener.onPartitionsAssigned"" listener.

But as messages were produced, the living consumer received only messages of some partitions (magically those that belonged to the now-dead consumer).
The messages were not lost. After I restarted the second consumer, it got the messages that it previously didn't get. But without restarting, the messages were not consumed by it.

It is quite serious issue, since there is no sign of something being wrong. Everything seems to be working. So the administrator has no chance to get the idea that (only some) messages are not consumed on the ""healthy"" system.",Linux,hachikuji,jakub.neubauer,vahid,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2877,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue May 24 16:46:00 UTC 2016,,,,,,,,,,"0|i2rp9j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"20/Jan/16 03:56;jakub.neubauer;BTW, this situation appeared more times during testing. So not occasional behaviour.;;;","20/Jan/16 08:47;hachikuji;[~jakub.neubauer] Have you tested against the 0.9.0 branch? This sounds like a duplicate of KAFKA-2877.;;;","24/May/16 02:38;vahid;I can't reproduce this using the current trunk.;;;","25/May/16 00:46;hachikuji;I'm going to go ahead and close this as a duplicate of KAFKA-2877. [~jakub.neubauer] Feel free to reopen if you hit this problem on 0.9.0.1 or later.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Socket server selector can stuck on one send in tight loop.,KAFKA-2936,12917796,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,onurkaraman,becket_qin,becket_qin,03/Dec/15 07:46,18/Feb/16 17:30,22/Mar/23 15:10,03/Feb/16 02:49,0.9.0.0,,,,,,,,,,,,,network,,,,0,,,,,,"When broker was sending a FetchResponse it is possible that the data to be sent back is truncated. In this case, a KafkaException will be thrown. This exception is caught by processor and the selector will be sending the message in a tight while loop. It will continue doing this until the socket is closed by the client due to request timeout.

We should have a max retry for the response send.",,becket_qin,ijuma,junrao,onurkaraman,turek@avast.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2978,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Feb 02 18:49:28 UTC 2016,,,,,,,,,,"0|i2p7k7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"30/Jan/16 00:11;ijuma;[~onurkaraman], are you still planning to submit a PR for this for 0.9.0.1?;;;","30/Jan/16 09:10;onurkaraman;Hi [~ijuma]. I actually forgot about this and have too much on my plate now. My apologies! Feel free to give it a shot if you'd like.;;;","03/Feb/16 00:05;junrao;[~becket_qin], is this still an issue? We fixed a similar issue in KAFKA-2813.;;;","03/Feb/16 02:48;becket_qin;[~junrao] It seems KAFKA-2813 should have fixed the problem. We were probably still running on an older version and did not notice the fix was made in selector. I will close the ticket.;;;","03/Feb/16 02:49;becket_qin;This issue has been fixed in KAFKA-2813. Close as duplicate.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Correctly Handle InvalidTopicException in KafkaApis.getTopicMetadata(),KAFKA-2393,12850640,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,granthenke,granthenke,01/Aug/15 00:29,06/Aug/15 06:57,22/Mar/23 15:10,06/Aug/15 06:57,0.8.2.1,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"It seems that in KafkaApis.getTopicMetadata(), we need to handle InvalidTopicException explicitly when calling AdminUtils.createTopic (by returning the corresponding error code for that topic). Otherwise, we may not be able to get the metadata for other valid topics. This seems to be an existing problem, but KAFKA-2337 makes InvalidTopicException more likely to happen. ",,githubbot,granthenke,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2337,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Aug 05 22:57:08 UTC 2015,,,,,,,,,,"0|i2i6sn:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"01/Aug/15 00:30;granthenke;Makes this scenario more likely to occur.;;;","06/Aug/15 05:47;githubbot;GitHub user granthenke opened a pull request:

    https://github.com/apache/kafka/pull/117

    KAFKA-2393: Correctly Handle InvalidTopicException in KafkaApis.getTo…

    …picMetadata()

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka invalid-topic

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/117.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #117
    
----
commit 0abda5fffe7cb7cda585941e4909be304ad011f6
Author: Grant Henke <granthenke@gmail.com>
Date:   2015-08-05T21:45:25Z

    KAFKA-2393: Correctly Handle InvalidTopicException in KafkaApis.getTopicMetadata()

----
;;;","06/Aug/15 06:56;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/117
;;;","06/Aug/15 06:57;junrao;Thanks for the patch. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Log deletion on stopping replicas should be async,KAFKA-1911,12771581,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,mgharat,jjkoshy,jjkoshy,01/Feb/15 14:46,27/Dec/16 06:38,22/Mar/23 15:10,01/Dec/16 03:04,,,,,,,,,,,,,,log,replication,,,0,newbie++,newbiee,,,,"If a StopReplicaRequest sets delete=true then we do a file.delete on the file message sets. I was under the impression that this is fast but it does not seem to be the case.

On a partition reassignment in our cluster the local time for stop replica took nearly 30 seconds.

{noformat}
Completed request:Name: StopReplicaRequest; Version: 0; CorrelationId: 467; ClientId: ;    DeletePartitions: true; ControllerId: 1212; ControllerEpoch: 53 from client/...:45964;totalTime:29191,requestQueueTime:1,localTime:29190,remoteTime:0,responseQueueTime:0,sendTime:0
{noformat}

This ties up one API thread for the duration of the request.

Specifically in our case, the queue times for other requests also went up and producers to the partition that was just deleted on the old leader took a while to refresh their metadata (see KAFKA-1303) and eventually ran out of retries on some messages leading to data loss.

I think the log deletion in this case should be fully asynchronous although we need to handle the case when a broker may respond immediately to the stop-replica-request but then go down after deleting only some of the log segments.",,avianey,becket_qin,githubbot,granders,jjkoshy,mgharat,sutambe,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Dec 26 22:38:02 UTC 2016,,,,,,,,,,"0|i251tz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"13/May/15 15:11;avianey;it should handle the case of a producer producing log to this replica...;;;","23/Sep/15 01:33;jjkoshy;The original motivation in this ticket was to avoid a high latency request from tying up request handlers. However, while thinking through some nuances of delete topic, I think delete topic would also benefit from this. Since stop-replica-requests can take a while to finish delete topic can also take a while (apart from failure cases such as a replica being down).

I think the easiest way to fix this would be to just rename the partition directory from <topic><partId> to something like <topic><partId>deleted<seqNo> and asynchronously delete that. The <seqNo> is probably needed if a user were to delete and recreate multiple times in rapid fire for whatever reason.;;;","13/Nov/15 07:52;mgharat;[~geoffra] are you actively working on this. If not I would like to take it up as I have recently started testing DeleteTopic usecases.

Thanks,

Mayuresh;;;","13/Nov/15 08:25;granders;[~mgharat] Feel free to grab this, I'm not actually working on this.;;;","08/Dec/15 06:09;githubbot;GitHub user MayureshGharat opened a pull request:

    https://github.com/apache/kafka/pull/636

    KAFKA-1911

    Made delete topic on brokers async

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/MayureshGharat/kafka kafka-1911

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/636.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #636
    
----
commit 86a432c21eb2b206ffe120a4a4172a087fb109d4
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2015-12-07T22:01:22Z

    Made Delete topic on the brokers Async

----
;;;","26/Jul/16 07:54;sutambe;Hi [~mgharat], I would like to take your patch over. I've rebased your patch on top of the latest trunk and fixed a couple of test failures. I'll send a pull-request soon.;;;","26/Jul/16 08:23;githubbot;GitHub user sutambe opened a pull request:

    https://github.com/apache/kafka/pull/1664

    KAFKA-1911: Async delete topic

    The last patch submitted by @MayureshGharat (back in Dec 15) has been rebased to the latest trunk. I took care of a couple of test failures (MetricsTest) along the way. @jjkoshy , @granders , @avianey , you may be interested in this PR.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/sutambe/kafka async-delete-topic

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1664.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1664
    
----
commit dbc54e6bcd5001c478028f7032f9ff0a59f53f89
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2015-12-07T22:01:22Z

    Made Delete topic on the brokers Async
    
    Signed-off-by: Sumant Tambe <sutambe@linkedin.com>

commit 5bfb31b070502ae06a65ec9cb5fcd4c8d6693278
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2015-12-17T23:13:07Z

    Change the file pointers for log and index to point to the renamed directory
    
    Signed-off-by: Sumant Tambe <sutambe@linkedin.com>

commit 692f8768f0903a60274f317f6a238b5a2c621c1f
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2015-12-21T23:54:15Z

    Added a check to not recoverLogs for directories marked for delete. This is to speedup startup process. Also added check that Log directories ending with .delete be added to a separate set of logs that the are to be deleted asynchronously.
    
    Signed-off-by: Sumant Tambe <sutambe@linkedin.com>

commit b6920ffaef5d086a691eba1ac4a66d429d1c5fcf
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2015-12-22T00:00:50Z

    Removed a bug from earlier commit
    
    Signed-off-by: Sumant Tambe <sutambe@linkedin.com>

commit 161cb8c669298744d60eec75ca5072d3b0f0045f
Author: Mayuresh Gharat <mgharat@mgharat-ld1.linkedin.biz>
Date:   2015-12-22T00:03:44Z

    Removed the extra ';'
    
    Signed-off-by: Sumant Tambe <sutambe@linkedin.com>

commit 161c14c5486cbe1fc0411fe6fc5745c78e36bedc
Author: MayureshGharat <gharatmayuresh15@gmail.com>
Date:   2016-03-10T21:25:38Z

    Addressed Joel's comments on the patch
    
    Signed-off-by: Sumant Tambe <sutambe@linkedin.com>

commit 859dbb7a1d3f2b7b9ddc5d8b9edc128b1903f28c
Author: MayureshGharat <gharatmayuresh15@gmail.com>
Date:   2016-04-01T20:26:11Z

    Addressed the NPE issue with race condition and also issues related to loading segments on a crash
    
    Signed-off-by: Sumant Tambe <sutambe@linkedin.com>

commit b93328cd446d9e0c753a966217b8b58fc6150ec6
Author: Sumant Tambe <sutambe@linkedin.com>
Date:   2016-07-26T00:11:25Z

    Async log deletion rebase and successful testing

----
;;;","01/Dec/16 02:41;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1664
;;;","27/Dec/16 06:38;githubbot;Github user pono closed the pull request at:

    https://github.com/apache/kafka/pull/636
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Intermittent network + DNS issues can cause brokers to permanently drop out of a cluster,KAFKA-2193,12829978,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,thomaslee,thomaslee,15/May/15 04:47,21/Nov/17 22:58,22/Mar/23 15:10,21/Nov/17 22:58,0.8.1.1,,,,,,,,,,,,,,,,,0,broker,,,,,"Our Kafka cluster recently experienced some intermittent network & DNS resolution issues such that this call to connect to Zookeeper failed with an UnknownHostException:

https://github.com/sgroschupf/zkclient/blob/0630c9c6e67ab49a51e80bfd939e4a0d01a69dfe/src/main/java/org/I0Itec/zkclient/ZkConnection.java#L67

We observed this happen during a processStateChanged(KeeperState.Expired) call:

https://github.com/sgroschupf/zkclient/blob/0630c9c6e67ab49a51e80bfd939e4a0d01a69dfe/src/main/java/org/I0Itec/zkclient/ZkClient.java#L649

the session expiry was in turn caused by what we suspect to be intermittent network issues.

The failed ZK reconnect seemed to put ZkClient into a state where it would never recover and the Kafka broker into a state where it would need a restart to rejoin the cluster: ZkConnection._zk == null, 0.3.x doesn't appear to automatically try to make further attempts to reconnect after the failure, and obviously no further state transitions seem likely to happen without a connection to ZK.

The newer zkclient 0.4.0/0.5.0 releases will helpfully fire a notification when this occurs, so the brokers have an opportunity to handle this sort of failure in a more graceful manner (e.g. by trying to reconnect after some backoff period):

https://github.com/sgroschupf/zkclient/blob/0.4.0/src/main/java/org/I0Itec/zkclient/ZkClient.java#L461

Happy to provide more info here if I can.",,ijuma,thomaslee,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-5473,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Nov 21 14:58:04 UTC 2017,,,,,,,,,,"0|i2er1z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Nov/17 22:58;ijuma;Duplicate of KAFKA-5473.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove max.message.bytes from topic config,KAFKA-1844,12765399,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,sriharsha,sriharsha,sriharsha,07/Jan/15 23:52,08/Jan/15 11:21,22/Mar/23 15:10,08/Jan/15 11:21,,,,,,,,,,,,,,,,,,0,,,,,,"This bug is related to KAFKA-1273. Kaka Broker on startup checks to see if the configured replica.fetch.max.bytes >= message.max.bytes. But users can override message.max.bytes per topic and there is no such validation happening for per topic message.max.bytes. If the users configured message.max.bytes > replica.fetch.max.bytes , followers won't be able to fetch data.
[~junrao] suggested "" I was thinking that one way is to just disallow customizing max.message.size per topic. Such customization may break downstream consumers like MirrorMaker. I am not sure if there is a strong use case for the per topic customization.""",,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jan/15 04:50;sriharsha;KAFKA-1844.patch;https://issues.apache.org/jira/secure/attachment/12690610/KAFKA-1844.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jan 08 03:20:47 UTC 2015,,,,,,,,,,"0|i241db:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"08/Jan/15 04:50;sriharsha;Created reviewboard https://reviews.apache.org/r/29668/diff/
 against branch origin/trunk;;;","08/Jan/15 11:20;sriharsha;There is already work being done in KAFKA-1786. Closing this as duplicate.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade to zkclient-0.5,KAFKA-2169,12826984,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,parth.brahmbhatt,nehanarkhede,nehanarkhede,05/May/15 01:44,21/Jul/15 00:19,22/Mar/23 15:10,19/May/15 04:03,0.8.2.0,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,zkclient-0.5 is released http://mvnrepository.com/artifact/com.101tec/zkclient/0.5 and has the fix for KAFKA-824,,githubbot,i_maravic,jijohn,junrao,nehanarkhede,parth.brahmbhatt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-824,KAFKA-1695,,,,,,,KAFKA-1082,,,,,,KAFKA-2182,,,,,,,,,,"12/May/15 02:34;parth.brahmbhatt;KAFKA-2169.patch;https://issues.apache.org/jira/secure/attachment/12731973/KAFKA-2169.patch","12/May/15 02:06;parth.brahmbhatt;KAFKA-2169.patch;https://issues.apache.org/jira/secure/attachment/12731967/KAFKA-2169.patch","12/May/15 04:53;parth.brahmbhatt;KAFKA-2169_2015-05-11_13:52:57.patch;https://issues.apache.org/jira/secure/attachment/12732008/KAFKA-2169_2015-05-11_13%3A52%3A57.patch","16/May/15 01:19;parth.brahmbhatt;KAFKA-2169_2015-05-15_10:18:41.patch;https://issues.apache.org/jira/secure/attachment/12733193/KAFKA-2169_2015-05-15_10%3A18%3A41.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jul 20 16:19:27 UTC 2015,,,,,,,,,,"0|i2e97z:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"05/May/15 02:26;parth.brahmbhatt;I am working on a patch for this as the move to 0.5 is required to secure zk node entries as part of kafka security work.;;;","08/May/15 04:17;githubbot;GitHub user Parth-Brahmbhatt opened a pull request:

    https://github.com/apache/kafka/pull/61

    KAFKA-2169: Moving to zkClient 0.5 release.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/Parth-Brahmbhatt/kafka KAFKA-2169

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/61.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #61
    
----
commit e5eb373dcec7562292cec32f3962e42dda5cea24
Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>
Date:   2015-05-07T20:15:55Z

    KAFKA-2169: Moving to zkClient 0.5 release.

----
;;;","08/May/15 23:45;i_maravic;We, Spotify, have just been hit by a BUG that's related to ZkClient. It made a whole Kafka cluster go down.

Long story short, we've restarted TOR switch and all of our brokers from the cluster lost all the connectivity with the zookeeper cluster, which was living in another rack. Because of that, all the connections to Zookeeper got expired.

Everything would be fine if we haven't lost hostname to IP Address mapping for some reason. Since we did lost that mapping, we got a UnknownHostException when the broker tried to reconnect. This exception got swallowed up, and we never got reconnected to Zookeeper, which in turn made our cluster of brokers useless.

If we had ""handleSessionEstablishmentError"" function, the whole exception could be caught, we could just completely kill KafkaServer process and start it cleanly, since this kind of exception is fatal for the KafkaCluster.

{code}
2015-05-05T12:49:01.709+00:00 127.0.0.1 apache-kafka[main-EventThread] INFO  zookeeper.ZooKeeper  - Initiating client connection, connectString=zookeeper1.spotify.net:2181,zookeeper2.spotify.net:2181,zookeeper3.spotify.net:2181/gabobroker-local sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@7303d690
2015-05-05T12:49:01.711+00:00 127.0.0.1 apache-kafka[main-EventThread] ERROR zookeeper.ClientCnxn  - Error while calling watcher
2015-05-05T12:49:01.711+00:00 127.0.0.1 java.lang.RuntimeException: Exception while restarting zk client
2015-05-05T12:49:01.711+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient.processStateChanged(ZkClient.java:462)
2015-05-05T12:49:01.711+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient.process(ZkClient.java:368)
2015-05-05T12:49:01.711+00:00 127.0.0.1 at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
2015-05-05T12:49:01.711+00:00 127.0.0.1 at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
2015-05-05T12:49:01.711+00:00 127.0.0.1 Caused by: org.I0Itec.zkclient.exception.ZkException: Unable to connect to zookeeper1.spotify.net:2181,zookeeper2.spotify.net:2181,zookeeper3.spotify.net:2181/gabobroker-local
2015-05-05T12:49:01.711+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkConnection.connect(ZkConnection.java:66)
2015-05-05T12:49:01.711+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient.reconnect(ZkClient.java:939)
2015-05-05T12:49:01.711+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient.processStateChanged(ZkClient.java:458)
2015-05-05T12:49:01.711+00:00 127.0.0.1 ... 3 more
2015-05-05T12:49:01.712+00:00 127.0.0.1 Caused by: java.net.UnknownHostException: zookeeper1.spotify.net: Name or service not known
2015-05-05T12:49:01.712+00:00 127.0.0.1 at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
2015-05-05T12:49:01.712+00:00 127.0.0.1 at java.net.InetAddress$1.lookupAllHostAddr(InetAddress.java:901)
2015-05-05T12:49:01.712+00:00 127.0.0.1 at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1293)
2015-05-05T12:49:01.712+00:00 127.0.0.1 at java.net.InetAddress.getAllByName0(InetAddress.java:1246)
2015-05-05T12:49:01.712+00:00 127.0.0.1 at java.net.InetAddress.getAllByName(InetAddress.java:1162)
2015-05-05T12:49:01.712+00:00 127.0.0.1 at java.net.InetAddress.getAllByName(InetAddress.java:1098)
2015-05-05T12:49:01.712+00:00 127.0.0.1 at org.apache.zookeeper.client.StaticHostProvider.<init>(StaticHostProvider.java:61)
2015-05-05T12:49:01.712+00:00 127.0.0.1 at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:445)
2015-05-05T12:49:01.712+00:00 127.0.0.1 at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:380)
2015-05-05T12:49:01.713+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkConnection.connect(ZkConnection.java:64)
2015-05-05T12:49:01.713+00:00 127.0.0.1 ... 5 more
2015-05-05T12:49:01.713+00:00 127.0.0.1 apache-kafka[ZkClient-EventThread-18-zookeeper1.spotify.net:2181,zookeeper2.spotify.net:2181,zookeeper3.spotify.net:2181/gabobroker-local] ERROR zkclient.ZkEventThread  - Error handling event ZkEvent[Children of /config/changes changed sent to kafka.server.TopicConfigManager$ConfigChangeListener$@17638f6]
2015-05-05T12:49:01.713+00:00 127.0.0.1 java.lang.NullPointerException
2015-05-05T12:49:01.713+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkConnection.exists(ZkConnection.java:95)
2015-05-05T12:49:01.713+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient$3.call(ZkClient.java:439)
2015-05-05T12:49:01.713+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient$3.call(ZkClient.java:436)
2015-05-05T12:49:01.713+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
2015-05-05T12:49:01.713+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient.exists(ZkClient.java:436)
2015-05-05T12:49:01.713+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient.exists(ZkClient.java:445)
2015-05-05T12:49:01.714+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient$7.run(ZkClient.java:566)
2015-05-05T12:49:01.714+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
2015-05-05T12:49:01.714+00:00 127.0.0.1 apache-kafka[main-EventThread] INFO  zookeeper.ClientCnxn  - EventThread shut down
2015-05-05T12:49:01.714+00:00 127.0.0.1 apache-kafka[ZkClient-EventThread-18-zookeeper1.spotify.net:2181,zookeeper2.spotify.net:2181,zookeeper3.spotify.net:2181/gabobroker-local] ERROR zkclient.ZkEventThread  - Error handling event ZkEvent[Data of /controller changed sent to kafka.server.ZookeeperLeaderElector$LeaderChangeListener@18360394]
2015-05-05T12:49:01.714+00:00 127.0.0.1 java.lang.NullPointerException
2015-05-05T12:49:01.714+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkConnection.exists(ZkConnection.java:95)
2015-05-05T12:49:01.714+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient$3.call(ZkClient.java:439)
2015-05-05T12:49:01.714+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient$3.call(ZkClient.java:436)
2015-05-05T12:49:01.714+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
2015-05-05T12:49:01.714+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient.exists(ZkClient.java:436)
2015-05-05T12:49:01.714+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:544)
2015-05-05T12:49:01.714+00:00 127.0.0.1 at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
{code};;;","09/May/15 00:09;parth.brahmbhatt;Here is the commit that added that method to zkClient. https://github.com/sgroschupf/zkclient/commit/ed48a6e4061b06790c1fc0df7a92b1f86dcb416a#diff-93471cb6deda2b6e1ce4aeb855fba8c5L462

Before this method was added zkClient threw RunTimeException and kafka dealt with it. To be clear we are not swallowing exceptions we are throwing the exact same exception that we got from zkClient in previous versions.  I recommend filing a different jira if you think this behavior needs to be updated. ;;;","09/May/15 15:31;i_maravic;[~parth.brahmbhatt] If you look at the stack trace more closely, you can see that you're swallowing that exact exception.
As far as I can see, all the exceptions, that are thrown while handling watchers are happily swallowed by ClientCnx in zookeeper and hence ignored by Kafka. In this particular case Kafka is just ignoring fatal exception, and it happily allows zkClient to shutdown. 

Since the reconnect event is run as a Zookeeper watcher, on the Zookeeper's ClientCnxn Event Thread, all the exception thrown from there are just swallowed here:

https://github.com/apache/zookeeper/blob/trunk/src/java/main/org/apache/zookeeper/ClientCnxn.java#L543

I'll open up a new JIRA ticket for this.


;;;","12/May/15 01:16;junrao;Parth,

Thanks for the patch. Since we haven't officially switched to github, could you still attach the patch to the jira?

A few comments on the patch.
1. Could you verify that zkClient 0.5 is api compatible with 0.3? For example, in the 0.8.2.0 release, if you just replace zkclient 0.3 jar with the 0.5 jar, does the consumer still work?
2. I agree with [~i_maravic]. If we can't establish a new ZK session, we should probably just let the broker or the consumer exit.
3. In the broker, the broker and the controller use the same zkclient instance. So the actually logic for handleSessionEstablishmentError() just needs to be done in one place. Similarly, on the consumer side, there is only one zkclient instance.
 ;;;","12/May/15 02:06;parth.brahmbhatt;Created reviewboard https://reviews.apache.org/r/34047/diff/
 against branch origin/trunk;;;","12/May/15 02:34;parth.brahmbhatt;Created reviewboard https://reviews.apache.org/r/34050/diff/
 against branch origin/trunk;;;","12/May/15 02:47;parth.brahmbhatt;Posted a review on review board. https://reviews.apache.org/r/34050/diff/
1) I tried console-producer and console-consumer at trunk with only my changes applied and it works.
2) I do not disagree with the approach, however that is a change in behavior and I was trying to get the upgrade in given its blocking other jiras without having to tie that behavior change discussion to this jira. I have modified the behavior so it will now do System.exit.
3) Not sure what you mean here , we are handling it as part of handleSessionEstablishmentError() in all cases. ;;;","12/May/15 04:25;junrao;1) By api compatibility, I meant the following. Let's say an application uses a third party library that includes a Kafka consumer. Let's say that the third party library is built with Kafka 0.8.2 jars. If the api is compatible, the application can upgrade to Kafka 0.8.3 with the same third party library w/o forcing it to recompile. To test this out, you can get a Kafka 0.8.2 binary release, replace everything in libs with the jars in a Kafka 0.8.3 binary release (in particular, the new zkclient jar) and see if console consumer in Kafka 0.8.2 still works.
3) Commented on the RB. ;;;","12/May/15 04:53;parth.brahmbhatt;Updated reviewboard https://reviews.apache.org/r/34050/diff/
 against branch origin/trunk;;;","12/May/15 05:54;junrao;Parth,

1. Have you done the api compatibility test?
3. Did you address the comment on handleSessionEstablishmentError() in the RB?

Thanks,;;;","12/May/15 05:57;parth.brahmbhatt;[~junrao]
1) Yes I tested with 0.8.2 and it works fine.
2) I commented on the RB and updated it.;;;","14/May/15 05:01;junrao;Thought a bit more about this. When handling handleSessionEstablishmentError() in the consumer, we can't just exit since that will kill the application.

There's a patch in KAFKA-1082 to upgrade to zkclient-0.4. The patch there tries to auto reconnect in handleSessionEstablishmentError() by ingesting a session expiration event through zkclient.process(). This handles the situation better. However, the approach doesn't quite work since zkclient.process() can only be called from the event thread in zkclient. So, I am not sure if there is an easy way to auto reconnect through the zkclient interface.

Given that handleSessionEstablishmentError is a rare event and we are removing the ZK dependency in the new consumer, perhaps we can do the following.
1. In the listeners in the consumer, just log this as an error. We just need to log this error in one of the listeners.
2. In the listeners in the broker, exit on such an error. To be consistent with 1, we can just exit in one of the listeners.
;;;","16/May/15 01:19;parth.brahmbhatt;Updated reviewboard https://reviews.apache.org/r/34050/diff/
 against branch origin/trunk;;;","16/May/15 01:21;parth.brahmbhatt;[~junrao] updated the review with changes you requested.;;;","19/May/15 04:03;junrao;Thanks for the patch. +1 and committed to trunk.;;;","21/Jul/15 00:19;githubbot;Github user Parth-Brahmbhatt closed the pull request at:

    https://github.com/apache/kafka/pull/61
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hold the produce request with ack > 1 in purgatory until replicas' HW has larger than the produce offset (KIP-101),KAFKA-1211,12689354,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,benstopford,guozhang,guozhang,17/Jan/14 05:13,07/Apr/17 22:33,22/Mar/23 15:10,07/Apr/17 05:53,,,,,,,0.11.0.0,,,,,,,,,,,1,reliability,,,,,"Today during leader failover we will have a weakness period when the followers truncate their data before fetching from the new leader, i.e., number of in-sync replicas is just 1. If during this time the leader has also failed then produce requests with ack >1 that have get responded will still be lost. To avoid this scenario we would prefer to hold the produce request in purgatory until replica's HW has larger than the offset instead of just their end-of-log offsets.",,abhishek.agarwal,antigremlin,aozeritsky,astubbs,BigAndy,cagatayk,cmolter,easyfmxu,fpj,guozhang,gwenshap,ijuma,jthakrar,junrao,kzadorozhny-tubemogul,mazhar.shaikh.in,mkizner,nehanarkhede,noslowerdna,sam.nguyen@sendgrid.com,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1188,,,,,,,,,,,,,,,,KAFKA-3919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,368321,,,Thu Apr 06 21:53:00 UTC 2017,,,,,,,,,,"0|i1rhfz:",368626,,,,,,,,,,,,,,,,,,,,"25/Jul/14 00:23;junrao;Yes, this is a potential problem. Waiting for HW to be propagated to the followers will introduce another round of network delay on every message to be committed though. The following is another potential solution that avoid this overhead.

Note that the follower in ISR always has all committed messages. On follower startup, if we can figure out accurately which messages are committed and which ones are not, we won't unnecessarily truncate committed messages. Not that when a follower takes over as the new leader, it always tries to commit all existing messages that are obtained from the previous generation of the leader. After that, it will start committing new messages received in its own generation. If we can track the leader generation of each message, we can do the truncation accurately. To do that, in each replica, we maintain a leader generation vector that contains the leader generation id and its starting offset (the offset of the first message written by the leader in that generation) and we persist that vector in a LeaderGeneration file locally.

If a replica becomes a leader, before it accepts any new message, it first appends the current leader generation id and its current log end offset to the LeaderGeneration file. If a replica becomes a follower, it first gets the leader generation vector from the leader and then determines the offset where its highest leader generation ends in the leader. It will then truncate its log up to that offset (if there are messages beyond that offset). After that, the follower will store the leader generation vector obtained from the leader in its local LeaderGeneration file and starts fetching messages from the leader from its log end offset.

Let's consider a couple of examples. 

Example 1. Suppose that we have two replicas A and B and A is the leader. At some point, we have the following messages in A and B.

{noformat}
offset   A    B
1       m1  m1
2       m2
{noformat}
 
Let's assume that message m1 is committed, but m2 is not. At this point, A dies and B takes over as the leader. Let's say B then commits 2 more messages m3 and m4.

{noformat}
offset    A    B
0        m1  m1
1        m2  m3
2            m4
{noformat}

When replica A comes back, it's important for A to get rid of m2 from offset 1 since m2 is never committed. In this case, the leader generation vector in A and B will look like the following.

{noformat}
                 A                                        B
leaderGenId   startOffset                leaderGenId   startOffset
1                     0                    1           0
                                           2           1
{noformat}

By comparing A's leader generation vector with that from the current leader B, A knows that its latest messages are produced by the leader in generation 1, which ends at offset 0. So any message in its local log after offset 0 are not committed and can be truncated. Any message at or before offset 0 is guaranteed to be committed. So, replica A will remove m2 from offset 1 and get m3 and m4 from B afterward. At that point, A's log is consistent with that of B. All committed messages are preserved and all uncommitted messages are removed.

Example 2. Suppose that we have two replicas A and B and A is the leader. At some point, we have the following messages in A and B.

{noformat}
offset    A    B
1          m1  m1
2          m2  m2
{noformat}
 
Let's assume that both message m1 and m2 are committed. At this point, A dies and B takes over as the leader. Let's say B then commits 2 more messages m3 and m4.

{noformat}
offset    A    B
0          m1  m1
1          m2  m2
2              m3
3              m4
{noformat}

In this case, the leader generation vector in A and B will look like the following.

{noformat}
                 A                                       B
leaderGenId   startOffset                leaderGenId   startOffset
1                     0                    1                0
                                           2                2
{noformat}

When A comes back, by comparing its leader generation vector with that from the current leader B, A knows that its latest messages are produced by the leader in generation 1, which ends at offset 1. So, it will keep m2 at offset 1 and get m3 and m4 from B. Again, this will make A's log consistent with B.

This approach doesn't pay the extra network roundtrip to commit a message. The becoming follower process will be a bit slower since It now needs to issue a new request to get the leader vector before it can start fetching from the leader. However, since leader changes are rare, this probably provides a better tradeoff. There are also other details that need to be worked out.

1. We need to deal with the case that the leader generation vector may have a gap, i.e., no messages are produced in a leader generation.
2. We probably need to remove old leader generations from the LeaderGeneration file so that it won't grow forever. Perhaps we need to configure a max # of generations to keep.

Since this problem is relatively rare and the fix is a bit involved, we can probably put it off until 0.9 or beyond.


;;;","25/Jul/14 01:43;guozhang;Jun, I think in your review of KAFKA-1430's patch, you are already suggesting to wait for leader HW to be larger than the produce offset instead of just log end offset for ack=-1.

So as for ack > 1, but not = to num.replicas, since data loss may happen anyways because of the leader election logic may choose a follower which does not have all the committed data, this issue would just potentially increase the data loss by a bit under such scenarios. For its complexity and the benefit maybe it is not an optimization worth doing?;;;","25/Jul/14 02:06;junrao;The issue is that this problem not only affects ack>1, but only affects ack=-1. Suppose that you have 3 replicas A, B, and C and A is the leader initially. If A fails and B takes over as the new leader, C will first truncate its log, which could include committed data. Now, if immediately after the truncation, B fails, C has to be the new leader. Now, we may have lost previously committed messages, even though we had only 2 failures.;;;","25/Jul/14 02:24;guozhang;What I meant is that the ack=-1 should be already handled in KAFKA-1430, as we are not wait for leader HW. Right?;;;","25/Jul/14 12:47;junrao;Not quite. The case that I described above could happen with ack = -1 too.;;;","25/May/16 04:58;gwenshap;[~junrao] is this still an issue?;;;","07/Jun/16 10:58;ijuma;[~guozhang], is this still an issue?;;;","08/Jun/16 00:25;junrao;This is still an issue. It can cause data loss if the leader of a partition changes too quickly. This is less likely to happen with the fix in KAFKA-3670, but could still happen in theory. Fixing this is a bit involved since it would require the leader and the follower to keep track of and communicate additional information about leader generations, and may potentially require a change in message format.;;;","08/Jun/16 00:32;ijuma;Thanks Jun, I changed the fix version since I don't think we are working on this for 0.10.1.0.;;;","02/Aug/16 02:51;junrao;The following is a draft proposal. [~fpj], does that look reasonable to you?

1. In every log directory, we create a new leader-generation-checkpoint file, where we store the sequence (LGS) of leader generation and the start offset of messages produced in that generation.
2. When a replica becomes a leader, it first adds the leader generation and the log end offset of the replica to the end of leader-generation-checkpoint file and flushes the file. It then remembers its last leader generation (LLG) and becomes the leader.
3. When a replica becomes a follower, it does the following steps.
  3.1 Send a new RetreiveLeaderGeneration request for the partition to the leader.
  3.2 The leader responds with its LGS in the RetreiveLeaderGeneration response
  3.3 The follower finds the first leader generation whose start offset differs between its local LGS and the leader's LGS. It then truncates its local log to the smaller of the start offset of the identified leader generation, if needed.
  3.4 The follower flushes the LGS from the leader to its local leader-generation-checkpoint file and also remembers the expected LLG from the leader's LGS.
  3.5 The follower starts fetching from the leader from its log end offset.
  3.5.1 During fetching, we extend the FetchResponse to add a new field per partition for the LLG in the leader.
  3.5.2 If the follower sees the returned LLG in the FetchResponse not matching its expected LLG, go back to 3.1. (This can only happen if the leader changes more than once between 2 consecutive fetch requests and should be rare. We could also just stop the follower and wait for the next becoming follower request from the controller.)
  3.5.3 Otherwise, the follower proceeds to append the fetched data to its local log in the normal way.

Implementation wise. We probably need to extend ReplicaFetchThread to maintain an additional state per partition. When a partition is added to a ReplicaFetchThread, it needs to go through steps 3.1 to 3.4 first before starting fetching the data.;;;","03/Aug/16 00:00;fpj;[~junrao] let me ask a few clarification questions.

# Is it right that the scenarios described here do not affect the cases in which min isr > 1 and unclean leader election is disabled? If min isr is greater than 1 and the leader is always coming from the latest isr, then the leader can either truncate the followers or have them fetch the missing log suffix.
# The main goal of the proposal is to have replicas in a lossy configuration (e.g. min isr = 1, unclean leader election enabled) a leader and a follower converging to a common prefix by choosing an offset based on a common generation. The chosen generation is the largest generation in common between the two replicas. Is it right?
# How do we guarantee that the generation id is unique, by using zookeeper versions?
# I think there is a potential race between updating the leader-generation-checkpoint file and appending the first message of the generation. We might be better off rolling the log segment file and having the generation being part of the log segment file name. This way when we start a new generation, we also start a new file and we know precisely when a message from that generation has been appended.
# Let's consider a scenario with 3 servers A B C. I'm again assuming that it is ok to have a single server up to ack requests. Say we have the following execution:

||Generation||A||B||C||
|1| |m1|m1|
| | |m2|m2|
|2|m3| | |
| |m4| | |

Say that now A and B start generation 3. They have no generation in common, so they start from zero, dropping m1 and m2. Is that right? If later on C joins A and B, then it will also drop m1 and m2, right? Given that the configuration is lossy, it doesn't wrong to do it as all we are trying to do is to converge to a consistent state. ;;;","03/Aug/16 01:10;junrao;[~fpj], for #1 and #2, there are a couple scenarios that this proposal can fix.
a. The first one is what's described in the original jira. Currently, when the follower does truncation, it can truncate some previously committed messages. If the follower immediately becomes the leader after truncation, we will lose some previously committed messages. This is rare, but if it happens, it's bad. The proposal fixes this case by preventing the follower from unnecessarily truncating previously committed messages.
b. Another issue is that a portion of the log in different replicas may not match in certain failure cases. This can happen when unclean leader election is enabled. However, even if unclean leader election is disabled, mis-matching can still happen when messages are lost due to power outage (see KAFKA-3919). The proposal fixes this issue by making sure that the replicas are always identical.

For #3, the controller increases the leader generation every time the leader changes. The latest leader generation is persisted in ZK.

For #4, putting the leader generation in the segment file name is another possibility. One concern I had on that approach is dealing with compacted topics. After compaction, it's possible there is only a small number (or even just a single) messages left in a particular generation. Putting the generation id in the segment file name will force us to have tiny segments, which is not ideal. About the race condition, even with a separate checkpoint file, we can avoid that. The sequencing will be (1) broker receives LeaderAndIsrRequest to become leader; (2) broker stops fetching from current leader; (3) no new writes can happen to this replica at this point; (4) broker writes the new leader generation and log end offset to checkpoint file; (5) broker marks replica as leader; (6) new writes can happen to this replica now.

For #5, it depends on who becomes the new leader in that case. If A becomes the new leader (generation 3), then B and C will remove m1 and m2 and copy m3 and m4 over from A. If B becomes the new leader, A will remove m3 and m4 and copy m1 and m2 over from B. In either case, the replicas will be identical.;;;","03/Aug/16 23:30;fpj;Thanks for the clarification, [~junrao]. There are a couple of specific points that still aren't entirely clear to me:

# We are trying to preserve the generation when we copy messages to a follower, correct? In step 3.4, when we say that the follower flushes the LGS, we are more specifically trying to replicate the leader LGS, is that right? What happens if either the follower crashes or the leader changes between persisting the new LGS and fetching the new messages from the leader? I'm concerned that we will leave the LGS and the log of the broker in an inconsistent state.
# When we say in step 3.4 that the follower needs to remember the LLG, I suppose this is just during this recovery period. Otherwise, once we have completed the sync up, the follower knows that the latest generation is the LLG. During sync up, there is the question I'm raising above, but it is also not super clear whether we need to persist the LLG independently to make sure that we don't have a situation in which the follower crashes, comes back, and accepts messages from a different generation.;;;","04/Aug/16 08:51;junrao;[~fpj], very good questions.

1. Yes, the idea is for the follower to copy LGS from the leader. About the possibility of leading to an inconsistent state. We just need to make sure the log is consistent with respect to the local leader-generation-checkpoint file up to the log end offset. One potential issue with the current proposal is when the follower truncates the file and then flushes the checkpoint file. If the follower crashes at this point and the truncation hasn't been flushed, we may treat some of the messages after the truncation point  to be in a wrong leader generation. To fix that, we can change the protocol a bit. The basic idea is that the follower will never flush the checkpoint ahead of the log. Specially, when the follower gets the LGS from the leader, it stores it in memory. After truncation, the follower only flushes the prefix of LGS whose start offset is up to the log end offset. As the follower starts fetching data, everytime the fetched messages cross the leader generation boundary (according to the cached LGS), the follower will add a new lead generation entry to the checkpoint file and flushes it.

2. LLG doesn't have to be persisted and only needs to be cached in memory. The idea of LLG is really to detect any leader generation changes since the follower issued the RetreiveLeaderGeneration request. Once this is detected, the follower can handle it properly. If the follower crashes and restarts, it can always re-get the LLG from the current leader.;;;","07/Aug/16 02:05;fpj;[~junrao] I get (2), but (1) might need a bit more tweaking because of the following. Say the follower executes the steps in the order you describe:

# Truncate log
# Update LGS to reflect the truncated log (flush the prefix of LGS whose start offset is up to the log end offset)
# Fetch and update the LGS as messages cross leader boundaries

If the follower crashes in the middle of fetching and updating the LGS, it may leave the LGS in an inconsistent state. For example, let's say that it crossed the boundary of a generation, it writes to the log, and crashes before updating the LGS. I'm actually thinking that it might be better to have the update in the LGS first because in the worst case we point to an offset that is not in the log, so we know that the LGS entry is invalid. In any case, it sounds like there is some work to be done to make sure the LGS and the log are consistent.

;;;","07/Aug/16 02:47;fpj;[~junrao] I was reading point (a) in your answer again, and there is something I don't understand. You say that the follower truncates and then become leader. This is fine, I understand it can happen. The bit I don't understand is how it can truncate committed messages. 

Let's say that we are talking about servers A and B, min ISR is 2 (the replica set can be larger than 2, but it doesn't really matter for this example):

# A leads initially and B follows A.
# B truncates
# B becomes leader

If A leads, the it means that it was previously in the ISR (assuming unclean leader election disabled) and it contains all committed messages. If B was also part of the previous ISR, then both A and B it will also have all committed and B won't truncate committed messages.

The situation you describe can only happen if either A or B lose committed messages on their own and not because of the truncation, e.g., if the messages didn't make it from the page cache to disk before a crash.

Is my understanding correct?;;;","09/Aug/16 01:23;junrao;[~fpj], yes, the idea is to always first write the new LGS before writing any messages in the new leader generation to the follower's log. So, if the follower fetches a chunk of messages that cross leader generation. We will have to split the messages into subsets of the same leader generation. We append subsets belonging to the current leader generation, update LGS to reflect to new leader generation, then append subsets belonging to the new leader generation.;;;","09/Aug/16 01:35;junrao;[~fpj], for (a), this is because the leader needs to first wait for the follower to receive a message before it can advance the last committed offset. After that, it can propagate the last committed offset to the follower. So, the last committed offset in the follower is always behind that in the leader. Since the follower truncates based on the local last committed offset, it's possible for the follower to truncate messages that are already committed by the leader.;;;","14/Aug/16 00:09;fpj;[~junrao]

bq. the leader needs to first wait for the follower to receive a message before it can advance the last committed offset.

makes sense

bq. it can propagate the last committed offset to the follower

makes sense

bq. the last committed offset in the follower is always behind that in the leader

makes sense, it is either equal or behind, never ahead.

bq. Since the follower truncates based on the local last committed offset, it's possible for the follower to truncate messages that are already committed by the leader.

I'm not sure why we are doing this. A follower can't truncate until it hears from the leader upon recovery, it shouldn't truncate based on its local last committed offset.;;;","06/Apr/17 06:41;junrao;The PR for this issue is https://github.com/apache/kafka/pull/2808;;;","07/Apr/17 05:53;junrao;The PR has been merged. Thanks, [~benstopford]!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ProducerFailureHandlingTest.testCannotSendToInternalTopic fails with TimeoutException while trying to fetch metadata for topic,KAFKA-1878,12768401,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jaikiran,jaikiran,jaikiran,19/Jan/15 17:57,20/Jan/15 01:06,22/Mar/23 15:10,20/Jan/15 01:06,,,,,,,0.9.0.0,,,,,,,system tests,,,,0,,,,,,"The testCannotSendToInternalTopic test method in ProducerFailureHandlingTest fails consistently with the following exception:

{code}
Unexpected exception while seding to an invalid topic org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 3000 ms.
java.lang.AssertionError: Unexpected exception while seding to an invalid topic org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 3000 ms.
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at kafka.api.test.ProducerFailureHandlingTest.testCannotSendToInternalTopic(ProducerFailureHandlingTest.scala:317)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at org.scalatest.junit.JUnit3Suite.run(JUnit3Suite.scala:321)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runSingleTest(ScalaTestRunner.java:245)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest1(ScalaTestRunner.java:213)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:30)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
{code}
This failure appears like it's intermittent when the ProducerFailureHandlingTest is run as whole because it hides the timing issue involved in the testCannotSendToInternalTopic test method. Running only that testCannotSendToInternalTopic test method (I did it from IntelliJ IDE) consistently reproduces this failure.

The real issue is that the initialization of the  __consumer_offset topic (being accessed in the testCannotSendToInternalTopic test method) is time consuming because that topic is backed by 50 partitions (default) and it takes a while for each of them to be assigned a leader and do other initialization. This times out the metadata fetch (3 seconds) being done by the producer during a send(), which causes the test method to fail.

I've a patch to fix that test method which I'll send shortly.",,jaikiran,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jan/15 18:09;jaikiran;KAFKA-1878.patch;https://issues.apache.org/jira/secure/attachment/12693056/KAFKA-1878.patch","20/Jan/15 00:33;jaikiran;KAFKA-1878_2015-01-19_22:02:54.patch;https://issues.apache.org/jira/secure/attachment/12693111/KAFKA-1878_2015-01-19_22%3A02%3A54.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jan 19 17:06:26 UTC 2015,,,,,,,,,,"0|i24imf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Jan/15 18:09;jaikiran;Created reviewboard https://reviews.apache.org/r/30026/diff/
 against branch origin/trunk;;;","20/Jan/15 00:33;jaikiran;Updated reviewboard https://reviews.apache.org/r/30026/diff/
 against branch origin/trunk;;;","20/Jan/15 01:06;junrao;Thanks for the patch. +1. Committed to trunk with a minor change to the comment.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LineMessageReader doesn't correctly parse the key separator,KAFKA-807,12637055,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Trivial,Fixed,dragosm,dragosm,dragosm,15/Mar/13 01:16,29/Mar/13 23:35,22/Mar/23 15:10,29/Mar/13 23:35,0.8.0,,,,,,0.8.0,,,,,,,tools,,,,0,patch,producer,,,,"Typo in key name prevents extracting the key separator. The patch follows; what's the recommended way to submit patches?

Index: core/src/main/scala/kafka/producer/ConsoleProducer.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>/**\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \""License\""); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n * \n *    http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \""AS IS\"" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage kafka.producer\n\nimport scala.collection.JavaConversions._\nimport joptsimple._\nimport java.util.Properties\nimport java.io._\nimport kafka.common._\nimport kafka.message._\nimport kafka.serializer._\n\nobject ConsoleProducer { \n\n  def main(args: Array[String]) { \n    val parser = new OptionParser\n    val topicOpt = parser.accepts(\""topic\"", \""REQUIRED: The topic id to produce messages to.\"")\n                           .withRequiredArg\n                           .describedAs(\""topic\"")\n                           .ofType(classOf[String])\n    val brokerListOpt = parser.accepts(\""broker-list\"", \""REQUIRED: The broker list string in the form HOST1:PORT1,HOST2:PORT2.\"")\n                           .withRequiredArg\n                           .describedAs(\""broker-list\"")\n                           .ofType(classOf[String])\n    val syncOpt = parser.accepts(\""sync\"", \""If set message send requests to the brokers are synchronously, one at a time as they arrive.\"")\n    val compressOpt = parser.accepts(\""compress\"", \""If set, messages batches are sent compressed\"")\n    val batchSizeOpt = parser.accepts(\""batch-size\"", \""Number of messages to send in a single batch if they are not being sent synchronously.\"")\n                             .withRequiredArg\n                             .describedAs(\""size\"")\n                             .ofType(classOf[java.lang.Integer])\n                             .defaultsTo(200)\n    val sendTimeoutOpt = parser.accepts(\""timeout\"", \""If set and the producer is running in asynchronous mode, this gives the maximum amount of time\"" + \n                                                   \"" a message will queue awaiting suffient batch size. The value is given in ms.\"")\n                               .withRequiredArg\n                               .describedAs(\""timeout_ms\"")\n                               .ofType(classOf[java.lang.Long])\n                               .defaultsTo(1000)\n    val queueSizeOpt = parser.accepts(\""queue-size\"", \""If set and the producer is running in asynchronous mode, this gives the maximum amount of \"" + \n                                                   \"" messages will queue awaiting suffient batch size.\"")\n                               .withRequiredArg\n                               .describedAs(\""queue_size\"")\n                               .ofType(classOf[java.lang.Long])\n                               .defaultsTo(10000)\n    val queueEnqueueTimeoutMsOpt = parser.accepts(\""queue-enqueuetimeout-ms\"", \""Timeout for event enqueue\"")\n                               .withRequiredArg\n                               .describedAs(\""queue enqueuetimeout ms\"")\n                               .ofType(classOf[java.lang.Long])\n                               .defaultsTo(0)\n    val requestRequiredAcksOpt = parser.accepts(\""request-required-acks\"", \""The required acks of the producer requests\"")\n                               .withRequiredArg\n                               .describedAs(\""request required acks\"")\n                               .ofType(classOf[java.lang.Integer])\n                               .defaultsTo(0)\n    val requestTimeoutMsOpt = parser.accepts(\""request-timeout-ms\"", \""The ack timeout of the producer requests. Value must be non-negative and non-zero\"")\n                               .withRequiredArg\n                               .describedAs(\""request timeout ms\"")\n                               .ofType(classOf[java.lang.Integer])\n                               .defaultsTo(1500)\n    val valueEncoderOpt = parser.accepts(\""value-serializer\"", \""The class name of the message encoder implementation to use for serializing values.\"")\n                                 .withRequiredArg\n                                 .describedAs(\""encoder_class\"")\n                                 .ofType(classOf[java.lang.String])\n                                 .defaultsTo(classOf[StringEncoder].getName)\n    val keyEncoderOpt = parser.accepts(\""key-serializer\"", \""The class name of the message encoder implementation to use for serializing keys.\"")\n                                 .withRequiredArg\n                                 .describedAs(\""encoder_class\"")\n                                 .ofType(classOf[java.lang.String])\n                                 .defaultsTo(classOf[StringEncoder].getName)\n    val messageReaderOpt = parser.accepts(\""line-reader\"", \""The class name of the class to use for reading lines from standard in. \"" + \n                                                          \""By default each line is read as a separate message.\"")\n                                  .withRequiredArg\n                                  .describedAs(\""reader_class\"")\n                                  .ofType(classOf[java.lang.String])\n                                  .defaultsTo(classOf[LineMessageReader].getName)\n    val socketBufferSizeOpt = parser.accepts(\""socket-buffer-size\"", \""The size of the tcp RECV size.\"")\n                                  .withRequiredArg\n                                  .describedAs(\""size\"")\n                                  .ofType(classOf[java.lang.Integer])\n                                  .defaultsTo(1024*100)\n    val propertyOpt = parser.accepts(\""property\"", \""A mechanism to pass user-defined properties in the form key=value to the message reader. \"" +\n                                                 \""This allows custom configuration for a user-defined message reader.\"")\n                            .withRequiredArg\n                            .describedAs(\""prop\"")\n                            .ofType(classOf[String])\n\n\n    val options = parser.parse(args : _*)\n    for(arg <- List(topicOpt, brokerListOpt)) {\n      if(!options.has(arg)) {\n        System.err.println(\""Missing required argument \\\""\"" + arg + \""\\\""\"")\n        parser.printHelpOn(System.err)\n        System.exit(1)\n      }\n    }\n\n    val topic = options.valueOf(topicOpt)\n    val brokerList = options.valueOf(brokerListOpt)\n    val sync = options.has(syncOpt)\n    val compress = options.has(compressOpt)\n    val batchSize = options.valueOf(batchSizeOpt)\n    val sendTimeout = options.valueOf(sendTimeoutOpt)\n    val queueSize = options.valueOf(queueSizeOpt)\n    val queueEnqueueTimeoutMs = options.valueOf(queueEnqueueTimeoutMsOpt)\n    val requestRequiredAcks = options.valueOf(requestRequiredAcksOpt)\n    val requestTimeoutMs = options.valueOf(requestTimeoutMsOpt)\n    val keyEncoderClass = options.valueOf(keyEncoderOpt)\n    val valueEncoderClass = options.valueOf(valueEncoderOpt)\n    val readerClass = options.valueOf(messageReaderOpt)\n    val socketBuffer = options.valueOf(socketBufferSizeOpt)\n    val cmdLineProps = parseLineReaderArgs(options.valuesOf(propertyOpt))\n    cmdLineProps.put(\""topic\"", topic)\n\n    val props = new Properties()\n    props.put(\""broker.list\"", brokerList)\n    val codec = if(compress) DefaultCompressionCodec.codec else NoCompressionCodec.codec\n    props.put(\""compression.codec\"", codec.toString)\n    props.put(\""producer.type\"", if(sync) \""sync\"" else \""async\"")\n    if(options.has(batchSizeOpt))\n      props.put(\""batch.num.messages\"", batchSize.toString)\n    props.put(\""queue.buffering.max.ms\"", sendTimeout.toString)\n    props.put(\""queue.buffering.max.messages\"", queueSize.toString)\n    props.put(\""queue.enqueue.timeout.ms\"", queueEnqueueTimeoutMs.toString)\n    props.put(\""request.required.acks\"", requestRequiredAcks.toString)\n    props.put(\""request.timeout.ms\"", requestTimeoutMs.toString)\n    props.put(\""key.serializer.class\"", keyEncoderClass)\n    props.put(\""serializer.class\"", valueEncoderClass)\n    props.put(\""send.buffer.bytes\"", socketBuffer.toString)\n    val reader = Class.forName(readerClass).newInstance().asInstanceOf[MessageReader[AnyRef, AnyRef]]\n    reader.init(System.in, cmdLineProps)\n\n    try {\n        val producer = new Producer[AnyRef, AnyRef](new ProducerConfig(props))\n\n        Runtime.getRuntime.addShutdownHook(new Thread() {\n          override def run() {\n            producer.close()\n          }\n        })\n\n        var message: KeyedMessage[AnyRef, AnyRef] = null\n        do {\n          message = reader.readMessage()\n          if(message != null)\n            producer.send(message)\n        } while(message != null)\n    } catch {\n      case e: Exception =>\n        e.printStackTrace\n        System.exit(1)\n    }\n    System.exit(0)\n  }\n\n  def parseLineReaderArgs(args: Iterable[String]): Properties = {\n    val splits = args.map(_ split \""=\"").filterNot(_ == null).filterNot(_.length == 0)\n    if(!splits.forall(_.length == 2)) {\n      System.err.println(\""Invalid line reader properties: \"" + args.mkString(\"" \""))\n      System.exit(1)\n    }\n    val props = new Properties\n    for(a <- splits)\n      props.put(a(0), a(1))\n    props\n  }\n\n  trait MessageReader[K,V] { \n    def init(inputStream: InputStream, props: Properties) {}\n    def readMessage(): KeyedMessage[K,V]\n    def close() {}\n  }\n\n  class LineMessageReader extends MessageReader[String, String] {\n    var topic: String = null\n    var reader: BufferedReader = null\n    var parseKey = false\n    var keySeparator = \""\\t\""\n    var ignoreError = false\n    var lineNumber = 0\n\n    override def init(inputStream: InputStream, props: Properties) {\n      topic = props.getProperty(\""topic\"")\n      if(props.containsKey(\""parse.key\""))\n        parseKey = props.getProperty(\""parse.key\"").trim.toLowerCase.equals(\""true\"")\n      if(props.containsKey(\""key.seperator\""))\n        keySeparator = props.getProperty(\""key.separator\"")\n      if(props.containsKey(\""ignore.error\""))\n        ignoreError = props.getProperty(\""ignore.error\"").trim.toLowerCase.equals(\""true\"")\n      reader = new BufferedReader(new InputStreamReader(inputStream))\n    }\n\n    override def readMessage() = {\n      lineNumber += 1\n      (reader.readLine(), parseKey) match {\n        case (null, _) => null\n        case (line, true) =>\n          line.indexOf(keySeparator) match {\n            case -1 =>\n              if(ignoreError)\n                new KeyedMessage(topic, line)\n              else\n                throw new KafkaException(\""No key found on line \"" + lineNumber + \"": \"" + line)\n            case n =>\n              new KeyedMessage(topic,\n                             line.substring(0, n), \n                             if(n + keySeparator.size > line.size) \""\"" else line.substring(n + keySeparator.size))\n          }\n        case (line, false) =>\n          new KeyedMessage(topic, line)\n      }\n    }\n  }\n}\n
===================================================================
--- core/src/main/scala/kafka/producer/ConsoleProducer.scala	(revision 290d5e0eac38e9917c64353a131154821b899f26)
+++ core/src/main/scala/kafka/producer/ConsoleProducer.scala	(revision )
@@ -196,7 +196,7 @@
       topic = props.getProperty(""topic"")
       if(props.containsKey(""parse.key""))
         parseKey = props.getProperty(""parse.key"").trim.toLowerCase.equals(""true"")
-      if(props.containsKey(""key.seperator""))
+      if(props.containsKey(""key.separator""))
         keySeparator = props.getProperty(""key.separator"")
       if(props.containsKey(""ignore.error""))
         ignoreError = props.getProperty(""ignore.error"").trim.toLowerCase.equals(""true"")
",,dragosm,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,317547,,,Fri Mar 29 15:35:17 UTC 2013,,,,,,,,,,"0|i1isk7:",317888,,,,,,,,,,,,,,,,,,,,"27/Mar/13 00:51;dragosm;Index: core/build.sbt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- core/build.sbt	(date 1364252653000)
+++ core/build.sbt	(date 1364254450000)
@@ -18,8 +18,9 @@
 
 libraryDependencies <<= (scalaVersion, libraryDependencies) { (sv, deps) =>
   deps :+ (sv match {
-    case ""2.8.0"" => ""org.scalatest"" %  ""scalatest"" % ""1.2"" % ""test""
+    case ""2.8.0"" => ""org.scalatest"" %  ""scalatest"" % ""1.2""   % ""test""
+    case ""2.9.2"" => ""org.scalatest"" %% ""scalatest"" % ""1.9.1"" % ""test""
-    case _       => ""org.scalatest"" %% ""scalatest"" % ""1.8"" % ""test""
+    case _       => ""org.scalatest"" %% ""scalatest"" % ""1.8""   % ""test""
   })
 }
 
Index: core/src/main/scala/kafka/producer/ConsoleProducer.scala
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- core/src/main/scala/kafka/producer/ConsoleProducer.scala	(date 1364252653000)
+++ core/src/main/scala/kafka/producer/ConsoleProducer.scala	(date 1364254450000)
@@ -196,7 +196,7 @@
       topic = props.getProperty(""topic"")
       if(props.containsKey(""parse.key""))
         parseKey = props.getProperty(""parse.key"").trim.toLowerCase.equals(""true"")
-      if(props.containsKey(""key.seperator""))
+      if(props.containsKey(""key.separator""))
         keySeparator = props.getProperty(""key.separator"")
       if(props.containsKey(""ignore.error""))
         ignoreError = props.getProperty(""ignore.error"").trim.toLowerCase.equals(""true"")
;;;","29/Mar/13 23:35;junrao;Thanks for the patch. Committed the change to ConsoleProducer to 0.8.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fetch on a replicated topic does not return as soon as possible,KAFKA-1150,12681365,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,nehanarkhede,abalmin,abalmin,27/Nov/13 04:01,25/Jul/14 00:25,22/Mar/23 15:10,25/Jul/14 00:25,0.8.0,,,,,,,,,,,,,core,replication,,,1,,,,,,"I see a huge performance difference between replicated and not replicated topics. On my laptop, running two brokers, I see producer-2-consumer latency of under 1ms for topics with one replica. 
However,  with two replicas the same latency equals to the max fetch delay. Here is a simple test I just did:
one producer thread in a loop sending one message and sleeping for 2500ms, and one consumer thread looping on the long poll with max fetch delay of 1000 ms.

Here is what happens with no replication:

Produced 1	 key: key1 at time: 15:33:52.822
Consumed up to 1 at time: 15:33:52.822
Consumed up to 1 at time: 15:33:53.823
Consumed up to 1 at time: 15:33:54.825
Produced 2	 key: key2 at time: 15:33:55.324
Consumed up to 2 at time: 15:33:55.324
Consumed up to 2 at time: 15:33:56.326
Consumed up to 2 at time: 15:33:57.328
Produced 3	 key: key3 at time: 15:33:57.827
Consumed up to 3 at time: 15:33:57.827

The are no delays between the message being produced and consumed -- this is the behavior I expected. 

Here is the same test, but for a topic with two replicas:

Consumed up to 0 at time: 15:50:29.575
Produced 1	 key: key1 at time: 15:50:29.575
Consumed up to 1 at time: 15:50:30.577
Consumed up to 1 at time: 15:50:31.579
Consumed up to 1 at time: 15:50:32.078
Produced 2	 key: key2 at time: 15:50:32.078
Consumed up to 2 at time: 15:50:33.081
Consumed up to 2 at time: 15:50:34.081
Consumed up to 2 at time: 15:50:34.581
Produced 3	 key: key3 at time: 15:50:34.581
Consumed up to 3 at time: 15:50:35.584

Notice how the fetch always returns as soon as the produce request is issued, but without the new message, which consistently arrives ~1002 ms later.

Below is the request log snippet for this part:

Produced 2	 key: key2 at time: 15:50:32.078
Consumed up to 2 at time: 15:50:33.081

You can see the first FetchRequest returns at the same time as the replica FetchRequest, but this fetch response is *empty* -- the message is not committed yet, so it cannot be returned. The message is committed at 15:50:32,079. However, the next FetchRequest (that does return the message) comes in at 15:50:32,078, but completes only at 15:50:33,081. Why is it waiting for the full 1000 ms, instead of returning right away?

[2013-11-25 15:50:32,077] TRACE Processor 1 received request : Name: ProducerRequest; Version: 0; CorrelationId: 5; ClientId: pro; RequiredAcks: 1; AckTimeoutMs: 20 ms; TopicAndPartition: [test_topic,0] -> 2078 (kafka.network.RequestChannel$)
[2013-11-25 15:50:32,078] TRACE Completed request:Name: FetchRequest; Version: 0; CorrelationId: 7; ClientId: con; ReplicaId: -1; MaxWait: 1000 ms; MinBytes: 1 bytes; RequestInfo: [test_topic,0] -> PartitionFetchInfo(129,1024000) from client /0:0:0:0:0:0:0:1%0:63264;totalTime:499,queueTime:0,localTime:0,remoteTime:499,sendTime:0 (kafka.request.logger)
[2013-11-25 15:50:32,078] TRACE Completed request:Name: FetchRequest; Version: 0; CorrelationId: 3463; ClientId: ReplicaFetcherThread-0-0; ReplicaId: 1; MaxWait: 500 ms; MinBytes: 1 bytes; RequestInfo: [test_topic,0] -> PartitionFetchInfo(129,1048576) from client /127.0.0.1:63056;totalTime:499,queueTime:1,localTime:0,remoteTime:498,sendTime:0 (kafka.request.logger)
[2013-11-25 15:50:32,078] TRACE Processor 1 received request : Name: FetchRequest; Version: 0; CorrelationId: 8; ClientId: con; ReplicaId: -1; MaxWait: 1000 ms; MinBytes: 1 bytes; RequestInfo: [test_topic,0] -> PartitionFetchInfo(129,1024000) (kafka.network.RequestChannel$)
[2013-11-25 15:50:32,078] TRACE Completed request:Name: ProducerRequest; Version: 0; CorrelationId: 5; ClientId: pro; RequiredAcks: 1; AckTimeoutMs: 20 ms; TopicAndPartition: [test_topic,0] -> 2078 from client /0:0:0:0:0:0:0:1%0:63266;totalTime:1,queueTime:0,localTime:1,remoteTime:0,sendTime:0 (kafka.request.logger)
[2013-11-25 15:50:32,079] TRACE Processor 0 received request : Name: FetchRequest; Version: 0; CorrelationId: 3464; ClientId: ReplicaFetcherThread-0-0; ReplicaId: 1; MaxWait: 500 ms; MinBytes: 1 bytes; RequestInfo: [test_topic,0] -> PartitionFetchInfo(130,1048576) (kafka.network.RequestChannel$)
[2013-11-25 15:50:32,581] TRACE Completed request:Name: FetchRequest; Version: 0; CorrelationId: 3464; ClientId: ReplicaFetcherThread-0-0; ReplicaId: 1; MaxWait: 500 ms; MinBytes: 1 bytes; RequestInfo: [test_topic,0] -> PartitionFetchInfo(130,1048576) from client /127.0.0.1:63056;totalTime:503,queueTime:1,localTime:0,remoteTime:502,sendTime:0 (kafka.request.logger)
[2013-11-25 15:50:32,582] TRACE Processor 0 received request : Name: FetchRequest; Version: 0; CorrelationId: 3465; ClientId: ReplicaFetcherThread-0-0; ReplicaId: 1; MaxWait: 500 ms; MinBytes: 1 bytes; RequestInfo: [test_topic,0] -> PartitionFetchInfo(130,1048576) (kafka.network.RequestChannel$)
[2013-11-25 15:50:33,081] TRACE Completed request:Name: FetchRequest; Version: 0; CorrelationId: 8; ClientId: con; ReplicaId: -1; MaxWait: 1000 ms; MinBytes: 1 bytes; RequestInfo: [test_topic,0] -> PartitionFetchInfo(129,1024000) from client /0:0:0:0:0:0:0:1%0:63264;totalTime:1003,queueTime:0,localTime:1,remoteTime:1001,sendTime:1 (kafka.request.logger)


----------
Environment note: I first noticed this behavior on three brokers running on three Ubuntu EC2 instances. I then boiled it down to this simple test running two brokers on a Mac laptop.",,abalmin,guozhang,jjkoshy,jkreps,junrao,thecoop1984,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1430,,,,KAFKA-1430,,,,,,,,,,,,,,,,"07/May/14 23:35;thecoop1984;Test.java;https://issues.apache.org/jira/secure/attachment/12643769/Test.java",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,360630,,,Thu Jul 24 15:02:45 UTC 2014,,,,,,,,,,"0|i1q60n:",360929,,,,,,,,,,,,,,,,,,,,"27/Nov/13 10:24;jjkoshy;Thank you for reporting this. We currently unblock delayed fetch requests when a producer request arrives and its byte count meets the min.bytes requirement of those fetch requests. For regular (non-replica fetcher) consumers we can only expose up to the high watermark - which means that consumer fetch request would (typically) send back an empty response and the consumer would then refetch as you found.

We should ideally unblock these regular consumer fetch requests only when we advance the high watermark. However, the problem there is that the HW is measured in logical offsets, not bytes. We could change the min.bytes concept to min.messages but I think it is worth thinking about a better solution for this.
;;;","27/Nov/13 11:09;abalmin;Notice that there are two problems here. First problem is that the second fetch is needed. But an even bigger problem (from my point of view) is that the second fetch does not return right away -- it waits a full second even though the high water mark has long been moved.;;;","27/Nov/13 13:28;junrao;Right, the first problem (second fetch is needed) is due to that logic for handling whether a fetch request is satisfied is incorrect. As Joel pointed out, currently, we check to see if a fetch request is satisfied after messages are added to the leader's log. At that point, the new messages are not committed yet. The way we do the check is to pass in the bytes of the new messages and add that to current accumulated size. If the result exceeds minBytes, the fetch request is satisfied. So, the place that we trigger the check is inappropriate and the way that we do the check is incorrect.

The second problem (second fetch is returned late) is due to that we don't check if any fetch request can be satisfied after new messages are committed.

To fix the issues, we have to (1) trigger the check at the right places (2) do the check correctly. For (2), one simple approach is to always do a translation from last committed offset to file position to compute the bytes from the fetch offset. This will add the index lookup overhead for every check though.;;;","10/Dec/13 02:51;guozhang;Another way of doing this would be change the highWatermarkValue from AtomicLong to AtomicReference of a pair, with both logical and physical offset. For backward-compatibility, at the first call HW gets incremented, search the physical offset using the index just once.;;;","07/May/14 23:35;thecoop1984;I've also come across this issue, but I've also seen it a few times on a non-replicated setup. Here's a simple testcase to reproduce it - program that reads and writes single messages to a queue, using a long poll to read it.

Using the packaged kafka at https://github.com/stealthly/scala-kafka, this is reproducible on a single node within a few thousand messages.;;;","18/Jul/14 23:22;guozhang;Simon, I am currently working on KAFKA-1430, which hopefully will fixes both problems reported here. You can probably take a look at the ticket for now and let me know if you think anything is still missing.;;;","18/Jul/14 23:28;jkreps;Yeah, [~thecoop1984], can you verify that the patch on that ticket actually fixes the problem you saw?;;;","24/Jul/14 00:32;thecoop1984;Yes, looks like that patch fixes the issue.;;;","24/Jul/14 00:53;guozhang;Hi Simon, just wondering did you apply the patch and re-do the test ?;;;","24/Jul/14 17:17;thecoop1984;Yes, I built a replicated system with the patched kafka, and ran the test for about 10 minutes, with no delayed polls.;;;","24/Jul/14 23:02;guozhang;Awesome!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Broker with an invalid id would not start when its id is updated to a new valid one,KAFKA-3091,12929606,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,granthenke,vahid,vahid,13/Jan/16 06:13,06/Feb/16 05:06,22/Mar/23 15:10,19/Jan/16 10:56,0.9.0.0,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"Setup being used:
- Kafka 0.9.0
- Two servers:
-- server 1: zookeeper and 3 brokers (ids: 0, 1, 2)
-- server 2: 2 brokers (ids: 10 and 1 -> 11)

When on server 2 the second broker with initial id of 1 is started an error returned indicating the id 1 is in use. When the corresponding servers.properties file is updated and id is changed to 11 the broker would no longer start. The following error is returned:

[2016-01-12 13:40:22,145] FATAL Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.InconsistentBrokerIdException: Configured brokerId 11 doesn't match stored brokerId 1 in meta.properties
	at kafka.server.KafkaServer.getBrokerId(KafkaServer.scala:630)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:175)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2016-01-12 13:40:22,147] INFO shutting down (kafka.server.KafkaServer)
[2016-01-12 13:40:22,148] INFO Shutting down. (kafka.log.LogManager)
[2016-01-12 13:40:22,153] INFO Shutdown complete. (kafka.log.LogManager)
[2016-01-12 13:40:22,153] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2016-01-12 13:40:22,155] INFO Session: 0x15237b0b6270014 closed (org.apache.zookeeper.ZooKeeper)
[2016-01-12 13:40:22,155] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[2016-01-12 13:40:22,156] INFO shut down completed (kafka.server.KafkaServer)
[2016-01-12 13:40:22,156] FATAL Fatal error during KafkaServerStartable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
kafka.common.InconsistentBrokerIdException: Configured brokerId 11 doesn't match stored brokerId 1 in meta.properties
	at kafka.server.KafkaServer.getBrokerId(KafkaServer.scala:630)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:175)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2016-01-12 13:40:22,157] INFO shutting down (kafka.server.KafkaServer)


I looked at existing JIRA tickets referencing this error but none seemed to describe the exact scenario as the one here. Restarting brokers or the zookeeper would not seem to help.

And upon further testing it appears the number of servers is irrelevant here, and the same issue would surface in a one server setup too.",,githubbot,gwenshap,vahid,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3012,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Feb 05 21:06:56 UTC 2016,,,,,,,,,,"0|i2r7dr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"13/Jan/16 06:53;granthenke;I can look at this since its related to KAFKA-3012.;;;","13/Jan/16 13:40;githubbot;GitHub user granthenke opened a pull request:

    https://github.com/apache/kafka/pull/763

    KAFKA-3091: Broker with an invalid id would not start when its id is …

    …updated to a new valid one

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka id-start-failure

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/763.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #763
    
----
commit ba409ae96450d9517cf321557ff5940d6924a9a1
Author: Grant Henke <granthenke@gmail.com>
Date:   2016-01-13T05:11:10Z

    KAFKA-3091: Broker with an invalid id would not start when its id is updated to a new valid one

----
;;;","19/Jan/16 10:56;gwenshap;Issue resolved by pull request 763
[https://github.com/apache/kafka/pull/763];;;","19/Jan/16 10:56;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/763
;;;","06/Feb/16 04:53;vahid;If I have version 0.9.0 running and run into this issue, what is the easiest way to manually work around it? Thanks.;;;","06/Feb/16 05:00;granthenke;[~vahid] Just remove any files in the configured log.dirs directories. There should be a meta.properties file.;;;","06/Feb/16 05:06;vahid;Never mind. I updated the {{broker.id}} property in the file {{kafka-logs/meta.properties}} to the right broker id, and were able to start the broker.;;;","06/Feb/16 05:06;vahid;[~granthenke] Just saw your note after my second message. Thanks for the pointer anyway.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsoleProducer tool shows stacktrace on invalid command parameters,KAFKA-2601,12901753,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,GabrielNicolasAvellaneda,GabrielNicolasAvellaneda,GabrielNicolasAvellaneda,01/Oct/15 09:16,09/Feb/16 00:29,22/Mar/23 15:10,05/Oct/15 13:25,0.8.2.1,,,,,,,,,,,,,tools,,,,0,easyfix,,,,,"Running kafka-console-producer tool with an invalid argument shows a full stack trace instead of a user-friendly error:

{code}
vagrant@vagrant-ubuntu-trusty-64:/vagrant/kafka/kafka_2.9.1-0.8.2.1$ bin/kafka-console-producer.sh --zookeeper localhost:2181 --topic another-topic
Exception in thread ""main"" joptsimple.UnrecognizedOptionException: 'zookeeper' is not a recognized option
        at joptsimple.OptionException.unrecognizedOption(OptionException.java:93)
        at joptsimple.OptionParser.handleLongOptionToken(OptionParser.java:402)
        at joptsimple.OptionParserState$2.handleArgument(OptionParserState.java:55)
        at joptsimple.OptionParser.parse(OptionParser.java:392)
        at kafka.tools.ConsoleProducer$ProducerConfig.<init>(ConsoleProducer.scala:216)
        at kafka.tools.ConsoleProducer$.main(ConsoleProducer.scala:35)
        at kafka.tools.ConsoleProducer.main(ConsoleProducer.scala)
{code}",,eribeiro,ewencp,GabrielNicolasAvellaneda,githubbot,guozhang,mgainty@hotmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Feb 08 16:29:09 UTC 2016,,,,,,,,,,"0|i2mhev:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"01/Oct/15 11:17;eribeiro;Excuse me, Gabriel, I jumped too soon on this issue without asking if you are working or want to take a stab at it? If not, then, please, let me know. ;);;;","01/Oct/15 21:08;GabrielNicolasAvellaneda;Hi [~eribeiro], 

Yeap, easy fix, I will do a PR right now,

Thanks you!;;;","01/Oct/15 21:28;GabrielNicolasAvellaneda;Edward, do you know any way to speed up the compilation of the tools?;;;","01/Oct/15 21:51;githubbot;GitHub user GabrielNicolasAvellaneda opened a pull request:

    https://github.com/apache/kafka/pull/269

    KAFKA-2601: ConsoleProducer tool shows stacktrace on invalid command parameters

    Signed-off-by: GabrielNicolasAvellaneda <avellaneda.gabriel@gmail.com>

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/GabrielNicolasAvellaneda/kafka KAFKA-2601-fix

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/269.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #269
    
----
commit 06ec8e6de68b37f088ae68eb89fa137d10851496
Author: GabrielNicolasAvellaneda <avellaneda.gabriel@gmail.com>
Date:   2015-10-01T13:48:35Z

    Catch UnsupportedOptionException to show a friendly error message.
    
    Signed-off-by: GabrielNicolasAvellaneda <avellaneda.gabriel@gmail.com>

----
;;;","01/Oct/15 21:52;GabrielNicolasAvellaneda;Hey Edward,

Here is the pull request:
https://github.com/apache/kafka/pull/269

Please tell me if this is OK. It's my first time I do a contribution to Kafka.

Best!;;;","02/Oct/15 00:15;eribeiro;Hi [~GabrielNicolasAvellaneda], 

LGTM, but I am a newbie too (started about three months ago, but has been on and off due to work commitments, not consistently participating **yet**). So, I will pass the review torch to [~gwenshap], she is a Kafka committer and the coolest person you will interact with. :) They are all very busy, so be patient. ;)

ps: send message to the dev mailing list asking to include you as a contributor, so you can assign issues to yourself.

Welcome!
;;;","02/Oct/15 00:56;GabrielNicolasAvellaneda;Okay perfect! Thanks Edward!
Você é o cara :);;;","05/Oct/15 12:09;ewencp;[~guozhang] Trivial patch and LGTM, mind committing?;;;","05/Oct/15 13:04;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/269
;;;","05/Oct/15 13:25;guozhang;This has been committed by Sriharsha, closing it for now.;;;","08/Feb/16 23:53;mgainty@hotmail.com;i cannot find https://github.com/apache/kafka/pull/269
can someone point me to trunk repo where joptsimple is supposed to be?
Thanks;;;","09/Feb/16 00:29;GabrielNicolasAvellaneda;[~mgainty] this is the commit
https://github.com/apache/kafka/commit/f9faf334b0f62aec04214236dd10e9ba36fb9567;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MirrorMaker with new consumer doesn't handle CommitFailedException,KAFKA-3056,12925210,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,gwenshap,gwenshap,02/Jan/16 09:31,16/Jun/17 04:26,22/Mar/23 15:10,16/Jun/17 04:26,,,,,,,,,,,,,,,,,,0,,,,,,"MirrorMaker currently doesn't handle CommitFailedException when trying to commit (it only handles WakeupException).

I didn't test,  but it appears that if MirrorMaker tries to commit while rebalancing is in progress, it will result in thread failure.  Probably not what we want. I think the right thing is to log a message and call poll() again to trigger a re-join.",,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3409,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,2016-01-02 01:31:01.0,,,,,,,,,,"0|i2qg9z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DelayedProduce may cause message loss during repeated leader change,KAFKA-2960,12920026,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,becket_qin,peoplebike,peoplebike,08/Dec/15 18:08,12/Mar/16 03:22,22/Mar/23 15:10,12/Mar/16 03:22,0.9.0.0,,,,,,0.10.0.0,,,,,,,core,,,,0,,,,,,"related to #KAFKA-1148
When a leader replica became follower then leader again, it may truncated its log as follower. But the second time it became leader, its ISR may shrink and if at this moment new messages were appended, the DelayedProduce generated when it was leader the first time may be satisfied, and the client will receive a response with no error. But, actually the messages were lost. 

We simulated this scene, which proved the message lose could happen. And it seems to be the reason for a data lose recently happened to us according to broker logs and client logs.

I think we should check the leader epoch when send a response, or satisfy DelayedProduce when leader change as described in #KAFKA-1148.

And we may need an new error code to inform the producer about this error. ",,becket_qin,githubbot,guozhang,jinxing6042@126.com,jjkoshy,peoplebike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Mar 11 19:22:50 UTC 2016,,,,,,,,,,"0|i2plav:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"09/Dec/15 02:27;becket_qin;[~iBuddha] In Kafka, the persistence guarantee are at different levels. Would the following settings solve the scenario you mentioned?
acks=-1
min.isr=2
replication factor > 2

This should guarantee when response was sent, at least two brokers in the ISR has persisted the messages. So there should be no message loss unless the entire cluster is down.;;;","09/Dec/15 08:17;peoplebike;The Partition class  check log end offset and current ISR to decide if there's enough replicas. But after a leader become follower, it may truncate its log, and if it became leader again very quickly, there is a chance that another client sent messages to it, so the LEO will increase, and the current ISR has changed to 2, so the DelayedProduce is satisfied, even acks=-1 and min.isr=2 and replica.factor=3;;;","09/Dec/15 09:19;becket_qin;Not sure I follow the issue, in that case the ProducerRequest to the new leader will sit in Purgatory until the new follower have the message.;;;","09/Dec/15 14:13;guozhang;[~becket_qin] I think the issue here is that when a broker becomes follower, its delayed produce request does NOT get cleaned and returned an error code to the producer, but will still sit in the purgatory. If its producer timeout is long enough to not being timed out, it can be incorrectly satisfied when the follower becomes leader again. For example let's say we have two brokers:

Broker 1 is the leader with its current LEO 50, HW 50.
Broker 2 is follower with current LEO 50, HW 50.

1) broker 1 gets one message ""a"" with ack = all and append with offset 51, and its LEO is 51.
2) this produce request sit in the purgatory for broker 2 to replicate.
3) broker 1 becomes the follower and broker 2 becomes leader.
4) broker 1 sees broker 2's HW is 50, so it will truncate out message ""a"" and reset its LEO to 50.
5) broker 1 becomes leader again and broker 2 becomes follower again.
6) broker 1 gets another message ""b"", append with offset 51.
7) broker 2 replicates message ""b"".
8) broker 1 now advanced its HW to 51, and satisfying both produce requests for ""a"" and ""b"" based on the offset, but ""a"" is actually truncated.

[~peoplebike] I'm wondering in your case, what is the produce request timeout value to trigger this issue? And how long did you observe the original leader to transit to follower and back to leader again?
;;;","09/Dec/15 15:30;peoplebike;We use Kafka 0.8.2. The produce request timeout is the default value, which is 10000ms.
At 40:07, controller did a preferred leader election, sent LeaderAndIsrRequest to replicas. Just one or two seconds later, it found the broker hosted the new leader failed. So, the controller did another leader election, and send the second batch of LeaderAndIsrRequests.
At 40:11, the related replicas processed the first LeaderAndIsrRequest.
At 40:12, they processed the second LeaderAndIsrRequest.
So, the original leader experienced a leader -> follower -> leader change in just two seconds, I think. ;;;","10/Dec/15 01:37;becket_qin;[~guozhang] Got it. Thanks for the explanation.;;;","07/Mar/16 12:08;githubbot;GitHub user becketqin opened a pull request:

    https://github.com/apache/kafka/pull/1018

    KAFKA-2960: Clear purgatory for partitions before becoming follower

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/becketqin/kafka KAFKA-2960

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1018.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1018
    
----
commit 6ee590bc8f65217227c8bda98644dce35ed0d701
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2016-03-07T04:04:45Z

    KAFKA-2960: Clear purgatory for partition before becoming follower

----
;;;","12/Mar/16 03:22;jjkoshy;Issue resolved by pull request 1018
[https://github.com/apache/kafka/pull/1018];;;","12/Mar/16 03:22;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1018
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
WorkerSinkTask doesn't handle rewinding offsets on rebalance,KAFKA-2894,12916295,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,liquanpei,ewencp,ewencp,26/Nov/15 07:04,24/Aug/16 06:48,22/Mar/23 15:10,24/Aug/16 01:19,0.9.0.0,,,,,,0.10.1.0,,,,,,,KafkaConnect,,,,1,,,,,,"rewind() is only invoked at the beginning of each poll(). This means that if a rebalance occurs in the poll, it's feasible to get data that doesn't match a request to change offsets during the rebalance. I think the consumer will hold on to consumer data across the rebalance if it is reassigned the same offset, so there may already be data ready to be delivered. Additionally we may already have data in an incomplete messageBatch that should be discarded when the rewind is requested.

While connectors that care about this (i.e. ones that manage their own offsets) can handle this correctly by tracking the offsets they're expecting to see, it's a hassle, error prone, an pretty unintuitive.",,diederik,ewencp,githubbot,lucasmartinez,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Aug 23 22:48:06 UTC 2016,,,,,,,,,,"0|i2oyav:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"16/Jun/16 01:23;ewencp;More generally, I think we need to handle cases like rewind() after *any* connector methods are invoked. The rewind() in poll() handles Connector.start() and Connector.put(), but we also need to handle the rebalance callbacks (where we can ignore Connector.close() and only do this after Connector.open()) and Connector.flush().;;;","19/Jul/16 17:36;lucasmartinez;I apologize if I am asking in the wrong place, but I believe this issue could solve the problem I am having, and which I’ll explain in a bit.
First, how do connectors actually manage their own offsets? I tried creating a sink connector extending SinkTask, and:

1) I tried assigning a Map of <TopicPartition, Offset> to the context obtained in initialize() by doing context.offset(offsetMap). But this results in an exception “No current assignment for partition…” because the partitions were not assigned yet.

2) I tried doing the same in the open() method by saving the context from initialize() in a variable and assigning to it a map built with the Collection<TopicPartition> parameter. The result was to fetch all the messages from the last kafka committed offset, plus again, all the messages from the offsets I assigned manually to the partitions!
I also tried setting a worker property “auto.offset.reset=latest” as a workaround, but apparently it is not supported and the default value of earliest was used anyway.

Am I wrong to think that rewinding offsets on rebalance would solve this issue and I would be able to manually assign offsets on the open() method?
;;;","23/Aug/16 07:53;githubbot;GitHub user kkonstantine opened a pull request:

    https://github.com/apache/kafka/pull/1771

    KAFKA-2894: WorkerSinkTask should rewind offsets on rebalance

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/kkonstantine/kafka KAFKA-2894-rewind-offsets-on-rebalance

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1771.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1771
    
----
commit d14eff6084bafcf5014c8309703faafd96fe7071
Author: Konstantine Karantasis <k.karantasis@gmail.com>
Date:   2016-08-22T23:30:27Z

    KAFKA-2894: WorkerSinkTask should rewind offsets on rebalance

----
;;;","24/Aug/16 01:19;ewencp;Issue resolved by pull request 1771
[https://github.com/apache/kafka/pull/1771];;;","24/Aug/16 06:48;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1771
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"when controlled shutdown attempt fails, the reason is not always logged",KAFKA-1108,12676488,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,jbrosenberg@gmail.com,jbrosenberg@gmail.com,30/Oct/13 04:37,18/Oct/14 06:07,22/Mar/23 15:10,18/Oct/14 06:07,,,,,,,0.8.2.0,,,,,,,,,,,0,newbie,,,,,"In KafkaServer.controlledShutdown(), it initiates a controlled shutdown, and then if there's a failure, it will retry the controlledShutdown.

Looking at the code, there are 2 ways a retry could fail, one with an error response from the controller, and this messaging code:

{code}
info(""Remaining partitions to move: %s"".format(shutdownResponse.partitionsRemaining.mkString("","")))
info(""Error code from controller: %d"".format(shutdownResponse.errorCode))
{code}

Alternatively, there could be an IOException, with this code executed:

{code}
            catch {
              case ioe: java.io.IOException =>
                channel.disconnect()
                channel = null
                // ignore and try again
            }
{code}

And then finally, in either case:

{code}
          if (!shutdownSuceeded) {
            Thread.sleep(config.controlledShutdownRetryBackoffMs)
            warn(""Retrying controlled shutdown after the previous attempt failed..."")
          }
{code}

It would be nice if the nature of the IOException were logged in either case (I'd be happy with an ioe.getMessage() instead of a full stack trace, as kafka in general tends to be too willing to dump IOException stack traces!).

I suspect, in my case, the actual IOException is a socket timeout (as the time between initial ""Starting controlled shutdown...."" and the first ""Retrying..."" message is usually about 35 seconds (the socket timeout + the controlled shutdown retry backoff).  So, it would seem that really, the issue in this case is that controlled shutdown is taking too long.  It would seem sensible instead to have the controller report back to the server (before the socket timeout) that more time is needed, etc.",,donnchadh,ewencp,guozhang,jbrosenberg@gmail.com,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Oct/14 02:55;ewencp;KAFKA-1108.patch;https://issues.apache.org/jira/secure/attachment/12675079/KAFKA-1108.patch","17/Oct/14 04:53;ewencp;KAFKA-1108_2014-10-16_13:53:11.patch;https://issues.apache.org/jira/secure/attachment/12675345/KAFKA-1108_2014-10-16_13%3A53%3A11.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,355920,,,Fri Oct 17 22:07:28 UTC 2014,,,,,,,,,,"0|i1pcxr:",356208,,,,,,,,,,,,,,,,,,,,"05/Sep/14 06:04;guozhang;Moving to 0.9 for now.;;;","16/Oct/14 02:55;ewencp;Created reviewboard https://reviews.apache.org/r/26770/diff/
 against branch origin/trunk;;;","17/Oct/14 04:53;ewencp;Updated reviewboard https://reviews.apache.org/r/26770/diff/
 against branch origin/trunk;;;","18/Oct/14 06:07;nehanarkhede;Thanks for the patch. Pushed to trunk and 0.8.2;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zkclient dies after UnknownHostException in zk reconnect,KAFKA-1082,12673305,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,gwenshap,fanatoly,fanatoly,11/Oct/13 04:52,19/May/15 04:27,22/Mar/23 15:10,19/May/15 04:27,0.7.2,0.8.0,,,,,0.9.0.0,,,,,,,core,,,,0,,,,,,"Moving this here from the dev list:

I've run into the following issue with the Kafka server. The zkclient lib seems to die silently if there is an UnknownHostException(or any IOException) while reconnecting the ZK session. I've filed a bug about this with the zkclient lib(https://github.com/sgroschupf/zkclient/issues/23). The ramifications for Kafka were the silent loss of all ephemeral nodes associated with the affected process. 

It is fairly easy to reproduce this locally using the following steps:
-- Configure a local kafka broker to connect to a local ZK instance using a DNS alias(e.g.  add ""127.0.0.1 kafka-test-dns"" to your /etc/hosts)
-- Start the broker, observe that ephemeral nodes have been added to ZK
-- Suspend the broker process, preventing it from sending heartbeats to the ZK instance. Observe the loss of ephemeral nodes in ZK.
-- Remove the DNS alias(e.g. comment out the /etc/hosts line).
-- Upon resuming the broker, the UknownHostException is logged. After this point, the server cannot re-establish its ZK connection. Re-enabling the alias, for example, does not resume normal operation. The broker continues accepting requests, without participating in the ZK protocols.
",,diederik,fanatoly,gwenshap,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-620,KAFKA-2169,,,,,,,,,,,,,,,,,"11/Oct/13 06:07;fanatoly;KAFKA-1082.patch;https://issues.apache.org/jira/secure/attachment/12607896/KAFKA-1082.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,352928,,,Mon May 18 20:27:11 UTC 2015,,,,,,,,,,"0|i1ouj3:",353215,,,,,,,,,,,,,,,,,,,,"11/Oct/13 06:07;fanatoly;Created reviewboard ;;;","11/Oct/13 06:14;fanatoly;Sorry, first time running the reviewboard script: https://reviews.apache.org/r/14582;;;","14/Oct/13 08:03;junrao;Thanks for the patch. Commented on the RB. Also, we need to make sure the new zkclient 0.4 jar is backward compatible, i.e., it can be a drop-in replacement of the 0.3 and 0.1 jar without causing any runtime issues. I did some verification on the broker and the consumer side. It does seem to be binary backward compatible, even tough there is a new method in the state change listener interface. It would be good if you can confirm this.;;;","31/Oct/14 10:26;gwenshap;Assigning to me so I can track this - we want to get it in when we add ACLs to ZK (KAFKA-1695);;;","19/May/15 04:27;junrao;This is already resolved in KAFKA-2169.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cleaner cannot clean after shutdown during replaceSegments,KAFKA-2118,12820575,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,rsivaram,gian,gian,14/Apr/15 00:38,27/Apr/15 08:17,22/Mar/23 15:10,27/Apr/15 08:17,0.8.2.0,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"If a broker shuts down after the cleaner calls replaceSegments with more than one segment, the partition can be left in an uncleanable state. We saw this on a few brokers after doing a rolling update. The sequence of things we saw is:

1) Cleaner cleaned segments with base offsets 0, 1094621529, and 1094831997 into a new segment 0.
2) Cleaner logged ""Swapping in cleaned segment 0 for segment(s) 0,1094621529,1094831997 in log xxx-15."" and called replaceSegments.
3) 0.cleaned was renamed to 0.swap.
4) Broker shut down before deleting segments 1094621529 and 1094831997.
5) Broker started up and logged ""Found log file /mnt/persistent/kafka-logs/xxx-15/00000000000000000000.log.swap from interrupted swap operation, repairing.""
6) Cleaner thread died with the exception ""kafka.common.InvalidOffsetException: Attempt to append an offset (1094911424) to position 1003 no larger than the last offset appended (1095045873) to /mnt/persistent/kafka-logs/xxx-15/00000000000000000000.index.cleaned.""

I think what's happening in #6 is that when the broker started back up and repaired the log, segment 0 ended up with a bunch of messages that were also in segment 1094621529 and 1094831997 (because the new segment 0 was created from cleaning all 3). But segments 1094621529 and 1094831997 were still on disk, so offsets on disk were no longer monotonically increasing, violating the assumption of OffsetIndex. We ended up fixing this by deleting segments 1094621529 and 1094831997 manually, and then removing the line for this partition from the cleaner-offset-checkpoint file (otherwise it would reference the non-existent segment 1094621529).

This can happen even on a clean shutdown (the async deletes in replaceSegments might not happen).

Cleaner logs post-startup:
2015-04-12 15:07:56,533 INFO [kafka-log-cleaner-thread-0] kafka.log.LogCleaner - Cleaner 0: Beginning cleaning of log xxx-15.
2015-04-12 15:07:56,533 INFO [kafka-log-cleaner-thread-0] kafka.log.LogCleaner - Cleaner 0: Building offset map for xxx-15...
2015-04-12 15:07:56,595 INFO [kafka-log-cleaner-thread-0] kafka.log.LogCleaner - Cleaner 0: Building offset map for log xxx-15 for 6 segments in offset range [1094621529, 1095924157).
2015-04-12 15:08:01,443 INFO [kafka-log-cleaner-thread-0] kafka.log.LogCleaner - Cleaner 0: Offset map for log xxx-15 complete.
2015-04-12 15:08:01,443 INFO [kafka-log-cleaner-thread-0] kafka.log.LogCleaner - Cleaner 0: Cleaning log xxx-15 (discarding tombstones prior to Sun Apr 12 14:05:37 UTC 2015)...
2015-04-12 15:08:01,443 INFO [kafka-log-cleaner-thread-0] kafka.log.LogCleaner - Cleaner 0: Cleaning segment 0 in log xxx-15 (last modified Sun Apr 12 14:05:38 UTC 2015) into 0, retaining deletes.
2015-04-12 15:08:04,283 INFO [kafka-log-cleaner-thread-0] kafka.log.LogCleaner - Cleaner 0: Cleaning segment 1094621529 in log xxx-15 (last modified Sun Apr 12 13:49:27 UTC 2015) into 0, discarding deletes.
2015-04-12 15:08:05,079 INFO [kafka-log-cleaner-thread-0] kafka.log.LogCleaner - Cleaner 0: Cleaning segment 1094831997 in log xxx-15 (last modified Sun Apr 12 14:04:28 UTC 2015) into 0, discarding deletes.
2015-04-12 15:08:05,157 ERROR [kafka-log-cleaner-thread-0] kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Error due to
kafka.common.InvalidOffsetException: Attempt to append an offset (1094911424) to position 1003 no larger than the last offset appended (1095045873) to /mnt/persistent/kafka-logs/xxx-15/00000000000000000000.index.
cleaned.
at kafka.log.OffsetIndex$$anonfun$append$1.apply$mcV$sp(OffsetIndex.scala:207)
at kafka.log.OffsetIndex$$anonfun$append$1.apply(OffsetIndex.scala:197)
at kafka.log.OffsetIndex$$anonfun$append$1.apply(OffsetIndex.scala:197)
at kafka.utils.Utils$.inLock(Utils.scala:535)
at kafka.log.OffsetIndex.append(OffsetIndex.scala:197)
at kafka.log.LogSegment.append(LogSegment.scala:81)
at kafka.log.Cleaner.cleanInto(LogCleaner.scala:427)
at kafka.log.Cleaner$$anonfun$cleanSegments$1.apply(LogCleaner.scala:358)
at kafka.log.Cleaner$$anonfun$cleanSegments$1.apply(LogCleaner.scala:354)
at scala.collection.immutable.List.foreach(List.scala:318)
at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:354)
at kafka.log.Cleaner$$anonfun$clean$4.apply(LogCleaner.scala:321)
at kafka.log.Cleaner$$anonfun$clean$4.apply(LogCleaner.scala:320)
at scala.collection.immutable.List.foreach(List.scala:318)
at kafka.log.Cleaner.clean(LogCleaner.scala:320)
at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:221)
at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:199)
at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)
2015-04-12 15:08:05,157 INFO [kafka-log-cleaner-thread-0] kafka.log.LogCleaner - [kafka-log-cleaner-thread-0], Stopped",,gian,jkreps,junrao,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Apr/15 22:49;rsivaram;KAFKA-2118.patch;https://issues.apache.org/jira/secure/attachment/12725241/KAFKA-2118.patch","15/Apr/15 17:44;rsivaram;KAFKA-2118_2015-04-15_09:43:51.patch;https://issues.apache.org/jira/secure/attachment/12725532/KAFKA-2118_2015-04-15_09%3A43%3A51.patch","20/Apr/15 03:03;rsivaram;KAFKA-2118_2015-04-19_19:02:38.patch;https://issues.apache.org/jira/secure/attachment/12726458/KAFKA-2118_2015-04-19_19%3A02%3A38.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Apr 27 00:17:51 UTC 2015,,,,,,,,,,"0|i2d6rb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"14/Apr/15 22:49;rsivaram;Created reviewboard https://reviews.apache.org/r/33168/diff/
 against branch origin/trunk;;;","14/Apr/15 23:06;rsivaram;Looking at the code, the sequence for replacing segments is:
# Cleaner cleans a sequence of segments into a new segment with suffix .cleaned
# .cleaned is renamed to .swap. 
# Old segments are renamed, adding .deleted suffix
# Async deletion of .deleted files is scheduled
# .swap suffix is removed from the swap file, resulting in the swap file replacing the segments

The different scenarios for recovery are:
* If broker crashes before 2), .cleaned files are deleted on startup, aborting the clean operation. No issues here.
* There is an issue if the broker crashes between 2) and 3). If the .swap file was created, but the old segment files were not yet renamed to .deleted, the current recovery process replaces the segment file with the swap file, but does not delete the old segment files.
* If broker crashes after 3), recovery works fine on startup because old segment files no longer exist and any .deleted files found on startup are deleted, completing 4). If .swap was not yet renamed, it is renamed on startup, completing 5). There are no issues here. As far as I can tell, graceful shutdown is similar to this case and should work fine since the log files being deleted would have been renamed to .deleted.

To fix the second scenario above, the recovery operation should delete any remaining log files corresponding to the .swap file before the .swap file replaces the actual log file.

The attached patch fixes the recovery process by invoking the same replaceSegments() method during recovery, leaving all the logic for crash-safe swapping in one place.
;;;","15/Apr/15 17:44;rsivaram;Updated reviewboard https://reviews.apache.org/r/33168/diff/
 against branch origin/trunk;;;","15/Apr/15 17:52;rsivaram;Have updated the patch with an unit test to check recovery process after broker crash at different stages of a clean and swap operation. Test fails with current Kafka code and works with the updated code in the patch. 

Have also done manual testing by recreating the scenario described in this report by forcing termination during replaceSegments(). Have tested that the failure no longer occurs with the attached patch with the same manual test.;;;","20/Apr/15 03:03;rsivaram;Updated reviewboard https://reviews.apache.org/r/33168/diff/
 against branch origin/trunk;;;","20/Apr/15 04:05;rsivaram;[~junrao] Thank you for the review. Code comments have been updated in the latest patch.;;;","20/Apr/15 12:05;junrao;[~rsivaram], your latest patch looks good to me.

[~jkreps], do you want to take another look of the patch?;;;","21/Apr/15 00:26;jkreps;I don't think I'll get to it, go ahead without me. Just be careful, that code is a bit tricky.;;;","27/Apr/15 08:17;junrao;Thanks for the latest patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Standardize --messages option in perf scripts,KAFKA-1621,12738309,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,rekhajoshm,jkreps,jkreps,02/Sep/14 01:19,27/Dec/16 06:38,22/Mar/23 15:10,29/Apr/15 00:33,0.8.1.1,,,,,,,,,,,,,,,,,0,newbie,,,,,"This option is specified in PerfConfig and is used by the producer, consumer and simple consumer perf commands. The docstring on the argument does not list it as required but the producer performance test requires it--others don't.

We should standardize this so that either all the commands require the option and it is marked as required in the docstring or none of them list it as required.",,githubbot,jkreps,nehanarkhede,omkreddy,rekhajoshm,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2157,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Dec 26 22:38:16 UTC 2016,,,,,,,,,,"0|i1zk53:",9223372036854775807,,jkreps,,,,,,,,,,,,,,,,,,"07/Oct/14 12:12;omkreddy;[~jkreps]  I would like to work on this issue. Are you referring kafka-consumer-perf-test.sh, kafka-producer-perf-test.sh,???,   scripts? ;;;","23/Feb/15 07:18;githubbot;GitHub user rekhajoshm opened a pull request:

    https://github.com/apache/kafka/pull/46

    KAFKA-1621 : Standardize --messages option

    KAFKA-1621: Standardize --messages option in perf scripts

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/rekhajoshm/kafka KAFKA-1621

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/46.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #46
    
----
commit d123f48f85604c765b464d6b9d5cee4b3ec0de25
Author: Joshi <rekhajoshm@gmail.com>
Date:   2015-02-22T23:21:55Z

    KAFKA-1621 : Standardize --messages option

----
;;;","23/Feb/15 07:21;rekhajoshm;https://github.com/apache/kafka/pull/46;;;","07/Apr/15 04:22;rekhajoshm;Hi.missed updating earlier. everything else was setup as https://cwiki.apache.org/confluence/display/KAFKA/Patch+submission+and+review but the jira-client could not be installed (Mac 10.9.5, Python 2.7.5, pip 1.5.6), hence could not update review board.
suggestion: why not review directly on git as rest of the apache projects?

python kafka-patch-review.py --help
Traceback (most recent call last):
  File ""kafka-patch-review.py"", line 10, in <module>
    from jira.client import JIRA
ImportError: No module named jira.client

pip install jira-python
Downloading/unpacking jira-python
  Could not find any downloads that satisfy the requirement jira-python
Cleaning up...
No distributions at all found for jira-python
Storing debug log for failure in /usr/local/.pip/pip.log

sudo easy_install jira-python
Searching for jira-python
Reading http://pypi.python.org/simple/jira-python/
Couldn't find index page for 'jira-python' (maybe misspelled?)
Scanning index of all packages (this may take a while)
Reading http://pypi.python.org/simple/
No local packages or download links found for jira-python
error: Could not find suitable distribution for Requirement.parse('jira-python')

Think it could be related to security enabled on pip?, but I would prefer not to downgrade pip as used for my other projects as well.;;;","27/Apr/15 07:13;nehanarkhede;[~rekhajoshm] Sorry for the delay, reviewed your PR. However, could you send it for trunk instead of 0.8.2?;;;","28/Apr/15 05:01;githubbot;GitHub user rekhajoshm opened a pull request:

    https://github.com/apache/kafka/pull/58

    KAFKA-1621 : Standardize --messages option

    As per review comments from @nehanarkhede Thanks.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/rekhajoshm/kafka localtrunk

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/58.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #58
    
----
commit 51cab8584872457a349d6ba154a1087b9749e0f8
Author: Joshi <rekhajoshm@gmail.com>
Date:   2015-04-27T21:02:15Z

    KAFKA-1621 : Standardize --messages option

----
;;;","28/Apr/15 05:09;rekhajoshm;No worries [~nehanarkhede] Thanks for your review, PerfConfig was found updated in trunk for REQUIRED, rest applied on pull #58.Thanks.;;;","29/Apr/15 00:33;nehanarkhede;Merged PR #58;;;","21/Jul/15 13:51;githubbot;Github user rekhajoshm closed the pull request at:

    https://github.com/apache/kafka/pull/58
;;;","27/Dec/16 06:38;githubbot;Github user pono closed the pull request at:

    https://github.com/apache/kafka/pull/46
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsumerGroupCommand should allow resetting offsets for consumer groups,KAFKA-3059,12927022,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,hachikuji,gwenshap,gwenshap,05/Jan/16 01:25,04/Sep/17 16:47,22/Mar/23 15:10,04/Sep/17 16:47,,,,,,,,,,,,,,,,,,7,,,,,,"As discussed here:
http://mail-archives.apache.org/mod_mbox/kafka-users/201601.mbox/%3CCA%2BndhHpf3ib%3Ddsh9zvtfVjRiUjSz%2B%3D8umXm4myW%2BpBsbTYATAQ%40mail.gmail.com%3E

* Given a consumer group, remove all stored offsets
* Given a group and a topic, remove offset for group  and topic
* Given a group, topic, partition and offset - set the offset for the specified partition and group with the given value",,codecraig,elevy,graphex,guozhang,gwenshap,hachikuji,hcai@pinterest.com,mjattiot,mjsax,omkreddy,phuna,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-4743,,,,,,,,KAFKA-3057,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Sep 04 08:47:06 UTC 2017,,,,,,,,,,"0|i2qrgf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"05/Jan/16 01:52;hachikuji;Would this call for a new request API (e.g. DeleteGroup or DeleteOffsets)? I'm not sure we'd be able to have the command write to the offsets topic directly without some significant changes. Currently, I think GroupMetadataManager only consumes from the offsets topic when it assumes leadership for one of the partitions, so external writes to these topics would lead to cache inconsistency.;;;","05/Jan/16 04:35;sslavic;KAFKA-3057 was earlier created to fix related documentation.;;;","06/Jan/16 06:00;hachikuji;One problem is defining the behavior of these operations when the consumer group is still active. The simple option would be to forbid them. Users would have to shutdown all consumers in the group, which actually seems pretty reasonable. But if there are legitimate use cases which call for overriding offsets while a group is still active, then it will take some tricky coordination to get all group members to reload offsets.

As far as implementation, writing to the offsets topic directly does not seem viable since there would be no way to verify whether the group is active or not. Even if we wanted to support offset updates while the group is active, it would still require some coordination with the group coordinator. That means we'll either need to override the commit API to support deletion (e.g. by using -1 as the offset for each partition as someone suggested on the user list), or introduce a DeleteOffsets API. Either way, this will probably need a KIP. 
;;;","06/Jan/16 06:14;gwenshap;One thing:
If we go the route of ""ask the users to shut down all consumers in the group"" (which I find painful, but reasonable), the tool must validate that this is the case before setting a new offset. Otherwise the results will be very unpredictable.

;;;","16/Jun/16 05:43;hcai@pinterest.com;We would like to have the capability to move the offset to a certain time in the past.  Doesn't have to be a precise point, move to the offset a little before that past time is fine, I think the ListOffsetRequest gives that capability.;;;","16/Jun/16 05:48;guozhang;Chiming in here since Streams may need this feature as well for cleaning up (cc [~mjsax]): I think ""all consumers in the group is shutdown"" is a reasonable request before using this admin command. And in addition there are cases where users only use Kafka for storing offsets but not for group management; so the validation on the server side would be: ""if there is no group registry information, or else if the group's member list is empty, proceed"".

For overriding offsets I agree that the current OffsetCommit Request with generation id equals to -1 would work. As for DeleteGroup v.s. DeleteOffsets for deleting offsets, personally I feel the latter may be necessary since there are cases when users only want to delete some specific offset (but not all offsets), and delete-group will not naturally support that. In addition, if users really want to delete the whole group before waiting it to be auto purged (with default purging frequency of 5 minutes today) they can still use delete-offsets on all offsets.

One orthogonal point is that today we do not enforce ""groupId"" as required config and default value is empty string, so that if two consumers started with manual assignment but both forgot to set the group id their overrides will interfere each other; one possible solution maybe to use ""threadId"" instead of empty string as defaults, since for cases where users do not care to specify a group id, they are usually just one instance starting on a single machine.;;;","04/Sep/17 16:47;omkreddy;This functionality is implemented in KAFKA-4743;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DefaultEventHandler causes unbalanced distribution of messages across partitions,KAFKA-1183,12684470,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,junrao,ddragos,ddragos,13/Dec/13 22:26,08/Oct/16 01:02,22/Mar/23 15:10,16/Dec/13 18:59,0.8.0,,,,,,,,,,,,,producer ,,,,0,,,,,,"KAFKA-959 introduced an optimisation in {{DefaultEventHandler}} that was supposed to have the effect of sending all messages from the same batch to a single partition if no key is specified.

The problem is that the {{sendPartitionPerTopicCache}} cache, which holds the current selected partition for each topic, isn't actually invalided at the start or end of each batch.

The observed result is that, after the first request chooses a random partition, all subsequent messages from that producer land in the same partition. If you have a large number of producers, then it should be fine, but if your producer count is comparable to the partition count, then it will get unbalanced.",,amuraru,ddragos,joestein,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1067,,,,,,,,,,,,,,,,"13/Dec/13 22:40;ddragos;KAFKA-1183-trunk.patch;https://issues.apache.org/jira/secure/attachment/12618605/KAFKA-1183-trunk.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,363542,,,Mon Dec 16 10:59:21 UTC 2013,,,,,,,,,,"0|i1qnxz:",363848,,,,,,,,,,,,,,,,,,,,"13/Dec/13 22:30;ddragos;Inspecting the {{DefaultEventHandler}} code, there are 2 cases in which this cache is invalidated:
1. Every {{topic.metadata.refresh.interval.ms}} ms. This defaults to 10 minutes (which I think is way too rarely for refreshing this cache).
2. When {{dispatchSerializedData}} fails to send all messages. Never noticed this actually happening.

I suppose the cache should also be invalidated at the start of the {{handle}} method.;;;","13/Dec/13 22:40;ddragos;Attached the proposed patch.;;;","13/Dec/13 23:39;ddragos;On further inspection, I noticed that the line was added and then removed in KAFKA-1017 to prevent {{num_producers x num_partitions}} sockets. Thus, for our use-case which involves a comparable number of producers and partitions coupled with the need of partitions being as balanced as possible over a 2m-10m window, the proposed solution would be lowering {{topic.metadata.refresh.interval.ms}}?;;;","14/Dec/13 00:26;junrao;Yes, for now, you can achieve it by either reducing the metadata refresh interval or providing a message key and potentially a customized random partitioner.

We have a jira (KAFKA-1067) to track this issue. Since it requires an api change, it will have to wait until 0.9.;;;","14/Dec/13 03:25;amuraru;[~junrao] Jun, what's the impact of lowering the metadata refresh interval to say 10 seconds, this would solve the partition stickiness in the producer but would that have other performance side effects? Reading the email thread on KAFKA-1067 I see that creating a customised random partioner is not possible at this point as it's not aware of AVAILABLE partitions. Thanks;;;","14/Dec/13 12:02;junrao;Metadata requests are cheap. So, as long as you don't have too many producers, reducing refresh interval to 10 secs will be fine.;;;","16/Dec/13 18:59;joestein;duplicate of KAFKA-1067;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
No more clients can connect after `TooManyConnectionsException` threshold (max.connections.per.ip) is reached,KAFKA-2614,12902782,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,ijuma,stephenchu810,stephenchu810,07/Oct/15 03:01,11/Oct/15 06:25,22/Mar/23 15:10,11/Oct/15 06:24,0.8.2.1,,,,,,0.9.0.0,,,,,,,core,,,,1,,,,,,"It seems no more clients can connect to Kafka after `max.connections.per.ip` is reached, even if previous clients were already disconnected.

Using 0.8.3 (9c936b18), upon starting a fresh Kafka server that is configured with (max.connections.per.ip = 24), I noticed that I can cause the server to hit the error case of {{INFO Rejected connection from /0:0:0:0:0:0:0:1, address already has the configured maximum of 24 connections.}} very quickly, by simply looping through a bunch of simple clients against the server:
{noformat}
#! /bin/bash

for i in {1..30}; do
    # either:
    nc -vz 127.0.0.1 9092;
    # or:
    ( telnet 127.0.0.1 9092; ) &
done

# if using telnet, kill all connected jobs now via:
kill %{2..31}
{noformat}

The problem seems to be that the counter for such short-lived client connections aren't properly decrementing when using the `max.connections.per.ip` feature.

Turning on DEBUG logs, I cannot see the log lines ""Closing connection from xxx"" on [this line|https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/network/SocketServer.scala#L164] from the first few still-under-threshold short-lived connections, but starts showing *after* I hit the limit per that config.",Debian Jessie,githubbot,ijuma,junrao,ronnieftw,stephenchu810,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Oct 10 22:25:04 UTC 2015,,,,,,,,,,"0|i2mnj3:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"07/Oct/15 20:47;ijuma;Thanks for filing this, there is indeed an issue where we are not handling disconnections properly. I have fixed it locally and will push a PR soon for discussion.;;;","08/Oct/15 23:44;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/288

    KAFKA-2614; No more clients can connect after `TooManyConnectionsException` threshold (max.connections.per.ip) is reached

    * Call `ConnectionQuotas.decr` when calling `Selector.close` and when disconnections happen.
    * Expand `SocketServerTest` to test for this and to close sockets.
    * Refactor and clean-up `SocketServer` and `Acceptor` to make the code easier to understand.
    


You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-2614-connection-count-not-updated

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/288.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #288
    
----
commit 1f0786e22e23858a6e76cd40c570ffbbd91fc349
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2015-10-08T15:38:24Z

    Call `ConnectionQuotas.decr` when calling `Selector.close` and when disconnections happen
    
    Also:
    * Expand `SocketServerTest` to test for this and to close sockets.
    * Refactor and clean-up `SocketServer` and `Acceptor` to make the code easier to understand.

----
;;;","08/Oct/15 23:50;ijuma;Ready for review [~junrao].;;;","11/Oct/15 06:24;junrao;Issue resolved by pull request 288
[https://github.com/apache/kafka/pull/288];;;","11/Oct/15 06:25;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/288
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Snappy compressor is not thread safe,KAFKA-1721,12749406,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,ewencp,ewencp,21/Oct/14 09:55,15/Nov/14 07:25,22/Mar/23 15:10,15/Nov/14 07:25,,,,,,,0.8.2.0,,,,,,,compression,,,,0,,,,,,"From the mailing list, it can generate this exception:

2014-10-20 18:55:21.841 [kafka-producer-network-thread] ERROR
org.apache.kafka.clients.producer.internals.Sender - Uncaught error in
kafka producer I/O thread:
*java.lang.NullPointerException*
at
org.xerial.snappy.BufferRecycler.releaseInputBuffer(BufferRecycler.java:153)
at org.xerial.snappy.SnappyOutputStream.close(SnappyOutputStream.java:317)
at java.io.FilterOutputStream.close(FilterOutputStream.java:160)
at org.apache.kafka.common.record.Compressor.close(Compressor.java:94)
at
org.apache.kafka.common.record.MemoryRecords.close(MemoryRecords.java:119)
at
org.apache.kafka.clients.producer.internals.RecordAccumulator.drain(RecordAccumulator.java:285)
at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:162)
at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:115)
at java.lang.Thread.run(Thread.java:744)

This appears to be an issue with the snappy-java library using ThreadLocal for an internal buffer recycling object which results in that object being shared unsafely across threads if one thread sends to multiple producers:

{quote}
I think the issue is that you're
using all your producers across a thread pool and the snappy library
uses ThreadLocal BufferRecyclers. When new Snappy streams are allocated,
they may be allocated from the same thread (e.g. one of your MyProducer
classes calls Producer.send() on multiple producers from the same
thread) and therefore use the same BufferRecycler. Eventually you hit
the code in the stacktrace, and if two producer send threads hit it
concurrently they improperly share the unsynchronized BufferRecycler.

This seems like a pain to fix -- it's really a deficiency of the snappy
library and as far as I can see there's no external control over
BufferRecycler in their API. One possibility is to record the thread ID
when we generate a new stream in Compressor and use that to synchronize
access to ensure no concurrent BufferRecycler access. That could be made
specific to snappy so it wouldn't impact other codecs. Not exactly
ideal, but it would work. Unfortunately I can't think of any way for you
to protect against this in your own code since the problem arises in the
producer send thread, which your code should never know about.

Another option would be to setup your producers differently to avoid the
possibility of unsynchronized access from multiple threads (i.e. don't
use the same thread pool approach), but whether you can do that will
depend on your use case.
{quote}",,Bmis13,ewencp,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Oct/14 09:17;ewencp;KAFKA-1721.patch;https://issues.apache.org/jira/secure/attachment/12676804/KAFKA-1721.patch","29/Oct/14 00:25;ewencp;KAFKA-1721_2014-10-28_09:25:50.patch;https://issues.apache.org/jira/secure/attachment/12677626/KAFKA-1721_2014-10-28_09%3A25%3A50.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 14 23:25:05 UTC 2014,,,,,,,,,,"0|i21dvb:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"22/Oct/14 03:01;Bmis13;I have filled https://github.com/xerial/snappy-java/issues/88 for tracking for Snappy. 

There is patch provided and Thanks to [~ewencp] for testing the patch.  Please see above link for more details.


Thanks,

Bhavesh ;;;","24/Oct/14 02:32;Bmis13;[~ewencp],

Thanks for fixing this issue.  Snappy Dev has release new version with fix https://oss.sonatype.org/content/repositories/releases/org/xerial/snappy/snappy-java/1.1.1.4/ 

Thanks,
Bhavesh;;;","24/Oct/14 06:58;junrao;Bhavesh,

Do you want to submit a patch to upgrade the snappy jar in Kafka? Thanks,;;;","24/Oct/14 07:00;ewencp;I have the trivial patch, but the upstream jar seems to be broken (see the earlier Github issue). I'll follow up on this once that issue is resolved.;;;","24/Oct/14 09:17;ewencp;Created reviewboard https://reviews.apache.org/r/27124/diff/
 against branch origin/trunk;;;","29/Oct/14 00:25;ewencp;Updated reviewboard https://reviews.apache.org/r/27124/diff/
 against branch origin/trunk;;;","15/Nov/14 02:42;ewencp;[~junrao] This is a trivial version update patch. It would be nice for the fix to make it to 0.8.2, but I'm not sure we want to push a dependency version change between beta and final.;;;","15/Nov/14 07:25;junrao;Thanks for the patch. Since this change is trivial, double committed to 0.8.2 and trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Coordinator should not allow empty groupIds,KAFKA-2648,12904752,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,hachikuji,hachikuji,hachikuji,14/Oct/15 12:56,29/Oct/15 05:09,22/Mar/23 15:10,29/Oct/15 05:09,0.9.0.0,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"The coordinator currently allows consumer groups with empty groupIds, but there probably aren't any cases where this is actually a good idea and it tends to mask problems where different groups have simply not configured a groupId. To address this, we can add a new error code, say INVALID_GROUP_ID, which the coordinator can return when it encounters an  empty groupID. We should also make groupId a required property in consumer configuration and enforce that it is non-empty. 

It's a little unclear whether this change would have compatibility concerns. The old consumer will fail with an empty groupId (because it cannot create the zookeeper paths), but other clients may allow it.",,githubbot,guozhang,hachikuji,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Oct 28 21:09:04 UTC 2015,,,,,,,,,,"0|i2mzhj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"27/Oct/15 03:41;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/362

    KAFKA-2648: group.id is required for new consumer and cannot be empty

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-2648

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/362.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #362
    
----
commit 5a419664f36fcbb955e250ebfe8c531e50fff981
Author: Jason Gustafson <jason@confluent.io>
Date:   2015-10-26T19:40:02Z

    KAFKA-2648: group.id is required for new consumer and cannot be empty

----
;;;","27/Oct/15 05:10;guozhang;The new consumer consolidates the old high-level and simple consumers, and for old simple consumer one does not need to specify group ids since it does not require any coordination at all. But given that I feel we do not need to be concerned about compatibility since the new consumer does not need to be compatible with the old consumer's APIs.

The concerns I have, though, is about enforcing group id at the consumer side as the submitted PR: consumer instances may be used by tooling / admin / high-level services like streaming etc, which does not necessarily need to specify group ids since they do not need coordination. An alternative is to do exactly this ticket's title suggested: let the coordinator check if group id is empty, but not necessarily enforce non-empty group ids at the consumer side, and document ""if you EVER want to subscribe during the lifetime of your consumer, you need to specify the group-id or otherwise subscribe() can throw a runtime exception"".;;;","27/Oct/15 09:25;hachikuji;[~guozhang] I would actually prefer checking this on the server side, and I agree that it would be nice to not have to set groupId in cases where you don't actually need it. The only concern I had was whether there were any existing applications that depended on being able to use empty groupId for offset commits. ;;;","28/Oct/15 04:49;guozhang;We can just check non-empty group-id in join-group / sync-group requests, but not in offset commit / fetch requests.;;;","29/Oct/15 05:09;guozhang;Issue resolved by pull request 362
[https://github.com/apache/kafka/pull/362];;;","29/Oct/15 05:09;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/362
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Various ZK listeners to support intra-cluster replication,KAFKA-44,12514681,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,junrao,,20/Jul/11 05:32,11/Jun/12 04:42,22/Mar/23 15:10,11/Jun/12 04:42,,,,,,,,,,,,,,,,,,0,,,,,,We need to implement the new ZK listeners for the new paths registered in ZK.,,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-50,,,,,,,,,,KAFKA-45,KAFKA-301,,,,,,,,,,,,,"28/Feb/12 12:32;prashanth.menon;KAFKA-44-DRAFT-v1.patch;https://issues.apache.org/jira/secure/attachment/12516272/KAFKA-44-DRAFT-v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,67071,,,Sun Jun 10 20:42:28 UTC 2012,,,,,,,,,,"0|i15yon:",242919,,,,,,,,,,,,,,,,,,,,"21/Feb/12 11:38;prashanth.menon;Hi all,

I spent today working through this (and consequently KAFKA-45 because there's a lot of overlap), hoping to have a patch in mid-week, and had a suggestion regarding how new replicas are assigned to brokers.  Currently, every broker effectively listens to every possible path in /brokers/topic/[topic]/partitions/[partition] because it doesn't know which partition replica will be assigned to it.  This places heavy burden on ZK since it will have to fire an unncecessary high volume of callbacks to every broker.  

The problem is that the broker doesn't know for which partition it will be assigned a replica for after its up.  I propose an approach whereby a new path in ZK acts as a queue which brokers watch to receive new replica assignments.  This path will exist for every broker in the system, so something like /brokers/[brokerId]/new_partition/[topic:partitionId] or some such thing?  The admin utilities will create these paths along with the replica assignments.  I realize this is additional overhead and somewhat asymmetric with the other partition paths so I'm interested to hear peoples thoughts!;;;","22/Feb/12 05:57;junrao;Prshanth, 

This seems like a good idea to me. Ideally, this new ZK path /brokers/[brokerId]/new_partition/[topic:partitionId] should be created atomically with other ZK paths constructed when a new topic is created. We could leverage the ZK multiple-row transaction support for this when ZK 3.4 is more stable.;;;","22/Feb/12 10:10;prashanth.menon;Sounds good.  Another question is what to do with that path should the broker go down with pending assignments.  My vote would be for the broker to recreate it as part of the startup process, thereby deleting previous data.  My thinking is that the broker will discover all assigned replicas naturally as part of startup assuming the topic creation admin tool did its job correctly updating partition replica lists in ZK.;;;","22/Feb/12 12:36;junrao;Not sure if I follow exactly what you are proposing here. In particular, what does the broker recreate? My thinking is the following:

/brokers/[brokerId]/new_partition/[topic:partitionId] is the source of truth about what topic/partitions a broker has and that path is only created during topic creation. A broker listens to that path to pick up new topic/partition assigned to it. When a broker starts up, it simply reads all /brokers/[brokerId]/new_partition/[topic:partitionId] to determine the set of topic/partition that it should have. So the broker never needs to recreate that path.;;;","23/Feb/12 01:01;prashanth.menon;Ah, I think I see where you're going with this.  You'd like to use it as a persistent path listing all partitions assigned to a broker.  If so, perhaps the path can be changed slightly to /brokers/[brokerId]/assigned_partitions/[topic:partitionId] to indicate appropriately?  

My intention was to have that just for new partition assignment notifications and act more like a queue.  So the flow would be:

1. Tool assigns topic X, partition Y to broker Z
1a. New entry added to /broker/topics/X/partitions/Y/replicas to append broker Z to list.
1b. New znode created at /broker/Z/new_partition/[X:Y]
2. Broker listens on /broker/Z/new_partition
2a. New partition is assigned, bootstrap replicas
2b After successful bootstrap, remove /broker/Z/new_partition/[X:Y]

I like you're idea much better; it's clear which partitions are assigned to which broker and makes startup simpler as well.
;;;","24/Feb/12 12:18;prashanth.menon;Can we also use this new path for partition reassignment?  When the admin would like to reassign a partition, the broker's ID is appeneded to the list at /brokers/partitions_reassigned/[topic]/[partId] and a znode is created in /brokers/[brokerId]/assigned_partitions/[topic:partId] ?  Then only the leader listens on the reassignment path in order to update the leader replicas RAR and the new brokers become aware of new partitions and bootstrap as they normally would.  Thoughts?;;;","25/Feb/12 00:40;junrao;It may be possible, but this can be a bit tricky. When you move a partition, you want to wait until the partition in the new broker has fully caught up, before deleting the one on the old broker. So, one way to achieve this is to have another ZK path that indicates this transition state. After the transition is done, the new assignment will be added to the assigned_partition path.

In any case, let's start by just focusing on static partition assignment. We can worry about partition reassignment a bit later when we get to kafka-42.;;;","28/Feb/12 12:31;prashanth.menon;Okay, I've attached a very very rough draft of a patch.  I'm really looking for feedback and thoughts because there's just a lot of overlap with KAFKA-45.

1. New classes are Replica, Partition and ReplicaManager.  kafka.replica.Partition will need to be merged with kafka.cluster.Partition which is a little light at the moment.
2. There are a few placeholders for KAFKA-45 and KAFKA-46 in there.
3. Does not include the partition reassignment listener.  We'll need to revisit this because the current process suffers from the same problem as the previous partition assignment logic.
4. Includes the new assigned_partitions path but relies on old replica assignment path creation for testing purposes.  This will need to change once the tools change.
5. I've tried to make it as unintrusive as possible.

There is one issue I'm trying to wrap my head around.  Consider a broker A that comes up with no partitions and the admin reassigns a partition X to it.  It properly bootstraps it and catches up.  Upon catch up, the current leader executes a leader election and assume broker A wins.  Broker A then does some bootstrapping before ""switching on"" the partition and serving fetch/produce requests.  Part of the bootstrap is determining which replicas are in ISR (read from ZK) by waiting for the replica to catch up, but because the server isn't responding to fetch requests for the replica and it isn't aware of where every replica is in terms of its HW and LEO, none will ever catch up ""in time"".  Am I missing something?;;;","02/Mar/12 04:08;nehanarkhede;This approach of having a queue of state change requests that each replica acts upon, is something I'm leaning towards for all state changes. 

There are 2 ways of making state changes in a system which uses ZK listeners -

1. Each server listens on various ZK paths, registers the same listeners, and follows the same code path to apply state changes to itself. Here, the state machine, is replicated on each server.
2. A highly-available co-ordinator listens of various ZK paths, registers ZK listeners, verifies system state and state transitions. Then issues state transition requests to the various replicas. Here, only the co-ordinator executes the state machine.

We have been down approach 1 earlier with the zookeeper consumer, and through experience, found that though, it seems simpler to design and implement at first, it turns into a fairly buggy and high operational overhead system. This is because that approach suffers from 

1. herd effect
2. ""split brain"" problem. 
3. In addition to these, it will be pretty complicated to perform upgrades on the state machine and can leave the cluster in an undefined state during upgrades.  
4. Monitoring the state machine is a hassle, due to it being distributed in nature

Approach 2 ensures the state machine only on the co-ordinator, which itself is elected from amongst the brokers. This approach ensures that - 

1. at any point of time, we can reason about the state of the entire cluster.
2. Only after the state is verified, can further state changes be applied. If verification fails, alerts can be triggered preventing the system from getting into an indefinite state.
3. A big advantage of this approach is easier upgrades to the state machine. It is true that, theoretically, state machine logic doesn't change much over time, but in reality, state machine changes would need upgrades, due to improvements in the logic or fixing code bugs. 
4. Monitoring the state machine becomes much simpler

In general, both approaches are “doable”, but we need to weigh the cost of “patching” the code to make it work VS choosing a simple design that will be easy to maintain and monitor.

I would like to see a discussion on this fundamental design choice, before jumping to code and patches on KAFKA-44 and KAFKA-45.  ;;;","02/Mar/12 06:56;prashanth.menon;That sounds fair enough.  Can we create a wiki page attached to one created for the overall replication work as mentioned in KAFKA-50?;;;","05/Mar/12 11:52;prashanth.menon;Also, mind if I assign this to myself?;;;","13/Mar/12 08:24;nehanarkhede;This JIRA can implement the stateChangeListener() as described in the Kafka replication design document, and leave stubs for becomeFollower()/becomeLeader() which are part of KAFKA-302. Also, lets leave out anything about partition reassignment for now. That work is included as part of other JIRAs and can be done when the basic replication functionality is nailed and tested.

Prashanth, I've attempted to reduce dependencies and define scope of KAFKA-44 and KAFKA-45. Hopefully the above clarifies the scope of this JIRA. Assigning it to you, as per your request;;;","13/Mar/12 10:11;prashanth.menon;Sounds good to me.  I'm also fine with removing this ticket and rolling this work as another subtask of KAFKA-45 just for clarity.  Your decision :);;;","17/Mar/12 01:04;nehanarkhede;This is very closely related to the broker startup procedure;;;","11/Jun/12 04:42;nehanarkhede;Fixed as part of KAFKA-301;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Issue sending more messages to single Kafka server (Load testing for Kafka transport),KAFKA-1693,12746933,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,kathees,kathees,09/Oct/14 13:49,26/Jan/15 13:59,22/Mar/23 15:10,26/Jan/15 13:59,0.8.1.1,,,,,,,,,,,,,,,,,0,,,,,,"I tried to send 50000 messages to single Kafka server.I sent the messages to ESB using JMeter and ESB sent to Kafka server. After 28000 message I am getting following exception.Do I need to change any parameter value in Kafka server.Please give me the solution.
 
[2014-10-06 11:41:05,182] ERROR - Utils$ fetching topic metadata for topics [Set(test1)] from broker [ArrayBuffer(id:0,host:localhost,port:9092)] failed
kafka.common.KafkaException: fetching topic metadata for topics [Set(test1)] from broker [ArrayBuffer(id:0,host:localhost,port:9092)] failed
at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:67)
at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
at kafka.producer.async.DefaultEventHandler$$anonfun$handle$1.apply$mcV$sp(DefaultEventHandler.scala:67)
at kafka.utils.Utils$.swallow(Utils.scala:167)
at kafka.utils.Logging$class.swallowError(Logging.scala:106)
at kafka.utils.Utils$.swallowError(Utils.scala:46)
at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:67)
at kafka.producer.Producer.send(Producer.scala:76)
at kafka.javaapi.producer.Producer.send(Producer.scala:33)
at org.wso2.carbon.connector.KafkaProduce.send(KafkaProduce.java:71)
at org.wso2.carbon.connector.KafkaProduce.connect(KafkaProduce.java:27)
at org.wso2.carbon.connector.core.AbstractConnector.mediate(AbstractConnector.java:32)
at org.apache.synapse.mediators.ext.ClassMediator.mediate(ClassMediator.java:78)
at org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:77)
at org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:47)
at org.apache.synapse.mediators.template.TemplateMediator.mediate(TemplateMediator.java:77)
at org.apache.synapse.mediators.template.InvokeMediator.mediate(InvokeMediator.java:129)
at org.apache.synapse.mediators.template.InvokeMediator.mediate(InvokeMediator.java:78)
at org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:77)
at org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:47)
at org.apache.synapse.mediators.base.SequenceMediator.mediate(SequenceMediator.java:131)
at org.apache.synapse.core.axis2.ProxyServiceMessageReceiver.receive(ProxyServiceMessageReceiver.java:166)
at org.apache.axis2.engine.AxisEngine.receive(AxisEngine.java:180)
at org.apache.synapse.transport.passthru.ServerWorker.processNonEntityEnclosingRESTHandler(ServerWorker.java:344)
at org.apache.synapse.transport.passthru.ServerWorker.processEntityEnclosingRequest(ServerWorker.java:385)
at org.apache.synapse.transport.passthru.ServerWorker.run(ServerWorker.java:183)
at org.apache.axis2.transport.base.threads.NativeWorkerPool$1.run(NativeWorkerPool.java:172)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.BindException: Cannot assign requested address
at sun.nio.ch.Net.connect0(Native Method)
at sun.nio.ch.Net.connect(Net.java:465)
at sun.nio.ch.Net.connect(Net.java:457)
at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
at kafka.producer.SyncProducer.connect(SyncProducer.scala:141)
at kafka.producer.SyncProducer.getOrMakeConnection(SyncProducer.scala:156)
at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:68)
at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:53)","Ubuntu 14, Java 6",junrao,kathees,Rasmeet Devji,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,86400,86400,,0%,86400,86400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jan 26 05:59:35 UTC 2015,,,,,,,,,,"0|i20z07:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"10/Oct/14 00:54;junrao;You may want to see if this is related to what's described in the following article.

http://javarevisited.blogspot.com/2014/02/fixing-javanetbindexception-cannot-assign-requested-address-JVMbind.html;;;","10/Oct/14 15:58;kathees;Thanks for your quick response.
I changed to 127.0.0.1 IP address for localhost  As said  in the above link. Still I am getting same exception. Could you please share  kafka server.properties file or give a solution to solve this problem.

kafka.common.KafkaException: fetching topic metadata for topics [Set(test1)] from broker [ArrayBuffer(id:0,host:127.0.0.1,port:9092)] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:67)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.async.DefaultEventHandler$$anonfun$handle$2.apply$mcV$sp(DefaultEventHandler.scala:78)
	at kafka.utils.Utils$.swallow(Utils.scala:167)
	at kafka.utils.Logging$class.swallowError(Logging.scala:106)
	at kafka.utils.Utils$.swallowError(Utils.scala:46)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:78)
	at kafka.producer.Producer.send(Producer.scala:76)
	at kafka.javaapi.producer.Producer.send(Producer.scala:33)
	at org.wso2.carbon.connector.KafkaProduce.send(KafkaProduce.java:76)
	at org.wso2.carbon.connector.KafkaProduce.connect(KafkaProduce.java:27)
	at org.wso2.carbon.connector.core.AbstractConnector.mediate(AbstractConnector.java:32)
	at org.apache.synapse.mediators.ext.ClassMediator.mediate(ClassMediator.java:78)
	at org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:77)
	at org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:47)
	at org.apache.synapse.mediators.template.TemplateMediator.mediate(TemplateMediator.java:77)
	at org.apache.synapse.mediators.template.InvokeMediator.mediate(InvokeMediator.java:129)
	at org.apache.synapse.mediators.template.InvokeMediator.mediate(InvokeMediator.java:78)
	at org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:77)
	at org.apache.synapse.mediators.AbstractListMediator.mediate(AbstractListMediator.java:47)
	at org.apache.synapse.mediators.base.SequenceMediator.mediate(SequenceMediator.java:131)
	at org.apache.synapse.core.axis2.ProxyServiceMessageReceiver.receive(ProxyServiceMessageReceiver.java:166)
	at org.apache.axis2.engine.AxisEngine.receive(AxisEngine.java:180)
	at org.apache.synapse.transport.passthru.ServerWorker.processNonEntityEnclosingRESTHandler(ServerWorker.java:344)
	at org.apache.synapse.transport.passthru.ServerWorker.processEntityEnclosingRequest(ServerWorker.java:385)
	at org.apache.synapse.transport.passthru.ServerWorker.run(ServerWorker.java:183)
	at org.apache.axis2.transport.base.threads.NativeWorkerPool$1.run(NativeWorkerPool.java:172)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.BindException: Cannot assign requested address
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.producer.SyncProducer.connect(SyncProducer.scala:141)
	at kafka.producer.SyncProducer.getOrMakeConnection(SyncProducer.scala:156)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:68)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:53)
;;;","23/Dec/14 00:37;Rasmeet Devji;Faced the same issue with Kafka 811, Java 6 on CentOS release 5.8 (Final)

Was able to resolve it by not opening too many connections to Kafka server.

As this link http://stackoverflow.com/questions/6145108/problem-running-into-java-net-bindexception-cannot-assign-requested-address  mentions – 
By default, Linux picks dynamically assigned ports from the range 32768..61000. The others are available for static assignment, if you bind to a specific port number. The range can be changed if you want more of the ports to be available for dynamic assignment, but just be careful that you do not include ports that are used for specific services that you need (e.g. 6000 for X11). Also you should not allow ports < 1024 to be dynamically assigned since they are privileged.

What you are most likely doing is creating a producer instance for every message you send. Instead you should have a limited number of producers or may be a pool of producers for your tests. ;;;","26/Jan/15 13:59;kathees;Thanks Rasmeet. The issue is resolved.

Thanks,
Kathees;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
retry.backoff.ms ignored by Producer,KAFKA-2868,12914864,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,junrao,nbordier,nbordier,20/Nov/15 22:24,12/May/16 18:36,22/Mar/23 15:10,12/May/16 18:36,0.8.2.1,,,,,,,,,,,,,producer ,,,,0,,,,,,"In our test, the Producer config parameter is defined as :
retry.backoff.ms = 10000

During kafka partition reassignement, the producer log NOT_LEADER_FOR_PARTITION  errors not every 10s (as defined in retry.backoff.ms) but very quickly (every 100ms maximum) :

[2015-11-17 11:53:30,002] WARN Got error produce response with correlation id 23080 on topic-partition raw-9, retrying (99 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender:257)
[2015-11-17 11:53:30,037] WARN Got error produce response with correlation id 23081 on topic-partition raw-9, retrying (98 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender:257)
[2015-11-17 11:53:30,260] WARN Got error produce response with correlation id 23083 on topic-partition raw-9, retrying (97 attempts left). Error: NOT_LEADER_FOR_PARTITION (org.apache.kafka.clients.producer.internals.Sender:257)

In our test, the retry.backoff.ms parameter is ignored by Producer.

We need to configure this parameter to avoid errors (ie : ""retrying (0 attempts left)"" like during a long time partition reassignement).

Thanks,
","Host : Ubuntu 14.04 LTS x86_64 (3.16.0-53-generic)
Container LXC : Centos 6",nbordier,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2138,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu May 12 10:36:43 UTC 2016,,,,,,,,,,"0|i2oph3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"12/May/16 18:36;omkreddy;This was fixed in KAFKA-2138;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
describe group IllegalArgumentException for kafka-consumer-groups,KAFKA-3231,12938551,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Duplicate,nehanarkhede,curtissallen,curtissallen,12/Feb/16 00:25,12/Feb/16 01:48,22/Mar/23 15:10,12/Feb/16 01:48,0.9.0.0,,,,,,,,,,,,,consumer,,,,0,,,,,,"The kafka-consumer-groups tool doesn't seem to work when describing new consumer groups. 

Listing groups work
{code}
$ ./bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server 127.0.0.1:9092 --list
testgroup
{code}

Describing throws an exception
{code}
$ ./kafka-consumer-groups.sh --new-consumer --bootstrap-server 127.0.0.1:9092 --describe --group testgroup
Error while executing consumer group command Error reading field 'user_data': java.lang.IllegalArgumentException
org.apache.kafka.common.protocol.types.SchemaException: Error reading field 'user_data': java.lang.IllegalArgumentException
	at org.apache.kafka.common.protocol.types.Schema.read(Schema.java:71)
	at org.apache.kafka.clients.consumer.internals.ConsumerProtocol.deserializeAssignment(ConsumerProtocol.java:109)
	at kafka.admin.AdminClient$$anonfun$describeConsumerGroup$1.apply(AdminClient.scala:165)
	at kafka.admin.AdminClient$$anonfun$describeConsumerGroup$1.apply(AdminClient.scala:164)
	at scala.collection.immutable.List.map(List.scala:273)
	at kafka.admin.AdminClient.describeConsumerGroup(AdminClient.scala:164)
	at kafka.admin.ConsumerGroupCommand$KafkaConsumerGroupService.describeGroup(ConsumerGroupCommand.scala:314)
	at kafka.admin.ConsumerGroupCommand$ConsumerGroupService$class.describe(ConsumerGroupCommand.scala:84)
	at kafka.admin.ConsumerGroupCommand$KafkaConsumerGroupService.describe(ConsumerGroupCommand.scala:302)
	at kafka.admin.ConsumerGroupCommand$.main(ConsumerGroupCommand.scala:63)
	at kafka.admin.ConsumerGroupCommand.main(ConsumerGroupCommand.scala)
{code}",,curtissallen,ijuma,zhangzs,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Feb 11 17:48:47 UTC 2016,,,,,,,,,,"0|i2sq9r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"12/Feb/16 00:38;ijuma;Thanks for the report. Which client did you use to commit the offsets for `testgroup`?;;;","12/Feb/16 00:45;curtissallen;Using https://github.com/Shopify/sarama via https://github.com/bsm/sarama-cluster

Using a simple command line client (https://github.com/bsm/sarama-cluster/blob/master/cmd/sarama-cluster-cli/main.go), the offsets seem to be persisted because I can the following messages in the kafka log

{code}
[2016-02-11 08:34:53,771] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-02-11 08:34:53,771] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[2016-02-11 08:34:53,778] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,4] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
{code}


Started the client using 
{code}
go run cmd/sarama-cluster-cli/main.go -brokers=127.0.0.1:9092 -group=testgroup -offset=oldest -topics=test -verbose=true
{code};;;","12/Feb/16 00:52;ijuma;Thanks. That client is possibly doing something unexpected by the tool. Is there any chance that you could use kafka-consumer-groups from trunk? It includes a fix for KAFKA-2695 that was affecting offsets committed by librdkafka.;;;","12/Feb/16 01:36;curtissallen;Thanks [~ijuma] ran kafka-consumer-groups from trunk and it worked! 

#2695 must have been in. 
;;;","12/Feb/16 01:48;ijuma;Thanks for checking [~curtissallen].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New consumer doesn't check magic version,KAFKA-2523,12862126,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Duplicate,,jkreps,jkreps,07/Sep/15 07:17,10/Sep/15 03:13,22/Mar/23 15:10,10/Sep/15 03:13,,,,,,,,,,,,,,,,,,0,,,,,,"The new consumer should be checking that messages it reads are in the format it expects (and give a sane error message otherwise) rather than just randomly reading other formats and running out of memory or getting cryptic errors. This should be a one-line fix.

It is important if we're thinking of changing the message format since you need the proper check in the versions BEFORE the version where you make the change so sane errors occur when the change eventually does happen.",,becket_qin,jkreps,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2512,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Sep 07 16:26:53 UTC 2015,,,,,,,,,,"0|i2ju9b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"08/Sep/15 00:26;becket_qin;[~jkreps], I have created KAFKA-2512 to add version check on both broker and clients. I have a patch ready and it seems not a big change to have the version check added cross board. Should we close this ticket as a duplicate? Or do you want to take the new consumer part out separately in this ticket? ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ISR reported by TopicMetadataResponse most of the time doesn't match the Zookeeper information (and the truth),KAFKA-1557,12729791,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,nehanarkhede,Wallrat2000,Wallrat2000,26/Jul/14 01:58,26/Jul/14 03:27,22/Mar/23 15:10,26/Jul/14 03:26,0.8.0,0.8.1,,,,,0.8.1.1,0.8.2.0,,,,,,controller,core,replication,,0,newbie++,,,,,"TL;DR - after a topic is created, and at least one broker in the ISR is restarted, the ISR reported by the TopicMetadataResponse is incorrect.

Specific steps to repro:
- Download 0.8.1 Kafka
- Copy server.properties twice into server1.properties and server2.properties (attached) - basically just ports and log paths changed to allow brokers to co-exist
- Start zookeper using ""sh bin/zookeeper-server-start.sh config/zookeper.properties""
- Start broker1: 'sh bin/kafka-server-start.sh config/server1.properties""
- Start broker2: 'sh bin/kafka-server-start.sh config/server2.properties""
- Create a new topic: ""sh bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic test --replication-factor 2 --partitions 3""
- Examine topic state: ""sh bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test"" - note that all ISRs are of length 2
- Run the attached Scala code that uses TopicMetadataRequest to exmaine topic state. Observer that all ISRs are of length 2 and match the information output by the script
- Shut down broker2 (simply hit Cntrl-C in the terminal), wait 5-10 seconds
- Restart broker 2 using the original command
- Check the status of the topic again. Observe that the leader for all topics is 0 (as expected), and all ISRs contain both brokers (as expected)
- Run the attached Scala snippet again. 

EXPECTED:
- The ISR information are of length 2

ACTUAL:
- ALL ISRs contain just broker 0

NOTE: depending on how long broker 2 was down, sometimes some ISRs will contain the full list, but shutting it down for 15+ secs seem to always yield consistent repro


Basically it appears that brokers have incorrect ISR information for the metadata cache.
Our production servers exhibit the same problem - after a topic gets created everything looks fine, but as brokers get restarted, ISR reported by the brokers is wrong, whereas the one in ZK appears to report the truth (it shrinks as brokers get shut down and grows back up after they get restarted)

I'm not sure if this has wider impact on the functioning of the cluster - bad metadata information is bad - but so far there has been no evidence of that
","OSX 10.9.3, Linux Scientific 6.5
It actually doesn't seem to matter and appears to be OS-agnostic",christian.h.mikkelsen@gmail.com,jjkoshy,Wallrat2000,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1367,,,,,,,,,,,,,,,,"26/Jul/14 02:02;Wallrat2000;BrokenKafkaLink.scala;https://issues.apache.org/jira/secure/attachment/12657869/BrokenKafkaLink.scala","26/Jul/14 01:58;Wallrat2000;server1.properties;https://issues.apache.org/jira/secure/attachment/12657867/server1.properties","26/Jul/14 01:58;Wallrat2000;server2.properties;https://issues.apache.org/jira/secure/attachment/12657868/server2.properties",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,407864,,,Fri Jul 25 18:57:01 UTC 2014,,,,,,,,,,"0|i1y6kv:",407873,,,,,,,,,,,,,,,,,,,,"26/Jul/14 02:19;jjkoshy;This seems related to KAFKA-1367 [~Wallrat2000] can you confirm?;;;","26/Jul/14 02:34;Wallrat2000;Thanks [~jjkoshy], yes, this does seem to be the same issue. 
A quick follow up before we can close this as a dup:
- Is there any impact on the cluster health? After all, internal broker metadata is not correct
- Is there an ETA on getting this fixed?;;;","26/Jul/14 02:57;jjkoshy;For the first question: I don't think cluster health is at risk here since the ISR information is important for:
*  leadership decisions
* ack'ing producers when required.acks = -1
Both these use-cases don't rely directly on the metadata cache.

For the second question: given that this is not critical enough for a hot-fix and shouldn't be too difficult to fix it would be a good opportunity for someone new to the codebase to take a stab at it - that's why we label jiras with newbie/newbie++ tags.

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Broker allows startup with incompatible listen port/inter-broker protocol settings,KAFKA-2876,12915587,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,ijuma,hachikuji,hachikuji,24/Nov/15 05:18,25/Feb/16 15:23,22/Mar/23 15:10,25/Feb/16 15:23,,,,,,,,,,,,,,,,,,0,,,,,,"Currently the broker allows startup with an incompatible inter-broker security setting. For example, if the only listening port is enabled for SSL and no ""security.inter.broker.protocol"" is set, then the broker will still attempt to use the default PLAINTEXT protocol. When the broker then attempts to send LeaderAndIsr and other requests over plain text to itself (which can happen if it becomes the controller), it will silently catch the error since it cannot find the corresponding endpoint. It would be better to raise a configuration error in this case since there's no way that the broker can work correctly when it becomes controller.",,hachikuji,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3194,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,2015-11-23 21:18:04.0,,,,,,,,,,"0|i2otxj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
reassignment tool needs to parse and validate the json,KAFKA-2218,12832360,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Duplicate,,joestein,joestein,23/May/15 23:52,17/Aug/17 20:49,22/Mar/23 15:10,17/Aug/17 20:49,,,,,,,,,,,,,,,,,,0,,,,,,"Ran into a production issue with the broker.id being set to a string instead of integer and the controller had nothing in the log and stayed stuck. Eventually we saw this in the log of the brokers where coming from 

	
me	11:42 AM
[2015-05-23 15:41:05,863] 67396362 [ZkClient-EventThread-14-****ERROR org.I0Itec.zkclient.ZkEventThread - Error handling event ZkEvent[Data of /admin/reassign_partitions changed sent to kafka.controller.PartitionsReassignedListener@78c6aab8]
java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer
 at scala.runtime.BoxesRunTime.unboxToInt(Unknown Source)
 at kafka.controller.KafkaController$$anonfun$4.apply(KafkaController.scala:579)

we then had to delete the znode from zookeeper (admin/reassign_partition) and then fix the json and try it again

",,jjirsa,joestein,leoxlin,omkreddy,umesh9794@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-4914,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Aug 17 12:49:34 UTC 2017,,,,,,,,,,"0|i2f51z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"14/Jun/15 13:45;omkreddy;[~charmalloc] I am not able to reproduce the issue with below json. Can you confirm affected kafka version? 

JSON :
{""partitions"":
[
{""topic"": ""EVENT"", ""partition"": 0, ""replicas"": [a] }
],
""version"":1
}


Output:
Partitions reassignment failed due to Partition reassignment data file /tmp/reassignment.json is empty
kafka.common.AdminCommandFailedException: Partition reassignment data file /tmp/reassignment.json is empty
;;;","17/Aug/17 20:49;omkreddy; PR is available for KAFKA-4914.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
controller logs exceptions during ZK session expiration,KAFKA-1272,12695903,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,junrao,junrao,junrao,19/Feb/14 10:34,19/Feb/14 10:40,22/Mar/23 15:10,19/Feb/14 10:40,0.8.1,,,,,,,,,,,,,,,,,0,,,,,,"Saw the following issues when there is ZK session expiration in the controller.

1. 
 ERROR Error handling event ZkEvent[Children of
/admin/delete_topics changed sent to
kafka.controller.PartitionStateMachine$DeleteTopicsListener@39abdac9]
(org.I0Itec.zkclient.ZkEventThread)
java.lang.NullPointerException
at
scala.collection.JavaConversions$JListWrapper.iterator(JavaConversions.scala:524)
at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
at
scala.collection.JavaConversions$JListWrapper.foreach(JavaConversions.scala:521)
at
scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:176)
at
scala.collection.JavaConversions$JListWrapper.foldLeft(JavaConversions.scala:521)
at
scala.collection.TraversableOnce$class.$div$colon(TraversableOnce.scala:139)
at
scala.collection.JavaConversions$JListWrapper.$div$colon(JavaConversions.scala:521)
at scala.collection.generic.Addable$class.$plus$plus(Addable.scala:54)
at scala.collection.immutable.Set$EmptySet$.$plus$plus(Set.scala:47)
at scala.collection.TraversableOnce$class.toSet(TraversableOnce.scala:436)
at
scala.collection.JavaConversions$JListWrapper.toSet(JavaConversions.scala:521)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener$$anonfun$handleChildChange$2.apply$mcV$sp(PartitionStateMachine.scala:448)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener$$anonfun$handleChildChange$2.apply(PartitionStateMachine.scala:445)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener$$anonfun$handleChildChange$2.apply(PartitionStateMachine.scala:445)
at kafka.utils.Utils$.inLock(Utils.scala:538)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener.handleChildChange(PartitionStateMachine.scala:445)
at org.I0Itec.zkclient.ZkClient$7.run(ZkClient.java:570)
at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71) 

2. IllegalStateException due to ""Kafka scheduler has not been started"".",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1271,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,374384,,,2014-02-19 02:34:12.0,,,,,,,,,,"0|i1silr:",374684,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
controller logs exceptions during ZK session expiration,KAFKA-1270,12695900,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,junrao,junrao,junrao,19/Feb/14 10:29,04/Apr/14 00:27,22/Mar/23 15:10,04/Apr/14 00:27,0.8.1,,,,,,,,,,,,,,,,,0,,,,,,"Saw the following issues when there is ZK session expiration in the controller.

1. 
 ERROR Error handling event ZkEvent[Children of
/admin/delete_topics changed sent to
kafka.controller.PartitionStateMachine$DeleteTopicsListener@39abdac9]
(org.I0Itec.zkclient.ZkEventThread)
java.lang.NullPointerException
at
scala.collection.JavaConversions$JListWrapper.iterator(JavaConversions.scala:524)
at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
at
scala.collection.JavaConversions$JListWrapper.foreach(JavaConversions.scala:521)
at
scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:176)
at
scala.collection.JavaConversions$JListWrapper.foldLeft(JavaConversions.scala:521)
at
scala.collection.TraversableOnce$class.$div$colon(TraversableOnce.scala:139)
at
scala.collection.JavaConversions$JListWrapper.$div$colon(JavaConversions.scala:521)
at scala.collection.generic.Addable$class.$plus$plus(Addable.scala:54)
at scala.collection.immutable.Set$EmptySet$.$plus$plus(Set.scala:47)
at scala.collection.TraversableOnce$class.toSet(TraversableOnce.scala:436)
at
scala.collection.JavaConversions$JListWrapper.toSet(JavaConversions.scala:521)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener$$anonfun$handleChildChange$2.apply$mcV$sp(PartitionStateMachine.scala:448)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener$$anonfun$handleChildChange$2.apply(PartitionStateMachine.scala:445)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener$$anonfun$handleChildChange$2.apply(PartitionStateMachine.scala:445)
at kafka.utils.Utils$.inLock(Utils.scala:538)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener.handleChildChange(PartitionStateMachine.scala:445)
at org.I0Itec.zkclient.ZkClient$7.run(ZkClient.java:570)
at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71) 

2. IllegalStateException due to ""Kafka scheduler has not been started"".",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1271,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,374381,,,Thu Apr 03 16:27:29 UTC 2014,,,,,,,,,,"0|i1sil3:",374681,,,,,,,,,,,,,,,,,,,,"04/Apr/14 00:27;junrao;Duplicate of KAFKA-1271.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZK-based producer can throw an unexpceted exception when sending a message,KAFKA-129,12521006,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,junrao,junrao,01/Sep/11 09:36,05/Oct/11 07:05,22/Mar/23 15:10,05/Oct/11 07:05,0.7,,,,,,0.7,,,,,,,,,,,0,,,,,,"Here is a log trace when that happens.

2011/08/26 11:25:20.104 FATAL [EmbeddedConsumer] [kafka-embedded-consumer-firehoseActivity-0] [kafka] java.util.NoSuchElementException: None.getjava.util.NoSuchElementException: None.get
        at scala.None$.get(Option.scala:185)
        at scala.None$.get(Option.scala:183)
        at kafka.producer.Producer$$anonfun$3.apply(Producer.scala:115)
        at kafka.producer.Producer$$anonfun$3.apply(Producer.scala:101)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)
        at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:32)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)
        at scala.collection.mutable.WrappedArray.map(WrappedArray.scala:32)
        at kafka.producer.Producer.send(Producer.scala:101)
        at kafka.server.EmbeddedConsumer$$anonfun$startNewConsumerThreads$1$$anonfun$apply$1$$anon$1$$anonfun$run$1.apply(KafkaServerStartable.scala:136)
        at kafka.server.EmbeddedConsumer$$anonfun$startNewConsumerThreads$1$$anonfun$apply$1$$anon$1$$anonfun$run$1.apply(KafkaServerStartable.scala:134)
        at scala.collection.Iterator$class.foreach(Iterator.scala:631)
        at kafka.utils.IteratorTemplate.foreach(IteratorTemplate.scala:30)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
        at kafka.consumer.KafkaMessageStream.foreach(KafkaMessageStream.scala:29)
        at kafka.server.EmbeddedConsumer$$anonfun$startNewConsumerThreads$1$$anonfun$apply$1$$anon$1.run(KafkaServerStartable.scala:134)
        at java.lang.Thread.run(Thread.java:619)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Oct/11 05:55;nehanarkhede;KAFKA-129.patch;https://issues.apache.org/jira/secure/attachment/12497714/KAFKA-129.patch","05/Oct/11 02:05;nehanarkhede;KAFKA-129.patch;https://issues.apache.org/jira/secure/attachment/12497673/KAFKA-129.patch","04/Oct/11 07:08;nehanarkhede;KAFKA-129.patch;https://issues.apache.org/jira/secure/attachment/12497565/KAFKA-129.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,43959,,,Tue Oct 04 21:59:32 UTC 2011,,,,,,,,,,"0|i15z2n:",242982,,,,,,,,,,,,,,,,,,,,"04/Oct/11 07:08;nehanarkhede;The producer using the zookeeper software load balancer maintains a ZK cache that gets updated by the zookeeper watcher listeners. During some events like a broker bounce, the producer ZK cache can get into an inconsistent state, for a small time period. In this time period, it could end up picking a broker partition that is unavailable, to complete the send operation. 

When this happens, the ZK cache needs to be updated, and the process of picking a broker partition for the current event should be repeated. This is repeated for a configurable number of retries, defaulting to 3. Arguably, if it takes more than 1-2 retries to get consistent data from zookeeper, something is really wrong, and we should throw an exception back to the user and fail the send operation.

This patch also adds a check around the debug and trace level logging in the producer;;;","05/Oct/11 01:35;junrao;1. import collection.SortedSet is not used in Producer.

2. In ZKBrokerPatitionInfo, it seem that we need to synchronize on zkWatcherLock in getBrokerInfo, to prevent seeing inconsistent info between allBrokers and the syncProducer list in ProducerPool.

3. In ProducerTest.testSendSingleMessage, the comment says that we want to send the request to a random partition, why is the partition number changed from -1 to 0? ;;;","05/Oct/11 02:05;nehanarkhede;2. Good catch. Updated the patch to include this.
3. While I was making this change, I found a bug in the partitioning approach of the producer when broker.list option is used. Previously, it choose a random broker, and then created a produce request with -1 as the partition. This is not, however, we intend to do partitioning. We let the default partitioner pick the right broker partition from amongst all available. So we never end up with a request with -1 as the partition. That test was also written with this buggy logic. It is using the StaticPartitioner, so the broker partition is deterministically selected. I fixed the bug as well as the tests to expose the right behavior.;;;","05/Oct/11 02:43;junrao;OK, for item 3, could you change the comment accordingly?;;;","05/Oct/11 03:58;nehanarkhede;Yeah, the comment in the test didn't quite match the new behavior. Fixed it;;;","05/Oct/11 05:55;nehanarkhede;This patch fixes the comments that didn't match the expected behavior in the code;;;","05/Oct/11 05:59;junrao;+1. Thanks for the patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
producer-perf-test does not enforce manditory arguments,KAFKA-401,12598430,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,appodictic,appodictic,12/Jul/12 02:53,15/Sep/12 07:16,22/Mar/23 15:10,15/Sep/12 07:16,,,,,,,,,,,,,,,,,,0,,,,,,"This ""seems like it works"" as in runs and does not produce error.
{noformat}
 bin/kafka-producer-perf-test.sh --topic letsgo --messages 20 --message-size 10 --brokerinfo zk.connect=127.0.0.2 --show-detailed-stats --threads 1 
{noformat}
But it does not actually produce messages until you specify a batch size
--batch-size 10",,appodictic,jjkoshy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,299111,,,Fri Sep 14 23:16:10 UTC 2012,,,,,,,,,,"0|i15znz:",243078,,,,,,,,,,,,,,,,,,,,"15/Sep/12 07:16;jjkoshy;Should be covered by KAFKA-408;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove getShutdownReceive() and other kafka specific code from the RequestChannel,KAFKA-745,12630021,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,sriramsub,nehanarkhede,nehanarkhede,31/Jan/13 06:54,01/Sep/17 00:58,22/Mar/23 15:10,01/Sep/17 00:58,0.8.0,,,,,,,,,,,,,network,,,,0,,,,,,Jay's suggestion from KAFKA-736 is to get rid of getShutdownReceive() and kafka request specific code from the generic requestchannel,,nehanarkhede,omkreddy,sriramsub,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Feb/13 19:10;sriramsub;KAFKA-745-v1.patch;https://issues.apache.org/jira/secure/attachment/12568209/KAFKA-745-v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,310517,,,Thu Aug 31 16:58:49 UTC 2017,,,,,,,,,,"0|i1hl7r:",310862,,,,,,,,,,,,,,,,,,,,"01/Feb/13 00:28;sriramsub;This bug also tracks decoupling requestObj from RequestChannel if possible.;;;","06/Feb/13 04:58;sriramsub;I would like to take this and complete it. Let me know if you want to work on it and I will reassign.;;;","06/Feb/13 14:56;sriramsub;Took a look at this. The main issue is that we seem to be tracking a bunch of metrics per request type and they all end up being tracked in the network layer. This has really made the network layer ugly. These metrics are really of two types Network level metrics and Request level metrics. 

1. Metrics that can be tracked at the network level are those that do not have any large difference based on the request type. For example, queueTime is a metric that is supposed to be the amount of time a request spends in the request queue. Tracking this for each request type does not really make sense. This is a network level property and should be tracked at that level.

2. Metrics that can be tracked at the request level have a large difference based on the request type. For example, local time is the amount of time the KafkaApi handle method takes to complete. This largely depends on the request type and should be tracked at the request level.

To summarize, with the decoupling specified above we have the following metrics at the two levels

Network metrics  
-----------------------
 // time a request spent in a request queue
  val queueTimeHist = newHistogram(name + ""-QueueTimeMs"")

// time to send the response to the requester from the response queue
  val responseSendTimeHist = newHistogram(name + ""-ResponseSendTimeMs"")

// total time taken for the request to be served 
  val totalTimeHist = newHistogram(name + ""-TotalTimeMs"")
 
Request metrics
------------------------

  // request rate by type
  val requestRate = newMeter(name + ""-RequestsPerSec"",  ""requests"", TimeUnit.SECONDS)   

  // time a request takes to be processed at the local broker
  val localTimeHist = newHistogram(name + ""-LocalTimeMs"")

  // time a request takes to wait on remote brokers (only relevant to fetch and produce requests)
  val remoteTimeHist = newHistogram(name + ""-RemoteTimeMs"")
   
With the separation specified above, any request can be defined as

queueTime + localTime + remoteTime + responseSendTime = totalTime

We can totally remove any kafkaapi dependency in the network layer with the proposed separation.;;;","06/Feb/13 19:10;sriramsub;This is a first version.

1. Removes all the metric stuff,requestObj etc from Request.
2.Adds Network metrics to track network level parameters
3. Any form of delayed request now uses a trimmed version of the Request object. 
4. Added Request metrics to the kafka layer to track kafka specific parameters

TODO - Need to add logging.
          - Some more cleanup

- We will not get all the different times for a given request as part of one log statement anymore. I think this is fine for the ability to maintain clean code.
- W.r.t the logging in the network layer, we would get info from the Request object (need to add a toString here to ignore the buffer) and nothing from the actual request. I think this is fine since knowing the request type is not useful at this layer based on the explanation above.;;;","01/Sep/17 00:58;omkreddy;These changes were done in newer Kafka versions.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Significant difference in time taken to produce messages between 1, -1 for request-num-acks",KAFKA-535,12609464,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,,jfung,jfung,28/Sep/12 06:31,21/Mar/14 05:44,22/Mar/23 15:10,21/Mar/14 05:44,,,,,,,,,,,,,,,,,,0,replication-testing,,,,,"There is a significant difference in time taken for ProducerPerformance to produce messages between 1 & -1 for request-num-acks.

The following are the log4j messages from ProducerPerformance with consequent calls from the system test script.

** Please note the time elapsed in consequent timestamps of calling ProducerPerformance.

The overall test scenarios:
1. This test is set up to have 1 zookeeper, 1 broker cluster of 6 nodes (distributed systems, non-local), replica factor 6, 1 topic, 1 partition
2. The script will wait for ProducerPerformance to complete sending all messages (500 each call in this case) before calling the producer again. 


1. request-num-acks = -1. The rate is about 10 messages per second. The timestamp indicates that it takes 60+ seconds for ProducerPerformance to completely sending 500 messages and exit by itself.

2012-09-26 21:20:56,102 - INFO - #### [producer thread] status of stopBackgroundProducer : [False] => producing [500] messages with starting message id : [0] (kafka_system_test_utils)
2012-09-26 21:20:56,102 - DEBUG - executing command: [ssh host0996.mydomain 'JAVA_HOME=/export/apps/jdk/JDK-1_6_0_21 JMX_PORT=9997 /kafka_pst_wip/bin/kafka-run-class.sh kafka.perf.ProducerPerformance --broker-list host0997.mydomain:9091,host0998.mydomain:9092,host0999.mydomain:9093,host1000.mydomain:9094,host1001.mydomain:9095,host1002.mydomain:9096 --initial-message-id 0 --messages 500 --topic test_1 --threads 5 --compression-codec 0 --message-size 500 --request-num-acks -1   >> /kafka_pst_wip/system_test/replication_testsuite/testcase_0001/logs/producer_performance-7/producer_performance.log  & echo pid:$! > /kafka_pst_wip/system_test/replication_testsuite/testcase_0001/logs/producer_performance-7/entity_7_pid'] (kafka_system_test_utils)
. . .
2012-09-26 21:22:00,162 - INFO - #### [producer thread] status of stopBackgroundProducer : [False] => producing [500] messages with starting message id : [500] (kafka_system_test_utils)
2012-09-26 21:22:00,162 - DEBUG - executing command: [ssh host0996.mydomain 'JAVA_HOME=/export/apps/jdk/JDK-1_6_0_21 JMX_PORT=9997 /kafka_pst_wip/bin/kafka-run-class.sh kafka.perf.ProducerPerformance --broker-list host0997.mydomain:9091,host0998.mydomain:9092,host0999.mydomain:9093,host1000.mydomain:9094,host1001.mydomain:9095,host1002.mydomain:9096 --initial-message-id 500 --messages 500 --topic test_1 --threads 5 --compression-codec 0 --message-size 500 --request-num-acks -1   >> /kafka_pst_wip/system_test/replication_testsuite/testcase_0001/logs/producer_performance-7/producer_performance.log  & echo pid:$! > /kafka_pst_wip/system_test/replication_testsuite/testcase_0001/logs/producer_performance-7/entity_7_pid'] (kafka_system_test_utils)


2. request-num-acks = 1. The rate is about 150 ~ 200 messages per second. The timestamp indicates that it takes < 3 seconds for ProducerPerformance to completely sending 500 messages.

2012-09-26 21:29:23,698 - INFO - #### [producer thread] status of stopBackgroundProducer : [False] => producing [500] messages with starting message id : [500] (kafka_system_test_utils)
2012-09-26 21:29:23,698 - DEBUG - executing command: [ssh host0996.mydomain 'JAVA_HOME=/export/apps/jdk/JDK-1_6_0_21 JMX_PORT=9997 /kafka_pst_wip/bin/kafka-run-class.sh kafka.perf.ProducerPerformance --broker-list host0997.mydomain:9091,host0998.mydomain:9092,host0999.mydomain:9093,host1000.mydomain:9094,host1001.mydomain:9095,host1002.mydomain:9096 --initial-message-id 500 --messages 500 --topic test_1 --threads 5 --compression-codec 0 --message-size 500 --request-num-acks 1   >> /kafka_pst_wip/system_test/replication_testsuite/testcase_0002/logs/producer_performance-7/producer_performance.log  & echo pid:$! > /kafka_pst_wip/system_test/replication_testsuite/testcase_0002/logs/producer_performance-7/entity_7_pid'] (kafka_system_test_utils)
. . .
2012-09-26 21:29:26,576 - INFO - #### [producer thread] status of stopBackgroundProducer : [False] => producing [500] messages with starting message id : [1000] (kafka_system_test_utils)
2012-09-26 21:29:26,577 - DEBUG - executing command: [ssh host0996.mydomain 'JAVA_HOME=/export/apps/jdk/JDK-1_6_0_21 JMX_PORT=9997 /kafka_pst_wip/bin/kafka-run-class.sh kafka.perf.ProducerPerformance --broker-list host0997.mydomain:9091,host0998.mydomain:9092,host0999.mydomain:9093,host1000.mydomain:9094,host1001.mydomain:9095,host1002.mydomain:9096 --initial-message-id 1000 --messages 500 --topic test_1 --threads 5 --compression-codec 0 --message-size 500 --request-num-acks 1   >> /kafka_pst_wip/system_test/replication_testsuite/testcase_0002/logs/producer_performance-7/producer_performance.log  & echo pid:$! > /kafka_pst_wip/system_test/replication_testsuite/testcase_0002/logs/producer_performance-7/entity_7_pid'] (kafka_system_test_utils)
",,jfung,jkreps,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,241636,,,Thu Mar 20 21:44:01 UTC 2014,,,,,,,,,,"0|i029gv:",11135,,,,,,,,,,,,,,,,,,,,"21/Mar/14 05:44;jkreps;I don't think this is a bug and is in any way fixed in the new producer.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix recursion in ZkSecurityMigrator,KAFKA-3069,12928029,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,fpj,fpj,fpj,06/Jan/16 23:03,13/Jan/16 01:49,22/Mar/23 15:10,13/Jan/16 01:49,0.9.0.0,,,,,,0.10.0.0,,,,,,,security,,,,0,,,,,,"The zk migrator tool recursively sets ACLs starting with the root, which we initially assumed was either the root of a dedicated ensemble or a chroot. However, there are at least two reasons for not doing it this way. First, shared ensembles might not really follow the practice of separating applications into branches, essentially creating a chroot for each. Second, there are paths we don't want to secure, like the ConsumersPath.

To fix this, we simply need to set the root ACL separately and start the recursion on each of the persistent paths to secure.  ",,ewencp,fpj,githubbot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jan 12 17:49:22 UTC 2016,,,,,,,,,,"0|i2qxnz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"07/Jan/16 01:14;githubbot;GitHub user fpj opened a pull request:

    https://github.com/apache/kafka/pull/736

    KAFKA-3069: Fix recursion in ZkSecurityMigrator

    I'm also fixing a bug in the testChroot test case.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/fpj/kafka KAFKA-3069

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/736.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #736
    
----
commit 81028a160f3653b53331f71c4ee988b4945a0a0f
Author: Flavio Junqueira <fpj@apache.org>
Date:   2016-01-06T17:11:46Z

    KAFKA-3069: Fixed issue in the migrator tool and bug in the testChroot case.

----
;;;","13/Jan/16 01:49;ewencp;Issue resolved by pull request 736
[https://github.com/apache/kafka/pull/736];;;","13/Jan/16 01:49;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/736
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bad zookeeper host causes broker to shutdown uncleanly and stall producers,KAFKA-2864,12914649,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Duplicate,,mahdouch,mahdouch,20/Nov/15 06:53,21/Nov/17 22:57,22/Mar/23 15:10,21/Nov/17 22:57,0.8.2.1,,,,,,,,,,,,,zkclient,,,,1,,,,,,"We are using kafka 0.8.2.1 and we noticed that kafka/zookeeper-client were not able to gracefully handle a non existing zookeeper instance. This caused one of our brokers to get stuck during a self-inflicted shutdown and that seemed to impact the partitions for which the broker was a leader even though we had two other replicas.

Here is a timeline of what happened (shortened for brevity, I'll attach log snippets):

We have a 7 node zookeeper cluster. Two of our nodes were decommissioned and their dns records removed (zookeeper15 and zookeeper16). The decommissioning happened about two weeks earlier. We noticed the following in the logs

- Opening socket connection to server ip-10-0-0-1.ec2.internal/10.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
- Client session timed out, have not heard from server in 858ms for sessionid 0x1250c5c0f1f5001c, closing socket connection and attempting reconnect
- Opening socket connection to server ip-10.0.0.2.ec2.internal/10.0.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
- zookeeper state changed (Disconnected)
- Client session timed out, have not heard from server in 2677ms for sessionid 0x1250c5c0f1f5001c, closing socket connection and attempting reconnect
- Opening socket connection to server ip-10.0.0.3.ec2.internal/10.0.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
- Socket connection established to ip-10.0.0.3.ec2.internal/10.0.0.3:2181, initiating session
- zookeeper state changed (Expired)
- Initiating client connection, connectString=zookeeper21.example.com:2181,zookeeper19.example.com:2181,zookeeper22.example.com:2181,zookeeper18.example.com:2181,zookeeper20.example.com:2181,zookeeper16.example.com:2181,zookeeper15.example.com:2181/foo/kafka/central sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@3bbc39f8
- Unable to reconnect to ZooKeeper service, session 0x1250c5c0f1f5001c has expired, closing socket connection
- Unable to re-establish connection. Notifying consumer of the following exception:
org.I0Itec.zkclient.exception.ZkException: Unable to connect to zookeeper21.example.com:2181,zookeeper19.example.com:2181,zookeeper22.example.com:2181,zookeeper18.example.com:2181,zookeeper20.example.com:2181,zookeeper16.example.com:2181,zookeeper15.example.com:2181/foo/kafka/central
        at org.I0Itec.zkclient.ZkConnection.connect(ZkConnection.java:69)
        at org.I0Itec.zkclient.ZkClient.reconnect(ZkClient.java:1176)
        at org.I0Itec.zkclient.ZkClient.processStateChanged(ZkClient.java:649)
        at org.I0Itec.zkclient.ZkClient.process(ZkClient.java:560)
        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
Caused by: java.net.UnknownHostException: zookeeper16.example.com: unknown error
        at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
        at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928)
        at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323)
        at java.net.InetAddress.getAllByName0(InetAddress.java:1276)
        at java.net.InetAddress.getAllByName(InetAddress.java:1192)
        at java.net.InetAddress.getAllByName(InetAddress.java:1126)
        at org.apache.zookeeper.client.StaticHostProvider.<init>(StaticHostProvider.java:61)
        at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:445)
        at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:380)
        at org.I0Itec.zkclient.ZkConnection.connect(ZkConnection.java:67)
        ... 5 more


That seems to have caused the following:
 [main-EventThread] [org.apache.zookeeper.ClientCnxn     ]: EventThread shut down

Which in turn caused kafka to shut itself down
[Thread-2] [kafka.server.KafkaServer            ]: [Kafka Server 13], shutting down
[Thread-2] [kafka.server.KafkaServer            ]: [Kafka Server 13], Starting controlled shutdown

However, the shutdown didn't go as expected apparently due to an NPE in the zk client

2015-11-12T12:03:40.101Z WARN  [Thread-2                           ] [kafka.utils.Utils$                  ]:
java.lang.NullPointerException
        at org.I0Itec.zkclient.ZkConnection.readData(ZkConnection.java:117)
        at org.I0Itec.zkclient.ZkClient$10.call(ZkClient.java:992)
        at org.I0Itec.zkclient.ZkClient$10.call(ZkClient.java:988)
        at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:883)
        at org.I0Itec.zkclient.ZkClient.readData(ZkClient.java:988)
        at org.I0Itec.zkclient.ZkClient.readData(ZkClient.java:983)
        at kafka.utils.ZkUtils$.readDataMaybeNull(ZkUtils.scala:450)
        at kafka.utils.ZkUtils$.getController(ZkUtils.scala:65)
        at kafka.server.KafkaServer.kafka$server$KafkaServer$$controlledShutdown(KafkaServer.scala:194)
        at kafka.server.KafkaServer$$anonfun$shutdown$1.apply$mcV$sp(KafkaServer.scala:269)
        at kafka.utils.Utils$.swallow(Utils.scala:172)
        at kafka.utils.Logging$class.swallowWarn(Logging.scala:92)
        at kafka.utils.Utils$.swallowWarn(Utils.scala:45)
        at kafka.utils.Logging$class.swallow(Logging.scala:94)
        at kafka.utils.Utils$.swallow(Utils.scala:45)
        at kafka.server.KafkaServer.shutdown(KafkaServer.scala:269)
        at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:42)
        at kafka.Kafka$$anon$1.run(Kafka.scala:42)
2015-11-12T12:03:40.106Z INFO  [Thread-2                           ] [kafka.network.SocketServer          ]: [Socket Server on Broker 13], Shutting down

The kafka process continued running after this point. This is confirmed by the continuous rolling of logs
[ReplicaFetcherThread-3-9           ] [kafka.log.Log                       ]: Rolled new log segment for 'topic-a-1' in 0 ms.
[ReplicaFetcherThread-0-12          ] [kafka.log.Log                       ]: Rolled new log segment for 'topic-b-4' in 0 ms.

etc..

At this point, that broker was in a half-dead state. Our clients were still timing out enqueuing messages to it. The under-replicated partition count on the other brokers was stuck at a positive, constant value and did not make any progress. We also noticed that the jmx connector threads weren't responding, which is how we found out that the process was in a bad shape. This happened for about 40mn till we killed the process and restarted it. Things have recovered after the restart.",,ijuma,jinxing6042@126.com,mahdouch,Xineohp,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-5473,,,,,,,,,,,,,,,,"20/Nov/15 06:56;mahdouch;kafka.log;https://issues.apache.org/jira/secure/attachment/12773364/kafka.log",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Nov 21 14:57:15 UTC 2017,,,,,,,,,,"0|i2oo5j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Nov/17 22:57;ijuma;Duplicate of KAFKA-5473.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow users to cleanup internal data,KAFKA-3185,12935768,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,mjsax,guozhang,guozhang,02/Feb/16 06:25,28/Jul/16 07:11,22/Mar/23 15:10,28/Jul/16 05:12,,,,,,,0.10.0.1,,,,,,,streams,,,,1,user-experience,,,,,"Currently the internal data is managed completely by Kafka Streams framework and users cannot clean them up actively. This results in a bad out-of-the-box user experience especially for running demo programs since it results internal data (changelog topics, RocksDB files, etc) that need to be cleaned manually. It will be better to add a

{code}
KafkaStreams.cleanup()
{code}

function call to clean up these internal data programmatically.",,githubbot,guozhang,hcai@pinterest.com,imandhan,kzakee,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jul 27 23:11:49 UTC 2016,,,,,,,,,,"0|i2s9cv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"03/May/16 06:21;hcai@pinterest.com;Second to this.  It's very painful for us to test our demo program.  We have to either change our application id or manually remove rocksDB or kafka log files.;;;","17/Jun/16 06:43;imandhan;[~guozhang] Do you think this is a bug a newbie(aka me) could work on? If not, could you point me to something? Thanks;;;","17/Jun/16 07:14;guozhang;I think [~mjsax] has already started working on this, but did not yet assign this ticket to himself.

There is indeed a list of newbie tickets for Kafka Streams:

https://issues.apache.org/jira/issues/?jql=project%20%3D%20KAFKA%20AND%20resolution%20%3D%20Unresolved%20AND%20component%20%3D%20streams%20AND%20labels%20in%20(newbie%2C%20%22newbie%2B%2B%22)%20ORDER%20BY%20priority%20DESC

Feel free to grab any that is not assigned yet.;;;","17/Jun/16 07:22;imandhan;Ah okay, sounds good- I'll look for something else. thank you!;;;","19/Jul/16 20:14;githubbot;GitHub user mjsax opened a pull request:

    https://github.com/apache/kafka/pull/1636

    KAFKA-3185: Allow users to cleanup internal Kafka Streams data

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/mjsax/kafka kafka-3185

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1636.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1636
    
----
commit d454d3d391c5838af0b232cd57e2f3b38ae70788
Author: Matthias J. Sax <matthias@confluent.io>
Date:   2016-06-11T12:12:42Z

    KAFKA-3185: [Streams] Added Kafka Streams cleanup client plus bash script

commit c397ad7fca6276ed1c45bb486999f59d5483b86d
Author: Matthias J. Sax <matthias@confluent.io>
Date:   2016-07-06T00:15:13Z

    minor fix: repartitioing

commit eeacd3a2f812395ead416412ccb7e5fe842543f1
Author: Matthias J. Sax <matthias@confluent.io>
Date:   2016-07-15T13:41:08Z

    moved local state store clean-up from script to library

----
;;;","28/Jul/16 05:12;guozhang;Issue resolved by pull request 1636
[https://github.com/apache/kafka/pull/1636];;;","28/Jul/16 05:12;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1636
;;;","28/Jul/16 06:35;githubbot;GitHub user mjsax opened a pull request:

    https://github.com/apache/kafka/pull/1671

    KAFKA-3185: [Streams] Added Kafka Streams Application Reset Tool

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/mjsax/kafka resetTool-0.10.0.1

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1671.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1671
    
----
commit 75e01c87a5de8a64b9d4b3baf2e0dd061e138b25
Author: Matthias J. Sax <matthias@confluent.io>
Date:   2016-06-11T12:12:42Z

    KAFKA-3185: [Streams] Added Kafka Streams Application Reset Tool
    
    cherry-picked from trunk
    
    Conflicts:
    	checkstyle/import-control.xml
    	streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java
    	streams/src/test/java/org/apache/kafka/streams/integration/utils/EmbeddedSingleNodeKafkaCluster.java

commit 1478653f08e3cfefe7f080572a41c38b3941775c
Author: Matthias J. Sax <matthias@confluent.io>
Date:   2016-07-27T22:28:28Z

    fixed cherry-pick issues

----
;;;","28/Jul/16 07:11;githubbot;Github user mjsax closed the pull request at:

    https://github.com/apache/kafka/pull/1671
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Data loss if broker is killed using kill -9,KAFKA-1193,12686344,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,hanish.bansal.agarwal,hanish.bansal.agarwal,25/Dec/13 17:49,05/Sep/14 06:02,22/Mar/23 15:10,05/Sep/14 06:02,0.8.0,0.8.1,,,,,0.8.2.0,,,,,,,replication,,,,4,,,,,,"We are having kafka cluster of 2 nodes. (Using Kafka 0.8.0 version)
Replication Factor: 2
Number of partitions: 2

Actual Behaviour:
-------------------------
Out of two nodes, if leader node goes down then data lost happens.

Steps to Reproduce:
------------------------------
1. Create a 2 node kafka cluster with replication factor 2
2. Start the Kafka cluster
3. Create a topic lets say ""test-trunk111""
4. Restart any one node.
5. Check topic status using kafka-list-topic tool.
topic isr status is:

topic: test-trunk111    partition: 0    leader: 0    replicas: 1,0    isr: 0,1
topic: test-trunk111    partition: 1    leader: 0    replicas: 0,1    isr: 0,1

If there is only one broker node in isr list then wait for some time and again check isr status of topic. There should be 2 brokers in isr list.
6. Start producing the data.
7. Kill leader node (borker-0 in our case) meanwhile of data producing.
8. After all data is produced start consumer.
9. Observe the behaviour. There is data loss.

After leader goes down, topic isr status is:

topic: test-trunk111    partition: 0    leader: 1    replicas: 1,0    isr: 1
topic: test-trunk111    partition: 1    leader: 1    replicas: 0,1    isr: 1

We have tried below things to avoid data loss:
----------------------------------------------------------------

1. Configured ""request.required.acks=-1"" in producer configuration because as mentioned in documentation http://kafka.apache.org/documentation.html#producerconfigs, setting this value to -1 provides guarantee that no messages will be lost.
2. Increased the ""message.send.max.retries"" from 3 to 10 in producer configuration.

3. Set ""controlled.shutdown.enable"" to true in broker configuration.

4. Tested with Kafka-0.8.1 after applying patch KAFKA-1188.patch available on https://issues.apache.org/jira/browse/KAFKA-1188 

Nothing work out from above things in case of leader node is killed using ""kill -9 <pid>"".

Expected Behaviour:
----------------------------
No data should be lost.
",Centos 6.3,felixgv,guozhang,hanish.bansal.agarwal,hubez,junrao,nehanarkhede,smeder,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,365327,,,Thu Sep 04 22:01:57 UTC 2014,,,,,,,,,,"0|i1qywn:",365629,,,,,,,,,,,,,,,,,,,,"29/Dec/13 00:01;junrao;Do you see the following in the controller log? This indicates an unclean leader election and could cause data loss.

""No broker in ISR is alive for ... There's potential data loss."";;;","29/Dec/13 00:46;hanish.bansal.agarwal;If i don't perform 5th step (i.e. If there is only one broker node in isr list then wait for some time and again check isr status of topic. There should be 2 brokers in isr list.) listed properly then i am able to see logs like:
{quote}
[2013-12-23 10:25:07,648] DEBUG [OfflinePartitionLeaderSelector]: No broker in ISR is alive for [test-trunk111,1]. Pick the leader from the alive assigned replicas: 1 (kafka.controller.OfflinePartitionLeaderSelector)
[2013-12-23 10:25:07,648] WARN [OfflinePartitionLeaderSelector]: No broker in ISR is alive for [test-trunk111,1]. Elect leader 1 from live brokers 1. There's potential data loss. (kafka.controller.OfflinePartitionLeaderSelector)
[2013-12-23 10:25:07,649] INFO [OfflinePartitionLeaderSelector]: Selected new leader and ISR {""leader"":1,""leader_epoch"":1,""isr"":[1]} for offline partition [test-trunk111,1] (kafka.controller.OfflinePartitionLeaderSelector)
{quote}

In this case where only one broker is in isr list i experienced 50-60 % data loss where is the case where both 2 brokers are in isr list i experienced only 2-3 % data loss.
;;;","03/Jan/14 03:25;guozhang;After thinking about this I am still leaning towards this being caused by KAFKA-1188, and probably the previous patch does not fully resolved the issue.

[~hanish.bansal.agarwal] Could you retry this procedure after we have fully tested the patch and commit it to trunk?;;;","03/Jan/14 03:31;guozhang;Hanish, one thing I was wondering is do you always see data loss with step 5 performed or do you see data loss from time to time? And also what is your producer's throughput?;;;","06/Jan/14 18:30;hanish.bansal.agarwal;Once 1188 is fixed We can retest that it is reproducible or not.

Yes, we always see data loss if broker is killed using kill -9.

Producer's throughput is around 800 records/sec. ;;;","27/Mar/14 20:16;nehanarkhede;[~hanish.bansal.agarwal] Would you mind repeating your test since KAFKA-1188 is checked in.;;;","10/May/14 13:45;hanish.bansal.agarwal;Neha, i was quite busy and couldn't get time to test this on 0.8.1. Now i tested this bug on 0.8.1.1 and its working fine. 

Thanks.;;;","05/Sep/14 06:01;guozhang;[~hanish.bansal.agarwal] I am closing this ticket now. Please feel free to re-open it if you observed this issue again.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
gradlew is not working on a fresh checkout,KAFKA-2124,12821001,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,granthenke,jghoman,jghoman,15/Apr/15 06:55,14/Dec/18 01:52,22/Mar/23 15:10,14/Dec/18 01:52,,,,,,,,,,,,,,build,,,,1,,,,,,"For a fresh checkout, the gradlew script is not working:

{noformat}heimdallr 15:54 $ asfclone kafka
Cloning into 'kafka'...
remote: Counting objects: 25676, done.
remote: Compressing objects: 100% (36/36), done.
remote: Total 25676 (delta 5), reused 0 (delta 0), pack-reused 25627
Receiving objects: 100% (25676/25676), 19.58 MiB | 4.29 MiB/s, done.
Resolving deltas: 100% (13852/13852), done.
Checking connectivity... done.
/tmp/kafka /tmp
/tmp
✔ /tmp
heimdallr 15:54 $ cd kafka
✔ /tmp/kafka [trunk|✔]
heimdallr 15:54 $ ./gradlew tasks
Error: Could not find or load main class org.gradle.wrapper.GradleWrapperMain{noformat}",,dejan2609,gwenshap,jghoman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1714,,,,,,KAFKA-1490,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Apr 14 23:18:28 UTC 2015,,,,,,,,,,"0|i2d993:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"15/Apr/15 07:08;gwenshap;Yep yep. Known issue and documented in the README.

We can't package the gradle jar in our repository (since we end up with a binary in our source distro).
The solution is for you to download Gradle and run it prior to running gradlew.

Edit: Actually, you got the right issue in the ""related jira"". So you probably know what I just explained. Do you have a suggested solution?;;;","15/Apr/15 07:18;jghoman;We can package the jar in the repo, we just need to exclude it from the source release, as Samza does: SAMZA-283.  The rule about no binaries applies to source releases, not repos.  This way the pain of having to have gradle installed is limited to just those who use the source distro and not a clone of the repo.

In addition, we should move the downloadWrapper task into a separate, more palatable script that works with more versions of gradle s.t. users don't have to much their gradle to whatever the current build.gradle is accepting.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CompressionUtils introduces a GZIP header while compressing empty message sets,KAFKA-109,12519264,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,nehanarkhede,nehanarkhede,18/Aug/11 17:10,13/Sep/11 09:27,22/Mar/23 15:10,13/Sep/11 09:27,0.7,,,,,,0.7,,,,,,,,,,,0,,,,,,"The CompressionUtils helper class takes in a sequence of messages and compresses those, using the appropriate codec. But even if it receives an empty sequence, it still ends up adding a GZIP compression header to the data, efffectively ""adding"" data to the resulting ByteBuffer. This doesn't match with the behavior for uncompressed empty message sets. CompressionUtils should be fixed by removing this side-effect.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/11 03:55;nehanarkhede;KAFKA-109.patch;https://issues.apache.org/jira/secure/attachment/12490844/KAFKA-109.patch","18/Aug/11 18:35;nehanarkhede;KAFKA-109.patch;https://issues.apache.org/jira/secure/attachment/12490782/KAFKA-109.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,60818,,,Thu Aug 18 21:43:47 UTC 2011,,,,,,,,,,"0|i15yyn:",242964,,,,,,,,,,,,,,,,,,,,"18/Aug/11 18:34;nehanarkhede;This patch handles the behavior of ByteBufferMessageSet for compression of empty list of messages. This modifies the ByteBufferMessageSet to create an empty byte buffer, in this case, instead of attaching a GZIP header to it. There are a couple of reasons to do this -

1. To maintain consistent behavior between an empty uncompressed message set and an empty compressed message set
2. To avoid attaching extraneous header information to non-existing data, effectively occupying space on disk;;;","19/Aug/11 00:03;junrao;+1. The patch looks good.;;;","19/Aug/11 01:03;junrao;Actually, this doesn't cover javaapi.ByteBufferMessageSet. It seems that javaapi.ByteBufferMessageSet duplicates some of the constructor code in ByteBufferMessageSet. We should avoid doing that.;;;","19/Aug/11 03:55;nehanarkhede;This is a revised patch that refactors the constructors of both java and scala ByteBufferMessageSet into a common API in MessageSet. This ensures that the bug fix exists both in the Java API as well as the Scala API;;;","19/Aug/11 05:43;junrao;+1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NoSuchElementException on server shutdown,KAFKA-1652,12744120,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,nehanarkhede,nehanarkhede,26/Sep/14 04:16,29/Sep/15 06:05,22/Mar/23 15:10,26/Sep/14 11:53,,,,,,,,,,,,,,,,,,0,newbie++,,,,,"Observed the following exception on server shutdown. Happens pretty frequently though not on every shutdown. Ways to reproduce -
1. Checkout kafka from trunk
2. Run bin/kafka-server-start.sh config/server.properties
3. Ctrl C

{noformat}
2014-09-25 12:31:14,441] ERROR None.get (kafka.network.Processor)
java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:313)
	at scala.None$.get(Option.scala:311)
	at kafka.network.ConnectionQuotas.dec(SocketServer.scala:522)
	at kafka.network.AbstractServerThread.close(SocketServer.scala:165)
	at kafka.network.AbstractServerThread.close(SocketServer.scala:157)
	at kafka.network.Processor.close(SocketServer.scala:372)
	at kafka.network.AbstractServerThread.closeAll(SocketServer.scala:178)
	at kafka.network.Processor$$anonfun$run$3.apply$mcV$sp(SocketServer.scala:362)
	at kafka.utils.Utils$.swallow(Utils.scala:172)
	at kafka.utils.Logging$class.swallowError(Logging.scala:106)
	at kafka.network.AbstractServerThread.swallowError(SocketServer.scala:108)
	at kafka.network.Processor.run(SocketServer.scala:362)
	at java.lang.Thread.run(Thread.java:695)
{noformat}",,jjkoshy,nehanarkhede,olindaspider,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Sep 28 22:05:05 UTC 2015,,,,,,,,,,"0|i20ht3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"26/Sep/14 04:31;jjkoshy;Are you sure you have the fix in KAFKA-1577 ? If so should we just reopen that?;;;","26/Sep/14 11:52;nehanarkhede;[~jjkoshy] I saw this on trunk as of yesterday and today. Sorry, missed the fact that 1577 basically reported the same issue. We can reopen that.;;;","26/Sep/14 12:55;sriharsha;[~jjkoshy] [~nehanarkhede] I am able to reproduce this will follow-up with a patch.;;;","27/Sep/14 02:42;nehanarkhede;Thanks [~sriharsha]. Appreciate the follow-up!;;;","29/Sep/15 06:05;olindaspider;I believe I have found the root cause of this issue as explained here: https://issues.apache.org/jira/browse/KAFKA-1804?focusedCommentId=14909940&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14909940;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
java.util.HashMap cannot be cast to scala.collection.immutable.Map When using  ZookeeperConsumerConnector.commitOffsets,KAFKA-3075,12928227,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,pengwei,pengwei,07/Jan/16 12:17,30/Jan/16 00:53,22/Mar/23 15:10,30/Jan/16 00:53,0.9.0.0,,,,,,0.9.0.1,,,,,,,consumer,,,,0,,,,,,"When using java api's commit offset :

 public void commitOffsets(Map<TopicAndPartition, OffsetAndMetadata> offsetsToCommit, boolean retryOnFailure);

and pass a  Java Hash Map to this interface, will found:

java.lang.ClassCastException: java.util.HashMap cannot be cast to scala.collection.immutable.Map
at kafka.javaapi.consumer.ZookeeperConsumerConnector.commitOffsets(ZookeeperConsumerConnector.scala:118)
at kafka.examples.CommitExceptionTest.testCommitNotExistTopicShoudThrowException(CommitExceptionTest.java:55)
at kafka.examples.CommitExceptionTest.main(CommitExceptionTest.java:20)
Test case testCommitNotExistTopicShoudThrowException OK.
Exception in thread ""main"" java.lang.ClassCastException: java.util.HashMap cannot be cast to scala.collection.immutable.Map
at kafka.javaapi.consumer.ZookeeperConsumerConnector.commitOffsets(ZookeeperConsumerConnector.scala:118)
at kafka.examples.CommitExceptionTest.testCommitOffsetOutOfRange(CommitExceptionTest.java:95)
at kafka.examples.CommitExceptionTest.main(CommitExceptionTest.java:22)

The Origin Code:
 def commitOffsets(offsetsToCommit: java.util.Map[TopicAndPartition, OffsetAndMetadata], retryOnFailure: Boolean) {
    underlying.commitOffsets(offsetsToCommit.asInstanceOf[immutable.Map[TopicAndPartition, OffsetAndMetadata]], retryOnFailure)
  }
I try to fix like this, it is OK:
  def commitOffsets(offsetsToCommit: java.util.Map[TopicAndPartition, OffsetAndMetadata], retryOnFailure: Boolean) {
    import scala.collection.JavaConverters._

    underlying.commitOffsets(offsetsToCommit.asScala.toMap, retryOnFailure)
  }
",,githubbot,ijuma,pengwei,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jan 29 16:53:17 UTC 2016,,,,,,,,,,"0|i2qyvr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"30/Jan/16 00:35;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/833

    KAFKA-3075; Fix ClassCastException in `ZookeeperConsumerConnector.commitOffsets`

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-3075-javaapi-consumer-class-cast-exception

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/833.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #833
    
----
commit 2391fcb2cce2f4abcf9c4084c4f2cd45e1b0a88b
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-01-29T16:32:51Z

    Fix ClassCastException in `ZookeeperConsumerConnector.commitOffsets`

----
;;;","30/Jan/16 00:36;ijuma;Thanks for the report.;;;","30/Jan/16 00:41;ijuma;Not related to the bug report, but you may consider using the new Java consumer if possible:

http://www.confluent.io/blog/tutorial-getting-started-with-the-new-apache-kafka-0.9-consumer-client;;;","30/Jan/16 00:53;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/833
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
potential socket leak in new producer and clean up,KAFKA-1307,12701930,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,18/Mar/14 01:06,19/Mar/14 01:56,22/Mar/23 15:10,19/Mar/14 01:56,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Address the delta review comments from kafka-1227.

20. Selector and Sender: need to close socket channel on IOException in addition to UnresolvedHostnameException.
21. AbstractConfig:
21.1 To be consistent, we probably should change the return value of the following api from Long to long.
public Long getLong(String key)
21.1 Could we also add getDouble(String key)?
22. Metadata.fetch(): The wait time is incorrect when there is an InterruptedException.
23. Add comments on BufferPool.allocate() and Struct.instanceOf() for clarification.
24. Various other minor fixes for mis-spelling.
",,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Mar/14 01:11;junrao;KAFKA-1307.patch;https://issues.apache.org/jira/secure/attachment/12635118/KAFKA-1307.patch","19/Mar/14 00:53;junrao;KAFKA-1307_2014-03-18_09:53:00.patch;https://issues.apache.org/jira/secure/attachment/12635343/KAFKA-1307_2014-03-18_09%3A53%3A00.patch","19/Mar/14 01:03;junrao;KAFKA-1307_2014-03-18_10:03:01.patch;https://issues.apache.org/jira/secure/attachment/12635344/KAFKA-1307_2014-03-18_10%3A03%3A01.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,380270,,,Tue Mar 18 17:56:19 UTC 2014,,,,,,,,,,"0|i1tir3:",380553,,,,,,,,,,,,,,,,,,,,"18/Mar/14 01:11;junrao;Created reviewboard https://reviews.apache.org/r/19311/
 against branch origin/trunk;;;","18/Mar/14 01:14;nehanarkhede;[~junrao] You mentioned that you also have a couple of logging changes that you found useful while troubleshooting this bug. Does this patch include all of those changes as well?;;;","18/Mar/14 04:05;junrao;The logging improvement is already committed in KAFKA-1302.;;;","19/Mar/14 00:53;junrao;Updated reviewboard https://reviews.apache.org/r/19311/
 against branch origin/trunk;;;","19/Mar/14 01:03;junrao;Updated reviewboard https://reviews.apache.org/r/19311/
 against branch origin/trunk;;;","19/Mar/14 01:56;junrao;Thanks for the review. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Version number major.major.minor.fix in kafka-merge-pr.py,KAFKA-2563,12895222,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,guozhang,guozhang,22/Sep/15 02:59,22/Sep/15 03:28,22/Mar/23 15:10,22/Sep/15 03:28,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Saw the following error while using the script to resolve a re-opened ticket a couple of times:

{code}
Traceback (most recent call last):
  File ""kafka-merge-pr.py"", line 474, in <module>
    main()
  File ""kafka-merge-pr.py"", line 460, in main
    resolve_jira_issues(commit_title, merged_refs, jira_comment)
  File ""kafka-merge-pr.py"", line 317, in resolve_jira_issues
    resolve_jira_issue(merge_branches, comment, jira_id)
  File ""kafka-merge-pr.py"", line 285, in resolve_jira_issue
    (major, minor, patch) = v.split(""."")
ValueError: too many values to unpack
{code}

Actually it is not related to re-opened tickets, but related to the new version number that the code tries to cope with:

{code}
(major, minor, patch) = v.split(""."")
{code}",,eribeiro,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2548,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Sep 21 19:28:31 UTC 2015,,,,,,,,,,"0|i2ld2f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"22/Sep/15 03:11;eribeiro;This is a duplicate of KAFKA-2548. ;)

;;;","22/Sep/15 03:28;guozhang;You are right, closing now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The FetcherRunnable busy waits on empty fetch requests ,KAFKA-117,12519882,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,nehanarkhede,nehanarkhede,24/Aug/11 05:42,13/Sep/11 09:30,22/Mar/23 15:10,13/Sep/11 09:30,0.7,,,,,,0.7,,,,,,,,,,,0,,,,,,The FetcherRunnable busy waits on empty fetch requests by skipping the backoff logic. This can fill up the disk space due to the public access log being filled up. Also the CPU usage shoots up to 100%. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Aug/11 08:21;nehanarkhede;KAFKA-117-v2.patch;https://issues.apache.org/jira/secure/attachment/12491421/KAFKA-117-v2.patch","24/Aug/11 08:59;nehanarkhede;KAFKA-117-v3.patch;https://issues.apache.org/jira/secure/attachment/12491427/KAFKA-117-v3.patch","24/Aug/11 05:49;nehanarkhede;KAFKA-117.patch;https://issues.apache.org/jira/secure/attachment/12491393/KAFKA-117.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,60814,,,Wed Aug 24 01:05:45 UTC 2011,,,,,,,,,,"0|i15z0f:",242972,,,,,,,,,,,,,,,,,,,,"24/Aug/11 05:49;nehanarkhede;The bug was in the shallowValidBytes logic where it returns a negative value when dealing with an empty fetch request.

Corrected the logic of shallowValidBytes to return 0 when there is no data in the ByteBufferMessageSet created from an empty fetch request.;;;","24/Aug/11 07:21;junrao;We probably should just have a method validBytes that returns the valid bytes in the original message (ie, if the message is compressed, the bytes refer to the compressed bytes). There is no real need for knowing the total valid bytes on a compressed message set.;;;","24/Aug/11 08:18;nehanarkhede;I think your suggestion makes sense. The deepValidBytes method is useless and never used, even by the unit tests. It is better to have just a single API for calculating valid bytes.;;;","24/Aug/11 08:21;nehanarkhede;Deleted the deepValidBytes API. Made the shallowValidBytes API private and had the validBytes API point to shallowValidBytes.

validBytes() API will always give you the number of compressed bytes in the ByteBufferMessageSet, if it is compressed. ;;;","24/Aug/11 08:59;nehanarkhede;Includes all changes from v2 patch + a unit test to cover the valid bytes for empty message sets;;;","24/Aug/11 09:05;junrao;+1 on v3.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Data read from network not processed by SSL transport layer,KAFKA-2801,12912015,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,rsivaram,rsivaram,rsivaram,11/Nov/15 07:09,11/Nov/15 08:37,22/Mar/23 15:10,11/Nov/15 08:37,0.9.0.0,,,,,,0.9.0.0,,,,,,,network,,,,0,,,,,,"We have been seeing intermittent failures in our performance tests when producer times out while waiting for metadata response, when running with SSL. Digging deeper into this failure, this is a result of data that was read into _SslTransporLayer.netReadBuffer_ during handshake processing, but never processed later unless more data arrives on the network. In the case of the producer, no more data is sent until the metadata response is received and hence metadata request is never processed, leading to timeouts in the producer.",,githubbot,junrao,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Nov 11 00:37:42 UTC 2015,,,,,,,,,,"0|i2o7zb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"11/Nov/15 07:37;githubbot;GitHub user rajinisivaram opened a pull request:

    https://github.com/apache/kafka/pull/493

    KAFKA-2801: Process any remaining data in SSL network read buffer after handshake

    Process any remaining data in the network read buffer in `SslTransportLayer` when `read()` is invoked. On handshake completion, there could be application data ready to be processed that was read into `netReadBuffer` during handshake processing. `read()` is already invoked from `Selector` after handshake completion, but data already read into the `netReadBuffer` was not being processed. This PR adds a check for remaining data and continues with processing data if data is available.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/rajinisivaram/kafka KAFKA-2801

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/493.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #493
    
----
commit 081cdc953c04e0fa12c7c8633c9f2d5e1db8638f
Author: Rajini Sivaram <rajinisivaram@googlemail.com>
Date:   2015-11-10T23:19:37Z

    KAFKA-2801: Process any remaining data in network read buffer during SSL read

----
;;;","11/Nov/15 07:40;rsivaram;Have run all existing unit tests. Can't think of an easy way to add a new unit test to catch this scenario.

It will be good if the fix can be included in 0.9.0.;;;","11/Nov/15 08:37;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/493
;;;","11/Nov/15 08:37;junrao;Issue resolved by pull request 493
[https://github.com/apache/kafka/pull/493];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
gradle release issue permgen space,KAFKA-1662,12745250,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,sriharsha,joestein,joestein,01/Oct/14 21:19,04/Oct/14 10:07,22/Mar/23 15:10,04/Oct/14 10:01,,,,,,,0.8.2.0,,,,,,,,,,,0,newbie,,,,,"Finding issues doing the kafka release with permgen space

./gradlew releaseTarGzAll

ant:scaladoc] java.lang.OutOfMemoryError: PermGen space
:kafka-0.8.2-ALPHA1-src:core:scaladoc FAILED
:releaseTarGz_2_10_1 FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':core:scaladoc'.
> PermGen space

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED

Total time: 5 mins 55.53 secs

FAILURE: Build failed with an exception.

* What went wrong:
PermGen space

",,joestein,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/14 07:14;sriharsha;KAFKA-1662.patch;https://issues.apache.org/jira/secure/attachment/12672868/KAFKA-1662.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Oct 04 02:07:43 UTC 2014,,,,,,,,,,"0|i20oof:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"04/Oct/14 07:14;sriharsha;Created reviewboard https://reviews.apache.org/r/26332/diff/
 against branch origin/trunk;;;","04/Oct/14 08:25;joestein;I tried the patch and ran

{code}
./gradlew releaseTarGzAll
{code}

and got 

{code}
Unexpected exception thrown.
java.lang.OutOfMemoryError: PermGen space
	at java.lang.Class.getDeclaredMethods0(Native Method)
	at java.lang.Class.privateGetDeclaredMethods(Class.java:2436)
	at java.lang.Class.getDeclaredMethod(Class.java:1937)
	at java.io.ObjectStreamClass.getPrivateMethod(ObjectStreamClass.java:1377)
	at java.io.ObjectStreamClass.access$1700(ObjectStreamClass.java:50)
	at java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:436)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:411)
	at java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:308)
	at java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:407)
	at java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:308)
	at java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:407)
	at java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:308)
	at java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:407)
	at java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:308)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1114)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1518)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1483)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1400)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1158)
	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1346)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1154)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:330)
	at org.gradle.messaging.remote.internal.Message.send(Message.java:40)
	at org.gradle.messaging.serialize.kryo.JavaSerializer$JavaWriter.write(JavaSerializer.java:62)
	at org.gradle.messaging.remote.internal.hub.MethodInvocationSerializer$MethodInvocationWriter.writeArguments(MethodInvocationSerializer.java:67)
	at org.gradle.messaging.remote.internal.hub.MethodInvocationSerializer$MethodInvocationWriter.write(MethodInvocationSerializer.java:63)
	at org.gradle.messaging.remote.internal.hub.MethodInvocationSerializer$MethodInvocationWriter.write(MethodInvocationSerializer.java:48)
	at org.gradle.messaging.serialize.kryo.TypeSafeSerializer$2.write(TypeSafeSerializer.java:46)
	at org.gradle.messaging.remote.internal.hub.InterHubMessageSerializer$MessageWriter.write(InterHubMessageSerializer.java:108)
	at org.gradle.messaging.remote.internal.hub.InterHubMessageSerializer$MessageWriter.write(InterHubMessageSer.java:93)
	at org.gradle.messaging.remote.internal.inet.SocketConnection.dispatch(SocketConnection.java:112)

{code};;;","04/Oct/14 08:40;sriharsha;[~charmalloc] can you share which os you are running this on. I was able to reproduce without this patch on OS X 10.9.4 but with this patch releaseTarGzAll works fine for me. Did you removed the existing gradle dir and reran the gradle command before running ./gradlew;;;","04/Oct/14 10:01;joestein;yup, works;;;","04/Oct/14 10:07;joestein;I committed to trunk and 0.8.2 branch.  Thanks for the patch!!!

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AsyncProducer shutdown logic causes data loss,KAFKA-116,12519801,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,nehanarkhede,nehanarkhede,23/Aug/11 15:55,13/Sep/11 09:30,22/Mar/23 15:10,13/Sep/11 09:30,0.7,,,,,,0.7,,,,,,,,,,,0,,,,,,"The current shutdown logic of the AsyncProducer allows adding events to the queue, after adding the shutdown command to it. The ProducerSendThread drains all the data in the queue until it hits the shutdown command. Hence, all data added after the shutdown command is lost.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Aug/11 16:16;nehanarkhede;KAFKA-116.patch;https://issues.apache.org/jira/secure/attachment/12491322/KAFKA-116.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,60812,,,Wed Aug 24 21:10:20 UTC 2011,,,,,,,,,,"0|i15z07:",242971,,,,,,,,,,,,,,,,,,,,"23/Aug/11 16:16;nehanarkhede;1. Fixed the shutdown bug by setting the closed queue flag before adding the shutdown command to the async producer queue
2. Added more logging at the trace level 
3. Refactored the blocking async producer logic to use case match instead of nested if else;;;","24/Aug/11 08:18;junrao;+1;;;","24/Aug/11 10:48;cburroughs;IllegalQueueStateException was missed in the commit.;;;","25/Aug/11 05:10;nehanarkhede;thanks for pointing that out. I checked it in now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Avoid checkpointing offsets in Kafka consumer that have not changed since the last commit,KAFKA-987,12659224,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,swapnilghike,swapnilghike,swapnilghike,23/Jul/13 07:08,27/Jul/13 05:19,22/Mar/23 15:10,24/Jul/13 02:21,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,improvement,,,,,We need to fix the Kafka zookeeper consumer to avoid checkpointing offsets that have not changed since the last offset commit. This will help reduce the write load on zookeeper.,,junrao,nehanarkhede,swapnilghike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jul/13 01:41;swapnilghike;kafka-987-v2.patch;https://issues.apache.org/jira/secure/attachment/12593742/kafka-987-v2.patch","23/Jul/13 07:56;swapnilghike;kafka-987.patch;https://issues.apache.org/jira/secure/attachment/12593616/kafka-987.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,339417,,,Fri Jul 26 21:19:01 UTC 2013,,,,,,,,,,"0|i1mjiv:",339737,,,,,,,,,,,,,,,,,,,,"23/Jul/13 07:56;swapnilghike;The only case wherein the code does not have a bug and yet the consumer could end up consuming from an offset < the previously committed offset is when there is an unclean leader election. Hence, this patch will commit new offsets as long as they are different from the previously committed offsets.;;;","24/Jul/13 00:47;nehanarkhede;Thanks for the patch, Swapnil. Good thinking about not limiting the check to offset < committed offset. Just one question about your patch -

 In commitOffsets, should the the map update move to inside the try block to ensure that the map is updated only if the zk write succeeds ?
;;;","24/Jul/13 01:41;swapnilghike;Yes, thank you. Attached v2.;;;","24/Jul/13 02:18;nehanarkhede;+1 on v2.;;;","24/Jul/13 02:20;nehanarkhede;committed v2 to 0.8;;;","24/Jul/13 12:55;junrao;It seems that we don't need to update the offset map in addPartitionTopicInfo(). In fact, currently, if there is no new messages coming in, we won't checkpoint the first offset.;;;","24/Jul/13 14:48;swapnilghike;I think that any call to createMessageStreams will trigger a rebalance, that will fill up the topicregistry and the checkpointing of offsets will start regardless of whether new messages are being consumed or not. Hence, we should probably update the cached checkpointedOffsets map in addPartitionTopicInfo().

May be I have missed something?;;;","25/Jul/13 00:55;nehanarkhede;Jun,

I think what you are suggesting makes sense on startup before the consumer has consumed any messages. However, since the offset map is a cache for what's in zookeeper, the safest way is to keep it in sync with the zookeeper data. Before the consumer can pull any data, it has to rebalance and while rebalancing we read the offsets from zk anyways. So I think it is correct to update the offset cache in addPartitionTopicInfo()
;;;","25/Jul/13 23:52;junrao;1. The issue on startup is the following. If a consumer starts up from the end of the log and there is no new message coming in, no offset will be checkpointed to ZK. This will affect tools like ConsumerOffsetChecker.

2. During rebalance, a consumer may pick up offsets committed by other consumer instances. If we don't update the offset cache in addPartitionTopicInfo(), we will do an extra unnecessary offset update to ZK.

It seems to me that the impact for #1 is bigger than the slight performance impact in #2. Another way to do that is to always force the very first offset (per partition) write to ZK. However, I am not sure if it's worth the complexity.;;;","26/Jul/13 23:34;nehanarkhede;I'm trying to see if I understand what you are saying here. 

1. The basic logic is that as long as the consumer rebalances before starting consumption, the offset cache will be updated. This is true for the zookeeper consumer behavior today. Now, it really doesn't matter much where the consumer starts consuming from. If it hasn't read any messages, there is no need to update offsets in zookeeper. If it reads messages, the offsets will be different from what's in the cache, so they will get checkpointed.

2. I don't think this is worth doing since it only reduces one zookeeper write.;;;","27/Jul/13 05:19;swapnilghike;I discussed this yesterday with Jun. If there is no offset already present in zookeeper, we set the offset value to -1 in the offset cache in addPartitionInfo(). Later, even if no message is consumed, the real offset will be checkpointed. Jun said that he was ok with this patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Throw exception to client if it makes a produce/consume request to a Kafka broker for a topic that hasn't been created,KAFKA-352,12558525,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,30/May/12 10:04,20/Jul/12 03:51,22/Mar/23 15:10,20/Jul/12 03:51,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,,,,,,It will be good to inform the client if it makes a produce/consume request to a Kafka broker for a topic that hasn't been created. The exception should be something like UnknownTopicException that is descriptive.,,jkreps,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-50,,,,,,,,,,,,,,"19/Jul/12 04:17;nehanarkhede;kafka-352-v1.patch;https://issues.apache.org/jira/secure/attachment/12537058/kafka-352-v1.patch","19/Jul/12 10:32;nehanarkhede;kafka-352-v2.patch;https://issues.apache.org/jira/secure/attachment/12537124/kafka-352-v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,248183,,,Thu Jul 19 19:51:30 UTC 2012,,,,,,,,,,"0|i09m2n:",54009,,,,,,,,,,,,,,,,,,,,"19/Jul/12 04:17;nehanarkhede;1. Improved error handling for produce, fetch, get offsets request to handle unknown topic error code

2. Topic metadata request error handling is fixed as part of KAFKA-350.

3. I understand that we have KAFKA-402 filed to go over all other error handling. This patch only handled unknown topics and unit tested it for all types of requests.;;;","19/Jul/12 08:16;jkreps;+1

A few minor things:
1. Remove the println in KafkaApis.scala
2. In LogOffsetTest, I think there is no need to define val part = 0 since it is only used once
3. What does the Thread.sleep(500) in SyncProducerTest.testProduceCorrectlyReceivesResponse wait for?


;;;","19/Jul/12 10:32;nehanarkhede;Thanks for the review, Jay ! Uploading another patch with the review comments addressed -
1. Deleted the println
2. Removed the definition of part variable
3. Removed the sleep. It seems like one of those unnecessary sleep() calls we have in our unit tests.
;;;","19/Jul/12 12:26;jkreps;+1;;;","20/Jul/12 03:51;nehanarkhede;Thanks for the review!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TopicMetadataRequest throws exception when no topics are specified,KAFKA-690,12626691,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,mumrah,mumrah,mumrah,09/Jan/13 08:50,10/Jan/13 00:49,22/Mar/23 15:10,10/Jan/13 00:49,0.8.0,,,,,,0.8.0,,,,,,,core,,,,0,,,,,,"If no topics are sent in a TopicMetadataRequest, `readFrom` throws an exception when trying to get the the head of the topic list for a debug statement.

java.util.NoSuchElementException: head of empty list
	at scala.collection.immutable.Nil$.head(List.scala:386)
	at scala.collection.immutable.Nil$.head(List.scala:383)
	at kafka.api.TopicMetadataRequest$$anonfun$readFrom$2.apply(TopicMetadataRequest.scala:43)
	at kafka.api.TopicMetadataRequest$$anonfun$readFrom$2.apply(TopicMetadataRequest.scala:43)
	at kafka.utils.Logging$class.debug(Logging.scala:51)
	at kafka.api.TopicMetadataRequest$.debug(TopicMetadataRequest.scala:25)
	at kafka.api.TopicMetadataRequest$.readFrom(TopicMetadataRequest.scala:43)
	at kafka.api.RequestKeys$$anonfun$4.apply(RequestKeys.scala:37)
	at kafka.api.RequestKeys$$anonfun$4.apply(RequestKeys.scala:37)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:47)
	at kafka.network.Processor.read(SocketServer.scala:320)
	at kafka.network.Processor.run(SocketServer.scala:231)
	at java.lang.Thread.run(Thread.java:680)
",,brugidou,jkreps,mumrah,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-653,,,,,,,,,,,,,,,,,,,"09/Jan/13 09:22;mumrah;KAFKA-690.patch;https://issues.apache.org/jira/secure/attachment/12563864/KAFKA-690.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,303299,,,Wed Jan 09 16:49:40 UTC 2013,,,,,,,,,,"0|i179a7:",250472,,,,,,,,,,,,,,,,,,,,"09/Jan/13 08:58;mumrah;Removing the debug statement fixes the issue. However, it seems instead of returning all of the topic metadata - I get none.

Here are some trace logs when I send a TopicMetadataRequest with no topics

[2013-01-08 19:53:34,463] TRACE 26 bytes read from /127.0.0.1:61558 (kafka.network.Processor)
[2013-01-08 19:53:34,465] TRACE Received request: TopicMetadataRequest(0,kafka-python,List(),0) (kafka.network.RequestChannel$)
[2013-01-08 19:53:34,466] TRACE Recieved request, sending for processing by handler: Request(1,sun.nio.ch.SelectionKeyImpl@785e8d7d,java.nio.HeapByteBuffer[pos=0 lim=26 cap=26],1357692814463) (kafka.network.Processor)
[2013-01-08 19:53:34,466] DEBUG [Kafka Request Handler 1 on Broker 0], handles request Request(1,sun.nio.ch.SelectionKeyImpl@785e8d7d,java.nio.HeapByteBuffer[pos=0 lim=26 cap=26],1357692814463) (kafka.server.KafkaRequestHandler)
[2013-01-08 19:53:34,466] TRACE Handling topic metadata request TopicMetadataRequest(0,kafka-python,List(),0) (kafka.request.logger)
[2013-01-08 19:53:34,466] TRACE [KafkaApi-0] Handling topic metadata request TopicMetadataRequest(0,kafka-python,List(),0) (kafka.server.KafkaApis)
[2013-01-08 19:53:34,475] TRACE Socket server received response to send, registering for write: Response(1,Request(1,sun.nio.ch.SelectionKeyImpl@785e8d7d,java.nio.HeapByteBuffer[pos=0 lim=26 cap=26],1357692814463),kafka.network.BoundedByteBufferSend@2e82674b) (kafka.network.Processor)
[2013-01-08 19:53:34,476] TRACE 16 bytes written to /127.0.0.1:61558 (kafka.network.Processor)
[2013-01-08 19:53:34,476] TRACE Completed request: TopicMetadataRequest(0,kafka-python,List(),0) totalTime:13 queueTime:3 localTime:9 remoteTime:0 sendTime:1 (kafka.network.RequestChannel$)

I would expect this to return info about the one existing topic ""test"".

Here are the logs for when I send a TopicMetadataRequest with the ""test"" topic (this gives the expected response):

[2013-01-08 19:55:26,247] TRACE 32 bytes read from /127.0.0.1:61719 (kafka.network.Processor)
[2013-01-08 19:55:26,247] TRACE Received request: TopicMetadataRequest(0,kafka-python,List(test),0) (kafka.network.RequestChannel$)
[2013-01-08 19:55:26,247] TRACE Recieved request, sending for processing by handler: Request(0,sun.nio.ch.SelectionKeyImpl@30d647d8,java.nio.HeapByteBuffer[pos=0 lim=32 cap=32],1357692926247) (kafka.network.Processor)
[2013-01-08 19:55:26,247] DEBUG [Kafka Request Handler 0 on Broker 0], handles request Request(0,sun.nio.ch.SelectionKeyImpl@30d647d8,java.nio.HeapByteBuffer[pos=0 lim=32 cap=32],1357692926247) (kafka.server.KafkaRequestHandler)
[2013-01-08 19:55:26,247] TRACE Handling topic metadata request TopicMetadataRequest(0,kafka-python,List(test),0) (kafka.request.logger)

[2013-01-08 19:55:26,247] TRACE [KafkaApi-0] Handling topic metadata request TopicMetadataRequest(0,kafka-python,List(test),0) (kafka.server.KafkaApis)

[2013-01-08 19:55:26,248] DEBUG Reading reply sessionid:0x13c15a1d848003f, packet:: clientPath:null serverPath:null finished:false header:: 30,3  replyHeader:: 30,354,0  request:: '/kafka/brokers/topics/test,F  response:: s{320,320,1357689749289,1357689749289,0,1,0,0,14,1,323}  (org.apache.zookeeper.ClientCnxn)
[2013-01-08 19:55:26,249] DEBUG Reading reply sessionid:0x13c15a1d848003f, packet:: clientPath:null serverPath:null finished:false header:: 31,4  replyHeader:: 31,354,0  request:: '/kafka/brokers/topics/test,F  response:: #7b202230223a205b2230225d207d,s{320,320,1357689749289,1357689749289,0,1,0,0,14,1,323}  (org.apache.zookeeper.ClientCnxn)
[2013-01-08 19:55:26,252] DEBUG Partition map for /brokers/topics/test is Map(0 -> List(0)) (kafka.utils.ZkUtils$)
[2013-01-08 19:55:26,255] DEBUG Reading reply sessionid:0x13c15a1d848003f, packet:: clientPath:null serverPath:null finished:false header:: 32,4  replyHeader:: 32,354,0  request:: '/kafka/brokers/topics/test/partitions/0/leaderAndISR,F  response:: #7b2022495352223a2230222c226c6561646572223a2230222c22636f6e74726f6c6c657245706f6368223a2232222c226c656164657245706f6368223a223022207d,s{325,325,1357689749406,1357689749406,0,0,0,0,66,0,325}  (org.apache.zookeeper.ClientCnxn)
[2013-01-08 19:55:26,266] DEBUG Reading reply sessionid:0x13c15a1d848003f, packet:: clientPath:null serverPath:null finished:false header:: 33,4  replyHeader:: 33,354,0  request:: '/kafka/brokers/topics/test/partitions/0/leaderAndISR,F  response:: #7b2022495352223a2230222c226c6561646572223a2230222c22636f6e74726f6c6c657245706f6368223a2232222c226c656164657245706f6368223a223022207d,s{325,325,1357689749406,1357689749406,0,0,0,0,66,0,325}  (org.apache.zookeeper.ClientCnxn)
[2013-01-08 19:55:26,277] DEBUG replicas = List(0), in sync replicas = ArrayBuffer(0), leader = Some(0) (kafka.admin.AdminUtils$)
[2013-01-08 19:55:26,278] DEBUG Reading reply sessionid:0x13c15a1d848003f, packet:: clientPath:null serverPath:null finished:false header:: 34,4  replyHeader:: 34,354,0  request:: '/kafka/brokers/ids/0,F  response:: #3139322e3136382e322e313a393039323a39393939,s{352,352,1357692804787,1357692804787,0,0,0,88969877503082559,21,0,352}  (org.apache.zookeeper.ClientCnxn)

>>> The TopicMetadataResponse <<<
[2013-01-08 19:55:26,282] TRACE [KafkaApi-0] Sending topic metadata TopicMetadata(test,List(PartitionMetadata(0,Some(id:0,host:192.168.2.1,port:9092),List(id:0,host:192.168.2.1,port:9092),ArrayBuffer(id:0,host:192.168.2.1,port:9092),0)),0) (kafka.server.KafkaApis)

[2013-01-08 19:55:26,284] TRACE Socket server received response to send, registering for write: Response(0,Request(0,sun.nio.ch.SelectionKeyImpl@30d647d8,java.nio.HeapByteBuffer[pos=0 lim=32 cap=32],1357692926247),kafka.network.BoundedByteBufferSend@3ddfd90f) (kafka.network.Processor)
[2013-01-08 19:55:26,284] TRACE 75 bytes written to /127.0.0.1:61719 (kafka.network.Processor)
[2013-01-08 19:55:26,284] TRACE Completed request: TopicMetadataRequest(0,kafka-python,List(test),0) totalTime:37 queueTime:0 localTime:37 remoteTime:0 sendTime:0 (kafka.network.RequestChannel$)
[2013-01-08 19:55:26,285] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
[2013-01-08 19:55:26,285] DEBUG Closing connection from /127.0.0.1:61719 (kafka.network.Processor)

;;;","09/Jan/13 09:22;mumrah;This patch will return all topic metadata if none are specified in the TopicMetadataRequest. Also fixes that debug statement;;;","09/Jan/13 13:42;nehanarkhede;+1. Thanks for the patch !;;;","09/Jan/13 20:13;brugidou;this would resolve KAFKA-653;;;","09/Jan/13 21:59;mumrah;Ah, I didn't see that JIRA. I was following https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-MetadataRequest and read ""TopicName -> The topics to produce metadata for. If empty the request will yield metadata for all topics"", so I assumed this was a bug instead of a TODO;;;","10/Jan/13 00:22;jkreps;+1 Thanks David!

Folks, objections to putting this on 0.8?;;;","10/Jan/13 00:49;nehanarkhede;The protocol was meant to do this, so checked it on 0.8 branch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
./sbt publish-local fails due to invalid javac flags passed to javadoc,KAFKA-939,12652489,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,frankgrimes97,frankgrimes97,13/Jun/13 04:28,27/Sep/13 11:02,22/Mar/23 15:10,27/Sep/13 11:02,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,,,,,,Fixed by applying suggestion found here: https://groups.google.com/forum/?fromgroups#!topic/simple-build-tool/I75AODwFlH0,,charmalloc,frankgrimes97,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,332813,,,Fri Sep 27 03:02:10 UTC 2013,,,,,,,,,,"0|i1levz:",333142,,,,,,,,,,,,,,,,,,,,"13/Jun/13 04:29;frankgrimes97;diff --git a/project/Build.scala b/project/Build.scala
index f177215..ecc74d4 100644
--- a/project/Build.scala
+++ b/project/Build.scala
@@ -34,7 +34,8 @@ object KafkaBuild extends Build {
     buildNumber := System.getProperty(""build.number"", """"),
     version <<= (buildNumber, version)  { (build, version)  => if (build == """") version else version + ""+"" + build},
     releaseName <<= (name, version, scalaVersion) {(name, version, scalaVersion) => name + ""_"" + scalaVersion + ""-"" + v
-    javacOptions ++= Seq(""-Xlint:unchecked"", ""-source"", ""1.5""),
+    javacOptions in compile ++= Seq(""-Xlint:unchecked"", ""-source"", ""1.5""),
+    javacOptions in doc ++= Seq(""-source"", ""1.5""),
     parallelExecution in Test := false, // Prevent tests from overrunning each other
     libraryDependencies ++= Seq(
       ""log4j""                 % ""log4j""        % ""1.2.15"",
@@ -57,7 +58,7 @@ object KafkaBuild extends Build {
   )
 
   val hadoopSettings = Seq(
-    javacOptions ++= Seq(""-Xlint:deprecation""),
+    javacOptions in compile ++= Seq(""-Xlint:deprecation""),
     libraryDependencies ++= Seq(
       ""org.apache.avro""      % ""avro""               % ""1.4.0"",
       ""org.apache.pig""       % ""pig""                % ""0.8.0"",;;;","27/Sep/13 10:43;charmalloc;reproduced

./sbt ""++2.9.2"" clean package publish-local

[error] (hadoop-consumer/compile:doc) javadoc returned nonzero exit code
[error] (hadoop-producer/compile:doc) javadoc returned nonzero exit code
[error] (java-examples/compile:doc) javadoc returned nonzero exit code
[error] Total time: 408 s, completed Sep 26, 2013 9:12:34 PM;;;","27/Sep/13 11:00;charmalloc;+1, patches works great, committing to branch;;;","27/Sep/13 11:02;charmalloc;committed to branch;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove getAllReplicasOnBroker from KafkaController,KAFKA-1020,12665134,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,guozhang,guozhang,23/Aug/13 06:39,16/Jan/14 00:36,22/Mar/23 15:10,16/Jan/14 00:36,,,,,,,0.8.1,,,,,,,,,,,0,,,,,,"Today KafkaController call getAllReplicasOnBroker on broker failure and new broker start up to get all the replicas that broker is holding (or suppose to hold). This function actually issue a read on each topic's partition znodes. With large number of topic/partitions this could seriously increase the latency of handling broker failure and new broker startup.

On the other hand, ControllerContext maintains a partitionReplicaAssignment cache, which is designed to keep the most updated partition replica assignment according to ZK. So instead of reading from ZK, we could just read from the local cache, given that partitionReplicaAssignment is guaranteed to be up-to-date.",,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Aug/13 06:00;guozhang;KAFKA-1020.v1.patch;https://issues.apache.org/jira/secure/attachment/12600270/KAFKA-1020.v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,345075,,,Wed Jan 15 16:36:37 UTC 2014,,,,,,,,,,"0|i1ni9r:",345376,,,,,,,,,,,,,,,,,,,,"27/Aug/13 08:48;guozhang;Proposed Approach:

1. Currently the partitionReplicaAssignment cache has two point of inconsistency with the ZK data: 1) in handling replica state change to NonExistentReplica we remove the replica in partitionReplicaAssignment before we update ZK; 2) in handling replica state change from New to Online we add the replica to partitionReplicaAssignment before we update ZK. Since partitionReplicaAssignment will be updated later in ZK, we can safely remove these two updates.

2. Then we can safely change the getAllReplicasOnBroker to reading from partitionReplicaAssignment instead of from ZK.

3. Some minor issues such as comments will also be fixed in this JIRA. ;;;","16/Jan/14 00:36;junrao;Fixed as part of kafka-1202.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Metric metadata-age is reset on a failed update,KAFKA-2101,12819071,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,timbrooks,timbrooks,timbrooks,08/Apr/15 05:04,16/Jun/15 08:44,22/Mar/23 15:10,16/Jun/15 08:44,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"In org.apache.kafka.clients.Metadata there is a lastUpdate() method that returns the time the metadata was lasted updated. This is only called by metadata-age metric. 

However the lastRefreshMs is updated on a failed update (when MetadataResponse has not valid nodes). This is confusing since the metric's name suggests that it is a true reflection of the age of the current metadata. But the age might be reset by a failed update. 

Additionally, lastRefreshMs is not reset on a failed update due to no node being available. This seems slightly inconsistent, since one failure condition resets the metrics, but another one does not. Especially since both failure conditions do trigger the backoff (for the next attempt).

I have not implemented a patch yet, because I am unsure what expected behavior is.",,junrao,nehanarkhede,timbrooks,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jun/15 05:51;timbrooks;KAFKA-2101.patch;https://issues.apache.org/jira/secure/attachment/12736460/KAFKA-2101.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jun 16 00:44:28 UTC 2015,,,,,,,,,,"0|i2cxlj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"27/Apr/15 06:48;nehanarkhede;[~timbrooks] To clarify your question - we shouldn't update the metric on failed attempts. ;;;","28/Apr/15 11:18;timbrooks;Okay. Well I made a number of changes related to Metadata in Kafka-2102. One of which would resolve this issue. Essentially split last successful update from last update attempt.

I guess I will wait to see if that patch is accepted before submitting one for this card.;;;","01/Jun/15 05:51;timbrooks;Created reviewboard https://reviews.apache.org/r/34865/diff/
 against branch origin/trunk;;;","01/Jun/15 05:54;timbrooks;As I mentioned earlier, this overlaps some with the changes in Kafka-2102. However, if that patch is not accepted, the patch I submitted here will resolve this ticket.

A second long is created for last successful update. This is used in the metrics. And it is used when considering when next to update based on metadataExpireMs. Whereas right now, if there is a failed update - the backoff will be for the entire metadataExpireMs opposed to just the refreshBackoffMs time period. ;;;","16/Jun/15 08:44;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Correct cleanableRatio calculation,KAFKA-2660,12905272,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,lindong,lindong,lindong,16/Oct/15 01:35,31/Oct/15 09:14,22/Mar/23 15:10,31/Oct/15 09:14,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,There is a bug in LogToClean that causes cleanableRatio to be over-estimated.,,githubbot,junrao,lindong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Oct 31 01:14:38 UTC 2015,,,,,,,,,,"0|i2n2p3:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"16/Oct/15 01:37;githubbot;GitHub user lindong28 opened a pull request:

    https://github.com/apache/kafka/pull/316

    KAFKA-2660; Correct cleanableRatio calculation

    @onurkaraman Could you have a look? This is the patch I discussed with you.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/lindong28/kafka KAFKA-2660

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/316.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #316
    
----
commit a303ec9f87a7e1f331771a837aad03c0cf4797a5
Author: Dong Lin <lindong28@gmail.com>
Date:   2015-10-15T17:36:12Z

    KAFKA-2660; Correct cleanableRatio calculation

----
;;;","31/Oct/15 09:14;junrao;Issue resolved by pull request 316
[https://github.com/apache/kafka/pull/316];;;","31/Oct/15 09:14;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/316
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Topic partition replica got reset due to ReplicaFetcherThread request out of range,KAFKA-2243,12834946,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Duplicate,,yuyang08,yuyang08,03/Jun/15 14:43,03/Jun/15 14:53,22/Mar/23 15:10,03/Jun/15 14:52,0.8.2.1,,,,,,,,,,,,,,,,,0,,,,,,"We are running a kafka 0.8.2.1 cluster. We found that topic partition replica often got reset for replication. The following is what we usually found in the log. 
It seems that this is related to https://issues.apache.org/jira/browse/KAFKA-1806. But KAFKA-1806 has been resolved. Is this a new issue in kafka 0.8.2.1? 

[2015-06-03 05:46:40,760] ERROR [ReplicaFetcherThread-1-4069], Current offset 308834471 for partition [request_log,192] out of range; reset offset to 198327005 (kafka.server.ReplicaFetcherThread)

The following is the command line that we use for kafka: 

/usr/bin/java -Xms3g -Xmx3g -XX:NewSize=256m -XX:MaxNewSize=256m -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -Xloggc:/var/log/kafka/gc.log -Djava.awt.headless=true -Dlog4j.configuration=file:/etc/kafka/log4j.properties -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=9999 -cp :/usr/local/libs/jopt-simple-3.2.jar:/usr/local/libs/kafka-clients-0.8.2.1.jar:/usr/local/libs/kafka_2.10-0.8.2.1-javadoc.jar:/usr/local/libs/kafka_2.10-0.8.2.1-scaladoc.jar:/usr/local/libs/kafka_2.10-0.8.2.1-sources.jar:/usr/local/libs/kafka_2.10-0.8.2.1-test.jar:/usr/local/libs/kafka_2.10-0.8.2.1.jar:/usr/local/libs/log4j-1.2.16.jar:/usr/local/libs/lz4-1.2.0.jar:/usr/local/libs/metrics-core-2.2.0.jar:/usr/local/libs/scala-library-2.10.4.jar:/usr/local/libs/slf4j-api-1.7.6.jar:/usr/local/libs/slf4j-log4j12-1.6.1.jar:/usr/local/libs/snappy-java-1.1.1.6.jar:/usr/local/libs/zkclient-0.3.jar:/usr/local/libs/zookeeper-3.4.6.jar kafka.Kafka /etc/kafka/server.properties","Ubuntu 12.04.5 LTS, java version ""1.7.0_67"",  command line:

/usr/bin/java -Xms3g -Xmx3g -XX:NewSize=256m -XX:MaxNewSize=256m -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -Xloggc:/var/log/kafka/gc.log -Djava.awt.headless=true -Dlog4j.configuration=file:/etc/kafka/log4j.properties -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=9999 -cp :/usr/local/libs/jopt-simple-3.2.jar:/usr/local/libs/kafka-clients-0.8.2.1.jar:/usr/local/libs/kafka_2.10-0.8.2.1-javadoc.jar:/usr/local/libs/kafka_2.10-0.8.2.1-scaladoc.jar:/usr/local/libs/kafka_2.10-0.8.2.1-sources.jar:/usr/local/libs/kafka_2.10-0.8.2.1-test.jar:/usr/local/libs/kafka_2.10-0.8.2.1.jar:/usr/local/libs/log4j-1.2.16.jar:/usr/local/libs/lz4-1.2.0.jar:/usr/local/libs/metrics-core-2.2.0.jar:/usr/local/libs/scala-library-2.10.4.jar:/usr/local/libs/slf4j-api-1.7.6.jar:/usr/local/libs/slf4j-log4j12-1.6.1.jar:/usr/local/libs/snappy-java-1.1.1.6.jar:/usr/local/libs/zkclient-0.3.jar:/usr/local/libs/zookeeper-3.4.6.jar kafka.Kafka /etc/kafka/server.properties
",yuyang08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jun 03 06:53:21 UTC 2015,,,,,,,,,,"0|i2fk6v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"03/Jun/15 14:53;yuyang08;It seems that this issue has been reported in https://issues.apache.org/jira/browse/KAFKA-2165. Resolving this as duplicate. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka server access log does not log request details coming from a MultiProduceRequest,KAFKA-115,12519771,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,nehanarkhede,nehanarkhede,23/Aug/11 09:51,13/Sep/11 09:30,22/Mar/23 15:10,13/Sep/11 09:30,0.7,,,,,,0.7,,,,,,,,,,,0,,,,,,"the access logger logic on the kafka server has a bug, that doesn't log the individual produce request that are part of a MultiProduceRequest. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Aug/11 10:24;nehanarkhede;KAFKA-115.patch;https://issues.apache.org/jira/secure/attachment/12491301/KAFKA-115.patch","23/Aug/11 09:55;nehanarkhede;KAFKA-115.patch;https://issues.apache.org/jira/secure/attachment/12491297/KAFKA-115.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,60813,,,Tue Aug 23 02:27:54 UTC 2011,,,,,,,,,,"0|i15yzz:",242970,,,,,,,,,,,,,,,,,,,,"23/Aug/11 10:24;nehanarkhede;Please ignore the previous patch. That could lead to redundant logging.;;;","23/Aug/11 10:27;junrao;V2 looks good. +1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
README in examples not update,KAFKA-1205,12688941,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,ailzhang,ailzhang,ailzhang,15/Jan/14 13:26,18/Jan/14 00:27,22/Mar/23 15:10,18/Jan/14 00:27,0.8.0,,,,,,0.8.1,,,,,,,,,,,0,patch,,,,,The commands in the examples/README are not working. The name of the projects and the order of them have been changed.,,ailzhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jan/14 01:49;ailzhang;2.patch;https://issues.apache.org/jira/secure/attachment/12623428/2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,367908,,,Fri Jan 17 16:27:53 UTC 2014,,,,,,,,,,"0|i1rexz:",368215,,,,,,,,,,,,,,,,,,,,"17/Jan/14 00:22;junrao;Thanks for the patch. It doesn't seem to apply to trunk though.

git apply ~/Downloads/1.patch 
error: patch failed: examples/README:6
error: examples/README: patch does not apply
;;;","17/Jan/14 01:49;ailzhang;Sorry for it. This 2.patch should be working. Thanks a lot! ;;;","17/Jan/14 01:57;ailzhang;Hi Jun Rao,
Thanks a lot for your reply! I'm new to kafka and it's my first time to use
patch to commit. Have updated a new 2.patch in the issue. It should be
working.
Have a nice day!

Ailing



;;;","18/Jan/14 00:27;junrao;Thanks for patch v2. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integer overflow causes incorrect node iteration in leastLoadedNode() ,KAFKA-3014,12923103,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,hachikuji,hachikuji,hachikuji,19/Dec/15 03:14,22/Dec/15 02:54,22/Mar/23 15:10,22/Dec/15 02:54,,,,,,,0.9.0.1,,,,,,,,,,,0,,,,,,"The leastLoadedNode() implementation iterates over all the known nodes to find a suitable candidate for sending metadata. The loop looks like this:

{code}
for (int i = 0; i < nodes.size(); i++) {
  int idx = Utils.abs((this.nodeIndexOffset + i) % nodes.size());
  Node node = nodes.get(idx);
  ...
}
{code}

Unfortunately, this doesn't handle integer overflow correctly, which can result in some nodes in the list being passed over. For example, if the size of the node list is 5 and the random offset is Integer.MAX_VALUE, then the loop will iterate over the following indices: 2, 3, 2, 1, 0. 

In pathological cases, this can prevent the client from being able to connect to good nodes in order to refresh metadata.",,githubbot,guozhang,hachikuji,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Dec 21 18:54:15 UTC 2015,,,,,,,,,,"0|i2q3qv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Dec/15 03:22;ijuma;Nice catch!;;;","19/Dec/15 04:12;guozhang;This is great find!;;;","19/Dec/15 06:31;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/696

    KAFKA-3014: fix integer overflow problem in leastLoadedNode

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-3014

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/696.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #696
    
----
commit d513df5a3e732cde7576a4a126ac137045e1046c
Author: Jason Gustafson <jason@confluent.io>
Date:   2015-12-18T22:18:07Z

    KAFKA-3014: fix integer overflow problem in leastLoadedNode

----
;;;","22/Dec/15 02:54;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/696
;;;","22/Dec/15 02:54;guozhang;Issue resolved by pull request 696
[https://github.com/apache/kafka/pull/696];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Socket Leak on ReplicaFetcherThread,KAFKA-1228,12691067,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,yulrizka,yulrizka,yulrizka,25/Jan/14 00:19,31/Jan/14 02:18,22/Mar/23 15:10,31/Jan/14 02:18,0.8.0,,,,,,0.8.1,,,,,,,consumer,,,,0,,,,,,"Follow up bug on the user mailing list

http://search-hadoop.com/m/4TaT4XrcE71/possibly+leaking&subj=Possibly+leaking+socket+on+ReplicaFetcherThread

uncaught ""java.nio.channels.UnresolvedAddressException"" when trying to resolve brokers domain lead to unclose socket
","Ubuntu 12.04 64 bit
java version ""1.6.0_27""
OpenJDK Runtime Environment (IcedTea6 1.12.6) (6b27-1.12.6-1ubuntu0.12.04.4)
OpenJDK 64-Bit Server VM (build 20.0-b12, mixed mode)",junrao,pasthelod,yulrizka,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7200,7200,,0%,7200,7200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jan/14 00:36;yulrizka;KAFKA-1228-2014-01-24.patch;https://issues.apache.org/jira/secure/attachment/12625067/KAFKA-1228-2014-01-24.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,369810,,,Thu Jan 30 18:18:06 UTC 2014,,,,,,,,,,"0|i1rql3:",370112,,,,,,,,,,,,,,,,,,,,"25/Jan/14 00:34;yulrizka;Catch all exception and close the socket;;;","25/Jan/14 00:37;yulrizka;Close socket connection on any Exception;;;","25/Jan/14 01:59;junrao;Thanks for the patch. We probably should do the same on the first try, instead of just on retry. ;;;","31/Jan/14 02:18;junrao;Thanks for the patch. Made some minor changes and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix leak of child sensors on remove,KAFKA-2973,12920488,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,ijuma,ijuma,10/Dec/15 01:11,10/Dec/15 01:54,22/Mar/23 15:10,10/Dec/15 01:52,0.9.0.0,,,,,,0.10.0.0,0.9.0.1,,,,,,clients,,,,0,,,,,,"We added the ability to remove sensors from Kafka Metrics in 0.9.0.0. There is, however, a bug in how we populate the `childrenSensors` map causing us to leak some child sensors (all, but the last one added).",,githubbot,gwenshap,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Dec 09 17:52:42 UTC 2015,,,,,,,,,,"0|i2po5j:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"10/Dec/15 01:17;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/650

    KAFKA-2973; Fix issue where `childrenSensors` is incorrectly updated

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-2973-fix-leak-child-sensors-on-remove

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/650.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #650
    
----
commit ef6a543edd4c14e44b8dd660b936a7efa8aeaee0
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2015-12-09T16:39:49Z

    Fix issue where `childrenSensors` was incorrectly updated

----
;;;","10/Dec/15 01:52;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/650
;;;","10/Dec/15 01:52;gwenshap;Issue resolved by pull request 650
[https://github.com/apache/kafka/pull/650];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A fetch request in Fetch Purgatory can double count the bytes from the same delayed produce request,KAFKA-703,12627496,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,sriramsub,sriramsub,sriramsub,15/Jan/13 05:07,05/Sep/14 05:56,22/Mar/23 15:10,05/Sep/14 05:56,0.8.1,,,,,,0.8.2.0,,,,,,,purgatory,,,,0,,,,,,"When a producer request is handled, the fetch purgatory is checked to ensure any fetch requests are satisfied. When the produce request is satisfied we do the check again and if the same fetch request was still in the fetch purgatory it would end up double counting the bytes received.

Possible Solutions

1. In the delayed produce request case, do the check only after the produce request is satisfied. This could potentially delay the fetch request from being satisfied.
2. Remove dependency of fetch request on produce request and just look at the last logical log offset (which should mostly be cached). This would need the replica.fetch.min.bytes to be number of messages rather than bytes. This also helps KAFKA-671 in that we would no longer need to pass the ProduceRequest object to the producer purgatory and hence not have to consume any memory.",,guozhang,nehanarkhede,sriramsub,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1430,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,304280,,,Thu Sep 04 21:56:26 UTC 2014,,,,,,,,,,"0|i17l6v:",252402,,,,,,,,,,,,,,,,,,,,"22/Jan/13 03:31;sriramsub;Can we move this jira to the next version since we have decided to punt this?;;;","02/Feb/14 03:37;nehanarkhede;Moving to 0.8.2;;;","05/Sep/14 05:56;guozhang;This problem is resolved in the purgatory / API redesign: KAFKA-1583. Closing now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Executing scripts that invoke kafka-run-class.sh results in 'permission denied to create log dir' warning.,KAFKA-2031,12783074,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Duplicate,,mnarayan,mnarayan,19/Mar/15 08:02,19/Mar/15 09:18,22/Mar/23 15:10,19/Mar/15 08:48,0.8.1.1,,,,,,,,,,,,,packaging,,,,0,,,,,,"Kafka-run-class.sh script expects LOG_DIR variable to be set, and if this variable is not set, it defaults log dir to $base_dir/logs. And in the event the executor of the script does not have the right permissions, it would lead to errors such as:
{noformat}
mkdir: cannot create directory `/usr/lib/kafka/bin/../logs': Permission denied.
{noformat}

Proposing one way to make this more configurable is by introducing kafka-env.sh. Sourcing this file would export LOG_DIR and potentially other variables if need be.",,mnarayan,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Mar 19 01:18:43 UTC 2015,,,,,,,,,,"0|i26y9z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Mar/15 08:39;sriharsha;[~mnarayan] we've a JIRA to add kafka-env.sh here https://issues.apache.org/jira/browse/KAFKA-1566;;;","19/Mar/15 09:18;mnarayan;Great! Thanks for resolving this one.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Measured rate should not be infinite,KAFKA-2191,12829460,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,lindong,lindong,lindong,13/May/15 14:02,30/Jun/15 05:38,22/Mar/23 15:10,30/Jun/15 05:38,,,,,,,,,,,,,,,,,,0,quotas,,,,,"Rate.measure() is called, it calculates elapsed time as now - stat.oldest(now).lastWindowMs. But the stat.oldest(now) may equal now due to the way SampledStat is implemented. As a result, Rate.measure() may return Infinite. 

This bug needs to be fixed in order for quota implementation to work properly.",,guozhang,jkreps,lindong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1346,,,,,,,,,,,,,,,,,,"20/May/15 01:12;jkreps;KAFKA-2191.patch;https://issues.apache.org/jira/secure/attachment/12733874/KAFKA-2191.patch","13/May/15 23:47;lindong;KAFKA-2191.patch;https://issues.apache.org/jira/secure/attachment/12732595/KAFKA-2191.patch","14/May/15 06:32;lindong;KAFKA-2191_2015-05-13_15:32:15.patch;https://issues.apache.org/jira/secure/attachment/12732697/KAFKA-2191_2015-05-13_15%3A32%3A15.patch","14/May/15 15:34;lindong;KAFKA-2191_2015-05-14_00:34:30.patch;https://issues.apache.org/jira/secure/attachment/12732802/KAFKA-2191_2015-05-14_00%3A34%3A30.patch","28/May/15 08:28;lindong;KAFKA-2191_2015-05-27_17:28:41.patch;https://issues.apache.org/jira/secure/attachment/12735748/KAFKA-2191_2015-05-27_17%3A28%3A41.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jun 29 21:38:54 UTC 2015,,,,,,,,,,"0|i2enxr:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"13/May/15 23:47;lindong;Created reviewboard https://reviews.apache.org/r/34170/diff/
 against branch origin/trunk;;;","14/May/15 06:32;lindong;Updated reviewboard https://reviews.apache.org/r/34170/diff/
 against branch origin/trunk;;;","14/May/15 15:34;lindong;Updated reviewboard https://reviews.apache.org/r/34170/diff/
 against branch origin/trunk;;;","20/May/15 01:12;jkreps;Created reviewboard https://reviews.apache.org/r/34418/diff/
 against branch trunk;;;","20/May/15 01:13;jkreps;Hey [~lindong] here is a patch that shows what I'm thinking. Can you contrast that with what you are doing?;;;","20/May/15 12:42;guozhang;[~jjkoshy] Could you help taking a look at this one or could you give me a heads-up on the context?;;;","28/May/15 08:28;lindong;Updated reviewboard https://reviews.apache.org/r/34170/diff/
 against branch origin/trunk;;;","30/Jun/15 05:38;lindong;Merged into KAFKA-2084.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
delete topic is not working ,KAFKA-1397,12708621,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,tnachen,junrao,junrao,16/Apr/14 04:57,13/Feb/16 05:46,22/Mar/23 15:10,07/May/14 01:39,0.8.2.0,,,,,,0.8.2.0,,,,,,,,,,,2,,,,,,All unit tests are disabled since they hang transiently (see details in KAFKA-1391).,,aozeritsky,av11du@gmail.com,banoss,eidi,fullung,harisekhon,huasanyelao,ijuma,jimplush,junrao,mgharat,mrlabbe,nehanarkhede,smiklosovic,spidaman,sriharsha,stevenz3wu,tnachen,vivumail@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SAMZA-374,,,,,,,,,,"27/Apr/14 14:43;tnachen;KAFKA-1397.patch;https://issues.apache.org/jira/secure/attachment/12642115/KAFKA-1397.patch","29/Apr/14 05:48;tnachen;KAFKA-1397_2014-04-28_14:48:32.patch;https://issues.apache.org/jira/secure/attachment/12642340/KAFKA-1397_2014-04-28_14%3A48%3A32.patch","29/Apr/14 08:08;tnachen;KAFKA-1397_2014-04-28_17:08:49.patch;https://issues.apache.org/jira/secure/attachment/12642365/KAFKA-1397_2014-04-28_17%3A08%3A49.patch","01/May/14 05:55;tnachen;KAFKA-1397_2014-04-30_14:55:28.patch;https://issues.apache.org/jira/secure/attachment/12642734/KAFKA-1397_2014-04-30_14%3A55%3A28.patch","02/May/14 06:54;tnachen;KAFKA-1397_2014-05-01_15:53:57.patch;https://issues.apache.org/jira/secure/attachment/12642945/KAFKA-1397_2014-05-01_15%3A53%3A57.patch","02/May/14 09:12;tnachen;KAFKA-1397_2014-05-01_18:12:24.patch;https://issues.apache.org/jira/secure/attachment/12642979/KAFKA-1397_2014-05-01_18%3A12%3A24.patch","03/May/14 04:38;tnachen;KAFKA-1397_2014-05-02_13:38:02.patch;https://issues.apache.org/jira/secure/attachment/12643112/KAFKA-1397_2014-05-02_13%3A38%3A02.patch","06/May/14 02:18;tnachen;KAFKA-1397_2014-05-05_11:17:59.patch;https://issues.apache.org/jira/secure/attachment/12643398/KAFKA-1397_2014-05-05_11%3A17%3A59.patch","06/May/14 05:00;tnachen;KAFKA-1397_2014-05-05_14:00:29.patch;https://issues.apache.org/jira/secure/attachment/12643426/KAFKA-1397_2014-05-05_14%3A00%3A29.patch",,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,386944,,,Fri Feb 12 21:46:55 UTC 2016,,,,,,,,,,"0|i1unov:",387207,,,,,,,,,,,,,,,,,,,,"17/Apr/14 05:41;jimplush;what was the regression that caused topic deletion to stop working?

;;;","17/Apr/14 06:30;junrao;The original implementation never fully worked.;;;","27/Apr/14 14:43;tnachen;Created reviewboard https://reviews.apache.org/r/20745/
 against branch origin/trunk;;;","29/Apr/14 03:09;nehanarkhede;[~tnachen] Can you please explain the issue that your patch attempts to fix? I couldn't find anything on the JIRA or reviewboard.;;;","29/Apr/14 05:48;tnachen;Updated reviewboard https://reviews.apache.org/r/20745/
 against branch origin/trunk;;;","29/Apr/14 08:08;tnachen;Updated reviewboard https://reviews.apache.org/r/20745/
 against branch origin/trunk;;;","01/May/14 05:55;tnachen;Updated reviewboard https://reviews.apache.org/r/20745/
 against branch origin/trunk;;;","02/May/14 06:54;tnachen;Updated reviewboard https://reviews.apache.org/r/20745/
 against branch origin/trunk;;;","02/May/14 09:12;tnachen;Updated reviewboard https://reviews.apache.org/r/20745/
 against branch origin/trunk;;;","03/May/14 04:38;tnachen;Updated reviewboard https://reviews.apache.org/r/20745/
 against branch origin/trunk;;;","06/May/14 02:18;tnachen;Updated reviewboard https://reviews.apache.org/r/20745/
 against branch origin/trunk;;;","06/May/14 05:00;tnachen;Updated reviewboard https://reviews.apache.org/r/20745/
 against branch origin/trunk;;;","07/May/14 01:39;junrao;Thanks for the patch. +1 and committed to trunk.;;;","12/Apr/15 20:22;smiklosovic;I am not sure what I am doing wrong but it seems to me this does not work in 0.8.2.1

I am doing this

$ bin/zookeeper-server-start.sh config/zookeeper.properties
$ bin/kafka-server-start.sh config/server.properties
$ bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --create --topic someTopic --partitions 10 --replication-factor 1 
$ bin/kafka-topics.sh --list // gives me ""someTopic""
$ bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --delete --topic someTopic
$ bin/kafka-topics.sh --list // gives me ""someTopic - marked for deletion""

and this is there forever, even when I stop broker and zookeeper and start it once again, nothing changes, it is there forever.

I set delete.topics.enable=true in server.properties for broker;;;","12/Apr/15 21:58;sriharsha;[~smiklosovic]
It looks like you are setting the wrong property , its not ""delete.topics.enable"" . Can you try setting ""delete.topic.enable"" (topic is not plural) to true ;;;","12/Apr/15 22:22;smiklosovic;Yes it is ""delete.topic.enable"", that was my typo in the original post, the behaviour is the same. Could you confirm this?;;;","12/Apr/15 22:38;sriharsha;[~smiklosovic] I did a quick test on a single kafka 0.8.2.1 . I am not able to reproduce this it takes a bit of time but the topic gets deleted.
Just to check make sure you don't have any producer or consumer sending any requests while the delete topic is going on or just set auto.creation.topic.enable to false in server.properties

./bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test-topic                                               
Topic:test-topic        PartitionCount:10       ReplicationFactor:1     Configs:
        Topic: test-topic       Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: test-topic       Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: test-topic       Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        Topic: test-topic       Partition: 3    Leader: 0       Replicas: 0     Isr: 0
        Topic: test-topic       Partition: 4    Leader: 0       Replicas: 0     Isr: 0
        Topic: test-topic       Partition: 5    Leader: 0       Replicas: 0     Isr: 0
        Topic: test-topic       Partition: 6    Leader: 0       Replicas: 0     Isr: 0
        Topic: test-topic       Partition: 7    Leader: 0       Replicas: 0     Isr: 0
        Topic: test-topic       Partition: 8    Leader: 0       Replicas: 0     Isr: 0
        Topic: test-topic       Partition: 9    Leader: 0       Replicas: 0     Isr: 0
 ⚙ ⮀ ~/build/kafka_2.10-0.8.2.1 ⮀ 
» ./bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test-topic                                                 
Topic test-topic is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
 ⚙ ⮀ ~/build/kafka_2.10-0.8.2.1 ⮀ 
» ./bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test-topic                                              
Topic:test-topic        PartitionCount:10       ReplicationFactor:1     Configs:
        Topic: test-topic       Partition: 0    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 1    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 2    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 3    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 4    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 5    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 6    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 7    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 8    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 9    Leader: -1      Replicas: 0     Isr: 
                                                                                     
 ⚙ ⮀ ~/build/kafka_2.10-0.8.2.1 ⮀ 
» ./bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test-topic                                               
Topic:test-topic        PartitionCount:10       ReplicationFactor:1     Configs:
        Topic: test-topic       Partition: 0    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 1    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 2    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 3    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 4    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 5    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 6    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 7    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 8    Leader: -1      Replicas: 0     Isr: 
        Topic: test-topic       Partition: 9    Leader: -1      Replicas: 0     Isr: 
 ⚙ ⮀ ~/build/kafka_2.10-0.8.2.1 ⮀ 
» ./bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test-topic 

Last command doesn't show the topic .;;;","10/Sep/15 16:36;harisekhon;I've got this same issue with 0.8.2.2 and there are no consumers or producers using the topic that is remaining as marked for deletion but not disappearing from --list or --describe. I even checked I had set the correct variable delete.topic.enable=true and restarted Kafka. This is on HDP 2.3 fully kerberized.;;;","16/Oct/15 06:09;spidaman;I'm using the ASF release of 0.8.2.2 and I can confirm, topic deletion does not work.  The only way to ditch a topic is to stop the brokers, remove the directories on disk, remove the topic from zookeeper and start the brokers back up;;;","16/Oct/15 08:59;junrao;One thing that you want to make sure is that the delete.topic.enable=true property is indeed set. If you start the broker, we log all overridden properties, could you check if delete.topic.enable is there?;;;","20/Jan/16 21:50;vivumail@gmail.com;I have 0.8.2.2 version kafka and the delete topic was working fine till today(i am running this version past 1 month). I used to delete the topics at times and it was working fine. Suddenly it stopped working. After multiple restart (and delete from zookeeper client) helped me to remove few topics but 3 of them remains in the server and after a restart of both kafka and zookeeper they are back to active topic. I have ensured all the consumers and producers stopped while removing and restarting the kafka. but still this issue is still there.;;;","21/Jan/16 02:01;mgharat;Can you paste the server side logs?;;;","13/Feb/16 05:39;av11du@gmail.com;I would just like to add that I am still seeing issues deleting topics in 0.9.0. I will delete topics with kafka-topics.sh and it is set as ""Marked for Deletion"" but never gets deleted. Is this still a known issue?

On server.log I see lot's of these messages:

[2016-02-12 21:33:29,480] WARN [Replica Manager on Broker 1]: While recording the replica LEO, the partition [spiderman-pricegrabber-prices,5] hasn't been created. (kafka.server.ReplicaManager)

On state-change.log, these are samples of the llog entries for this topic after I tried to delete with kafka-topics.sh. For each of these entries, there is typically one per partition... I've just summarized.

[2016-02-12 21:02:19,585] TRACE Controller 1 epoch 234 changed state of replica 2 for partition [spiderman-pricegrabber-prices,3] from ReplicaDeletionIneligible to OfflineReplica (state.change.logger)
[2016-02-12 21:02:19,766] TRACE Controller 1 epoch 234 sending UpdateMetadata request (Leader:-2,ISR:1,3,LeaderEpoch:0,ControllerEpoch:234) to broker 1 for partition spiderman-pricegrabber-prices-5 (state.change.logger)
[2016-02-12 21:02:19,824] ERROR Controller 1 epoch 234 initiated state change of replica 2 for partition [spiderman-pricegrabber-prices,6] from OfflineReplica to ReplicaDeletionIneligible failed (state.change.logger)
java.lang.AssertionError: assertion failed: Replica [Topic=spiderman-pricegrabber-prices,Partition=6,Replica=2] should be in the ReplicaDeletionStarted states before moving to ReplicaDeletionIneligible state. Instead it is in OfflineReplica state
[2016-02-12 21:02:20,117] TRACE Controller 1 epoch 234 changed state of replica 1 for partition [spiderman-pricegrabber-prices,4] from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2016-02-12 21:02:20,131] TRACE Broker 1 deleted partition [spiderman-pricegrabber-prices,3] from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 234 with correlation id 1013 (state.change.logger)
[2016-02-12 21:02:20,132] TRACE Controller 1 epoch 234 received response {error_code=0,partitions=[{topic=spiderman-pricegrabber-prices,partition=0,error_code=0}]} for a request sent to broker Node(3, 10.108.0.105, 9092) (state.change.logger)
[2016-02-12 21:02:20,139] TRACE Broker 1 handling stop replica (delete=false) for partition [spiderman-pricegrabber-prices,5] (state.change.logger)
[2016-02-12 21:02:20,139] TRACE Broker 1 finished handling stop replica (delete=false) for partition [spiderman-pricegrabber-prices,5] (state.change.logger)
[2016-02-12 21:02:20,140] TRACE Controller 1 epoch 234 received response {error_code=0,partitions=[{topic=spiderman-pricegrabber-prices,partition=7,error_code=0}]} for a request sent to broker Node(3, 10.108.0.105, 9092) (state.change.logger)
[2016-02-12 21:02:20,151] TRACE Broker 1 handling stop replica (delete=false) for partition [spiderman-pricegrabber-prices,3] (state.change.logger)
[2016-02-12 21:02:20,151] TRACE Broker 1 finished handling stop replica (delete=false) for partition [spiderman-pricegrabber-prices,3] (state.change.logger)
[2016-02-12 21:02:20,152] TRACE Controller 1 epoch 234 received response {error_code=0,partitions=[{topic=spiderman-pricegrabber-prices,partition=3,error_code=0}]} for a request sent to broker Node(1, 10.108.0.122, 9092) (state.change.logger)
[2016-02-12 21:02:20,153] TRACE Broker 1 handling stop replica (delete=false) for partition [spiderman-pricegrabber-prices,1] (state.change.logger)
[2016-02-12 21:02:20,838] TRACE Controller 1 epoch 234 received response {error_code=0,partitions=[{topic=spiderman-pricegrabber-prices,partition=4,error_code=0}]} for a request sent to broker Node(1, 10.108.0.122, 9092) (state.change.logger)
[2016-02-12 21:02:20,838] TRACE Controller 1 epoch 234 changed state of replica 1 for partition [spiderman-pricegrabber-prices,4] from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger)
[2016-02-12 21:02:21,090] TRACE Controller 1 epoch 234 received response {error_code=0,partitions=[{topic=spiderman-pricegrabber-prices,partition=6,error_code=0}]} for a request sent to broker Node(3, 10.108.0.105, 9092) (state.change.logger)
[2016-02-12 21:02:21,090] TRACE Controller 1 epoch 234 changed state of replica 3 for partition [spiderman-pricegrabber-prices,6] from ReplicaDeletionStarted to ReplicaDeletionSuccessful (state.change.logger);;;","13/Feb/16 05:46;ijuma;There is also KAFKA-2937 which was fixed for 0.9.0.1.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KafkaProducer logs erroneous warning on startup,KAFKA-2289,12839275,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Trivial,Fixed,,hgschmie,hgschmie,20/Jun/15 07:15,23/Dec/17 04:09,22/Mar/23 15:10,20/Aug/17 00:40,0.8.2.1,,,,,,,,,,,,,clients,,,,0,,,,,,"When creating a new KafkaProducer using the 

KafkaProducer(KafkaConfig, Serializer<K>, Serializer<V>) constructor, Kafka will list the following lines, which are harmless but are still at WARN level:

WARN  [2015-06-19 23:13:56,557] org.apache.kafka.clients.producer.ProducerConfig: The configuration value.serializer = class XXXX was supplied but isn't a known config.
WARN  [2015-06-19 23:13:56,557] org.apache.kafka.clients.producer.ProducerConfig: The configuration key.serializer = class YYYY was supplied but isn't a known config.

",,bharat,githubbot,hgschmie,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Dec 22 20:09:54 UTC 2017,,,,,,,,,,"0|i2gahb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"20/Jun/15 07:20;githubbot;GitHub user hgschmie opened a pull request:

    https://github.com/apache/kafka/pull/71

    KAFKA-2289: KafkaProducer logs erroneous warning on startup

    This change fixes the problem.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hgschmie/kafka KAFKA-2289

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/71.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #71
    
----
commit ef6c0961c905d65ff8997a1ba7a09ded617b9837
Author: Henning Schmiedehausen <henning@groupon.com>
Date:   2015-06-19T23:17:38Z

    KAFKA-2289: KafkaProducer logs erroneous warning on startup
    
    This change fixes the problem.

----
;;;","20/Jun/15 07:20;hgschmie;Pull request with a fix is at https://github.com/apache/kafka/pull/71;;;","02/Jun/17 10:40;bharat;[~hgschmie] Would you like to continue to work on this?
If not, I will provide a patch based on latest trunk code.;;;","20/Aug/17 00:40;omkreddy;This has been fixed.;;;","23/Dec/17 04:09;githubbot;guozhangwang commented on issue #71: KAFKA-2289: KafkaProducer logs erroneous warning on startup
URL: https://github.com/apache/kafka/pull/71#issuecomment-353667249
 
 
   Closing for cleanup

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;","23/Dec/17 04:09;githubbot;guozhangwang closed pull request #71: KAFKA-2289: KafkaProducer logs erroneous warning on startup
URL: https://github.com/apache/kafka/pull/71
 
 
   

This is a PR merged from a forked repository.
As GitHub hides the original diff on merge, it is displayed below for
the sake of provenance:

As this is a foreign pull request (from a fork), the diff is supplied
below (as it won't show otherwise due to GitHub magic):

diff --git a/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java b/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java
index 5a37580ec69..4f10cc89bcf 100644
--- a/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java
+++ b/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java
@@ -256,6 +256,7 @@ private KafkaProducer(ProducerConfig config, Serializer<K> keySerializer, Serial
                         Serializer.class);
                 this.keySerializer.configure(config.originals(), true);
             } else {
+                config.use(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);
                 this.keySerializer = keySerializer;
             }
             if (valueSerializer == null) {
@@ -263,6 +264,7 @@ private KafkaProducer(ProducerConfig config, Serializer<K> keySerializer, Serial
                         Serializer.class);
                 this.valueSerializer.configure(config.originals(), false);
             } else {
+                config.use(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);
                 this.valueSerializer = valueSerializer;
             }
             config.logUnused();
diff --git a/clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java b/clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java
index bae528d3151..642774760e7 100644
--- a/clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java
+++ b/clients/src/main/java/org/apache/kafka/common/config/AbstractConfig.java
@@ -51,10 +51,14 @@ public AbstractConfig(ConfigDef definition, Map<?, ?> originals) {
     }
 
     protected Object get(String key) {
+        use(key);
+        return values.get(key);
+    }
+
+    public void use(String key) {
         if (!values.containsKey(key))
             throw new ConfigException(String.format(""Unknown configuration '%s'"", key));
         used.add(key);
-        return values.get(key);
     }
 
     public Short getShort(String key) {


 

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Follow-up patch of KAFKA-1650,KAFKA-2186,12829030,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,becket_qin,becket_qin,12/May/15 08:54,29/May/15 05:00,22/Mar/23 15:10,29/May/15 05:00,,,,,,,,,,,,,,,,,,0,,,,,,Offsets commit with a map was added in KAFKA-1650. It should be added to consumer connector java API also.,,becket_qin,jjkoshy,rmetzger,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/May/15 06:05;becket_qin;KAFKA-2186.patch;https://issues.apache.org/jira/secure/attachment/12734657/KAFKA-2186.patch","12/May/15 09:39;becket_qin;KAFKA-2186.patch;https://issues.apache.org/jira/secure/attachment/12732102/KAFKA-2186.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu May 28 21:00:33 UTC 2015,,,,,,,,,,"0|i2eldb:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"12/May/15 09:39;becket_qin;Created reviewboard https://reviews.apache.org/r/34070/diff/
 against branch origin/trunk;;;","13/May/15 04:53;jjkoshy;Hmm.. though this is trivial and an omission from KAFKA-1650, this is an API change. Probably not KIP-worthy but maybe warrants some discussion on the open source list?;;;","22/May/15 02:56;jjkoshy;Thanks for the patch - committed to trunk.;;;","22/May/15 05:34;jjkoshy;Reverted. Reopening due to compilation failure.;;;","22/May/15 06:05;becket_qin;Created reviewboard https://reviews.apache.org/r/34569/diff/
 against branch origin/trunk;;;","29/May/15 05:00;jjkoshy;Thanks for the patch - committed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka classpath has grown too large and breaks some system tests,KAFKA-2719,12909488,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,rsivaram,rsivaram,rsivaram,01/Nov/15 20:34,04/Nov/15 00:11,22/Mar/23 15:10,04/Nov/15 00:10,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"The jars added under KAFKA-2369 makes the Kafka command line used in system tests much higher than 4096 due to more jars in the classpath. Since the ps command used to find processes in system tests truncates the command line, some system tests are failing.",,githubbot,granders,junrao,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Nov 03 16:11:00 UTC 2015,,,,,,,,,,"0|i2nshj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"01/Nov/15 20:49;githubbot;GitHub user rajinisivaram opened a pull request:

    https://github.com/apache/kafka/pull/400

    KAFKA-2719: Use wildcard classpath for dependant-libs

    PR switches to wildcard classpath for dependant libs to restrict the length of classpath, thereby reducing command line length.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/rajinisivaram/kafka KAFKA-2719

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/400.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #400
    
----
commit f49a366334391074456859ac42059c0752bc40d2
Author: Rajini Sivaram <rajinisivaram@googlemail.com>
Date:   2015-11-01T12:40:23Z

    KAFKA-2719: Use wildcard classpath for dependant-libs to reduce command line length

----
;;;","01/Nov/15 20:55;rsivaram;PR uses wildcard classpath for dependant libs to reduce the length of CLASSPATH, thereby reducing command line length. Classpath when running using a release is not affected since the new dependency jars are not in the kafka release libs directory. 

An alternative would be to export CLASSPATH instead of using -cp option on the java command, but that would be a visible change while running kafka using the release, and could potentially break scripts which expect to match some entry in the classpath (eg. scala version).;;;","03/Nov/15 03:13;granders;[~rsivaram] I wonder if this problem is better addressed in the services rather than changes to the kafka-run-class script?
;;;","03/Nov/15 03:39;rsivaram;[~geoffra] If system tests are guaranteed to start only one java process on each VM, then services could always grep for _java_ to find processes instead of grepping for the classname as they do now (since _java_ is at the start and classname is at the end). But in general, it is useful to see what is running when you run _ps_, and not just in system tests. Hence the PR. Also, the changes to kafka-run-class.sh only change the parts of the script that are used to run from the development build, not from a release build. It felt like the simplest fix (because it is contained in one file), but I dont have a strong opinion either way.;;;","03/Nov/15 05:08;granders;[~rsivaram] Unfortunately we don't have this guarantee, for example with the addition of jmx. 
As for your change, my take is that this is probably good enough for now, and does make the classpath more legible.;;;","04/Nov/15 00:10;junrao;Issue resolved by pull request 400
[https://github.com/apache/kafka/pull/400];;;","04/Nov/15 00:11;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/400
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
UnsatisfiedLinkError causes snappy unit tests to fail on hudson server,KAFKA-504,12606971,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,jkreps,jkreps,11/Sep/12 07:56,09/Oct/12 03:19,22/Mar/23 15:10,09/Oct/12 03:19,,,,,,,,,,,,,,,,,,0,,,,,,"I am not sure why this happens. It may be that some of the hudson slaves that Apache uses aren't running Linux or x86 or it may be some bug in the library packaging. In any case, we can't assume that native libraries will always load, so I propose just making the test pass if the library is not loadable.",,charmalloc,jkreps,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Sep/12 08:09;jkreps;KAFKA-504.patch;https://issues.apache.org/jira/secure/attachment/12544565/KAFKA-504.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,241656,,,Mon Oct 08 19:19:38 UTC 2012,,,,,,,,,,"0|i029mn:",11161,,,,,,,,,,,,,,,,,,,,"11/Sep/12 08:08;jkreps;Check if snappy is loadable before running the unit test. If snappy can't be loaded, test is a no-op.;;;","11/Sep/12 08:10;jkreps;Note that I can't really test this case very well since I don't have a non-supported platform, but presumably this will fix the failing test on the test server.;;;","06/Oct/12 05:03;charmalloc;patch applies cleanly, tests passed, lets see how it goes through the CI

+1 ;;;","09/Oct/12 03:19;jkreps;Included in KAFKA-506;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Some arguments are always set to default in ProducerPerformance,KAFKA-710,12628107,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jfung,jfung,jfung,18/Jan/13 04:23,22/Jan/13 00:09,22/Mar/23 15:10,21/Jan/13 12:55,,,,,,,0.8.0,,,,,,,,,,,0,,,,,,,,jfung,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jan/13 04:26;jfung;kafka-710-v1.patch;https://issues.apache.org/jira/secure/attachment/12565370/kafka-710-v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,304958,,,Mon Jan 21 16:09:48 UTC 2013,,,,,,,,,,"0|i17x4f:",254336,,,,,,,,,,,,,,,,,,,,"18/Jan/13 04:25;jfung;The following arguments are always set to default values:
--request-num-acks
--compression-codec
--request-timeout-ms;;;","18/Jan/13 04:26;jfung;Uploaded kafka-710-v1.patch to remove the additional variables;;;","21/Jan/13 12:55;junrao;Thanks for the patch. Committed to 0.8 by adding a better description in the compress-codec option.;;;","22/Jan/13 00:09;junrao;Just to clarify. The problem is that there are duplicated command line options. After this patch, those options are still available, but work correctly.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zkclient does not show up in pom,KAFKA-91,12518343,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,cburroughs,cburroughs,cburroughs,10/Aug/11 02:27,31/Oct/11 05:42,22/Mar/23 15:10,31/Oct/11 05:42,,,,,,,0.7,,,,,,,packaging,,,,0,,,,,,"The pom from created by `make-pom`. Does not include zkclient, which is  of course a key dependency.  Not sure yet how to pull in zkclient while excluding sbt itself.

$ cat core/target/scala_2.8.0/kafka-0.7.pom  | grep -i zkclient | wc -l
0
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/11 08:37;cburroughs;k91-v1.txt;https://issues.apache.org/jira/secure/attachment/12498495/k91-v1.txt","27/Oct/11 07:55;cburroughs;k91-v2.txt;https://issues.apache.org/jira/secure/attachment/12500992/k91-v2.txt",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,49662,,,Sun Oct 30 21:40:21 UTC 2011,,,,,,,,,,"0|i15yw7:",242953,,,,,,,,,,,,,,,,,,,,"10/Aug/11 02:36;nehanarkhede;One way to do this would be to override the make-pom command in KafkaProject.scala and customize the output pom ;;;","10/Aug/11 02:59;cburroughs;Your right that's probably the best way instead of trying to do something clever and automatic with the contents of lib.  Some examples I found: http://vasilrem.com/blog/software-development/from-sbt-to-maven-in-one-move/ , https://gist.github.com/878462;;;","07/Oct/11 01:58;nehanarkhede;Moving it to 0.8;;;","11/Oct/11 08:37;cburroughs;This magic incantation appears to work.;;;","25/Oct/11 03:05;cburroughs;Could I get a review?;;;","25/Oct/11 03:15;nehanarkhede;Have we verified what other dependent jars this zkClient pulls in ? We've hit the multiple jar versions problem before.;;;","25/Oct/11 03:19;cburroughs;Our custom build of zkclient isn't in any repo and does not have a pom, so it can not pull in any dependencies.;;;","25/Oct/11 03:41;nehanarkhede;Oh, I missed that. I tried to apply the patch, but it doesn't apply on a clean checkout of the repository. Could you rebase and upload it again ?;;;","27/Oct/11 07:55;cburroughs;Sorry missed your reply, rebased as of 76957e5e3a748b59525e5e7934f93721eb8f4c38;;;","31/Oct/11 05:40;nehanarkhede;+1. Just committed this, but realized you could've done it yourself.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gradle issues for release,KAFKA-1243,12694113,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,,joestein,joestein,09/Feb/14 01:59,20/Feb/14 13:15,22/Mar/23 15:10,20/Feb/14 13:15,0.8.1,,,,,,0.8.1,,,,,,,,,,,0,,,,,,This is the parent issue for all of the sub tasks found for the release that are required to update on gradle.  I think some of the changes are going to be minor and in some cases not blockers but there are a bunch of them so we can identify each minuscule item but have it a bit organized.,,clarkbreyman,joestein,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Feb/14 07:25;junrao;KAFKA-1243.patch;https://issues.apache.org/jira/secure/attachment/12628105/KAFKA-1243.patch","12/Feb/14 05:37;junrao;KAFKA-1243_2014-02-11_13:37:25.patch;https://issues.apache.org/jira/secure/attachment/12628340/KAFKA-1243_2014-02-11_13%3A37%3A25.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,372622,,,Thu Feb 20 05:15:19 UTC 2014,,,,,,,,,,"0|i1s7sv:",372926,,,,,,,,,,,,,,,,,,,,"11/Feb/14 07:25;junrao;Created reviewboard https://reviews.apache.org/r/17923/
 against branch origin/trunk;;;","11/Feb/14 07:40;junrao;I made a pass of this jira and fixed the following.
1. added LICENSE and NOTICE file to all built jars (KAFKA-1244)
2. removed ""-dist"" from release tgz file (KAFKA-1249)
3. removed the step ""./gradlew copyDependantLibs"" by making it a dependency of ""./gradlew core:jar""

KAFKA-1246: There is no scala 2.10 release. The released ones are 2.10.1, 2.10.2, 2.10.3, etc. So, there shouldn't be a kafka jar for scala 2.10. What we are doing now in gradle seems correct.

KAFKA-1248: I don't think those jars (include the test jar) need to be in maven. We can build a test jar for local testing though.

Joe,

I am not so sure about KAFKA-121. The pom file generated by gradle does have license, url and group id. What else do you think are needed?

KAFKA-1254: Once we addressed all sub-jiras, we can remove sbt.;;;","12/Feb/14 05:37;junrao;Updated reviewboard https://reviews.apache.org/r/17923/
 against branch origin/trunk;;;","12/Feb/14 05:49;junrao;KAFKA-1246: It seems that the sbt way is correct. The reason is that all scala 2.10.* versions are both forward and backward compatible. So, we just need to publish one version of artifact with suffix 2.10 (i.e., w/o minor revision #).

Attach another patch to address this issue.;;;","13/Feb/14 00:33;junrao;Double committed my patch to 0.8.1 and trunk. Will close kafka-1244, kafka-1246 and kafka-1249.

Joe,

Could you rebase your patch kafka-1245 and comment on what we should do for kafka-121?;;;","13/Feb/14 01:02;joestein;Thanks Jun! Sorry I have been swamped the last few days.  KAFKA-121 was there just so folks could review the POM as it is now and I agree with you it looks good so I resolved that ticket.  I will rebase 1245 and give another release dry run through hopefully later today/tonight/tomorrow.  Thanks!;;;","14/Feb/14 08:03;clarkbreyman;Perhaps this is worthy of a separate ticket, but the generated jar files do not include a META-INF/maven/ directory tree or pom. This is different from what would be expected if the artifact were generated from maven. ;;;","15/Feb/14 03:06;junrao;Clark,

Is this needed to 0.8.1? If not, could you open a separate jira to track it?

Thanks,;;;","15/Feb/14 04:27;clarkbreyman;Jun - Nice to have but if it doesn't make the train that's ok. The SBT/IVY jars had the same problem. I'll file a separate ticket. ;;;","15/Feb/14 04:55;clarkbreyman;KAFKA-1265 has the addMavenDescriptor compatibility issues. ;;;","20/Feb/14 13:15;joestein;everything related to this has been taken care of and is committed to 0.8.1 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Publishing kafka-client:test in order to utilize the helper utils in TestUtils,KAFKA-1861,12767337,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,omkreddy,navina,navina,14/Jan/15 10:07,29/Jan/15 09:41,22/Mar/23 15:10,29/Jan/15 09:41,,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"Related to SAMZA-227 (Upgrade KafkaSystemProducer to new java-based Kafka API)
Turns out that some of the utilities that are helpful in writing unit tests are available in org.apache.kafka.test.TestUtils.java (:kafka-clients). This is not published to maven repository. Hence, we are forced to reproduce the same code in samza. This can be avoided if the test package is published to the Maven repo.

For example, we are creating a customize MockProducer to be used in Samza unit-tests and access to these quick helper utils will be useful.
",,jkreps,junrao,navina,nehanarkhede,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jan/15 02:05;omkreddy;KAFKA-1861.patch;https://issues.apache.org/jira/secure/attachment/12693653/KAFKA-1861.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jan 29 01:41:00 UTC 2015,,,,,,,,,,"0|i24cef:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"15/Jan/15 01:29;jkreps;Hey [~navina] we can definitely publish the jar but it won't necessarily have stable APIs. That is, we may refactor release to release. Is that a problem?;;;","15/Jan/15 04:03;navina;[~jkreps] : That should be ok, I guess. Samza can upgrade the jar version whenever necessary. For now, it will be useful to just have the existing test jar published. 
;;;","22/Jan/15 02:05;omkreddy;Created reviewboard https://reviews.apache.org/r/30128/diff/
 against branch origin/0.8.2;;;","22/Jan/15 02:09;omkreddy;Can we include this simple patch to 0.8.2? So that SAMZA developers can use it.;;;","26/Jan/15 09:48;nehanarkhede;[~navina] Can you please see if the above patch gets you the jar? ;;;","26/Jan/15 22:17;omkreddy;We already have kafka-client-test jar. This patch includes the kafka-client-test jar to be part of maven artifacts.   We need to run  ./gradlew uploadArchivesAll  to upload to maven repository.
;;;","27/Jan/15 02:10;navina;[~nehanarkhede] I don't see it maven central. Looks like it has not been published to the repo.

[~omkreddy] Thanks for doing this!;;;","29/Jan/15 02:17;omkreddy;[~junrao] we can include this is 0.8.2 RC3;;;","29/Jan/15 09:41;junrao;Thanks for the patch. +1. Committed to 0.8.2 and trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Can't leave comments in Confluence,KAFKA-2037,12783772,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,soid,soid,21/Mar/15 06:07,21/Mar/15 06:45,22/Mar/23 15:10,21/Mar/15 06:43,,,,,,,,,,,,,,website,,,,0,,,,,,"I create this jira issue related to Confluence because I've read the message ""THIS WIKI HAS MOVED TO A NEW HOME - REPORT ANY ISSUES WITH AN JIRA TICKET !!!"" on confluence.

I wanted to leave a comment on the page https://cwiki.apache.org/confluence/display/KAFKA/Developer+Setup but I don't have the permission. I think it's a bug. 

My newly created user id is ""soid""",,junrao,soid,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Mar 20 22:45:08 UTC 2015,,,,,,,,,,"0|i272iv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Mar/15 06:43;junrao;Just granted you the permission to Kafka wiki.;;;","21/Mar/15 06:45;soid;Should the permission be granted to all new users? ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
StateStore seems to be writing state to one topic but restoring from another,KAFKA-3207,12936758,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,guozhang,tom_dearman,tom_dearman,04/Feb/16 23:27,05/Feb/16 06:51,22/Mar/23 15:10,05/Feb/16 06:51,0.10.0.0,,,,,,0.10.0.0,,,,,,,streams,,,,0,,,,,,"The state store (I am using in-memory state store) writes to a topic call [store-name] but restores from [job-id]-[store-name]-changelog.  You can see in StoreChangeLogger that it writes to a topic which is the [store-name] passed through from the store supplier factory, but restores from the above topic name. My topology is:
		TopologyBuilder builder = new TopologyBuilder();

		SerializerAdapter<CommonKey> commonKeyAdapter = new SerializerAdapter<>(JDKBinarySerializer.INSTANCE);
		SerializerAdapter<GamePlayValue> gamePlayAdapter = new SerializerAdapter<>(JDKBinarySerializer.INSTANCE);
		builder.addSource(""SOURCE"", commonKeyAdapter, gamePlayAdapter, kafkaStreamConfig.getGamePlayTopic());

		Duration activityInterval = kafkaStreamConfig.getActivityInterval();
		if (activityInterval.toMinutes() % 5 != 0 || 24 * 60 % activityInterval.toMinutes() != 0)
		{
			throw new SystemFaultException(
				""The game activity interval must be a multiple of 5 minutes and divide into 24 hours current value ["" +
					activityInterval.toMinutes() + ""]"");
		}
		builder.addProcessor(""PROCESS"", new GameActivitySupplier(kafkaStreamConfig.getStoreName(),
		                                                         kafkaStreamConfig.getGameActivitySendPeriod(),
		                                                         activityInterval,
		                                                         kafkaStreamConfig.getRemoveOldestTime(),
		                                                         kafkaStreamConfig.getRemoveAbsoluteTime()), ""SOURCE"");

		SerializerAdapter<StoreValue> storeValueAdapter = new SerializerAdapter<>(JDKBinarySerializer.INSTANCE);
		builder.addStateStore(
			Stores.create(kafkaStreamConfig.getStoreName()).withKeys(commonKeyAdapter, commonKeyAdapter).withValues(
				storeValueAdapter, storeValueAdapter).inMemory().build(), ""PROCESS"");

		builder.addSink(""SINK"", kafkaStreamConfig.getGameActivityTopic(), commonKeyAdapter,
		                new SerializerAdapter<GameActivityTotalMessage>(JDKBinarySerializer.INSTANCE), ""PROCESS"");
",MacOS El Capitan,githubbot,guozhang,tom_dearman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Feb 04 22:51:45 UTC 2016,,,,,,,,,,"0|i2sffr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"05/Feb/16 02:13;githubbot;GitHub user guozhangwang opened a pull request:

    https://github.com/apache/kafka/pull/865

    KAFKA-3207: Fix StateChangeLogger to use the right topic name

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/guozhangwang/kafka K3207

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/865.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #865
    
----
commit 0e6392cfa51d9ba0cc1abb9052abdff3316cec74
Author: Guozhang Wang <wangguoz@gmail.com>
Date:   2016-02-04T18:13:05Z

    fis StateChangeLogger to use the right topic name

----
;;;","05/Feb/16 02:17;guozhang;[~tom_dearman] I have uploaded  a patch in the above PR, could you try to apply it and see if it solves your problem when you got time? Thanks.;;;","05/Feb/16 06:51;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/865
;;;","05/Feb/16 06:51;guozhang;Issue resolved by pull request 865
[https://github.com/apache/kafka/pull/865];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Producer using broker list does not load balance requests across multiple partitions on a broker,KAFKA-161,12527665,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,19/Oct/11 05:58,25/Oct/11 12:59,22/Mar/23 15:10,25/Oct/11 12:59,0.7,,,,,,0.7,,,,,,,,,,,0,,,,,,"https://issues.apache.org/jira/browse/KAFKA-129 introduced a bug in the load balancing logic of the Producer using broker.list.
Since the broker.list doesn't specify the number of partitions in total, it should ideally pick a broker randomly, and then send the produce request with partition id -1, so that the EventHandler routes the request to a random partition.
Instead of that, it defaults to 1 partition on each broker and ends up using the Partitioner to pick a partitions amongst the available ones.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Oct/11 03:41;nehanarkhede;KAFKA-161.patch;https://issues.apache.org/jira/secure/attachment/12499914/KAFKA-161.patch","21/Oct/11 01:34;nehanarkhede;KAFKA-161.patch;https://issues.apache.org/jira/secure/attachment/12499897/KAFKA-161.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,88925,,,Thu Oct 20 23:51:23 UTC 2011,,,,,,,,,,"0|i15z8f:",243008,,,,,,,,,,,,,,,,,,,,"21/Oct/11 01:34;nehanarkhede;Fixing the load balancing strategy for the broker.list option on the Producer. With this change, when broker.list is used, the producer will pick a random broker and send request to partition -1 on that broker.;;;","21/Oct/11 02:53;junrao;1. We should guard logger.debug with the isDebugEnabled check.
2. The method name getNumPartitionsForTopic is misleading since the return value is a list of partitions, instead of number of partitions. Can we rename it to sth like getPartitionListForTopic? Ditto for the name of the variable being assigned to.
;;;","21/Oct/11 03:41;nehanarkhede;1. Guarded the logger.debug
2. Changed the names of variables and functions to make more sense;;;","21/Oct/11 07:51;junrao;+1 on the new patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incomplete message set validation checks in kafka.log.Log's append API can corrupt on disk log,KAFKA-310,12547095,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,nehanarkhede,nehanarkhede,nehanarkhede,20/Mar/12 05:33,23/Mar/12 00:04,22/Mar/23 15:10,23/Mar/12 00:04,0.7,,,,,,,,,,,,,,,,,0,,,,,,"The behavior of the ByteBufferMessageSet's iterator is to ignore and return false if some trailing bytes are found that cannot be de serialized into a Kafka message. The append API in Log, iterates through a ByteBufferMessageSet and validates the checksum of each message. Though, while appending data to the log, it just uses the underlying ByteBuffer that forms the ByteBufferMessageSet. Now, due to some bug, if the ByteBuffer has some trailing data, that will get appended to the on-disk log too. This can cause corruption of the log.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-308,,,,,"22/Mar/12 23:42;nehanarkhede;kafka-310-v2.patch;https://issues.apache.org/jira/secure/attachment/12519452/kafka-310-v2.patch","22/Mar/12 07:23;nehanarkhede;kafka-310.patch;https://issues.apache.org/jira/secure/attachment/12519362/kafka-310.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,232253,,,Thu Mar 22 16:04:26 UTC 2012,,,,,,,,,,"0|i0rsb3:",160230,,,,,,,,,,,,,,,,,,,,"20/Mar/12 05:34;nehanarkhede;This can potentially cause the log corruption described in KAFKA-308;;;","22/Mar/12 07:23;nehanarkhede;In this patch, Log's append API truncates the ByteBufferMessageSet to validBytes before appending its backing byte buffer to the FileChannel.;;;","22/Mar/12 23:26;junrao;ByteBufferMessageSet.validBytes currently makes a deep iteration of all messages, which means that we need to decompress messages. To avoid this overhead, we should change ByteBufferMessageSet.validBytes to use a shallow iterator.;;;","22/Mar/12 23:42;nehanarkhede;That's true. This was probably overlooked KAFKA-277. Fixed it and uploaded v2.;;;","23/Mar/12 00:00;junrao;+1 on v2.;;;","23/Mar/12 00:04;nehanarkhede;Thanks for the review. Committed this to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Exception in KafkaScheduler while shutting down,KAFKA-1596,12734257,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,jjkoshy,jjkoshy,15/Aug/14 05:23,25/Feb/15 01:19,22/Mar/23 15:10,25/Feb/15 01:19,,,,,,,,,,,,,,,,,,0,newbie,,,,,"Saw this while trying to reproduce KAFKA-1577. It is very minor and won't happen in practice but annoying nonetheless.

{code}
[2014-08-14 18:03:56,686] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2014-08-14 18:03:56,776] INFO Loading logs. (kafka.log.LogManager)
[2014-08-14 18:03:56,783] INFO Logs loading complete. (kafka.log.LogManager)
[2014-08-14 18:03:57,120] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2014-08-14 18:03:57,124] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2014-08-14 18:03:57,158] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2014-08-14 18:03:57,160] INFO [Socket Server on Broker 0], Started (kafka.network.SocketServer)
^C[2014-08-14 18:03:57,203] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2014-08-14 18:03:57,211] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2014-08-14 18:03:57,222] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[2014-08-14 18:03:57,226] INFO [Replica Manager on Broker 0]: Shut down (kafka.server.ReplicaManager)
[2014-08-14 18:03:57,228] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2014-08-14 18:03:57,233] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2014-08-14 18:03:57,274] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[2014-08-14 18:03:57,276] INFO Shutting down. (kafka.log.LogManager)
[2014-08-14 18:03:57,296] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2014-08-14 18:03:57,297] INFO Shutdown complete. (kafka.log.LogManager)
[2014-08-14 18:03:57,301] FATAL Fatal error during KafkaServerStable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
java.lang.IllegalStateException: Kafka scheduler has not been started
        at kafka.utils.KafkaScheduler.ensureStarted(KafkaScheduler.scala:114)
        at kafka.utils.KafkaScheduler.schedule(KafkaScheduler.scala:95)
        at kafka.server.ReplicaManager.startup(ReplicaManager.scala:138)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:112)
        at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:28)
        at kafka.Kafka$.main(Kafka.scala:46)
        at kafka.Kafka.main(Kafka.scala)
[2014-08-14 18:03:57,324] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2014-08-14 18:03:57,326] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2014-08-14 18:03:57,329] INFO Session: 0x147d5b0a51a0000 closed (org.apache.zookeeper.ZooKeeper)
[2014-08-14 18:03:57,329] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[2014-08-14 18:03:57,329] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
{code}",,guozhang,jjkoshy,nehanarkhede,pachalko,shroman,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1724,,,,,,,,,,,,,,,,,,"29/Aug/14 19:31;pachalko;kafka-1596.patch;https://issues.apache.org/jira/secure/attachment/12665318/kafka-1596.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,412197,,,Tue Feb 24 17:19:00 UTC 2015,,,,,,,,,,"0|i1ywtj:",412186,,jjkoshy,,,,,,,,,,,,,,,,,,"29/Aug/14 19:30;pachalko;Suppressed the exception when trying to shutdown already downed scheduler;;;","29/Aug/14 19:31;pachalko;Patch attached;;;","30/Aug/14 00:44;guozhang;Thanks for the patch Pirotr. But I am still trying to figure out the root cause of this exception though. Since the socket server is started after the kafka scheduler, and from the logs 

{code}
[2014-08-14 18:03:57,160] INFO [Socket Server on Broker 0], Started (kafka.network.SocketServer)
{code}

It seems the socket server has already started, and hence kafka scheduler should also be started already. So why it will still fail in ""ensureStarted""? [~jjkoshy] could you describe a bit here?;;;","15/Sep/14 09:55;nehanarkhede;[~jjkoshy], [~pachalko] Bump. Same question as [~guozhang].;;;","21/Jan/15 05:06;sriharsha;[~nehanarkhede] [~guozhang] looks like KAFKA-1724 is a duplicate of this. I have details on how it happens on that JIRA and steps to reproduce.  This is easy to reproduce in single-host env.  We have two instances of KafkaScheduler being initiated one in KafkaBroker and another one in KafkaController.autoRebalanceScheduler.  KafkaBroker.kafkaScheduler will start initially but incase if the broker is the controller and before it starts up, if there is onControllerResignation gets called due to zookeeper watcher it calls KafkaScheduler.shutdown() which is not started yet causing above exception to be thrown.  More details are under  the reviewboard here https://reviews.apache.org/r/28027/ . Please check my comments there.;;;","25/Feb/15 01:19;sriharsha;This is issue is already fixed as part of KAFKA-1760.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Delete temporary data directory after unit test finishes,KAFKA-1258,12694579,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,omkreddy,guozhang,guozhang,12/Feb/14 03:59,17/May/16 22:14,22/Mar/23 15:10,13/Jul/14 03:50,,,,,,,0.8.2.0,,,,,,,,,,,0,newbie,,,,,"Today in unit testsuite most of the time when a test case is setup a temporary directory will be created with a random int as suffix, and will not be deleted after the test. After a few unit tests this will create tons of directories in java.io.tmpdir (/tmp for Linux). Would be better to remove them for clean unit tests.",,guozhang,jkreps,omkreddy,sriramsub,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jul/14 18:38;omkreddy;KAFKA-1258.patch;https://issues.apache.org/jira/secure/attachment/12655377/KAFKA-1258.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,373087,,,Sat Jul 12 19:50:39 UTC 2014,,,,,,,,,,"0|i1samv:",373388,,,,,,,,,,,,,,,,,,,,"12/Feb/14 05:00;jkreps;Yeah this annoys me too. The core problem is that java provides File.deleteOnExit but this doesn't work for directories. Instead what we should do is change TestUtils.createTempDir to add a shutdown hook that deletes the directory recursively.;;;","12/Feb/14 14:43;sriramsub;Look into http://junit.org/javadoc/4.9/org/junit/rules/TemporaryFolder.html. Helps to manage temp folders in junit. It may be supported only in java 7. ;;;","12/Jul/14 18:38;omkreddy;Created reviewboard https://reviews.apache.org/r/23439/diff/
 against branch origin/trunk;;;","12/Jul/14 18:46;omkreddy;Junit 4.7 can be used to manage temporary folders. But this  requires
changes in all the test cases and some base test classes.

Submitted patch by adding shutdown hook to TestUtils.tempDir method.;;;","13/Jul/14 03:50;jkreps;Committed. Thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
missing import util.parsing.json.JSON,KAFKA-1874,12768227,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,sreevaddi,sreevaddi,18/Jan/15 00:00,20/Jan/15 09:01,22/Mar/23 15:10,20/Jan/15 09:01,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,class,missing,scala,,,"core project
main scala folder
kafka.utils.Json.scala file

line#21
import util.parsing.json.JSON

this class is missing.
","Mac OSX Yosemite
Oracle JDK 1.7.0_72
eclipse Mars M4
Scala 2.11.5",junrao,omkreddy,sreevaddi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jan/15 07:16;sreevaddi;Screen Shot 2015-01-17 at 3.14.33 PM.png;https://issues.apache.org/jira/secure/attachment/12692942/Screen+Shot+2015-01-17+at+3.14.33+PM.png",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jan 20 01:00:55 UTC 2015,,,,,,,,,,"0|i24hnb:",9223372036854775807,,omkreddy,,,,,,,,,,,,,,,,,,"18/Jan/15 00:18;omkreddy;I'm not sure if I understand your question. Can you elaborate?.  util.parsing.json.JSON is part of scala-library.jar;;;","18/Jan/15 07:16;sreevaddi;[~omkreddy]
screenshot of the compilation error.
;;;","20/Jan/15 03:01;junrao;You need to add the dependency to scala-parser-combinators_2.11.;;;","20/Jan/15 09:00;sreevaddi;[~junrao] [~omkreddy] This fixes it.

kafka/gradle.properties
scalaVersion=2.11.5 ===> change it from 2.10.4

project 'core' -> right click -> Scala -> Restart Presentation Compiler.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unit Test BUILD FAILED,KAFKA-2361,12849078,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jinxing6042@126.com,wangbo23,wangbo23,25/Jul/15 17:40,27/Nov/15 14:57,22/Mar/23 15:10,19/Nov/15 12:06,0.8.2.1,,,,,,,,,,,,,unit tests,,,,0,,,,,,"290 tests completed, 2 failed :



kafka.api.ProducerFailureHandlingTest > testNotEnoughReplicasAfterBrokerShutdown FAILED
    org.scalatest.junit.JUnitTestFailedError: Expected NotEnoughReplicasException when producing to topic with fewer brokers than min.insync.replicas
        at org.scalatest.junit.AssertionsForJUnit$class.newAssertionFailedException(AssertionsForJUnit.scala:101)
        at org.scalatest.junit.JUnit3Suite.newAssertionFailedException(JUnit3Suite.scala:149)
        at org.scalatest.Assertions$class.fail(Assertions.scala:711)
        at org.scalatest.junit.JUnit3Suite.fail(JUnit3Suite.scala:149)
        at kafka.api.ProducerFailureHandlingTest.testNotEnoughReplicasAfterBrokerShutdown(ProducerFailureHandlingTest.scala:355)

kafka.server.ServerShutdownTest > testCleanShutdownAfterFailedStartup FAILED
    org.scalatest.junit.JUnitTestFailedError: Expected KafkaServer setup to fail with connection exception but caught a different exception.
        at org.scalatest.junit.AssertionsForJUnit$class.newAssertionFailedException(AssertionsForJUnit.scala:101)
        at org.scalatest.junit.JUnit3Suite.newAssertionFailedException(JUnit3Suite.scala:149)
        at org.scalatest.Assertions$class.fail(Assertions.scala:711)
        at org.scalatest.junit.JUnit3Suite.fail(JUnit3Suite.scala:149)
        at kafka.server.ServerShutdownTest.testCleanShutdownAfterFailedStartup(ServerShutdownTest.scala:136)",Linux,githubbot,jinxing6042@126.com,wangbo23,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,172800,172800,,0%,172800,172800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 27 06:57:22 UTC 2015,,,,,,,,,,"0|i2hxe7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Nov/15 11:48;githubbot;GitHub user ZoneMayor opened a pull request:

    https://github.com/apache/kafka/pull/558

    KAFKA-2361: unit test failure in ProducerFailureHandlingTest.testNotE…

    the same issue stated at https://issues.apache.org/jira/browse/KAFKA-1999, but on branch 0.8.2, still not fixed @junrao 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ZoneMayor/kafka 0.8.2

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/558.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #558
    
----
commit da1d0d88cd4fd8819b2bbc1068a4473062a041e9
Author: jinxing <jinxing@fenbi.com>
Date:   2015-11-19T03:42:05Z

    KAFKA-2361: unit test failure in ProducerFailureHandlingTest.testNotEnoughReplicasAfterBrokerShutdown

----
;;;","21/Nov/15 15:18;githubbot;Github user ZoneMayor closed the pull request at:

    https://github.com/apache/kafka/pull/558
;;;","21/Nov/15 15:21;githubbot;GitHub user ZoneMayor opened a pull request:

    https://github.com/apache/kafka/pull/571

    KAFKA-2361: unit test failure in ProducerFailureHandlingTest.testNotE…

    same issue with KAFKA-1999, so I want to fix it
    https://issues.apache.org/jira/browse/KAFKA-1999

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ZoneMayor/kafka 0.8.2

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/571.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #571
    
----
commit da1d0d88cd4fd8819b2bbc1068a4473062a041e9
Author: jinxing <jinxing@fenbi.com>
Date:   2015-11-19T03:42:05Z

    KAFKA-2361: unit test failure in ProducerFailureHandlingTest.testNotEnoughReplicasAfterBrokerShutdown

----
;;;","27/Nov/15 14:57;githubbot;Github user ZoneMayor closed the pull request at:

    https://github.com/apache/kafka/pull/571
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Running a consumer client using scala 2.8 fails,KAFKA-287,12544314,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,elben,elben,28/Feb/12 05:24,08/Feb/15 07:52,22/Mar/23 15:10,08/Feb/15 07:52,,,,,,,,,,,,,,,,,,0,,,,,,"Built the kafka library using the instructions found in the README. My client uses scala 2.9.1, sbt 0.11. My consumer client has this snippet of code: https://gist.github.com/a35006cc25e39ba386e2

The client compiles, but running it produces this stacktrace: https://gist.github.com/efeb85f50402b477d6e0

I think this may be because of a bug found in scala 2.9.0 (though I'm not sure if it was present in scala 2.8.0): https://issues.scala-lang.org/browse/SI-4575

To get around this, I built the kafka library using scala 2.9.1 (by changing build.properties).","Java 1.6, OS X",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,229551,,,Tue Feb 28 20:20:20 UTC 2012,,,,,,,,,,"0|i029wf:",11205,,,,,,,,,,,,,,,,,,,,"29/Feb/12 04:20;charmalloc;I run Kafka in production using Scala 2.9.1 changing build.properties and creating a new build

I run sbt 11.2 for all of my code but use the existing sbt in the Kafka project for building kafka.

KAFKA-134 tries to address an upgrade to 0.10.1 which I tried once but ran into an issue.  we should look at KAFKA-134 and making it be 11.2 (should not be much more than what was already in 0.10.1 changes)

do you want to take a look into KAFKA-134 ? I can review when you are done..   I think this ticket though is covered in KAFKA-134 changes.

the workaround is exactly what you did, change build.properties to 2.9.1 and rebuild.  works great just some warnings otherwise have no issue in production;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testUnreachableServer sporadically fails,KAFKA-146,12525615,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,nehanarkhede,cburroughs,cburroughs,04/Oct/11 10:09,06/Oct/11 04:29,22/Mar/23 15:10,06/Oct/11 04:29,,,,,,,0.7,,,,,,,,,,,0,,,,,,"(If anyone can tell me how to convince Jira to do verbatim output,  I would be grateful)

This seems to fail about 50% of the time on builds.apache.org, also reported by Bao Thai Ngo on the -dev list.  I have not had success reproducing it locally on my Ubuntu laptop.

[0m[[0minfo[0m] [34m[0m
[0m[[0minfo[0m] [34m== core-kafka / kafka.javaapi.producer.SyncProducerTest ==[0m
[0m[[0minfo[0m] [0mTest Starting: testUnreachableServer[0m
First message send retries took 365 ms
[0m[[31merror[0m] [0mTest Failed: testUnreachableServer[0m
junit.framework.AssertionFailedError: null
	at junit.framework.Assert.fail(Assert.java:47)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at junit.framework.Assert.assertTrue(Assert.java:27)
	at kafka.javaapi.producer.SyncProducerTest.testUnreachableServer(SyncProducerTest.scala:75)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.internal.runners.TestMethodRunner.executeMethodBody(TestMethodRunner.java:99)
	at org.junit.internal.runners.TestMethodRunner.runUnprotected(TestMethodRunner.java:81)
	at org.junit.internal.runners.BeforeAndAfterRunner.runProtected(BeforeAndAfterRunner.java:34)
	at org.junit.internal.runners.TestMethodRunner.runMethod(TestMethodRunner.java:75)
	at org.junit.internal.runners.TestMethodRunner.run(TestMethodRunner.java:45)
	at org.junit.internal.runners.TestClassMethodsRunner.invokeTestMethod(TestClassMethodsRunner.java:71)
	at org.junit.internal.runners.TestClassMethodsRunner.run(TestClassMethodsRunner.java:35)
	at org.junit.internal.runners.TestClassRunner$1.runUnprotected(TestClassRunner.java:42)
	at org.junit.internal.runners.BeforeAndAfterRunner.runProtected(BeforeAndAfterRunner.java:34)
	at org.junit.internal.runners.TestClassRunner.run(TestClassRunner.java:52)
	at org.junit.internal.runners.CompositeRunner.run(CompositeRunner.java:29)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:121)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:100)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:91)
	at org.scalatest.junit.JUnitSuite$class.run(JUnitSuite.scala:261)
	at kafka.javaapi.producer.SyncProducerTest.run(SyncProducerTest.scala:33)
	at org.scalatest.tools.ScalaTestFramework$ScalaTestRunner.run(ScalaTestFramework.scala:40)
	at sbt.TestRunner.run(TestFramework.scala:53)
	at sbt.TestRunner.runTest$1(TestFramework.scala:67)
	at sbt.TestRunner.run(TestFramework.scala:76)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11.runTest$2(TestFramework.scala:194)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)
	at sbt.NamedTestTask.run(TestFramework.scala:92)
	at sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)
	at sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)
	at sbt.TaskManager$Task.invoke(TaskManager.scala:62)
	at sbt.impl.RunTask.doRun$1(RunTask.scala:77)
	at sbt.impl.RunTask.runTask(RunTask.scala:85)
	at sbt.impl.RunTask.sbt$impl$RunTask$$runIfNotRoot(RunTask.scala:60)
	at sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)
	at sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)
	at sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)
	at sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)
	at sbt.Control$.trapUnit(Control.scala:19)
	at sbt.Distributor$Run$Worker.run(ParallelRunner.scala:131)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Oct/11 09:39;nehanarkhede;KAFKA-146.patch;https://issues.apache.org/jira/secure/attachment/12497739/KAFKA-146.patch","05/Oct/11 06:50;nehanarkhede;KAFKA-146.patch;https://issues.apache.org/jira/secure/attachment/12497722/KAFKA-146.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,43994,,,Wed Oct 05 20:29:38 UTC 2011,,,,,,,,,,"0|i15z5r:",242996,,,,,,,,,,,,,,,,,,,,"05/Oct/11 06:50;nehanarkhede;This test keeps failing on and off on Mac boxes as well. Basically, it is written to test the producer reconnect timeout, so it is timing dependent. I think we should clean all unit tests that have a timing dependency. 

For this ticket, I've attached a patch that deletes these tests from the unit test suite. ;;;","05/Oct/11 09:12;junrao;It seems that the problem is caused by this assertion: Assert.assertTrue((firstEnd-firstStart) < 300). However, I don't see too much value of these 2 tests and would agree that they can be removed. We should also remove the same tests in javaapi too.
.;;;","05/Oct/11 09:39;nehanarkhede;Deleted those tests from kafka.producer.SyncProducerTest as well as kafka.javaapi.producer.SyncProducerTest;;;","05/Oct/11 09:53;junrao;+1;;;","06/Oct/11 04:29;nehanarkhede;Committed this patch. Thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SslTransportLayerTest.testInvalidEndpointIdentification fails consistently,KAFKA-2850,12913751,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,rsivaram,fpj,fpj,17/Nov/15 23:59,07/Jan/16 07:01,22/Mar/23 15:10,07/Jan/16 07:01,0.9.0.0,,,,,,0.10.0.0,,,,,,,clients,security,,,0,,,,,,"This test case is failing consistently for me. From the logs, I've noticed that waitForChannelClose is failing and the output is this:

{noformat}
[2015-11-17 15:51:50,374] WARN Failed to send SSL Close message  (org.apache.kafka.common.network.SslTransportLayer:164)
    java.nio.channels.ClosedChannelException
    	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
    	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
    	at org.apache.kafka.common.network.SslTransportLayer.flush(SslTransportLayer.java:194)
    	at org.apache.kafka.common.network.SslTransportLayer.close(SslTransportLayer.java:161)
    	at org.apache.kafka.common.network.KafkaChannel.close(KafkaChannel.java:50)
    	at org.apache.kafka.common.network.Selector.close(Selector.java:442)
    	at org.apache.kafka.common.network.Selector.poll(Selector.java:310)
    	at org.apache.kafka.common.network.SslTransportLayerTest$SslEchoServer.run(SslTransportLayerTest.java:577)

org.apache.kafka.common.network.SslTransportLayerTest > testInvalidEndpointIdentification FAILED
    java.lang.AssertionError
        at org.junit.Assert.fail(Assert.java:86)
        at org.junit.Assert.assertTrue(Assert.java:41)
        at org.junit.Assert.assertTrue(Assert.java:52)
        at org.apache.kafka.common.network.SslTransportLayerTest.waitForChannelClose(SslTransportLayerTest.java:430)
        at org.apache.kafka.common.network.SslTransportLayerTest.testInvalidEndpointIdentification(SslTransportLayerTest.java:124)
{noformat}",,fpj,githubbot,junrao,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jan 06 23:01:42 UTC 2016,,,,,,,,,,"0|i2oimn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"18/Nov/15 05:42;githubbot;GitHub user rajinisivaram opened a pull request:

    https://github.com/apache/kafka/pull/546

    KAFKA-2850: Fix SSL invalid endpoint validation test

    Use invalid hostname to ensure that test works in all environments

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/rajinisivaram/kafka KAFKA-2850

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/546.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #546
    
----
commit 51d649fb6196c7efb67d2870c18f2a5a54ad7153
Author: Rajini Sivaram <rajinisivaram@googlemail.com>
Date:   2015-11-17T21:27:24Z

    KAFKA-2850: Use invalid hostname in SSL endpoint validation test to ensure it works in all environments

----
;;;","18/Nov/15 05:44;rsivaram;[~fpj] Do you mind testing the fix in the PR since I cannot recreate the failure? Thank you.;;;","18/Nov/15 07:02;fpj;works for me, thanks [~rsivaram].;;;","07/Jan/16 07:01;junrao;Issue resolved by pull request 546
[https://github.com/apache/kafka/pull/546];;;","07/Jan/16 07:01;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/546
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Drop java 1.6 support,KAFKA-2316,12843226,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriharsha,sriharsha,sriharsha,08/Jul/15 00:39,09/Jul/15 04:08,22/Mar/23 15:10,09/Jul/15 01:24,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,,,gwenshap,ijuma,jarcec,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2322,,,,,,,,,,,,,,,,,,,,,,,,"08/Jul/15 00:53;sriharsha;KAFKA-2316.patch;https://issues.apache.org/jira/secure/attachment/12743989/KAFKA-2316.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jul 08 20:08:50 UTC 2015,,,,,,,,,,"0|i2gy13:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"08/Jul/15 00:53;sriharsha;Created reviewboard https://reviews.apache.org/r/36265/diff/
 against branch origin/trunk;;;","08/Jul/15 01:59;ijuma;I think it would be more accurate for the title of this ticket to be: ""Drop Java 1.6 support"".;;;","09/Jul/15 01:24;gwenshap;+1. Committed and pushed to trunk.;;;","09/Jul/15 02:15;ijuma;It looks like this broke Jenkins:

https://builds.apache.org/job/Kafka-trunk/534/console

It works locally for me, so it looks like the Jenkins job needs to be updated somehow.;;;","09/Jul/15 02:18;ijuma;I don't have access to the config, which may be more enlightening. Still, I did notice that the following is using an old version of Scala (it should use 2.10.5 instead):

`./gradlew -PscalaVersion=2.10.1 test`

Seems unrelated to the problem at hand though.;;;","09/Jul/15 02:18;gwenshap;ouch, yeah. I guess Jenkins is running with Java 6 still.

I don't have access to modify our build job, lets see if someone in the PMC can help:
[~joestein] [~junrao] [~guozhang] [~jjkoshy] ?;;;","09/Jul/15 02:44;gwenshap;Apache Member [~jarcec] volunteered to help out! 
Please go ahead and upgrade our Java, Jarcec. ;;;","09/Jul/15 02:45;jarcec;I've configured the job to use Java ""JDK 7 u51"". Let me know if you will need further tweaks to that job.;;;","09/Jul/15 03:20;ijuma;Thank you [~jarcec], any chance you could also update https://builds.apache.org/job/KafkaPreCommit (if you haven't already)?;;;","09/Jul/15 04:08;jarcec;I've just updated the second job as well [~ijuma].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
max.message.size is not enforced for compressed messages,KAFKA-275,12542981,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,nehanarkhede,nehanarkhede,17/Feb/12 09:56,17/Aug/17 20:02,22/Mar/23 15:10,17/Aug/17 20:02,0.7,,,,,,,,,,,,,core,,,,1,,,,,,"The max.message.size check is not performed for compressed messages, but only for each message that forms a compressed message. Due to this, even if the max.message.size is set to 1MB, the producer can technically send n 1MB messages as one compressed message. This can cause memory issues on the server as well as deserialization issues on the consumer. The consumer's fetch size has to be > max.message.size in order to be able to read data. If one message is larger than the fetch.size, the consumer will throw an exception and cannot proceed until the fetch.size is increased. 

Due to this bug, even if the fetch.size > max.message.size, the consumer can still get stuck on a message that is larger than max.message.size.",,omkreddy,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-273,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,228267,,,Thu Aug 17 12:02:41 UTC 2017,,,,,,,,,,"0|i15zfz:",243042,,,,,,,,,,,,,,,,,,,,"17/Feb/12 10:22;nehanarkhede;In corner cases, this can cause KAFKA-273;;;","17/Aug/17 20:02;omkreddy;This issue is fixed in latest versions.  Please reopen if the issue still exists. 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsoleConsumer regressions,KAFKA-2467,12858521,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,ewencp,ewencp,25/Aug/15 13:47,27/Aug/15 09:36,22/Mar/23 15:10,27/Aug/15 09:36,,,,,,,0.9.0.0,,,,,,,tools,,,,0,,,,,,"It seems that the patch for KAFKA-2015 caused a few changes in the behavior of the console consumer. I picked this up because it caused the new mirror maker sanity system test to hang. We need a separate fix for ducktape to address the lack of a timeout where it got stuck, but I'd also like to get this fixed ASAP since it affects pretty much all system test efforts since they commonly use console consumer to validate data produced to Kafka.

I've tracked down a couple of changes so far:

1. The --consumer.config option handling was changed entirely. I think the new approach was trying to parse it as key=value parameters, but it's supposed to be a properties file *containing* key=value pairs.
2. A few different exceptions during message processing are not handled the same way. The skipMessageOnErrorOpt is not longer being used at all (it's parsed, but that option is never checked anymore). Also, exceptions during iteration are not caught. After fixing the consumer.config issue, which was keeping the consumer.timeout.ms setting from making it into the consumer config, this also caused the process to hang. It killed the main thread, but there must be another non-daemon thread still running (presumably the consumer threads?)
3. The ""consumed X messages"" message changed from stderr to stdout.",,benstopford,ewencp,githubbot,guozhang,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2466,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Aug 27 01:36:51 UTC 2015,,,,,,,,,,"0|i2jbo7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"25/Aug/15 14:10;githubbot;GitHub user ewencp opened a pull request:

    https://github.com/apache/kafka/pull/166

    KAFKA-2467: Fix changes to behavior in ConsoleConsumer: properly parse consumer.config option, handle exceptions during message processing, and print number of processed messages to stderr.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ewencp/kafka kafka-2467-fix-console-consumer-behavior-regressions

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/166.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #166
    
----
commit a6961ee0c7551b69922a43ca91f8146662e21209
Author: Ewen Cheslack-Postava <me@ewencp.org>
Date:   2015-08-25T05:50:12Z

    KAFKA-2467: Fix changes to behavior in ConsoleConsumer: properly parse consumer.config option, handle exceptions during message processing, and print number of processed messages to stderr.

----
;;;","25/Aug/15 15:54;ijuma;[~ewencp], do I understand correctly that the system tests would have caught this regression? Shall we be running the system tests against PR branches automatically?;;;","25/Aug/15 16:01;ewencp;[~ijuma] Sort of. We still need refinements since the tests would have hung and had to be killed by Jenkins (we're missing a timeout in a pretty critical place).

As for running system tests on every PR, that would be nice but at the moment isn't practical because of how long they can take to run. It'd be great to get there eventually, but we need to continue refining the tests, ducktape (e.g., adding the parallel test runner), and even the jenkins config (reuse clusters to avoid the startup costs for each test run that we currently pay). For now, we're working on making it easy for people to run the system tests manually on specific PRs when they think it would be useful, which I think is a reasonable intermediate step before doing builds on every PR.;;;","25/Aug/15 16:06;ijuma;Thanks for the explanation [~ewencp]. That sounds good. It would be good to update https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes with the instructions once ready. ;;;","25/Aug/15 16:25;benstopford;Apologies for this regression. 2015 was adapted by me from a submitted patch. This caused some confusion and I should have been more questioning. Lesson learnt. 

Automated tests here would obviously be a boon too.   ;;;","25/Aug/15 16:30;ewencp;No worries, I was just thankful that the patch had added any unit tests since they helped track the problem down and fix it! This is one class of issues that are harder to catch in unit tests. Apparently the addition of some system tests that we're running regularly is paying off :);;;","27/Aug/15 08:59;ewencp;[~gwenshap] or [~guozhang] Can one of you review and commit this? It's currently breaking system tests.;;;","27/Aug/15 09:26;guozhang;I should be the guy apologizing here.. My original patch on KAFKA-2015 was not complete but only sufficient for some of my local validations long time ago which is essentially a very small subset of the old system test. When [~benstopford] picked it up I did not clearly mention it to him. Sorry about that.;;;","27/Aug/15 09:36;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/166
;;;","27/Aug/15 09:36;guozhang;Issue resolved by pull request 166
[https://github.com/apache/kafka/pull/166];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Following KAFKA-1697, checkEnoughReplicasReachOffset doesn't need to get requiredAcks",KAFKA-1992,12778556,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,gwenshap,gwenshap,gwenshap,01/Mar/15 15:02,08/Apr/15 06:14,22/Mar/23 15:10,08/Apr/15 06:11,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Follow up from Jun's review:

""Should we just remove requiredAcks completely since checkEnoughReplicasReachOffset() will only be called when requiredAcks is -1?""

Answer is: Yes, we should :)",,gwenshap,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Mar/15 15:58;gwenshap;KAFKA-1992.patch;https://issues.apache.org/jira/secure/attachment/12701682/KAFKA-1992.patch","04/Mar/15 06:16;gwenshap;KAFKA-1992_2015-03-03_14:16:34.patch;https://issues.apache.org/jira/secure/attachment/12702270/KAFKA-1992_2015-03-03_14%3A16%3A34.patch","04/Mar/15 09:17;gwenshap;KAFKA-1992_2015-03-03_17:17:43.patch;https://issues.apache.org/jira/secure/attachment/12702332/KAFKA-1992_2015-03-03_17%3A17%3A43.patch","07/Mar/15 05:34;gwenshap;KAFKA-1992_2015-03-06_13:34:20.patch;https://issues.apache.org/jira/secure/attachment/12703138/KAFKA-1992_2015-03-06_13%3A34%3A20.patch","07/Mar/15 05:36;gwenshap;KAFKA-1992_2015-03-06_13:36:32.patch;https://issues.apache.org/jira/secure/attachment/12703140/KAFKA-1992_2015-03-06_13%3A36%3A32.patch","07/Mar/15 05:37;gwenshap;KAFKA-1992_2015-03-06_13:37:39.patch;https://issues.apache.org/jira/secure/attachment/12703141/KAFKA-1992_2015-03-06_13%3A37%3A39.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Apr 07 22:14:26 UTC 2015,,,,,,,,,,"0|i267hr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"01/Mar/15 15:58;gwenshap;Created reviewboard https://reviews.apache.org/r/31591/diff/
 against branch trunk;;;","04/Mar/15 06:16;gwenshap;Updated reviewboard https://reviews.apache.org/r/31591/diff/
 against branch trunk;;;","04/Mar/15 09:17;gwenshap;Updated reviewboard https://reviews.apache.org/r/31591/diff/
 against branch trunk;;;","07/Mar/15 05:34;gwenshap;Updated reviewboard https://reviews.apache.org/r/31591/diff/
 against branch trunk;;;","07/Mar/15 05:36;gwenshap;Updated reviewboard https://reviews.apache.org/r/31591/diff/
 against branch trunk;;;","07/Mar/15 05:37;gwenshap;Updated reviewboard https://reviews.apache.org/r/31591/diff/
 against branch trunk;;;","08/Apr/15 06:11;junrao;Thanks for the latest patch. +1 and committed to trunk.;;;","08/Apr/15 06:14;gwenshap;oh wow, thanks :)
Totally forgot about this one, or I would have bugged you earlier ;);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZK consumer gets into infinite loop if a message is larger than fetch size,KAFKA-160,12527622,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,junrao,junrao,junrao,19/Oct/11 01:11,20/Oct/11 07:53,22/Mar/23 15:10,20/Oct/11 07:53,0.7,,,,,,0.7,,,,,,,core,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Oct/11 01:30;junrao;KAFKA-160.patch;https://issues.apache.org/jira/secure/attachment/12499567/KAFKA-160.patch","20/Oct/11 00:04;junrao;KAFKA-160_v2.patch;https://issues.apache.org/jira/secure/attachment/12499702/KAFKA-160_v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,88873,,,Wed Oct 19 23:53:34 UTC 2011,,,,,,,,,,"0|i15z87:",243007,,,,,,,,,,,,,,,,,,,,"19/Oct/11 01:39;junrao;There were a couple of problems.
1. We used to throw an exception while iterating messages in a ByteBufferMessageSet, if we can't iterate a single message out of the buffer. This indicates that either the fetch size is too small or if there is corruption in the data. Throwing exception is a good way to notify the consumer that something is wrong. After the compression patch, such an exception is no longer thrown.

2. The constructor of ByetBufferMessageSet recently added a new parameter in the middle and some of the callers didn't get changed accordingly. So, some input parameters are misaligned.

Attach a patch that fixes both problems.;;;","19/Oct/11 05:44;jkreps;Hey did I break this?;;;","19/Oct/11 05:50;junrao;I think this was introduced when compression was added. I reviewed the patch, but didn't catch this.;;;","20/Oct/11 00:04;junrao;Submitted patch v2, adding a unit test that uncovers the problem.;;;","20/Oct/11 06:57;nehanarkhede;+1 on patch v2;;;","20/Oct/11 07:53;junrao;Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MetadataRequest returns stale list of brokers,KAFKA-972,12657261,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,singhashish,vccarvalho,vccarvalho,11/Jul/13 21:34,15/Jul/15 02:22,22/Mar/23 15:10,14/Jul/15 08:17,0.8.0,,,,,,0.9.0.0,,,,,,,core,,,,1,,,,,,"When we issue an metadatarequest towards the cluster, the list of brokers is stale. I mean, even when a broker is down, it's returned back to the client. The following are examples of two invocations one with both brokers online and the second with a broker down:

{
    ""brokers"": [
        {
            ""nodeId"": 0,
            ""host"": ""10.139.245.106"",
            ""port"": 9092,
            ""byteLength"": 24
        },
        {
            ""nodeId"": 1,
            ""host"": ""localhost"",
            ""port"": 9093,
            ""byteLength"": 19
        }
    ],
    ""topicMetadata"": [
        {
            ""topicErrorCode"": 0,
            ""topicName"": ""foozbar"",
            ""partitions"": [
                {
                    ""replicas"": [
                        0
                    ],
                    ""isr"": [
                        0
                    ],
                    ""partitionErrorCode"": 0,
                    ""partitionId"": 0,
                    ""leader"": 0,
                    ""byteLength"": 26
                },
                {
                    ""replicas"": [
                        1
                    ],
                    ""isr"": [
                        1
                    ],
                    ""partitionErrorCode"": 0,
                    ""partitionId"": 1,
                    ""leader"": 1,
                    ""byteLength"": 26
                },
                {
                    ""replicas"": [
                        0
                    ],
                    ""isr"": [
                        0
                    ],
                    ""partitionErrorCode"": 0,
                    ""partitionId"": 2,
                    ""leader"": 0,
                    ""byteLength"": 26
                },
                {
                    ""replicas"": [
                        1
                    ],
                    ""isr"": [
                        1
                    ],
                    ""partitionErrorCode"": 0,
                    ""partitionId"": 3,
                    ""leader"": 1,
                    ""byteLength"": 26
                },
                {
                    ""replicas"": [
                        0
                    ],
                    ""isr"": [
                        0
                    ],
                    ""partitionErrorCode"": 0,
                    ""partitionId"": 4,
                    ""leader"": 0,
                    ""byteLength"": 26
                }
            ],
            ""byteLength"": 145
        }
    ],
    ""responseSize"": 200,
    ""correlationId"": -1000
}


{
    ""brokers"": [
        {
            ""nodeId"": 0,
            ""host"": ""10.139.245.106"",
            ""port"": 9092,
            ""byteLength"": 24
        },
        {
            ""nodeId"": 1,
            ""host"": ""localhost"",
            ""port"": 9093,
            ""byteLength"": 19
        }
    ],
    ""topicMetadata"": [
        {
            ""topicErrorCode"": 0,
            ""topicName"": ""foozbar"",
            ""partitions"": [
                {
                    ""replicas"": [
                        0
                    ],
                    ""isr"": [],
                    ""partitionErrorCode"": 5,
                    ""partitionId"": 0,
                    ""leader"": -1,
                    ""byteLength"": 22
                },
                {
                    ""replicas"": [
                        1
                    ],
                    ""isr"": [
                        1
                    ],
                    ""partitionErrorCode"": 0,
                    ""partitionId"": 1,
                    ""leader"": 1,
                    ""byteLength"": 26
                },
                {
                    ""replicas"": [
                        0
                    ],
                    ""isr"": [],
                    ""partitionErrorCode"": 5,
                    ""partitionId"": 2,
                    ""leader"": -1,
                    ""byteLength"": 22
                },
                {
                    ""replicas"": [
                        1
                    ],
                    ""isr"": [
                        1
                    ],
                    ""partitionErrorCode"": 0,
                    ""partitionId"": 3,
                    ""leader"": 1,
                    ""byteLength"": 26
                },
                {
                    ""replicas"": [
                        0
                    ],
                    ""isr"": [],
                    ""partitionErrorCode"": 5,
                    ""partitionId"": 4,
                    ""leader"": -1,
                    ""byteLength"": 22
                }
            ],
            ""byteLength"": 133
        }
    ],
    ""responseSize"": 188,
    ""correlationId"": -1000
}
",,junrao,nehanarkhede,singhashish,sslavic,vccarvalho,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1367,,,,,,,,,,"24/Jun/15 23:28;granthenke;BrokerMetadataTest.scala;https://issues.apache.org/jira/secure/attachment/12741634/BrokerMetadataTest.scala","30/Jun/15 08:46;singhashish;KAFKA-972.patch;https://issues.apache.org/jira/secure/attachment/12742664/KAFKA-972.patch","01/Jul/15 09:42;singhashish;KAFKA-972_2015-06-30_18:42:13.patch;https://issues.apache.org/jira/secure/attachment/12742993/KAFKA-972_2015-06-30_18%3A42%3A13.patch","01/Jul/15 16:37;singhashish;KAFKA-972_2015-07-01_01:36:56.patch;https://issues.apache.org/jira/secure/attachment/12743020/KAFKA-972_2015-07-01_01%3A36%3A56.patch","01/Jul/15 16:43;singhashish;KAFKA-972_2015-07-01_01:42:42.patch;https://issues.apache.org/jira/secure/attachment/12743021/KAFKA-972_2015-07-01_01%3A42%3A42.patch","01/Jul/15 23:06;singhashish;KAFKA-972_2015-07-01_08:06:03.patch;https://issues.apache.org/jira/secure/attachment/12743100/KAFKA-972_2015-07-01_08%3A06%3A03.patch","07/Jul/15 14:07;singhashish;KAFKA-972_2015-07-06_23:07:34.patch;https://issues.apache.org/jira/secure/attachment/12743895/KAFKA-972_2015-07-06_23%3A07%3A34.patch","08/Jul/15 01:42;singhashish;KAFKA-972_2015-07-07_10:42:41.patch;https://issues.apache.org/jira/secure/attachment/12744001/KAFKA-972_2015-07-07_10%3A42%3A41.patch","08/Jul/15 14:24;singhashish;KAFKA-972_2015-07-07_23:24:13.patch;https://issues.apache.org/jira/secure/attachment/12744146/KAFKA-972_2015-07-07_23%3A24%3A13.patch",,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,337483,,,Tue Jul 14 18:22:20 UTC 2015,,,,,,,,,,"0|i1m7lz:",337806,,,,,,,,,,,,,,,,,,,,"13/Sep/13 23:58;junrao;Could you describe how to reproduce this?;;;","14/Sep/13 01:00;nehanarkhede;Is this repetitive or the metadata starts returning consistent data after some time ? Since the metadata is communicated to the brokers by the controller, it is possible that there is a time window after an event has happened and before all the brokers have learned of the event.;;;","24/Jun/15 23:28;granthenke;Sample Failing Tests:
- testBrokerMetadataOnClusterWithNoTopics
- testBrokerMetadataOnBrokerShutdown
- testBrokerMetadataOnBrokerAddition;;;","25/Jun/15 11:10;singhashish;Hey Guys,

I spent some time reproducing the issue and finding the root cause. Turns out KAFKA-1367 is not the issue here. Below is the problem and my suggested solution.

Problem:
Alive brokers list not being propagated to brokers by coordinator. When a broker is started, it writes to ZK brokers path. Coordinator watches that path and notices the new broker. On noticing a new broker, the coordinator sends the UpdateMetadataRequest to only the new broker that just started up. The other brokers in cluster never gets to know that there are new brokers in the cluster.

Effect of KAFKA-1367: After KAFKA-1367 goes in it correct alive brokers information will be propagated to all live brokers after ISR changes at any broker. However, if there are no topics/ partitions KAFKA-1367 will not help and this issue will still be there.

Solution:
Instead of sending the UpdateMetadataRequest only to new broker, send it to all live brokers in the cluster.

[~junrao], [~nehanarkhede], [~granthenke], [~gwenshap], [~charmalloc], [~jjkoshy] please provide your thoughts. I have a patch ready which I will post if you guys think this is indeed the correct approach. I have verified that above approach fixes the issue.;;;","26/Jun/15 03:50;granthenke;This solutions sounds reasonable to me.;;;","30/Jun/15 08:46;singhashish;Created reviewboard https://reviews.apache.org/r/36030/
 against branch trunk;;;","01/Jul/15 09:42;singhashish;Updated reviewboard https://reviews.apache.org/r/36030/
 against branch trunk;;;","01/Jul/15 16:37;singhashish;Updated reviewboard https://reviews.apache.org/r/36030/
 against branch trunk;;;","01/Jul/15 16:43;singhashish;Updated reviewboard https://reviews.apache.org/r/36030/
 against branch trunk;;;","01/Jul/15 23:06;singhashish;Updated reviewboard https://reviews.apache.org/r/36030/
 against branch trunk;;;","07/Jul/15 14:07;singhashish;Updated reviewboard https://reviews.apache.org/r/36030/
 against branch trunk;;;","08/Jul/15 01:42;singhashish;Updated reviewboard https://reviews.apache.org/r/36030/
 against branch trunk;;;","08/Jul/15 14:24;singhashish;Updated reviewboard https://reviews.apache.org/r/36030/
 against branch trunk;;;","11/Jul/15 06:08;singhashish;[~junrao] could you take a look, thanks.;;;","14/Jul/15 08:17;junrao;Thanks for the latest patch. +1 and committed to trunk.;;;","15/Jul/15 02:22;singhashish;Thanks [~junrao]!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
missing synchronization in access to leaderCache in KafkaApis,KAFKA-1169,12682933,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,06/Dec/13 00:04,06/Dec/13 01:37,22/Mar/23 15:10,06/Dec/13 01:37,,,,,,,0.8.1,,,,,,,core,,,,0,,,,,,,,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Dec/13 00:18;junrao;KAFKA-1169.patch;https://issues.apache.org/jira/secure/attachment/12617181/KAFKA-1169.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,362190,,,Thu Dec 05 17:37:50 UTC 2013,,,,,,,,,,"0|i1qflj:",362485,,,,,,,,,,,,,,,,,,,,"06/Dec/13 00:18;junrao;Created reviewboard  against branch origin/trunk;;;","06/Dec/13 00:22;junrao;Got the following error when creating the RB. Not sure what happened.

python kafka-patch-review.py -b origin/trunk -j KAFKA-1169 -s ""missing synchronization in access to leaderCache in KafkaApis""
Configuring reviewboard url to https://reviews.apache.org
Updating your remote branches to pull the latest changes
Traceback (most recent call last):
  File ""/usr/local/bin/post-review"", line 8, in <module>
    load_entry_point('RBTools==0.5.2', 'console_scripts', 'post-review')()
  File ""build/bdist.macosx-10.8-intel/egg/rbtools/postreview.py"", line 1372, in main
  File ""build/bdist.macosx-10.8-intel/egg/rbtools/postreview.py"", line 983, in tempt_fate
  File ""build/bdist.macosx-10.8-intel/egg/rbtools/postreview.py"", line 623, in publish
  File ""build/bdist.macosx-10.8-intel/egg/rbtools/postreview.py"", line 829, in api_put
  File ""build/bdist.macosx-10.8-intel/egg/rbtools/postreview.py"", line 662, in process_error
rbtools.api.errors.APIError: HTTP 502
Creating diff against origin/trunk and uploading patch to JIRA KAFKA-1169
Created a new reviewboard  
;;;","06/Dec/13 00:24;junrao;RB is created though:

https://reviews.apache.org/r/16040/;;;","06/Dec/13 01:11;nehanarkhede;That's probably because Apache reviewboard was down for sometime in the morning.;;;","06/Dec/13 01:37;junrao;Thanks for the review. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TopicConfigManager javadoc references incorrect paths,KAFKA-2087,12787739,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Trivial,Fixed,aauradkar,aauradkar,aauradkar,03/Apr/15 01:19,21/Apr/15 00:28,22/Mar/23 15:10,21/Apr/15 00:28,,,,,,,,,,,,,,,,,,0,,,,,,"The TopicConfigManager docs refer to znodes in /brokers/topics/<topic_name>/config which is incorrect.

Fix javadoc",,aauradkar,auradkar,jkreps,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Apr/15 01:22;auradkar;KAFKA-2087.patch;https://issues.apache.org/jira/secure/attachment/12709011/KAFKA-2087.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Apr 20 16:28:30 UTC 2015,,,,,,,,,,"0|i27po7:",9223372036854775807,,nehanarkhede,,,,,,,,,,,,,,,,,,"03/Apr/15 01:22;auradkar;Created reviewboard https://reviews.apache.org/r/32778/diff/
 against branch origin/trunk;;;","05/Apr/15 10:40;jkreps;[~aauradkar] this doesn't look like a javadoc patch...;;;","05/Apr/15 13:26;aauradkar;[~jkreps] Yeah, I've discarded that patch. Submitted in error. Here's the right one.

https://reviews.apache.org/r/32781/diff/#;;;","21/Apr/15 00:28;nehanarkhede;Pushed to trunk. Thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Memory leak in `Sender.completeBatch` on TOPIC_AUTHORIZATION_FAILED,KAFKA-3122,12932569,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,ijuma,ijuma,20/Jan/16 08:01,20/Jan/16 14:51,22/Mar/23 15:10,20/Jan/16 14:51,0.9.0.0,,,,,,0.9.0.1,,,,,,,clients,,,,0,,,,,,,,githubbot,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jan 20 06:50:46 UTC 2016,,,,,,,,,,"0|i2rpnj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"20/Jan/16 08:02;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/791

    KAFKA-3122; Fix memory leak in `Sender` on TOPIC_AUTHORIZATION_FAILED

    Also fix missing call to `sensors.record` on this error.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka fix-producer-memory-leak-on-authorization-exception

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/791.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #791
    
----
commit 9d6c451995ae5b50bec7f3841778840977e4d3b5
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2016-01-19T23:54:46Z

    Fix memory leak in `Sender` on TOPIC_AUTHORIZATION_FAILED
    
    Also fix missing call to `sensors.record` on this error.

----
;;;","20/Jan/16 14:50;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/791
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Number of alive brokers not known after single node cluster startup,KAFKA-3037,12923945,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,granthenke,sslavic,sslavic,23/Dec/15 16:37,06/Feb/16 05:16,22/Mar/23 15:10,06/Feb/16 05:16,0.8.2.1,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,Single broker cluster is not aware of itself being alive. This can cause failure in logic which relies on number of alive brokers being known - e.g. consumer offsets topic creation logic success depends on number of alive brokers being known.,,ewencp,githubbot,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Feb 05 21:16:33 UTC 2016,,,,,,,,,,"0|i2q8xr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"05/Feb/16 12:52;granthenke;[~sslavic] I think this is resolved. I wrote a small unit test that fails in 0.8.2 but passes in trunk and 0.9. I will open a PR with the test upstream, let me know if it doesn't cover the scenario you expect. ;;;","05/Feb/16 12:53;githubbot;GitHub user granthenke opened a pull request:

    https://github.com/apache/kafka/pull/875

    KAFKA-3037: Test number of alive brokers known after single node clus…

    …ter startup

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka self-aware

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/875.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #875
    
----
commit 21ec8efa3a1d218e1bd578a5498d25c8e3d95ee8
Author: Grant Henke <granthenke@gmail.com>
Date:   2016-02-05T04:52:27Z

    KAFKA-3037: Test number of alive brokers known after single node cluster startup

----
;;;","06/Feb/16 05:16;ewencp;Issue resolved by pull request 875
[https://github.com/apache/kafka/pull/875];;;","06/Feb/16 05:16;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/875
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NetworkClient.close should remove node from inFlightRequests,KAFKA-2519,12861859,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,ijuma,ijuma,ijuma,04/Sep/15 22:36,05/Sep/15 00:30,22/Mar/23 15:10,05/Sep/15 00:30,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,,,githubbot,ijuma,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Sep 04 16:30:42 UTC 2015,,,,,,,,,,"0|i2jsnb:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"04/Sep/15 22:59;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/193

    KAFKA-2519; NetworkClient.close should remove node from inFlightRequests

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-2519-network-client-close-remove-in-flight

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/193.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #193
    
----
commit 8ff38fee7c194901cdcf168dd41eb969c6aaca47
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2015-09-04T14:56:08Z

    NetworkClient.close should remove node from inFlightRequests

----
;;;","04/Sep/15 23:12;ijuma;[~junrao], can you please review this. It's a small fix for an important issue (I think this is the reason for a transient test failure I saw yesterday).;;;","05/Sep/15 00:30;junrao;Issue resolved by pull request 193
[https://github.com/apache/kafka/pull/193];;;","05/Sep/15 00:30;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/193
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move the decoding logic from ConsumerIterator.makeNext to next,KAFKA-1140,12680664,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,guozhang,guozhang,22/Nov/13 10:01,28/Nov/13 13:56,22/Mar/23 15:10,28/Nov/13 13:56,,,,,,,0.8.1,,,,,,,,,,,0,,,,,,"Usually people will write code around consumer like

while(iter.hasNext()) {
try {
  msg = iter.next()
  // do something
}
catch{
}
}

----

However, the iter.hasNext() call itself can throw exceptions due to decoding failures. It would be better to move the decoding to the next function call.",,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Nov/13 06:37;guozhang;KAFKA-1140.patch;https://issues.apache.org/jira/secure/attachment/12615399/KAFKA-1140.patch","26/Nov/13 04:53;guozhang;KAFKA-1140_2013-11-25_12:53:17.patch;https://issues.apache.org/jira/secure/attachment/12615664/KAFKA-1140_2013-11-25_12%3A53%3A17.patch","26/Nov/13 04:55;guozhang;KAFKA-1140_2013-11-25_12:55:34.patch;https://issues.apache.org/jira/secure/attachment/12615665/KAFKA-1140_2013-11-25_12%3A55%3A34.patch","27/Nov/13 06:41;guozhang;KAFKA-1140_2013-11-26_14:41:00.patch;https://issues.apache.org/jira/secure/attachment/12615932/KAFKA-1140_2013-11-26_14%3A41%3A00.patch","27/Nov/13 10:30;guozhang;KAFKA-1140_2013-11-26_18:29:53.patch;https://issues.apache.org/jira/secure/attachment/12615980/KAFKA-1140_2013-11-26_18%3A29%3A53.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,359929,,,Thu Nov 28 05:56:48 UTC 2013,,,,,,,,,,"0|i1q1pj:",360228,,,,,,,,,,,,,,,,,,,,"23/Nov/13 06:37;guozhang;Created reviewboard https://reviews.apache.org/r/15805/
 against branch origin/trunk;;;","26/Nov/13 04:53;guozhang;Updated reviewboard https://reviews.apache.org/r/15805/
 against branch origin/trunk;;;","26/Nov/13 04:55;guozhang;Updated reviewboard https://reviews.apache.org/r/15805/
 against branch origin/trunk;;;","27/Nov/13 06:41;guozhang;Updated reviewboard https://reviews.apache.org/r/15805/
 against branch origin/trunk;;;","27/Nov/13 10:30;guozhang;Updated reviewboard https://reviews.apache.org/r/15805/
 against branch origin/trunk;;;","28/Nov/13 13:56;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
run-class.sh and other shell scripts are copy pasted all over the place,KAFKA-1085,12673505,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,jkreps,jkreps,12/Oct/13 06:28,26/Jan/16 12:23,22/Mar/23 15:10,26/Jan/16 12:23,,,,,,,,,,,,,,,,,,0,,,,,,"This is kind of embaressing.

jkreps-mn:kafka jkreps$ find . -name ""*.sh""
./bin/kafka-add-partitions.sh
./bin/kafka-console-consumer.sh
./bin/kafka-console-producer.sh
./bin/kafka-consumer-perf-test.sh
./bin/kafka-create-topic.sh
./bin/kafka-list-topic.sh
./bin/kafka-preferred-replica-election.sh
./bin/kafka-producer-perf-test.sh
./bin/kafka-reassign-partitions.sh
./bin/kafka-replay-log-producer.sh
./bin/kafka-run-class.sh
./bin/kafka-server-start.sh
./bin/kafka-server-stop.sh
./bin/kafka-simple-consumer-perf-test.sh
./bin/kafka-simple-consumer-shell.sh
./bin/run-rat.sh
./bin/zookeeper-server-start.sh
./bin/zookeeper-server-stop.sh
./bin/zookeeper-shell.sh
./contrib/hadoop-consumer/copy-jars.sh
./contrib/hadoop-consumer/hadoop-setup.sh
./contrib/hadoop-consumer/run-class.sh
./examples/bin/java-producer-consumer-demo.sh
./examples/bin/java-simple-consumer-demo.sh
./system_test/broker_failure/bin/kafka-run-class.sh
./system_test/broker_failure/bin/run-test.sh
./system_test/common/util.sh
./system_test/migration_tool_testsuite/0.7/bin/kafka-run-class.sh
./system_test/migration_tool_testsuite/0.7/bin/zookeeper-server-start.sh
./system_test/mirror_maker/bin/run-test.sh
./system_test/producer_perf/bin/run-compression-test.sh
./system_test/producer_perf/bin/run-test.sh
./system_test/run_sanity.sh",,jkreps,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,353128,,,Tue Jan 26 04:23:11 UTC 2016,,,,,,,,,,"0|i1ovrj:",353415,,,,,,,,,,,,,,,,,,,,"26/Jan/16 12:23;granthenke;Looks like this was resolved through contrib and systest removal.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Junit3 Misusage,KAFKA-1782,12756206,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,apakulov,guozhang,guozhang,19/Nov/14 04:35,15/Aug/15 12:54,22/Mar/23 15:10,15/Aug/15 12:54,,,,,,,0.9.0.0,,,,,,,,,,,0,newbie,,,,,"This is found while I was working on KAFKA-1580: in many of our cases where we explicitly extend from junit3suite (e.g. ProducerFailureHandlingTest), we are actually misusing a bunch of features that only exist in Junit4, such as (expected=classOf). For example, the following code

{code}
import org.scalatest.junit.JUnit3Suite
import org.junit.Test

import java.io.IOException

class MiscTest extends JUnit3Suite {
  @Test (expected = classOf[IOException])
  def testSendOffset() {
  }
}
{code}

will actually pass even though IOException was not thrown since this annotation is not supported in Junit3. Whereas

{code}
import org.junit._

import java.io.IOException

class MiscTest extends JUnit3Suite {
  @Test (expected = classOf[IOException])
  def testSendOffset() {
  }
}
{code}

or

{code}
import org.scalatest.junit.JUnitSuite
import org.junit._

import java.io.IOException

class MiscTest extends JUnit3Suite {
  @Test (expected = classOf[IOException])
  def testSendOffset() {
  }
}
{code}

or

{code}
import org.junit._

import java.io.IOException

class MiscTest {
  @Test (expected = classOf[IOException])
  def testSendOffset() {
  }
}
{code}

will fail.

I would propose to not rely on Junit annotations other than @Test itself but use scala unit test annotations instead, for example:

{code}
import org.junit._

import java.io.IOException

class MiscTest {
  @Test
  def testSendOffset() {
    intercept[IOException] {
      //nothing
    }
  }
}

{code}

will fail with a clearer stacktrace.
",,apakulov,githubbot,guozhang,hachikuji,ijuma,jholoman,jjkoshy,mliesenberg,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2398,,,,,,,,,,,,,,,,,,"17/Jul/15 02:47;apakulov;KAFKA-1782.patch;https://issues.apache.org/jira/secure/attachment/12745667/KAFKA-1782.patch","19/Jun/15 02:28;apakulov;KAFKA-1782.patch;https://issues.apache.org/jira/secure/attachment/12740464/KAFKA-1782.patch","19/Jun/15 02:53;apakulov;KAFKA-1782_2015-06-18_11:52:49.patch;https://issues.apache.org/jira/secure/attachment/12740471/KAFKA-1782_2015-06-18_11%3A52%3A49.patch","16/Jul/15 07:58;apakulov;KAFKA-1782_2015-07-15_16:57:44.patch;https://issues.apache.org/jira/secure/attachment/12745551/KAFKA-1782_2015-07-15_16%3A57%3A44.patch","17/Jul/15 02:50;apakulov;KAFKA-1782_2015-07-16_11:50:05.patch;https://issues.apache.org/jira/secure/attachment/12745670/KAFKA-1782_2015-07-16_11%3A50%3A05.patch","17/Jul/15 02:56;apakulov;KAFKA-1782_2015-07-16_11:56:11.patch;https://issues.apache.org/jira/secure/attachment/12745672/KAFKA-1782_2015-07-16_11%3A56%3A11.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Aug 15 04:54:41 UTC 2015,,,,,,,,,,"0|i22ivb:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"19/Nov/14 05:35;guozhang;For more information:

http://www.asjava.com/junit/junit-3-vs-junit-4-comparison/

And

http://www.artima.com/docs-scalatest-2.2.0-RC1/index.html#org.scalatest.junit.package (look for class Junit3Suite and JunitSuite);;;","26/Dec/14 00:27;jholoman;Given the timing, is it best to move the fix version to 0.8.3?;;;","26/Dec/14 13:57;jjkoshy;I think it would be beneficial to at least survey affected unit tests and verify those tests manually - i.e., there may be test failures that are in fact escaping due to this issue.;;;","28/Dec/14 08:26;jholoman;I did a check through the tests looking for things like '(expected' and 'JUnit3Suite'. The good news is I don't think there are any cases that tests are passing where they shouldn't be, and I didn't find any instances against trunk where a test would pass silently due features that aren't implemented in JUnit 3. There is one exception (HighwatermarkPersistenceTest) where the teardown is not being called due to use of the  @After notation. There is also a bit of ""mixing"" where both JUnitSuite and the older junit.framework.Assert (vs. org.junit.Assert) is being used. 

So how would we like to proceed here? It probably makes sense to have a standard set of libraries that are imported in each test. 
Are we ok with using scalatest features like intercept[] rather than @Test(expected..) ?. If we remove all the references to JUnit3Suite there is some cleanup work (mostly in setup/teardown and adding annotations). 
;;;","30/Dec/14 06:00;nehanarkhede;[~guozhang], [~jjkoshy] It looks like we can push this to 0.8.3. Any objections?;;;","22/Jan/15 02:41;guozhang;Jeff,

Sorry for getting late on this.

I would recommend we remove all the references to JUnit3Suite as it is 1) no longer the latest version and 2) is confusing to people for ""expected"" usage. And we will also remove other annotations other than ""@Test"" itself but use scalatest features instead.;;;","22/Jan/15 07:03;jholoman;Thank you for the feedback [~guozhang]. I will get to work on this.;;;","19/Jun/15 02:28;apakulov;Created reviewboard https://reviews.apache.org/r/35615/diff/
 against branch origin/trunk;;;","19/Jun/15 02:53;apakulov;Updated reviewboard https://reviews.apache.org/r/35615/diff/
 against branch upstream/trunk;;;","14/Jul/15 05:03;apakulov;[~guozhang] [~junrao] is this ticket still relevant?;;;","14/Jul/15 09:16;guozhang;[~apakulov] Yes this is still relevant, sorry for being late on the reviews, will take a look at it soon.;;;","16/Jul/15 07:58;apakulov;Updated reviewboard https://reviews.apache.org/r/35615/diff/
 against branch upstream/trunk;;;","17/Jul/15 02:47;apakulov;Created reviewboard https://reviews.apache.org/r/36552/diff/
 against branch origin/trunk;;;","17/Jul/15 02:50;apakulov;Updated reviewboard https://reviews.apache.org/r/35615/diff/
 against branch trunk;;;","17/Jul/15 02:56;apakulov;Updated reviewboard https://reviews.apache.org/r/35615/diff/
 against branch trunk;;;","13/Aug/15 10:57;guozhang;Issue resolved by pull request 135
[https://github.com/apache/kafka/pull/135];;;","13/Aug/15 10:59;guozhang;[~apakulov] Thanks for the patch, [~ewencp] helped fixing another issue and it has not been committed to trunk.

EDIT: not => now;;;","13/Aug/15 15:36;ijuma;Guozhang meant that it has now been committed to trunk.;;;","14/Aug/15 01:53;apakulov;[~ewencp] [~guozhang] thanks for taking care of it.;;;","14/Aug/15 07:21;apakulov;[~guozhang] am I able to use github PR to send changset or kafka-review tool is still a preferred way?;;;","14/Aug/15 07:32;guozhang;[~apakulov] we are currently moving to the PR for contribution / reviews, you can take a look at this wiki (section ""Contributor and Reviewer Workflow""):

https://cwiki.apache.org/confluence/display/KAFKA/Patch+submission+and+review;;;","15/Aug/15 04:13;hachikuji;It looks like this patch broke some of the tests (e.g. ConsumerTest). We probably need to go through and add the Test annotation to all the test cases which were converted.;;;","15/Aug/15 06:44;githubbot;GitHub user ewencp opened a pull request:

    https://github.com/apache/kafka/pull/140

    KAFKA-1782: Follow up - add missing @Test annotations.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ewencp/kafka kafka-1782-followup

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/140.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #140
    
----
commit 1dcaf39d489c26b564186fbe8d1bddb987f38e3e
Author: Ewen Cheslack-Postava <me@ewencp.org>
Date:   2015-08-14T22:43:56Z

    KAFKA-1782: Follow up - add missing @Test annotations.

----
;;;","15/Aug/15 12:54;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/140
;;;","15/Aug/15 12:54;guozhang;Issue resolved by pull request 140
[https://github.com/apache/kafka/pull/140];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Decompression and re-compression on MirrorMaker could result in messages being dropped in the pipeline,KAFKA-1011,12663922,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,guozhang,guozhang,16/Aug/13 05:10,25/May/16 04:57,22/Mar/23 15:10,25/May/16 04:57,,,,,,,,,,,,,,,,,,0,,,,,,"The way MirrorMaker works today is that its consumers could use deep iterator to decompress messages received from the source brokers and its producers could re-compress the messages while sending them to the target brokers. Since MirrorMakers use a centralized data channel for its consumers to pipe messages to its producers, and since producers would compress messages with the same topic within a batch as a single produce request, this could result in messages accepted at the front end of the pipeline being dropped at the target brokers of the MirrorMaker due to MesageSizeTooLargeException if it happens that one batch of messages contain too many messages of the same topic in MirrorMaker's producer. If we can use shallow iterator at the MirrorMaker's consumer side to directly pipe compressed messages this issue can be fixed. 

Also as Swapnil pointed out, currently if the MirrorMaker lags and there are large messages in the MirrorMaker queue (large after decompression), it can run into an OutOfMemoryException. Shallow iteration will be very helpful in avoiding this exception.

The proposed solution of this issue is also related to KAFKA-527.",,chienle,guozhang,gwenshap,junrao,me.venkatr,nehanarkhede,vanyatka,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Aug/13 01:51;guozhang;KAFKA-1011.v1.patch;https://issues.apache.org/jira/secure/attachment/12599666/KAFKA-1011.v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,343923,,,Tue May 24 20:57:13 UTC 2016,,,,,,,,,,"0|i1nb6n:",344225,,,,,,,,,,,,,,,,,,,,"23/Aug/13 00:23;guozhang;Proposed Approach:

1. Since the compression function ByteBufferMessageSet.create will only be called over a set of messages either with the same key hash value or with key null, we can write the key to the compressed wrapper message according to their destination partition id (currently it is always written as null).

2. Add a isShallow parameter to consumerIterator and KafkaStream, and passing the parameter from KafkaStream to consumerIterator; in consumerIterator, if isShallow is true call currentDataChunk.messages.shallowIterator otherwise call currentDataChunk.messages.iterator

3. In MirrorMaker, set shallowIterator to true.

4. Also in MirrorMaker, set CompressionCodec to NoCompression to avoid second compression of compressed message.

5. Ordering in MirrorMaker will be automatically preserved since MirrorMaker producer's event handler would use the message key to decide the outgoing partition, hence compressed messages with the same key would go to the same partition.;;;","24/Aug/13 01:51;guozhang;Passed Unit Test and System Test MirrorMaker 5001.

One drawback is that for if the number of partitions for certain topic in the source cluster is less than the number of partitions in the target cluster, then some partitions would not get any data.;;;","03/Sep/13 23:36;junrao;Thanks for the patch. Not sure if it works correctly though. The issue is that in MirrorMaker, if we pass in the compressed bytes to Producer, we need to let the producer mark the message as compressed (in the attribute in the message header). We can only do that by enabling compression in the producer. However, we can't do that since that will compress the compressed bytes again.

So, we will have to either change the Producer api to give us enough hook to package the message correctly. Alternatively, we could send data using SyncProducer by packaging the message in exactly the way that we want. However, some of the logic in Producer will have to be duplicated.;;;","05/Sep/13 09:09;guozhang;Thank Jun, you are right. The message metadata is thrown away when the producer of the MirrorMaker sends it to the target partition, and the new metadata will be added at the producer side. And after thinking about this I believe the viable solution would be a producer API change, sending MessageAndMetadata instead of KeyedMessage so that the metadata will not be dropped if there is any.

That said, I agree that this would not be an 0.8 fix but rather goes to trunk. And it may also need to align with the client-redesign stuff:

https://cwiki.apache.org/confluence/display/KAFKA/Client+Rewrite

;;;","16/Sep/13 01:09;nehanarkhede;I think using the SyncProducer in the MirrorMaker might solve this issue until the client redesign is complete. The only extra work that is involved in making this work is batching. This will resolve the unintuitive behavior that we see today where a message is accepted at the source but gets dropped at one or more of the intermediate pipelines. I think we can attempt this is in trunk instead of waiting for the client rewrite since the work is not significantly large and the client rewrite release is many months away.;;;","17/Sep/13 01:31;guozhang;Besides batching, two other critical functions that was missing from SyncProducer are partition-leader-discovery and retry-on-failure. I think without those the MirrorMaker SyncProducer will not work.;;;","17/Sep/13 05:45;guozhang;Currently the main issue is the MessageAndMetadata returned by ConsumerIterator does not maintain the compression information, and hence we would not know if the message contained is compressed or not. So in order for this to work we have to add the compression info into MessageAndMetadata also. With the SyncProducer approach the changes on MM would be:

1) Add compression info into MessageAndMetadata;
2) Use SyncProducer instead of Producer in MM;
3) Add the batching and retry mechanism around SyncProducer;
4) Use a specific SyncProducer to send MetadataRequest, and maintain the cached metadata structure;
5) Reconstruct the Message object from the MessageAndMetadata object, and then construct the MessageSetByteBuffer object, and then the ProduceRequest, and call the SyncProducer;

3), 4), 5) would be implemented as a different class which will mimic the Producer's behavior but would use a different interface that takes MessageAndMetadata instead of KeyedMessage.;;;","25/May/16 04:57;gwenshap;MirrorMaker was rewritten, compression was re-written, lets just assume it was fixed :);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve semantics of timestamp in OffsetCommitRequests and update documentation,KAFKA-1634,12741376,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,guozhang,nehanarkhede,nehanarkhede,15/Sep/14 09:39,31/Mar/15 04:41,22/Mar/23 15:10,31/Mar/15 04:41,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"From the mailing list -

following up on this -- I think the online API docs for OffsetCommitRequest
still incorrectly refer to client-side timestamps:

https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-OffsetCommitRequest

Wasn't that removed and now always handled server-side now?  Would one of
the devs mind updating the API spec wiki?",,asvyazin,dana.powers,guozhang,jjkoshy,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1927,,,,,KAFKA-1841,,,,,,,,,,,,,,,,,,,"31/Oct/14 02:43;guozhang;KAFKA-1634.patch;https://issues.apache.org/jira/secure/attachment/12678266/KAFKA-1634.patch","07/Nov/14 07:35;guozhang;KAFKA-1634_2014-11-06_15:35:46.patch;https://issues.apache.org/jira/secure/attachment/12679995/KAFKA-1634_2014-11-06_15%3A35%3A46.patch","08/Nov/14 08:54;guozhang;KAFKA-1634_2014-11-07_16:54:33.patch;https://issues.apache.org/jira/secure/attachment/12680339/KAFKA-1634_2014-11-07_16%3A54%3A33.patch","18/Nov/14 09:42;guozhang;KAFKA-1634_2014-11-17_17:42:44.patch;https://issues.apache.org/jira/secure/attachment/12682057/KAFKA-1634_2014-11-17_17%3A42%3A44.patch","22/Nov/14 06:00;guozhang;KAFKA-1634_2014-11-21_14:00:34.patch;https://issues.apache.org/jira/secure/attachment/12682964/KAFKA-1634_2014-11-21_14%3A00%3A34.patch","02/Dec/14 03:44;guozhang;KAFKA-1634_2014-12-01_11:44:35.patch;https://issues.apache.org/jira/secure/attachment/12684467/KAFKA-1634_2014-12-01_11%3A44%3A35.patch","02/Dec/14 10:03;guozhang;KAFKA-1634_2014-12-01_18:03:12.patch;https://issues.apache.org/jira/secure/attachment/12684529/KAFKA-1634_2014-12-01_18%3A03%3A12.patch","15/Jan/15 07:50;guozhang;KAFKA-1634_2015-01-14_15:50:15.patch;https://issues.apache.org/jira/secure/attachment/12692382/KAFKA-1634_2015-01-14_15%3A50%3A15.patch","22/Jan/15 08:43;guozhang;KAFKA-1634_2015-01-21_16:43:01.patch;https://issues.apache.org/jira/secure/attachment/12693763/KAFKA-1634_2015-01-21_16%3A43%3A01.patch","23/Jan/15 10:47;guozhang;KAFKA-1634_2015-01-22_18:47:37.patch;https://issues.apache.org/jira/secure/attachment/12694072/KAFKA-1634_2015-01-22_18%3A47%3A37.patch","24/Jan/15 08:06;guozhang;KAFKA-1634_2015-01-23_16:06:07.patch;https://issues.apache.org/jira/secure/attachment/12694292/KAFKA-1634_2015-01-23_16%3A06%3A07.patch","07/Feb/15 03:01;guozhang;KAFKA-1634_2015-02-06_11:01:08.patch;https://issues.apache.org/jira/secure/attachment/12697086/KAFKA-1634_2015-02-06_11%3A01%3A08.patch","27/Mar/15 03:16;guozhang;KAFKA-1634_2015-03-26_12:16:09.patch;https://issues.apache.org/jira/secure/attachment/12707563/KAFKA-1634_2015-03-26_12%3A16%3A09.patch","27/Mar/15 03:27;guozhang;KAFKA-1634_2015-03-26_12:27:18.patch;https://issues.apache.org/jira/secure/attachment/12707568/KAFKA-1634_2015-03-26_12%3A27%3A18.patch",,,,,,,,,,,,,,14.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Mar 30 20:41:08 UTC 2015,,,,,,,,,,"0|i2012f:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"21/Sep/14 01:49;junrao;The wiki is actually consistent with the code in trunk. The timestamp is used to decide whether some old consumer offsets can be garbage collected. Typically, the timestamp should just be the time when the offset is committed (and can be obtained just on the broker side). However, this idea is that a client, if needed, can set a larger timestamp if it wants to preserve the offset for longer. It's not clear to me if this is super useful. We can debate that in a separate jira if needed.;;;","21/Sep/14 03:03;nehanarkhede;[~junrao], that explanation is actually pretty unintuitive. So seems like this is something that needs to be fixed. The client shouldn't need to specify a timestamp for an offset commit. Unless I'm missing something that it is designed for. [~jjkoshy], any idea?;;;","21/Sep/14 03:03;nehanarkhede;Reopening until we have filed a JIRA to fix the issue.;;;","25/Sep/14 12:32;junrao;One use case is that if a client never wants the offset to be garbage collected on the broker, it can set timestamp to be max long. ;;;","25/Sep/14 13:01;nehanarkhede;How general is that use case and if it just a means for picking infinite retention, then why not just have a boolean option rather than a full timestamp? My main concern is that this is looking more like an after thought instead of a well thought out API. We should think how the user would interpret the timestamp and what makes sense as a general solution. ;;;","29/Sep/14 08:47;junrao;Another use case is the following. It may not make sense to retain an offset longer than the data retention time. So, if data is kept for only 7 days, a consumer client may want to set timestamp to be now + 7 days to preserve the offset as long as it's still valid.

Joel probably can comment on the general use cases more.
;;;","30/Sep/14 02:44;nehanarkhede;Basically, I'm not sure this is great user experience. When I looked at the API, I found it awkward to use and understand why I needed to specify a timestamp. If there are use cases that are general, I'd like to hear and maybe we should update documentation. But if not, we should remove it. [~jjkoshy] Any comments?;;;","30/Sep/14 06:56;jjkoshy;[~nehanarkhede] I agree that timestamp in the request API is a bit odd since that is an implementation detail on the server-side (on how long to retain offsets) and setting ""future"" timestamps on the client-side is a hack to ""trick"" the server into retaining the offset.

The use-cases though are as Jun described - i.e., if a client wants to ensure that offsets are retained for a certain period of time (regardless of when the server cleans up stale offsets). That said, the field could be renamed and reimplemented as a retentionPeriod field (not timestamp). i.e., if set the consumer would explicitly say ""retain my offsets for X milliseconds/days/whatever"". The broker can have a second hard staleness threshold to cap this client-driven staleness threshold.;;;","01/Oct/14 22:30;nehanarkhede;[~jjkoshy] Thanks for the explanation. If retention is the use case, it is easier to understand if it was called retentionPeriod. Since 0.8.2 is when this releases, it will be great to make that renaming change before 0.8.2 goes out. If there is a broker side feature that is required for this to work properly and it's not done, then we can either get rid of this and add it when it's useful or leave it in there as a no-op or with a warning. What do you prefer?;;;","11/Oct/14 06:35;jjkoshy;Actually, one more potential source of confusion is that we use OffsetAndMetadata for both offset commits requests and offset fetch responses.

i.e., an OffsetFetchResponse will contain: offset, metadata and this timestamp field. The timestamp field should really be ignored. It is annoying to document such things - i.e., tell users to just ignore the field.

Ideally, I think we should do the following:
* Remove the timestamp from the OffsetAndMetadata class
* Move it to the top-level of the OffsetCommitRequest and rename it to retentionMs
* The broker will compute the absolute time (based off time of receipt) that the offset should be expired
* The above absolute time will continue to be stored in the offsets topic and the cleanup thread can remove those offsets when they are past their TTL.
* OffsetFetchResponse will just return OffsetAndMetadata (no timestamp)

We (linkedin and possibly others) already deployed this to some of our consumers but if we can bump up the protocol version when doing the above and translate requests that come in with the older version I think it should be okay.
;;;","11/Oct/14 06:40;jjkoshy;(BTW, I'm looking for a  +1 or -1 on the above comment :) );;;","13/Oct/14 00:05;junrao;Joel,

I don't see OffsetFetchResponse contain timestamp (it only contains offset, metadata and error code). I agree that it's better to move retentionMs to the topic-level of OffsetCommitRequest. We can bump up the protocol version if needed.;;;","13/Oct/14 05:42;nehanarkhede;+1 to your suggestions above. Thanks [~jjkoshy];;;","14/Oct/14 02:00;jjkoshy;[~junrao] yes you are right. The OffsetFetchResponse returns offset, metadata and error - it does not include the timestamp.
;;;","14/Oct/14 07:57;guozhang;I will work on this after KAFKA-1583.;;;","21/Oct/14 12:07;junrao;Moving this to 0.8.3 since it's easier to fix after KAFKA-1583 is done.;;;","30/Oct/14 07:08;guozhang;While working on this: should a retention time better be scaled at secs than ms? Do we have scenarios where people want to just retain their offsets for miliseconds? If not then we may end up always having very large number for this field.;;;","31/Oct/14 02:43;guozhang;Created reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","07/Nov/14 07:35;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","08/Nov/14 08:54;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","18/Nov/14 09:42;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","22/Nov/14 06:00;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","02/Dec/14 03:44;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","02/Dec/14 10:03;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","06/Jan/15 04:19;dana.powers;possibly related to this JIRA: KAFKA-1841 .  The timestamp field itself was not in the released api version 0 and if it is to be included in 0.8.2 (this JIRA suggests it is, but to be removed in 0.8.3 ?) then I think it will need to be versioned.;;;","13/Jan/15 14:35;junrao;Committed KAFKA-1841 to 0.8.2. It would be easier to incorporate the changes in KAFKA-1841 into this jira and commit them together to trunk.;;;","15/Jan/15 07:50;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","15/Jan/15 07:51;guozhang;[~jjkoshy], [~junrao] My plan is to check in this patch first and than rebase 1481 on that, so could you take a look at the latest patch incorporating your comments?;;;","22/Jan/15 08:43;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","22/Jan/15 09:57;junrao;I guess you mean rebasing KAFAK-1841, instead of KAFKA-1481?;;;","23/Jan/15 10:47;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","24/Jan/15 08:06;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","07/Feb/15 03:01;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","19/Mar/15 00:16;junrao;[~guozhang], [~jjkoshy], in order to work on KAFKA-1927, we will need to have KAFKA-1841 merged into trunk, which depends on this jira.;;;","27/Mar/15 03:16;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","27/Mar/15 03:27;guozhang;Updated reviewboard https://reviews.apache.org/r/27391/diff/
 against branch origin/trunk;;;","27/Mar/15 08:17;guozhang;Thanks for the reviews, committed to trunk.;;;","27/Mar/15 08:20;jjkoshy;[~guozhang] we actually need to merge KAFKA-1841 now. Or do you want to do that in a separate jira?;;;","27/Mar/15 09:00;junrao;Also, could you also update the protocol wiki (https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-OffsetCommitRequest)? For the new version, please document the release from which the new version will be supported.;;;","27/Mar/15 11:17;guozhang;Just updated the protocol wiki with the new version. As for merging KAFKA-1841, I can do that after 04/06; if that is too late some one can pick it up.;;;","28/Mar/15 01:49;jjkoshy;Reopening since we need to merge KAFKA-1841;;;","30/Mar/15 00:49;junrao;Perhaps, we can do KAFKA-1841 together with KAFKA-2068. There will probably be less duplicated code that way.;;;","31/Mar/15 04:41;jjkoshy;Yes I think that makes more sense;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsumerPerformance reports a throughput much higher than the actual one,KAFKA-2202,12831037,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,omkreddy,capitao,capitao,19/May/15 23:01,11/Aug/15 11:57,22/Mar/23 15:10,11/Aug/15 11:57,0.8.2.0,,,,,,0.9.0.0,,,,,,,tools,,,,0,,,,,,"I've been using the kafka.tools.ConsumerPerformance tool for some benchmarking until in one of my tests I got a throughput much higher than the supported by my network interface.
The test consisted in consuming around ~4900 MB from one topic using one consumer with one thread. The reported throughput reported was ~1400 MB/s which surpasses the 10 Gbps of the network. The time for the whole operation was ~8 seconds, which should correspond to a throughput of ~612 MB/s.
Digging the ConsumerPerformance code, I've found this at line 73:
{code:java}
val elapsedSecs = (endMs - startMs - config.consumerConfig.consumerTimeoutMs) / 1000.0
{code}
The {{consumerTimeoutMs}} defined as 5000 at line 131 is always considered leading to wrong results.

This bug seems to be related to this one [https://issues.apache.org/jira/browse/KAFKA-1828]",,capitao,guozhang,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1828,,,,,,,,,,,,,,,,"14/Jun/15 19:27;omkreddy;KAFKA-2202.patch;https://issues.apache.org/jira/secure/attachment/12739486/KAFKA-2202.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Aug 11 03:57:47 UTC 2015,,,,,,,,,,"0|i2exj3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"14/Jun/15 19:27;omkreddy;Created reviewboard https://reviews.apache.org/r/35437/diff/
 against branch origin/trunk;;;","09/Aug/15 17:50;omkreddy;[~gwenshap] [~guozhang] pinging for review..;;;","11/Aug/15 11:57;guozhang;Thanks for the patch [~omkreddy], +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KAFKA-2205 causes existing Topic config changes to be lost,KAFKA-2446,12857275,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,aauradkar,aauradkar,aauradkar,20/Aug/15 01:10,20/Aug/15 09:18,22/Mar/23 15:10,20/Aug/15 09:18,,,,,,,,,,,,,,,,,,0,,,,,,"The path was changed from ""/config/topics/"" to ""/config/topic"". This causes existing config overrides to not get read",,aauradkar,githubbot,jjkoshy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Aug 20 01:18:11 UTC 2015,,,,,,,,,,"0|i2j44f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"20/Aug/15 08:15;githubbot;GitHub user auradkar opened a pull request:

    https://github.com/apache/kafka/pull/152

    Fix for KAFKA-2446

    This bug was introduced while committing KAFKA-2205. Basically, the path for topic overrides was renamed to ""topic"" from ""topics"". However, this causes existing topic config overrides to break because they will not be read from ZK anymore since the path is different.
    
    https://reviews.apache.org/r/34554/

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/auradkar/kafka 2446

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/152.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #152
    
----
commit 4bb7adeb27673145dcb735f9e2039a05d94faea8
Author: Aditya Auradkar <aauradkar@linkedin.com>
Date:   2015-08-20T00:12:04Z

    Fix for 2446

----
;;;","20/Aug/15 08:16;aauradkar;[~junrao][~jjkoshy] - Can one of you review this quickly?
https://github.com/apache/kafka/pull/152/

;;;","20/Aug/15 09:17;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/152
;;;","20/Aug/15 09:18;jjkoshy;Pushed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New producer metadata update always get all topics.,KAFKA-2042,12785098,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,becket_qin,becket_qin,becket_qin,24/Mar/15 16:12,25/Mar/15 11:57,22/Mar/23 15:10,25/Mar/15 11:57,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"The new java producer metadata.topics is initially empty so the producer sends TMR with empty topic set. The broker takes the empty requested topic set as all topics, so metadata.cluster contains all topic metadata. Later on, when a new topic was produced, it gets added into the metadata.topics. The next metadata update will only contain the meta data for this new topic, so the metadata.cluster will only have this topic. Since there are a lot of messages are still in the accumulator but has no metadata in metadata.cluster, if a caller thread do a flush(), the caller thread will block forever because the messages sitting in accumulator without metadata will never be ready to send.
We should add check for the metadata.topics, if it is empty, no TMR should be sent.",,becket_qin,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Mar/15 16:17;becket_qin;KAFKA-2042.patch;https://issues.apache.org/jira/secure/attachment/12706857/KAFKA-2042.patch","25/Mar/15 04:37;becket_qin;KAFKA-2042_2015-03-24_13:37:49.patch;https://issues.apache.org/jira/secure/attachment/12706992/KAFKA-2042_2015-03-24_13%3A37%3A49.patch","25/Mar/15 04:57;becket_qin;KAFKA-2042_2015-03-24_13:57:23.patch;https://issues.apache.org/jira/secure/attachment/12707003/KAFKA-2042_2015-03-24_13%3A57%3A23.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Mar 25 01:42:07 UTC 2015,,,,,,,,,,"0|i279lz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"24/Mar/15 16:17;becket_qin;Created reviewboard https://reviews.apache.org/r/32434/diff/
 against branch origin/trunk;;;","25/Mar/15 04:38;becket_qin;Updated reviewboard https://reviews.apache.org/r/32434/diff/
 against branch origin/trunk;;;","25/Mar/15 04:57;becket_qin;Updated reviewboard https://reviews.apache.org/r/32434/diff/
 against branch origin/trunk;;;","25/Mar/15 06:49;guozhang;Thanks for the patch, committed to trunk.;;;","25/Mar/15 07:53;junrao;Could you explain a bit more when the new producer will send a TMR with an empty topic list? I can see this happen if after the producer is created, no message is sent within the window of metadata age. Is that the only case when this can happen?;;;","25/Mar/15 08:12;becket_qin;Yes, it depends on whether the topic list is empty or not when we send the first TMR.
I might miss something but I think the TMR will be sent very soon after the producer is instantiated. 
In the first NetworkClient.poll(), it checks if metadata needs update by getting the max of
timeToNextMeatadataUpdate
timeToNextReconnectAttempt
waitForMetadataFetch
All of them will be 0 on starting up. That means the TMR will be sent at the first poll().
;;;","25/Mar/15 08:37;junrao;If I start a console-producer w/o typing in any message, the producer actually doesn't send any metadata request immediately. On initializing the producer, we update metadata with the bootstrap broker. This sets lastRefreshMs to the current time. So, in NetworkClient.poll(), timeToNextMeatadataUpdate will actually be the metadata age, which defaults to 300 secs.

In what situation did you discover this problem?;;;","25/Mar/15 09:42;becket_qin;Ah, yes, that's right. I found this issue when starting mirror maker. Because a large mirror maker cluster might take some time to finish consumer rebalance. So that's why no producer.send() was called before the first TMR was sent. So this issue probably will not cause issue in normal cases under default settings.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SocketServer.Processor should catch exception and close the socket properly in configureNewConnections.,KAFKA-2353,12846650,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,becket_qin,becket_qin,22/Jul/15 03:19,21/Jun/17 15:56,22/Mar/23 15:10,24/Jul/15 08:19,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"We see an increasing number of sockets in CLOSE_WAIT status in our production environment in recent couple of days. From the thread dump it seems one of the Processor thread has died but the acceptor was still putting many new connections its new connection queue.

The cause of dead Processor thread was due to we are not catching all the exceptions in the Processor thread. For example, in our case it seems to be an exception thrown in configureNewConnections().

",,becket_qin,guozhang,gwenshap,wupppgg@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jul/15 07:03;becket_qin;KAFKA-2353.patch;https://issues.apache.org/jira/secure/attachment/12746438/KAFKA-2353.patch","22/Jul/15 13:02;becket_qin;KAFKA-2353_2015-07-21_22:02:24.patch;https://issues.apache.org/jira/secure/attachment/12746472/KAFKA-2353_2015-07-21_22%3A02%3A24.patch","23/Jul/15 08:51;becket_qin;KAFKA-2353_2015-07-22_17:51:42.patch;https://issues.apache.org/jira/secure/attachment/12746685/KAFKA-2353_2015-07-22_17%3A51%3A42.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jun 21 07:41:49 UTC 2017,,,,,,,,,,"0|i2hiiv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"22/Jul/15 07:03;becket_qin;Created reviewboard https://reviews.apache.org/r/36664/diff/
 against branch origin/trunk;;;","22/Jul/15 07:35;becket_qin;[~gwenshap] Can you help take a look at this patch when get some time since you made a lot of change in the socket server in KAFKA-1928 :) Thanks.;;;","22/Jul/15 08:00;gwenshap;I left comments in RB :);;;","22/Jul/15 13:02;becket_qin;Updated reviewboard https://reviews.apache.org/r/36664/diff/
 against branch origin/trunk;;;","23/Jul/15 08:51;becket_qin;Updated reviewboard https://reviews.apache.org/r/36664/diff/
 against branch origin/trunk;;;","24/Jul/15 08:19;guozhang;Committed to trunk, thanks.;;;","24/Jul/15 08:21;guozhang;I made a mistake on not changing the author... [~gwenshap] do you know if it is possible to change the commit message?;;;","24/Jul/15 08:30;gwenshap;Perhaps:
git commit --amend --author=""User Name <user@abc.com>"";;;","24/Jul/15 08:50;guozhang;That seems not work once it is already pushed to apache.;;;","24/Jul/15 11:14;becket_qin;[~guozhang] I'm fine with that : ). Thanks a lot, [~gwenshap] and [~guozhang].;;;","21/Jun/17 15:41;wupppgg@gmail.com;Excuse me sir. What is the Affects Version of this patch?
I have the same error just like you, so I want to try this patch.
My kafka version is 0.8.2.2.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Dead lock between delete log segment and shutting down.,KAFKA-2454,12857598,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,becket_qin,becket_qin,21/Aug/15 01:31,22/Oct/15 04:25,22/Mar/23 15:10,22/Oct/15 04:25,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"When the broker shutdown, it will shutdown scheduler which grabs the scheduler lock then wait for all the threads in scheduler to shutdown.

The dead lock will happen when the scheduled task try to delete old log segment, it will schedule a log delete task which also needs to acquire the scheduler lock. In this case the shutdown thread will hold scheduler lock and wait for the the log deletion thread to finish, but the log deletion thread will block on waiting for the scheduler lock.

Related stack trace:
{noformat}
""Thread-1"" #21 prio=5 os_prio=0 tid=0x00007fe7601a7000 nid=0x1a4e waiting on condition [0x00007fe7cf698000]
   java.lang.Thread.State: TIMED_WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x0000000640d53540> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1465)
        at kafka.utils.KafkaScheduler.shutdown(KafkaScheduler.scala:94)
        - locked <0x0000000640b6d480> (a kafka.utils.KafkaScheduler)
        at kafka.server.KafkaServer$$anonfun$shutdown$4.apply$mcV$sp(KafkaServer.scala:352)
        at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:79)
        at kafka.utils.Logging$class.swallowWarn(Logging.scala:92)
        at kafka.utils.CoreUtils$.swallowWarn(CoreUtils.scala:51)
        at kafka.utils.Logging$class.swallow(Logging.scala:94)
        at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:51)
        at kafka.server.KafkaServer.shutdown(KafkaServer.scala:352)
        at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:42)
        at com.linkedin.kafka.KafkaServer.notifyShutdown(KafkaServer.java:99)
        at com.linkedin.util.factory.lifecycle.LifeCycleMgr.notifyShutdownListener(LifeCycleMgr.java:123)
        at com.linkedin.util.factory.lifecycle.LifeCycleMgr.notifyListeners(LifeCycleMgr.java:102)
        at com.linkedin.util.factory.lifecycle.LifeCycleMgr.notifyStop(LifeCycleMgr.java:82)
        - locked <0x0000000640b77bb0> (a java.util.ArrayDeque)
        at com.linkedin.util.factory.Generator.stop(Generator.java:177)
        - locked <0x0000000640b77bc8> (a java.lang.Object)
        at com.linkedin.offspring.servlet.OffspringServletRuntime.destroy(OffspringServletRuntime.java:82)
        at com.linkedin.offspring.servlet.OffspringServletContextListener.contextDestroyed(OffspringServletContextListener.java:51)
        at org.eclipse.jetty.server.handler.ContextHandler.doStop(ContextHandler.java:813)
        at org.eclipse.jetty.servlet.ServletContextHandler.doStop(ServletContextHandler.java:160)
        at org.eclipse.jetty.webapp.WebAppContext.doStop(WebAppContext.java:516)
        at com.linkedin.emweb.WebappContext.doStop(WebappContext.java:35)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)
        - locked <0x00000006400018b8> (a java.lang.Object)
        at com.linkedin.emweb.ContextBasedHandlerImpl.doStop(ContextBasedHandlerImpl.java:112)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)
        - locked <0x0000000640001900> (a java.lang.Object)
        at com.linkedin.emweb.WebappDeployerImpl.stop(WebappDeployerImpl.java:349)
        at com.linkedin.emweb.WebappDeployerImpl.doStop(WebappDeployerImpl.java:414)
        - locked <0x00000006400019c0> (a com.linkedin.emweb.MapBasedHandlerImpl)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)
        - locked <0x00000006404ee8e8> (a java.lang.Object)
        at org.eclipse.jetty.util.component.AggregateLifeCycle.doStop(AggregateLifeCycle.java:107)
        at org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:69)
        at org.eclipse.jetty.server.handler.HandlerWrapper.doStop(HandlerWrapper.java:108)
        at org.eclipse.jetty.server.Server.doStop(Server.java:338)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)
        - locked <0x0000000640476ab0> (a java.lang.Object)
        at com.linkedin.emweb.BaseRunner.destroy(BaseRunner.java:162)
        at com.linkedin.spring.core.TerminationHandler.destroy(TerminationHandler.java:151)
        at com.linkedin.spring.core.TerminationHandler.runTermination(TerminationHandler.java:113)
        at com.linkedin.spring.core.TerminationHandler.destroy(TerminationHandler.java:79)
        at com.linkedin.spring.core.SettableFactoryBean.destroy(SettableFactoryBean.java:68)
        at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:211)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:500)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:476)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:445)
        at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1078)
        at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1052)
        at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:1000)
        - locked <0x000000064001c718> (a java.lang.Object)
        at com.linkedin.spring.cmdline.CmdLineAppRunner.terminate(CmdLineAppRunner.java:277)
        at com.linkedin.spring.cmdline.CmdLineAppRunner$1.run(CmdLineAppRunner.java:219)
...
""kafka-scheduler-2"" #272 daemon prio=5 os_prio=0 tid=0x00007fecd58be000 nid=0x7868 waiting for monitor entry [0x00007feb991d4000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at kafka.utils.KafkaScheduler.schedule(KafkaScheduler.scala:103)
        - waiting to lock <0x0000000640b6d480> (a kafka.utils.KafkaScheduler)
        at kafka.log.Log.kafka$log$Log$$asyncDeleteSegment(Log.scala:789)
        at kafka.log.Log.kafka$log$Log$$deleteSegment(Log.scala:775)
        - locked <0x0000000641d18030> (a java.lang.Object)
        at kafka.log.Log$$anonfun$deleteOldSegments$1.apply(Log.scala:533)
        at kafka.log.Log$$anonfun$deleteOldSegments$1.apply(Log.scala:533)
        at scala.collection.immutable.List.foreach(List.scala:318)
        at kafka.log.Log.deleteOldSegments(Log.scala:533)
        - locked <0x0000000641d18030> (a java.lang.Object)
        at kafka.log.LogManager.kafka$log$LogManager$$cleanupExpiredSegments(LogManager.scala:421)
        at kafka.log.LogManager$$anonfun$cleanupLogs$3.apply(LogManager.scala:452)
        at kafka.log.LogManager$$anonfun$cleanupLogs$3.apply(LogManager.scala:450)
        at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
        at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
        at kafka.log.LogManager.cleanupLogs(LogManager.scala:450)
        at kafka.log.LogManager$$anonfun$startup$1.apply$mcV$sp(LogManager.scala:190)
        at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:108)
        at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
{noformat}
",,becket_qin,crazyjvm,githubbot,jjkoshy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Oct 21 20:25:08 UTC 2015,,,,,,,,,,"0|i2j633:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Aug/15 02:23;githubbot;GitHub user becketqin opened a pull request:

    https://github.com/apache/kafka/pull/153

    KAFKA-2454: Deadlock between log segment deletion and server shutdown.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/becketqin/kafka KAFKA-2454

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/153.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #153
    
----
commit 27c6a6e70f969ee13d857213d5a0aa3e40b1c19f
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2015-08-20T18:21:32Z

    KAFKA-2454: Deadlock between log segment deletion and server shutdown.

----
;;;","21/Aug/15 08:18;jjkoshy;I'm a bit unclear on the root cause that you describe. The thread-dump shows that the deletion task has not even entered the executor at this point. It is definitely blocked on entering the executor, but that means {{executor.awaitTermination}} must be from some other already executing task right?;;;","21/Aug/15 08:28;becket_qin;[~jjkoshy] Here are the two threads:
Thread 1: The log deletion task that periodically running to delete log segments. This task has been scheduled when broker starts up. The problem is it is deleting log asynchronously by submitting another file deletion task to the scheduler. The deadlock happens here.
Thread 2: It is just the thread executing KafkaServer.shutdown(), it calls KafkaScheduler.shutdown() which grabs the lock and executor.awaitTermination().;;;","22/Aug/15 01:32;jjkoshy;Thanks - got it. Will take a look at your patch today.;;;","22/Oct/15 04:24;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/153
;;;","22/Oct/15 04:25;jjkoshy;Issue resolved by pull request 153
[https://github.com/apache/kafka/pull/153];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move Kafka version to be generated in code by build (instead of in manifest),KAFKA-1901,12770011,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,omkreddy,jbrosenberg@gmail.com,jbrosenberg@gmail.com,26/Jan/15 14:52,07/Jan/16 04:49,22/Mar/23 15:10,21/Aug/15 04:28,0.8.2.0,,,,,,0.9.0.0,,,,,,,,,,,3,,,,,,"With 0.8.2 (rc2), I've started seeing this warning in the logs of apps deployed to our staging (both server and client):

{code}
2015-01-23 00:55:25,273  WARN [async-message-sender-0] common.AppInfo$ - Can't read Kafka version from MANIFEST.MF. Possible cause: java.lang.NullPointerException
{code}

The issues is that in our deployment, apps are deployed with single 'shaded' jars (e.g. using the maven shade plugin).  This means the MANIFEST.MF file won't have a kafka version.  Instead, suggest the kafka build generate the proper version in code, as part of the build.",,3dragan,githubbot,guozhang,jbrosenberg@gmail.com,jjkoshy,joestein,jvurghese,omkreddy,silves89,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jun/15 18:11;omkreddy;KAFKA-1901.patch;https://issues.apache.org/jira/secure/attachment/12741831/KAFKA-1901.patch","26/Jun/15 15:49;omkreddy;KAFKA-1901_2015-06-26_13:16:29.patch;https://issues.apache.org/jira/secure/attachment/12742069/KAFKA-1901_2015-06-26_13%3A16%3A29.patch","10/Jul/15 19:15;omkreddy;KAFKA-1901_2015-07-10_16:42:53.patch;https://issues.apache.org/jira/secure/attachment/12744693/KAFKA-1901_2015-07-10_16%3A42%3A53.patch","14/Jul/15 20:32;omkreddy;KAFKA-1901_2015-07-14_17:59:56.patch;https://issues.apache.org/jira/secure/attachment/12745245/KAFKA-1901_2015-07-14_17%3A59%3A56.patch","09/Aug/15 17:37;omkreddy;KAFKA-1901_2015-08-09_15:04:39.patch;https://issues.apache.org/jira/secure/attachment/12749456/KAFKA-1901_2015-08-09_15%3A04%3A39.patch","20/Aug/15 15:09;omkreddy;KAFKA-1901_2015-08-20_12:35:00.patch;https://issues.apache.org/jira/secure/attachment/12751430/KAFKA-1901_2015-08-20_12%3A35%3A00.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jan 06 20:49:07 UTC 2016,,,,,,,,,,"0|i24sbr:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"28/Jan/15 02:23;jbrosenberg@gmail.com;At the very least, this could be updated to just log at INFO level, and have it state that the version was not available in the manifest (rather than log an NPE).;;;","28/Jan/15 15:06;jjkoshy;Funny I was thinking about this earlier today - I think we should actually extract the git hash as well and generate some code that produces the app-info. http://forums.gradle.org/gradle/topics/how_can_i_store_the_git_revision_for_use_in_the_project
So app-info would include git hash, branch, major/minor version, etc. Furthermore, we can emit a metric that reports the md5 of this entire app-info string modulo some large number (say 100000). That may be convenient to (at a glance at graphs) say the brokers are all running the same version. I'm more interested in the app-info string though for the git hash. When people report issues it is always helpful to get the precise git hash they are at if they are (say) on trunk.;;;","28/Jan/15 15:43;joestein;Can we collect that info during a meta data fetch for producers and consumers too? We can visualize producers, consumers and brokers roll states from each brokers perspective.;;;","29/Jan/15 02:27;jjkoshy;Can you clarify what you mean by metadata fetch for p/c and rolling states? Producers and consumers also contain app-info right?;;;","29/Jan/15 02:53;joestein;The same way you are suggesting for the brokers to have their metric for version emitted, do the same from producers and consumers. I think though that the producer and consumer metric should keep flowing down to the brokers so you see the metrics of what each broker is seeing for each producer also. Ops can watch the brokers roll and then all the different consumers and producers and see how everything is going during testing prior to release succinctly. Making sure this is in the wire protocol allows non apache clients to utilize the feature.;;;","21/Mar/15 02:19;jbrosenberg@gmail.com;This is really a pretty severe error.  Any client that uses the javaapi producer within it's app will see this error everytime the app is started.  It's not just the server, but any producer client.  It would seem a quick fix would be to catch the NPE, and log as INFO that it was unable to determine the kafka version.  Or log nothing at all.

After rolling this out to our environment, I'm fielding lots of inquiries from app developers (should I be worried about this?)....;;;","23/Jun/15 20:10;omkreddy;Probably the easiest thing to do would be to generate a properties file (kafkaversion.props) with  version, git-hash info in it and put that in kafka jar as a resource. 

[~jbrosenberg@gmail.com] Do you think this approach works for you? ;;;","24/Jun/15 20:11;jbrosenberg@gmail.com;[~omkreddy] Yes, that sounds find.  Preferably it should not be at the top-level directory, so as not to be confusing when bundled as part of a shaded jar!;;;","25/Jun/15 18:11;omkreddy;Created reviewboard https://reviews.apache.org/r/35867/diff/
 against branch origin/trunk;;;","26/Jun/15 15:49;omkreddy;Updated reviewboard https://reviews.apache.org/r/35867/diff/
 against branch origin/trunk;;;","10/Jul/15 19:15;omkreddy;Updated reviewboard https://reviews.apache.org/r/35867/diff/
 against branch origin/trunk;;;","10/Jul/15 19:20;omkreddy;[~jjkoshy] pinging for review;;;","10/Jul/15 21:57;jjkoshy;Will review today.;;;","14/Jul/15 20:33;omkreddy;Updated reviewboard https://reviews.apache.org/r/35867/diff/
 against branch origin/trunk;;;","09/Aug/15 17:37;omkreddy;Updated reviewboard https://reviews.apache.org/r/35867/diff/
 against branch origin/trunk;;;","20/Aug/15 15:09;omkreddy;Updated reviewboard https://reviews.apache.org/r/35867/diff/
 against branch origin/trunk;;;","21/Aug/15 04:28;jjkoshy;Thanks for the patch - committed to trunk.;;;","10/Sep/15 07:16;guozhang;[~omkreddy] I ran into an issue with determineCommitId task in build.gradle because I packed the refs into .git/packed-refs, and hence .git/refs/heads becomes empty. Is it resolvable in build.gradle?;;;","10/Sep/15 07:16;guozhang;Just to be more clear, an error is thrown in line 404 complaining there is no .git/ref/heads/[BRANCH_NAME] file.;;;","14/Sep/15 00:54;githubbot;GitHub user omkreddy opened a pull request:

    https://github.com/apache/kafka/pull/209

    KAFKA-1901: follow-up on KAFKA-1901; Added error handling.

    @guozhangwang  added .git/refs/heads/ file existence check.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/omkreddy/kafka KAFKA-1901

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/209.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #209
    
----

----
;;;","07/Jan/16 04:49;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/209
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unclean leader election docs outdated,KAFKA-2551,12864254,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Trivial,Fixed,omkreddy,sslavic,sslavic,15/Sep/15 20:54,14/Mar/16 17:17,22/Mar/23 15:10,14/Mar/16 17:17,0.8.2.2,,,,,,0.10.0.0,,,,,,,website,,,,0,documentation,newbie,,,,"Current unclean leader election docs state:
{quote}
In the future, we would like to make this configurable to better support use cases where downtime is preferable to inconsistency.
{quote}

Since 0.8.2.0, unclean leader election strategy (whether to allow it or not) is already configurable via {{unclean.leader.election.enable}} broker config property.

That sentence is in both https://svn.apache.org/repos/asf/kafka/site/083/design.html and https://svn.apache.org/repos/asf/kafka/site/082/design.html near the end of ""Unclean leader election: What if they all die?"" section. Next section, ""Availability and Durability Guarantees"", mentions ability to disable unclean leader election, so likely just this one reference needs to be updated.",,githubbot,jinxing6042@126.com,noslowerdna,omkreddy,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Mar 14 03:33:39 UTC 2016,,,,,,,,,,"0|i2k78v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Sep/15 17:22;jinxing6042@126.com;yes I agree with you;
currently we can configure via unclean.leader.election.enable;

for this parameter, I did an experiment:
I have 2 brokers(broker0 and broker1) and 1 topic named ""p1r2"" with 1 partition and 2 replicas;
firstly, I use default unclean.leader.election.enable=true; at this moment log size=1000;
then I shutdown broker1, and use console producer to send messages into kafka queue, tail log size=1009;
then I shutdown broker0, and restart broker1, found log size=1000, but the leader changed to be broker1;
but when I want to send messages to kafka(at this moment, only broker1 alive), I got exception as below:


[2015-09-21 17:06:06,654] ERROR fetching topic metadata for topics [Set(p1r2)] from broker [ArrayBuffer(id:0,host:soho-pipe-kafka-test1-test,port:9092, id:1,host:soho-pipe-kafka-test2-test:9092,port:9092)] failed (kafka.utils.Utils$)
kafka.common.KafkaException: fetching topic metadata for topics [Set(p1r2)] from broker [ArrayBuffer(id:0,host:soho-pipe-kafka-test1-test,port:9092, id:1,host:soho-pipe-kafka-test2-test:9092,port:9092)] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:72)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.async.DefaultEventHandler$$anonfun$handle$2.apply$mcV$sp(DefaultEventHandler.scala:78)
	at kafka.utils.Utils$.swallow(Utils.scala:172)
	at kafka.utils.Logging$class.swallowError(Logging.scala:106)
	at kafka.utils.Utils$.swallowError(Utils.scala:45)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:78)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:105)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:88)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:68)
	at scala.collection.immutable.Stream.foreach(Stream.scala:547)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:67)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:45)
Caused by: java.nio.channels.ClosedChannelException
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:100)
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:73)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:72)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:113)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:58)
	... 12 more
[2015-09-21 17:06:06,655] ERROR Failed to send requests for topics p1r2 with correlation ids in [17,24] (kafka.producer.async.DefaultEventHandler)
[2015-09-21 17:06:06,655] ERROR Error in handling batch of 1 events (kafka.producer.async.ProducerSendThread)
kafka.common.FailedToSendMessageException: Failed to send messages after 3 tries.
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:90)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:105)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:88)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:68)
	at scala.collection.immutable.Stream.foreach(Stream.scala:547)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:67)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:45)
with unclean.leader.election.enable, I was expecting that I can still send messages to broker1, even though I lost messages on broker0;
Am I wrong?;;;","13/Mar/16 15:31;omkreddy;GitHub user omkreddy opened a pull request:

    https://github.com/apache/kafka/pull/1054;;;","14/Mar/16 11:33;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1054
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
releaseTarGz target needs signing task,KAFKA-1297,12699308,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,07/Mar/14 09:05,14/Jun/14 23:23,22/Mar/23 15:10,21/Mar/14 00:08,0.8.2.0,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"./gradlew releaseTarGz

three warnings found
:core:processResources UP-TO-DATE
:core:classes
:core:copyDependantLibs UP-TO-DATE
:core:jar
:core:signArchives FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':core:signArchives'.
> Cannot perform signing task ':core:signArchives' because it has no configured signatory

",,coderplay,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,377655,,,Sat Jun 14 15:23:00 UTC 2014,,,,,,,,,,"0|i1t2pj:",377947,,,,,,,,,,,,,,,,,,,,"07/Mar/14 09:06;junrao;Joe Stein,

Do you know how we can run the releaseTarGz target w/o setting the signing key?;;;","20/Mar/14 23:22;junrao;We can use the following workaround. Then, we don't need to set up the signing key. Will check in a trivial change in README.

./gradlew releaseTarGz -x signArchives;;;","21/Mar/14 00:08;junrao;Committed to trunk.;;;","14/Jun/14 08:20;coderplay;Hi Jun,

Seems still can't work when building kafka like below

./gradlew releaseTarGzAll -x signArchives ;;;","14/Jun/14 23:23;junrao;Not sure why it doesn't work. However, if you run the individual command, it works.
./gradlew -PscalaVersion=2.10.1 releaseTarGz  -x signArchives;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
the pom output from publish and publish-local is not accurate,KAFKA-944,12653347,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,charmalloc,charmalloc,charmalloc,18/Jun/13 07:30,20/Jun/13 11:00,22/Mar/23 15:10,20/Jun/13 11:00,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"the groupId in the publish-local and publish output is wrong

its

<groupId>org.apache</groupId>

and should be

<groupId>org.apache.kafka</groupId> 

per https://issues.apache.org/jira/browse/INFRA-6399

also, I think we should be adding this http://www.apache.org/dev/publishing-maven-artifacts.html#adjust-maven maybe some other things going through it over again",,charmalloc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jun/13 07:37;charmalloc;KAFKA-944.patch;https://issues.apache.org/jira/secure/attachment/12588722/KAFKA-944.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,333625,,,Thu Jun 20 03:00:06 UTC 2013,,,,,,,,,,"0|i1ljw7:",333953,,,,,,,,,,,,,,,,,,,,"18/Jun/13 07:41;charmalloc;Some sbt docs in publishing http://www.scala-sbt.org/0.12.3/docs/Detailed-Topics/Publishing.html;;;","20/Jun/13 07:37;charmalloc;so far in my research and testing these are the changes required

i tried to stage the artifacts to apache central but getting an auth error (even when navigating outside of SBT through a browser) so I will open a INFRA ticket for that part;;;","20/Jun/13 11:00;charmalloc;before publish local

[warn] 		::::::::::::::::::::::::::::::::::::::::::::::
[warn] 		::          UNRESOLVED DEPENDENCIES         ::
[warn] 		::::::::::::::::::::::::::::::::::::::::::::::
[warn] 		:: org.apache.kafka#kafka_2.9.1;0.8.0-beta1: not found
[warn] 		::::::::::::::::::::::::::::::::::::::::::::::

and after publish local :)

Joes-MacBook-Air:stub joestein$ ./sbt compile
[info] Set current project to default-63d5f2 (in build file:/opt/medialets/SymanticManager/scala/stub/)
[info] Updating {file:/opt/medialets/SymanticManager/scala/stub/}default-63d5f2...
[info] Done updating.
[success] Total time: 4 s, completed Jun 19, 2013 10:59:14 PM;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Github is still showing 0.7 as the default branch,KAFKA-1128,12678232,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,joestein,joestein,08/Nov/13 22:46,07/Dec/13 16:02,22/Mar/23 15:10,07/Dec/13 16:02,,,,,,,0.8.1,,,,,,,,,,,0,,,,,,"https://github.com/apache/kafka

I think this is because we don't have a master branch.  My thoughts are we should branch trunk creating a master branch and then everything would be ok... we then start using master as we used to use trunk.

I think this is important to promote the adoption of 0.8.0 otherwise folks that find Kafka on github are still going to start with 0.7 and we should always be whatever is latest and live (0.9 moving forward and so on) from the main repo.

thoughts?",,joestein,omnomnom,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,357607,,,Sat Dec 07 08:02:04 UTC 2013,,,,,,,,,,"0|i1pnbz:",357897,,,,,,,,,,,,,,,,,,,,"08/Nov/13 23:32;omnomnom;Actually you don't need to create any branches, just head to https://github.com/apache/kafka/settings and adjust settings appropriately: http://take.ms/Qqv8u2;;;","08/Nov/13 23:36;joestein;Yes, but I was trying to avoid bugging the INFRA folks as I am not sure how that would get changed if we could do it ourselves but contacting Apache INFRA is an option too, sure.;;;","08/Nov/13 23:37;joestein;I don't have access to this in github but if someone else does and can make the change to trunk and save then awesome!!!;;;","07/Dec/13 15:43;joestein;opened an INFRA ticket https://issues.apache.org/jira/browse/INFRA-7079;;;","07/Dec/13 16:02;joestein;all set now https://github.com/apache/kafka;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DelayedOperationPurgatory should remove the pair in watchersForKey with empty watchers list,KAFKA-2160,12826383,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,guozhang,guozhang,01/May/15 02:18,06/Jun/15 07:13,22/Mar/23 15:10,20/May/15 10:17,,,,,,,,,,,,,,,,,,0,,,,,,"With purgatory usage in consumer coordinator, it will be common that watcher lists are very short and live only for a short time. So we'd better clean them from the watchersForKey Pool once the list become empty in checkAndComplete() calls. ",,guozhang,jjkoshy,mgharat,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2253,,,,,,,,,,,,,,,,,,,,,,"16/May/15 02:10;guozhang;KAFKA-2160.patch;https://issues.apache.org/jira/secure/attachment/12733207/KAFKA-2160.patch","01/May/15 05:03;guozhang;KAFKA-2160.patch;https://issues.apache.org/jira/secure/attachment/12729613/KAFKA-2160.patch","01/May/15 06:20;guozhang;KAFKA-2160_2015-04-30_15:20:14.patch;https://issues.apache.org/jira/secure/attachment/12729639/KAFKA-2160_2015-04-30_15%3A20%3A14.patch","07/May/15 07:31;guozhang;KAFKA-2160_2015-05-06_16:31:48.patch;https://issues.apache.org/jira/secure/attachment/12730997/KAFKA-2160_2015-05-06_16%3A31%3A48.patch","19/May/15 05:08;guozhang;KAFKA-2160_2015-05-18_14:07:48.patch;https://issues.apache.org/jira/secure/attachment/12733624/KAFKA-2160_2015-05-18_14%3A07%3A48.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jun 05 23:13:09 UTC 2015,,,,,,,,,,"0|i2e5jr:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"01/May/15 05:03;guozhang;Created reviewboard https://reviews.apache.org/r/33731/diff/
 against branch origin/trunk;;;","01/May/15 06:20;guozhang;Updated reviewboard https://reviews.apache.org/r/33731/diff/
 against branch origin/trunk;;;","07/May/15 07:31;guozhang;Updated reviewboard https://reviews.apache.org/r/33731/diff/
 against branch origin/trunk;;;","16/May/15 02:10;guozhang;Created reviewboard https://reviews.apache.org/r/34283/diff/
 against branch origin/trunk;;;","16/May/15 06:27;guozhang;Ran kafka.TestPurgatoryPerformance to compare the performance of purgatory against trunk.

Setup: request rate = 1000 / sec, latency pct50 = 50ms, pct75 = 75ms, each request has 3 keys. Test with varying total key space size (with more keys it is more likely that some key's watch list gets empty and hence can be removed). 

The following table shows elapsed time (ms):

||#.keys||100||1000||10000||10000||100000||
|trunk (without global lock)|100339|100616|100018|100280|100324|
|K2160 (with global lock)|100157|100270|100330|99934|99867|;;;","16/May/15 06:28;guozhang;[~junrao][~jjkoshy] Could you take a look at the most recent approach? If it works promising to you I will pursue this direction and make some more optimizations on the coordiantor's usage of the purgatories.;;;","16/May/15 06:49;jjkoshy;I would be surprised if the global RW lock is a problem since it is all in memory and purged only at an interval. This works well for the coordinator use case where you have empty watchers created slowly. As we discussed offline earlier in the week, I suggested this for simplicity. If in future there are other delayed operation purgatories in which these get created very quickly then this approach may not work as well. However, I doubt we will have such use-cases.;;;","19/May/15 05:08;guozhang;Updated reviewboard https://reviews.apache.org/r/34283/diff/
 against branch origin/trunk;;;","20/May/15 04:56;guozhang;Ping [~junrao] for another look at this patch as it is blocking some other implementations (KAFKA-2017, KAFKA-2018).;;;","20/May/15 10:17;guozhang;Thanks for the review, committed to trunk.;;;","06/Jun/15 07:13;mgharat;We hit a deadlock while running brokers with git hash: 9e894aa0173b14d64a900bcf780d6b7809368384
{code}
Found one Java-level deadlock:
=============================
""kafka-request-handler-a"":
  waiting for ownable synchronizer 0x00000006da08f9e0, (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync),
  which is held by ""ExpirationReaper-xyz""
""ExpirationReaper-xyz"":
  waiting to lock monitor 0x00007f4500004e18 (object 0x00000006b0563fe8, a java.util.LinkedList),
  which is held by ""kafka-request-handler-b""
""kafka-request-handler-b"":
  waiting for ownable synchronizer 0x00000006da08f9e0, (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync),
  which is held by ""ExpirationReaper-xyz""

""kafka-request-handler-a"":
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00000006da08f9e0> (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(AbstractQueuedSynchronizer.java:967)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(AbstractQueuedSynchronizer.java:1283)
        at java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.lock(ReentrantReadWriteLock.java:727)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:296)
        at kafka.utils.CoreUtils$.inReadLock(CoreUtils.scala:304)
        at kafka.server.DelayedOperationPurgatory.checkAndComplete(DelayedOperation.scala:224)
        at kafka.server.ReplicaManager.tryCompleteDelayedFetch(ReplicaManager.scala:166)
        at kafka.cluster.Partition.kafka$cluster$Partition$$maybeIncrementLeaderHW(Partition.scala:358)
        at kafka.cluster.Partition$$anonfun$maybeExpandIsr$1.apply$mcV$sp(Partition.scala:288)
        at kafka.cluster.Partition$$anonfun$maybeExpandIsr$1.apply(Partition.scala:270)
        at kafka.cluster.Partition$$anonfun$maybeExpandIsr$1.apply(Partition.scala:270)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:298)
        at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:306)
        at kafka.cluster.Partition.maybeExpandIsr(Partition.scala:268)
        at kafka.cluster.Partition.updateReplicaLogReadResult(Partition.scala:244)
        at kafka.server.ReplicaManager$$anonfun$updateFollowerLogReadResults$2.apply(ReplicaManager.scala:790)
        at kafka.server.ReplicaManager$$anonfun$updateFollowerLogReadResults$2.apply(ReplicaManager.scala:787)
        at scala.collection.immutable.Map$Map4.foreach(Map.scala:181)
        at kafka.server.ReplicaManager.updateFollowerLogReadResults(ReplicaManager.scala:787)
        at kafka.server.ReplicaManager.fetchMessages(ReplicaManager.scala:432)
        at kafka.server.KafkaApis.handleFetchRequest(KafkaApis.scala:312)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:60)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
        at java.lang.Thread.run(Thread.java:745)

""ExpirationReaper-xyz"":
        at kafka.server.DelayedOperationPurgatory$Watchers.watched(DelayedOperation.scala:278)
        - waiting to lock <0x00000006b0563fe8> (a java.util.LinkedList)
        at kafka.server.DelayedOperationPurgatory$$anonfun$kafka$server$DelayedOperationPurgatory$$removeKeyIfEmpty$1.apply(DelayedOperation.scala:258)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:298)
        at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:306)
        at kafka.server.DelayedOperationPurgatory.kafka$server$DelayedOperationPurgatory$$removeKeyIfEmpty(DelayedOperation.scala:256)
        at kafka.server.DelayedOperationPurgatory$Watchers.purgeCompleted(DelayedOperation.scala:322)
        - locked <0x000000071a86a478> (a java.util.LinkedList)
        at kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper$$anonfun$3.apply(DelayedOperation.scala:347)
        at kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper$$anonfun$3.apply(DelayedOperation.scala:347)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper.doWork(DelayedOperation.scala:347)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)

""kafka-request-handler-b"":
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00000006da08f9e0> (a java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199)
        at java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.lock(ReentrantReadWriteLock.java:943)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:296)
        at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:306)
        at kafka.server.DelayedOperationPurgatory.kafka$server$DelayedOperationPurgatory$$removeKeyIfEmpty(DelayedOperation.scala:256)
        at kafka.server.DelayedOperationPurgatory$Watchers.tryCompleteWatched(DelayedOperation.scala:303)
        - locked <0x00000006b0563fe8> (a java.util.LinkedList)
        at kafka.server.DelayedOperationPurgatory.checkAndComplete(DelayedOperation.scala:228)
        at kafka.server.ReplicaManager.tryCompleteDelayedFetch(ReplicaManager.scala:166)
        at kafka.cluster.Partition$$anonfun$appendMessagesToLeader$1.apply(Partition.scala:426)
        at kafka.cluster.Partition$$anonfun$appendMessagesToLeader$1.apply(Partition.scala:410)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:298)
        at kafka.utils.CoreUtils$.inReadLock(CoreUtils.scala:304)
        at kafka.cluster.Partition.appendMessagesToLeader(Partition.scala:410)
        at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:365)
        at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:350)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:350)
        at kafka.server.ReplicaManager.appendMessages(ReplicaManager.scala:286)
        at kafka.server.KafkaApis.handleProducerRequest(KafkaApis.scala:272)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:59)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
        at java.lang.Thread.run(Thread.java:745)

Found 1 deadlock.
{code}

We'll track this in a separate jira :
https://issues.apache.org/jira/browse/KAFKA-2253;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Race condition shutting down high-level consumer results in spinning background thread,KAFKA-989,12660099,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,phargett,phargett,phargett,27/Jul/13 00:50,06/Aug/13 22:13,22/Mar/23 15:10,06/Aug/13 10:04,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"Running an application that uses the Kafka client under load, can often hit this issue within a few hours.

High-level consumers come and go over this application's lifecycle, but there are a variety of defenses that ensure each high-level consumer lasts several seconds before being shutdown.  Nevertheless, some race is causing this background thread to continue long after the ZKClient it is using has been disconnected.  Since the thread was spawned by a consumer that has already been shutdown, the application has no way to find this thread and stop it.

Reported on the users-kafka mailing list 6/25 as ""0.8 throwing exception 'Failed to find leader' and high-level consumer fails to make progress"". 

The only remedy is to shutdown the application and restart it.  Externally detecting that this state has occurred is not pleasant: need to grep log for repeated occurrences of the same exception.

Stack trace:

Failed to find leader for Set([topic6,0]): java.lang.NullPointerException
	at org.I0Itec.zkclient.ZkClient$2.call(ZkClient.java:416)
	at org.I0Itec.zkclient.ZkClient$2.call(ZkClient.java:413)
	at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)
	at org.I0Itec.zkclient.ZkClient.getChildren(ZkClient.java:413)
	at org.I0Itec.zkclient.ZkClient.getChildren(ZkClient.java:409)
	at kafka.utils.ZkUtils$.getChildrenParentMayNotExist(ZkUtils.scala:438)
	at kafka.utils.ZkUtils$.getAllBrokersInCluster(ZkUtils.scala:75)
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:63)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)",Ubuntu Linux x64,junrao,phargett,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Aug/13 22:27;phargett;KAFKA-989-failed-to-find-leader-patch2.patch;https://issues.apache.org/jira/secure/attachment/12596121/KAFKA-989-failed-to-find-leader-patch2.patch","06/Aug/13 03:13;phargett;KAFKA-989-failed-to-find-leader-patch3.patch;https://issues.apache.org/jira/secure/attachment/12596189/KAFKA-989-failed-to-find-leader-patch3.patch","03/Aug/13 01:32;phargett;KAFKA-989-failed-to-find-leader.patch;https://issues.apache.org/jira/secure/attachment/12595635/KAFKA-989-failed-to-find-leader.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,340291,,,Tue Aug 06 14:13:48 UTC 2013,,,,,,,,,,"0|i1mowf:",340609,,,,,,,,,,,,,,,,,,,,"03/Aug/13 01:31;phargett;This patch may minimize the issue, as there does seem to be a race between startConnections / stopConnections in ConsumerFetcherManager *and* the doWork method of the inner LeaderFinderThread class.

It seems that a thread could be started (from startConnections) but shutdown could happen (from stopConnections) even before the leader thread actually even started to do work.;;;","03/Aug/13 01:32;phargett;Here's the patch: KAFKA-989-failed-to-find-leader.patch.;;;","03/Aug/13 03:57;phargett;Not good enough.  Deadlocks because ShutdownableThread.shutdown grabs another lock.;;;","05/Aug/13 22:26;phargett;When in doubt about how to fix a locking issue...add another lock. ;)

While the real race here involves startConnections / stopConnections in ConsumerFetcherManager, the real trigger for such races appears to be the lack of protection in the shutdown and rebalance operations on ZookeeperConsumerConnector.  There is nothing to prevent a rebalance while a shutdown is in progress, and it would appear that could trigger the race in ConsumerFetcherManager.

The patch I'm attaching (see KAFKA-989-failed-to-find-leader-patch2.patch) adds a shutdown lock grabbed first in both shutdown() and in the run method of the ZKRebalancerListener.  This should prevent a rebalance from happening on a consumer that has already shutdown.  This prevents the fetcher or the zkclient from being in intermediate states, and thus should prevent the race.;;;","06/Aug/13 00:33;junrao;Thanks for the patch. I think it addresses one particular issue: When the consumer connector is shut down, there could still be an outstanding rebalance that uses zkclient which is already set to null. I am not sure if it addresses the problem that you hit though. Some comments:

1. Since syncedRebalance() is called in multiple places, so the shutdown lock should be checked inside syncedRebalance(). Since there is already a rebalanceLock in syncedRebalance(), perhaps shutdown() can just synchronize on that.

;;;","06/Aug/13 00:48;phargett;Thanks for the feedback! Working on a patch that incorporates your suggestions now.

FWIW, I think this will indirectly address my original situation.  I think the reason the original stack trace has occurred is because a rebalance has started a fetcher with a LeaderFinderThread while the consumer itself is in the process of being shutdown.  The LeaderFinderThread is left with a stale ZkClient, and has no other way to know that it's should shutdown.  Since the fetcher has already set its reference to null its reference to the LeaderFinderThread, the running state of the thread will never be changed to shut the thread off.

I'm stuck trying to find an acceptable solution in LeaderFinderThread; this change in ZooKeeperConsumerConnector may have to do until then.

Will post new patch once I have it coded and tested.;;;","06/Aug/13 01:18;junrao;Hmm, in the shutdown logic of consumer connector, we set zkclient to null the last. So, all fetchers and the leader finder thread should have been stopped when zkclient is null.;;;","06/Aug/13 01:27;phargett;Yes, but my working hypothesis is that because there are at least 2 sets of races (in consumer connector syncedRebalance/shutdown, then in ConsumerFetcherManager startConnections/stopConnections), it is actually possible to have a LeaderFinderThread still running that has not been shutdown, even though its consumer has--because a stopConnections call completed before a startConnections call finished.  So there's a started leader finder thread, but its ZkClient has been closed.

The key, I think, is that there is no guarantee that while the consumer connector is shutting down a rebalance event won't actually startup another leader finder thread (by starting fetchers again).

I believe the race in ConsumerFetcherManager is not likely to happen, if the race in ZookeeperConsumerConnector is fixed instead. Thus I avoid fixing the harder race by fixing an easier one that may be its only trigger (at present). :);;;","06/Aug/13 03:13;phargett;Changed to reuse the existing rebalanceLock in shutdown() rather than add in yet another lock.  Modified both shutdown and syncedRebalance accordingly.;;;","06/Aug/13 03:15;phargett;I also think I've convinced myself that while the race in ConsumerFetcherManager is not ideal, the real resource to protect is not the leader finder thread but the shared ZkClient instance--which is managed by ZookeeperConsumerConnector, where these fixes are made.

By reducing the races in the consumer connector, then we're less likely to mismanage the ZkClient.;;;","06/Aug/13 10:04;junrao;Thanks for patch v3. Committed to 0.8.;;;","06/Aug/13 22:13;phargett;Thank you!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add maxParallelForks to build.gradle to speedup tests,KAFKA-2438,12856510,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriharsha,sriharsha,sriharsha,17/Aug/15 11:29,20/Sep/15 09:33,22/Mar/23 15:10,17/Aug/15 11:53,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"With current trunk unit tests on my machine takes 16+ mins and with this patch runs about 6mins. Tested on OS X and linux.
Before 
{code}
Total time: 18 mins 29.806 secs
{code}
After
{code}
BUILD SUCCESSFUL

Total time: 5 mins 37.194 secs
{code}",,fpj,githubbot,gwenshap,ijuma,jjkoshy,onurkaraman,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Sep 20 01:33:22 UTC 2015,,,,,,,,,,"0|i2izk7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"17/Aug/15 11:31;githubbot;GitHub user harshach opened a pull request:

    https://github.com/apache/kafka/pull/143

    KAFKA-2438: add maxParallelForks to build.gradle to speedup tests.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/harshach/kafka KAFKA-2438

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/143.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #143
    
----
commit 69b0edecc9becebc08c2a8a21777e8707fb3a564
Author: Sriharsha Chintalapani <harsha@hortonworks.com>
Date:   2015-08-17T03:29:46Z

    KAFKA-2438: add maxParallelForks to build.gradle to speedup tests.

----
;;;","17/Aug/15 11:31;sriharsha;PR posted here https://github.com/apache/kafka/pull/143;;;","17/Aug/15 11:53;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/143
;;;","17/Aug/15 11:53;gwenshap;Issue resolved by pull request 143
[https://github.com/apache/kafka/pull/143];;;","19/Sep/15 06:06;jjkoshy;FYI, I find that this patch appears to exacerbate timing-related test failures with JDK 7 on my linux machine - not on JDK 8 though. (cc [~ijuma] since I made mention of this in KAFKA-2120);;;","19/Sep/15 06:21;onurkaraman;I am running into transient failures for some kafka.server.ServerShutdownTest tests that check the number of non-daemon threads. I narrowed it down to running two unit tests:
kafka.server.ServerShutdownTest.testCleanShutdown
kafka.controller.ControllerFailoverTest.testMetadataUpdate

kafka.server.ServerShutdownTest.testCleanShutdown sees that kafka.controller.RequestSendThread is non-daemon and still alive.

Maybe it's related to this?;;;","19/Sep/15 06:21;ijuma;Jenkins has indeed been less stable since this went in from what I've seen. At the time, I suggested that maybe we should be less aggressive with the number of parallel forks.;;;","20/Sep/15 09:33;fpj;See KAFKA-2558 for a fix to the RequestSendThread issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fetcher.getTopicMetadata NullPointerException when broker cannot be reached,KAFKA-2880,12915641,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,hachikuji,ewencp,ewencp,24/Nov/15 08:13,24/Dec/15 15:49,22/Mar/23 15:10,03/Dec/15 03:28,0.9.0.0,,,,,,0.9.0.1,,,,,,,clients,,,,0,,,,,,"The Fetcher class will throw a NullPointerException if a broker cannot be reached:

{quote}
Exception in thread ""main"" java.lang.NullPointerException
        at org.apache.kafka.common.requests.MetadataResponse.<init>(MetadataResponse.java:130)
        at org.apache.kafka.clients.consumer.internals.Fetcher.getTopicMetadata(Fetcher.java:203)
        at org.apache.kafka.clients.consumer.KafkaConsumer.partitionsFor(KafkaConsumer.java:1143)
        at org.apache.kafka.connect.util.KafkaBasedLog.start(KafkaBasedLog.java:126)
        at org.apache.kafka.connect.storage.KafkaOffsetBackingStore.start(KafkaOffsetBackingStore.java:85)
        at org.apache.kafka.connect.runtime.Worker.start(Worker.java:108)
        at org.apache.kafka.connect.runtime.Connect.start(Connect.java:56)
        at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:62)
{quote}

This is trivially reproduced by trying to start Kafka Connect in distributed mode (i.e. connect-distributed.sh config/connect-distributed.properties) with no broker running. However, it's not specific to Kafka Connect, it just happens to use the consumer in a way that triggers it reliably.",,drsmith,ewencp,githubbot,guozhang,hachikuji,hakim.acharifi,rmetzger,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3041,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Dec 09 20:00:04 UTC 2015,,,,,,,,,,"0|i2ou9j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"24/Nov/15 11:50;hachikuji;[~ewencp] Looks like we're missing a disconnect check on the client response. Looking over the code, error handling for the listTopics() and partitionsFor() API clearly hasn't been given enough attention. How about we expand the scope of this ticket to include the following cases?

1. Unauthorized topics: raise TopicAuthorizationException
2. Miscellaneous topic errors (e.g. leader/replica not available): retry until request timeout expires
3. Disconnect errors: retry until request timeout expires
4. Request timeout: raise TimeoutException
;;;","24/Nov/15 12:46;ewencp;[~hachikuji] Agreed, makes sense to round out error handling in general for those APIs.;;;","25/Nov/15 01:42;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/581

    KAFKA-2880: consumer should handle disconnect/timeout for metadata requests

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-2880

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/581.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #581
    
----
commit 605641249dc289ae7e8d7e003cd0e1f35367abad
Author: Jason Gustafson <jason@confluent.io>
Date:   2015-11-24T01:45:32Z

    KAFKA-2880: consumer should handle disconnect/timeout for metadata requests

commit 851c9b3877b337c83e88f4c4100383129f83222c
Author: Jason Gustafson <jason@confluent.io>
Date:   2015-11-24T17:40:00Z

    additional error handling/test cases for topic metadata API

----
;;;","03/Dec/15 03:27;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/581
;;;","03/Dec/15 03:28;guozhang;Issue resolved by pull request 581
[https://github.com/apache/kafka/pull/581];;;","10/Dec/15 03:52;drsmith;Looks like it's already documented, but ran into this same issue with listTopics:

{noformat}
! Caused by: java.lang.NullPointerException
! at org.apache.kafka.common.requests.MetadataResponse.<init>(MetadataResponse.java:130)
! at org.apache.kafka.clients.consumer.internals.Fetcher.getTopicMetadata(Fetcher.java:203)
! at org.apache.kafka.clients.consumer.internals.Fetcher.getAllTopicMetadata(Fetcher.java:180)
! at org.apache.kafka.clients.consumer.KafkaConsumer.listTopics(KafkaConsumer.java:1162)
{noformat};;;","10/Dec/15 04:00;guozhang;[~drsmith] This is fixed in current trunk, which will be included in the next point release (0.9.0.1).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka.api.consumerTests are hanging,KAFKA-1948,12774463,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,gwenshap,gwenshap,12/Feb/15 14:54,12/Mar/15 12:05,22/Mar/23 15:10,11/Mar/15 02:22,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Noticed today that very often when I run the full test suite, it hangs on kafka.api.consumerTest (not always same test though). It doesn't reproduce 100% of the time, but enough to be very annoying.

I also saw it happening on trunk after KAFKA-1333:
https://builds.apache.org/view/All/job/Kafka-trunk/389/",,guozhang,gwenshap,tongli,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1910,,,,,,,,,,"13/Feb/15 03:36;guozhang;KAFKA-1948.patch;https://issues.apache.org/jira/secure/attachment/12698514/KAFKA-1948.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Feb 12 20:35:55 UTC 2015,,,,,,,,,,"0|i25ixr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"12/Feb/15 14:54;gwenshap;[~guozhang] [~onurkaraman] - since you worked on KAFKA-1333, can you check if the hangs are related?;;;","12/Feb/15 15:03;guozhang;Gwen,

Just ran locally a few times and I do see this issue coming, will take a look at this asap.;;;","12/Feb/15 22:58;tongli;Pulled down the latest trunk and run into this problem. It will be nice if someone can take a look. The test does not stuck always at the same place. I did notice there are tons of threads getting created and died. What I did is when the test hung, I ran this command.

top -H -p <theprocessid of the test java>

You will notice that many threads come and go. and the state of these threads are always S (meaning sleep). including the parent thread. Not really sure what the deal is.;;;","13/Feb/15 03:36;guozhang;Created reviewboard https://reviews.apache.org/r/30946/diff/
 against branch origin/trunk;;;","13/Feb/15 03:39;guozhang;One issue I found is that in ConsumerTest.testPartitionReassignmentCallback, the shutdown coordinator may also be the leader of the ""test"" topic partition, and hence consumer cannot shutdown. This issue exist before KAFKA-1333 but was not exposed.

I did not see the test hangs on other cases, [~gwenshap] do you want to apply this patch and see if you still see the test hanging, please let me know the specific test case.;;;","13/Feb/15 04:35;gwenshap;Applied the patch and the tests are passing! Thank you for the quick solution.

Non-binding +1 from me, and I hope this will be committed ASAP.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Async Producer will cause 'java.net.SocketException: Too many open files' when broker host does not exist,KAFKA-1832,12763960,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,barneywill,barneywill,29/Dec/14 11:01,16/Aug/17 01:47,22/Mar/23 15:10,16/Aug/17 01:47,0.8.1,0.8.1.1,,,,,,,,,,,,producer ,,,,0,,,,,,"h3.How to replay the problem:
* producer configuration:
** producer.type=async
** metadata.broker.list=not.existed.com:9092
Make sure the host '*not.existed.com*' does not exist in DNS server or /etc/hosts;
* send a lot of messages continuously using the above producer
It will cause '*java.net.SocketException: Too many open files*' after a while, or you can use '*lsof -p $pid|wc -l*' to check the count of open files which will be increasing as time goes by until it reaches the system limit(check by '*ulimit -n*').

h3.Problem cause:
{code:title=kafka.network.BlockingChannel|borderStyle=solid} 
channel.connect(new InetSocketAddress(host, port))
{code}
this line will throw an exception '*java.nio.channels.UnresolvedAddressException*' when broker host does not exist, and at this same time the field '*connected*' is false;
In *kafka.producer.SyncProducer*, '*disconnect()*' will not invoke '*blockingChannel.disconnect()*' because '*blockingChannel.isConnected*' is false which means the FileDescriptor will be created but never closed;

h3.More:
When the broker is an non-existent ip(for example: metadata.broker.list=1.1.1.1:9092) instead of an non-existent host, the problem will not appear;
In *SocketChannelImpl.connect()*, '*Net.checkAddress()*' is not in try-catch block but '*Net.connect()*' is in, that makes the difference;

h3.Temporary Solution:
{code:title=kafka.network.BlockingChannel|borderStyle=solid} 
try
{
    channel.connect(new InetSocketAddress(host, port))
}
catch
{
    case e: UnresolvedAddressException => 
    {
        disconnect();
        throw e
    }
}
{code}",linux,barneywill,omkreddy,pasthelod,yabodnar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Aug 15 17:47:45 UTC 2017,,,,,,,,,,"0|i23t47:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"16/Aug/17 01:47;omkreddy;Fixed in  KAFKA-1041;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Newly elected KafkaController might not start deletion of pending topics,KAFKA-1681,12746415,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,sriharsha,sriharsha,sriharsha,07/Oct/14 22:43,10/Oct/14 05:35,22/Mar/23 15:10,10/Oct/14 05:35,,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,As part of KAFKA-1663 deleteTopicStateChanged.set(true) is removed from start(). This will cause newly elected kafka controller not to process the existing delete topic requests.,,junrao,nehanarkhede,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1663,,,"10/Oct/14 03:53;sriharsha;KAFKA-1681.patch;https://issues.apache.org/jira/secure/attachment/12673979/KAFKA-1681.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Oct 09 21:35:41 UTC 2014,,,,,,,,,,"0|i20vvj:",9223372036854775807,,nehanarkhede,,,,,,,,,,,,,,,,,,"08/Oct/14 23:13;sriharsha;[~nehanarkhede] [~junrao]
adding this code to TopicDeletionManager.start method should cover this issue right?
      if (topicsToBeDeleted.size > 0)
        resumeTopicDeletionThread()
;;;","09/Oct/14 12:27;junrao;Yes, or just set deleteTopicStateChanged to true instead of calling resumeTopicDeletionThread().;;;","09/Oct/14 23:20;nehanarkhede;[~sriharsha], adding that to the end of the start() API might unnecessarily start the thread, possibly have it wait and then signal it. I think it is easier to just set deleteTopicStateChanged to true before starting the thread. Also, I thought about the other possible race condition where the controller completes starting the delete topic manager and effectively the delete topic thread and a watch related to delete topic fires before the delete topic thread waits on the condition. The controller watch would then call resumeTopicDeletion which would signal a non waiting thread. That seemed like a problem at first, but it's not since when the thread invokes awaitTopicDeletion.., it would find the deleteTopicStateChanged to be true, so it will proceed to acting on topicsToBeDeleted.

In short, the previous code was right :);;;","09/Oct/14 23:58;sriharsha;[~nehanarkhede] can you clarify bit on ""In short, the previous code was right "" . You mean code before KAFKA-1663. 
That code only waits till the thread starts running since the condition is
while(!deleteTopicsThread.isRunning.get() && !deleteTopicStateChanged.compareAndSet(true, false)) {
once thread starts and if there is resumeTopicsThread() invoked thread never waits because ""!deleteTopicsThread.isRunning.get()"". This causes a problem when deleteTopicsThread.shudown() is called . I believe the intention is to wait for notifications on delete topics and resume thread. With the above condition it won't wait and keeps running. ;;;","10/Oct/14 00:49;junrao;Sriharsha,

I think what Neha meant is that in kafka-1663, the change of the condition in awaitTopicDeletionNotification() is correct. However, kafka-1663 also removed setting deleteTopicStateChanged to true in start() and is causing a new problem. We can just add the following code in start() before the deleteTopicsThread is started.
if (topicsToBeDeleted.size > 0)
  deleteTopicStateChanged.set(true);;;","10/Oct/14 01:49;nehanarkhede;[~sriharsha], sorry for being unclear. I meant that the regression introduced by part of the KAFKA-1663 patch where you removed deleteTopicStateChanged.set(true) needs to be reverted. The other part of the patch where you changed the while loop condition is correct. So the patch for this JIRA is a one liner fix where we add that change(deleteTopicStateChanged.set(true)) back in. ;;;","10/Oct/14 03:53;sriharsha;Created reviewboard https://reviews.apache.org/r/26516/diff/
 against branch origin/trunk;;;","10/Oct/14 05:35;junrao;Thanks for the patch. +1. Committed to both trunk and 0.8.2.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Addition of partitions requires bouncing all the consumers of that topic,KAFKA-1030,12665845,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,guozhang,swapnilghike,swapnilghike,28/Aug/13 12:58,18/Sep/13 05:24,22/Mar/23 15:10,18/Sep/13 05:24,0.8.0,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"Consumer may not notice new partitions because the propagation of the metadata to servers can be delayed. 

Options:
1. As Jun suggested on KAFKA-956, the easiest fix would be to read the new partition data from zookeeper instead of a kafka server.
2. Run a fetch metadata loop in consumer, and set auto.offset.reset to smallest once the consumer has started.

1 sounds easier to do. If 1 causes long delays in reading all partitions at the start of every rebalance, 2 may be worth considering.
 
The same issue affects MirrorMaker when new topics are created, MirrorMaker may not notice all partitions of the new topics until the next rebalance.",,guozhang,nehanarkhede,richardatcloudera,swapnilghike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Sep/13 02:00;guozhang;KAFKA-1030-v1.patch;https://issues.apache.org/jira/secure/attachment/12603632/KAFKA-1030-v1.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,345784,,,Tue Sep 17 21:24:46 UTC 2013,,,,,,,,,,"0|i1nmmv:",346085,,,,,,,,,,,,,,,,,,,,"28/Aug/13 13:02;swapnilghike;As Jun suggested on KAFKA-956, the easiest fix would be to read the new partition data from zookeeper instead of a kafka server.;;;","29/Aug/13 01:45;nehanarkhede;One alternative is to change the topic metadata request handling on the controller broker and let the consumer re-issue a metadata request to the controller broker when the partition change listener fires. If the broker is the controller, it should serve the metadata request by reading from the controller cache directly. If not, it can rely on leaderCache that is updated via the UpdateMetadata request. Upside of this approach is that it won't kill performance and will solve the problem. Downside is that it might make the metadata request handling on the controller broker somewhat slower since it invovlves locking on the controller lock.;;;","29/Aug/13 02:27;swapnilghike;Hmm, this will mean that the consumer client will cease to be controller agnostic. Is that a good idea? Plus if there is a controller failover at the same time as a consumer trying to fetch metadata, the broker the consumer was talking to for fetching metadata may have stale metadata. So, we may need to implement a controller failover watcher on consumer to trigger fetching metadata. Thoughts?;;;","29/Aug/13 04:05;nehanarkhede;Longer term, the right fix will be to move rebalancing to the controller and let it co-ordinate state changes for the consumer. Until then, it will be some sort of a work around to get the latest state changes. To your point, if controller failover is happening, the rebalance attempt will fail. This is no different from leadership changes. I don't see why we need controller failover watch. This controller metadata is only required when partitions change, so it is on-demand.;;;","29/Aug/13 09:06;guozhang;I think the first option might work just okay, since the consumer do not actually needs the partition leader id, etc. All it needs is the map of topic -> list of partition ids. This can be done by just reading one ZK path per topic: /brokers/topics/[topic]. Of course this will put more pressure on MirrorMaker though, but we should really not do full rebalance for added partition or topic anyways..;;;","18/Sep/13 02:00;guozhang;Updated reviewboard https://reviews.apache.org/r/14041/
;;;","18/Sep/13 04:15;guozhang;Here are the performance testing results:

Setup: 1) 5 instances of mirror maker consuming from around 3800 topic/partitions, 2) 1 instance of console consumer consuming from around 300 topic/partitions.

1). Bouncing mirror makers:

ZK-located-in-same-DC: 4 minutes and 20 seconds with the fix

ZK-located-in-same-DC: 3 minutes 50 secs without the fix

ZK-located-in-other-DC: 8 minutes 2 seconds with the fix

ZK-located-in-other-DC: 7 minutes 6 seconds without the fix

2). Bouncing console consumer 

ZK-located-in-same-DC: 15 seconds with the fix

ZK-located-in-same-DC: 15 seconds without the fix

---------------

Given the results, I think it worth pushing this approach (read-from-ZK) in 0.8 and we can later pursue the other approach Joel proposed in the reviewboard in trunk.
;;;","18/Sep/13 04:18;swapnilghike;+1 that Guozhang, thanks for running the tests.;;;","18/Sep/13 05:24;nehanarkhede;Thanks for the updated patch and the performance comparison analysis. I agree that the ideal change might prove to be too large for 0.8 and will require non-trivial amount of time stabilizing it since it is fairly tricky. We can just do it properly on trunk and live with this minor performance hit for consumer rebalancing on 0.8.
;;;","18/Sep/13 05:24;nehanarkhede;
Checked in the latest patch to 0.8;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ISR propagation should be throttled to avoid overwhelming controller.,KAFKA-2406,12851589,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,becket_qin,becket_qin,becket_qin,05/Aug/15 13:36,14/Aug/15 08:02,22/Mar/23 15:10,14/Aug/15 05:55,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"This is a follow up patch for KAFKA-1367.
We need to throttle the ISR propagation rate to avoid flooding in controller to broker traffic. This might significantly increase time of controlled shutdown or cluster startup.",,abraithwaite,becket_qin,christian.h.mikkelsen@gmail.com,githubbot,junrao,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Aug 14 00:02:51 UTC 2015,,,,,,,,,,"0|i2icjr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"05/Aug/15 15:11;githubbot;GitHub user becketqin opened a pull request:

    https://github.com/apache/kafka/pull/114

    KAFKA-2406[WIP]: Throttle ISR propagation

    This is a follow up patch for KAFKA-2406. Further test to verify if this change alone is enough to solve the problem or not. 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/becketqin/kafka KAFKA-2406

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/114.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #114
    
----
commit 27224779c21781e87353a28d060322bfc2c70be2
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2015-08-05T07:09:06Z

    KAFKA-2406: Throttle ISR propagation

----
;;;","05/Aug/15 23:50;junrao;[~becket_qin], thanks for the patch. Have you tested the patch in a cluster with lots of partitions? How is the controlled shutdown time with your patch?

;;;","06/Aug/15 01:13;becket_qin;Hi [~junrao], I'm doing the test right now. This patch only takes care of the second part of ISR propagation, which is controller to broker propagation. I hope this would solve our current problem. However, I am still not sure if creating a zookeeper path for each ISR change is a good way for the broker to report ISR change. Creating tens of thousands of ZKpath during cluster startup might cause issue.;;;","06/Aug/15 02:56;junrao;[~becket_qin], another way to reduce the overhead is to batch on the broker side. Every time a broker changes an ISR, it just saves the partition in an in-memory map. Periodically, the replica manager can collect all partitions in the map and write a single node in the ISR change path. This should reduce the number of UpdateMetadataRequests the controller sends to the brokers. It also reduces the number of ZK nodes to be deleted and the number of times the ISR change watchers are triggered.

Also, could you provide a bit more details on the performance issue? Does that issue happen when shutting down the first broker in the cluster or when there is another broker just being restarted? It will also be good know where the bottleneck is: whether just in the number of UpdateMetadataRequests or in processing the watchers as well.;;;","06/Aug/15 04:01;becket_qin;[~junrao], I'm still doing the test, here is what I see:
1. When controller was on old version, the controlled shutdown during rolling bounce seems to be normal.
2. After controller is running on new version, the controlled shutdown of brokers become very slow.
3. There are many zk paths still left in /isr_change_notification after the cluster bounce.
4. The first broker shuts down a little bit slower than before, but after that the subsequent shutdown takes super long - which is expected.

Because of [1] I was thinking maybe throttling UpdateMetadataRequest would be the minimum solution for now, but I have the same concern as you do on the number of zk writes and watcher fires.
[3] probably is an indication of zk watcher cannot catch up with the change reported by brokers.

Having broker side to batch the changes makes sense. I am thinking about doing the following:
1. Broker only update ISR change in a batch periodically by writing partitions data to /isr_change_notification/brokerId_IsrChangeEpoch path. so zkWrite is bounded to #broker/update_interval.
2. Instead of using zk watcher, controller simply periodically query zookeeper and propagate ISR changes.;;;","06/Aug/15 04:55;singhashish;[~junrao], [~becket_qin] it sounds like we are delaying ISR change propagation to fix this issue. Quick intimation of ISR change is a good thing, I believe. However, what [~becket_qin] ran into is certainly an issue that needs to be fixed. I think the issue will surface only when there are lot of changes happening in system, like during rolling bounce. Such scenarios are usually started by admins. If we just specify a way to turn off or delay ISR notifications only during such operations, we will still react fast to ISR changes and won;t hit this issue during rolling bounce like scenarios. Thoughts?;;;","06/Aug/15 05:01;junrao;[~becket_qin], are you suggesting not using sequential ZK node, but just having an isrChangePath per broker and keeping updating it? Not sure how this coordinates with the controller.

Also, not sure having the controller periodically read from the IsrChange path is better. After the cluster is stable, there shouldn't be any ISR change and the periodic ZK read is just pure overhead. If we batch enough, there shouldn't be that many ZK watchers fired. Another optimization that we could do is that on controller failover, the controller can actually delete all existing sequential ZK nodes in isr_change before initialization. The initialization will read the latest leader and ISR for all partitions from ZK anyway.;;;","06/Aug/15 05:04;becket_qin;[~ashishujjain], the large number of ISR change might not only occur during Admin operations, for example, any long GC might cause this issue. Also when a broker goes down if zk session timeout is longer than the replica.lag.time.max.ms will also cause problem.

I kind of think it is OK to delay the ISR change propagation. From user point of view, the ISR from two brokers still can be different even with the current approach considering we have a propagation delay.
;;;","06/Aug/15 05:10;singhashish;Makes sense. Can I suggest that we still keep the batching window duration configurable?;;;","06/Aug/15 05:22;becket_qin;[~junrao], I was thinking to have a sequential path for each broker before, but it probably does not make sense. So a global sequential zk path should be good enough.

And I agree that a periodically checking thread might be a bad idea. The main concern I have is that what if there are many brokers and they report isr change almost at same time, will the watcher be fired for that many times? Will that cause problem on controller?

Deleting the zk path on controller migration makes sense and I'm actually manually doing it now. The only issue I see here is that when I was trying to delete the zk path with > 110000 children paths, it takes quite a while. Not sure if that will cause issue. But if we throttle the zk path creation, it should reduce the paths to be deleted also.;;;","06/Aug/15 05:40;junrao;[~singhashish], yes, ideally we want to propagate isr asap. However, this is not critical for the current known use cases. The first use case is for admin tools like describing a topic. The second potential use case is for read affinity in the consumer, which is just an optimization. For both cases, delaying the propagation of isr is ok. Also, isr typically only changes during rolling bounces. If you turn off and delay the propagation then, most of the isr changes will be delayed anyway.

We can probably have a configurable batching window on the broker side.;;;","06/Aug/15 05:55;junrao;[~becket_qin], the ZK watcher is a one-time watcher. So, when a watcher is triggered, you have to do another read to register the watcher. There could be multiple changes in between, but only one more watcher will be triggered. However, the brokers may not be writing to ZK at exactly the same time. So, the more brokers you have, likely the more times the watcher will be fired. I think if we make the batch window configurable, one can adjust this value based on the cluster size if needed.

Writes are more expensive than reads in ZK. By batching, we can significantly reduce the number of ZK writes for isr changes. The controller still needs to read the changed isr from ZK for all affected partitions though. Hopefully there's not the main bottleneck.;;;","06/Aug/15 07:03;becket_qin;[~ashishujjain] [~junrao], sure, we can make the batching window size configurable. The related question is that, If we are adding a configuration, do you think we need a KIP? I think this is a pretty small change, but since we think of config change as API change, so just want to confirm.;;;","06/Aug/15 07:50;junrao;[~becket_qin], we can probably do a quick KIP on the config change so that people are aware of it. We probably want to test if this approach works first.;;;","06/Aug/15 08:43;becket_qin;[~junrao], sure. I'm testing the new patch and will update the findings later. Also another problem in current code is that it is creating znode in /isr_change_notification, but we are deleting path from /config. So the znode never got deleted.;;;","07/Aug/15 23:58;becket_qin;[~junrao] I submitted a new patch and it works according to my test. Could you help take a look? Thanks.;;;","08/Aug/15 00:35;becket_qin;Just created KIP-29 for adding the config.
https://cwiki.apache.org/confluence/display/KAFKA/KIP-29+-+Add+an+IsrPropagateIntervalMs+configuration+to+KafkaConfig;;;","08/Aug/15 10:54;becket_qin;[~ashishujjain] We are discussing whether to expose the batch window as a configuration or not in the discussion mail thread. It seems people are a little bit hesitant on adding this configuration because of lack of valid use case. Do you have some use cases that can share on the discussion thread?
Thanks.;;;","10/Aug/15 03:23;junrao;Left some review comments in the PR.;;;","10/Aug/15 07:11;becket_qin;[~junrao], thanks for the review. Just updated the PR to address your comments.;;;","12/Aug/15 04:28;becket_qin;[~junrao] [~ashishujjain] We discussed about KIP-29 on today's KIP hangout. In this ticket we will hard code the ISR propagation interval to fix the trunk. I will create another ticket and link that to KIP-29 and submit follow up patch once we reach conclusion for KIP-29.

I just submitted a new patch that has the ISR propagation interval hard coded to 5 seconds. Could you help review? Thanks.

Jiangjie (Becket) Qin;;;","14/Aug/15 04:58;becket_qin;[~junrao] ping for review.;;;","14/Aug/15 05:55;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/114
;;;","14/Aug/15 05:55;junrao;Issue resolved by pull request 114
[https://github.com/apache/kafka/pull/114];;;","14/Aug/15 08:02;becket_qin;Thanks, [~junrao].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConfigDef toHtmlTable() sorts in a way that is a bit confusing,KAFKA-2702,12908722,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,gwenshap,gwenshap,29/Oct/15 05:56,06/Nov/15 10:19,22/Mar/23 15:10,06/Nov/15 10:19,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Because we put everything without default first (without prioritizing), critical  parameters get placed below low priority ones when they both have no defaults. Some parameters are without default and optional (SASL server in ConsumerConfig for instance).

Try printing ConsumerConfig parameters and see the mandatory group.id show up as #15.

I suggest sorting the no-default parameters by priority as well, or perhaps adding a ""REQUIRED"" category that gets printed first no matter what.",,abiletskyi,githubbot,gwenshap,hachikuji,ijuma,jkreps,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Nov/15 07:50;granthenke;ConsumerConfig-After-v2.html;https://issues.apache.org/jira/secure/attachment/12770458/ConsumerConfig-After-v2.html","29/Oct/15 11:57;granthenke;ConsumerConfig-After.html;https://issues.apache.org/jira/secure/attachment/12769467/ConsumerConfig-After.html","29/Oct/15 11:57;granthenke;ConsumerConfig-Before.html;https://issues.apache.org/jira/secure/attachment/12769468/ConsumerConfig-Before.html",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 06 02:19:13 UTC 2015,,,,,,,,,,"0|i2nnrb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"29/Oct/15 07:23;granthenke;I can take this one if you are not planning to work on it Gwen.;;;","29/Oct/15 08:29;jkreps;Aren't things without default required? That rationale for that order was that effectively any required parameter is kind of it's own ""essential"" level of importance....;;;","29/Oct/15 11:51;granthenke;Looking into this a bit more...

{quote}
Try printing ConsumerConfig parameters and see the mandatory group.id show up as #15.
{quote}
There is an issue in ConfigDef where _NO_DEFAULT_VALUE = new String("""")_, however an empty string is actually a valid default value. Later on in the html output, there is also an issue where null is interpreted as NO_DEFAULT_VALUE. Null could also be a valid default. 

This may also be an html output issue. If there is a default, its just empty string (""""), maybe we should print that. Many of the string parameters have a default of """".

{quote}
or perhaps adding a ""REQUIRED"" category that gets printed first no matter 
{quote}
There is a ""required"" field in ConfigKey. Adding that as a column to the table is a good idea.

{quote}
Aren't things without default required? 
{quote}
There are many optional parameters that don't have a default, but are not required. Especially with the addition of many of the SSL parameters.

I think what we are looking for it prioritizing parameters that are required and have no default. I will submit a patch, fixing the issues mentioned above and adjusting the sort with that change, and we can discuss if its actually an improvement over what exists.






;;;","29/Oct/15 11:52;githubbot;GitHub user granthenke opened a pull request:

    https://github.com/apache/kafka/pull/379

    KAFKA-2702: ConfigDef toHtmlTable() sorts in a way that is a bit conf…

    …using

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka config-html

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/379.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #379
    
----
commit 257655b3b5a6f0a374332c6d403bbcc117844117
Author: Grant Henke <granthenke@gmail.com>
Date:   2015-10-29T03:49:24Z

    KAFKA-2702: ConfigDef toHtmlTable() sorts in a way that is a bit confusing

----
;;;","29/Oct/15 11:57;granthenke;Added sample ConsumerConfig output tables before and after patch for comparison.;;;","29/Oct/15 12:27;jkreps;Originally the presence or absence of a default indicated whether something was required--i.e. *all* fields are required to have a value but you can provide a default. Looks like later someone wanted to make a separate variable for whether it was required (not sure why) and they decided that if there was no default they would just fill in null as the default. But this change doesn't seem to have been fully carried out.

The original approach was actually done that way on purpose. In the new approach setting a config to non-required field seems to be a duplicative way of saying a config with a default value of null, which you could already do. But null is actually not always a very good default value to set so having people explicitly give the default for non-required fields is probably good.

For example what happens if I have a non-required int config with no default and I do something like
  int myValue = config.getInt(MYCONFIGNAME);
I think I will get a null pointer.

I think this happened in KAFKA-1845 so it might be good to figure out what the intention was in the change, probably there was some issue this fixed...;;;","29/Oct/15 12:30;jkreps;Also note that the check against NO_DEFAULT_VALUE isn't a check against the empty string it is a check against being the object named NO_DEFAULT_VALUE (i.e. reference equality vs object equality). That object happens to be an empty string so it prints out as nothing but that doesn't make it equal to other empty strings for the purpose of determining if there is a default or not.;;;","29/Oct/15 12:42;granthenke;[~jkreps] Good point. I was in Scala mode. I reverted the NO_DEFAULT_VALUE change. ;;;","30/Oct/15 01:08;granthenke;[~jkreps] You are right, that _required_ was added in [KAFKA-1845|https://issues.apache.org/jira/browse/KAFKA-1845]. The addition was not discussed in the jira or [patch reviews|https://reviews.apache.org/r/30126/]. [~abiletskyi] do you have an insight? 

I do like the idea of explicitly providing a good default for any optional argument in the configuration definition. But I don't have too strong of a feeling either way. If we do revert the addition of _required_, the newly added SSL and Kerberos configs look like they might need to be reviewed/updated. They leverage _required=false_ quite a bit.;;;","30/Oct/15 08:15;gwenshap;This needs some cleanup - because required=true is the default, there are tons of stuff where required=true that make no sense (either because they have defaults or are not required).

;;;","30/Oct/15 22:37;granthenke;[~gwenshap] Yeah, there is definitely some config cleanup needed. This is for similar reason to what [~jkreps] was saying:
{quote}
Originally the presence or absence of a default indicated whether something was required
{quote}

Before doing that I want to be sure we agree on the approach. Should we:
A. Keep the required field, adjust the sort, and cleanup configs.
B. Remove the required field, and cleanup configs adding defaults where needed.
;;;","30/Oct/15 23:15;abiletskyi;It's been a while, but, yes, as far as I remember I added required field because not all configs had default values and we couldn't instantiate Config unless all settings have their value - the default one, or the one came from the user (config file).;;;","31/Oct/15 04:08;gwenshap;I'd prefer B, and I think that both Jay and you mentioned the same - the ""required"" field is not needed and just adds confusion.;;;","31/Oct/15 04:29;ijuma;For SSL and SASL configs, a default of null can be used for all optional configs to fit within the original design of the library.

Personally, I'd prefer if the library supported optional types in a way where one could leverage the type system (ie Option and Optional), but that's a bigger change and needs to be carefully considered. Relying on each config to follow a convention in order to choose the right default for the optional value for a given type is error-prone and leads to inconsistencies (-1, null, empty list, false, etc.).;;;","03/Nov/15 08:28;granthenke;[~ijuma] I agree. This would be fairly simple in Scala, as Option is a commonly used concept and transparently handles null/empty-string/empty-list well. However, In java its not so common. There are going to be a lot of null defaults with this change (Its not new, it just was less obvious before with the required parameter) and thats not great either.

A default of null is not currently allowed. See ConfigDefTest.testNullDefault. At first look that seams like the best approach. Especially to avoid NPEs. But without null or some sort of Option type, how do I represent a default of ""unset"" for types like Integer or Long? I suspect this is why required was added. Should I allow null defaults with this change? ;;;","03/Nov/15 14:00;junrao;[~granthenke], we can probably do the following.

1. Remove the required field.
2. Change all instances of non-required field to default to null.
3. Allow null as a default value.
4. Print the null default value properly in html output.;;;","04/Nov/15 07:54;granthenke;Thanks for all the input [~jkreps], [~gwenshap], [~abiletskyi], [~ijuma], [~junrao]

I have updated the PR removing the required field and changing all instances of non-required field to default to null. I also uploaded a v2 sample output to this jira. Most notably defaults of """" and null are now output and I added a ""valid values"" column. ;;;","04/Nov/15 08:53;gwenshap;Not 100% related to this patch, but I thought group.id is required (for consumer). Looks like the default is """" now? 
[~hachikuji]?;;;","04/Nov/15 08:59;hachikuji;I think it's only required if the user is using group management. We throw a runtime error if you try to join a group with an empty groupId.;;;","04/Nov/15 15:04;granthenke;[~gwenshap] There was no default for group.id in KAFKA-1328. It was changed to """" in KAFKA-1760. It looks like it was required in the old consumer. ;;;","06/Nov/15 01:35;githubbot;Github user granthenke closed the pull request at:

    https://github.com/apache/kafka/pull/379
;;;","06/Nov/15 01:35;githubbot;GitHub user granthenke reopened a pull request:

    https://github.com/apache/kafka/pull/379

    KAFKA-2702: ConfigDef toHtmlTable() sorts in a way that is a bit conf…

    …using

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka config-html

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/379.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #379
    
----
commit bc17f6b923f63891c1c36c531b525783df834e42
Author: Grant Henke <granthenke@gmail.com>
Date:   2015-10-29T03:49:24Z

    KAFKA-2702: ConfigDef toHtmlTable() sorts in a way that is a bit confusing

----
;;;","06/Nov/15 04:16;granthenke;I have updated the pull request based on all discussion above. Your reviews and feedback are greatly appreciated. ;;;","06/Nov/15 10:18;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/379
;;;","06/Nov/15 10:19;gwenshap;Issue resolved by pull request 379
[https://github.com/apache/kafka/pull/379];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MetadataResponse is Empty on a Fresh Cluster,KAFKA-2154,12825617,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,,kfb,kfb,29/Apr/15 02:21,05/Jun/15 04:44,22/Mar/23 15:10,05/Jun/15 04:44,0.8.1.1,,,,,,0.9.0.0,,,,,,,core,,,,1,,,,,,"When I start a fresh cluster using {{bin/kafka-server-start.sh}} and issue a MetadataRequest to it, the results are blank.  It's correct that there are no topics, but there are also no brokers returned.  I'm writing a driver for Kafka, so this makes the initial connection to the cluster difficult.

To reproduce:

  * Start Zookeeper with {{bin/zookeeper-server-start.sh config/zookeeper.properties}} and a broker with {{bin/kafka-server-start.sh config/server.properties}}.  Be sure there's nothing in {{/tmp}} from a previous run.
  * Run this {{echo -e ""\x00\x00\x00\x15\x00\x03\x00\x01\x00\x00\x00\x00\x00\x07pykafka\x00\x00\x00\x00"" | nc localhost 9092 | hd}} and observe the output:
    {noformat}
00000000  00 00 00 0c 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00000010
    {noformat}
  * Create a topic using {{bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic test --partitions 2 --replication-factor 1}}
  * Re-run the same command and now observe the output:
    {noformat}
kfb@parsely-dev:~/src/ct/pykafka$ echo -e ""\x00\x00\x00\x15\x00\x03\x00\x01\x00\x00\x00\x00\x00\x07pykafka\x00\x00\x00\x00"" | nc localhost 9092 | hd
00000000  00 00 00 61 00 00 00 00  00 00 00 01 00 00 00 00  |...a............|
00000010  00 0b 70 61 72 73 65 6c  79 2d 64 65 76 00 00 23  |..parsely-dev..#|
00000020  84 00 00 00 01 00 00 00  04 74 65 73 74 00 00 00  |.........test...|
00000030  02 00 00 00 00 00 01 00  00 00 00 00 00 00 01 00  |................|
00000040  00 00 00 00 00 00 01 00  00 00 00 00 00 00 00 00  |................|
00000050  00 00 00 00 00 00 00 00  01 00 00 00 00 00 00 00  |................|
00000060  01 00 00 00 00                                    |.....|
00000065
    {noformat}

In this case, ""parsely-dev"" is the name of my work VM and the ""#"" following it is the port number.  I've verified it's a correctly formatted MetadataResponse.  It's the first null result that we've having a hard time dealing with.

As for the bytestring, that's a correctly formatted MetadataRequest with no topics specified.  Presumably if I specified a topic name it would auto-create the topic and then start returning broker information.  It doesn't really change the fact that the initial state is fairly broken.

Finally, it's worth noting that if I delete the ""test"" topic (after turning on {{delete.topic.enable}}) then the responses still include broker information. It's just the initial state which is causing problems.

{noformat}
kfb@parsely-dev:~/src/kafka$ bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test
Topic test is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
kfb@parsely-dev:~/src/ct/pykafka$ echo -e ""\x00\x00\x00\x15\x00\x03\x00\x01\x00\x00\x00\x00\x00\x07pykafka\x00\x00\x00\x00"" | nc localhost 9092 | hd
00000000  00 00 00 21 00 00 00 00  00 00 00 01 00 00 00 00  |...!............|
00000010  00 0b 70 61 72 73 65 6c  79 2d 64 65 76 00 00 23  |..parsely-dev..#|
00000020  84 00 00 00 00                                    |.....|
00000025
{noformat}",,hachikuji,kfb,sensitiveemmett,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jun 04 20:44:14 UTC 2015,,,,,,,,,,"0|i2e0xz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"29/Apr/15 07:26;sensitiveemmett;I've been able to replicate this issue on Debian 7.8 running Kafka 0.8.2.1. Currently I'm working around it by manually creating a topic whenever I spin up a fresh cluster. However, needing to do this in production is suboptimal.;;;","27/May/15 05:22;hachikuji;This seems like a duplicate of KAFKA-1867, which has been resolved and is scheduled for 0.8.3.;;;","31/May/15 11:27;kfb;Seems likely to be the root cause.  I'll pull 0.8.3 and give it a test this week to verify.;;;","05/Jun/15 04:44;kfb;Confirmed fixed in 0.8.3. Thanks for the help!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sample Java code contains Scala syntax,KAFKA-1625,12739614,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,davidzchen,davidzchen,davidzchen,06/Sep/14 06:33,12/Sep/14 11:59,22/Mar/23 15:10,12/Sep/14 11:59,,,,,,,,,,,,,,website,,,,0,,,,,,"As I was reading the Kafka documentation, I noticed that some of the parameters use Scala syntax, even though the code appears to be Java. For example:

{code}
public static kafka.javaapi.consumer.ConsumerConnector createJavaConsumerConnector(config: ConsumerConfig);
{code}

Also, what is the reason for fully qualifying these classes? I understand that there are Scala and Java classes with the same name, but I think that fully qualifying them in the sample code would encourage that practice by users, which is not desirable in Java code.",,davidzchen,jjkoshy,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1626,,,"06/Sep/14 06:38;davidzchen;KAFKA-1625.site.0.patch;https://issues.apache.org/jira/secure/attachment/12666922/KAFKA-1625.site.0.patch","06/Sep/14 07:22;davidzchen;KAFKA-1625.site.1.patch;https://issues.apache.org/jira/secure/attachment/12666936/KAFKA-1625.site.1.patch","10/Sep/14 05:17;davidzchen;KAFKA-1625.site.2.patch;https://issues.apache.org/jira/secure/attachment/12667488/KAFKA-1625.site.2.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Sep 12 03:59:44 UTC 2014,,,,,,,,,,"0|i1zqxb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"06/Sep/14 06:38;davidzchen;I am attaching a patch for this.

How do I create an RB for a change to the website? I tried to manually create the RB and entered {{/site}} for the base directory, but RB gave me the following error:

{code}
Line undefined: Repository moved permanently to 'https://svn.apache.org/repos/asf/kafka/site/081/api.html'; please relocate
{code};;;","06/Sep/14 07:22;davidzchen;Attaching a new patch that removes the full qualification of class names in the sample code.;;;","10/Sep/14 04:49;jjkoshy;Thanks for pointing out the reference to scala code from Java.

We should probably keep full qualification due to the dual-naming (between Scala and Java) that you noted - otherwise most people who try the examples out of the box would run into the question of which one do I use (say, when prompted to select imports in an IDE).;;;","10/Sep/14 05:03;davidzchen;Sounds good. Do we have plans to consolidate the classes in the way that [samza-api|https://samza.incubator.apache.org/learn/documentation/0.7.0/api/javadocs/] does?;;;","10/Sep/14 05:07;jjkoshy;Not that I know of, but the new producer is implemented in Java anyway and the new consumer (also Java) is being developed.;;;","10/Sep/14 05:17;davidzchen;Attaching a new patch that re-fully-qualifies class names.;;;","12/Sep/14 11:59;nehanarkhede;Thanks for the patch, [~davidzchen];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
go consumer & producer to support compression,KAFKA-158,12527450,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,,jdamick,jdamick,17/Oct/11 21:52,27/Oct/11 22:23,22/Mar/23 15:10,27/Oct/11 22:23,0.7,,,,,,,,,,,,,clients,,,,0,go-client,,,,,"As related to KAFKA-79, the go consumer and producer needs to support the compression attribute per https://cwiki.apache.org/confluence/display/KAFKA/Compression.

Can someone assign this to me, i'll add support and create a patch.

thanks ",,jdamick,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Oct/11 00:46;araddon;KAFKA-158-try2.patch;https://issues.apache.org/jira/secure/attachment/12499710/KAFKA-158-try2.patch","19/Oct/11 09:35;araddon;KAFKA-158.patch;https://issues.apache.org/jira/secure/attachment/12499621/KAFKA-158.patch","21/Oct/11 00:00;jdamick;kafka_158_go_compress.patch;https://issues.apache.org/jira/secure/attachment/12499881/kafka_158_go_compress.patch","23/Oct/11 23:22;jdamick;kafka_158_go_compress_working.patch;https://issues.apache.org/jira/secure/attachment/12500368/kafka_158_go_compress_working.patch","27/Oct/11 22:14;jdamick;kafka_158_go_compress_working_2.patch;https://issues.apache.org/jira/secure/attachment/12501095/kafka_158_go_compress_working_2.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,88155,,,Thu Oct 27 14:23:33 UTC 2011,,,,,,,,,,"0|i15z7r:",243005,,,,,,,,,,,,,,,,,,,,"18/Oct/11 00:11;nehanarkhede;Jeffrey, I tried assigning this to you, but your name doesn't show up in the JIRA list for Kafka. ;;;","19/Oct/11 09:35;araddon;tested against the kafka/bin/producershell and consumer.  ;;;","19/Oct/11 11:52;jdamick;ok, but the tests weren't updated and no new ones added, it doesnt support either compressed or uncompressed messages, and it doesnt transparently decompress the messages or have a way to plugin different compression codecs.. Let me just finish up this patch...;;;","20/Oct/11 00:46;araddon;Take 2 on the patch, with updated tests ;;;","21/Oct/11 00:00;jdamick;patch to add ability to compressed messages

Seeing strange behavior from kafka when sending the compressed messages:

go client sends this: 

00 00 00 36 00 00 00 04 74 65 73 74 00 00 00 00 00 00 00 26 00 00 00 22 01 01 F0 17 43 A5 1F 8B 08 00 00 00 00 00 04 FF 4A CE CF 2D 00 04 00 00 FF FF 3A 6F 0A CB 04 00 00 00

and servers gives:

[2011-10-20 11:51:50,106] DEBUG Listening to new connection from /127.0.0.1:59861 (kafka.network.Processor)
[2011-10-20 11:51:50,107] TRACE 54 bytes read from /127.0.0.1:59861 (kafka.network.Processor)
[2011-10-20 11:51:50,115] TRACE Handling produce request from /127.0.0.1:59861 (kafka.request.logger)
[2011-10-20 11:51:50,119] TRACE Producer request ProducerRequest(test,0,38) (kafka.request.logger)
[2011-10-20 11:51:50,119] DEBUG makeNext() in deepIterator: innerDone = true (kafka.message.ByteBufferMessageSet)
[2011-10-20 11:51:50,119] TRACE Remaining bytes in iterator = 34 (kafka.message.ByteBufferMessageSet)
[2011-10-20 11:51:50,119] TRACE size of data = 34 (kafka.message.ByteBufferMessageSet)
[2011-10-20 11:51:50,120] DEBUG Message is compressed. Valid byte count = 0 (kafka.message.ByteBufferMessageSet)
[2011-10-20 11:51:50,133] DEBUG makeNext() in deepIterator: innerDone = true (kafka.message.ByteBufferMessageSet)
[2011-10-20 11:51:50,133] TRACE Remaining bytes in iterator = 0 (kafka.message.ByteBufferMessageSet)
[2011-10-20 11:51:50,133] TRACE size of data = 1668246896 (kafka.message.ByteBufferMessageSet)
[2011-10-20 11:51:50,134] ERROR Error processing ProduceRequest on test:0 (kafka.server.KafkaRequestHandlers)
kafka.common.InvalidMessageSizeException: invalid message size: 1668246896 only received bytes: 0 at 0( possible causes (1) a single message larger than the fetch size; (2) log corruption )

;;;","21/Oct/11 00:21;junrao;It seems that you are sending a message marked as compressed. However, after the payload is decompressed, the content is not well-formatted. Likely causes include: (1) the message is actually not compressed; (2) the compression codec is not gzip. ;;;","21/Oct/11 02:27;jdamick;the curious part is that the scala producer writes this:

0000003c0000000474657374000000000000002c000000280101891b70861f8b0800000000000000636060e0626438cd956f959c9f5b0000dce317a70e000000

And after breaking it down, the message part is:

1f 8b 08 00 00 00 00 00 00 00 63 60 60 e0 62 64 38 cd 95 6f 95 9c 9f 5b 00 00 dc e3 17 a7 0e 00 00 00

after ungzip'ing it becomes (gzip cmd line to hexdump):

00 00 00 0a 01 00 cb 0a  6f 3a 63 6f 6d 70        |........o:comp|

Did something else in the message format change when it's compressed?

I see the same result when i decompress it in go in my consumer.. 

;;;","21/Oct/11 02:27;jdamick;i should add the text i send from the producer was:  'comp';;;","21/Oct/11 02:33;junrao;The go producer and the scala producer should send the same bytes for the same message, right?;;;","21/Oct/11 02:44;jdamick;not necessarily, the gzip implementation is different. But I'm wondering why when I use gzip (cmd line, not from go) to ungzip that message it has this on the front: (as seen above) 00 00 00 0a 01 00 cb 0a 6f 3a

This happens to match what i see in go (the extra bytes on the front of 'comp') .. so i must be parsing it wrong somehow...
;;;","21/Oct/11 03:02;junrao;In the broker, we need to unzip compressed messages to verify the crc. Can unzip decoder messages encoded by compress?;;;","21/Oct/11 03:20;jdamick;Are you saying you don't use gzip to decompress the messages in the broker?  i don't understand the question?;;;","21/Oct/11 23:28;jdamick;I think I figured out my mistake, inside the gzip is yet another message... i misunderstood and thought it was only the payload that compressed.  So it's a compressed message with an uncompressed message inside it, is that really what it's supposed to be? 

;;;","21/Oct/11 23:37;junrao;That's right. We take one or more uncompressed messages and compress them using gzip and store the compressed bytes in the payload of a single message. This way, we can recursively iterate into a compressed message. See CompressionUtils.compress for details.;;;","21/Oct/11 23:51;jdamick;thanks, i'll make the appropriate updates.  But it seems like this compression flag would be a better fit on the 'message set' and then use that to encapsulate all messages.. ;;;","22/Oct/11 00:06;junrao;There is a compression flag on ByteBufferMessageSet, with the following signature:

  def this(compressionCodec: CompressionCodec, messages: Message*)
;;;","22/Oct/11 02:03;jdamick;nevermind, i see.;;;","23/Oct/11 23:22;jdamick;Working patch for dealing with compressed & uncompressed messages.  Updated tests & added a pluggable interface for future other payload codecs (compression or other);;;","25/Oct/11 03:46;nehanarkhede;Jeffrey, thanks for the patch. It looks good, though I wasn't able to build the go code and run the unit tests. The instructions in the README seem to be outdated ? ;;;","25/Oct/11 04:38;jjkoshy;I get the following - are these files missing from your patch?

Thanks,

Joel

clients/go]$ GOROOT=. make install
Makefile:1: src/Make.inc: No such file or directory
Makefile:14: src/Make.pkg: No such file or directory
make: *** No rule to make target `src/Make.pkg'.  Stop.;;;","25/Oct/11 08:36;jdamick;joel: just a guess but it looks like you goroot isn't set right.  It needs to point to the location where you installed go, mine points to /opt/go for example.  May want to double check: http://golang.org/doc/install.html#install

Neha: i'm glad to help, what error did you get?;;;","25/Oct/11 08:48;nehanarkhede;I saw the same error that Joel mentioned. Let me follow the installation for go and see if that helps.;;;","25/Oct/11 12:43;jjkoshy;Yes - that was the issue. It is probably obvious to go users. Otherwise, it would be good to mention this in the readme.

+1

;;;","25/Oct/11 12:58;nehanarkhede;+1 on updating the README. Thanks for the patch !;;;","27/Oct/11 21:58;jdamick;who commits the patch then?  i would if i could, can i have access to that part of the tree?;;;","27/Oct/11 22:03;nehanarkhede;One of the committers can accept the patch. Please can you update the README and upload an updated patch ?;;;","27/Oct/11 22:14;jdamick;updated the README, including links to the incubator website & go installation.;;;","27/Oct/11 22:23;nehanarkhede;Thanks for being responsive. Just committed this !;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix MetricName so that Yammer reporter can work correctly,KAFKA-1902,12770392,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,junrao,junrao,junrao,28/Jan/15 00:14,29/Jan/15 09:13,22/Mar/23 15:10,29/Jan/15 09:13,,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"Currently, we create MetricName in the following format.

group: ""kafka.server""
type: ""BrokerTopicMetrics""
name: ""BytesInPerSec""
scope: null
mBeanName: ""kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=test""

However, Yammer metric reporter seems to only use the first four fields group, type, name and scope during reporting.
",,eidi,jbrosenberg@gmail.com,jjkoshy,junrao,kbanker,otis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jan/15 00:16;junrao;kafka-1902.patch;https://issues.apache.org/jira/secure/attachment/12694799/kafka-1902.patch","29/Jan/15 01:23;junrao;kafka-1902_2015-01-28_09:23:51.patch;https://issues.apache.org/jira/secure/attachment/12695024/kafka-1902_2015-01-28_09%3A23%3A51.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jan 29 01:13:05 UTC 2015,,,,,,,,,,"0|i24ulr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"28/Jan/15 00:16;junrao;Created reviewboard https://reviews.apache.org/r/30321/diff/
 against branch origin/0.8.2;;;","28/Jan/15 00:37;junrao;The fix is to use tag name as the scope. So, we will have scopes like the following.

scope: topic=test
scope: topic=test,partition=1;;;","28/Jan/15 01:29;jbrosenberg@gmail.com;In the yammer metric reporter (which is based on the Graphite metric naming scheme: https://graphite.readthedocs.org/en/latest/render_api.html#graphing-metrics), it's assumed that the metric name is comprised of components separated by dots, e.g. part1.part2.part3.part4.  These components make up branches in the navigation tree typically presented in a ui, etc.

No spaces are allowed (the yammer metric reporter replaces spaces with dashes '-').  But other characters are allowed, including '='. 

The yammer metric name is a concatenation of the group, type, name, scope (with '.'s inserted between each).  But if any of these also have a '.' internal to them, then that will also result in a separate component, so if we have:

{code}
group: ""kafka.server""
type: ""BrokerTopicMetrics""
name: ""BytesInPerSec""
scope: topic=my.topic.with.dots,partition=2
{code}

This will result in the metric path (broken down by navigation components):

{code}
kafka
server
BrokerTopicMetrics
BytesInPerSec
topic=my
topic
with
dots,partitions=2
{code}

Thus, I don't think the inclusion of '=' and ',' really maps well here, if the kafka topic has dots in it.  Instead, I think it would be better to just have the scope be something like:

{code}
scope: topicname.partition
{code}

(e.g. scope: my.topic.with.dots.2 in the example above).

The bottom line is that jmx tag syntax doesn't necessarily map directly to a metric navigation path.
;;;","28/Jan/15 01:36;kbanker;This definitely fixes the issue. I'm now seeing all of the missing metrics, and if you go with this approach, we Graphite users should be fine.

There are a couple of aesthetic issues we might consider, though, given that the Graphite convention is to use dot-separated names to form a hierarchy.

1. Do we want topics under BrokerTopicMetrics to be indicated as ""topic=foo"" or would it be better to set the scope as ""Topics.foo"" to form a more natural Graphite hierarchy?
2. FetcherLagMetrics now show up as clientId=ReplicaFetcherThread-0-2,topic=foo,partition=0.
Alternative: ReplicaFetcherThread-0-2.Topics.foo.partition-0
3. Log metrics look like this: topic=foo,partition=1. A Graphite alternative would be: Topics.foo.partition1, Topics.foo.partition2, etc.

Overall, these metrics naming conventions skew toward the JMX standard. We can pretty easily work around that in the Graphite world, and keeping the format the same will probably make it easier to compare metrics across systems.

Either way, it will be a big change for those using Graphite.;;;","28/Jan/15 02:28;junrao;Thanks for the explanation. A couple of things: (1) Since tags can be topic, partition, node, clientId, etc, it's probably useful to include the tag name in scope. Otherwise, you don't know exactly what the value is for. For example, if you have topic=mytopic,clientId=myclientId, using a scope of just mytopic.myclientId, it's not clear which part is for which. (2) About using dots, I was thinking that we can have scope like the following
  scope: topic.test.partition.10
However, since topic and clientId allow dots, using the dot convention can be confusing. For example, if you have topic=mytopic.with.dot,clientId=myclientId.with.dot, the scope will look like 
  topic.mytopic.with.dot.clientId.myclientId.with.dot
It's not clear if that's the hierarchy that everybody wants. Another problem with this convention is that it loses the info in the original tags. So, from the scope string, you can't easily recreate the original tags and their values. I am not sure if the dot convention is standard, but it seems it's specific to Graphite. So, we probably don't want to use a lossy naming convention just for the convenience of Graphite.

What if we just use the convention used in the patch, then you can customize your Graphite reporter to report the metric name in whatever format that you want?

Another option is to put the value part in quotes. So you will have 
  topic.""mytopic.with.dot"".clientId.""myclientId.with.dot"".

But that may have it's own complexity and problems.
;;;","28/Jan/15 03:43;jbrosenberg@gmail.com;Since many people use the vanilla GraphiteReporter bundled with the yammer libraries, it's a bit of work to ask them to roll a custom Graphite reporter.  Further, a custom reporter would have to embed specific knowledge around kafka metric scopes (while still supporting lots of general metrics coming from other libraries and the app itself).

Instead, if we don't want to create a reasonably formatted scope string that is already compatible with yammer metrics (which generally assumes the graphite format), it might work best if the scope string is sanitized to replace all dots with underscores.  This way, the scope is simply a unique (but still human identifiable) string, and is readily usable without too much guessing about a reasonable format.  The string would then be guaranteed to be a single, unbroken navigable component of a graphite metric.

;;;","28/Jan/15 05:13;junrao;Topic and clientId allow underscores too. How about replacing dots with sth like $? So scope will look like the following if dot is used in topic or clientId.

topic=mytopic$with$dot,clientId=myclientId$with$dot;;;","28/Jan/15 05:40;jjkoshy;It's unfortunate it seems graphite does not allow overriding the separator for hierarchy.

Jun, I'm not sure if Jason meant the following when he mentioned replacing the dots with underscore - since he mentioned that it should be ""navigable"" (by which I presume hierarchy). i.e., it would be more like:
topic.mytopic$with$dot.clientid.myclientId$with$dot - i.e., this way a graphite user can browse the hierarchy as before (although the topic names are fudged). It definitely loses information as you pointed out but that is probably okay since the scope is really only relevant for the graphite reporter.;;;","28/Jan/15 05:41;jjkoshy;I meant mytopic$with$dot.myclientId$with$dot;;;","28/Jan/15 05:55;jbrosenberg@gmail.com;[~jjkoshy] I did mean to just replace all dots with underscores.  I wasn't suggesting we need sub-navigation within the scope piece (although that wouldn't be ok too).  I really don't like the ""$""'s though, cuz they are ugly to read.  The whole point is that this is human readable.  I'm ok with underscores potentially coexisting with 'converted' dots-to-underscores (would still be readable).

Do topic and clientId not allow $?  What about dashes ('-')?;;;","28/Jan/15 06:06;junrao;Is graphite the only reporter using scope? t seems that there are ganglia, cvs, and console reporters as well. If we use mytopic$with$dot.myclientId$with$dot, we lose the tag info for other reporters. Actually, even for Graphite reporter, preserving the tag names are probably useful. Otherwise, you are not sure exactly what you are navigating into (e.g., groupId, clientId and topic sometimes can be the same). Using topic.mytopic$with$dot.clientid.myclientId$with$dot would be better, but it may make parsing a bit harder for other types of reporters, if they make use of scope.;;;","28/Jan/15 06:09;jbrosenberg@gmail.com;Actually, a red flag here too, is why are we using 'clientId' in the metric name? Won't that change each time an app is restarted (or is it stable long term)?  If it's not stable, it should not be part of a metric name.;;;","28/Jan/15 06:11;junrao;In Kafka, topic/group/clientId can include only -, _ and dot, in addition to alpha numerics. The problem of replacing dot with - or _ is that looking at the scope string, you don't know if a - or _ is originally there or not. Some users may find preserving that info useful.;;;","28/Jan/15 06:16;junrao;clientId is useful because one may want to run multiple producer/consumer instances in the same jvm and clientId is our way of distinguishing the metrics from different instances. clientId is a configuration and typically doesn't change after a restart.;;;","28/Jan/15 06:22;kbanker;Couple ideas here:

1. [~junrao] For what it's worth, the typical way of representing types in Graphite is with an extra level of hierarchy: i.e., instead of BrokerTopicMetrics.topic=foo, we'd do BrokerTopicMetrics.Topics.foo.

2. The character used to replace the dots in topic names could be configurable.

3. The default replacement could indeed be underscores. This is, I believe, the standard convention used when a hostname is part of a Graphite metric: simply replace dots with underscores. (Note that although host names aren't allowed to have underscores in the real world, DNS names often do. Still, no confusion results).

;;;","28/Jan/15 06:41;jbrosenberg@gmail.com;+1;;;","28/Jan/15 08:26;junrao;Making the replacing character configurable is actually not very easy and I think it's also a bit over killing. Do you know if the dot convention is followed in other reporters like Ganglia?

If we do end up using the dot convention in scope name, I think we should use a replacing character other than - or _. The reasoning is that if you see an issue with a metric on a topic, you probably want to do some trouble-shooting on the topic. If you can't figure out the exact topic, this will be a problem. Yes, using $ is not very readable. However, it's probably better than not figuring out the exact topic name. Also, this only affects the case when dot is actually used in the tag value, which may not be common.
;;;","28/Jan/15 08:43;jjkoshy;Jun - to answer your earlier question. I took a look at the GangliaReporter in metrics 2.x and it does seem that the ganglia reporter also uses the scope field. http://grepcode.com/file/repo1.maven.org/maven2/com.yammer.metrics/metrics-ganglia/2.0.0-BETA18/com/yammer/metrics/reporting/GangliaReporter.java#447 So it seems that ganglia users should also be affected by this issue that Jason reported;;;","28/Jan/15 09:17;kbanker;[~junrao] Agree that the dot may not be common, which minimizes the problems with the '$'.;;;","28/Jan/15 13:33;otis;bq. It's unfortunate it seems graphite does not allow overriding the separator for hierarchy.

Maybe that should be a feature request for Graphite devs?;;;","29/Jan/15 00:33;jbrosenberg@gmail.com;For the record, at Square, we do use '.''s heavily in topic names (for whatever reason).  I don't think making graphite use configurable separators is too likely (or should be a dependency on this effort).

One point worth making (if not obvious), is that the ordering of tags should be stable (e.g. always have clientid come before topic? Or vice-versa?).
;;;","29/Jan/15 01:23;junrao;Updated reviewboard https://reviews.apache.org/r/30321/diff/
 against branch origin/0.8.2;;;","29/Jan/15 01:29;junrao;It seems that the ganglia reporter replaces anything other than alpha-numeric, -, _ and dot to _ in the metric name. So, we can't put in chars like $ and = in scope. So, followed the suggestion by (1) using the dot convention; (2) replacing dot in tag value with _; (3) sort all tags alphabetically.

So, scope will look like
clientid.myclientid.topic.mytopic
clientid.myclientId_with_dot.topic.mytopic_with_dot

Jason, Kyle,

Could you verify the patch? Thanks,
;;;","29/Jan/15 01:36;kbanker;This looks great, [~junrao]!;;;","29/Jan/15 01:47;kbanker;I'll run the patch and report back.;;;","29/Jan/15 02:00;kbanker;I've just verified the patch against Graphite in a staging environment. Works great.

One minor note: a comment in the patch says ""// convert dot to _ since jmx reporters typically use dot to represent hierarchy"". I think you meant ""Graphite"" instead of ""JMX""?;;;","29/Jan/15 02:09;jbrosenberg@gmail.com;LGTM;;;","29/Jan/15 09:13;junrao;Thanks for the reviews. Committed to 0.8.2 and trunk after fixing the comment.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
scalatest_2.10-1.9.1.jar of core build path is cross-compiled with an incompatible version of Scala (2.10.0),KAFKA-1873,12768226,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,,sreevaddi,sreevaddi,17/Jan/15 23:48,20/Jan/15 08:59,22/Mar/23 15:10,20/Jan/15 08:59,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,2.10.0,core,incompatible,scala,scalatest,"When you setup your development environment, you see this in Problems for the project 'core'.

Description	Resource	Path	Location	Type
scalatest_2.10-1.9.1.jar of core build path is cross-compiled with an incompatible version of Scala (2.10.0). In case this report is mistaken, this check can be disabled in the compiler preference page.	core		Unknown	Scala Version Problem
","Mac OSX Yosemite
Oracle JDK 1.7.0_72
eclipse Mars M4",junrao,sreevaddi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7200,7200,,0%,7200,7200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jan 20 00:59:31 UTC 2015,,,,,,,,,,"0|i24hn3:",9223372036854775807,,omkreddy,,,,,,,,,,,,,,,,,,"17/Jan/15 23:50;sreevaddi;Workaround:
Eclipse - Preferences - Scala - Compiler - Build manager
uncheck withVersionClasspathVariable

[~junrao] Would be good to fix the scalatest.jar itself.
;;;","18/Jan/15 00:21;junrao;Hmm, our build script is the following. It explicitly specifies scalatest_2.10-1.9.1.jar for scala 2.10 and our tests have been running fine. Are you sure this is an issue?

    if (scalaVersion.startsWith('2.10')) {
      testCompile 'org.scalatest:scalatest_2.10:1.9.1'
    } else if (scalaVersion.startsWith('2.11')) {
      compile 'org.scala-lang.modules:scala-xml_2.11:1.0.2'
      compile 'org.scala-lang.modules:scala-parser-combinators_2.11:1.0.2'
      testCompile ""org.scalatest:scalatest_2.11:2.2.0""
    } else {
      testCompile ""org.scalatest:scalatest_$scalaVersion:1.8""
    }
;;;","20/Jan/15 08:59;sreevaddi;[~junrao] This fixes it.

kafka/gradle.properties
scalaVersion=2.11.5 ===> change it from 2.10.4

project 'core' -> right click -> Scala -> Restart Presentation Compiler.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Group metadata cache loading is not safe when reloading a partition,KAFKA-2841,12913047,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,hachikuji,hachikuji,hachikuji,14/Nov/15 12:15,18/Nov/15 10:35,22/Mar/23 15:10,18/Nov/15 10:35,0.9.0.0,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"If the coordinator receives a leaderAndIsr request which includes a higher leader epoch for one of the partitions that it owns, then it will reload the offset/metadata for that partition again. This can happen because the leader epoch is incremented for ISR changes which do not result in a new leader for the partition. Currently, the coordinator replaces cached metadata values blindly on reloading, which can result in weird behavior such as unexpected session timeouts or request timeouts while rebalancing.

To fix this, we need to check that the group being loaded has a higher generation than the cached value before replacing it. Also, if we have to replace a cached value (which shouldn't happen except when loading), we need to be very careful to ensure that any active delayed operations won't affect the group. ",,githubbot,guozhang,hachikuji,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Nov 18 02:35:18 UTC 2015,,,,,,,,,,"0|i2oeb3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"14/Nov/15 13:40;guozhang;[~hachikuji] Is this solvable in KAFKA-2721?;;;","14/Nov/15 13:57;hachikuji;[~guozhang] Yeah, I think that addresses the major issue, but I think it's still worthwhile to add the checks when inserting into the metadata cache.;;;","15/Nov/15 10:42;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/530

    KAFKA-2841: safe group metadata cache loading/unloading

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-2841

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/530.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #530
    
----
commit 881380eac954e0906ef2ec0fe3d5d8e067473a35
Author: Jason Gustafson <jason@confluent.io>
Date:   2015-11-14T23:54:25Z

    KAFKA-2841: safe group metadata cache loading/unloading

----
;;;","17/Nov/15 02:16;junrao;I thought the current logic is that if a group is being uploaded, the group is not accessible until the upload completes? Once the upload completes, the group should have the latest info.;;;","17/Nov/15 02:27;hachikuji;[~junrao] That is correct. The problem is that the group may be loaded more than once and the cached metadata object which holds group and member state may be replaced. When this happens, you can get very strange behavior since join/sync response callbacks may be lost and delayed operations (which still refer to the original metadata object) can cause conflicts. My patch makes this safer by preventing this replacement from taking place when a partition is loaded and by cleaning up the group state when the cached metadata is unloaded due to partition emigration to a new leader.;;;","18/Nov/15 10:35;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/530
;;;","18/Nov/15 10:35;junrao;Issue resolved by pull request 530
[https://github.com/apache/kafka/pull/530];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Logging of unused options always shows null for the value and is misleading if the option is used by serializers,KAFKA-2026,12782661,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Trivial,Fixed,omkreddy,ewencp,ewencp,18/Mar/15 02:57,31/Jul/15 05:32,22/Mar/23 15:10,31/Jul/15 05:32,0.8.2.1,,,,,,0.9.0.0,,,,,,,clients,,,,0,,,,,,"This is a really simple issue. When AbstractConfig logs unused messages, it gets the value from the parsed configs. Since those are generated from the ConfigDef, they value will not have been parsed or copied over from the original map. This is especially confusing if you've explicitly set an option to pass through to the serializers since you're always going to see these warnings in your log.

The simplest patch would grab the original value from this.originals. But now I'm not sure logging this makes sense at all anymore since configuring any serializer that has options that aren't in ProducerConfig will create a misleading warning message. Further, using AbstractConfig for your serializer implementation would cause all the producer's config settings to be logged as unused. Since a single set of properties is being used to configure multiple components, trying to log unused keys may not make sense anymore.

Example of confusion caused by this: http://mail-archives.apache.org/mod_mbox/kafka-users/201503.mbox/%3CCAPAVcJ8nwSVjia3%2BH893V%2B87StST6r0xN4O2ac8Es2bEXjv1OA%40mail.gmail.com%3E",,ewencp,guozhang,omkreddy,umesh9794@gmail.com,xgong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jun/15 18:07;omkreddy;KAFKA-2026.patch;https://issues.apache.org/jira/secure/attachment/12739412/KAFKA-2026.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jul 30 21:32:20 UTC 2015,,,,,,,,,,"0|i26vt3:",9223372036854775807,,ewencp,,,,,,,,,,,,,,,,,,"13/Jun/15 18:07;omkreddy;Created reviewboard https://reviews.apache.org/r/35421/diff/
 against branch origin/trunk;;;","28/Jul/15 12:08;xgong;I think that the warning messages here are used to remind the users that they did not specify some configurations. So, instead of simply changing the value, we could rephrase the warning messages which include something like ""This configuration is not specified explicitly, will use the default value"", etc;;;","31/Jul/15 03:55;guozhang;Assigning to [~ewencp] for reviews.;;;","31/Jul/15 04:39;ewencp;[~guozhang] This looks fine to commit as it addresses the most basic problem where it suggested you had set null config parameters when you hadn't. It's definitely better than the current code. I'm still not sure if we should do something more though, since I regularly see warnings from this code because we pass schema.registry.url in via configs for the Confluent serializers and this will always complain about those extra settings that are to be passed to serializers. I guess since they are warnings it's not that big a deal, but it's not great to have expected and standard usage result in warnings...;;;","31/Jul/15 05:32;guozhang;Thanks. I agree the current warning message might be a bit misleading, have committed the current patch and closed the ticket for now. If people later found this misleading-ness really matters let's go back and revisit this ticket.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to change min.insync.replicas default,KAFKA-2114,12820345,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,gwenshap,bbaugher,bbaugher,12/Apr/15 04:44,09/Sep/15 23:57,22/Mar/23 15:10,27/Apr/15 04:09,0.8.2.0,0.8.2.1,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Following the comment here[1] I was unable to change the min.insync.replicas default value. I tested this by setting up a 3 node cluster, wrote to a topic with a replication factor of 3, using request.required.acks=-1 and setting min.insync.replicas=2 on the broker's server.properties. I then shutdown 2 brokers but I was still able to write successfully. Only after running the alter topic command setting min.insync.replicas=2 on the topic did I see write failures.

[1] - http://mail-archives.apache.org/mod_mbox/kafka-users/201504.mbox/%3CCANZ-JHF71yqKE6%2BKKhWe2EGUJv6R3bTpoJnYck3u1-M35sobgg%40mail.gmail.com%3E",,bbaugher,eidi,gwenshap,nehanarkhede,noslowerdna,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/15 08:10;gwenshap;KAFKA-2114.patch;https://issues.apache.org/jira/secure/attachment/12727044/KAFKA-2114.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Sep 09 15:57:26 UTC 2015,,,,,,,,,,"0|i2d5cf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"22/Apr/15 08:10;gwenshap;Created reviewboard https://reviews.apache.org/r/33421/diff/
 against branch trunk;;;","22/Apr/15 08:11;gwenshap;Ended up being very silly case of not passing the broker config for minISR to the log manager.

Fixed and added a test.;;;","27/Apr/15 04:09;nehanarkhede;Pushed to trunk. Thanks Gwen!;;;","03/Sep/15 15:40;sslavic;I guess affected version should be 0.8.2, correct?;;;","09/Sep/15 23:57;noslowerdna;Yes, that is correct.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Excessive storage usage on newly added node,KAFKA-1712,12748951,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,ovgolovin,ovgolovin,18/Oct/14 03:09,29/Aug/18 03:08,22/Mar/23 15:10,29/Aug/18 03:08,,,,,,,,,,,,,,log,,,,5,,,,,,"When a new node is added to cluster data starts replicating into it. The mtime of creating segments will be set on the last message being written to them. Though the replication is a prolonged process, let's assume (for simplicity of explanation) that their mtime is very close to the time when the new node was added.

After the replication is done, new data will start to flow into this new node. After `log.retention.hours` the amount of data will be 2 * daily_amount_of_data_in_kafka_node (first one is the replicated data from other nodes when the node was added (let us call it `t1`) and the second is the amount of replicated data from other nodes which happened from `t1` to `t1 + log.retention.hours`). So by that time the node will have twice as much data as the other nodes.

This poses a big problem to us as our storage is chosen to fit normal amount of data (not twice this amount).

In our particular case it poses another problem. We have an emergency segment cleaner which runs in case storage is nearly full (>90%). We try to balance the amount of data for it not to run to rely solely on kafka internal log deletion, but sometimes emergency cleaner runs.
It works this way:
- it gets all kafka segments for the volume
- it filters out last segments of each partition (just to avoid unnecessary recreation of last small-size segments)
- it sorts them by segment mtime
- it changes mtime of the first N segements (with the lowest mtime) to 1, so they become really really old. Number N is chosen to free specified percentage of volume (3% in our case).  Kafka deletes these segments later (as they are very old).

Emergency cleaner works very well. Except for the case when the data is replicated to the newly added node. 
In this case segment mtime is the time the segment was replicated and does not reflect the real creation time of original data stored in this segment.
So in this case kafka emergency cleaner will delete segments with the lowest mtime, which may hold the data which is much more recent than the data in other segments.
This is not a big problem until we delete the data which hasn't been fully consumed.
In this case we loose data and this makes it a big problem.

Is it possible to retain segment mtime during initial replication on a new node?
This will help not to load the new node with the twice as large amount of data as other nodes have.

Or maybe there are another ways to sort segments by data creation times (or close to data creation time)? (for example if this ticket is implemented https://issues.apache.org/jira/browse/KAFKA-1403, we may take time of the first message from .index). In our case it will help with kafka emergency cleaner, which will be deleting really the oldest data.",,abraithwaite,aozeritsky,ataraxer,bobrik,i.galic,junrao,omkreddy,ovgolovin,Pegerto,suninside,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Aug 28 19:08:07 UTC 2018,,,,,,,,,,"0|i21b1r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Oct/14 05:25;junrao;This is being discussed in https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Enriched+Message+Metadata;;;","01/Mar/17 07:51;abraithwaite;Has this been looked at recently?  We've found it's an issue for nodes which are coming back into a cluster as well.;;;","29/Aug/18 03:08;omkreddy;Fixed via https://issues.apache.org/jira/browse/KAFKA-2511;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
StackOverflowError during builds,KAFKA-2457,12857812,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,ijuma,ijuma,ijuma,21/Aug/15 18:36,22/Aug/15 03:52,22/Mar/23 15:10,22/Aug/15 02:33,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,We need to set -Xss to avoid this problem. Will submit PR.,,githubbot,gwenshap,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Aug 21 19:52:46 UTC 2015,,,,,,,,,,"0|i2j7dj:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"21/Aug/15 18:55;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/157

    KAFKA-2457; StackOverflowError during builds

    The default is typically `1m` for 64-bit machines and the Scala compiler sometimes needs more than this.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-2457-stackoverflowerror-during-builds

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/157.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #157
    
----
commit 6054599e480f0f6b1fb413edd7a512766befba9b
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2015-08-21T10:53:46Z

    Set stack size at `2m`
    
    The default is typically `1m` for 64-bit machines
    and the Scala compiler sometimes needs more than
    this.

----
;;;","21/Aug/15 18:56;ijuma;I have verified that this fixed an instance where I was reproducibly getting a SOE.;;;","22/Aug/15 02:33;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/157
;;;","22/Aug/15 02:33;gwenshap;Issue resolved by pull request 157
[https://github.com/apache/kafka/pull/157];;;","22/Aug/15 03:34;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/159

    KAFKA-2457; Fix how the argument is passed to `compileScala`

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-2457-fix

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/159.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #159
    
----
commit 562f9c18524a59aefa14fd7a46d213039ba47e46
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2015-08-21T19:33:21Z

    KAFKA-2457; Fix how the argument is passed to `compileScala`

----
;;;","22/Aug/15 03:52;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/159
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka producer does not cope well with topic deletions,KAFKA-2948,12918982,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,rsivaram,rsivaram,rsivaram,04/Dec/15 22:13,14/Mar/17 02:42,22/Mar/23 15:10,07/Jun/16 02:58,0.9.0.0,,,,,,0.10.1.0,,,,,,,producer ,,,,2,,,,,,"Kafka producer gets metadata for topics when send is invoked and thereafter it attempts to keep the metadata up-to-date without any explicit requests from the client. This works well in static environments, but when topics are added or deleted, list of topics in Metadata grows but never shrinks. Apart from being a memory leak, this results in constant requests for metadata for deleted topics.

We are running into this issue with the Confluent REST server where topic deletion from tests are filling up logs with warnings about unknown topics. Auto-create is turned off in our Kafka cluster.

I am happy to provide a fix, but am not sure what the right fix is. Does it make sense to remove topics from the metadata list when UNKNOWN_TOPIC_OR_PARTITION response is received if there are no outstanding sends? It doesn't look very straightforward to do this, so any alternative suggestions are welcome.
",,becket_qin,githubbot,guozhang,ijuma,mgharat,rsivaram,samuel.beniamin,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SPARK-18057,,,,,,,,,,,,,,,,KAFKA-3450,KAFKA-4385,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jun 06 18:56:35 UTC 2016,,,,,,,,,,"0|i2pevb:",9223372036854775807,,ewencp,,,,,,,,,,,,,,,,,,"08/Dec/15 02:07;becket_qin;[~rsivaram] As you pointed out we never remove the topics set in producer metadata. I am not sure if removing the topic from the set when we see UNKNOWN_TOPIC_OR_PARTITION error code is the right way to fix this, because UNKNOWN_TOPIC_OR_PARTITION can also occur in other cases such as partition reassignment, the producer is supposed to retry in this case. 

Maybe a TTL is a better solution here. e.g. If the producer hasn't sent data to a particular topic since last metadata refresh, we can remove the topic from metadata topic set on next metadata refresh.;;;","08/Dec/15 18:49;rsivaram;[~becket_qin] Thank you for your feedback. The fix that we are testing at the moment removes topics with `UNKNOWN_TOPIC_OR_PARTITION` error from the metadata set when the error is received in a response, but re-adds it when metadata is requested for the topic (eg. producer waiting for metadata to send a message). This ensures that the request is retried when required, but not when the topic is no longer in use. 

TTL sounds like a better option to remove not just deleted topics, but also any topic that is no longer being used. My only concern is that deleted topics would remain in the list for a longer period of time with a lot of warnings in the logs as metadata requests are retried. I could combine the current fix and TTL if required to avoid this, but I will try out TTL on its own first with the REST service and see how that goes. ;;;","09/Dec/15 02:38;mgharat;Adding TTL would mean another user exposed config. Can we not use the number of times we got ""UNKNOWN_TOPIC_OR_PARTITION"" and then get rid of the  topic.;;;","09/Dec/15 03:24;becket_qin;[~mgharat] I think TTL should not be a config but simply an internal mechanism. User should not care about this at all.;;;","09/Dec/15 03:40;rsivaram;[~mgharat] [~becket_qin] The code that I am testing at the moment uses the current config `metadata.max.age.ms`. If no messages are sent to a topic for this interval, then the topic is removed from the metadata set. Subsequent send will add it back to the set. I am also marking the topic for delete if a send fails because no metadata was available for a topic, to limit the number of retries for deleted topics. Will submit a PR later today for review.;;;","09/Dec/15 08:35;githubbot;GitHub user rajinisivaram opened a pull request:

    https://github.com/apache/kafka/pull/645

    KAFKA-2948: Remove unused topics from producer metadata set

    If no messages are sent to a topic during the last refresh interval or if UNKNOWN_TOPIC_OR_PARTITION error is received, remove the topic from the metadata list. Topics are added to the list on the next attempt to send a message to the topic.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/rajinisivaram/kafka KAFKA-2948

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/645.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #645
    
----
commit f7e40e5ce515d700e8cc7ab02a0f16141fa14f67
Author: rsivaram <rsivaram@uk.ibm.com>
Date:   2015-12-09T00:16:18Z

    KAFKA-2948: Remove unused topics from producer metadata set

----
;;;","09/Dec/15 13:59;guozhang;Assigning to [~ewencp] to review.;;;","06/Feb/16 02:57;ijuma;Setting target as 0.9.1.0 as 0.9.0.1 will be released very soon and we want to be careful about last-minute regressions.;;;","07/Jun/16 02:56;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/645
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Vagrantfile sets global configs instead of per-provider override configs,KAFKA-2330,12844405,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,ewencp,ewencp,ewencp,12/Jul/15 10:08,20/Aug/15 09:21,22/Mar/23 15:10,20/Aug/15 09:21,0.8.2.1,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"There's a couple of minor incorrect usages of the global configuration object in the Vagrantfile inside provider-specific override blocks where we should be using the override config object. Two end up being harmless since they have no affect on other providers (but should still be corrected). The third results in using rsync when using Virtualbox, which is unnecessary, slower, and requires copying the entire kafka directory to every VM.",,ewencp,granders,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jul/15 10:10;ewencp;KAFKA-2330.patch;https://issues.apache.org/jira/secure/attachment/12744916/KAFKA-2330.patch","20/Aug/15 08:50;ewencp;KAFKA-2330_2015-08-19_17:50:17.patch;https://issues.apache.org/jira/secure/attachment/12751382/KAFKA-2330_2015-08-19_17%3A50%3A17.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Aug 20 01:21:46 UTC 2015,,,,,,,,,,"0|i2h55z:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"12/Jul/15 10:10;ewencp;Created reviewboard https://reviews.apache.org/r/36427/diff/
 against branch origin/trunk;;;","16/Jul/15 07:27;granders;+1 from me

I confirmed on my mac that changes in the kafka directory are immediately visible within the vm's /vagrant directory, and that aws requires rsync.

Note that the rsync excludes don't work, but this may actually be a problem with vagrant-aws: https://github.com/mitchellh/vagrant-aws/issues/304

At first I thought this might be an issue with the variable name 'vagrant_excludes': the current Vagrant docs show 'vagrant__exclude' (double underscore, singular - http://docs.vagrantup.com/v2/synced-folders/rsync.html), however you can find both usages in a quick google search, so it's not clear to me which if any is incorrect. I did a quick trial of both variable names, and neither seems to work.;;;","16/Jul/15 09:43;ewencp;[~granders] Uggh, that's really annoying. It looks like the right setting depends on the version of vagrant-aws you're using. Older versions had a custom rsyncing solution inside the vagrant-aws plugin, newer versions (0.6.0+) use the support provided by vagrant. It's very likely that I originally developed this pre-0.6.0 when this setting would have worked.

Since the rsync_excludes version no longer works on the most recent versions of the plugin, we should switch to the rsync__exclude form, but we'll probably have to dig through Vagrant code to figure out why its not working.

For reference, which versions do vagrant version and vagrant plugin list show for the machine you tested this on?;;;","16/Jul/15 09:50;granders;Sorry, for reference, the aws machine I tested this on had:

$ vagrant --version 
Vagrant 1.7.2  

$ vagrant plugin list  
vagrant-aws (0.6.0)                                                                                                                                                         
vagrant-hostmanager (1.5.0) 
vagrant-share (1.1.3, system);;;","19/Aug/15 12:50;ewencp;[~gwenshap] Reassigned to you since I think you're familiar with some of this since you reviewed the system test patch. This is pretty minimal and still applies cleanly, should be a quick review. Or maybe [~guozhang] wants to review?;;;","20/Aug/15 07:55;granders;rsync_excludes should maybe include 'tests/results';;;","20/Aug/15 07:58;gwenshap;Please add to the README that we need HostManager 1.5.0 (but no higher):
vagrant plugin install vagrant-hostmanager --plugin-version 1.5.0;;;","20/Aug/15 08:50;ewencp;Updated reviewboard https://reviews.apache.org/r/36427/diff/
 against branch origin/trunk;;;","20/Aug/15 09:21;gwenshap;+1 and pushed to trunk.

Thanks for the improvement, [~ewencp];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZKBrokerPartitionInfo doesn't allow load balancing on a new topic,KAFKA-13,12514650,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,,,20/Jul/11 05:32,20/Jul/11 05:32,22/Mar/23 15:10,20/Jul/11 05:32,0.6,,,,,,0.6,,,,,,,,,,,0,,,,,,"The problem is that initially no broker has registered for a topic in ZK. Once the producer sends a message to a broker, that broker is registered in ZK. After that, the producer sticks with that broker.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,67503,,,2011-07-19 21:32:12.0,,,,,,,,,,"0|i15yin:",242892,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NumberFormatException in PartitionStateInfo,KAFKA-715,12628597,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,nehanarkhede,criccomini,criccomini,22/Jan/13 03:25,08/Feb/15 07:34,22/Mar/23 15:10,08/Feb/15 07:34,0.8.0,,,,,,,,,,,,,replication,,,,0,,,,,,"Hey Guys,

During a broker restart, I got this exception:

2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:zookeeper.version=3.3.3-1203054, built on 11/17/2011 05:47 GMT
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:host.name=eat1-qa466.corp.linkedin.com
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:java.version=1.6.0_21
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:java.vendor=Sun Microsystems Inc.
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:java.home=/export/apps/jdk/JDK-1_6_0_21/jre
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:java.class.path=/export/apps/jdk/JDK-1_6_0_21/lib/tools.jar:lib/activation-1.0.2.jar:lib/ant-1.6.5.jar:lib/aopalliance-1.0.jar:lib/cfg-2.8.0.jar:lib/cfg-api-6.6.6.jar:lib/cfg-impl-6.6.6.jar:lib/com.linkedin.customlibrary.j2ee-1.0.jar:lib/com.linkedin.customlibrary.mx4j-3.0.2.jar:lib/com.linkedin.customlibrary.xmsg-0.6.jar:lib/commons-beanutils-1.7.0.jar:lib/commons-cli-1.0.jar:lib/commons-lang-2.4.jar:lib/commons-logging-1.1.jar:lib/configuration-api-1.4.8.jar:lib/configuration-repository-impl-1.4.8.jar:lib/container-management-impl-1.1.15.jar:lib/container-server-1.1.15.jar:lib/emweb-impl-1.1.15.jar:lib/jaxen-1.1.1.jar:lib/jdom-1.0.jar:lib/jetty-6.1.26.jar:lib/jetty-management-6.1.26.jar:lib/jetty-naming-6.1.26.jar:lib/jetty-plus-6.1.26.jar:lib/jetty-util5-6.1.26.jar:lib/jetty-util-6.1.26.jar:lib/jmx-impl-1.4.8.jar:lib/json-simple-1.1.jar:lib/jsp-2.1-6.1.1.jar:lib/jsp-api-2.1-6.1.1.jar:lib/lispring-lispring-core-1.4.8.jar:lib/lispring-lispring-servlet-1.4.8.jar:lib/log4j-1.2.15.jar:lib/mail-1.3.0.jar:lib/mx4j-tools-3.0.2.jar:lib/servlet-api-2.5.jar:lib/spring-aop-3.0.3.jar:lib/spring-asm-3.0.3.jar:lib/spring-aspects-3.0.3.jar:lib/spring-beans-3.0.3.jar:lib/spring-context-3.0.3.jar:lib/spring-context-support-3.0.3.jar:lib/spring-core-3.0.3.jar:lib/spring-expression-3.0.3.jar:lib/spring-jdbc-3.0.3.jar:lib/spring-jms-3.0.3.jar:lib/spring-orm-3.0.3.jar:lib/spring-transaction-3.0.3.jar:lib/spring-web-3.0.3.jar:lib/spring-web-servlet-3.0.3.jar:lib/util-core-4.0.40.jar:lib/util-i18n-4.0.40.jar:lib/util-jmx-4.0.22.jar:lib/util-log-4.0.40.jar:lib/util-servlet-4.0.40.jar:lib/util-xmsg-4.0.40.jar:lib/xml-apis-1.3.04.jar
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:java.library.path=/export/apps/jdk/JDK-1_6_0_21/jre/lib/amd64/server:/export/apps/jdk/JDK-1_6_0_21/jre/lib/amd64:/export/apps/jdk/JDK-1_6_0_21/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:java.io.tmpdir=/export/content/glu/apps/kafka/i001/tmp
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:java.compiler=<NA>
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:os.name=Linux
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:os.arch=amd64
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:os.version=2.6.32-220.13.1.el6.x86_64
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:user.name=app
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:user.home=/home/app
2013/01/21 19:21:10.918 INFO [ZooKeeper] [main] [kafka] []  Client environment:user.dir=/export/content/glu/apps/kafka/i001
2013/01/21 19:21:10.919 INFO [ZooKeeper] [main] [kafka] []  Initiating client connection, connectString=eat1-app309.corp.linkedin.com:12913,eat1-app310.corp.linkedin.com:12913,eat1-app311.corp.linkedin.com:12913,eat1-app312.corp.linkedin.com:12913,eat1-app313.corp.linkedin.com:12913/kafka-samsa sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@1bfdbab5
2013/01/21 19:21:10.932 INFO [ClientCnxn] [main-SendThread()] [kafka] []  Opening socket connection to server eat1-app313.corp.linkedin.com/172.20.72.73:12913
2013/01/21 19:21:10.933 INFO [ClientCnxn] [main-SendThread(eat1-app313.corp.linkedin.com:12913)] [kafka] []  Socket connection established to eat1-app313.corp.linkedin.com/172.20.72.73:12913, initiating session
2013/01/21 19:21:10.963 INFO [ClientCnxn] [main-SendThread(eat1-app313.corp.linkedin.com:12913)] [kafka] []  Session establishment complete on server eat1-app313.corp.linkedin.com/172.20.72.73:12913, sessionid = 0x53afd073784059c, negotiated timeout = 6000
2013/01/21 19:21:10.964 INFO [ZkClient] [main-EventThread] [kafka] []  zookeeper state changed (SyncConnected)
2013/01/21 19:21:10.979 INFO [ZkUtils$] [main] [kafka] []  Registered broker 466 at path /brokers/ids/466 with address eat1-qa466.corp.linkedin.com:10251.
2013/01/21 19:21:10.979 INFO [KafkaServer] [main] [kafka] []  [Kafka Server 466], Connecting to ZK: eat1-app309.corp.linkedin.com:12913,eat1-app310.corp.linkedin.com:12913,eat1-app311.corp.linkedin.com:12913,eat1-app312.corp.linkedin.com:12913,eat1-app313.corp.linkedin.com:12913/kafka-samsa
2013/01/21 19:21:11.018 INFO [ControllerEpochListener] [main] [kafka] []  [ControllerEpochListener on 466]: Initialized controller epoch to 22 and zk version 21
2013/01/21 19:21:11.054 ERROR [Processor] [kafka-processor-10251-0] [kafka] []  Closing socket for /172.18.146.131 because of error
java.lang.NumberFormatException: For input string: """"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)
	at java.lang.Integer.parseInt(Integer.java:470)
	at java.lang.Integer.parseInt(Integer.java:499)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:207)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:31)
	at kafka.api.PartitionStateInfo$$anonfun$1.apply(LeaderAndIsrRequest.scala:51)
	at kafka.api.PartitionStateInfo$$anonfun$1.apply(LeaderAndIsrRequest.scala:51)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)
	at scala.collection.mutable.ArrayOps.foreach(ArrayOps.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)
	at scala.collection.mutable.ArrayOps.map(ArrayOps.scala:34)
	at kafka.api.PartitionStateInfo$.readFrom(LeaderAndIsrRequest.scala:51)
	at kafka.api.LeaderAndIsrRequest$$anonfun$readFrom$2.apply(LeaderAndIsrRequest.scala:100)
	at kafka.api.LeaderAndIsrRequest$$anonfun$readFrom$2.apply(LeaderAndIsrRequest.scala:97)
	at scala.collection.immutable.Range$ByOne$class.foreach(Range.scala:282)
	at scala.collection.immutable.Range$$anon$2.foreach(Range.scala:265)
	at kafka.api.LeaderAndIsrRequest$.readFrom(LeaderAndIsrRequest.scala:97)
	at kafka.api.RequestKeys$$anonfun$5.apply(RequestKeys.scala:36)
	at kafka.api.RequestKeys$$anonfun$5.apply(RequestKeys.scala:36)
	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:47)
	at kafka.network.Processor.read(SocketServer.scala:320)
	at kafka.network.Processor.run(SocketServer.scala:231)
	at java.lang.Thread.run(Thread.java:619)
2013/01/21 19:21:11.071 INFO [Mx4jLoader$] [main] [kafka] []  mx4j successfuly loaded
2013/01/21 19:21:11.073 INFO [KafkaController] [main] [kafka] []  [Controller 466]: Controller starting up
2013/01/21 19:21:11.091 INFO [ZkUtils$] [main] [kafka] []  conflict in /controller data: 466 stored data: 465
2013/01/21 19:21:11.093 INFO [KafkaController] [main] [kafka] []  [Controller 466]: Controller startup complete
2013/01/21 19:21:11.099 INFO [KafkaServer] [main] [kafka] []  [Kafka Server 466], started
2013/01/21 19:21:11.099 INFO [VerifiableProperties] [main] [kafka] []  Verifying properties
2013/01/21 19:21:11.100 WARN [VerifiableProperties] [main] [kafka] []  Property zk.sessiontimeout.ms is not valid
2013/01/21 19:21:11.100 INFO [VerifiableProperties] [main] [kafka] []  Property num.replica.fetchers is overridden to 1
2013/01/21 19:21:11.100 INFO [VerifiableProperties] [main] [kafka] []  Property log.retention.hours is overridden to 168
2013/01/21 19:21:11.100 WARN [VerifiableProperties] [main] [kafka] []  Property zk.connectiontimeout.ms is not valid
2013/01/21 19:21:11.100 INFO [VerifiableProperties] [main] [kafka] []  Property auto.create.topics.enable is overridden to true
2013/01/21 19:21:11.101 INFO [VerifiableProperties] [main] [kafka] []  Property replica.fetch.min.bytes is overridden to 1
2013/01/21 19:21:11.101 INFO [VerifiableProperties] [main] [kafka] []  Property replica.lag.time.max.ms is overridden to 10000
2013/01/21 19:21:11.101 INFO [VerifiableProperties] [main] [kafka] []  Property log.retention.bytes is overridden to -1
2013/01/21 19:21:11.101 INFO [VerifiableProperties] [main] [kafka] []  Property log.flush.interval.messages is overridden to 10000
2013/01/21 19:21:11.101 INFO [VerifiableProperties] [main] [kafka] []  Property socket.request.max.bytes is overridden to 104857600
2013/01/21 19:21:11.101 INFO [VerifiableProperties] [main] [kafka] []  Property default.replication.factor is overridden to 3
2013/01/21 19:21:11.101 INFO [VerifiableProperties] [main] [kafka] []  Property replica.fetch.wait.max.ms is overridden to 500
2013/01/21 19:21:11.102 INFO [VerifiableProperties] [main] [kafka] []  Property log.cleanup.interval.mins is overridden to 30
2013/01/21 19:21:11.102 INFO [VerifiableProperties] [main] [kafka] []  Property num.partitions is overridden to 12
2013/01/21 19:21:11.102 INFO [VerifiableProperties] [main] [kafka] []  Property log.segment.bytes.per.topic is overridden to 
2013/01/21 19:21:11.102 INFO [VerifiableProperties] [main] [kafka] []  Property controller.socket.timeout.ms is overridden to 30000
2013/01/21 19:21:11.102 WARN [VerifiableProperties] [main] [kafka] []  Property log.flush.intervals.ms.per.topic is not valid
2013/01/21 19:21:11.102 INFO [VerifiableProperties] [main] [kafka] []  Property socket.receive.buffer.bytes is overridden to 1048576
2013/01/21 19:21:11.102 INFO [VerifiableProperties] [main] [kafka] []  Property queued.max.requests is overridden to 16
2013/01/21 19:21:11.102 INFO [VerifiableProperties] [main] [kafka] []  Property replica.high.watermark.checkpoint.interval.ms is overridden to 5000
2013/01/21 19:21:11.103 INFO [VerifiableProperties] [main] [kafka] []  Property replica.socket.receive.buffer.bytes is overridden to 65536
2013/01/21 19:21:11.103 INFO [VerifiableProperties] [main] [kafka] []  Property replica.lag.max.messages is overridden to 4000
2013/01/21 19:21:11.103 INFO [VerifiableProperties] [main] [kafka] []  Property socket.send.buffer.bytes is overridden to 1048576
2013/01/21 19:21:11.103 INFO [VerifiableProperties] [main] [kafka] []  Property log.index.interval.bytes is overridden to 4096
2013/01/21 19:21:11.103 INFO [VerifiableProperties] [main] [kafka] []  Property producer.purgatory.purge.interval.requests is overridden to 1000
2013/01/21 19:21:11.103 INFO [VerifiableProperties] [main] [kafka] []  Property message.max.bytes is overridden to 1000000
2013/01/21 19:21:11.103 INFO [VerifiableProperties] [main] [kafka] []  Property log.flush.scheduler.interval.ms is overridden to 10000
2013/01/21 19:21:11.103 INFO [VerifiableProperties] [main] [kafka] []  Property replica.fetch.max.bytes is overridden to 1048576
2013/01/21 19:21:11.104 INFO [VerifiableProperties] [main] [kafka] []  Property broker.id is overridden to 466
2013/01/21 19:21:11.104 INFO [VerifiableProperties] [main] [kafka] []  Property port is overridden to 10251
2013/01/21 19:21:11.104 INFO [VerifiableProperties] [main] [kafka] []  Property num.network.threads is overridden to 3
2013/01/21 19:21:11.104 INFO [VerifiableProperties] [main] [kafka] []  Property log.index.size.max.bytes is overridden to 10485760
2013/01/21 19:21:11.104 INFO [VerifiableProperties] [main] [kafka] []  Property log.roll.hours is overridden to 168
2013/01/21 19:21:11.105 WARN [VerifiableProperties] [main] [kafka] []  Property zk.synctime.ms is not valid
2013/01/21 19:21:11.105 INFO [VerifiableProperties] [main] [kafka] []  Property fetch.purgatory.purge.interval.requests is overridden to 1000
2013/01/21 19:21:11.105 INFO [VerifiableProperties] [main] [kafka] []  Property log.dirs is overridden to /tmp/kafka-logs
2013/01/21 19:21:11.105 INFO [VerifiableProperties] [main] [kafka] []  Property controller.message.queue.size is overridden to 10
2013/01/21 19:21:11.105 INFO [VerifiableProperties] [main] [kafka] []  Property log.retention.bytes.per.topic is overridden to 
2013/01/21 19:21:11.105 INFO [VerifiableProperties] [main] [kafka] []  Property log.flush.interval.ms is overridden to 10000
2013/01/21 19:21:11.105 INFO [VerifiableProperties] [main] [kafka] []  Property log.roll.hours.per.topic is overridden to 
2013/01/21 19:21:11.105 INFO [VerifiableProperties] [main] [kafka] []  Property zk.connect is overridden to eat1-app309.corp.linkedin.com:12913,eat1-app310.corp.linkedin.com:12913,eat1-app311.corp.linkedin.com:12913,eat1-app312.corp.linkedin.com:12913,eat1-app313.corp.linkedin.com:12913/kafka-samsa
2013/01/21 19:21:11.106 INFO [VerifiableProperties] [main] [kafka] []  Property num.io.threads is overridden to 8
2013/01/21 19:21:11.106 INFO [VerifiableProperties] [main] [kafka] []  Property log.segment.bytes is overridden to 1073741824
2013/01/21 19:21:11.106 INFO [VerifiableProperties] [main] [kafka] []  Property replica.socket.timeout.ms is overridden to 30000
2013/01/21 19:21:11.106 INFO [VerifiableProperties] [main] [kafka] []  Property log.retention.hours.per.topic is overridden to 
2013/01/21 19:21:11.106 INFO [ComponentsContextLoaderListener] [main] [kafka] []  Started.
2013/01/21 19:21:11.106 INFO [ComponentsContextLoaderListener] [main] [kafka] []  Boot sequence complete.

Everything seems OK, but I thought I'd raise the issue anyway. I was doing something kind of evil with the brokers. I brought the entire cluster down, then rm -rf'd * in my Kafka data directory (ran out of disk space). Perhaps this triggered it? Seems kind of unrelated, give that it's ZK.

Just raising the issue. Might not be a big deal, but better safe than sorry.

Cheers,
Chris",,criccomini,swapnilghike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-708,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,307081,,,Mon Jan 21 19:33:17 UTC 2013,,,,,,,,,,"0|i1a4hz:",267195,,,,,,,,,,,,,,,,,,,,"22/Jan/13 03:29;swapnilghike;Looks like a duplicate of KAFKA-708;;;","22/Jan/13 03:33;criccomini;Indeed, it does!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix LogCleanerIntegrationTest,KAFKA-2669,12905715,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,lindong,lindong,lindong,17/Oct/15 17:17,13/May/16 17:38,22/Mar/23 15:10,20/Oct/15 05:45,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"LogCleanerIntegrationTest calls LogCleaner.awaitCleaned() to wait until cleaner has processed up to given offset. However, existing awaitCleaned() implementation doesn't wait for this.",,githubbot,guozhang,lindong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1201,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Oct 19 21:45:42 UTC 2015,,,,,,,,,,"0|i2n5fb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"17/Oct/15 17:18;githubbot;GitHub user lindong28 opened a pull request:

    https://github.com/apache/kafka/pull/327

    KAFKA-2669; Fix LogCleanerIntegrationTest

    LogCleanerIntegrationTest calls LogCleaner.awaitCleaned() to wait until cleaner has processed up to given offset. However, existing awaitCleaned() implementation doesn't wait for this. This patch fix the problem.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/lindong28/kafka KAFKA-2669

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/327.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #327
    
----
commit 4e80bd95e906b0afb193d2870a351e86b7336a3b
Author: Dong Lin <lindong@cis.upenn.edu>
Date:   2015-10-17T09:17:34Z

    KAFKA-2669; Fix LogCleanerIntegrationTest

----
;;;","20/Oct/15 05:45;guozhang;Issue resolved by pull request 327
[https://github.com/apache/kafka/pull/327];;;","20/Oct/15 05:45;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/327
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable server to indefinitely retry on controlled shutdown,KAFKA-1235,12692642,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,guozhang,guozhang,01/Feb/14 11:24,28/Jan/15 14:20,22/Mar/23 15:10,28/Jan/15 14:20,,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"Today the kafka server can exit silently if it hits an exception that is swallowed during controlled shut down or ""controlled.shutdown.max.retries"" has been exhausted. It is better to add an option to let it retry indefinitely.

Also will fix some other loose-check bugs on socket-closing logic.",,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Feb/14 04:02;guozhang;KAFKA-1235.patch;https://issues.apache.org/jira/secure/attachment/12626728/KAFKA-1235.patch","21/Feb/14 03:28;guozhang;KAFKA-1235_2014-02-20_11:28:36.patch;https://issues.apache.org/jira/secure/attachment/12630127/KAFKA-1235_2014-02-20_11%3A28%3A36.patch","21/Feb/14 05:08;guozhang;KAFKA-1235_2014-02-20_13:08:23.patch;https://issues.apache.org/jira/secure/attachment/12630151/KAFKA-1235_2014-02-20_13%3A08%3A23.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,371237,,,Wed Jan 28 06:20:08 UTC 2015,,,,,,,,,,"0|i1rzb3:",371540,,,,,,,,,,,,,,,,,,,,"04/Feb/14 04:02;guozhang;Created reviewboard https://reviews.apache.org/r/17671/
 against branch origin/trunk;;;","20/Feb/14 07:57;guozhang;Updated reviewboard https://reviews.apache.org/r/17671/
against branch origin/trunk;;;","21/Feb/14 03:28;guozhang;Updated reviewboard https://reviews.apache.org/r/17671/
 against branch origin/trunk;;;","21/Feb/14 05:08;guozhang;Updated reviewboard https://reviews.apache.org/r/17671/
 against branch origin/trunk;;;","05/Sep/14 06:22;guozhang;Moving to 0.9.;;;","28/Jan/15 14:20;guozhang;The patch is actually already committed on Feb.20th, 2014. Closing it now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Disallow star imports,KAFKA-3009,12922914,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,manasvigupta,gwenshap,gwenshap,18/Dec/15 10:17,22/Dec/15 05:31,22/Mar/23 15:10,22/Dec/15 05:31,,,,,,,0.10.0.0,,,,,,,,,,,0,newbie,,,,,"Looks like we don't want star imports in our code (java.utils.*)
So, lets add this rule to checkstyle and fix existing violations.",,ewencp,githubbot,gwenshap,manasvigupta,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Dec/15 01:26;manasvigupta;main.xml;https://issues.apache.org/jira/secure/attachment/12778864/main.xml",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Dec 21 21:31:51 UTC 2015,,,,,,,,,,"0|i2q2l3:",9223372036854775807,,ewencp,,,,,,,,,,,,,,,,,,"20/Dec/15 18:06;githubbot;GitHub user manasvigupta opened a pull request:

    https://github.com/apache/kafka/pull/700

    KAFKA-3009 : Disallow star imports

    Summary of code changes
    ------------------------------------
    1) Added a new Checkstyle rule to flag any code using star imports
    2) Fixed ALL existing code violations using star imports
    
    Testing
    -----------
    Local build was successful
    ALL JUnits ran successfully on local.
    
    @ewencp - Request you to please review changes. Thank you !
    
    I state that the contribution is my original work and I license the work to the project under the project's open source license.
    


You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/manasvigupta/kafka KAFKA-3009

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/700.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #700
    
----
commit fbe5a941a2aefc6507ef4d2eb515f8279d93313b
Author: manasvigupta <manasvigupta@yahoo.co.in>
Date:   2015-12-20T09:40:30Z

    code changes to fix issue - KAFKA-3009

----
;;;","22/Dec/15 01:26;manasvigupta;Checkstyle errors on core module;;;","22/Dec/15 05:31;ewencp;Issue resolved by pull request 700
[https://github.com/apache/kafka/pull/700];;;","22/Dec/15 05:31;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/700
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka consumer delivers message whose offset is earlier than sought offset.,KAFKA-3179,12935470,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,becket_qin,becket_qin,01/Feb/16 07:24,05/Feb/16 16:18,22/Mar/23 15:10,05/Feb/16 08:09,0.9.0.0,,,,,,0.10.0.0,0.9.0.1,,,,,,clients,,,,0,,,,,,This problem is reproducible by seeking to the middle a compressed message set. Because KafkaConsumer does not filter out the messages earlier than the sought offset in the compressed message. The message returned to user will always be the first message in the compressed message set instead of the message user sought to.,,becket_qin,githubbot,ijuma,jjkoshy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Feb 05 08:18:43 UTC 2016,,,,,,,,,,"0|i2s7in:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"01/Feb/16 09:46;githubbot;GitHub user becketqin opened a pull request:

    https://github.com/apache/kafka/pull/842

    KAFKA-3179 Fix seek on compressed messages

    The fix itself is simple. 
    
    Some explanation on unit tests. Currently we the vast majority of unit test is running with uncompressed messages.  I was initially thinking about run all the tests using compressed messages. But it seems uncompressed messages are necessary in a many test cases because we need the bytes sent and appended to the log to be predictable. In most of other cases, it does not matter whether the message is compressed or not, and compression will slow down the unit test. So I just added one method in the BaseConsumerTest to send compressed messages whenever we need it. 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/becketqin/kafka KAFKA-3179

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/842.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #842
    
----
commit 0f5cd3184f63ba9ec93c4450f81e0222ae96b422
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2016-02-01T01:38:37Z

    KAFKA-3179 Fix seek on compressed messages

----
;;;","05/Feb/16 08:09;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/842
;;;","05/Feb/16 08:09;jjkoshy;Issue resolved by pull request 842
[https://github.com/apache/kafka/pull/842];;;","05/Feb/16 16:18;ijuma;Joel also committed it to 0.9.0:

https://github.com/apache/kafka/commit/c3f575d5f248cd60daada7037838d0c7c5be1277;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
String#getBytes is platform dependent,KAFKA-468,12603911,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Trivial,Fixed,,mumrah,mumrah,18/Aug/12 04:42,23/Nov/12 06:04,22/Mar/23 15:10,23/Nov/12 06:04,0.8.0,,,,,,0.8.0,,,,,,,core,,,,0,,,,,,"Just noticed while looking at the source that some calls to java.lang.String#getBytes do not include the encoding. They should probably specify ""UTF-8"" for platform-independence.
",,initialcontext,jkreps,mumrah,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-367,,,,,,,,,,,,,,,,"18/Aug/12 07:39;mumrah;KAFKA-468.diff;https://issues.apache.org/jira/secure/attachment/12541434/KAFKA-468.diff",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,248160,,,Thu Nov 22 22:04:14 UTC 2012,,,,,,,,,,"0|i09lwf:",53981,,,,,,,,,,,,,,,,,,,,"18/Aug/12 07:38;mumrah;Specifying ""UTF-8"" in StringEncoder/Decoder;;;","24/Aug/12 20:33;mumrah;Didn't see that one when I create this ticket.;;;","30/Aug/12 08:47;initialcontext;Hey David, if you're happy with your fix let me know and I can resolve mine (I was working on KAFKA-367.) The other end of mine is fact that in KAFKA-367 they want the UTF-8 to be configurable rather than set in stone, but I agree having some agreed-upon default is better than not setting one at all so your patch works for me if it works for you.

I am having trouble viewing your diff file, it comes up on Safari as a blank page URL -- could you check it?

Anyway let me know, and I can cancel KAFKA-367...or you're welcome to help complete it I think I was basically done and am just having a small problem with StringEncoder subclass. Will try to fix it tonight or tomorrow AM but not all that sure I will succeed as I am new to Scala.

Thanks again!
;;;","30/Aug/12 23:43;jkreps;I think it does make sense to make the encoding configurable.;;;","23/Nov/12 06:04;jkreps;I integrated the changes in KAFKA-367 into the patch for KAFKA-544, which has been committed on the 0.8 branch. I wonder if anyone would be willing to take a look at the change and validate I didn't muck anything up?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
 testDuplicateListeners()  has a typo,KAFKA-2104,12819154,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,gwenshap,gwenshap,gwenshap,08/Apr/15 09:49,09/Apr/15 04:29,22/Mar/23 15:10,09/Apr/15 04:29,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"[~onurkaraman] caught a problem introduced in KAFKA-1809:

In testDuplicateListeners() from KafkaConfigTest, your property key has a typo(the comma should be a dot):
{code}
props.put(""advertised,listeners"", ""PLAINTEXT://localhost:9091,TRACE://localhost:9091"")
{code}
should be:
{code}
props.put(""advertised.listeners"", ""PLAINTEXT://localhost:9091,TRACE://localhost:9091"")
{code}

",,gwenshap,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Apr/15 09:54;gwenshap;KAFKA-2104.patch;https://issues.apache.org/jira/secure/attachment/12723811/KAFKA-2104.patch","09/Apr/15 03:08;gwenshap;KAFKA-2104_2015-04-08_12:08:40.patch;https://issues.apache.org/jira/secure/attachment/12723989/KAFKA-2104_2015-04-08_12%3A08%3A40.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Apr 08 20:29:07 UTC 2015,,,,,,,,,,"0|i2cy1r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"08/Apr/15 09:54;gwenshap;Created reviewboard https://reviews.apache.org/r/32953/diff/
 against branch trunk;;;","09/Apr/15 03:08;gwenshap;Updated reviewboard https://reviews.apache.org/r/32953/diff/
 against branch trunk;;;","09/Apr/15 04:29;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Message loss if mirror maker is killed with hard kill and then restarted,KAFKA-2747,12910572,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,granders,granders,05/Nov/15 09:59,13/Nov/15 05:49,22/Mar/23 15:10,13/Nov/15 05:49,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"I recently added simple failover to the existing mirror maker test (https://github.com/apache/kafka/pull/427) and found that killing mirror maker process with a hard kill resulted in message loss.

The test here has two single-node broker clusters, one producer producing to the source cluster, one consumer consuming from the target cluster, and a single mirror maker instance mirroring data between the two clusters.

mirror maker is using old consumer, zookeeper for offset storage",,becket_qin,granders,guozhang,hachikuji,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2770,,,,,,,,,,"09/Nov/15 08:34;granders;2015-11-08--004-dataloss-newconsumer.tar.gz;https://issues.apache.org/jira/secure/attachment/12771253/2015-11-08--004-dataloss-newconsumer.tar.gz",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 12 21:48:58 UTC 2015,,,,,,,,,,"0|i2nz7z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"05/Nov/15 11:01;becket_qin;[~geoffra], could you verify the following two things?
1. Is the group id of consumer the same after mirror maker restarts?
2. Is the committed offset out of range after mirror maker restarts?

Both are caused by the fact that we are setting the auto.offset.reset to largest.;;;","07/Nov/15 05:48;granders;[~becket_qin] The group id is the same, but the committed offset was out of range after mirror maker restarted due to the fact that no messages had been committed yet.

[~ewencp] opened https://issues.apache.org/jira/browse/KAFKA-2759 to track whether this is desirable behavior.;;;","09/Nov/15 08:32;granders;Although ensuring committed offsets solved the problem with old consumer, this once again fails when using new consumer.;;;","09/Nov/15 08:34;granders;Attachment contains reports and logs from a failed mirrormaker (with new consumer) hard bounce test 

worker1 - source zookeeper
worker3 - source kafka cluster

worker2 - target zookeeper
worker4 - target kafka cluster;;;","10/Nov/15 02:38;becket_qin;[~geoffra] Not sure how this happens. I dumped the log segments from source and target cluster, found the following messages are missing:
offset 34291 (target) ----> offset 34079 (source)
offset 34292 (target) ----> offset 57421 (source)
{noformat}
From mirror maker log it does not seems have any problem.
[2015-11-09 00:18:43,870] INFO Starting mirror maker (kafka.tools.MirrorMaker$)
....
[2015-11-09 00:19:17,744] DEBUG Committed offset 28549 for partition topic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
..... (hard kill)
[2015-11-09 00:19:23,772] INFO Starting mirror maker (kafka.tools.MirrorMaker$)
....
[2015-11-09 00:19:17,744] DEBUG Committed offset 28549 for partition topic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
...
[2015-11-09 00:19:49,099] DEBUG Committed offset 57421 for partition topic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
... (hard kill)
[2015-11-09 00:19:55,351] INFO Starting mirror maker (kafka.tools.MirrorMaker$)
....
[2015-11-09 00:20:16,608] DEBUG Resetting offset for partition topic-0 to the committed offset 57421 (org.apache.kafka.clients.consumer.internals.Fetcher)
....
[2015-11-09 00:20:19,076] DEBUG Committed offset 87423 for partition topic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
....(Another hard kill)
[2015-11-09 00:20:26,268] INFO Starting mirror maker (kafka.tools.MirrorMaker$)
....
[2015-11-09 00:20:46,612] DEBUG Resetting offset for partition topic-0 to the committed offset 87423 (org.apache.kafka.clients.consumer.internals.Fetcher)
...
[2015-11-09 00:21:52,803] DEBUG Committed offset 120567 for partition topic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
...
[2015-11-09 00:21:52,829] INFO [mirrormaker-thread-0] Mirror maker thread shutdown complete (kafka.tools.MirrorMaker$MirrorMakerThread)
{noformat}

It looks mirror maker committed offset 57421 when the messages between 34079 and 57421 haven't been sent successfully. I am not sure how this happened because in mirror maker we always call producer.flush() before committing offsets. Can you turn on trace level logging on MirrorMaker and broker for further debugging?;;;","10/Nov/15 02:45;hachikuji;It would also be helpful to add some logging to o.a.k.clients.consumer.internals.Fetcher, in particular for each offset fetched by the client and each offset returned to the user.;;;","13/Nov/15 05:48;guozhang;This issue is resolved as part of KAFKA-2770.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Controller failover not working correctly.,KAFKA-1600,12735001,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,,dinghaifeng,dinghaifeng,19/Aug/14 18:29,05/Oct/14 09:13,22/Mar/23 15:10,05/Oct/14 09:13,0.8.1,,,,,,0.8.2.0,,,,,,,controller,,,,0,,,,,,"We are running a 10 node Kafka 0.8.1 cluster and experienced a failure as following. 
At some time, broker A stopped acting as controller any more. We see this by kafka.controller - KafkaController - ActiveControllerCount in JMX metrics jumped from 1 to 0.
In the meanwhile, broker A was still running and registering itself in the zookeeper /kafka/controller node. So no other brokers could be elected as new controller.
Since that the cluster was running without controller. Producers and consumers still worked. But functions requiring a controller such as new topic leader election and topic leader failover were not working any more.
A force restart of broker A could lead to a controller election and bring the cluster back to a correct state.
Here is our brief observations. I can provide more necessary informations if needed.

","Linux 3.2.0-4-amd64 #1 SMP Debian 3.2.46-1 x86_64 GNU/Linux
java version ""1.7.0_03""",bcalmac,dinghaifeng,guozhang,nehanarkhede,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1663,,,,,,,,,,,,,,,,"20/Aug/14 15:45;dinghaifeng;kafka_failure_logs.tar.gz;https://issues.apache.org/jira/secure/attachment/12663071/kafka_failure_logs.tar.gz",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,412941,,,Sun Oct 05 01:13:43 UTC 2014,,,,,,,,,,"0|i1z1av:",412927,,nehanarkhede,,,,,,,,,,,,,,,,,,"20/Aug/14 00:29;guozhang;Hello Haifeng,

Could you upload the broker and controller log of broker A here?;;;","20/Aug/14 02:08;nehanarkhede;[~dinghaifeng], thanks for reporting the issue. It will help to have controller.log, server.log from *all* brokers. You can attach these logs to this JIRA.;;;","20/Aug/14 15:45;dinghaifeng;Guozhang and Neha, Thanks for reply.

In the attachment are controller.log and server.log from 2 of total 10 brokers. broker.id=6 is the misbehaving controller broker.

controller.log from other brokers are empty at that time. It also proves that controller failover didn't happen. server.log from other brokers are much the same with these broker and not attached.

Some critical moments I found which could help understanding the logs:
14:30:50 - a new topic ""user_action_log_from_history"" created.
16:04:51 - topic ""user_action_log_from_history"" deleted.
16:04:56 - the last line in controller.log from broker 6. The ActiveControllerCount metric also decreased to 0 since then.
16:28:48 - another broker (broker.id=1) restarted manually but failed to start. Some topic partitions on broker 1 lost their leader and were not readable and writeable since then.

What happens later:
We didn’t fully get what was wrong at that time. To bring the production system back to work ASAP, we created another Kafka cluster and switched to the new cluster. In the post-mortem analysis, we found the clues above and open this issue here. Hope it can helps. Also contact me if you need any other information.
;;;","23/Aug/14 02:38;guozhang;Haifeng,

I looked into the controller and broker logs, but cannot figure out exactly what was the issue from the logs themselves. However, there are known issues with delete topic tools that may be causing the controller to fall in a bad state (KAFKA-1558), and your issue may be related to it.;;;","15/Sep/14 11:50;nehanarkhede;Marking this as a blocker for 0.8.2 since it is related to delete topic;;;","03/Oct/14 13:21;sriharsha;[~nehanarkhede] [~guozhang] I looked at the logs this is same issue as KAFKA-1663;;;","05/Oct/14 09:13;nehanarkhede;Duplicate JIRA KAFKA-1600 is now resolved.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ReplicaManagerTest hard-codes log dir,KAFKA-1364,12707003,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,junrao,junrao,08/Apr/14 02:47,10/Apr/14 05:50,22/Mar/23 15:10,10/Apr/14 05:50,,,,,,,0.8.2.0,,,,,,,core,,,,1,,,,,,"Saw the following unit test failure. This is probably due to that the hard-coded log.dir conflicts with the default config when running a standalone sack.

kafka.server.ReplicaManagerTest > testHighwaterMarkDirectoryMapping FAILED
    java.lang.IllegalArgumentException: requirement failed: Corrupt index found, index file (/tmp/kafka-logs/test-topic-1/00000000000000000000.index) has non-zero size but the last offset is 0 and the base offset is 0
        at scala.Predef$.require(Predef.scala:145)
        at kafka.log.OffsetIndex.sanityCheck(OffsetIndex.scala:352)
        at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:159)
        at kafka.log.Log$$anonfun$loadSegments$5.apply(Log.scala:158)
        at scala.collection.Iterator$class.foreach(Iterator.scala:631)
        at scala.collection.JavaConversions$JIteratorWrapper.foreach(JavaConversions.scala:474)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
        at scala.collection.JavaConversions$JCollectionWrapper.foreach(JavaConversions.scala:495)
        at kafka.log.Log.loadSegments(Log.scala:158)
        at kafka.log.Log.<init>(Log.scala:64)
        at kafka.server.ReplicaManagerTest.testHighwaterMarkDirectoryMapping(ReplicaManagerTest.scala:43)
",,adenysenko,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Apr/14 04:56;guozhang;KAFKA-1364.patch;https://issues.apache.org/jira/secure/attachment/12639262/KAFKA-1364.patch","10/Apr/14 01:24;guozhang;KAFKA-1364_2014-04-09_10:24:24.patch;https://issues.apache.org/jira/secure/attachment/12639436/KAFKA-1364_2014-04-09_10%3A24%3A24.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,385326,,,Wed Apr 09 21:50:23 UTC 2014,,,,,,,,,,"0|i1udr3:",385593,,,,,,,,,,,,,,,,,,,,"09/Apr/14 04:56;guozhang;Created reviewboard https://reviews.apache.org/r/20128/
 against branch origin/trunk;;;","10/Apr/14 01:24;guozhang;Updated reviewboard https://reviews.apache.org/r/20128/
 against branch origin/trunk;;;","10/Apr/14 05:50;junrao;Thanks for the patch. +1 Committed to trunk. I don't think this needs to be in 0.8.1.1 since it's not a blocker.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka.perf.ConsumerPerformance not shutting down consumer,KAFKA-1005,12662770,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,pmackles,pmackles,pmackles,09/Aug/13 10:34,05/Apr/15 23:45,22/Mar/23 15:10,05/Apr/15 10:38,,,,,,,,,,,,,,tools,,,,0,,,,,,"I have been using the consumer-perf and producer-perf scripts to try out different failure scenarios with 0.8. In one such test I had consumer-perf reading from a topic that was no longer being written to. While consumer-perf finished normally, I noticed that ConsumerOffsetChecker reported lags >0 for several partitions on my topic. I believe this is due to kafka.perf.ConsumerPerformance not calling shutdown on the consumer after all of the threads have completed. After adding the shutdown call, I was able to verify that lag=0 for all partitions on my test topic after consumer-perf finished normally.

This is pretty minor but since I am guessing the perf tools are used pretty heavily by newbies like myself, might as well make them right.

Patch attached.",,jkreps,pmackles,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Aug/13 10:36;pmackles;ConsumerPerformance.scala.patch;https://issues.apache.org/jira/secure/attachment/12597015/ConsumerPerformance.scala.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,342772,,,Sun Apr 05 02:38:36 UTC 2015,,,,,,,,,,"0|i1n43b:",343076,,,,,,,,,,,,,,,,,,,,"05/Apr/15 10:38;jkreps;Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unit tests hard code ports,KAFKA-98,12518808,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,jkreps,jkreps,jkreps,14/Aug/11 13:36,16/Aug/11 01:34,22/Mar/23 15:10,16/Aug/11 01:34,,,,,,,,,,,,,,,,,,0,,,,,,This doesn't work on a test server or on your own box if you have kafka running. Patch removes this.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Aug/11 13:37;jkreps;kafka-fix-hardcoded-ports.diff;https://issues.apache.org/jira/secure/attachment/12490372/kafka-fix-hardcoded-ports.diff",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,64994,,,Mon Aug 15 17:34:35 UTC 2011,,,,,,,,,,"0|i15yx3:",242957,,,,,,,,,,,,,,,,,,,,"14/Aug/11 13:37;jkreps;Also check out the awesome assertion I fixed:

assert(x - x < 300)

We had better hope that is true or we have bigger problems.;;;","16/Aug/11 01:02;junrao;+1. The patch looks good to me.;;;","16/Aug/11 01:34;jkreps;Applied.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Dynamically loaded classes (encoders, etc.) may not be found by Kafka Producer ",KAFKA-2295,12839790,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,omkreddy,tdas,tdas,23/Jun/15 16:53,16/Mar/16 22:55,22/Mar/23 15:10,16/Oct/15 02:07,,,,,,,0.9.0.0,,,,,,,producer ,,,,0,,,,,,"Kafka Producer (via CoreUtils.createObject) effectively uses Class.forName to load encoder classes. Class.forName is by design finds classes only in the defining classloader of the enclosing class (which is often the bootstrap class loader). It does not use the current thread context class loader. This can lead to problems in environments where classes are dynamically loaded and therefore may not be present in the bootstrap classloader.

This leads to ClassNotFound Exceptions in environments like Spark where classes are loaded dynamically using custom classloaders. Issues like this have reported. E.g. - 
https://www.mail-archive.com/user@spark.apache.org/msg30951.html

Other references regarding this issue with Class.forName 
http://stackoverflow.com/questions/21749741/though-my-class-was-loaded-class-forname-throws-classnotfoundexception

This is a problem we have faced repeatedly in Apache Spark and we solved it by explicitly specifying the class loader to use. See 
https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/util/Utils.scala#L178


",,githubbot,guozhang,jamesnetherton,joconnor,omkreddy,tdas,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3218,,,,,,,,,,"26/Jun/15 00:24;omkreddy;KAFKA-2295.patch;https://issues.apache.org/jira/secure/attachment/12741888/KAFKA-2295.patch","06/Jul/15 14:05;omkreddy;KAFKA-2295_2015-07-06_11:32:58.patch;https://issues.apache.org/jira/secure/attachment/12743670/KAFKA-2295_2015-07-06_11%3A32%3A58.patch","20/Aug/15 20:18;omkreddy;KAFKA-2295_2015-08-20_17:44:56.patch;https://issues.apache.org/jira/secure/attachment/12751475/KAFKA-2295_2015-08-20_17%3A44%3A56.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Feb 17 11:01:09 UTC 2016,,,,,,,,,,"0|i2gdkv:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"26/Jun/15 00:24;omkreddy;Created reviewboard https://reviews.apache.org/r/35880/diff/
 against branch origin/trunk;;;","06/Jul/15 14:05;omkreddy;Updated reviewboard https://reviews.apache.org/r/35880/diff/
 against branch origin/trunk;;;","11/Jul/15 02:35;guozhang;[~tdas] The latest patch from [~omkreddy] looks good to me, do you want to apply it and see if it resolves your Spark usecase?

Guozhang;;;","20/Aug/15 20:18;omkreddy;Updated reviewboard https://reviews.apache.org/r/35880/diff/
 against branch origin/trunk;;;","20/Aug/15 20:20;omkreddy;[~guozhang]  Can we go ahead and commit this minor patch?;;;","30/Sep/15 23:07;jamesnetherton;Any news on this?

This issue looks critical.;;;","13/Oct/15 04:36;guozhang;Pinging [~tdas] once again for validation, or if someone else and verify the issue was reproducible and now fixed with the patch, we can go ahead and check it in.;;;","15/Oct/15 07:39;guozhang;[~omkreddy] Could you rebase the patch again, and probably using PR for the rebased patch?;;;","15/Oct/15 18:10;githubbot;GitHub user omkreddy opened a pull request:

    https://github.com/apache/kafka/pull/314

    KAFKA-2295; Support given for dynamically loaded classes (encoders, e…

    Rebased code..

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/omkreddy/kafka KAFKA-2295

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/314.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #314
    
----
commit dafc210c2501ac7fc91ba63e744d9939fbeb64c5
Author: Manikumar reddy O <manikumar.reddy@gmail.com>
Date:   2015-10-15T10:06:40Z

    KAFKA-2295; Support given for dynamically loaded classes (encoders, etc.)

----
;;;","16/Oct/15 02:07;guozhang;Issue resolved by pull request 314
[https://github.com/apache/kafka/pull/314];;;","16/Oct/15 02:07;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/314
;;;","08/Feb/16 19:12;joconnor;This change appears to have caused  KAFKA-3218, ClassNotFoundException when using kafka-clients as an OSGi  module;;;","17/Feb/16 19:01;guozhang;Thanks for reporting [~joconnor]. Could you try to verify if the patch provided in KAFKA-3218 fixes the issue?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Expose version via JMX for 'new' producer ,KAFKA-1877,12768384,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,omkreddy,vladimir.tretyakov,vladimir.tretyakov,19/Jan/15 16:42,22/Aug/15 04:02,22/Mar/23 15:10,21/Aug/15 15:39,0.8.2.0,,,,,,0.9.0.0,,,,,,,clients,producer ,,,0,,,,,,"Add version of Kafka to jmx (monitoring tool can use this info).
Something like that
{code}
kafka.common:type=AppInfo,name=Version
      Value java.lang.Object = 0.8.2-beta
{code}
we already have this in ""core"" Kafka module (see kafka.common.AppInfo object).
",,gwenshap,jkreps,omkreddy,rkellogg,vladimir.tretyakov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Aug 21 20:02:32 UTC 2015,,,,,,,,,,"0|i24iin:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"08/Feb/15 19:08;omkreddy;[~jkreps] [~junrao]  Currently Kafka metrics can return only double value (Metric.java). 
How to handle future metrics which can return other data types (int, long, string).?
We may need to introduce generic types to metrics.  This will be a sizable change and will change some public APIs.

I encountered this, while I was trying to include version info to producer metrics. ;;;","27/Feb/15 23:11;rkellogg;Please be aware that exposure of version information can sometimes cause security certification problems.  Individuals use this information to target security holes.  So as a consequence, there should be a way to disable this information.;;;","01/Mar/15 03:31;jkreps;The metrics are just for metrics which are by nature numeric, right?

I don't think that package is the best way to expose generic JMX information. I would just use normal Java JMX support for that. That works, right?;;;","02/Mar/15 23:36;omkreddy;Yes, version info can be exposed as JMX info.   If some one want to programmatically retrieve the version  info,  how to retrieve?;;;","21/Aug/15 15:39;omkreddy;This got fixed part of KAFKA-1901
 
{code}
Server AppInfo MBean: kafka.server:type=app-info,id=([0-9]+)
Producer AppInfo MBean: kafka.producer:type=app-info,id=([-.\w]+)
Consumer AppInfo MBean: kafka.consumer=app-info,id=([-.\w]+)

MBean Attributes: 
CommitId : gives the build time commit hash 
Version : gives the version of the running kafka 
{code};;;","22/Aug/15 04:02;gwenshap;Thanks for updating the status.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsoleProducer compresses messages and ignores the --compress flag,KAFKA-634,12617847,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,anentropic,anentropic,28/Nov/12 02:11,09/Jan/13 20:19,22/Mar/23 15:10,09/Jan/13 20:19,0.7,,,,,,0.8.0,,,,,,,core,,,,0,console,producer,,,,"I am using the kafka-producer-shell.sh script without the --compress option

however my messages seem to be gzipped

the docs say compression is off by default:
http://incubator.apache.org/kafka/configuration.html

The only producer.properties file I can find is at:
/home/ubuntu/kafka-0.7.2-incubating-src/config/producer.properties

In there is:
compression.codec=0

My process looks like:

root      1748  1746  0 Nov19 ?        00:02:37 java -Xmx512M -server -Dlog4j.configuration=file:/usr/local/bin/kafka/../config/log4j.properties -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -cp :/usr/local/bin/kafka/../project/boot/scala-2.8.0/lib/scala-compiler.jar:/usr/local/bin/kafka/../project/boot/scala-2.8.0/lib/scala-library.jar:/usr/local/bin/kafka/../core/target/scala_2.8.0/kafka-0.7.2.jar:/usr/local/bin/kafka/../core/lib/*.jar:/usr/local/bin/kafka/../perf/target/scala_2.8.0/kafka-perf-0.7.2.jar:/usr/local/bin/kafka/../core/lib_managed/scala_2.8.0/compile/jopt-simple-3.2.jar:/usr/local/bin/kafka/../core/lib_managed/scala_2.8.0/compile/log4j-1.2.15.jar:/usr/local/bin/kafka/../core/lib_managed/scala_2.8.0/compile/snappy-java-1.0.4.1.jar:/usr/local/bin/kafka/../core/lib_managed/scala_2.8.0/compile/zkclient-0.1.jar:/usr/local/bin/kafka/../core/lib_managed/scala_2.8.0/compile/zookeeper-3.3.4.jar kafka.producer.ConsoleProducer --topic logtail --zookeeper x.x.x.x:2181

But the messages come out gobbledegook unless I use a client that understands compressed messages, and in that client it identifies the bit as set to 1, gzip compression.


Jun Rao junrao@gmail.com via incubator.apache.org 
Nov 26 (1 day ago)
to kafka-users 

This seems to be a bug in ConsoleProducer. It also compresses messages and
ignores the --compress flag. Could you file a jira?

Thanks,
Jun",,anentropic,brugidou,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-506,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,292413,,,Wed Jan 09 12:18:34 UTC 2013,,,,,,,,,,"0|i0ry6n:",161182,,,,,,,,,,,,,,,,,,,,"09/Jan/13 20:18;brugidou;KAFKA-506 fixed this (commit f64fd3dcbaace1dba7bbd72398bb3e7d28b41d61 in the 0.8 branch)

This will be fixed in 0.8 I guess;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor KafkaScheduler,KAFKA-597,12614258,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,jkreps,jkreps,jkreps,01/Nov/12 02:46,11/Dec/12 03:31,22/Mar/23 15:10,11/Dec/12 03:31,0.8.1,,,,,,,,,,,,,,,,,0,,,,,,"It would be nice to cleanup KafkaScheduler. Here is what I am thinking

Extract the following interface:

trait Scheduler {
  def startup()
  def schedule(fun: () => Unit, name: String, delayMs: Long = 0, periodMs: Long): Scheduled
  def shutdown(interrupt: Boolean = false)
}

class Scheduled {
  def lastExecution: Long
  def cancel()
}

We would have two implementations, KafkaScheduler and  MockScheduler. KafkaScheduler would be a wrapper for ScheduledThreadPoolExecutor. MockScheduler would only allow manual time advancement rather than using the system clock, we would switch unit tests over to this.

This change would be different from the existing scheduler in a the following ways:
1. Would not return a ScheduledFuture (since this is useless)
2. shutdown() would be a blocking call. The current shutdown calls, don't really do what people want.
3. We would remove the daemon thread flag, as I don't think it works.
4. It returns an object which let's you cancel the job or get the last execution time.

",,jjkoshy,jkreps,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Dec/12 13:33;jkreps;KAFKA-597-v1.patch;https://issues.apache.org/jira/secure/attachment/12555896/KAFKA-597-v1.patch","05/Dec/12 02:10;jkreps;KAFKA-597-v2.patch;https://issues.apache.org/jira/secure/attachment/12555960/KAFKA-597-v2.patch","06/Dec/12 08:43;jkreps;KAFKA-597-v3.patch;https://issues.apache.org/jira/secure/attachment/12556189/KAFKA-597-v3.patch","08/Dec/12 07:12;jkreps;KAFKA-597-v4.patch;https://issues.apache.org/jira/secure/attachment/12559975/KAFKA-597-v4.patch","08/Dec/12 12:02;jkreps;KAFKA-597-v5.patch;https://issues.apache.org/jira/secure/attachment/12560016/KAFKA-597-v5.patch","11/Dec/12 03:11;jkreps;KAFKA-597-v6.patch;https://issues.apache.org/jira/secure/attachment/12560239/KAFKA-597-v6.patch",,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,253491,,,Mon Dec 10 19:22:51 UTC 2012,,,,,,,,,,"0|i0dnun:",77793,,,,,,,,,,,,,,,,,,,,"04/Dec/12 13:33;jkreps;This patch refactors the scheduler as described above except that I didn't implement task cancelation.

It also converts LogManagerTest to use the new MockScheduler.;;;","05/Dec/12 02:10;jkreps;Updated patch, includes misc additional cleanups.;;;","06/Dec/12 08:43;jkreps;Attached v3 patch, same as before but fully rebased to trunk.;;;","06/Dec/12 13:33;jkreps;Ready for review.;;;","08/Dec/12 07:12;jkreps;Patch v4. 
- Rebased
- Makes use of thread factory
- Fixed broken scaladoc;;;","08/Dec/12 09:35;jjkoshy;I haven't fully reviewed, but a couple of initial comments:
- I think the javadoc on KafkaScheduler's daemon param is a bit misleading as it currently suggests that daemon=true would prevent the VM from shutting down.
- The patch inverts the daemon flag on some of the existing usages of KafkaScheduler - i.e., daemon now defaults to true and there are some places where daemon was false. We would need to survey these usages and identify whether it makes sense to keep them non-daemon or not.
- The other question is on shutdownNow: the previous scheduler allowed the relaxed shutdown - i.e., don't interrupt threads that are currently executing. This change forces all shutdowns to use shutdownNow. Question is whether there are existing tasks that need to complete that would not tolerate an interrupt. I'm not sure about that - we'll need to look at existing usages. E.g., KafkaServer's kafkaScheduler used the shutdown() method - now it's effectively shutdownNow.
;;;","08/Dec/12 12:02;jkreps;Thanks, new patch v5 addresses your comments:
- Improved javadoc
- This is actually good. I thought about it a bit and since I am making shutdown block the only time daemon vs non-daemon comes into play is if you don't call shutdown. If that is the case non-daemon threads will prevent garbage collection of the scheduler tasks and eventually block shutdown of the jvm, which seems unnecessary.
- The change to shutdownNow is not good. This will invoke interrupt on all threads, which is too aggressive. Better to let them finish. If we end up needing to schedule long-running tasks we can invent a new notification mechanism. I changed this so that we use normal shutdown instead.;;;","08/Dec/12 14:55;jjkoshy;On daemon vs non-daemon and shutdown vs shutdownNow. I may be misunderstanding the javadoc but I think: since the
default is now daemon=true and you switched to use shutdown, VM shutdown can continue even in the middle of a
scheduled task like checkpointing high watermarks or cleaning up logs. i.e., there may be such scenarios where it makes
sense to make them non-daemon - i.e., set it as a non-daemon, and use shutdown (not shutdownNow - or use
shutdownNow and handle InterruptedException properly in the task) to let them finish gracefully. Otherwise (iiuc)
it seems if we call shutdown on the executor the VM could exit and simply kill (i.e., abruptly terminate) any running
task that was started by the executor in one of the (daemon) threads from its pool.

Minor comments:
- Line 81 of KafkaScheduler: closing brace is mis-aligned.
- The scaladoc on MockScheduler uses a non-existent schedule variant - i.e., I think you intended to add a period < 0
  no?
;;;","08/Dec/12 23:35;jkreps;Nice catch on the brace, will fix before check in.

With respect to the scaladoc, that is a legitimate call, I think. The api take default values so all of the following should work:
  scheduler.schedule(""task"", println(""hello"")) // immediately kick of a one-time background task
  scheduler.schedule(""task"", println(""hello""), delay=50) // kick off a one-time task in 50ms
  scheduler.schedule(""task"", println(""hello""), period = 50) // immediately kick off a repeating task that will repeat every 50 ms
  etc

WRT daemon, you are correct, but I don't think this is necessarily a bad thing. The requirement of the api is that you call startup() before calling schedule() and call shutdown() when done. Shutdown was previously a non-blocking call so it was very important whether the threads were blocking or non-blocking (but this functionality was totally *broken*) because you would likely call shutdown() and then exit the JVM. Now the only possible way to get to JVM shutdown with remaining scheduler threads is if your program has a bug and fails to call shutdown(). What should we do in this case? Hard to say. All tasks must handle unclean shutdown because unclean shutdown is a lot like a crash. Blocking JVM shutdown can really mess up automated deployment, so defaulting to that is not necessarily wise. So I am fine with either default but at least the consumer scheduler really needs to be set to daemon so we don't block people's jvms.;;;","11/Dec/12 03:11;jkreps;Attached patch v6, which fixes Joel's comments--
- Formatting issue
- Scaladoc issue
- Changed shutdownNow to shutdown
- But leaves daemon as the defualt;;;","11/Dec/12 03:22;jjkoshy;+1 - thanks for the patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Broker topic metadata not kept in sync with ZooKeeper,KAFKA-1367,12707041,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,singhashish,rberdeen,rberdeen,08/Apr/14 06:23,05/Aug/15 13:50,22/Mar/23 15:10,08/Jul/15 00:49,0.8.0,0.8.1,,,,,0.9.0.0,,,,,,,,,,,5,newbie++,,,,,"When a broker is restarted, the topic metadata responses from the brokers will be incorrect (different from ZooKeeper) until a preferred replica leader election.

In the metadata, it looks like leaders are correctly removed from the ISR when a broker disappears, but followers are not. Then, when a broker reappears, the ISR is never updated.


I used a variation of the Vagrant setup created by Joe Stein to reproduce this with latest from the 0.8.1 branch: https://github.com/also/kafka/commit/dba36a503a5e22ea039df0f9852560b4fb1e067c",,aauradkar,abiletskyi,aozeritsky,ataraxer,becket_qin,christian.h.mikkelsen@gmail.com,daisuke.kobayashi,fsaintjacques,fullung,guozhang,gwenshap,jeffwidman,jjkoshy,jkreps,jonbringhurst,junrao,mazhar.shaikh.in,nehanarkhede,ottomata,rberdeen,ScottReynolds,singhashish,Skandragon,smeder,sslavic,vanyatka,Wallrat2000,winbatch,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1557,,,,,,,,,,KAFKA-972,,,,,,,,"24/Jun/15 13:09;singhashish;KAFKA-1367.patch;https://issues.apache.org/jira/secure/attachment/12741448/KAFKA-1367.patch","08/Apr/14 06:26;rberdeen;KAFKA-1367.txt;https://issues.apache.org/jira/secure/attachment/12639080/KAFKA-1367.txt","02/Jul/15 08:23;singhashish;KAFKA-1367_2015-07-01_17:23:14.patch;https://issues.apache.org/jira/secure/attachment/12743187/KAFKA-1367_2015-07-01_17%3A23%3A14.patch","07/Jul/15 13:04;singhashish;KAFKA-1367_2015-07-06_22:04:06.patch;https://issues.apache.org/jira/secure/attachment/12743887/KAFKA-1367_2015-07-06_22%3A04%3A06.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,385364,,,Wed Aug 05 05:50:26 UTC 2015,,,,,,,,,,"0|i1udzj:",385631,,,,,,,,,,,,,,,,,,,,"08/Apr/14 06:26;rberdeen;JIRA ate my whitespace. See Attached for a description of the steps.;;;","20/Sep/14 02:06;ottomata;This happens to me as well.  See:  https://github.com/edenhill/librdkafka/issues/147
;;;","20/Sep/14 02:15;ottomata;I just updated the librdkafka issue, pasting it here as well:

I noticed that in my case, only 1 of the 4 brokers was ever missing in the ISRs reported by Kafka Brokers (via librdkafka). This JIRA indicated that a preferred-replica-election should fix the problem. I did this:

controlled-shutdown of offending broker 21. Then actual shutdown of broker 21. Once this was done, librdkafka metadata showed the correct ISRs, since this offending broker really was not in any ISRs. I then restarted broker 21 and let its replicas catch back up. Once it caught up, zookeeper reported that all ISRs were in sync. I then checked librdkafka's metadata, and broker 21 was not listed in any ISR. I then ran a preferred-replica-election. broker 21 was then promoted to leader of some partitions. librdkafka then only showed broker 21 being in the ISRs for which it was also the leader. Any partition that has a replica on broker 21 does not show up in the ISR unless broker 21 is the leader.

  $ kafkacat -L -b analytics1022.eqiad.wmnet  -t webrequest_upload
  Metadata for webrequest_upload (from broker -1: analytics1022.eqiad.wmnet:9092/bootstrap):
   4 brokers:
    broker 12 at analytics1012.eqiad.wmnet:9092
    broker 21 at analytics1021.eqiad.wmnet:9092
    broker 22 at analytics1022.eqiad.wmnet:9092
    broker 18 at analytics1018.eqiad.wmnet:9092
   1 topics:
    topic ""webrequest_upload"" with 12 partitions:
      partition 11, leader 12, replicas: 12,21,22, isrs: 12,22
      partition 5, leader 21, replicas: 21,22,12, isrs: 22,12,21
      partition 10, leader 22, replicas: 22,18,21, isrs: 18,22
      partition 7, leader 12, replicas: 12,18,21, isrs: 12,18
      partition 8, leader 18, replicas: 18,22,12, isrs: 12,18,22
      partition 3, leader 12, replicas: 12,22,18, isrs: 12,18,22
      partition 4, leader 18, replicas: 18,21,22, isrs: 18,22
      partition 1, leader 21, replicas: 21,18,22, isrs: 18,22,21
      partition 6, leader 22, replicas: 22,12,18, isrs: 12,18,22
      partition 2, leader 22, replicas: 22,21,12, isrs: 12,22
      partition 9, leader 21, replicas: 21,12,18, isrs: 12,18,21
      partition 0, leader 18, replicas: 18,12,21, isrs: 12,18



vs kafka-topic.sh --describe

  Topic:webrequest_upload	PartitionCount:12	ReplicationFactor:3	Configs:
  	Topic: webrequest_upload	Partition: 0	Leader: 18	Replicas: 18,12,21	Isr: 12,18,21
  	Topic: webrequest_upload	Partition: 1	Leader: 21	Replicas: 21,18,22	Isr: 18,22,21
  	Topic: webrequest_upload	Partition: 2	Leader: 22	Replicas: 22,21,12	Isr: 12,22,21
  	Topic: webrequest_upload	Partition: 3	Leader: 12	Replicas: 12,22,18	Isr: 12,18,22
  	Topic: webrequest_upload	Partition: 4	Leader: 18	Replicas: 18,21,22	Isr: 18,22,21
  	Topic: webrequest_upload	Partition: 5	Leader: 21	Replicas: 21,22,12	Isr: 22,12,21
  	Topic: webrequest_upload	Partition: 6	Leader: 22	Replicas: 22,12,18	Isr: 12,18,22
  	Topic: webrequest_upload	Partition: 7	Leader: 12	Replicas: 12,18,21	Isr: 12,18,21
  	Topic: webrequest_upload	Partition: 8	Leader: 18	Replicas: 18,22,12	Isr: 12,18,22
  	Topic: webrequest_upload	Partition: 9	Leader: 21	Replicas: 21,12,18	Isr: 12,18,21
  	Topic: webrequest_upload	Partition: 10	Leader: 22	Replicas: 22,18,21	Isr: 18,22,21
  	Topic: webrequest_upload	Partition: 11	Leader: 12	Replicas: 12,21,22	Isr: 12,22,21;;;","20/Sep/14 13:01;junrao;Yes, in the current implementation, ISR returned from metadata requests can be inconsistent with what's stored in ZK. This is because metadata is only propagated from the controller to the brokers when the controller changes the leader or the ISR. However, when a follower catches up, the leader (not the controller) adds it back to ISR and updates ZK. That info is not propagated to all brokers.

Currently, the ISR part in a metadata response is not really used by the clients. Do you have a usage for this?;;;","22/Sep/14 21:53;edenhill;Apart from supplying the ISR count and list in its metadata API, librdkafka also provides an `enforce.isr.cnt` configuration property that fails
produce requests locally before transmission if the currently known ISR count is smaller than the configured value.
This is a workaround for the broker not fully honoring `request.required.acks`, i.e., if `request.required.acks=3` and only one broker is available the produce request will not fail.
More info in the original issue here: https://github.com/edenhill/librdkafka/issues/91

Generally I would assume that information provided by the broker is correct, otherwise it should not be included at all since it can't be used (reliably).;;;","23/Sep/14 00:57;guozhang;Hello [~edenhill], I think your use case may be supported in a new feature that is currently developed: KAFKA-1555. Would you like to take a look at it and see if your case is really covered?;;;","23/Sep/14 08:28;winbatch;I'd also add that having the broker being able to serve up (accurate) metadata allows client applications to build custom dashboards, etc.  As I understand it, there is the idea to move away from zookeeper (or at least for somethings) within the kafka infrastructure - so having the broker be able to provide this would be good.;;;","23/Sep/14 14:48;jjkoshy;I definitely agree with [~edenhill] that if such a field exists in the response then the information populated in the field should be accurate (or we may as well not include the field) - so we should fix this.;;;","25/Sep/14 13:08;nehanarkhede;bq. I definitely agree with Magnus Edenhill that if such a field exists in the response then the information populated in the field should be accurate (or we may as well not include the field) - so we should fix this.

+1;;;","26/Sep/14 02:04;edenhill;[~guozhang] Yes, KAFKA-1555 looks like a good match.;;;","07/Oct/14 01:26;guozhang;Regarding the fix to this issue, we can either 1) remove the ISR field from the metadata response and hence enforce people to use the admin tool (with ZK dependency) for such usages, which would also require a protocol change between client / server; or 2) let the controller to also watch for ISR change and propagate that information to brokers, this will not introduce protocol change to clients but will likely add a lot of burden on controllers since ISR change is more frequent than leader migrations.

[~jjkoshy][~junrao] any other thoughts?;;;","07/Oct/14 03:02;guozhang;Just talked to Joel offline. I think since ISR (and also Leader) info in broker is just a cached snapshot and cannot be really used in a scenario like this (i.e. depending on the ISR list to determine if the ack received with -1 setting is reliable or not, since the ISR can shrink while the ack is sent back), we could remove the ISR cache from the brokers and also remove it from the metadata response, unless there is a clear use case of this information.;;;","07/Oct/14 03:20;nehanarkhede;The ISR cache on the broker was added only because we had to expose that information through the topic metadata response. I don't think we gave a lot of thought, back then, on why the ISR information is useful in the topic metadata response (especially since it's stale and effectively inaccurate). I am not entirely sure if having the controller be aware of all ISR changes is terrible even though it's true that the # of watches it has to add is proportional to the # of partitions in a cluster. But it's not worth doing that if we don't find a use for the ISR information in the topic metadata response. So I'd vote for removing ISR from topic metadata and also from the broker's metadata cache.;;;","07/Oct/14 04:57;edenhill;May I suggest not to change the protocol but to only send an empty ISR vector in the MetadataResponse?;;;","07/Feb/15 05:35;fsaintjacques;Instead of silently removing the field, could the controller force a cache refresh on a metadata request?;;;","05/Apr/15 05:37;jkreps;[~nehanarkhede] Does this problem still exist?;;;","10/Apr/15 03:24;Skandragon;There is another issue that no one seems to be discussing.  This ISR data is AFAIK the only way to know when a broker is ""Back in service""

Consider this scenario.  I have 5 brokers, and want to upgrade them.  I want to know when a broker has caught up so I can take down the next one in sequence to upgrade it.  How can I know this if the reported state of the world is different than what is actually in use by the brokers themselves?

This seems to be very much an operational issue.;;;","10/Apr/15 04:33;junrao;[~Skandragon], for the operational issue that you pointed out, there are jmx such as the underReplicatedCount that one can leverage.

That said, it's probably useful for an admin client to know the accurate ISR. As Guozhang has suggested, one approach is to register a watcher of the state path for each partition. We probably need to do a bit experiments to see how much overhead this adds. Another approach is to have the controller periodically read the latest ISR for each partition. This is probably a bit simpler to implement, but may not reflect ISR timely and may add unnecessary load to ZK.;;;","15/Apr/15 04:31;jonbringhurst;Hey [~jkreps], I can confirm that the metadata response is still out of sync with ZK in a recent trunk build (about a month old).

Btw, it's not much effort for me to simply look at ZK or JMX -- it was just confusing when I initially ran into this.;;;","27/Apr/15 05:10;nehanarkhede;[~jkreps] Yup, issue still exists and the solution I still recommend is to have the controller register watches and know the latest ISR for all partitions. This change isn't big if someone wants to take a stab. ;;;","27/Apr/15 09:23;singhashish;[~nehanarkhede] If no one has already started working on this I would like to take a stab at it.;;;","28/Apr/15 01:26;jjkoshy;I'm a bit wary of the watch approach. I believe at the last google hangout we decided against doing this (as part of the KIP-4 discussion). A number of people had dropped off at that point - I believe we were going with a broker-level metadata request that can return ISR information for partitions that it leads. [~abiletskyi] can you confirm? I didn't see it in the summary notes so I could be wrong.;;;","28/Apr/15 03:24;abiletskyi;[~jjkoshy] Yes, it appears that topic commands don't require ISR information so it was proposed to remove it at all from the TopicMetadataRequest. There was an idea to create some sort of BrokerMetadataRequest which will include correct topic metadata but since it's not related to KIP-4 directly it won't be a part of it. So everyone is welcome to create a separate KIP for it. Atleast to this conclusion we came last time.;;;","28/Apr/15 12:02;nehanarkhede;[~jjkoshy] That would work too but looks like [~abiletskyi] is suggesting that it is not included as part of KIP-4. Maybe we can have whoever picks this JIRA discuss this change as part of a separate KIP?;;;","09/May/15 08:05;singhashish;[~nehanarkhede]/ [~jjkoshy] I have put together [KIP-24|https://cwiki.apache.org/confluence/display/KAFKA/KIP-24+-+Remove+ISR+information+from+TopicMetadataRequest+and+add+broker+level+metadata+request]. I will need a bit more information on what we decided for BrokerMetadataRequest, before I can update ""Public Interfaces"" section of the KIP.

Is my understanding correct that below is the plan we agreed upon. Below excerpt is actually from the KIP.

{quote}
It is proposed to remove ISR information from the TopicMetadataRequest. However, a new request, BrokerMetadataRequest, is proposed to be added. The new request will include ISR information for all the partitions that the broker leads.
{quote};;;","29/May/15 06:24;singhashish;[~jjkoshy] pinging you for your confirmation on this.;;;","29/May/15 07:10;jjkoshy;Hi [~singhashish] - sorry I missed your pings. Yes that is the approach we are planning to take. i.e., remove ISR from TMR. As mentioned in KIP-4 the ISR will be removed in v1 of TMR.;;;","29/May/15 07:38;singhashish;Thanks [~jjkoshy]! I will update the KIP accordingly.;;;","29/May/15 07:56;junrao;There is actually a reasonable use case of ISR in KAFKA-2225. Basically, for economical reasons, we may want to let a consumer fetch from a replica in ISR that's in the same zone. In order to support that, it will be convenient to have TMR return the correct ISR for the consumer to choose.

Implementation wise, one way to address the concern with too many watchers is to do sth similar to changing topic configs. Basically, when the leader changes the isr, in addition to writing the new isr in the partition state in ZK, it also writes the change as a sequential node under a new isrChangeNotification path in ZK. The controller listens to child changes in the isrChangeNotification path. On child change, the controller reads the new isr and broadcasts it through an UpdateMetadataRequest to every broker.;;;","29/May/15 08:14;jjkoshy;Jun - that is a good point. That sounds like a good approach to address the concern with watcher counts. Another way is to just allow brokers to send an equivalent update metadata (or similar) request to the controller to notify it of an ISR change - or even allow leaders to broadcast update metadata requests for ISR changes. We currently don't allow this, but maybe we should consider a generic broker-broker communication component. Given the use-case that Theo raised on the list yesterday, it appears we may want to keep the ISR even in TMR v1. It may make sense to discuss this at an upcoming hangout especially since it affects KIP-4.;;;","29/May/15 08:42;junrao;It's probably better to always let the controller propagate metadata changes to the brokers. If the metadata change can be sent from both the controller and other brokers, we need additional logic to reason about ordering.

Having the broker send the change to the controller is possible. The implication is that there is another thread that can exercise the controller logic, instead of just the ZK watcher thread. So, we may need to deal with more concurrency issues.;;;","29/May/15 08:55;jjkoshy;One minor issue with depending on the TMR for KAKFA-2225 even if we fix this is that the consumer would need to periodically refresh its metadata in case the ISR changes after it starts reading from a follower in ISR.

Another approach for KAFKA-2225 is to add the ISR information to the fetch response. The followers will then have the current ISR information and so will the consumers. There are at least two concerns though: first, it depends on a live replica fetcher thread; second, it's a bit hacky to add ISR to fetch response as it is more associated with metadata.
;;;","29/May/15 09:08;junrao;Well, in that approach, you still have the problem on the very first fetch request. If ISR is not returned in TMR, the first fetch request has to go to the leader. Then the consumer has to switch to another broker on a subsequent request, which seems more complicated.

I am not sure if we need to rely on periodic metadata refresh to detect whether a replica is out of sync. Basically, as long as the fetch offset is less than HW, the replica can serve the request. If the fetch offset is larger than HW (an indication that the replica is out of sync), the consumer will get an OffsetOutOfRangeException and has to refresh the metadata and pick a new broker to fetch from.;;;","29/May/15 23:40;singhashish;[~junrao] can we add this to the agenda of next KIP hangout?;;;","30/May/15 01:11;junrao;Yes.;;;","03/Jun/15 01:02;jjkoshy;You may still want to switch back to a replica in the same (or nearer) availability zone right after it catches up and rejoins the ISR. Also, I'm not sure about the offset going out of range while fetching from a given replica. i.e., the fetcher will just fetch with an offset larger than the last fetched chunk. It may occur if you were switching between replicas though but that would only be if you were switching to a replica out of the ISR.;;;","03/Jun/15 01:46;junrao;[~joel koshy], yes, that's a good point. If we want to switch back to the closest replica for consumption, we do need to refresh the metadata periodically to check if the closest replica is back in ISR. We also need to handle OffsetOutOfRangeException a bit differently. If the consumer gets OffsetOutOfRangeException because the replica is out of sync, we want to switch to another in-sync replica instead of resetting the offset. One way to do that is the following protocol.

1. Get topic metadata.
2. Pick the ""closest"" in-sync replica to issue fetch requests.
3. On an OffsetOutOfRangeException, get the smallest/largest offset. If the fetch offset is within the range, go back to step 1 to switch to a different in-sync replica. Otherwise, go through the offset reset logic.
4. Periodically refresh the metadata. Switch to the ""closest"" in-sync replica for fetching, if needed.

;;;","03/Jun/15 05:36;guozhang;One note is that with the new consumer, one has to periodically refresh metadata anyways for wildcard subscriptions.;;;","04/Jun/15 00:13;jjkoshy;Follow-up from the KIP hangout. Side-note: this and most of the above comments are actually implementation details for KAFKA-2225. This is relevant here only because we are considering keeping vs. removing the ISR field.

I do think it is possible to implement KAFKA-2225 without ISR support either in metadata or the fetch response. The fetch response already contains HW. So the consumer can watch its fetch offset and the current HW (from the last fetch response). If the fetchOffset << HW but if the fetch response size is smaller than the requested bytes and the highest offset in the response is << HW then the consumer knows that the follower that it is fetching from is lagging behind (especially if this difference increases in successive fetches). The main caveat with this is that it depends on the replica having a live replica fetcher. The other issue is that the consumer needs to have its own definition of what it takes to deem a replica as out of sync (since the replica lag time config is server-side). The other observation is that ISR is a highly relevant and useful field in the topic metadata response. I would be in favor of keeping it in the TMR and just having the consumer refresh the topic metadata periodically to keep itself informed of ISR changes.;;;","09/Jun/15 01:31;aauradkar;[~jjkoshy] [~junrao] KAFKA-2225, even if we leave the ISR in the TopicMetadataRequest, how do the consumers detect which of the replicas in ISR to fetch from right? The consumers need to know which ""zone"" each of the brokers live in and their own in order to fetch from the closest replica (which mitigates with the bandwidth issues described in 2225).

Couple of options:
1. Return it in BrokerMetadataRequest (KIP-24)
2. Piggyback it along with the ISR field in TMR. i.e. isr : {0: ""zone1"", 1: ""zone2""}

If we choose to do (2), then the TMR will evolve anyway.;;;","09/Jun/15 02:05;junrao;Yes, we need some kind of notion of zones for both the brokers and the clients. Each broker and each client (producer/consumer) need a configuration for which zone it belongs to. It's probably simpler to just return the zone info in TMR. We will need to evolve TMR, but that can probably be done separately from fixing the ISR in TMR. We probably should move these design discussions to KAFKA-2225 itself.;;;","09/Jun/15 03:47;gwenshap;By ""zones"" do we mean rack-awareness? Or more general locality notion?
Sounds like something that may need its own JIRA and design.;;;","09/Jun/15 04:10;becket_qin;I agree with [~gwenshap], it sounds this deserves a KIP.;;;","09/Jun/15 07:27;junrao;Yes, perhaps some kind of more general locality could be useful. That can be done in a separate jira.

Here, we just want to figure out whether it's useful to maintain ISR in TMR.

[~jjkoshy], another issue without ISR is that initially a client will have no idea which replica is in sync and can only guess.;;;","11/Jun/15 08:45;singhashish;[~junrao] and [~jjkoshy], correct me if my understanding is wrong, but I think we agreed on keeping ISR info in TMR and below mentioned approach is our preference.

{quote}
When the leader changes the isr, in addition to writing the new isr in the partition state in ZK, it also writes the change as a sequential node under a new isrChangeNotification path in ZK. The controller listens to child changes in the isrChangeNotification path. On child change, the controller reads the new isr and broadcasts it through an UpdateMetadataRequest to every broker.
{quote}

Now that we want to keep ISR as part of TMR, do we still need a new BrokerMetadataRequest?;;;","12/Jun/15 03:57;jjkoshy;[~singhashish] - yes that is a good summary. BrokerMetadataRequest - probably yes, but that is now orthogonal.;;;","12/Jun/15 05:20;singhashish;[~jjkoshy] thanks for confirming. I will get started on the suggested solution for this issue. We will probably need a separate JIRA for KIP-24.;;;","24/Jun/15 13:09;singhashish;Created reviewboard https://reviews.apache.org/r/35820/
 against branch trunk;;;","24/Jun/15 13:15;singhashish;[~junrao], [~jjkoshy], [~nehanarkhede], [~gwenshap] just uploaded a patch to fix this. Apart from the changes suggested above, I just had to update controller's leader and isr cache before sending update metadata request. Tested it on a 3 node kafka cluster and the patch resolves the issue.;;;","02/Jul/15 08:23;singhashish;Updated reviewboard https://reviews.apache.org/r/35820/
 against branch trunk;;;","07/Jul/15 13:04;singhashish;Updated reviewboard https://reviews.apache.org/r/35820/
 against branch trunk;;;","08/Jul/15 00:49;junrao;Thanks for the latest patch. +1. Committed to trunk after fixing the last minor issue in the RB.;;;","05/Aug/15 06:26;junrao;[~singhashish], forgot to mention this earlier. Could you include the ZK structure change in https://cwiki.apache.org/confluence/display/KAFKA/Kafka+data+structures+in+Zookeeper ? Thanks,;;;","05/Aug/15 12:45;singhashish;[~junrao] done!;;;","05/Aug/15 13:31;becket_qin;[~ashishujjain] [~junrao] [~jjkoshy], I found some issue when trying to deploy the latest trunk with this patch. 

The problem is that during a rolling bounce in a cluster the ISR state propagation flooded the controller to broker traffic, the controlled shutdown of one broker takes about 1.5 hour to finish for a 30 node cluster.

Also, even during a clean cluster startup, there are more than 70,000 ISR change ephemeral path got created.

I feel we need to either find another way to propagate ISR change other than using zookeeper, or at very least we need to throttle the propagation rate to, say, once every 10 seconds.

I'm going to create another ticket to address the issue. Hopefully the fix should be quick. If the fix takes some time, do we consider reverting this patch and rework on it?;;;","05/Aug/15 13:44;singhashish;[~becket_qin] that is a valid concern. I guess what you are suggesting makes sense, controller should wait for a configurable time before sending out Update Metadata Request to brokers.;;;","05/Aug/15 13:50;becket_qin;Thanks for the quick response [~ashishujjain]. I created KAFKA-2406 and will submit a patch tonight. This has become a blocker for us now so I want to get it fixed ASAP. Thanks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
org.apache.kafka.common.utils.Utils.abs method returns wrong value for negative numbers.,KAFKA-1988,12778076,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,tongli,tongli,tongli,27/Feb/15 08:18,13/Mar/15 08:19,22/Mar/23 15:10,04/Mar/15 10:36,0.8.2.0,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"org.apache.kafka.common.utils.Utils.abs method returns wrong value for negative numbers. The method only returns intended value for positive numbers. All negative numbers except the Integer.Min_Value will be returned an unsigned integer.
",,ewencp,guozhang,junrao,noxis,tongli,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Feb/15 07:16;tongli;KAFKA-1988.patch;https://issues.apache.org/jira/secure/attachment/12701483/KAFKA-1988.patch","27/Feb/15 17:18;tongli;KAFKA-1988.patch;https://issues.apache.org/jira/secure/attachment/12701305/KAFKA-1988.patch","27/Feb/15 08:45;tongli;KAFKA-1988.patch;https://issues.apache.org/jira/secure/attachment/12701227/KAFKA-1988.patch","04/Mar/15 08:00;tongli;KAFKA-1988_2015-03-03_19:00:21.patch;https://issues.apache.org/jira/secure/attachment/12702309/KAFKA-1988_2015-03-03_19%3A00%3A21.patch","04/Mar/15 08:03;tongli;KAFKA-1988_2015-03-03_19:03:31.patch;https://issues.apache.org/jira/secure/attachment/12702310/KAFKA-1988_2015-03-03_19%3A03%3A31.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Mar 13 00:19:40 UTC 2015,,,,,,,,,,"0|i264jb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"27/Feb/15 08:45;tongli;Created reviewboard https://reviews.apache.org/r/31517/diff/
 against branch origin/trunk;;;","27/Feb/15 09:02;junrao;Thanks for the patch. +1.

We actually made the same mistake in the scala code before: KAFKA-1469.;;;","27/Feb/15 09:03;junrao;Since this affects how partitioning works in the new producer, we will have to fix this in 0.8.2.1. Marking this an an 0.8.2.1 blocker.;;;","27/Feb/15 13:42;junrao;Actually, we can probably keep the same logic in determining the partition from key in Partitioner. We  can move the current code in abs() into Partitioner, and give it a new name like toPositive(). Then we can replace Utils.abs() with toPositive() it in the following code in Partitioner.

            // hash the key to choose a partition
            return Utils.abs(Utils.murmur2(key)) % numPartitions;

This way, we will preserve the key distribution of existing users of the new producer.

Tong,

Do you want to submit a new patch based on that?

;;;","27/Feb/15 17:18;tongli;Created reviewboard https://reviews.apache.org/r/31533/diff/
 against branch origin/trunk;;;","27/Feb/15 17:20;tongli;Jun Rao,
	Thanks for taking time reviewing the patch. Would like to confirm here is what you suggested to do:

	1. Utils.abs will be renamed to Utils.toPositive
	2. Make changes in these methods of class DefaultPartitioner and ByteArrayPartitioner so that toPositive gets called in partition method.

		def partition(key: Any, numPartitions: Int): Int = {
    			Utils.abs(key.hashCode) % numPartitions
  		}


	I can certainly make the above changes.  however method abs gets used many other places and making the case worse is that there are two abs methods both in core and clients. I found this problem when I was in an effort of addressing issue 1926. For now, what if I keep that method in clients, remove the one in core Utils module and making changes to all other modules where abs method gets called so that all use of abs method will point to the clients Utils.abs instead of two locations?

The patch set reflects the above thoughts is here https://reviews.apache.org/r/31533/diff/;;;","28/Feb/15 03:26;junrao;Hi, Tong,

My suggestion is slightly different. My point is that If we change the behavior of o.a.k.c.u.Utils.abs(), it will impact the following code in o.a.k.c.p.i.Partitioner since a given key will now be mapped to a different partition.

            // hash the key to choose a partition
            return Utils.abs(Utils.murmur2(key)) % numPartitions;

To preserve the current behavior, I was suggesting that we define a local method in o.a.k.c.p.i.Partitioner that looks like the following.

    private static int toPositive(int n) {
        return n & 0x7fffffff;
    }

and change the partitioning code to

            // hash the key to choose a partition
            return toPositive(Utils.murmur2(key)) % numPartitions;

This will preserve the partitioning behavior of the producer in o.a.k.c.p. The rest of the changes will be the same as your original patch. We don't have to change the partitioning code in DefaultEventHandler. The scala producer already uses a different hash function from the java producer in o.a.k.c.p. So, the partitioning won't be consistent btw the scala and the java producer anyway. The replacing of k.u.Utils.abs() with o.a.k.c.u.Utils.abs() doesn't have to be done in this jira since you are already handling it in KAFKA-1926.
;;;","28/Feb/15 06:42;tongli;Run Rao, I got the point now. Thanks so much for your very detailed explanation. A patch is coming in few minutes with only that.;;;","28/Feb/15 07:08;guozhang;+1. Thanks Tong / Jun for fixing this and preserve compatibility at the same time.

Is the current o.a.k.c.c.u.Utils.abs() used anywhere else?;;;","28/Feb/15 07:16;tongli;Created reviewboard https://reviews.apache.org/r/31566/diff/
 against branch origin/trunk;;;","02/Mar/15 20:22;tongli;[~guozhang] Yes, the o.a.k.c.c.u.Utils.abs used in few places.  in patch set for issue 1926, I will consolidate both Utils modules from clients and core into one. So that we do not have name conflict all over the place. The patch set for issue 1926 will be quite big. I would like to get this thing fixed for coming up release first, then we can address issue 1926. Thanks.;;;","04/Mar/15 08:00;tongli;Updated reviewboard https://reviews.apache.org/r/31566/diff/
 against branch origin/trunk;;;","04/Mar/15 08:03;tongli;Updated reviewboard https://reviews.apache.org/r/31566/diff/
 against branch origin/trunk;;;","04/Mar/15 10:36;guozhang;Thanks [~tongli], +1 and committed to trunk.;;;","12/Mar/15 20:57;noxis;Why this fix is not included in 0.8.2.1 release?
;;;","13/Mar/15 01:19;ewencp;[~noxis] Because it wasn't a critical fix. It didn't change any behavior, the change only made it so the code wasn't misleading. There are only a couple of other uses of the Util.abs method and the change doesn't affect them.;;;","13/Mar/15 03:36;noxis;Please update this issue. Currently it is a blocker fixed in 0.8.2.1.
;;;","13/Mar/15 08:17;tongli;

I thought this one was merged. Please let me know what I need to do with
it?

Thanks

Sent from my iPhone

wrote:
[ https://issues.apache.org/jira/browse/KAFKA-1988?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&focusedCommentId=14359229#comment-14359229 ]

negative numbers.
----------------------------------------------------------------------------------------

KAFKA-1988.patch, KAFKA-1988_2015-03-03_19:00:21.patch,
KAFKA-1988_2015-03-03_19:03:31.patch
negative numbers. The method only returns intended value for positive
numbers. All negative numbers except the Integer.Min_Value will be returned
an unsigned integer.
;;;","13/Mar/15 08:19;ewencp;[~tongli] You're all good, it was merged. I just updated the fix version so it is accurate.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update NOTICE file,KAFKA-2518,12861835,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,gwenshap,fpj,fpj,04/Sep/15 21:10,03/Nov/15 03:08,22/Mar/23 15:10,03/Nov/15 03:08,,,,,,,0.9.0.0,,,,,,,packaging,,,,0,,,,,,"According to this page from ASF legal:

{noformat}
http://www.apache.org/legal/src-headers.html
{noformat}

the years in the NOTICE header should reflect the product name and years of distribution of the current and past versions of the product. The current NOTICE file says only 2012. ",,fpj,githubbot,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Nov 02 19:08:47 UTC 2015,,,,,,,,,,"0|i2jshz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"29/Oct/15 08:44;junrao;The following is the answer that Flavio got from Apache legal.

Question:
I have a couple of questions about the NOTICE file. In this page:

http://www.apache.org/legal/src-headers.html

it says that it should include the following text, suitably modified to reflect the product name and year(s) of distribution of the current and past versions of the product:
Apache [PRODUCT_NAME]
Copyright [yyyy] The Apache Software Foundation
As I understand it, it means that every year, if there is a release, the year part needs to be modified to add the new year, e.g., 2010-2015 if there is a release in 2015. How much of a problem is it if a release comes out without that year field updated? 

Answer:
Unnecessary to have a span of years, and now considered improper form.  The current year (when this specific package is published) is the only year necessary.  The copyrights on individual bits probably go back many years before the first ASF release, but what is important here is the copyright of the collective work that is your current release (here and now).;;;","03/Nov/15 01:32;githubbot;GitHub user gwenshap opened a pull request:

    https://github.com/apache/kafka/pull/404

    KAFKA-2518: Update NOTICE file

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/gwenshap/kafka KAFKA-2518

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/404.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #404
    
----
commit bc576c869c1627dacd6ea5341f9238cc9e61ccc8
Author: Gwen Shapira <cshapi@gmail.com>
Date:   2015-11-02T17:32:08Z

    KAFKA-2518: Update NOTICE file

----
;;;","03/Nov/15 03:08;guozhang;Issue resolved by pull request 404
[https://github.com/apache/kafka/pull/404];;;","03/Nov/15 03:08;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/404
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Only invoke SinkTask onPartitionsRevoked and commitOffsets after task has fully started,KAFKA-2786,12911710,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,ewencp,ewencp,ewencp,10/Nov/15 07:39,10/Nov/15 12:43,22/Mar/23 15:10,10/Nov/15 12:43,,,,,,,0.9.0.0,,,,,,,KafkaConnect,,,,0,,,,,,"Currently we're invoking task.onPartitionsRevoked and commitOffsets on any consumer onPartitionsRevoked callback. Since this happens even on the first rebalance (which is somewhat unexpected given that partitions cannot actually be revoked at that point), we will not be fully setup in the SinkTask and this can throw exceptions.

It turns out this is easy to miss for two reasons. First, the code is likely to throw an exception, but the consumer catches this and handles it. We end up not missing any important steps as a result. Second, the logging was a bit screwed up and we weren't getting the full exception stacktrace, just the toString(), so it was easy to miss that there was a problem.",,ewencp,githubbot,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Nov 10 04:43:44 UTC 2015,,,,,,,,,,"0|i2o63j:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"10/Nov/15 07:41;githubbot;GitHub user ewencp opened a pull request:

    https://github.com/apache/kafka/pull/476

    KAFKA-2786: Only respond to SinkTask onPartitionsRevoked after the WorkerSinkTask has finished starting up.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ewencp/kafka kafka-2786-on-partitions-assigned-only-after-start

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/476.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #476
    
----

----
;;;","10/Nov/15 12:43;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/476
;;;","10/Nov/15 12:43;gwenshap;Issue resolved by pull request 476
[https://github.com/apache/kafka/pull/476];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
more better bootstrapping of the gradle-wrapper.jar ,KAFKA-1714,12749044,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,joestein,joestein,18/Oct/14 21:44,02/Dec/19 05:03,22/Mar/23 15:10,22/Nov/19 14:32,0.8.2.0,,,,,,1.0.3,1.1.2,2.0.2,2.1.2,2.2.3,2.3.2,2.4.0,build,,,,1,,,,,,From https://issues.apache.org/jira/browse/KAFKA-1490 we moved out the gradle-wrapper.jar for our source maintenance. This makes builds for folks coming in the first step somewhat problematic.  A bootstrap step is required if this could be somehow incorporated that would be great.,,githubbot,joestein,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2124,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 21 16:06:11 UTC 2019,,,,,,,,,,"0|i21blz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"14/Dec/18 02:10;githubbot;granthenke opened a new pull request #6031: KAFKA-1714: Fix gradle wrapper bootstrapping
URL: https://github.com/apache/kafka/pull/6031
 
 
   Given we need to follow the Apache rule of not checking
   any binaries into the source code, Kafka has always had
   a bit of a tricky Gradle bootstrap.
   Using ./gradlew as users expect doesn’t work and a
   local and compatible version of Gradle was required to
   generate the wrapper first.
   
   This patch changes the behavior of the wrapper task to
   instead generate a gradlew script that can bootstrap the
   jar itself. Additionally it adds a license, removes the bat
   script, and handles retries.
   
   The documentation in the readme was also updated.
   
   Going forward patches that upgrade gradle should run
   `gradle wrapper` before checking in the change.
   
   With this change users using ./gradlew can be sure they
   are always building with the correct version of Gradle.
   
   *More detailed description of your change,
   if necessary. The PR title and PR message become
   the squashed commit message, so use a separate
   comment to ping reviewers.*
   
   *Summary of testing strategy (including rationale)
   for the feature or bug fix. Unit and/or integration
   tests are expected for any behaviour change and
   system tests should be considered for larger changes.*
   
   ### Committer Checklist (excluded from commit message)
   - [ ] Verify design and implementation 
   - [ ] Verify test coverage and CI build status
   - [ ] Verify documentation (including upgrade notes)
   

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;","22/Nov/19 00:06;githubbot;ijuma commented on pull request #6031: KAFKA-1714: Fix gradle wrapper bootstrapping
URL: https://github.com/apache/kafka/pull/6031
 
 
   
 
----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move protocol field default values to Protocol,KAFKA-2617,12902835,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,sinus,guozhang,guozhang,07/Oct/15 05:53,30/Mar/19 08:42,22/Mar/23 15:10,30/Mar/19 08:42,,,,,,,2.2.0,,,,,,,,,,,0,newbie,,,,,"Right now the default values are scattered in the Request / Response classes, and some duplicates already exists like JoinGroupRequest.UNKNOWN_CONSUMER_ID and OffsetCommitRequest.DEFAULT_CONSUMER_ID. We would like to move all default values into org.apache.kafka.common.protocol.Protocol since org.apache.kafka.common.requests depends on org.apache.kafka.common.protocol anyways.
",,githubbot,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Mar 30 00:40:49 UTC 2019,,,,,,,,,,"0|i2mnuv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"21/Oct/15 05:28;githubbot;GitHub user Mszak opened a pull request:

    https://github.com/apache/kafka/pull/338

    KAFKA-2617: Move protocol field default values to Protocol.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/Mszak/kafka kafka-2617-move-default-values

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/338.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #338
    
----
commit a99c5dff41aa548303c4f6dec586cb22e3b70a59
Author: Jakub Nowak <jakub.nowak94@interia.pl>
Date:   2015-10-20T21:11:30Z

    Move protocol field default values to Protocol.

----
;;;","23/Dec/17 04:23;githubbot;guozhangwang commented on issue #338: KAFKA-2617: Move protocol field default values to Protocol.
URL: https://github.com/apache/kafka/pull/338#issuecomment-353669036
 
 
   Closing for cleanup.

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;","23/Dec/17 04:23;githubbot;guozhangwang closed pull request #338: KAFKA-2617: Move protocol field default values to Protocol.
URL: https://github.com/apache/kafka/pull/338
 
 
   

This is a PR merged from a forked repository.
As GitHub hides the original diff on merge, it is displayed below for
the sake of provenance:

As this is a foreign pull request (from a fork), the diff is supplied
below (as it won't show otherwise due to GitHub magic):

diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Coordinator.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Coordinator.java
index 98193e829ad..5b9a8d0bc5c 100644
--- a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Coordinator.java
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Coordinator.java
@@ -102,8 +102,8 @@ public Coordinator(ConsumerNetworkClient client,
                        long autoCommitIntervalMs) {
         this.client = client;
         this.time = time;
-        this.generation = OffsetCommitRequest.DEFAULT_GENERATION_ID;
-        this.consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID;
+        this.generation = OffsetCommitRequest.getDefaultGenerationId();
+        this.consumerId = JoinGroupRequest.getDefaultConsumerId();
         this.groupId = groupId;
         this.consumerCoordinator = null;
         this.subscriptions = subscriptions;
@@ -353,7 +353,7 @@ public void handle(JoinGroupResponse joinResponse, RequestFuture<Void> future) {
                 future.complete(null);
             } else if (errorCode == Errors.UNKNOWN_CONSUMER_ID.code()) {
                 // reset the consumer id and retry immediately
-                Coordinator.this.consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID;
+                Coordinator.this.consumerId = JoinGroupRequest.getDefaultConsumerId();
                 log.info(""Attempt to join group {} failed due to unknown consumer id, resetting and retrying."",
                         groupId);
                 future.raise(Errors.UNKNOWN_CONSUMER_ID);
@@ -453,8 +453,8 @@ private void maybeAutoCommitOffsetsSync() {
      * Reset the generation/consumerId tracked by this consumer.
      */
     public void resetGeneration() {
-        this.generation = OffsetCommitRequest.DEFAULT_GENERATION_ID;
-        this.consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID;
+        this.generation = OffsetCommitRequest.getDefaultGenerationId();
+        this.consumerId = JoinGroupRequest.getDefaultConsumerId();
     }
 
     /**
@@ -483,7 +483,7 @@ public void resetGeneration() {
         OffsetCommitRequest req = new OffsetCommitRequest(this.groupId,
                 this.generation,
                 this.consumerId,
-                OffsetCommitRequest.DEFAULT_RETENTION_TIME,
+                OffsetCommitRequest.getDefaultRetentionId(),
                 offsetData);
 
         return client.send(consumerCoordinator, ApiKeys.OFFSET_COMMIT, req)
@@ -720,7 +720,7 @@ public void handle(HeartbeatResponse heartbeatResponse, RequestFuture<Void> futu
                 future.raise(Errors.ILLEGAL_GENERATION);
             } else if (error == Errors.UNKNOWN_CONSUMER_ID.code()) {
                 log.info(""Attempt to heart beat failed since consumer id is not valid, reset it and try to re-join group."");
-                consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID;
+                consumerId = JoinGroupRequest.getDefaultConsumerId();
                 subscriptions.needReassignment();
                 future.raise(Errors.UNKNOWN_CONSUMER_ID);
             } else {
diff --git a/clients/src/main/java/org/apache/kafka/common/protocol/Protocol.java b/clients/src/main/java/org/apache/kafka/common/protocol/Protocol.java
index 9f8e9817437..9f4a3de8030 100644
--- a/clients/src/main/java/org/apache/kafka/common/protocol/Protocol.java
+++ b/clients/src/main/java/org/apache/kafka/common/protocol/Protocol.java
@@ -20,6 +20,8 @@
 import org.apache.kafka.common.protocol.types.Field;
 import org.apache.kafka.common.protocol.types.Schema;
 
+import java.nio.ByteBuffer;
+
 import static org.apache.kafka.common.protocol.types.Type.*;
 
 public class Protocol {
@@ -130,6 +132,9 @@
                                                                                new Field(""offset"",
                                                                                          INT64,
                                                                                          ""Message offset to be committed.""),
+                                                                               new Field(""timestamp"",
+                                                                                         INT64,
+                                                                                         ""Timestamp of the commit"", -1L),
                                                                                new Field(""metadata"",
                                                                                          STRING,
                                                                                          ""Any associated metadata the client wants to keep.""));
@@ -142,7 +147,7 @@
                                                                                          ""Message offset to be committed.""),
                                                                                new Field(""timestamp"",
                                                                                          INT64,
-                                                                                         ""Timestamp of the commit""),
+                                                                                         ""Timestamp of the commit"", -1L),
                                                                                new Field(""metadata"",
                                                                                          STRING,
                                                                                          ""Any associated metadata the client wants to keep.""));
@@ -203,13 +208,13 @@
                                                                                ""The consumer group id.""),
                                                                      new Field(""group_generation_id"",
                                                                                INT32,
-                                                                               ""The generation of the consumer group.""),
+                                                                               ""The generation of the consumer group."", -1),
                                                                      new Field(""consumer_id"",
                                                                                STRING,
-                                                                               ""The consumer id assigned by the group coordinator.""),
+                                                                               ""The consumer id assigned by the group coordinator."", """"),
                                                                      new Field(""retention_time"",
                                                                                INT64,
-                                                                               ""Time period in ms to retain the offset.""),
+                                                                               ""Time period in ms to retain the offset."", -1L),
                                                                      new Field(""topics"",
                                                                                new ArrayOf(OFFSET_COMMIT_REQUEST_TOPIC_V2),
                                                                                ""Topics to commit offsets.""));
@@ -265,10 +270,10 @@
                                                                                          ""Topic partition id.""),
                                                                                new Field(""offset"",
                                                                                          INT64,
-                                                                                         ""Last committed message offset.""),
+                                                                                         ""Last committed message offset."", -1L),
                                                                                new Field(""metadata"",
                                                                                          STRING,
-                                                                                         ""Any associated metadata the client wants to keep.""),
+                                                                                         ""Any associated metadata the client wants to keep."", """"),
                                                                                new Field(""error_code"", INT16));
 
     public static final Schema OFFSET_FETCH_RESPONSE_TOPIC_V0 = new Schema(new Field(""topic"", STRING),
@@ -343,7 +348,7 @@
 
     public static final Schema FETCH_REQUEST_V0 = new Schema(new Field(""replica_id"",
                                                                        INT32,
-                                                                       ""Broker id of the follower. For normal consumers, use -1.""),
+                                                                       ""Broker id of the follower. For normal consumers, use -1."", -1),
                                                              new Field(""max_wait_time"",
                                                                        INT32,
                                                                        ""Maximum time in ms to wait for the response.""),
@@ -363,14 +368,21 @@
                                                                         new Field(""error_code"", INT16),
                                                                         new Field(""high_watermark"",
                                                                                   INT64,
-                                                                                  ""Last committed offset.""),
-                                                                        new Field(""record_set"", BYTES));
+                                                                                  ""Last committed offset."", -1L),
+                                                                        new Field(""record_set"",
+                                                                                  BYTES,
+                                                                                  ""Partition bytes."", ByteBuffer.allocate(0)));
 
     public static final Schema FETCH_RESPONSE_TOPIC_V0 = new Schema(new Field(""topic"", STRING),
                                                                     new Field(""partition_responses"",
                                                                               new ArrayOf(FETCH_RESPONSE_PARTITION_V0)));
 
-    public static final Schema FETCH_RESPONSE_V0 = new Schema(new Field(""responses"",
+    public static final Schema FETCH_RESPONSE_V0 = new Schema(new Field(""throttle_time_ms"",
+                                                                        INT32,
+                                                                        ""Duration in milliseconds for which the request was throttled"" +
+                                                                                "" due to quota violation. (Zero if the request did not violate any quota.)"",
+                                                                        0),
+                                                              new Field(""responses"",
                                                                         new ArrayOf(FETCH_RESPONSE_TOPIC_V0)));
     public static final Schema FETCH_RESPONSE_V1 = new Schema(new Field(""throttle_time_ms"",
                                                                         INT32,
@@ -427,7 +439,7 @@
                                                                             ""An array of topics to subscribe to.""),
                                                                   new Field(""consumer_id"",
                                                                             STRING,
-                                                                            ""The assigned consumer id or an empty string for a new consumer.""),
+                                                                            ""The assigned consumer id or an empty string for a new consumer."", """"),
                                                                   new Field(""partition_assignment_strategy"",
                                                                             STRING,
                                                                             ""The strategy for the coordinator to assign partitions.""));
@@ -437,10 +449,10 @@
     public static final Schema JOIN_GROUP_RESPONSE_V0 = new Schema(new Field(""error_code"", INT16),
                                                                    new Field(""group_generation_id"",
                                                                              INT32,
-                                                                             ""The generation of the consumer group.""),
+                                                                             ""The generation of the consumer group."", -1),
                                                                    new Field(""consumer_id"",
                                                                              STRING,
-                                                                             ""The consumer id assigned by the group coordinator.""),
+                                                                             ""The consumer id assigned by the group coordinator."", """"),
                                                                    new Field(""assigned_partitions"",
                                                                              new ArrayOf(JOIN_GROUP_RESPONSE_TOPIC_V0)));
 
diff --git a/clients/src/main/java/org/apache/kafka/common/protocol/types/Schema.java b/clients/src/main/java/org/apache/kafka/common/protocol/types/Schema.java
index 3a14ac0fb35..0154037c4e1 100644
--- a/clients/src/main/java/org/apache/kafka/common/protocol/types/Schema.java
+++ b/clients/src/main/java/org/apache/kafka/common/protocol/types/Schema.java
@@ -121,6 +121,16 @@ public Field get(String name) {
         return this.fields;
     }
 
+    /**
+     * Get a nested scheme its name
+     *
+     * @param name The name of the field
+     * @return The field
+     */
+    public Schema getNestedSchema(String name) {
+        return (Schema) ((ArrayOf) this.fieldsByName.get(name).type).type();
+    }
+
     /**
      * Display a string representation of the schema
      */
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/FetchRequest.java b/clients/src/main/java/org/apache/kafka/common/requests/FetchRequest.java
index feb4109bf8b..ec42a425e89 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/FetchRequest.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/FetchRequest.java
@@ -28,7 +28,6 @@
 
 public class FetchRequest extends AbstractRequest {
     
-    public static final int CONSUMER_REPLICA_ID = -1;
     private static final Schema CURRENT_SCHEMA = ProtoUtils.currentRequestSchema(ApiKeys.FETCH.id);
     private static final String REPLICA_ID_KEY_NAME = ""replica_id"";
     private static final String MAX_WAIT_KEY_NAME = ""max_wait_time"";
@@ -63,7 +62,7 @@ public PartitionData(long offset, int maxBytes) {
      * Create a non-replica fetch request
      */
     public FetchRequest(int maxWait, int minBytes, Map<TopicPartition, PartitionData> fetchData) {
-        this(CONSUMER_REPLICA_ID, maxWait, minBytes, fetchData);
+        this((int) CURRENT_SCHEMA.get(REPLICA_ID_KEY_NAME).defaultValue, maxWait, minBytes, fetchData);
     }
 
     /**
@@ -125,8 +124,8 @@ public AbstractRequestResponse getErrorResponse(int versionId, Throwable e) {
 
         for (Map.Entry<TopicPartition, PartitionData> entry: fetchData.entrySet()) {
             FetchResponse.PartitionData partitionResponse = new FetchResponse.PartitionData(Errors.forException(e).code(),
-                    FetchResponse.INVALID_HIGHWATERMARK,
-                    FetchResponse.EMPTY_RECORD_SET);
+                    FetchResponse.getInvalidHighWatermark(),
+                    FetchResponse.getEmptyRecordSet());
             responseData.put(entry.getKey(), partitionResponse);
         }
 
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java b/clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java
index 7b7841579c7..4e9bbcf0604 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java
@@ -46,9 +46,6 @@
     private static final String PARTITION_KEY_NAME = ""partition"";
     private static final String ERROR_CODE_KEY_NAME = ""error_code"";
 
-    // Default throttle time
-    private static final int DEFAULT_THROTTLE_TIME = 0;
-
   /**
      * Possible error code:
      *
@@ -62,9 +59,6 @@
     private static final String HIGH_WATERMARK_KEY_NAME = ""high_watermark"";
     private static final String RECORD_SET_KEY_NAME = ""record_set"";
 
-    public static final long INVALID_HIGHWATERMARK = -1L;
-    public static final ByteBuffer EMPTY_RECORD_SET = ByteBuffer.allocate(0);
-
     private final Map<TopicPartition, PartitionData> responseData;
     private final int throttleTime;
 
@@ -88,7 +82,7 @@ public FetchResponse(Map<TopicPartition, PartitionData> responseData) {
         super(new Struct(ProtoUtils.responseSchema(ApiKeys.FETCH.id, 0)));
         initCommonFields(responseData);
         this.responseData = responseData;
-        this.throttleTime = DEFAULT_THROTTLE_TIME;
+        this.throttleTime = (int) CURRENT_SCHEMA.get(THROTTLE_TIME_KEY_NAME).defaultValue;
     }
 
   /**
@@ -120,7 +114,8 @@ public FetchResponse(Struct struct) {
                 responseData.put(new TopicPartition(topic, partition), partitionData);
             }
         }
-        this.throttleTime = struct.hasField(THROTTLE_TIME_KEY_NAME) ? struct.getInt(THROTTLE_TIME_KEY_NAME) : DEFAULT_THROTTLE_TIME;
+        this.throttleTime = struct.hasField(THROTTLE_TIME_KEY_NAME) ? struct.getInt(THROTTLE_TIME_KEY_NAME)
+                : (int) CURRENT_SCHEMA.get(THROTTLE_TIME_KEY_NAME).defaultValue;
     }
 
     private void initCommonFields(Map<TopicPartition, PartitionData> responseData) {
@@ -162,4 +157,14 @@ public static FetchResponse parse(ByteBuffer buffer) {
     public static FetchResponse parse(ByteBuffer buffer, int version) {
         return new FetchResponse((Struct) ProtoUtils.responseSchema(ApiKeys.FETCH.id, version).read(buffer));
     }
+
+    public static long getInvalidHighWatermark() {
+        return (long) CURRENT_SCHEMA.getNestedSchema(RESPONSES_KEY_NAME).getNestedSchema(PARTITIONS_KEY_NAME)
+                .get(HIGH_WATERMARK_KEY_NAME).defaultValue;
+    }
+
+    public static ByteBuffer getEmptyRecordSet() {
+        return (ByteBuffer) CURRENT_SCHEMA.getNestedSchema(RESPONSES_KEY_NAME).getNestedSchema(PARTITIONS_KEY_NAME)
+                .get(RECORD_SET_KEY_NAME).defaultValue;
+    }
 }
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/JoinGroupRequest.java b/clients/src/main/java/org/apache/kafka/common/requests/JoinGroupRequest.java
index 1ffe0760b40..a69d7f7f1bb 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/JoinGroupRequest.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/JoinGroupRequest.java
@@ -33,7 +33,8 @@
     private static final String CONSUMER_ID_KEY_NAME = ""consumer_id"";
     private static final String STRATEGY_KEY_NAME = ""partition_assignment_strategy"";
 
-    public static final String UNKNOWN_CONSUMER_ID = """";
+    private static final Schema CURRENT_RESPONSE_SCHEMA = ProtoUtils.currentResponseSchema(ApiKeys.JOIN_GROUP.id);
+    private static final String GENERATION_ID_KEY_NAME = ""group_generation_id"";
 
     private final String groupId;
     private final int sessionTimeout;
@@ -73,8 +74,8 @@ public AbstractRequestResponse getErrorResponse(int versionId, Throwable e) {
             case 0:
                 return new JoinGroupResponse(
                         Errors.forException(e).code(),
-                        JoinGroupResponse.UNKNOWN_GENERATION_ID,
-                        JoinGroupResponse.UNKNOWN_CONSUMER_ID,
+                        (int) CURRENT_RESPONSE_SCHEMA.get(GENERATION_ID_KEY_NAME).defaultValue,
+                        CURRENT_RESPONSE_SCHEMA.get(CONSUMER_ID_KEY_NAME).defaultValue.toString(),
                         Collections.<TopicPartition>emptyList());
             default:
                 throw new IllegalArgumentException(String.format(""Version %d is not valid. Valid versions for %s are 0 to %d"",
@@ -109,4 +110,8 @@ public static JoinGroupRequest parse(ByteBuffer buffer, int versionId) {
     public static JoinGroupRequest parse(ByteBuffer buffer) {
         return new JoinGroupRequest((Struct) CURRENT_SCHEMA.read(buffer));
     }
+
+    public static String getDefaultConsumerId() {
+        return CURRENT_SCHEMA.get(CONSUMER_ID_KEY_NAME).defaultValue.toString();
+    }
 }
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/JoinGroupResponse.java b/clients/src/main/java/org/apache/kafka/common/requests/JoinGroupResponse.java
index 7bf544ef170..b8ddad00c36 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/JoinGroupResponse.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/JoinGroupResponse.java
@@ -44,9 +44,6 @@
     private static final String TOPIC_KEY_NAME = ""topic"";
     private static final String PARTITIONS_KEY_NAME = ""partitions"";
 
-    public static final int UNKNOWN_GENERATION_ID = -1;
-    public static final String UNKNOWN_CONSUMER_ID = """";
-
     private final short errorCode;
     private final int generationId;
     private final String consumerId;
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/OffsetCommitRequest.java b/clients/src/main/java/org/apache/kafka/common/requests/OffsetCommitRequest.java
index 03df1e780c0..694dea085ff 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/OffsetCommitRequest.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/OffsetCommitRequest.java
@@ -16,6 +16,7 @@
 import org.apache.kafka.common.protocol.ApiKeys;
 import org.apache.kafka.common.protocol.Errors;
 import org.apache.kafka.common.protocol.ProtoUtils;
+import org.apache.kafka.common.protocol.types.Field;
 import org.apache.kafka.common.protocol.types.Schema;
 import org.apache.kafka.common.protocol.types.Struct;
 import org.apache.kafka.common.utils.CollectionUtils;
@@ -50,16 +51,6 @@
     @Deprecated
     private static final String TIMESTAMP_KEY_NAME = ""timestamp"";         // for v0, v1
 
-    // default values for the current version
-    public static final int DEFAULT_GENERATION_ID = -1;
-    public static final String DEFAULT_CONSUMER_ID = """";
-    public static final long DEFAULT_RETENTION_TIME = -1L;
-
-    // default values for old versions,
-    // will be removed after these versions are deprecated
-    @Deprecated
-    public static final long DEFAULT_TIMESTAMP = -1L;            // for V0, V1
-
     private final String groupId;
     private final String consumerId;
     private final int generationId;
@@ -81,7 +72,7 @@ public PartitionData(long offset, long timestamp, String metadata) {
         }
 
         public PartitionData(long offset, String metadata) {
-            this(offset, DEFAULT_TIMESTAMP, metadata);
+            this(offset, getDefaultTimestamp(), metadata);
         }
     }
 
@@ -96,9 +87,9 @@ public OffsetCommitRequest(String groupId, Map<TopicPartition, PartitionData> of
 
         initCommonFields(groupId, offsetData);
         this.groupId = groupId;
-        this.generationId = DEFAULT_GENERATION_ID;
-        this.consumerId = DEFAULT_CONSUMER_ID;
-        this.retentionTime = DEFAULT_RETENTION_TIME;
+        this.generationId = (int) CURRENT_SCHEMA.get(GENERATION_ID_KEY_NAME).defaultValue;
+        this.consumerId = CURRENT_SCHEMA.get(CONSUMER_ID_KEY_NAME).defaultValue.toString();
+        this.retentionTime = (long) CURRENT_SCHEMA.get(RETENTION_TIME_KEY_NAME).defaultValue;
         this.offsetData = offsetData;
     }
 
@@ -119,7 +110,7 @@ public OffsetCommitRequest(String groupId, int generationId, String consumerId,
         this.groupId = groupId;
         this.generationId = generationId;
         this.consumerId = consumerId;
-        this.retentionTime = DEFAULT_RETENTION_TIME;
+        this.retentionTime = (long) CURRENT_SCHEMA.get(RETENTION_TIME_KEY_NAME).defaultValue;
         this.offsetData = offsetData;
     }
 
@@ -180,19 +171,19 @@ public OffsetCommitRequest(Struct struct) {
         if (struct.hasField(GENERATION_ID_KEY_NAME))
             generationId = struct.getInt(GENERATION_ID_KEY_NAME);
         else
-            generationId = DEFAULT_GENERATION_ID;
+            generationId = (int) CURRENT_SCHEMA.get(GENERATION_ID_KEY_NAME).defaultValue;
 
         // This field only exists in v1.
         if (struct.hasField(CONSUMER_ID_KEY_NAME))
             consumerId = struct.getString(CONSUMER_ID_KEY_NAME);
         else
-            consumerId = DEFAULT_CONSUMER_ID;
+            consumerId = CURRENT_SCHEMA.get(CONSUMER_ID_KEY_NAME).defaultValue.toString();
 
         // This field only exists in v2
         if (struct.hasField(RETENTION_TIME_KEY_NAME))
             retentionTime = struct.getLong(RETENTION_TIME_KEY_NAME);
         else
-            retentionTime = DEFAULT_RETENTION_TIME;
+            retentionTime = (long) CURRENT_SCHEMA.get(RETENTION_TIME_KEY_NAME).defaultValue;
 
         offsetData = new HashMap<TopicPartition, PartitionData>();
         for (Object topicDataObj : struct.getArray(TOPICS_KEY_NAME)) {
@@ -263,4 +254,21 @@ public static OffsetCommitRequest parse(ByteBuffer buffer, int versionId) {
     public static OffsetCommitRequest parse(ByteBuffer buffer) {
         return new OffsetCommitRequest((Struct) CURRENT_SCHEMA.read(buffer));
     }
+
+    public static int getDefaultGenerationId() {
+        return (int) CURRENT_SCHEMA.get(GENERATION_ID_KEY_NAME).defaultValue;
+    }
+
+    public static long getDefaultRetentionId() {
+        return (long) CURRENT_SCHEMA.get(RETENTION_TIME_KEY_NAME).defaultValue;
+    }
+
+    public static String getDefaultConsumerId() {
+        return CURRENT_SCHEMA.get(CONSUMER_ID_KEY_NAME).defaultValue.toString();
+    }
+
+    public static long getDefaultTimestamp() {
+        Field timestampField = CURRENT_SCHEMA.getNestedSchema(TOPICS_KEY_NAME).getNestedSchema(PARTITIONS_KEY_NAME).get(TIMESTAMP_KEY_NAME);
+        return timestampField == null ? -1L : (long) timestampField.defaultValue;
+    }
 }
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/OffsetFetchRequest.java b/clients/src/main/java/org/apache/kafka/common/requests/OffsetFetchRequest.java
index 6ee75973d64..c1b0d1f1b8a 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/OffsetFetchRequest.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/OffsetFetchRequest.java
@@ -89,8 +89,8 @@ public AbstractRequestResponse getErrorResponse(int versionId, Throwable e) {
         Map<TopicPartition, OffsetFetchResponse.PartitionData> responseData = new HashMap<TopicPartition, OffsetFetchResponse.PartitionData>();
 
         for (TopicPartition partition: partitions) {
-            responseData.put(partition, new OffsetFetchResponse.PartitionData(OffsetFetchResponse.INVALID_OFFSET,
-                    OffsetFetchResponse.NO_METADATA,
+            responseData.put(partition, new OffsetFetchResponse.PartitionData(OffsetFetchResponse.getInvalidOffset(),
+                    OffsetFetchResponse.getEmptyMetadata(),
                     Errors.forException(e).code()));
         }
 
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/OffsetFetchResponse.java b/clients/src/main/java/org/apache/kafka/common/requests/OffsetFetchResponse.java
index 3dc8521296e..52f5f1f2e34 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/OffsetFetchResponse.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/OffsetFetchResponse.java
@@ -41,9 +41,6 @@
     private static final String METADATA_KEY_NAME = ""metadata"";
     private static final String ERROR_CODE_KEY_NAME = ""error_code"";
 
-    public static final long INVALID_OFFSET = -1L;
-    public static final String NO_METADATA = """";
-
     /**
      * Possible error code:
      *
@@ -123,4 +120,14 @@ public OffsetFetchResponse(Struct struct) {
     public static OffsetFetchResponse parse(ByteBuffer buffer) {
         return new OffsetFetchResponse((Struct) CURRENT_SCHEMA.read(buffer));
     }
+
+    public static long getInvalidOffset() {
+        return (long) CURRENT_SCHEMA.getNestedSchema(RESPONSES_KEY_NAME).getNestedSchema(PARTITIONS_KEY_NAME)
+                .get(COMMIT_OFFSET_KEY_NAME).defaultValue;
+    }
+
+    public static String getEmptyMetadata() {
+        return (String) CURRENT_SCHEMA.getNestedSchema(RESPONSES_KEY_NAME).getNestedSchema(PARTITIONS_KEY_NAME)
+                .get(METADATA_KEY_NAME).defaultValue;
+    }
 }
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/ProduceResponse.java b/clients/src/main/java/org/apache/kafka/common/requests/ProduceResponse.java
index 28685501897..d76fe0d8b86 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/ProduceResponse.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/ProduceResponse.java
@@ -43,7 +43,6 @@
     private static final String ERROR_CODE_KEY_NAME = ""error_code"";
 
     public static final long INVALID_OFFSET = -1L;
-    private static final int DEFAULT_THROTTLE_TIME = 0;
 
     /**
      * Possible error code:
@@ -64,7 +63,7 @@ public ProduceResponse(Map<TopicPartition, PartitionResponse> responses) {
         super(new Struct(ProtoUtils.responseSchema(ApiKeys.PRODUCE.id, 0)));
         initCommonFields(responses);
         this.responses = responses;
-        this.throttleTime = DEFAULT_THROTTLE_TIME;
+        this.throttleTime = (int) CURRENT_SCHEMA.get(THROTTLE_TIME_KEY_NAME).defaultValue;
     }
 
     /**
diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/CoordinatorTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/CoordinatorTest.java
index 66b2e32f402..a7b4fd356cc 100644
--- a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/CoordinatorTest.java
+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/CoordinatorTest.java
@@ -383,8 +383,8 @@ public void testResetGeneration() {
             @Override
             public boolean matches(ClientRequest request) {
                 OffsetCommitRequest commitRequest = new OffsetCommitRequest(request.request().body());
-                return commitRequest.consumerId().equals(OffsetCommitRequest.DEFAULT_CONSUMER_ID) &&
-                        commitRequest.generationId() == OffsetCommitRequest.DEFAULT_GENERATION_ID;
+                return commitRequest.consumerId().equals(OffsetCommitRequest.getDefaultConsumerId()) &&
+                        commitRequest.generationId() == OffsetCommitRequest.getDefaultGenerationId();
             }
         }, offsetCommitResponse(Collections.singletonMap(tp, Errors.NONE.code())));
 
diff --git a/core/src/main/scala/kafka/api/OffsetCommitRequest.scala b/core/src/main/scala/kafka/api/OffsetCommitRequest.scala
index 5b362ef7a76..13451978850 100644
--- a/core/src/main/scala/kafka/api/OffsetCommitRequest.scala
+++ b/core/src/main/scala/kafka/api/OffsetCommitRequest.scala
@@ -48,20 +48,20 @@ object OffsetCommitRequest extends Logging {
       if (versionId >= 1)
         buffer.getInt
       else
-        org.apache.kafka.common.requests.OffsetCommitRequest.DEFAULT_GENERATION_ID
+        org.apache.kafka.common.requests.OffsetCommitRequest.getDefaultGenerationId
 
     val consumerId: String =
       if (versionId >= 1)
         readShortString(buffer)
       else
-        org.apache.kafka.common.requests.OffsetCommitRequest.DEFAULT_CONSUMER_ID
+        org.apache.kafka.common.requests.OffsetCommitRequest.getDefaultConsumerId
 
     // version 2 specific fields
     val retentionMs: Long =
       if (versionId >= 2)
         buffer.getLong
       else
-        org.apache.kafka.common.requests.OffsetCommitRequest.DEFAULT_RETENTION_TIME
+        org.apache.kafka.common.requests.OffsetCommitRequest.getDefaultRetentionId
 
     val topicCount = buffer.getInt
     val pairs = (1 to topicCount).flatMap(_ => {
@@ -92,9 +92,9 @@ case class OffsetCommitRequest(groupId: String,
                                versionId: Short = OffsetCommitRequest.CurrentVersion,
                                correlationId: Int = 0,
                                clientId: String = OffsetCommitRequest.DefaultClientId,
-                               groupGenerationId: Int = org.apache.kafka.common.requests.OffsetCommitRequest.DEFAULT_GENERATION_ID,
-                               consumerId: String =  org.apache.kafka.common.requests.OffsetCommitRequest.DEFAULT_CONSUMER_ID,
-                               retentionMs: Long = org.apache.kafka.common.requests.OffsetCommitRequest.DEFAULT_RETENTION_TIME)
+                               groupGenerationId: Int = org.apache.kafka.common.requests.OffsetCommitRequest.getDefaultGenerationId,
+                               consumerId: String =  org.apache.kafka.common.requests.OffsetCommitRequest.getDefaultConsumerId,
+                               retentionMs: Long = org.apache.kafka.common.requests.OffsetCommitRequest.getDefaultRetentionId)
     extends RequestOrResponse(Some(RequestKeys.OffsetCommitKey)) {
 
   assert(versionId == 0 || versionId == 1 || versionId == 2,
diff --git a/core/src/main/scala/kafka/coordinator/ConsumerCoordinator.scala b/core/src/main/scala/kafka/coordinator/ConsumerCoordinator.scala
index bf23e9ba198..0e5c14f6ff9 100644
--- a/core/src/main/scala/kafka/coordinator/ConsumerCoordinator.scala
+++ b/core/src/main/scala/kafka/coordinator/ConsumerCoordinator.scala
@@ -121,7 +121,7 @@ class ConsumerCoordinator(val brokerId: Int,
       // exist we should reject the request
       var group = coordinatorMetadata.getGroup(groupId)
       if (group == null) {
-        if (consumerId != JoinGroupRequest.UNKNOWN_CONSUMER_ID) {
+        if (consumerId != JoinGroupRequest.getDefaultConsumerId) {
           responseCallback(Set.empty, consumerId, 0, Errors.UNKNOWN_CONSUMER_ID.code)
         } else {
           group = coordinatorMetadata.addGroup(groupId, partitionAssignmentStrategy)
@@ -148,7 +148,7 @@ class ConsumerCoordinator(val brokerId: Int,
         responseCallback(Set.empty, consumerId, 0, Errors.UNKNOWN_CONSUMER_ID.code)
       } else if (partitionAssignmentStrategy != group.partitionAssignmentStrategy) {
         responseCallback(Set.empty, consumerId, 0, Errors.INCONSISTENT_PARTITION_ASSIGNMENT_STRATEGY.code)
-      } else if (consumerId != JoinGroupRequest.UNKNOWN_CONSUMER_ID && !group.has(consumerId)) {
+      } else if (consumerId != JoinGroupRequest.getDefaultConsumerId && !group.has(consumerId)) {
         // if the consumer trying to register with a un-recognized id, send the response to let
         // it reset its consumer id and retry
         responseCallback(Set.empty, consumerId, 0, Errors.UNKNOWN_CONSUMER_ID.code)
@@ -161,7 +161,7 @@ class ConsumerCoordinator(val brokerId: Int,
         completeAndScheduleNextHeartbeatExpiration(group, consumer)
         responseCallback(consumer.assignedTopicPartitions, consumerId, group.generationId, Errors.NONE.code)
       } else {
-        val consumer = if (consumerId == JoinGroupRequest.UNKNOWN_CONSUMER_ID) {
+        val consumer = if (consumerId == JoinGroupRequest.getDefaultConsumerId) {
           // if the consumer id is unknown, register this consumer to the group
           val generatedConsumerId = group.generateNextConsumerId
           val consumer = addConsumer(generatedConsumerId, topics, sessionTimeoutMs, group)
diff --git a/core/src/main/scala/kafka/server/KafkaApis.scala b/core/src/main/scala/kafka/server/KafkaApis.scala
index 6acab8da18f..e6235c3c114 100644
--- a/core/src/main/scala/kafka/server/KafkaApis.scala
+++ b/core/src/main/scala/kafka/server/KafkaApis.scala
@@ -239,7 +239,7 @@ class KafkaApis(val requestChannel: RequestChannel,
       // if it is v1 or not specified by user, we can use the default retention
       val offsetRetention =
         if (offsetCommitRequest.versionId <= 1 ||
-          offsetCommitRequest.retentionMs == org.apache.kafka.common.requests.OffsetCommitRequest.DEFAULT_RETENTION_TIME) {
+          offsetCommitRequest.retentionMs == org.apache.kafka.common.requests.OffsetCommitRequest.getDefaultRetentionId) {
           coordinator.offsetConfig.offsetsRetentionMs
         } else {
           offsetCommitRequest.retentionMs
diff --git a/core/src/test/scala/unit/kafka/coordinator/ConsumerCoordinatorResponseTest.scala b/core/src/test/scala/unit/kafka/coordinator/ConsumerCoordinatorResponseTest.scala
index c108955f59f..5d63d89ef70 100644
--- a/core/src/test/scala/unit/kafka/coordinator/ConsumerCoordinatorResponseTest.scala
+++ b/core/src/test/scala/unit/kafka/coordinator/ConsumerCoordinatorResponseTest.scala
@@ -71,7 +71,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testJoinGroupWrongCoordinator() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
     val partitionAssignmentStrategy = ""range""
 
     val joinGroupResult = joinGroup(groupId, consumerId, partitionAssignmentStrategy, DefaultSessionTimeout, isCoordinatorForGroup = false)
@@ -82,7 +82,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testJoinGroupUnknownPartitionAssignmentStrategy() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
     val partitionAssignmentStrategy = ""foo""
 
     val joinGroupResult = joinGroup(groupId, consumerId, partitionAssignmentStrategy, DefaultSessionTimeout, isCoordinatorForGroup = true)
@@ -93,7 +93,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testJoinGroupSessionTimeoutTooSmall() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
     val partitionAssignmentStrategy = ""range""
 
     val joinGroupResult = joinGroup(groupId, consumerId, partitionAssignmentStrategy, ConsumerMinSessionTimeout - 1, isCoordinatorForGroup = true)
@@ -104,7 +104,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testJoinGroupSessionTimeoutTooLarge() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
     val partitionAssignmentStrategy = ""range""
 
     val joinGroupResult = joinGroup(groupId, consumerId, partitionAssignmentStrategy, ConsumerMaxSessionTimeout + 1, isCoordinatorForGroup = true)
@@ -126,7 +126,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testValidJoinGroup() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
     val partitionAssignmentStrategy = ""range""
 
     val joinGroupResult = joinGroup(groupId, consumerId, partitionAssignmentStrategy, DefaultSessionTimeout, isCoordinatorForGroup = true)
@@ -137,8 +137,8 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testJoinGroupInconsistentPartitionAssignmentStrategy() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
-    val otherConsumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
+    val otherConsumerId = JoinGroupRequest.getDefaultConsumerId
     val partitionAssignmentStrategy = ""range""
     val otherPartitionAssignmentStrategy = ""roundrobin""
 
@@ -155,7 +155,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testJoinGroupUnknownConsumerExistingGroup() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
     val otherConsumerId = ""consumerId""
     val partitionAssignmentStrategy = ""range""
 
@@ -190,7 +190,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testHeartbeatUnknownConsumerExistingGroup() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
     val otherConsumerId = ""consumerId""
     val partitionAssignmentStrategy = ""range""
 
@@ -206,7 +206,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testHeartbeatIllegalGeneration() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
     val partitionAssignmentStrategy = ""range""
 
     val joinGroupResult = joinGroup(groupId, consumerId, partitionAssignmentStrategy, DefaultSessionTimeout, isCoordinatorForGroup = true)
@@ -222,7 +222,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testValidHeartbeat() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
     val partitionAssignmentStrategy = ""range""
 
     val joinGroupResult = joinGroup(groupId, consumerId, partitionAssignmentStrategy, DefaultSessionTimeout, isCoordinatorForGroup = true)
@@ -253,8 +253,8 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
     val tp = new TopicAndPartition(""topic"", 0)
     val offset = OffsetAndMetadata(0)
 
-    val commitOffsetResult = commitOffsets(groupId, OffsetCommitRequest.DEFAULT_CONSUMER_ID,
-      OffsetCommitRequest.DEFAULT_GENERATION_ID, Map(tp -> offset), true)
+    val commitOffsetResult = commitOffsets(groupId, OffsetCommitRequest.getDefaultConsumerId,
+      OffsetCommitRequest.getDefaultGenerationId, Map(tp -> offset), true)
     assertEquals(Errors.NONE.code, commitOffsetResult(tp))
   }
 
@@ -264,7 +264,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
     val partitionAssignmentStrategy = ""range""
 
     // First start up a group (with a slightly larger timeout to give us time to heartbeat when the rebalance starts)
-    val joinGroupResult = joinGroup(groupId, JoinGroupRequest.UNKNOWN_CONSUMER_ID, partitionAssignmentStrategy,
+    val joinGroupResult = joinGroup(groupId, JoinGroupRequest.getDefaultConsumerId, partitionAssignmentStrategy,
       DefaultSessionTimeout, isCoordinatorForGroup = true)
     val assignedConsumerId = joinGroupResult._2
     val initialGenerationId = joinGroupResult._3
@@ -273,7 +273,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
 
     // Then join with a new consumer to trigger a rebalance
     EasyMock.reset(offsetManager)
-    sendJoinGroup(groupId, JoinGroupRequest.UNKNOWN_CONSUMER_ID, partitionAssignmentStrategy,
+    sendJoinGroup(groupId, JoinGroupRequest.getDefaultConsumerId, partitionAssignmentStrategy,
       DefaultSessionTimeout, isCoordinatorForGroup = true)
 
     // We should be in the middle of a rebalance, so the heartbeat should return rebalance in progress
@@ -285,8 +285,8 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testGenerationIdIncrementsOnRebalance() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
-    val otherConsumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
+    val otherConsumerId = JoinGroupRequest.getDefaultConsumerId
     val partitionAssignmentStrategy = ""range""
 
     val joinGroupResult = joinGroup(groupId, consumerId, partitionAssignmentStrategy, DefaultSessionTimeout, isCoordinatorForGroup = true)
@@ -306,7 +306,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testLeaveGroupWrongCoordinator() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
 
     val leaveGroupResult = leaveGroup(groupId, consumerId, isCoordinatorForGroup = false)
     assertEquals(Errors.NOT_COORDINATOR_FOR_CONSUMER.code, leaveGroupResult)
@@ -324,7 +324,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testLeaveGroupUnknownConsumerExistingGroup() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
     val otherConsumerId = ""consumerId""
     val partitionAssignmentStrategy = ""range""
 
@@ -340,7 +340,7 @@ class ConsumerCoordinatorResponseTest extends JUnitSuite {
   @Test
   def testValidLeaveGroup() {
     val groupId = ""groupId""
-    val consumerId = JoinGroupRequest.UNKNOWN_CONSUMER_ID
+    val consumerId = JoinGroupRequest.getDefaultConsumerId
     val partitionAssignmentStrategy = ""range""
 
     val joinGroupResult = joinGroup(groupId, consumerId, partitionAssignmentStrategy, DefaultSessionTimeout, isCoordinatorForGroup = true)


 

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;","30/Mar/19 08:40;guozhang;I'm closing this ticket as it is resolved by KAFKA-7609 now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Consumer group doesn't lend itself well for slow consumers with varying message size,KAFKA-2986,12921482,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,ztyx,ztyx,13/Dec/15 21:23,01/Sep/17 03:40,22/Mar/23 15:10,01/Sep/17 03:40,0.9.0.0,,,,,,,,,,,,,consumer,,,,3,,,,,,"I sent a related post to the Kafka mailing list, but haven't received any response: http://mail-archives.apache.org/mod_mbox/kafka-users/201512.mbox/%3CCAL%2BArfWNfkpymkNDuf6UJ06CJJ63XC1bPHeT4TSYXKjSsOpu-Q%40mail.gmail.com%3E So far, I think this is a design issue in Kafka so I'm taking the liberty of creating an issue.

*Use case:*
 - Slow consumtion. Maybe around 20 seconds per record.
 - Large variation in message size: Serialized tasks are in the range of ~300 bytes up to ~3 MB.
 - Consumtion latency (20 seconds) is independent of message size.

*Code example:*
{noformat}
while (isRunning()) {
  ConsumerRecords<String, byte[]> records = consumer.poll(100);
  for (final ConsumerRecord<String, byte[]> record : records) {
    // Handle record...
  }
}
{noformat}

*Problem:* Kafka doesn't have any issues with large messages (as long as you bump some configuration flags). However, the problem is two-fold:
- KafkaConsumer#poll is the only call that sends healthchecks.
- There is no limit as to how many messages KafkaConsumer#poll will return. The limit is only set to the total number of bytes to be prefetched. This is problematic for varying message sizes as the session timeout becomes extremelly hard to tune:
-- delay until next KafkaConsumer#poll call is proportional to the number of records returned by previous KafkaConsumer#poll call.
-- KafkaConsumer#poll will return many small records or just a few larger records. For many small messages the risk is very large of the session timeout to kick in. Raising the session timeout in the order of magnitudes required to handle the smaller messages increases the latency until a dead consumer is discovered a thousand fold.

*Proposed fixes:* I do not claim to be a Kafka expert, but two ideas are to either
 - allow add `KafkaConsumer#healthy` call to let the broker know we are still processing records; or
 - add an upper number of message limit to `KafkaConsumer#poll`. I am thinking of something like `KafkaConsumer#poll(timeout, nMaxMessages)`. This could obviously be set a configuration property instead. To avoid the broker having to look at the messages it sends, I suggest the KafkaConsumer decides how many messages it returns from poll.

*Workarounds:*
 - Have different topics for different message sizes. Makes tuning of partition prefetch easier.
 - Use another tool :)

*Questions:* Should Kafka be able to handle this case? Maybe I am using the wrong tool for this and Kafka is simply designed for high-throughput/low latency?",Java consumer API 0.9.0.0,chienle,davispw,jeffwidman,jstrom,koeninger,mazhar.shaikh.in,mjuarez,movermeyer,mskott.falcon,omkreddy,rgevers,turek@avast.com,ztyx,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3007,KAFKA-2985,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Aug 31 19:40:20 UTC 2017,,,,,,,,,,"0|i2ptrj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"30/Jan/16 22:29;ztyx;KIP 41 has since last week been passed in on the dev mailing list. Any ETA on when to start working on this? I think Jason Gustafsson expressed some interest in implementing this.;;;","01/Sep/17 03:40;omkreddy;Fixed in newer versions.  Pl reopen if you think the issue still exists
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConfigDef validators require a default value,KAFKA-3237,12938980,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,jcustenborder,jcustenborder,jcustenborder,13/Feb/16 09:12,09/Mar/16 14:01,22/Mar/23 15:10,09/Mar/16 13:57,0.9.0.0,,,,,,0.10.0.0,,,,,,,config,,,,0,,,,,,"I should be able to add a ConfigDef that has a validator but does has null as the default value. This would allow me to have a required property that is restricted to certain strings in this example. This exception should be thrown upon call to ConfigDef.parse instead. 
{code}
ConfigDef def = new ConfigDef();
def.define(key, Type.STRING, null, ValidString.in(""ONE"", ""TWO"", ""THREE""), Importance.HIGH, ""docs"");
{code}

{code}
Invalid value null for configuration test: String must be one of: ONE, TWO, THREE
org.apache.kafka.common.config.ConfigException: Invalid value null for configuration enum_test: String must be one of: ONE, TWO, THREE
	at org.apache.kafka.common.config.ConfigDef$ValidString.ensureValid(ConfigDef.java:349)
	at org.apache.kafka.common.config.ConfigDef$ConfigKey.<init>(ConfigDef.java:375)
{code}
",,ewencp,githubbot,ijuma,jcustenborder,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Mar 09 05:57:16 UTC 2016,,,,,,,,,,"0|i2sswv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"13/Feb/16 09:41;jcustenborder;There are two test cases [testInvalidDefaultRange() and testInvalidDefaultString()|https://github.com/apache/kafka/blob/trunk/clients/src/test/java/org/apache/kafka/common/config/ConfigDefTest.java#L118-L126] which test the defaults passed in with ConfigDef.define(). Does checking the default really matter? The exception text is going to be the same if checked during define or when parse() is called. Correcting the behavior in the description requires removal of these two test cases. Does that sound valid?;;;","13/Feb/16 10:01;ijuma;Why don't you use the overload of define that doesn't take a default value? That makes it required.;;;","13/Feb/16 13:40;jcustenborder;Correct me if i'm wrong but there is only one [define|https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/config/ConfigDef.java#L75] method that takes a validator. It also looks like the testing of default values is handled by the constructor of [ConfigKey|https://github.com/apache/kafka/blob/ab5ac264a71d7f895b21b4acfd93d9581dabd7c1/clients/src/main/java/org/apache/kafka/common/config/ConfigDef.java#L363]. If there is a validator present it's ran against the default. In my case I want the user to define a value that is present in an enum, that I will hit with Enum.valueOf() later. I don't want to define a default because it could be wrong for the user. Setting a validator with the constants from the enum will give me a nice error message to the user if they omit the setting.

{code}
public ConfigDef define(String name, Type type, Object defaultValue, Validator validator, Importance importance, String documentation) {
{code}





;;;","19/Feb/16 14:07;githubbot;GitHub user jcustenborder opened a pull request:

    https://github.com/apache/kafka/pull/936

    KAFKA-3237 - Remove test cases testInvalidDefaultRange() and testInva…

    Remove test cases testInvalidDefaultRange() and testInvalidDefaultString(). Defaults if not overridden will get checked on parse. Testing the defaults is unnecessary. This allows you to set that a parameter is required while setting a validator for that parameter. Added a test case testNullDefaultWithValidator that allows a null default with a validator for certain strings.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/jcustenborder/kafka KAFKA-3237

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/936.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #936
    
----
commit 249e4d781235311742d270033a13b92bea582745
Author: Jeremy Custenborder <jcustenborder@gmail.com>
Date:   2016-02-19T06:04:46Z

    KAFKA-3237 - Remove test cases testInvalidDefaultRange() and testInvalidDefaultString(). Defaults if not overridden will get checked on parse. Testing the defaults is unnecessary. This allows you to set that a parameter is required while setting a validator for that parameter. Added a test case testNullDefaultWithValidator that allows a null default with a validator for certain strings.

----
;;;","09/Mar/16 13:57;ewencp;Issue resolved by pull request 936
[https://github.com/apache/kafka/pull/936];;;","09/Mar/16 13:57;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/936
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
System tests: reduce storage footprint of collected logs,KAFKA-2927,12917445,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granders,granders,granders,02/Dec/15 10:21,11/Dec/15 09:35,22/Mar/23 15:10,11/Dec/15 09:35,,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"Looking at recent night test runs (testing.confluent.io/kafka), the storage requirements for log output from the various services has increased significantly, up to 7-10G for a single test run, up from hundreds of MB

Current breakdown:
23M	Benchmark
3.2M	ClientCompatibilityTest
613M	ConnectDistributedTest
1.1M	ConnectRestApiTest
1.5M	ConnectStandaloneFileTest
2.0M	ConsoleConsumerTest
440K	KafkaVersionTest
744K	Log4jAppenderTest
49M 	QuotaTest
3.0G	        ReplicationTest
1.2G	        TestMirrorMakerService
185M	TestUpgrade
372K	TestVerifiableProducer
2.3G	        VerifiableConsumerTest


The biggest contributors in these test suites:

ReplicationTest:
verifiable_producer.log (currently TRACE level)

VerifiableConsumerTest:
kafka server.log

TestMirrorMakerService:
verifiable_producer.log

ConnectDistributedTest:
kafka server.log


The worst offenders are therefore 
verifiable_producer.log which is logging at TRACE level, and kafka server.log which is logging at debug level

One solution is to:
1) Update the log4j configs to log separately to both an INFO level file, and another file for DEBUG at least for the worst offenders.

2) Don't collect these DEBUG (and below) logs by default; only mark for collection during failure
",,ewencp,githubbot,granders,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Dec 11 01:35:49 UTC 2015,,,,,,,,,,"0|i2p5dz:",9223372036854775807,,ewencp,,,,,,,,,,,,,,,,,,"10/Dec/15 09:48;githubbot;GitHub user granders opened a pull request:

    https://github.com/apache/kafka/pull/657

    KAFKA-2927: reduce system test storage footprint

    Split kafka logging into two levels - DEBUG and INFO, and do not collect DEBUG by default.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/confluentinc/kafka KAFKA-2927-reduce-log-footprint

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/657.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #657
    
----
commit 0dc3a1a367083f57f3cb6d8e1cd82571598d7108
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-12-10T01:09:59Z

    Split kafka logging into two levels - DEBUG and INFO, and do not collect DEBUG by default

----
;;;","11/Dec/15 09:35;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/657
;;;","11/Dec/15 09:35;ewencp;Issue resolved by pull request 657
[https://github.com/apache/kafka/pull/657];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
unsubscribe() call leaves KafkaConsumer in invalid state for manual topic-partition assignment,KAFKA-2686,12907136,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,BigAndy,BigAndy,23/Oct/15 00:27,19/Jan/16 17:41,22/Mar/23 15:10,23/Oct/15 12:01,0.9.0.0,,,,,,0.9.0.0,,,,,,,consumer,,,,0,,,,,,"The bellow code snippet demonstrated the problem.

Basically, the unsubscribe() call leaves the KafkaConsumer in a state that means poll() will always return empty record sets, even if new topic-partitions have been assigned that have messages pending.  This is because unsubscribe() sets SubscriptionState.needsPartitionAssignment to true, and assign() does not clear this flag. The only thing that clears this flag is when the consumer handles the response from a JoinGroup request.

{code}
final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);

consumer.assign(Collections.singletonList(new TopicPartition(topicName, 1)));
ConsumerRecords<String, String> records = consumer.poll(100);// <- Works, returning records

consumer.unsubscribe();   // Puts consumer into invalid state.

consumer.assign(Collections.singletonList(new TopicPartition(topicName, 2)));
records = consumer.poll(100);// <- Always returns empty record set.
{code}

",,BigAndy,githubbot,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jan 19 09:41:10 UTC 2016,,,,,,,,,,"0|i2ne1b:",9223372036854775807,,hachikuji,,,,,,,,,,,,,,,,,,"23/Oct/15 03:01;githubbot;GitHub user guozhangwang opened a pull request:

    https://github.com/apache/kafka/pull/352

    KAFKA-2686: Reset needsPartitionAssignment in SubscriptionState.assign()

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/guozhangwang/kafka K2686

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/352.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #352
    
----
commit ecc94205c0731ecf25737307aac2ffda20fc1a14
Author: Guozhang Wang <wangguoz@gmail.com>
Date:   2015-10-22T19:05:50Z

    v1

----
;;;","23/Oct/15 12:01;guozhang;Issue resolved by pull request 352
[https://github.com/apache/kafka/pull/352];;;","23/Oct/15 12:01;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/352
;;;","19/Jan/16 17:41;BigAndy;Sorry for the late response - but thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement generation/term per leader to reconcile messages correctly,KAFKA-977,12658108,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriramsub,sriramsub,sriramsub,17/Jul/13 04:32,17/May/17 00:08,22/Mar/23 15:10,16/May/17 21:01,,,,,,,0.11.0.0,,,,,,,,,,,0,,,,,,"During unclean leader election, the log messages can diverge and when the followers come back up Kafka does not reconcile correctly. To implement it correctly, we need to add a term/generation to each message and use that to reconcile.",,ijuma,junrao,sriramsub,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,338302,,,Tue May 16 16:08:27 UTC 2017,,,,,,,,,,"0|i1mcnb:",338622,,,,,,,,,,,,,,,,,,,,"22/Sep/14 15:44;sriramsub;I would like to bring this issue to discussion again. Kafka is used a lot more now for use cases other than just moving data from point A to point B. For example, consider the case where Kafka acts as the log and materialized views are created by consuming these logs. In such scenarios, it is important that the logs are consistent and do not diverge even under unclean leader elections (Replaying these replicas should create the same view). Having a generation/term is essential for log replication and it would be great for Kafka to have the same guarantees as other log replication protocols.  I would be happy to give more detailed examples for this but would want to know if we think this is an issue to address soon.;;;","28/Sep/14 23:40;junrao;Sriram,

There has been some discussion related to this in KAFKA-1211 as well. Yes, by using the leader generations per partition, we can (1) make sure replicas are consistent after unclean leader election; (2) make sure there is no data loss in the corner case discussed in KAFKA-1211 (i.e., another leader failure happens just after the follower has truncated the log, but before it has re-replicated existing committed data from the leader). The change potentially requires wire protocol and on-disk format change though. So, we need to think through how to do that in a backward compatible way.;;;","16/May/17 21:01;ijuma;Marking this as fixed since it seems to be the same as KIP-101/KAFKA-1211.;;;","16/May/17 23:59;junrao;Just to clarify. KAFKA-1211 added leader epoch in message set to prevent data losses. However, it didn't address the log divergency issue due to unclean leader election. The complexity is mostly on compacted topics. When a log is compacted, it's possible for all messages in a given leader epoch to be deleted. Therefore, it's a bit tricky to fully reconcile the log when an unclean leader election happens. This is less an issue since unclean leader election will be turned off by default from 0.11.0.;;;","17/May/17 00:08;ijuma;[~junrao], should we reopen this then? I believe there was at least one more JIRA for the log divergence issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OffsetFetchRequest returns extra partitions when input only contains unknown partitions,KAFKA-1851,12765928,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,junrao,junrao,junrao,09/Jan/15 10:43,02/Dec/15 10:03,22/Mar/23 15:10,10/Jan/15 03:34,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"When issuing an OffsetFetchRequest with an unknown topic partition, the OffsetFetchResponse unexpectedly returns all partitions in the same consumer group, in addition to the unknown partition.",,githubbot,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jan/15 10:53;junrao;kafka-1851.patch;https://issues.apache.org/jira/secure/attachment/12691026/kafka-1851.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Dec 02 02:03:43 UTC 2015,,,,,,,,,,"0|i243vb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"09/Jan/15 10:53;junrao;Created reviewboard https://reviews.apache.org/r/29751/diff/
 against branch origin/0.8.2;;;","10/Jan/15 01:48;nehanarkhede;[~junrao] Why is this a blocker?;;;","10/Jan/15 02:39;junrao;Because it doesn't match the spec of the protocol. If you pass in one partition in the request, you are expected to get only one partition in the response.;;;","10/Jan/15 03:34;junrao;Thanks for the review. Committed to both 0.8.2 and trunk.;;;","02/Dec/15 08:09;githubbot;GitHub user apovzner opened a pull request:

    https://github.com/apache/kafka/pull/609

    KAFKA-1851 Using random dir under /temp for local kdc files to avoid conflicts.

    when multiple test jobs are running.
    
    I manually separated changes for KAFKA-2851 from this PR:  https://github.com/apache/kafka/pull/570 which also had KAFKA-2825 changes.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/apovzner/kafka kafka-2851

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/609.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #609
    
----
commit d19a8533243a77f026a4f547bad40fd10dd68745
Author: Anna Povzner <anna@confluent.io>
Date:   2015-12-02T00:02:13Z

    KAFKA-1851 Using random dir under /temp for local kdc files to avoid conflicts when multiple test jobs are running.

----
;;;","02/Dec/15 10:03;githubbot;GitHub user apovzner opened a pull request:

    https://github.com/apache/kafka/pull/610

    KAFKA-1851 Using random file names for local kdc files to avoid conflicts.

    I originally tried to solve the problem by using tempfile, and creating and using scp() utility method that created a random local temp file every time it was called. However, it required passing miniKdc object to SecurityConfig setup_node which looked very invasive, since many tests use this method. Here is the PR for that, which I think we will close: https://github.com/apache/kafka/pull/609
    
    This change is the least invasive change to solve conflicts between multiple tests jobs. 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/apovzner/kafka kafka_2851_01

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/610.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #610
    
----
commit 4c9c76825b9dff5fb509eac01592d37f357b5775
Author: Anna Povzner <anna@confluent.io>
Date:   2015-12-02T01:55:08Z

    KAFKA-2851:  Using random file names for local kdc files to avoid conflicts

----
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SIGINT during Kafka server startup can leave server deadlocked,KAFKA-2468,12858536,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,singhashish,singhashish,singhashish,25/Aug/15 15:08,28/Aug/15 11:43,22/Mar/23 15:10,28/Aug/15 11:43,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"KafkaServer on receiving a SIGINT will try to shutdown and if this happens while the server is starting up, it will get into deadlock.

Thread dump after deadlock
{code}
2015-08-24 22:03:52
Full thread dump Java HotSpot(TM) 64-Bit Server VM (24.55-b03 mixed mode):

""Attach Listener"" daemon prio=5 tid=0x00007fc08e827800 nid=0x5807 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Thread-2"" prio=5 tid=0x00007fc08b9de000 nid=0x6b03 waiting for monitor entry [0x000000011ad3a000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at java.lang.Shutdown.exit(Shutdown.java:212)
	- waiting to lock <0x00000007bae86ac0> (a java.lang.Class for java.lang.Shutdown)
	at java.lang.Runtime.exit(Runtime.java:109)
	at java.lang.System.exit(System.java:962)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:46)
	at kafka.Kafka$$anon$1.run(Kafka.scala:65)

""SIGINT handler"" daemon prio=5 tid=0x00007fc08ca51800 nid=0x6503 in Object.wait() [0x000000011aa31000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x00000007bcb40610> (a kafka.Kafka$$anon$1)
	at java.lang.Thread.join(Thread.java:1281)
	- locked <0x00000007bcb40610> (a kafka.Kafka$$anon$1)
	at java.lang.Thread.join(Thread.java:1355)
	at java.lang.ApplicationShutdownHooks.runHooks(ApplicationShutdownHooks.java:106)
	at java.lang.ApplicationShutdownHooks$1.run(ApplicationShutdownHooks.java:46)
	at java.lang.Shutdown.runHooks(Shutdown.java:123)
	at java.lang.Shutdown.sequence(Shutdown.java:167)
	at java.lang.Shutdown.exit(Shutdown.java:212)
	- locked <0x00000007bae86ac0> (a java.lang.Class for java.lang.Shutdown)
	at java.lang.Terminator$1.handle(Terminator.java:52)
	at sun.misc.Signal$1.run(Signal.java:212)
	at java.lang.Thread.run(Thread.java:745)

""RMI TCP Accept-0"" daemon prio=5 tid=0x00007fc08c164000 nid=0x5c07 runnable [0x0000000119fe8000]
   java.lang.Thread.State: RUNNABLE
	at java.net.PlainSocketImpl.socketAccept(Native Method)
	at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:398)
	at java.net.ServerSocket.implAccept(ServerSocket.java:530)
	at java.net.ServerSocket.accept(ServerSocket.java:498)
	at sun.management.jmxremote.LocalRMIServerSocketFactory$1.accept(LocalRMIServerSocketFactory.java:52)
	at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:388)
	at sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:360)
	at java.lang.Thread.run(Thread.java:745)

""Service Thread"" daemon prio=5 tid=0x00007fc08d015000 nid=0x5503 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""C2 CompilerThread1"" daemon prio=5 tid=0x00007fc08c82b000 nid=0x5303 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""C2 CompilerThread0"" daemon prio=5 tid=0x00007fc08c82a000 nid=0x5103 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Signal Dispatcher"" daemon prio=5 tid=0x00007fc08c829800 nid=0x4f03 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Surrogate Locker Thread (Concurrent GC)"" daemon prio=5 tid=0x00007fc08d002000 nid=0x400b waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

""Finalizer"" daemon prio=5 tid=0x00007fc08d012800 nid=0x3b03 in Object.wait() [0x0000000117ee6000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x00000007bae05568> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)
	- locked <0x00000007bae05568> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:189)

""Reference Handler"" daemon prio=5 tid=0x00007fc08c803000 nid=0x3903 in Object.wait() [0x0000000117de3000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x00000007bae050f0> (a java.lang.ref.Reference$Lock)
	at java.lang.Object.wait(Object.java:503)
	at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)
	- locked <0x00000007bae050f0> (a java.lang.ref.Reference$Lock)

""main"" prio=5 tid=0x00007fc08d000800 nid=0x1303 waiting for monitor entry [0x000000010f353000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at java.lang.Shutdown.exit(Shutdown.java:212)
	- waiting to lock <0x00000007bae86ac0> (a java.lang.Class for java.lang.Shutdown)
	at java.lang.Runtime.exit(Runtime.java:109)
	at java.lang.System.exit(System.java:962)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:35)
	at kafka.Kafka$.main(Kafka.scala:69)
	at kafka.Kafka.main(Kafka.scala)

""VM Thread"" prio=5 tid=0x00007fc08b83b000 nid=0x3703 runnable 

""Gang worker#0 (Parallel GC Threads)"" prio=5 tid=0x00007fc08d00f800 nid=0x2103 runnable 

""Gang worker#1 (Parallel GC Threads)"" prio=5 tid=0x00007fc08b80e000 nid=0x2303 runnable 

""Gang worker#2 (Parallel GC Threads)"" prio=5 tid=0x00007fc08c801000 nid=0x2503 runnable 

""Gang worker#3 (Parallel GC Threads)"" prio=5 tid=0x00007fc08c801800 nid=0x2703 runnable 

""Gang worker#4 (Parallel GC Threads)"" prio=5 tid=0x00007fc08c804000 nid=0x2903 runnable 

""Gang worker#5 (Parallel GC Threads)"" prio=5 tid=0x00007fc08c804800 nid=0x2b03 runnable 

""Gang worker#6 (Parallel GC Threads)"" prio=5 tid=0x00007fc08c805000 nid=0x2d03 runnable 

""Gang worker#7 (Parallel GC Threads)"" prio=5 tid=0x00007fc08c806000 nid=0x2f03 runnable 

""Concurrent Mark-Sweep GC Thread"" prio=5 tid=0x00007fc08c806800 nid=0x3503 runnable 
""Gang worker#0 (Parallel CMS Threads)"" prio=5 tid=0x00007fc08c0bd800 nid=0x3103 runnable 

""Gang worker#1 (Parallel CMS Threads)"" prio=5 tid=0x00007fc08c0be800 nid=0x3303 runnable 

""VM Periodic Task Thread"" prio=5 tid=0x00007fc08c155000 nid=0x5d03 waiting on condition 

JNI global references: 239
{code}",,ewencp,githubbot,guozhang,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Aug 28 03:43:56 UTC 2015,,,,,,,,,,"0|i2jbrj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"25/Aug/15 15:36;githubbot;GitHub user SinghAsDev opened a pull request:

    https://github.com/apache/kafka/pull/167

    KAFKA-2468: SIGINT during Kafka server startup can leave server deadlocked

    As we handle exceptions or invalid states in Kafka server by shutting it down, there is no reason to use exit() and not halt() in shutdown itself.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/SinghAsDev/kafka KAFKA-2468

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/167.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #167
    
----
commit 6b5954fb2747f9c94289ad4a75873131b7f55d0a
Author: asingh <asingh@cloudera.com>
Date:   2015-08-25T07:34:42Z

    KAFKA-2468: SIGINT during Kafka server startup can leave server deadlocked

----
;;;","26/Aug/15 07:52;ewencp;Does this actually solve the problem? The docs on Runtime.exit say:

bq. If this method is invoked after the virtual machine has begun its shutdown sequence then if shutdown hooks are being run this method will block indefinitely. If shutdown hooks have already been run and on-exit finalization has been enabled then this method halts the virtual machine with the given status code if the status is nonzero; otherwise, it blocks indefinitely. 

Since the issue here seems to be that System.exit gets invoked due to an exception from KafkaServerStartable.startup, that invokes the shtudown hook, which invokes KafkaServerStartable.shutdown, which calls KafkaServer.shutdown, which throws an exception and then KafkaServerStartable's exception handler invokes System.exit. If we replace one with Runtime.exit, doesn't the above comment imply it will also block indefinitely since the first System.exit in the scenario above will still invoke Runtime.exit (the first call), then the subsequent Runtime.exit call via the shutdown hook's call to KafkaServerStartable.shutdown will actually end up waiting on itself (since it blocks until shutdown hooks are complete, but it is running in a shutdown hook)?

It seems like a better solution would be to just use a flag. Set it to true after startup() returns, then in shutdown(), check it before invoking KafkaServer.shutdown() so we don't ever produce the IllegalStateException.;;;","26/Aug/15 08:12;singhashish;[~ewencp] unlike exit(), halt() forcibly terminates the jvm. Below is an excerpt from [here|http://geekexplains.blogspot.com/2008/06/runtimeexit-vs-runtimehalt-in-java.html].

{quote}
You might have noticed so far that the difference between the two methods is that Runtime.exit() invokes the shutdown sequence of the underlying JVM whereas Runtime.halt() forcibly terminates the JVM process. So, Runtime.exit() causes the registered shutdown hooks to be executed and then also lets all the uninvoked finalizers to be executed before the JVM process shuts down whereas Runtime.halt() simply terminates the JVM process immediately and abruptly.
{quote}

I have tested that the current PR resolves the issue. I did think about protecting exits with a flag. However, exit() can be called in Kafka.scala as well. Also, it does not make a lot of sense to wait for anything in catch block of shutdown.;;;","26/Aug/15 10:52;ewencp;[~ashi.khurana@gmail.com] Ok, makes sense. I just got stuck on the exit methods and completely missed that it was calling halt instead. LGTM.;;;","26/Aug/15 11:13;singhashish;[~guozhang] could you review and help with getting this committed?;;;","28/Aug/15 11:43;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/167
;;;","28/Aug/15 11:43;guozhang;Issue resolved by pull request 167
[https://github.com/apache/kafka/pull/167];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Delete consumer offsets from kafka once the topic is deleted,KAFKA-2000,12779167,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,omkreddy,sriharsha,sriharsha,04/Mar/15 04:06,25/Feb/18 14:56,22/Mar/23 15:10,26/Jan/17 00:18,,,,,,,0.10.2.0,0.11.0.0,,,,,,,,,,2,newbie++,,,,,,,baluchicken,boniek,ecomar,fcorreia,githubbot,hachikuji,ijuma,jeffwidman,memelet,parth.brahmbhatt,sriharsha,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-4456,,,,,,,,,,,,,,,,,,"31/Mar/15 05:47;sriharsha;KAFKA-2000.patch;https://issues.apache.org/jira/secure/attachment/12708244/KAFKA-2000.patch","04/May/15 01:39;sriharsha;KAFKA-2000_2015-05-03_10:39:11.patch;https://issues.apache.org/jira/secure/attachment/12730040/KAFKA-2000_2015-05-03_10%3A39%3A11.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Feb 25 06:56:29 UTC 2018,,,,,,,,,,"0|i26b53:",9223372036854775807,,hachikuji,,,,,,,,,,,,,,,,,,"31/Mar/15 05:47;sriharsha;Created reviewboard https://reviews.apache.org/r/32650/diff/
 against branch origin/trunk;;;","04/May/15 01:39;sriharsha;Updated reviewboard https://reviews.apache.org/r/32650/diff/
 against branch origin/trunk;;;","18/Dec/15 00:58;ijuma;Is this still applicable?;;;","18/Dec/15 01:18;ijuma;Looks like it is, `GroupMetadataManager` has the following code:

{code}
val expiredOffsets = offsetsCache.filter { case (groupTopicPartition, offsetAndMetadata) =>
  offsetAndMetadata.expireTimestamp < startMs
}
{code}

[~harsha_ch], do you want to submit a PR with this change?;;;","18/Dec/15 02:54;sriharsha;[~ijuma] Yes.;;;","19/Dec/15 03:27;parth.brahmbhatt;Talked to [~harsha_ch] , I will submit an updated patch for this one today.;;;","22/Dec/15 04:18;githubbot;GitHub user Parth-Brahmbhatt opened a pull request:

    https://github.com/apache/kafka/pull/704

    KAFKA-2000: Delete topic should also delete consumer offsets.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/Parth-Brahmbhatt/kafka KAFKA-2000

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/704.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #704
    
----
commit ceae0b7031d297a7db6664b435bb3cdc55228646
Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>
Date:   2015-12-18T20:35:32Z

    KAFKA-2000: Delete topic should also delete consumer offsets.

----
;;;","22/Dec/15 18:47;sslavic;I'm still on 0.8.2.x and it's hurting my system smoke tests, reusing same topics over and over again in the test, (consumer) state preserved - deleting topic, creating it, publishing message, not being able to read just published message. Now have to introduce dummy read after topic is recreated, just to have existing offset fall outside of the valid range, and get reset.

Curious, are there any plans to backport this fix to 0.9.0.x or even 0.8.2.x?;;;","14/Sep/16 01:00;githubbot;GitHub user omkreddy opened a pull request:

    https://github.com/apache/kafka/pull/1850

    KAFKA-2000: Delete topic should also delete consumer offsets.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/omkreddy/kafka KAFKA-2700-DELETE

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1850.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1850
    
----
commit 3bcb8232b6f184e232797519b1a829e74d0f37b1
Author: Manikumar Reddy O <manikumar.reddy@gmail.com>
Date:   2016-09-13T16:07:41Z

    KAFKA-2000: Delete topic should also delete consumer offsets.

----
;;;","21/Jan/17 03:28;hachikuji;It would be nice to get this fixed. The patch from [~parth.brahmbhatt] has review comments from Feb. 2016 which have not been addressed. Perhaps [~omkreddy] can rebase the patch posted above and we can try to get it merged?;;;","21/Jan/17 04:45;jeffwidman;If neither of them is interested, I'm happy to cleanup the existing patch to get it merged into 0.10.2. The test suite at my work would benefit from this. Just let me know.;;;","21/Jan/17 05:16;sriharsha;[~jeffwidman] 

[~omkreddy] working on it.;;;","26/Jan/17 00:18;sriharsha;Issue resolved by pull request 1850
[https://github.com/apache/kafka/pull/1850];;;","26/Jan/17 00:18;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/1850
;;;","25/Feb/18 14:56;githubbot;hachikuji closed pull request #704: KAFKA-2000: Delete topic should also delete consumer offsets.
URL: https://github.com/apache/kafka/pull/704
 
 
   

This is a PR merged from a forked repository.
As GitHub hides the original diff on merge, it is displayed below for
the sake of provenance:

As this is a foreign pull request (from a fork), the diff is supplied
below (as it won't show otherwise due to GitHub magic):

diff --git a/core/src/main/scala/kafka/coordinator/GroupMetadataManager.scala b/core/src/main/scala/kafka/coordinator/GroupMetadataManager.scala
index 48818c3edff..56dc1139cf1 100644
--- a/core/src/main/scala/kafka/coordinator/GroupMetadataManager.scala
+++ b/core/src/main/scala/kafka/coordinator/GroupMetadataManager.scala
@@ -62,14 +62,14 @@ class GroupMetadataManager(val brokerId: Int,
   /* group metadata cache */
   private val groupsCache = new Pool[String, GroupMetadata]
 
-  /* partitions of consumer groups that are being loaded, its lock should be always called BEFORE offsetExpireLock and the group lock if needed */
+  /* partitions of consumer groups that are being loaded, its lock should be always called BEFORE removeOffsetLock and the group lock if needed */
   private val loadingPartitions: mutable.Set[Int] = mutable.Set()
 
   /* partitions of consumer groups that are assigned, using the same loading partition lock */
   private val ownedPartitions: mutable.Set[Int] = mutable.Set()
 
-  /* lock for expiring stale offsets, it should be always called BEFORE the group lock if needed */
-  private val offsetExpireLock = new ReentrantReadWriteLock()
+  /* lock for removing stale/deleted topic's offsets, it should be always called BEFORE the group lock if needed */
+  private val removeOffsetLock = new ReentrantReadWriteLock()
 
   /* shutting down flag */
   private val shuttingDown = new AtomicBoolean(false)
@@ -163,6 +163,19 @@ class GroupMetadataManager(val brokerId: Int,
     }
   }
 
+  /**
+   * Removes all the groups and corresponding offsets for this topicPartition.
+   * @param topicPartition
+   */
+  def removeOffsetsByTopicPartition(topicPartition: TopicPartition): Unit = {
+    val startMs = SystemTime.milliseconds
+    val numberOfDeletedExpiredOffsets = inWriteLock(removeOffsetLock) {
+      val offsetsToBeDeleted = offsetsCache.filter(_._1.topicPartition == TopicAndPartition(topicPartition.topic, topicPartition.partition))
+      deleteOffsets(offsetsToBeDeleted)
+    }
+    info(s""Removed ${numberOfDeletedExpiredOffsets} offsets in ${SystemTime.milliseconds - startMs} milliseconds for topicPartition ${topicPartition}"")
+  }
+
   def prepareStoreGroup(group: GroupMetadata,
                         groupAssignment: Map[String, Array[Byte]],
                         responseCallback: Short => Unit): DelayedStore = {
@@ -365,7 +378,7 @@ class GroupMetadataManager(val brokerId: Int,
             var currOffset = log.logSegments.head.baseOffset
             val buffer = ByteBuffer.allocate(config.loadBufferSize)
             // loop breaks if leader changes at any time during the load, since getHighWatermark is -1
-            inWriteLock(offsetExpireLock) {
+            inWriteLock(removeOffsetLock) {
               val loadedGroups = mutable.Map[String, GroupMetadata]()
               val removedGroups = mutable.Set[String]()
 
@@ -534,53 +547,62 @@ class GroupMetadataManager(val brokerId: Int,
     debug(""Collecting expired offsets."")
     val startMs = SystemTime.milliseconds
 
-    val numExpiredOffsetsRemoved = inWriteLock(offsetExpireLock) {
+    val numExpiredOffsetsRemoved = inWriteLock(removeOffsetLock) {
       val expiredOffsets = offsetsCache.filter { case (groupTopicPartition, offsetAndMetadata) =>
         offsetAndMetadata.expireTimestamp < startMs
       }
 
-      debug(""Found %d expired offsets."".format(expiredOffsets.size))
+      deleteOffsets(expiredOffsets)
+    }
+
+    info(s""Removed ${numExpiredOffsetsRemoved} expired offsets in ${SystemTime.milliseconds - startMs} milliseconds."")
+  }
+
+  /**
+   * Deletes the provided offsets.
+   * @param offsetsToBeDeleted collection of offsets that needs to be deleted.
+   * @return number of deleted offsets.
+   */
+  def deleteOffsets(offsetsToBeDeleted: scala.Iterable[(GroupTopicPartition, OffsetAndMetadata)]): Int = {
+    debug(""Found %d offsets that needs to be removed."".format(offsetsToBeDeleted.size))
 
-      // delete the expired offsets from the table and generate tombstone messages to remove them from the log
-      val tombstonesForPartition = expiredOffsets.map { case (groupTopicAndPartition, offsetAndMetadata) =>
-        val offsetsPartition = partitionFor(groupTopicAndPartition.group)
-        trace(""Removing expired offset and metadata for %s: %s"".format(groupTopicAndPartition, offsetAndMetadata))
+    // delete the offsets from the table and generate tombstone messages to remove them from the log
+    val tombstonesForPartition = offsetsToBeDeleted.map { case (groupTopicAndPartition, offsetAndMetadata) =>
+      val offsetsPartition = partitionFor(groupTopicAndPartition.group)
+      trace(""Removing offset and metadata for %s: %s"".format(groupTopicAndPartition, offsetAndMetadata))
 
-        offsetsCache.remove(groupTopicAndPartition)
+      offsetsCache.remove(groupTopicAndPartition)
 
-        val commitKey = GroupMetadataManager.offsetCommitKey(groupTopicAndPartition.group,
-          groupTopicAndPartition.topicPartition.topic, groupTopicAndPartition.topicPartition.partition)
+      val commitKey = GroupMetadataManager.offsetCommitKey(groupTopicAndPartition.group,
+        groupTopicAndPartition.topicPartition.topic, groupTopicAndPartition.topicPartition.partition)
 
-        (offsetsPartition, new Message(bytes = null, key = commitKey))
-      }.groupBy { case (partition, tombstone) => partition }
+      (offsetsPartition, new Message(bytes = null, key = commitKey))
+    }.groupBy { case (partition, tombstone) => partition }
 
-      // Append the tombstone messages to the offset partitions. It is okay if the replicas don't receive these (say,
-      // if we crash or leaders move) since the new leaders will get rid of expired offsets during their own purge cycles.
-      tombstonesForPartition.flatMap { case (offsetsPartition, tombstones) =>
-        val partitionOpt = replicaManager.getPartition(GroupCoordinator.GroupMetadataTopicName, offsetsPartition)
-        partitionOpt.map { partition =>
-          val appendPartition = TopicAndPartition(GroupCoordinator.GroupMetadataTopicName, offsetsPartition)
-          val messages = tombstones.map(_._2).toSeq
+    // Append the tombstone messages to the offset partitions. It is okay if the replicas don't receive these (say,
+    // if we crash or leaders move) since the new leaders will get rid of expired offsets during their own purge cycles.
+    tombstonesForPartition.flatMap { case (offsetsPartition, tombstones) =>
+      val partitionOpt = replicaManager.getPartition(GroupCoordinator.GroupMetadataTopicName, offsetsPartition)
+      partitionOpt.map { partition =>
+        val appendPartition = TopicAndPartition(GroupCoordinator.GroupMetadataTopicName, offsetsPartition)
+        val messages = tombstones.map(_._2).toSeq
 
-          trace(""Marked %d offsets in %s for deletion."".format(messages.size, appendPartition))
+        trace(""Marked %d offsets in %s for deletion."".format(messages.size, appendPartition))
 
-          try {
-            // do not need to require acks since even if the tombstone is lost,
-            // it will be appended again in the next purge cycle
-            partition.appendMessagesToLeader(new ByteBufferMessageSet(config.offsetsTopicCompressionCodec, messages: _*))
-            tombstones.size
-          }
-          catch {
-            case t: Throwable =>
-              error(""Failed to mark %d expired offsets for deletion in %s."".format(messages.size, appendPartition), t)
-              // ignore and continue
-              0
-          }
+        try {
+          // do not need to require acks since even if the tombsone is lost,
+          // it will be appended again in the next purge cycle
+          partition.appendMessagesToLeader(new ByteBufferMessageSet(config.offsetsTopicCompressionCodec, messages: _*))
+          tombstones.size
         }
-      }.sum
-    }
-
-    info(""Removed %d expired offsets in %d milliseconds."".format(numExpiredOffsetsRemoved, SystemTime.milliseconds - startMs))
+        catch {
+          case t: Throwable =>
+            error(""Failed to mark %d offsets for deletion in %s."".format(messages.size, appendPartition), t)
+            // ignore and continue
+            0
+        }
+      }
+    }.sum
   }
 
   private def getHighWatermark(partitionId: Int): Long = {
diff --git a/core/src/main/scala/kafka/server/KafkaApis.scala b/core/src/main/scala/kafka/server/KafkaApis.scala
index f2e95332e8f..09cb06196ab 100644
--- a/core/src/main/scala/kafka/server/KafkaApis.scala
+++ b/core/src/main/scala/kafka/server/KafkaApis.scala
@@ -164,6 +164,7 @@ class KafkaApis(val requestChannel: RequestChannel,
     val response =
       if (authorize(request.session, ClusterAction, Resource.ClusterResource)) {
         val (result, error) = replicaManager.stopReplicas(stopReplicaRequest)
+        stopReplicaRequest.partitions.asScala.foreach(topicPartition => coordinator.groupManager.removeOffsetsByTopicPartition(topicPartition))
         new StopReplicaResponse(error, result.asInstanceOf[Map[TopicPartition, JShort]].asJava)
       } else {
         val result = stopReplicaRequest.partitions.asScala.map((_, new JShort(Errors.CLUSTER_AUTHORIZATION_FAILED.code))).toMap
diff --git a/core/src/test/scala/unit/kafka/server/OffsetCommitTest.scala b/core/src/test/scala/unit/kafka/server/OffsetCommitTest.scala
index 1d5148b0e15..cffe852b6a8 100755
--- a/core/src/test/scala/unit/kafka/server/OffsetCommitTest.scala
+++ b/core/src/test/scala/unit/kafka/server/OffsetCommitTest.scala
@@ -17,9 +17,10 @@
 
 package kafka.server
 
+import kafka.admin.AdminUtils
 import kafka.api.{GroupCoordinatorRequest, OffsetCommitRequest, OffsetFetchRequest}
 import kafka.consumer.SimpleConsumer
-import kafka.common.{OffsetMetadata, OffsetMetadataAndError, OffsetAndMetadata, TopicAndPartition}
+import kafka.common._
 import kafka.utils._
 import kafka.utils.TestUtils._
 import kafka.zk.ZooKeeperTestHarness
@@ -49,7 +50,7 @@ class OffsetCommitTest extends ZooKeeperTestHarness {
   @Before
   override def setUp() {
     super.setUp()
-    val config: Properties = createBrokerConfig(1, zkConnect)
+    val config: Properties = createBrokerConfig(1, zkConnect, enableDeleteTopic = true)
     config.setProperty(KafkaConfig.OffsetsTopicReplicationFactorProp, ""1"")
     config.setProperty(KafkaConfig.OffsetsRetentionCheckIntervalMsProp, retentionCheckInterval.toString)
     val logDirPath = config.getProperty(""log.dir"")
@@ -307,4 +308,33 @@ class OffsetCommitTest extends ZooKeeperTestHarness {
     assertEquals(Errors.UNKNOWN_TOPIC_OR_PARTITION.code, commitResponse.commitStatus.get(TopicAndPartition(topic1, 0)).get)
     assertEquals(Errors.NONE.code, commitResponse.commitStatus.get(TopicAndPartition(topic2, 0)).get)
   }
+
+  @Test
+  def testOffsetsDeleteAfterTopicDeletion() {
+    // set up topic partition
+    val topic = ""topic""
+    val topicPartition = TopicAndPartition(topic, 0)
+    createTopic(zkUtils, topic, servers = Seq(server), numPartitions = 1)
+
+    val fetchRequest = OffsetFetchRequest(group, Seq(TopicAndPartition(topic, 0)))
+
+    // v0 version commit request with commit timestamp set to -1
+    // should not expire
+    val commitRequest0 = OffsetCommitRequest(
+      groupId = group,
+      requestInfo = immutable.Map(topicPartition -> OffsetAndMetadata(1L, ""metadata"", -1L)),
+      versionId = 0
+    )
+    assertEquals(Errors.NONE.code(), simpleConsumer.commitOffsets(commitRequest0).commitStatus.get(topicPartition).get)
+
+    // start topic deletion
+    AdminUtils.deleteTopic(zkUtils, topic)
+    TestUtils.verifyTopicDeletion(zkUtils, topic, 1, Seq(server))
+    Thread.sleep(retentionCheckInterval * 2)
+
+    // check if offsets deleted
+    val offsetMetadataAndErrorMap = simpleConsumer.fetchOffsets(fetchRequest)
+    val offsetMetadataAndError = offsetMetadataAndErrorMap.requestInfo(topicPartition)
+    assertEquals(OffsetMetadataAndError.NoOffset, offsetMetadataAndError)
+  }
 }


 

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create topic support and new ZK data structures for intra-cluster replication,KAFKA-47,12514684,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,junrao,,20/Jul/11 05:32,08/Sep/17 02:20,22/Mar/23 15:10,08/Sep/17 02:20,,,,,,,,,,,,,,,,,,0,,,,,,"We need the DDL syntax for creating new topics. May need to use things like javaCC. Also, we need to register new data structures in ZK accordingly.",,alexfo,lanzaa,omkreddy,rektide,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-50,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,64997,,,Thu Sep 07 18:20:54 UTC 2017,,,,,,,,,,"0|i029wv:",11207,,,,,,,,,,,,,,,,,,,,"15/Aug/11 05:40;jkreps;I recommend we just make a command line tool rather than a formal ddl. That will be more sysadmin friendly and easier to script up.

We should also think through how this will interact with topic auto-creation which is a feature we are currently reliant on.;;;","16/Aug/11 00:49;junrao;Yes, I agree that we can start with just a command line tool. 

For auto-creation of a topic, we can optionally enable the producer to automatically create a non-existing topic (with some preconfigured # partitions, replication factors, etc), using the same underlying logic of the command line tool.;;;","14/Nov/11 08:25;junrao;Some thoughts on the create/delete topic support.

1. What if the create process dies in the middle of the creation?
The create process will create 1 ZK node like the following for each partition in the topic. 
/brokers/topics/[topic]/[partition_id]/replicas --> {replica_id : broker_id …}

This means that if the process fails in the middle, some of the partitions may not be created. Ideally, we should probably use the multi-row transaction support feature in ZK (ZOOKEEPER-965), which will be released in ZK 3.4. Since this should be a relatively rare event, for now, we can probably just do this as a best effort. If the create command fails in the middle, we can always delete the topic and create it gain.

2. How to delete a topic?
We can simply delete all entries in /brokers/topics/[topic] in ZK. On receiving the delete event, each replica will delete its corresponding local log directory. 

A broker could be down when the delete command was issued. When the broker is restarted, it should check if a topic still exists in ZK. If not, it will delete the local log directory.

A more subtle issue can happen when a topic is deleted and recreated while a broker is down. When this broker is restarted, it should recognize that its local log directory is out of date. It should delete everything in the local log directory and create a new one. One way to do this is to store a version id (could be just a timestamp) in /brokers/topics/[topic]. The same version id is also stored in a .version file in the local log directory when it's first created. By comparing the version id in the local log directory and in ZK, a broker can detect when a local log directory is out of date during startup.

3. Where to store the log locally?
Currently, a log is stored in {log.dir}/topicname-x for partition x. Now, a partition can have multiple replicas. One possibility is {log.dir}/topicname/x-y for partition x and replica y.

4. What about auto-creation?
One possibility is to add an option in the producer so that it can automatically create a topic if the topic doesn't exist in ZK yet.

5. I'd like to break this jira into 2 parts. The first part just adds the create/delete command and the corresponding ZK path. The second part will change the local log directory, add the auto topic creation support, and simply route the produce/consume requests to the first replica of each partition. This can be a separate jira.
;;;","14/Nov/11 14:04;jkreps;1,2. The other approach would be to implement a zk structure representing some kind of queue of actions to be carried out for each node. I think the delete case may be a special case of needing to reliably issue a command to a broker. This could be a CREATE or DELETE command or some kind of other operational command (e.g. MIGRATE-PARTITION). I think this was why Kishore and co took the zk route for communciation for Helix, I think this is one of the problems they were trying to solve.

The other question is how this is initiated. Do we add some administrative APIs to the brokers or is the communication through zookeeper? Either is fine, but we should be consistent about how we do administrative actions. I recommend we brainstorm a list of admin type actions we might want and try to generalize something that will work for all them.

3. As a matter of taste, I like what you propose for the directory structure, topic/x-y, better then what we currently do. This does mean needing to rename lots of files when there is a mastership change, though.

4. One concern is that auto-create may be really slow if we are blocking on acknowledgement from all the brokers. Not sure if this is a major problem.;;;","15/Nov/11 01:40;junrao;1,2. It seems to me it's simpler to have all brokers read from a single ZK path that stores the source of true, instead of broadcasting messages to every broker. For the latter, one has to further worry about what if only part of but not all messages are posted.

To be consistent, I think all administrative commands simply create some data structures in ZK and should complete very quickly. Each broker watches those ZK paths and take actions accordingly.

3. The directory name is only tied to replica id and won't change with a mastership change. The mastership info is recorded in ZK, not in directory  names.

4.  Typically, auto-create should complete very quickly since it just writes a few data structures in ZK.;;;","08/Feb/12 22:22;prashanth.menon;Does how we store the logs locally still require changes in light of the modifications we've made to the protocol?  A replica for partition X is stored at most once on a broker so with the current naming conventon we'll never run into conflicts.  Perhaps to be explicit that a certain directory is a replica, we could put them into {log.dir}/topicname/replica/partitionId but I don't think it's entirely necessary? ;;;","09/Feb/12 00:39;junrao;Prashanth, good question.

Yes, we could continue using the current log structure {log.dir}/topicname-partitionid. The only thing is that we would like to store some per topic metadata on disk, e.g., the version id (creation time) of a topic (to deal with some of the edge cases during topic re-creation). With the current structure, we either have to duplicate the topic metadata in each partition directory or deterministically pick one partition (like the smallest one) to store the metadata. Neither is ideal. It's much cleaner if we use the new structure {log.dir}/topicname/partitionid. Then the topic metadata can be stored under {log.dir}/topicname.;;;","09/Feb/12 01:45;tgautier;Hmm, if you guys are considering changing something about the log structure might I request that you consider doing something to ease the pain when there are 1,000's or 10,000's topics? 

The current structure doesn't work well since most filesystems tend to have problems when you store 20k or more directories in one directory.

A hashing scheme is a good solution.  The tradeoff is that it is much more difficult to find the topic directory by hand.  A hash of even 10 top level directories would afford 10x more total topics (currently, the practical limit appears to hover around 20k, so 10x would give us 200k) -- this would probably be sufficient for my needs. ;;;","09/Feb/12 02:31;prashanth.menon;Just my two cents here. Hashing (even consistent) is a logical idea, the caveat being that it will require maintaining an upper bound on the number of topic ""buckets"" to avoid renaming and moving a bunch of large files around if we don't enforce such a limit.  To solve the other issue of not being able to quickly determine which bucket a topic falls into by-hand, we could maintain a file at the bucket-level that lists which topic belongs in which bucket, much like the metadata file Jun mentioned earlier.  It's extra overhead on the part of the system, I'm not familiar with a single broker requiring so many topics but it's certainly conceivable.;;;","09/Feb/12 08:07;junrao;By using {log.dir}/topicname/partitionid, we already reduce the # of directories from # total partitions to # total topics. We can think a bit more how to improve it further. This should probably be a separate jira.;;;","08/Sep/17 02:20;omkreddy;Closing this umbrella JIRA as all tasks are resolved.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Movement of throughput throttler to common broke upgrade tests,KAFKA-2807,12912082,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,ewencp,granders,granders,11/Nov/15 15:11,25/Feb/23 07:24,22/Mar/23 15:10,13/Nov/15 03:13,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"In order to run compatibility tests with an 0.8.2 producer, and using VerifiableProducer, we use the 0.8.2 kafka-run-tools.sh classpath augmented by the 0.9.0 tools and tools dependencies classpaths.

Recently, some refactoring efforts moved ThroughputThrottler to org.apache.kafka.common.utils package, but this breaks the existing compatibility tests:

{code}
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/kafka/common/utils/ThroughputThrottler
        at org.apache.kafka.tools.VerifiableProducer.main(VerifiableProducer.java:334)
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.utils.ThroughputThrottler
        at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
        ... 1 more
{code}

Given the need to be able to run VerifiableProducer against 0.8.X, I'm not sure VerifiableProducer can depend on org.apache.kafka.common.utils at this point in time. ",,ewencp,githubbot,granders,gwenshap,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-14760,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 12 19:13:49 UTC 2015,,,,,,,,,,"0|i2o8e7:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"12/Nov/15 03:24;ewencp;[~geoffra] Hmm, I moved it into common because that seemed the logical place given it was now to be used by both tools and copycat-tools classes. I think we could probably resolve this by moving it back to tools and have copycat-tools depend on tools. It's a little awkward, but I don't think would cause any problems for copycat-tools.;;;","12/Nov/15 03:47;nehanarkhede;We don't want our tests to fail, so marking this as a blocker.;;;","12/Nov/15 05:08;githubbot;GitHub user ewencp opened a pull request:

    https://github.com/apache/kafka/pull/499

    KAFKA-2807: Move ThroughputThrottler back to tools jar to fix upgrade tests.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ewencp/kafka kafka-2807-relocate-throughput-throttler

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/499.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #499
    
----
commit 410e876f2466c0fabd2c5e3a1ba9252375a35939
Author: Ewen Cheslack-Postava <me@ewencp.org>
Date:   2015-11-11T20:14:49Z

    KAFKA-2807: Move ThroughputThrottler back to tools jar to fix upgrade tests.

----
;;;","12/Nov/15 05:09;ewencp;Tested the upgrade test and a copycat test locally, we can rerun the full suite if necessary. This patch required a bit of renaming in the build file because Gradle does not like : in project names.;;;","12/Nov/15 07:55;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/499
;;;","12/Nov/15 07:55;gwenshap;Issue resolved by pull request 499
[https://github.com/apache/kafka/pull/499];;;","13/Nov/15 02:55;ewencp;Turns out the original patch actually broke things. The way the projects are named with colons is important in gradle and renaming them actually pointed the projects at the wrong directories.

Fundamentally, the issue turns out to be a limitation of gradle. It identifies projects by group (i.e. org.apache.kafka) and the last component of the name (e.g. :connect:tools is identified by the tuple (org.apache.kafka, tools). This means that having a top-level tools project and tools within a subproject like connect:tools makes it impossible to get gradle to express a dependency of :connect:tools on :tools. See https://discuss.gradle.org/t/dependency-substitution-wrong-with-more-than-one-sub-project-with-same-name/7253/6;;;","13/Nov/15 02:55;githubbot;GitHub user ewencp opened a pull request:

    https://github.com/apache/kafka/pull/512

    KAFKA-2807: Fix Kafka Connect packaging and move VerifiableSource/Sink into runtime jar.

    Gradle does not handle subprojects with the same name (top-level tools vs
    connect/tools) properly, making the dependency impossible to express correctly
    since we need to move the ThroughputThrottler class into the top level tools
    project. Moving the current set of tools into the runtime jar works fine since
    they are only used for system tests at the moment.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ewencp/kafka kafka-2807-redux

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/512.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #512
    
----
commit 7632c27cb5583d285aa66a9d2bf0510139666b41
Author: Ewen Cheslack-Postava <me@ewencp.org>
Date:   2015-11-12T18:25:33Z

    KAFKA-2807: Fix Kafka Connect packaging and move VerifiableSource/Sink into runtime jar.
    
    Gradle does not handle subprojects with the same name (top-level tools vs
    connect/tools) properly, making the dependency impossible to express correctly
    since we need to move the ThroughputThrottler class into the top level tools
    project. Moving the current set of tools into the runtime jar works fine since
    they are only used for system tests at the moment.

----
;;;","13/Nov/15 03:13;gwenshap;Issue resolved by pull request 512
[https://github.com/apache/kafka/pull/512];;;","13/Nov/15 03:13;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/512
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KafkaConsumer.close() can block unnecessarily due to leave group waiting for a reply,KAFKA-2792,12911746,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,ewencp,ewencp,ewencp,10/Nov/15 10:35,11/Nov/15 03:52,22/Mar/23 15:10,11/Nov/15 02:27,,,,,,,0.9.0.0,,,,,,,consumer,,,,0,,,,,,"The current implementation of close() waits for a response to LeaveGroup. However, if we have an outstanding rebalance in the works, this can cause the close() operation to have to wait for the entire rebalance process to complete, which is annoying since the goal is to get rid of the consumer object anyway. This is at best surprising and at worst can cause unexpected bugs due to close() taking excessively long -- this was found due to exceeding timeouts unexpectedly causing other operations in Kafka Connect to timeout.

Waiting for a response isn't necessary since as soon as the data is in the TCP buffer, it'll be delivered to the broker. The client doesn't benefit at all from seeing the close group. So we can instead just always send the request ",,ewencp,githubbot,guozhang,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Nov 10 19:52:52 UTC 2015,,,,,,,,,,"0|i2o6bj:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"10/Nov/15 10:56;githubbot;GitHub user ewencp opened a pull request:

    https://github.com/apache/kafka/pull/480

    KAFKA-2792: Don't wait for a response to the leave group message when closing the new consumer.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ewencp/kafka kafka-2792-fix-blocking-consumer-close

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/480.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #480
    
----
commit a781fba82af6a6224f441885e22d3d6b35fc96f0
Author: Ewen Cheslack-Postava <me@ewencp.org>
Date:   2015-11-10T02:56:08Z

    KAFKA-2792: Don't wait for a response to the leave group message when closing the new consumer.

----
;;;","11/Nov/15 02:27;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/480
;;;","11/Nov/15 02:27;gwenshap;Issue resolved by pull request 480
[https://github.com/apache/kafka/pull/480];;;","11/Nov/15 03:52;guozhang;[~ewencp] [~onurkaraman] If we fire-and-forget in the close() call, it will likely lead to an EOF exception on the server side whenever some consumer closes themselves, causing some log pollutions. This is why I was deciding to not do fire-and-forget in close() but only in unsubscribe(). We need to think about if this issue can be resolved in the socket server if we stick to this plan.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
zookeeper-server-stop.sh may fail to shutdown ZK and/or may stop unrelated processes,KAFKA-2874,12915265,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,miguno,miguno,23/Nov/15 17:07,07/Jan/16 07:22,22/Mar/23 15:10,07/Jan/16 07:22,0.8.2.1,0.9.0.0,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"We have run into the problem of ZK not shutting down properly when the included {{bin/zookeeper-server-stop.sh}} is being used.  In a nutshell, ZK may not shutdown when you send only a SIGINT;  instead, there are certain situations (which unfortunately are a bit hard to pin down) where for some reason only a SIGTERM will shut ZK down.

Similarly, the current [zookeeper-server-stop|https://github.com/apache/kafka/blob/trunk/bin/zookeeper-server-stop.sh#L16] script uses a very broad grep statement (`grep -i zookeeper`) that might cause the script to shutdown other processes on the machine as well, think: collateral damage.

For reference this is the current command to stop ZK:

{code}
ps ax | grep -i 'zookeeper' | grep -v grep | awk '{print $1}' | xargs kill -SIGINT
{code}

Disclaimer: I don't know whether there are any unwanted side effects of switching from SIGINT to SIGTERM.",,githubbot,junrao,miguno,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jan 06 23:22:08 UTC 2016,,,,,,,,,,"0|i2orxz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"23/Nov/15 17:11;githubbot;GitHub user miguno opened a pull request:

    https://github.com/apache/kafka/pull/573

    KAFKA-2874: shutdown ZK process reliably

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/miguno/kafka KAFKA-2874

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/573.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #573
    
----
commit 8775d9bae5c1abf490cbe0c256944544aeda7420
Author: Michael G. Noll <michael@confluent.io>
Date:   2015-11-23T09:10:25Z

    KAFKA-2874: shutdown ZK process reliably

----
;;;","07/Jan/16 07:22;junrao;Issue resolved by pull request 573
[https://github.com/apache/kafka/pull/573];;;","07/Jan/16 07:22;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/573
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SinkTasks do not handle rebalances and offset commit properly,KAFKA-2748,12910585,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,ewencp,ewencp,05/Nov/15 10:33,06/Nov/15 02:08,22/Mar/23 15:10,06/Nov/15 02:07,,,,,,,0.9.0.0,,,,,,,KafkaConnect,,,,0,,,,,,"Since the initial SinkTask code was originally written with an early version of the new consumer, it wasn't setup to handle rebalances properly. Since we recently added the rebalance listener, we can use it to correctly commit offsets. However, the existing code also has two issues. First, in the case of a failure to flush data in the sink task, we are not correctly rewinding to the last committed offsets. We need to do this since we cannot be sure what happened to the outstanding data, so we need to reprocess it. 

Second, flushing when stopping was not being handled propertly. The existing code was assuming that as part of SinkTask.stop() we would. However, this did not make sense since SinkTask.stop() was being invoked before the worker thread was stopped, so we could end up committing the wrong offsets. Instead, we need to wait for the worker thread to finish whatever it is currently doing, do one final flush + commit offsets, and only then invoke stop() to allow the task to do final cleanup. This is a bit confusing because stop means different things for source and sink tasks since they have pull vs push semantics.",,ewencp,githubbot,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 05 18:08:04 UTC 2015,,,,,,,,,,"0|i2nzav:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"06/Nov/15 01:34;githubbot;GitHub user ewencp opened a pull request:

    https://github.com/apache/kafka/pull/431

    KAFKA-2748: Ensure sink tasks commit offsets upon rebalance and rewind if the SinkTask flush fails.

    Also fix the incorrect consumer group ID setting which was giving each task its
    own group instead of one for the entire sink connector.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ewencp/kafka kafka-2748-sink-task-rebalance-commit

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/431.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #431
    
----
commit 4fc35c2fd6f358b9d234bf9338a7ef342c87af83
Author: Ewen Cheslack-Postava <me@ewencp.org>
Date:   2015-11-05T01:04:56Z

    KAFKA-2748: Ensure sink tasks commit offsets upon rebalance and rewind if the SinkTask flush fails.
    
    Also fix the incorrect consumer group ID setting which was giving each task its
    own group instead of one for the entire sink connector.

----
;;;","06/Nov/15 02:07;guozhang;Issue resolved by pull request 431
[https://github.com/apache/kafka/pull/431];;;","06/Nov/15 02:08;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/431
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Windows Bat files are not working properly,KAFKA-1210,12689253,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Trivial,Fixed,sslavic,HCanber,HCanber,16/Jan/14 22:43,13/Apr/14 23:44,22/Mar/23 15:10,13/Apr/14 23:44,0.8.1,,,,,,0.8.2.0,,,,,,,,,,,2,,,,,,"The bat files are not working properly.
The paths in them are invalid.
They have not been updated to reflect the changes made to the shell scripts.",Windows,HCanber,johnarnold,junrao,reinhard.maier,sslavic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1195,,,,,,,,KAFKA-581,,,,,,,,"16/Jan/14 22:59;HCanber;1210-v1.patch;https://issues.apache.org/jira/secure/attachment/12623399/1210-v1.patch","10/Apr/14 20:54;sslavic;KAFKA-1210-v2.patch;https://issues.apache.org/jira/secure/attachment/12639569/KAFKA-1210-v2.patch","09/Apr/14 16:31;sslavic;KAFKA-1210-v2.patch;https://issues.apache.org/jira/secure/attachment/12639365/KAFKA-1210-v2.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,368220,,,Sun Apr 13 15:44:32 UTC 2014,,,,,,,,,,"0|i1rgtj:",368525,,,,,,,,,,,,,,,,,,,,"16/Jan/14 22:56;HCanber;Patch: Updated windows bat files
The patch do not include -daemon -loggc or name <name> options since shifting command arguments are not working properly in bat files (when shifting the argument isn't removed from the all-arguments-variable).;;;","25/Feb/14 02:22;junrao;Thanks for the patch. We have moved to gradle now. Could you double check that the patch still applies?;;;","08/Apr/14 18:04;sslavic;kafka-run-class.bat changes from the patch unfortunatelly do not apply to current 0.8.1 branch head.
Befor trying to apply patch file, on Windows, I had to first convert patch file encoding to ANSI and EOL to Unix format, like explained in [this SO question|http://stackoverflow.com/q/13675782/381140].;;;","09/Apr/14 01:59;johnarnold;Is there a branch that ""just works"" on windows?

I tried the 0.8.1 tarball with windows batch file fixes and had issues with loading the classes, even after setting static paths in the batch files.

PS C:\kafka> .\bin\windows\kafka-create-topic.bat --zookeeper localhost:2181 --replica 1 --partition 1 --topic test
C:\kafka
C:\kafka\libs
classpath=C:\kafka\libs;""C:\kafka\target\scala-2.9.2\kafka_2.9.2-0.1-SNAPSHOT.jar"";""C:\kafka\target\scala-2.9.2\kafka_2.9.2-0.1-SNAPSHOT.jar"";""C:\kafka\libs\jopt-simple-3.2.jar"";""C:\kafka\libs\kafka_2.9.2-0.8.1.jar"";""C:\kafka\libs\log4j-1.2.15.jar"";""C:\kafka\libs\metrics-annotation-2.2.0.jar"";""C:\kafka\libs\metrics-core-2.2.0.jar"";""C:\kafka\libs\scala-library-2.9.2.jar"";""C:\kafka\libs\slf4j-api-1.7.2.jar"";""C:\kafka\libs\slf4j-log4j12-1.7.6.jar"";""C:\kafka\libs\snappy-java-1.0.5.jar"";""C:\kafka\libs\zkclient-0.3.jar"";""C:\kafka\libs\zookeeper-3.3.4.jar""

""C:\java\bin\java"" -Xmx256M -server -XX:+UseCompressedOops -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC -Djava.awt.headless=true -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false -Dlog4j.configuration=file:C:\kafka\config\tools-log4j.properties -cp C:\kafka\libs;""C:\kafka\target\scala-2.9.2\kafka_2.9.2-0.1-SNAPSHOT.jar"";""C:\kafka\target\scala-2.9.2\kafka_2.9.2-0.1-SNAPSHOT.jar"";""C:\kafka\libs\jopt-simple-3.2.jar"";""C:\kafka\libs\kafka_2.9.2-0.8.1
.jar"";""C:\kafka\libs\log4j-1.2.15.jar"";""C:\kafka\libs\metrics-annotation-2.2.0.jar"";""C:\kafka\libs\metrics-core-2.2.0.jar"";""C:\kafka\libs\scala-library-2.9.2.jar"";""C:\kafka\libs\slf4j-api-1.7.2.jar"";""C:\kafka\libs\slf4j-log4j12-1.7.6.jar"";""C:\kafka\libs\snappy-java-1.0.5.jar"";""C:\kafka\libs\zkclient-0.3.jar"";""C:\kafka\libs\zookeeper-3.3.4.jar""  kafka.admin.CreateTopicCommand --zookeeper localhost:2181 --replica 1 --partition 1 --topic test

Error: Could not find or load main class kafka.admin.CreateTopicCommand
PS C:\kafka>

Help?;;;","09/Apr/14 16:31;sslavic;Attaching updated [^KAFKA-1210-v2.patch], based on [^1210-v1.patch] by [~HCanber], with following changes:
- adjusted libs (classpath element) references, changed due to migration from SBT to Gradle
- In {{windows/kafka-run-class.bat}} implemented error handling, when empty classpath is detected, giving feedback that user/developer likely has not built the project before trying to run a given class;;;","09/Apr/14 23:20;junrao;Thanks for the patch. Could another window user confirm that the script works?;;;","10/Apr/14 20:54;sslavic;Attaching updated [^KAFKA-1210-v2.patch] with extra fixes and little bit of fine tuning after feedback from a colleague.;;;","10/Apr/14 21:01;reinhard.maier;verified the patch on Windows 7 by  starting Zookeeper and Kafka and changing the log levels in log4j.properties;;;","13/Apr/14 23:44;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use different keyTab for client and server in SASL tests,KAFKA-2844,12913399,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,ijuma,ijuma,17/Nov/15 02:45,17/May/16 22:17,22/Mar/23 15:10,02/Apr/16 06:26,,,,,,,0.10.0.0,,,,,,,security,,,,0,,,,,,"We currently use the same keyTab, which could hide problems in the implementation.",,githubbot,gwenshap,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Apr 01 22:26:13 UTC 2016,,,,,,,,,,"0|i2oggv:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"17/Nov/15 02:55;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/533

    KAFKA-2844; Separate keyTabs for sasl tests

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka separate-keytabs-for-sasl-tests

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/533.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #533
    
----
commit 7cd7fba5f3fb23991b93a0180d41b6fd67cd0b99
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2015-11-16T17:10:37Z

    Move `FourLetterWords` to its own file and clean-up its usage

commit 4f423a8d6e14660ae25b7c2eba2901e51e75b00e
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2015-11-16T18:51:51Z

    Use a different keyTab for server and client in SASL tests
    
    In order to do this, replace templated `kafka_jaas.conf` file
    with programmatic approach.

----
;;;","02/Apr/16 06:26;gwenshap;Issue resolved by pull request 533
[https://github.com/apache/kafka/pull/533];;;","02/Apr/16 06:26;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/533
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Get rid of Guava dependency,KAFKA-3061,12927113,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,gwenshap,gwenshap,05/Jan/16 06:16,09/Jan/20 23:20,22/Mar/23 15:10,09/Jan/20 23:20,,,,,,,2.5.0,,,,,,,,,,,0,,,,,,"KAFKA-2422 adds Reflections library to KafkaConnect, which depends on Guava.
Since lots of people want to use Guavas, having it in the framework will lead to conflicts.",,ewencp,gwenshap,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Jan 08 13:58:24 UTC 2020,,,,,,,,,,"0|i2qs0n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Jan/16 17:50;ijuma;Do we want to target this for 0.9.1.0?;;;","20/Jan/16 01:34;gwenshap;I was thinking its not urgent and we can do it whenever we run into Guava related conflicts. But I think [~ewencp] viewed it with more urgency.;;;","20/Jan/16 01:46;ijuma;If users have an issue with the Guava, can they exclude it and still use Connect? If that's the case, then it seems fine. Otherwise, we may want to consider at making this possible for 0.9.1.0.;;;","23/Jan/16 01:22;ewencp;[~ijuma] I think they could if they could as of 58def1c because if they specify the full class name, the reflections library is never invoked since we use it to scan for subclasses of Connector. However, if we also want to, e.g., expose a REST endpoint for listing available connectors, that will require using reflections (and this is useful functionality for validating your connector plugin installation, for getting metadata when we expose more of that, etc). On the other hand, I guess you could still get by in that case by never invoking that REST endpoint if you really needed to avoid Guava.

So strictly speaking you should be fine as long as you allow whatever plugin has a conflicting version to provide the jar and avoid a small amount of functionality. The real question is whether we think telling people that is a reasonable response to incompatibilities... I don't have a strong opinion because at this point it's hard for us to know how many connectors might pull in Guava via whatever library they are using to connect to the external system. This might be a case where it's fine to leave it in with these possible limitations if you encounter a conflict, and if we see too many problems we can replace it with another library or write that code ourselves.;;;","23/Jan/16 07:01;ijuma;Your suggestion to wait for feedback to see if it's worth investing time on this JIRA seems fine to me given the workarounds available.;;;","08/Jun/16 03:10;ewencp;Following up on this as I saw [~rekhajoshm] just assigned themselves -- we should also consider if this could be resolved by KAFKA-3487 instead, which we need to avoid conflicts between connectors anyway. If we can isolate the framework internal classloader from the one used for connectors, maybe the use of guava becomes non-problem.;;;","08/Jan/20 21:58;ijuma;Reflections 0.9.12 no longer depends on Guava.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Socket connection closing is logged, but not corresponding opening of socket",KAFKA-2252,12835528,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,gwenshap,jbrosenberg@gmail.com,jbrosenberg@gmail.com,05/Jun/15 04:52,17/Jun/15 06:38,22/Mar/23 15:10,17/Jun/15 06:38,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"(using 0.8.2.1)
We see a large number of ""Closing socket connection"" logging to the broker logs, e.g.:

{code}
2015-06-04 16:49:30,262  INFO [kafka-network-thread-27330-2] network.Processor - Closing socket connection to /1.2.3.4.
2015-06-04 16:49:30,262  INFO [kafka-network-thread-27330-0] network.Processor - Closing socket connection to /5.6.7.8.
2015-06-04 16:49:30,695  INFO [kafka-network-thread-27330-0] network.Processor - Closing socket connection to /9.10.11.12.
2015-06-04 16:49:31,465  INFO [kafka-network-thread-27330-1] network.Processor - Closing socket connection to /13.14.15.16.
2015-06-04 16:49:31,806  INFO [kafka-network-thread-27330-0] network.Processor - Closing socket connection to /17.18.19.20.
2015-06-04 16:49:31,842  INFO [kafka-network-thread-27330-2] network.Processor - Closing socket connection to /21.22.23.24.
{code}

However, we have no corresponding logging for when these connections are established.  Consequently, it's not very useful to see a flood of closed connections, etc.  I'd think we'd want to see the corresponding 'connection established' messages, also logged as INFO.

Occasionally, we see a flood of the above messages, and have no idea as to whether it indicates a problem, etc.  (Sometimes it might be due to an ongoing rolling restart, or a change in the Zookeeper cluster).",,gwenshap,jbrosenberg@gmail.com,junrao,omkreddy,toddpalino,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/15 05:28;gwenshap;KAFKA-2252.patch;https://issues.apache.org/jira/secure/attachment/12739697/KAFKA-2252.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jun 16 22:38:20 UTC 2015,,,,,,,,,,"0|i2fnlj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"15/Jun/15 15:04;omkreddy;Some of these logs are removed/modified as part of KAFKA-1928.;;;","16/Jun/15 01:48;gwenshap;We still have this exact issue. Only now its in Selector and not SocketServer.
;;;","16/Jun/15 02:18;toddpalino;I moved the normal connection closed message to DEBUG level in KAFKA-2175. In general, we should not log either normal connection close or open at INFO level. There is far too much noise due to these messages.;;;","16/Jun/15 02:24;gwenshap;Ick! I lost your fix while working on KAFKA-1928. So sorry!

I'll move it back to DEBUG, add another DEBUG for creating connections (for symmetry), and I think we are good.;;;","16/Jun/15 05:28;gwenshap;Created reviewboard https://reviews.apache.org/r/35474/diff/
 against branch trunk;;;","17/Jun/15 06:38;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use Apache Rat to enforce copyright headers,KAFKA-2248,12835455,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,ewencp,ewencp,05/Jun/15 00:33,07/Jul/15 06:48,22/Mar/23 15:10,07/Jul/15 06:48,,,,,,,0.9.0.0,,,,,,,build,,,,0,,,,,,Follow up to KAFKA-2161. Use Apache Rat during builds to make sure copyright headers are present so we don't forget any and don't allow any incorrect ones to be checked in.,,ewencp,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jun/15 00:35;ewencp;KAFKA-2248.patch;https://issues.apache.org/jira/secure/attachment/12737612/KAFKA-2248.patch","14/Jun/15 05:10;ewencp;KAFKA-2248_2015-06-13_14:10:23.patch;https://issues.apache.org/jira/secure/attachment/12739449/KAFKA-2248_2015-06-13_14%3A10%3A23.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jul 06 22:48:26 UTC 2015,,,,,,,,,,"0|i2fn5z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"05/Jun/15 00:35;ewencp;Created reviewboard https://reviews.apache.org/r/35076/diff/
 against branch origin/trunk;;;","05/Jun/15 00:39;ewencp;Patch is mostly lifted from the Samza version. A couple of notes:

1. I attached the check to test rather than check so it runs under normal developer steps before submitting a patch. One drawback to that is that it doesn't look like you can control the order of gradle build steps yet and it seems to run before the tests themselves, which is slightly inconvenient during development.
2. I ignored everything under system_test/ because there's a KIP to replace them and there was a lot of cleanup to be done there.
3. Extra files that match file types checked by Rat can cause failures. For example, I had a couple of patch files in the root of my repo and had to clear them out. Samza has the same issue, but they only run this during the check step, so maybe most people don't notice it?;;;","14/Jun/15 05:10;ewencp;Updated reviewboard https://reviews.apache.org/r/35076/diff/
 against branch origin/trunk;;;","14/Jun/15 05:12;ewencp;[~junrao] Try this new updated version. I used a gradle git library to generate most of the excludes so we don't consider anything that's not checked in/staged for check in. This should cover most of the annoying cases where Rat picks up files we don't care about. The rest are covered by only a couple of rules to handle files that are checked in but shouldn't need licenses.;;;","07/Jul/15 06:48;junrao;Thanks the latest patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
change log4j to slf4j ,KAFKA-1044,12667240,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,viktorsomogyi,shijinkui,shijinkui,06/Sep/13 09:32,22/Nov/17 23:35,22/Mar/23 15:10,22/Nov/17 23:35,0.8.0,,,,,,1.1.0,,,,,,,log,,,,7,newbie,,,,,"can u chanage the log4j to slf4j, in my project, i use logback, it's conflict with log4j.",,crao,ewencp,githubbot,grussell,ijuma,jbarksdale,jkreps,luchob,michaelmoss,rehevkor5,rkellogg,shijinkui,stevenschlansker,viktorsomogyi,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,347177,,,Wed Nov 22 15:13:08 UTC 2017,,,,,,,,,,"0|i1nv73:",347476,,,,,,,,,,,,,,,,,,,,"06/Dec/14 07:33;jbarksdale;More specifically, at least swapping to slf4j for the producer and consumer related stuff will allow users to use logging frameworks other than log4j, since it currently does not compile without that as a dependency.  ;;;","09/Dec/14 06:56;jbarksdale;As as workaround, you can exclude log4j from kafka, and just use the org.slf4j:log4j-over-slf4j instead.  That feeds in most log4j commands to slf4j, and then logback or another slf4j binding can be used.  ;;;","08/Feb/15 07:16;jkreps;This would be nice to do. If anyone wants to take it on...;;;","22/Jul/16 04:44;rehevkor5;In addition, can we change the dependency on slf4j-log4j12 from ""compile"" scope to ""runtime"" scope and mark it ""optional""?;;;","24/Jan/17 13:27;ewencp;To clarify for anyone coming back to this, I believe wrt clients this should only apply to the core project, the new client libs should already be using just the slf4j API except in tests.;;;","07/Jun/17 08:27;viktorsomogyi;Hi,

I'm new to Kafka and was searching for a fitting task.
If this is still relevant then I'd like to pick it up. Could someone please add me as contributor so I could assign it to me?;;;","07/Jun/17 12:03;ewencp;[~viktorsomogyi] I've added you as a contributor. I assigned this JIRA to you, but since you are a contributor now you should be able to assign any other JIRAs to yourself as well.;;;","10/Jun/17 02:47;viktorsomogyi;[~ewencp], thank you, started working on it.
I found two incompatibilities and I'm asking your advice in the resolution.
 * Fatal logging level: slf4j doesn't support it
 * kafka.utils.Log4jController: there are some log4j specific features used here that can't be replaced with a generic solution

I have two solutions for these:
 # we could simply use the log4j-over-slf4j package. This will redirect all Fatal logs to Error level and also provides some of the functionalities required by Log4jController (but not all).
    * Pros: a few lines of changes only, quite straightforward
    * Cons: loss of features. However Fatal can't be worked around so we have to accept that, but we also lose Log4jController.getLoggers as there is no way of collecting the current loggers by simply relying on slf4j. Also other methods' behaviour will change (no way to detect existing loggers in slf4j as far as I'm aware of it)
# we could separate off Log4jController into a separate module and have the users to put it on the classpath explicitly if they use log4j for logging. From Logging class we can instantiate it by reflection.
    * Pros: except Fatal logging level we keep all the features
    * Cons: more complicated and breaking, also requires documentation so users will be aware of this

I'll try to create PRs of both solutions (and they are rather work in progress, I just want to show approximate solutions) just in case if that is fine.;;;","03/Jul/17 15:46;githubbot;GitHub user viktorsomogyi opened a pull request:

    https://github.com/apache/kafka/pull/3477

    KAFKA-1044: eliminating log4j from core

    The aim of this PR to move kafka core/main away from log4j and introduce using slf4j only.
    To accomplish this task I:
    - refactored Log4jController into its own module as it is very tightly coupled with log4j (and removing these dependencies would have been impossible without feature loss).
    - as log4j supports FATAL level but slf4j doesn't, I introduced a FATAL marker similarly to the log4j-slf4j bridge

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/viktorsomogyi/kafka KAFKA-1044

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/3477.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #3477
    
----
commit 9abe1a37c2ca4f9ea95fdee394b7135ad779d971
Author: Viktor Somogyi <viktor.somogyi@cloudera.com>
Date:   2017-06-08T22:22:36Z

    KAFKA-1044: eliminating log4j from core

----
;;;","10/Jul/17 18:23;viktorsomogyi;[~ewencp] could you please look at my change when you have time?
An important question has been asked on the review: should we use scala logging?;;;","08/Sep/17 21:24;grussell;Since [log4j is EOL | https://blogs.apache.org/foundation/entry/apache_logging_services_project_announces] it would be beneficial to the community if a solution to this issue (dependency elimination) could get some priority.;;;","08/Sep/17 21:31;viktorsomogyi;Hi [~grussell], currently I need to resolve some merge conflits but let me do that and try to get it reviewed with someone :).;;;","08/Sep/17 21:50;ijuma;I do think we should use scala-logging since it's the most efficient. It doesn't create closures, there is no syntactic penalty and it doesn't generate garbage if the log message won't be printed.;;;","22/Nov/17 23:13;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/3477
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Infinite recursive function call occurs when ConsumerRebalanceCallback.onPartitionRevoked() calls commitSync(),KAFKA-2555,12875705,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,becket_qin,becket_qin,becket_qin,18/Sep/15 06:03,26/Sep/15 02:58,22/Mar/23 15:10,26/Sep/15 02:58,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"In new consumer's ConsumerRebalanceCallback.onPartitionRevoked() when user call commitSync(), it causes infinite recursive call of onPartitionRevoked().",,becket_qin,githubbot,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Sep 25 18:58:15 UTC 2015,,,,,,,,,,"0|i2kd1r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Sep/15 01:53;githubbot;GitHub user becketqin opened a pull request:

    https://github.com/apache/kafka/pull/221

    KAFKA-2555: Infinite recursive function call when call commitSync in …

    @hachikuji @ewencp I found this problem when adding new consumer to mirror maker which commits offset in the rebalance callback. It is not clear to me why we are triggering rebalance for commitSync() and fetchCommittedOffset(). Can you help review to see if I miss something?
    
    Regarding commitSync, After each poll() the partitions will be either assigned to a consumer or it will be already revoked. As long as user is using internal offset map, the offset map will always be valid. i.e. the offset map will always only contain the assigned partitions when commitSync is called. Hence there is no need to trigger a rebalance in commitSync().
    
    The same guarantee also apply to fetchCommittedOffset(), isn't the only requirement is to ensure we know the coordinator?
    
    Another related issue is that today the IllegalGenerationIdException is a bit confusing. When we receive an IllegalGenerationIdException from heartbeat, we need to use that same generation Id to commit offset and the coordinator will take it. So the generation ID was not really illegal. I will file a ticket for this issue.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/becketqin/kafka KAFKA-2555

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/221.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #221
    
----
commit 77b6a59eb926bf99773e7b53bf0e4b1610dc8277
Author: Jiangjie Qin <becket.qin@gmail.com>
Date:   2015-09-18T17:21:27Z

    KAFKA-2555: Infinite recursive function call when call commitSync in RebalanceListener.onPartitionRevoked()

----
;;;","26/Sep/15 02:58;guozhang;Issue resolved by pull request 221
[https://github.com/apache/kafka/pull/221];;;","26/Sep/15 02:58;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/221
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Current perf directory has buggy perf tests,KAFKA-149,12526092,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,nehanarkhede,nehanarkhede,07/Oct/11 02:25,10/Oct/11 05:53,22/Mar/23 15:10,07/Oct/11 03:48,,,,,,,0.7,,,,,,,,,,,0,,,,,,"The scripts in the current perf directory are buggy and not useful to run any reliable Kafka performance tests. The performance tools that work correctly are -

ProducerPerformance.scala
SimpleConsumerPerformance.scala
ConsumerPerformance.scala

Currently, the above are in the tools directory. Ideally, a Kafka performance suite should repackage these tools with some sample performance load and output data in csv format that can be graphed. 

I suggest deleting the perf directory and redoing this cleanly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,49665,,,Sun Oct 09 21:53:23 UTC 2011,,,,,,,,,,"0|i15z6f:",242999,,,,,,,,,,,,,,,,,,,,"07/Oct/11 03:02;junrao;+1;;;","07/Oct/11 09:43;cburroughs;I'm not following what was wrong with the perf/ tools, or what changed to make them unreliable.;;;","10/Oct/11 04:16;nehanarkhede;The perf directory had quite a few problems 

1. Our perf tools which are tested well were not used.
2. No clear separation between perf tools and definition of performance load
3. A lot of custom code written to plot some custom graphs, that cannot be easily understood by existing and new developers
4. The custom code was in Java, and was buggy (the perf numbers that it gave wasn't exactly indicative of real Kafka performance)

Ideally, our thought is to improve and bundle up the perf tools that we have and write some scripts that clearly define the performance load used and purpose of the perf test.

;;;","10/Oct/11 05:53;cburroughs;Thanks, that makes sense.  Is there a ticket yet for the New and Improved perf scripts?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sender.java: handleProduceResponse does not check protocol version,KAFKA-2750,12910597,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,granders,granders,05/Nov/15 11:05,01/Sep/17 03:23,22/Mar/23 15:10,01/Sep/17 03:23,0.10.1.0,,,,,,,,,,,,,,,,,1,,,,,,"If you try run an 0.9 producer against 0.8.2.2 kafka broker, you get a fairly cryptic error message:

[2015-11-04 18:55:43,583] ERROR Uncaught error in kafka producer I/O thread:  (org.apache.kafka.clients.producer.internals.Sender)
org.apache.kafka.common.protocol.types.SchemaException: Error reading field 'throttle_time_ms': java.nio.BufferUnderflowException
	at org.apache.kafka.common.protocol.types.Schema.read(Schema.java:71)
	at org.apache.kafka.clients.NetworkClient.handleCompletedReceives(NetworkClient.java:462)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:279)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:216)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:141)

Although we shouldn't expect an 0.9 producer to work against an 0.8.X broker since the protocol version has been increased, perhaps the error could be clearer.

The cause seems to be that in Sender.java, handleProduceResponse does not to have any mechanism for checking the protocol version of the received produce response - it just calls a constructor which blindly tries to grab the throttle time field which in this case fails.
",,ddhiraj,diederik,felixgv,granders,jjkoshy,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2756,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Aug 31 19:23:07 UTC 2017,,,,,,,,,,"0|i2nzdj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"10/Feb/16 05:21;felixgv;Shouldn't the producer automatically do a graceful degradation of its protocol, without even bubbling anything up to the user?;;;","10/Feb/16 08:39;jjkoshy;[~felixgv] You mean retry with the older protocol? It does not do it currently - i.e., it always sends with the latest version. However, it should be possible after we support protocol version querying:
https://cwiki.apache.org/confluence/display/KAFKA/KIP-35+-+Retrieving+protocol+version Until that is available we only recommend upgrading the clients _after_ the brokers.;;;","01/Sep/17 03:23;omkreddy;This was fixed in KAFKA-4462 /KIP-97 for newer clients;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New-consumer sends invalid describeGroupResponse while restabilizing,KAFKA-2768,12911233,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,singhashish,singhashish,singhashish,07/Nov/15 06:33,14/Nov/15 04:50,22/Mar/23 15:10,14/Nov/15 04:50,,,,,,,0.9.0.0,,,,,,,consumer,,,,0,,,,,,"While a consumer group is restabilizing, it sends describeGroupResponse with no error, but empty metadata and assignments. That leads to SchemaException on client.

{code}
Error while executing consumer group command Error reading field 'version': java.nio.BufferUnderflowException
org.apache.kafka.common.protocol.types.SchemaException: Error reading field 'version': java.nio.BufferUnderflowException
	at org.apache.kafka.common.protocol.types.Schema.read(Schema.java:73)
	at org.apache.kafka.clients.consumer.internals.ConsumerProtocol.deserializeAssignment(ConsumerProtocol.java:106)
	at kafka.admin.AdminClient$$anonfun$describeConsumerGroup$1.apply(AdminClient.scala:163)
	at kafka.admin.AdminClient$$anonfun$describeConsumerGroup$1.apply(AdminClient.scala:161)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.admin.AdminClient.describeConsumerGroup(AdminClient.scala:161)
	at kafka.admin.ConsumerGroupCommand$.describe(ConsumerGroupCommand.scala:109)
	at kafka.admin.ConsumerGroupCommand$.main(ConsumerGroupCommand.scala:63)
	at kafka.admin.ConsumerGroupCommand.main(ConsumerGroupCommand.scala)
{code}",,githubbot,guozhang,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 13 20:50:26 UTC 2015,,,,,,,,,,"0|i2o35j:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"07/Nov/15 06:35;githubbot;GitHub user SinghAsDev opened a pull request:

    https://github.com/apache/kafka/pull/447

    KAFKA-2768: New-consumer sends invalid describeGroupResponse while re…

    …stabilizing

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/SinghAsDev/kafka KAFKA-2768

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/447.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #447
    
----
commit 547f1b2f1c46cc4c09bbd334bcc9e1db7fc7cbd8
Author: Ashish Singh <asingh@cloudera.com>
Date:   2015-11-06T22:34:38Z

    KAFKA-2768: New-consumer sends invalid describeGroupResponse while restabilizing

----
;;;","14/Nov/15 04:50;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/447
;;;","14/Nov/15 04:50;guozhang;Issue resolved by pull request 447
[https://github.com/apache/kafka/pull/447];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsumerConsume throw unexpected exception during clean shutdown,KAFKA-2819,12912512,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,junrao,junrao,13/Nov/15 00:07,13/Nov/15 13:57,22/Mar/23 15:10,13/Nov/15 13:57,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Saw the following error during a clean shutdown.

[2015-11-12 13:12:58,918] INFO [ConsumerFetcherManager-1447333891220] All connections stopped (kafka.consumer.ConsumerFetcherManager)
[2015-11-12 13:12:58,921] ERROR Error processing message, terminating consumer process:  (kafka.tools.ConsoleConsumer$)
java.util.NoSuchElementException
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)
	at kafka.consumer.OldConsumer.receive(BaseConsumer.scala:79)
	at kafka.tools.ConsoleConsumer$.process(ConsoleConsumer.scala:101)
	at kafka.tools.ConsoleConsumer$.run(ConsoleConsumer.scala:64)
	at kafka.tools.ConsoleConsumer$.main(ConsoleConsumer.scala:42)
	at kafka.tools.ConsoleConsumer.main(ConsoleConsumer.scala)
",,githubbot,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 13 05:23:46 UTC 2015,,,,,,,,,,"0|i2ob1r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"13/Nov/15 00:09;junrao;It seems that the following assumption in OldConsumer is incorrect. We should first check iter.hasNext since it can return false if the ConsumerConnector is shut down.

  override def receive(): BaseConsumerRecord = {
    // we do not need to check hasNext for KafkaStream iterator
    val messageAndMetadata = iter.next
;;;","13/Nov/15 04:18;githubbot;GitHub user guozhangwang opened a pull request:

    https://github.com/apache/kafka/pull/516

    KAFKA-2819: catch NoSuchElementException in ConsoleConsumer

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/guozhangwang/kafka K2819

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/516.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #516
    
----
commit 2bde950387eee79a0d19c852d827e6cfffd656d3
Author: Guozhang Wang <wangguoz@gmail.com>
Date:   2015-11-12T20:22:27Z

    v1

----
;;;","13/Nov/15 13:23;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/516
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsoleConsumerTest.test_version system test fails consistently,KAFKA-3080,12928516,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,ewencp,ewencp,08/Jan/16 08:20,22/Jan/16 03:18,22/Mar/23 15:10,22/Jan/16 03:18,,,,,,,0.10.0.0,,,,,,,system tests,,,,0,,,,,,"This test on trunk is failing consistently:

{quote}
test_id:    2016-01-07--001.kafkatest.sanity_checks.test_console_consumer.ConsoleConsumerTest.test_version
status:     FAIL
run time:   38.451 seconds


    num_produced: 1000, num_consumed: 0
Traceback (most recent call last):
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.8-py2.7.egg/ducktape/tests/runner.py"", line 101, in run_all_tests
    result.data = self.run_single_test()
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.3.8-py2.7.egg/ducktape/tests/runner.py"", line 151, in run_single_test
    return self.current_test_context.function(self.current_test)
  File ""/var/lib/jenkins/workspace/kafka_system_tests/kafka/tests/kafkatest/sanity_checks/test_console_consumer.py"", line 93, in test_version
    assert num_produced == num_consumed, ""num_produced: %d, num_consumed: %d"" % (num_produced, num_consumed)
AssertionError: num_produced: 1000, num_consumed: 0
{quote}

Example run where it fails: http://jenkins.confluent.io/job/kafka_system_tests/79/console",,ewencp,githubbot,granders,gwenshap,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Jan 21 19:18:50 UTC 2016,,,,,,,,,,"0|i2r0nz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"14/Jan/16 08:46;granders;I did a quick manual binary search through archived test results. 

The last successful run of this test was 
2015/12/17 at 9:42am UTC

No results from 2015/12/18

First failure:
2015/12/18 at 9:42am UTC

Theoretically possible culprits are:
{code}
commit 8c754c45af57a3249232268c6093cb4f50e1d45f
Author: Ismael Juma <ismael@juma.me.uk>
Date:   Fri Dec 18 10:27:03 2015 -0800

    MINOR: Change return type of `Schema.read` to be `Struct` instead of `Object`

commit 9220df9f8b58870a2282d3e4ceb2e003667d854b
Author: Ben Stopford <benstopford@gmail.com>
Date:   Thu Dec 17 18:02:38 2015 -0800

    KAFKA-2964: Split Security Rolling Upgrade Test by Client and Broker Protocols


commit a2a417caf9fa4f177e099fed7d2a9b8d1942a9d6
Author: vahidhashemian <vahidhashemian@us.ibm.com>
Date:   Thu Dec 17 16:52:24 2015 -0800

    MINOR: Fix broken documentation link
{code}


;;;","14/Jan/16 13:45;ijuma;My change was simply a types change so it sounds pretty unlikely.;;;","14/Jan/16 16:16;githubbot;GitHub user ewencp opened a pull request:

    https://github.com/apache/kafka/pull/770

    KAFKA-3080: Fix ConsoleConsumerTest by checking version when service is started

    The MessageFormatter being used was only introduced as of 0.9.0.0. The Kafka
    version in some tests is changed dynamically, sometimes from trunk back to an
    earlier version, so this option must be set based on the version used when the
    service is started, not when it is created.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ewencp/kafka kafka-3080-system-test-console-consumer-version-failure

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/770.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #770
    
----
commit 0f0d33fe251f7dd94bd580c7e368f763ea680aea
Author: Ewen Cheslack-Postava <me@ewencp.org>
Date:   2016-01-14T07:54:55Z

    KAFKA-3080: Fix ConsoleConsumerTest by checking version when service is started
    
    The MessageFormatter being used was only introduced as of 0.9.0.0. The Kafka
    version in some tests is changed dynamically, sometimes from trunk back to an
    earlier version, so this option must be set based on the version used when the
    service is started, not when it is created.

----
;;;","22/Jan/16 03:18;gwenshap;Issue resolved by pull request 770
[https://github.com/apache/kafka/pull/770];;;","22/Jan/16 03:18;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/770
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OffsetsMessageFormatter hits unexpected exception,KAFKA-2833,12912901,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,junrao,junrao,14/Nov/15 01:20,14/Nov/15 06:11,22/Mar/23 15:10,14/Nov/15 06:11,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Add the following property to config/consumer.properties 
exclude.internal.topics=false

bin/kafka-console-consumer.sh --consumer.config config/consumer.properties --from-beginning --topic __consumer_offsets --zookeeper localhost:2181 --formatter ""kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter""

Processed a total of 1 messages
[2015-11-13 09:17:06,376] ERROR Unknown error when running consumer:  (kafka.tools.ConsoleConsumer$)
org.apache.kafka.common.protocol.types.SchemaException: Error reading field 'metadata': java.nio.BufferUnderflowException
	at org.apache.kafka.common.protocol.types.Schema.read(Schema.java:71)
	at kafka.coordinator.GroupMetadataManager$.kafka$coordinator$GroupMetadataManager$$readOffsetMessageValue(GroupMetadataManager.scala:861)
	at kafka.coordinator.GroupMetadataManager$OffsetsMessageFormatter.writeTo(GroupMetadataManager.scala:934)
	at kafka.tools.ConsoleConsumer$.process(ConsoleConsumer.scala:114)
	at kafka.tools.ConsoleConsumer$.run(ConsoleConsumer.scala:65)
	at kafka.tools.ConsoleConsumer$.main(ConsoleConsumer.scala:43)
	at kafka.tools.ConsoleConsumer.main(ConsoleConsumer.scala)
",,githubbot,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 13 22:11:16 UTC 2015,,,,,,,,,,"0|i2odev:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"14/Nov/15 03:37;guozhang;I missed in while doing KAFKA-2017, my bad. Submitting a fix below.;;;","14/Nov/15 04:15;githubbot;GitHub user guozhangwang opened a pull request:

    https://github.com/apache/kafka/pull/527

    KAFKA-2833: print only group offset / metadata according to the formatter

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/guozhangwang/kafka K2833

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/527.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #527
    
----
commit 6b7a88a84e9f80a29b3ca49ac6db95f5c70e3ee3
Author: Guozhang Wang <wangguoz@gmail.com>
Date:   2015-11-13T20:06:55Z

    v1

commit f558f027a5db69b351b0b32f52257ae6d3839795
Author: Guozhang Wang <wangguoz@gmail.com>
Date:   2015-11-13T20:07:05Z

    Merge branch 'trunk' of https://github.com/apache/kafka into K2833

----
;;;","14/Nov/15 06:10;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/527
;;;","14/Nov/15 06:11;junrao;Issue resolved by pull request 527
[https://github.com/apache/kafka/pull/527];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make UnknownTopicOrPartitionException a WARN in broker,KAFKA-627,12616769,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,criccomini,criccomini,20/Nov/12 01:34,13/Jul/19 06:15,22/Mar/23 15:10,24/Aug/17 23:30,0.8.0,,,,,,,,,,,,,core,,,,0,,,,,,"Currently, when sending messages to a topic that doesn't yet exist, the broker spews out these ""errors"" as it tries to auto-create new topics. I spoke with Neha, and she said that this should be a warning, not an error.

Could you please change it to something less scary, if, in fact, it's not scary.

2012/11/14 22:38:53.238 INFO [LogManager] [kafka-request-handler-6] [kafka] []  [Log Manager on Broker 464] Created log for 'firehoseReads'-5
2012/11/14 22:38:53.241 WARN [HighwaterMarkCheckpoint] [kafka-request-handler-6] [kafka] []  No previously checkpointed highwatermark value found for topic firehoseReads partition 5. Returning 0 as the highwatermark
2012/11/14 22:38:53.242 INFO [Log] [kafka-request-handler-6] [kafka] []  [Kafka Log on Broker 464], Truncated log segment /export/content/kafka/i001_caches/firehoseReads-5/00000000000000000000.log to target offset 0
2012/11/14 22:38:53.242 INFO [ReplicaFetcherManager] [kafka-request-handler-6] [kafka] []  [ReplicaFetcherManager on broker 464] adding fetcher on topic firehoseReads, partion 5, initOffset 0 to broker 466 with fetcherId 0
2012/11/14 22:38:53.248 ERROR [ReplicaFetcherThread] [ReplicaFetcherThread-466-0-on-broker-464] [kafka] []  [ReplicaFetcherThread-466-0-on-broker-464], error for firehoseReads 5 to broker 466
kafka.common.UnknownTopicOrPartitionException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at java.lang.Class.newInstance0(Class.java:355)
        at java.lang.Class.newInstance(Class.java:308)
        at kafka.common.ErrorMapping$.exceptionFor(ErrorMapping.scala:68)
        at kafka.server.AbstractFetcherThread$$anonfun$doWork$5$$anonfun$apply$3.apply(AbstractFetcherThread.scala:124)
        at kafka.server.AbstractFetcherThread$$anonfun$doWork$5$$anonfun$apply$3.apply(AbstractFetcherThread.scala:124)
        at kafka.utils.Logging$class.error(Logging.scala:102)
        at kafka.utils.ShutdownableThread.error(ShutdownableThread.scala:23)
        at kafka.server.AbstractFetcherThread$$anonfun$doWork$5.apply(AbstractFetcherThread.scala:123)
        at kafka.server.AbstractFetcherThread$$anonfun$doWork$5.apply(AbstractFetcherThread.scala:99)
        at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:125)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:344)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:344)
        at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:99)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:50)","Kafka 0.8, RHEL6, Java 1.6",criccomini,githubbot,jkreps,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,258638,,,Thu Aug 24 15:30:03 UTC 2017,,,,,,,,,,"0|i0l1qv:",120933,,,,,,,,,,,,,,,,,,,,"20/Nov/12 01:41;jkreps;Since this is expected behavior it seems like this shouldn't have a stack trace or even be a WARNing, just an INFO message.;;;","15/Feb/16 04:48;githubbot;GitHub user kichristensen opened a pull request:

    https://github.com/apache/kafka/pull/913

    KAFKA-627: Make UnknownTopicOrPartitionException a WARN in broker

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/kichristensen/kafka KAFKA-627

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/913.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #913
    
----
commit 9dc94fc95ceed94bd14cffa321023c902b11e19d
Author: Kim Christensen <kich@mvno.dk>
Date:   2016-02-14T20:45:13Z

    UnknownTopicOrPartition should be logged as warn

----
;;;","24/Aug/17 23:30;omkreddy;Not observed on latest versions;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Validate security.inter.broker.protocol against the advertised.listeners protocols,KAFKA-3194,12936143,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,granthenke,granthenke,03/Feb/16 06:08,25/Feb/16 15:23,22/Mar/23 15:10,04/Feb/16 07:54,0.9.0.0,,,,,,0.10.0.0,0.9.0.1,,,,,,core,,,,0,,,,,,"When testing Kafka I found that Kafka can run in a very unhealthy state due to a misconfigured security.inter.broker.protocol. There are errors in the log such (shown below) but it would be better to prevent startup with a clear error message in this scenario.

Sample error in the server logs:
{code}
ERROR kafka.controller.ReplicaStateMachine$BrokerChangeListener: [BrokerChangeListener on Controller 71]: Error while handling broker changes
kafka.common.BrokerEndPointNotAvailableException: End point PLAINTEXT not found for broker 69
	at kafka.cluster.Broker.getBrokerEndPoint(Broker.scala:141)
	at kafka.controller.ControllerChannelManager.kafka$controller$ControllerChannelManager$$addNewBroker(ControllerChannelManager.scala:88)
	at kafka.controller.ControllerChannelManager.addBroker(ControllerChannelManager.scala:73)
	at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$apply$mcV$sp$1$$anonfun$apply$mcV$sp$4.apply(ReplicaStateMachine.scala:372)
	at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$apply$mcV$sp$1$$anonfun$apply$mcV$sp$4.apply(ReplicaStateMachine.scala:372)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ReplicaStateMachine.scala:372)
	at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$apply$mcV$sp$1.apply(ReplicaStateMachine.scala:359)
	at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1$$anonfun$apply$mcV$sp$1.apply(ReplicaStateMachine.scala:359)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply$mcV$sp(ReplicaStateMachine.scala:358)
	at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply(ReplicaStateMachine.scala:357)
	at kafka.controller.ReplicaStateMachine$BrokerChangeListener$$anonfun$handleChildChange$1.apply(ReplicaStateMachine.scala:357)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:259)
	at kafka.controller.ReplicaStateMachine$BrokerChangeListener.handleChildChange(ReplicaStateMachine.scala:356)
	at org.I0Itec.zkclient.ZkClient$10.run(ZkClient.java:842)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
{code}",,githubbot,granthenke,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2876,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Feb 03 23:42:47 UTC 2016,,,,,,,,,,"0|i2sbnz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"03/Feb/16 06:46;githubbot;GitHub user granthenke opened a pull request:

    https://github.com/apache/kafka/pull/851

    KAFKA-3194: Validate security.inter.broker.protocol against the adver…

    …tised.listeners protocols

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka verify-protocol

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/851.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #851
    
----
commit 918a391a2fc3cf825bfbad73ae3ab923a307f4e4
Author: Grant Henke <granthenke@gmail.com>
Date:   2016-02-02T22:38:58Z

    KAFKA-3194: Validate security.inter.broker.protocol against the advertised.listeners protocols

----
;;;","04/Feb/16 05:34;granthenke;[~junrao] [~ewencp] [~gwenshap] [~guozhang]
Would any of you have a chance to review this today?;;;","04/Feb/16 07:42;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/851
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix javadoc in KafkaConsumer,KAFKA-2981,12921027,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,,vesense,vesense,11/Dec/15 18:26,12/Dec/15 03:33,22/Mar/23 15:10,12/Dec/15 03:33,0.9.0.0,,,,,,0.9.0.1,,,,,,,clients,,,,0,,,,,,"error javadoc:
{code}consumer.subscribe(""topic"");{code}
fix:
{code}consumer.subscribe(Arrays.asList(""topic""));{code}

Since KafkaConsumer.subscribe() method uses List as the input type, using string ""topic"" will get an error.",,githubbot,guozhang,vesense,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Dec 11 19:33:30 UTC 2015,,,,,,,,,,"0|i2prhb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"11/Dec/15 18:27;githubbot;GitHub user vesense opened a pull request:

    https://github.com/apache/kafka/pull/668

    KAFKA-2981: Fix javadoc in KafkaConsumer

    https://issues.apache.org/jira/browse/KAFKA-2981

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/vesense/kafka patch-2

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/668.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #668
    
----
commit ab23830a67d3e02c4ba0cada87dc2e98e09ceb44
Author: Xin Wang <best.wangxin@163.com>
Date:   2015-12-11T10:11:09Z

    fix javadoc in KafkaConsumer

----
;;;","12/Dec/15 03:33;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/668
;;;","12/Dec/15 03:33;guozhang;Issue resolved by pull request 668
[https://github.com/apache/kafka/pull/668];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsumerMetadataResponse is not read completely,KAFKA-1491,12720694,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,jjkoshy,jjkoshy,12/Jun/14 05:01,22/Jul/14 22:27,22/Mar/23 15:10,28/Jun/14 02:11,,,,,,,0.8.2.0,,,,,,,,,,,0,,,,,,"This is a regression after KAFKA-1437

The broker always populates the coordinator broker field, but the consumer may do a partial read if error code is non-zero. It should always read the field or we will probably end up with a buffer overflow exception of some sort when reading from a response that has a non-zero error code.",,jjkoshy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jun/14 07:18;jjkoshy;KAFKA-1491.patch;https://issues.apache.org/jira/secure/attachment/12649942/KAFKA-1491.patch","12/Jun/14 07:17;jjkoshy;KAFKA-1491.patch;https://issues.apache.org/jira/secure/attachment/12649941/KAFKA-1491.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,398893,,,Fri Jun 27 18:11:01 UTC 2014,,,,,,,,,,"0|i1wo8n:",399015,,,,,,,,,,,,,,,,,,,,"12/Jun/14 07:06;jjkoshy;So it turns out this is not as bad as I thought.

We read ConsumerMetadatResponse's through a request channel in ClientUtils.
The entire response is received and we just call readFrom on the underlying
buffer. It's fine if we ignore the remaining since retries create a new
BoundedByteBufferReceive.

I verified this locally.

That said, we may as well change the code to always read the coordinator.

;;;","12/Jun/14 07:17;jjkoshy;Created reviewboard  against branch origin/trunk;;;","12/Jun/14 07:18;jjkoshy;Created reviewboard https://reviews.apache.org/r/22482/diff/
 against branch origin/trunk;;;","28/Jun/14 02:11;jjkoshy;Committed (changed the log level to debug - Neha's review comment).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ZkUtils updateEphemeralPath JavaDoc (spelling and correctness),KAFKA-2167,12826948,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,jonbringhurst,jonbringhurst,04/May/15 23:31,16/Feb/18 00:59,22/Mar/23 15:10,16/Feb/18 00:59,,,,,,,,,,,,,,,,,,0,newbie,,,,,"I'm not 100% sure on this, but it seems like ""persistent"" should instead say ""ephemeral"" in the JavaDoc. Also, note that ""parrent"" is misspelled.

{noformat}
  /**
   * Update the value of a persistent node with the given path and data.
   * create parrent directory if necessary. Never throw NodeExistException.
   */
  def updateEphemeralPath(client: ZkClient, path: String, data: String): Unit = {
    try {
      client.writeData(path, data)
    }
    catch {
      case e: ZkNoNodeException => {
        createParentPath(client, path)
        client.createEphemeral(path, data)
      }
      case e2 => throw e2
    }
  }
{noformat}

should be:

{noformat}
  /**
   * Update the value of an ephemeral node with the given path and data.
   * create parent directory if necessary. Never throw NodeExistException.
   */
  def updateEphemeralPath(client: ZkClient, path: String, data: String): Unit = {
    try {
      client.writeData(path, data)
    }
    catch {
      case e: ZkNoNodeException => {
        createParentPath(client, path)
        client.createEphemeral(path, data)
      }
      case e2 => throw e2
    }
  }
{noformat}",,andrew.musselman,andy.chambers@fundingcircle.com,githubbot,jonbringhurst,qwertymaniac,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Sep 21 20:22:03 UTC 2017,,,,,,,,,,"0|i2e8zz:",9223372036854775807,,nehanarkhede,,,,,,,,,,,,,,,,,,"12/May/15 13:25;githubbot;GitHub user neeleshCloud opened a pull request:

    https://github.com/apache/kafka/pull/63

    Corrected the Changes in ZkUtils.scala - KAFKA-2167

    Corrected Spelling errors.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/neeleshCloud/kafka 0.8.2

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/63.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #63
    
----
commit 904af08e2437d2ddf57017a3f3f1decc2087c491
Author: Neelesh Srinivas Salian <nsalian@cloudera.com>
Date:   2015-05-12T05:17:42Z

    KAFKA-2167

----
;;;","13/May/15 05:24;githubbot;GitHub user nssalian opened a pull request:

    https://github.com/apache/kafka/pull/64

    Kafka 2167

    Changed ZkUtils.scala for KAFKA-2167

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/nssalian/kafka KAFKA-2167

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/64.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #64
    
----
commit 904af08e2437d2ddf57017a3f3f1decc2087c491
Author: Neelesh Srinivas Salian <nsalian@cloudera.com>
Date:   2015-05-12T05:17:42Z

    KAFKA-2167

commit aa86ba400eab8d1511418ef7fea5f3d06db03b18
Author: Neelesh Srinivas Salian <nsalian@cloudera.com>
Date:   2015-05-12T21:09:01Z

    Revert ""KAFKA-2167""
    
    This reverts commit 904af08e2437d2ddf57017a3f3f1decc2087c491.

commit 61cbb120e12c60fc952b2e2fdb96db5111e1551a
Author: Neelesh Srinivas Salian <nsalian@cloudera.com>
Date:   2015-05-12T21:20:06Z

    Changed ZkUtils.scala

----
;;;","13/May/15 05:25;githubbot;Github user nssalian closed the pull request at:

    https://github.com/apache/kafka/pull/63
;;;","14/May/15 01:42;neelesh77;Here is the pull request:
https://github.com/apache/kafka/pull/64;;;","14/May/15 01:45;neelesh77;Updated fix version from 0.8.2 to 0.8.3;;;","18/Oct/16 02:24;andrew.musselman;Looks like this ticket should be closed.;;;","22/Sep/17 04:22;andy.chambers@fundingcircle.com;Yeah please close. This is fixed in trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
StreamingConfig getConsumerConfiigs uses getRestoreConsumerConfigs instead of  getBaseConsumerConfigs,KAFKA-2902,12916688,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,bbejeck,bbejeck,bbejeck,28/Nov/15 05:01,22/Feb/17 09:07,22/Mar/23 15:10,03/Dec/15 10:40,0.10.0.0,,,,,,0.10.0.0,,,,,,,streams,,,,0,,,,,,"When starting a KafkaStreaming instance the StreamingConfig.getConsumerConfigs method uses the getRestoreConsumerConfigs to retrieve properties. But this method removes the groupId property which causes an error and the KafkaStreaming instance shuts down.  On KafkaStreaming startup StreamingConfig should use getBaseConsumerConfigs instead.

Exception in thread ""StreamThread-1"" org.apache.kafka.common.KafkaException: org.apache.kafka.common.errors.ApiException: The configured groupId is invalid
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:309)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:198)
Caused by: org.apache.kafka.common.errors.ApiException: The configured groupId is invalid ",,bbejeck,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Dec 03 02:40:25 UTC 2015,,,,,,,,,,"0|i2p0pz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"28/Nov/15 06:52;bbejeck;Changes made for using getBaseConsumerProps from StreamingConfig from getConsumerProps call;;;","03/Dec/15 10:40;guozhang;Issue resolved by pull request 596
[https://github.com/apache/kafka/pull/596];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SASL implementation checks for unused System property java.security.auth.login.config,KAFKA-3279,12942977,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,rsivaram,rsivaram,rsivaram,24/Feb/16 23:11,09/Mar/16 15:40,22/Mar/23 15:10,09/Mar/16 15:40,,,,,,,0.10.0.0,,,,,,,security,,,,0,,,,,,"In many environments (eg. JEE containers), JAAS configuration may be set using methods different from the System property {{java.security.auth.login.config}}. While Kafka obtains JAAS configuration correctly using {{Configuration.getConfiguration()}},  an exception is thrown if the System property {{java.security.auth.login.config}} is not set even when the property is never used. There are also misleading error messages which refer to the value of this property which may or may not be the configuration for which the error is being reported. 
",,ewencp,githubbot,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Mar 09 07:40:46 UTC 2016,,,,,,,,,,"0|i2thjb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"24/Feb/16 23:51;githubbot;GitHub user rajinisivaram opened a pull request:

    https://github.com/apache/kafka/pull/967

    KAFKA-3279: Remove checks for JAAS system property

    JAAS configuration may be set using other methods and hence the check for System property doesn't  always match where the actual configuration used by Kafka is loaded from.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/rajinisivaram/kafka KAFKA-3279

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/967.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #967
    
----
commit 16f17a90412a8f66a942e0c6736578b95ef7942b
Author: Rajini Sivaram <rajinisivaram@googlemail.com>
Date:   2016-02-24T15:39:09Z

    KAFKA-3279: Remove checks for system property
    java.security.auth.login.config

----
;;;","09/Mar/16 15:40;ewencp;Issue resolved by pull request 967
[https://github.com/apache/kafka/pull/967];;;","09/Mar/16 15:40;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/967
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Async onCompletion callback may not be called,KAFKA-2060,12785989,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,,bsobel,bsobel,27/Mar/15 03:43,25/May/17 05:40,22/Mar/23 15:10,25/May/17 05:40,0.8.1.2,,,,,,0.9.0.2,,,,,,,clients,,,,1,easyfix,,,,,"The 'done' function in RecordBatch.java attempts to enumerate and call each onCompletion() callback.  However the call to thunk.future.get() can throw an exception.  When this occurs the callback is not invoked.  This appears to be the only place where a callback per async send would not occur and the callback orphaned.

The call to thunk.future.get() appears to need to occur in its own try/catch and then the onCompletion called with the results if it doesn't throw an exception or thunk.callback.onCompletion(null, recordException) if it does.

e.g.

    /**
     * Complete the request
     * 
     * @param baseOffset The base offset of the messages assigned by the server
     * @param exception The exception that occurred (or null if the request was successful)
     */
    public void done(long baseOffset, RuntimeException exception) {
        this.produceFuture.done(topicPartition, baseOffset, exception);
        log.trace(""Produced messages to topic-partition {} with base offset offset {} and error: {}."",
                  topicPartition,
                  baseOffset,
                  exception);
        // execute callbacks
        for (int i = 0; i < this.thunks.size(); i++) {
            try {
                Thunk thunk = this.thunks.get(i);
                if (exception == null) {
                        RecordMetadata rc = null;
                        try {
                                rc = thunk.future.get();
                        }
                         catch(Exception recordException) {
                                thunk.callback.onCompletion(null, recordException);
                        }
                        if(rc != null) {
                                thunk.callback.onCompletion(rc, null);
                        }
                }
                 else {
                     thunk.callback.onCompletion(null, exception);
                 }

            } catch (Exception e) {
                log.error(""Error executing user-provided callback on message for topic-partition {}:"", topicPartition, e);
            }
        }
    }

",All,bsobel,norden.tom,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed May 24 21:40:14 UTC 2017,,,,,,,,,,"0|i27ezr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"15/Apr/15 20:19;rsivaram;RecordBatch.done() no longer calls thunk.future.get(). This was modified under KAFKA-1865 to invoke the callback with a new RecordMetadata object when there are no exceptions (instead of calling thunk.future.get() which could have thrown an exception). So this issue can be closed.;;;","25/May/17 05:40;bsobel;Per notes this was fixed with the later Kafka libs;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DeleteTopics gives Successful message even if the specified Topic is not present,KAFKA-1177,12683779,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,,siddhesh_toraskar,siddhesh_toraskar,10/Dec/13 14:21,22/Aug/14 08:54,22/Mar/23 15:10,22/Aug/14 08:54,0.8.0,,,,,,,,,,,,,core,,,,0,newbie,,,,,"I am implementating basic functionalities of kafka. I have created some java classes for creating topics , a producer to send messages,a ConsumerGroup to consume those messages and at last,a class for deleting topic. My other functionalities are working normal but my class for deleting topic is not working as required. The problems are:
1. It is displaying 'deletion successful' for the topics not present.
2. If a topic is deleted and then another topic with same name is created, the messages from previous deleted topics are consumed.(This happens till I dont restart the server).
 So, is it required that everytime I delete a topic, I have to restart my kafka server?.Or, there are some other solutions?",Centos 6.3 with jdk 1.6 and apache kafka 0.8,gwenshap,junrao,siddhesh_toraskar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-330,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,362851,,,Fri Aug 22 00:54:21 UTC 2014,,,,,,,,,,"0|i1qjpj:",363157,,,,,,,,,,,,,,,,,,,,"11/Dec/13 00:06;junrao;Deleting topics is not supported yet. We have a jira (KAFKA-330) to track that.;;;","11/Dec/13 16:13;siddhesh_toraskar;Hi Jun,
    I think i didnt do homework before creating this issue. I have gone through kafka-330 , kafka-784& other issues and yes, there are already similar ones with the DeleteTopic. I will have to study on this again.
    Thanks,
    Siddhesh;;;","11/Dec/13 16:14;siddhesh_toraskar;Forgot to mention another thing, Long deleting operations are blocking some other operations in kafka as like electing new leader.;;;","22/Aug/14 08:54;gwenshap;Following KAFKA-1443 and KAFKA-1576, this should be resolved.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
IllegalFormatConversionException in Partition.scala,KAFKA-2293,12839607,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,aauradkar,aauradkar,aauradkar,23/Jun/15 01:12,20/Aug/15 07:46,22/Mar/23 15:10,20/Aug/15 07:46,,,,,,,,,,,,,,,,,,0,,,,,,"ERROR [KafkaApis] [kafka-request-handler-9] [kafka-server] [] [KafkaApi-306] error when handling request Name: 
java.util.IllegalFormatConversionException: d != kafka.server.LogOffsetMetadata
        at java.util.Formatter$FormatSpecifier.failConversion(Formatter.java:4302)
        at java.util.Formatter$FormatSpecifier.printInteger(Formatter.java:2793)
        at java.util.Formatter$FormatSpecifier.print(Formatter.java:2747)
        at java.util.Formatter.format(Formatter.java:2520)
        at java.util.Formatter.format(Formatter.java:2455)
        at java.lang.String.format(String.java:2925)
        at scala.collection.immutable.StringLike$class.format(StringLike.scala:266)
        at scala.collection.immutable.StringOps.format(StringOps.scala:31)
        at kafka.cluster.Partition.updateReplicaLogReadResult(Partition.scala:253)
        at kafka.server.ReplicaManager$$anonfun$updateFollowerLogReadResults$2.apply(ReplicaManager.scala:791)
        at kafka.server.ReplicaManager$$anonfun$updateFollowerLogReadResults$2.apply(ReplicaManager.scala:788)
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:109)
        at kafka.server.ReplicaManager.updateFollowerLogReadResults(ReplicaManager.scala:788)
        at kafka.server.ReplicaManager.fetchMessages(ReplicaManager.scala:433)
",,aauradkar,auradkar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jun/15 01:35;auradkar;KAFKA-2293.patch;https://issues.apache.org/jira/secure/attachment/12741079/KAFKA-2293.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Aug 19 23:46:03 UTC 2015,,,,,,,,,,"0|i2gchr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"23/Jun/15 01:35;auradkar;Created reviewboard https://reviews.apache.org/r/35734/diff/
 against branch origin/trunk;;;","23/Jun/15 01:36;aauradkar;[~junrao] Can you take a look at this minor fix?;;;","20/Aug/15 07:46;aauradkar;Committed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Log4jAppender is unable to send the message.,KAFKA-1283,12697603,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,sriharsha,style95,style95,27/Feb/14 13:51,21/Jun/14 04:24,22/Mar/23 15:10,21/Jun/14 04:24,0.8.0,,,,,,0.8.0,,,,,,,producer ,,,,0,newbie,,,,,"User application can`t send any messages via KafkaLog4jAppender.

Here is log4j.properties.
----------------------------------------------------------------------------------------------
log4j.rootLogger=INFO, stdout, KAFKA

log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%5p [%t] (%F:%L) - %m%n


log4j.appender.KAFKA=kafka.producer.KafkaLog4jAppender
log4j.appender.KAFKA.layout=org.apache.log4j.PatternLayout
log4j.appender.KAFKA.layout.ConversionPattern=%-5p: %c - %m%n
log4j.appender.KAFKA.BrokerList=hnode01:9092
log4j.appender.KAFKA.Topic=DKTestEvent

#log4j.appender.KAFKA.SerializerClass=kafka.log4j.AppenderStringEncoder
----------------------------------------------------------------------------------------------


And this is a sample application.
----------------------------------------------------------------------------------------------
import org.apache.log4j.Logger;
import org.apache.log4j.BasicConfigurator;
import org.apache.log4j.PropertyConfigurator;

public class HelloWorld {

	static Logger logger = Logger.getLogger(HelloWorld.class.getName());

	public static void main(String[] args) {
		PropertyConfigurator.configure(args[0]);

		logger.info(""Entering application."");
		logger.debug(""Debugging!."");
		logger.info(""Exiting application."");
	}
}
----------------------------------------------------------------------------------------------

Since my project is maven project, I attached pom.xml also.

----------------------------------------------------------------------------------------------
<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
	xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
	<modelVersion>4.0.0</modelVersion>
	<groupId>com.my.app</groupId>
	<artifactId>log4-appender</artifactId>
	<version>0.0.1-SNAPSHOT</version>

	<dependencies>
		<dependency>
			<groupId>org.apache.kafka</groupId>
			<artifactId>kafka_2.8.2</artifactId>
			<version>0.8.0</version>
		</dependency>

		<dependency>
			<groupId>log4j</groupId>
			<artifactId>log4j</artifactId>
			<version>1.2.17</version>
		</dependency>
	</dependencies>

</project>
----------------------------------------------------------------------------------------------------------


And I am getting these error:
----------------------------------------------------------------------------------------------
INFO [main] (Logging.scala:67) - Verifying properties
 INFO [main] (Logging.scala:67) - Property metadata.broker.list is overridden to hnode01:9092
 INFO [main] (Logging.scala:67) - Property serializer.class is overridden to kafka.serializer.StringEncoder
 INFO [main] (HelloWorld.java:14) - Entering application.
 INFO [main] (HelloWorld.java:14) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 0 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (HelloWorld.java:14) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 1 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (HelloWorld.java:14) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 2 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (HelloWorld.java:14) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 3 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (HelloWorld.java:14) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 4 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (HelloWorld.java:14) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 5 for 1 topic(s) Set(DKTestEvent)
.
.
.
INFO [main] (HelloWorld.java:14) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 60 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (HelloWorld.java:14) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 61 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (HelloWorld.java:14) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 62 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (Logging.scala:67) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 63 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (Logging.scala:67) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 64 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (Logging.scala:67) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 65 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (Logging.scala:67) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 66 for 1 topic(s) Set(DKTestEvent)
 INFO [main] (Logging.scala:67) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 67 for 1 topic(s) Set(DKTestEvent)
.
.
.
 INFO [main] (Logging.scala:67) - Fetching metadata from broker id:0,host:hnode01,port:9092 with correlation id 534 for 1 topic(s) Set(DKTestEvent)
ERROR [main] (Logging.scala:67) - 
ERROR [main] (Logging.scala:67) - 
ERROR [main] (Logging.scala:67) - 
ERROR [main] (Logging.scala:67) - 
ERROR [main] (Logging.scala:67) - 
ERROR [main] (Logging.scala:67) - 
java.lang.StackOverflowError
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:643)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:277)
	at java.net.URLClassLoader.access$000(URLClassLoader.java:73)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:212)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:205)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:323)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:294)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:268)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:643)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:277)
	at java.net.URLClassLoader.access$000(URLClassLoader.java:73)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:212)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:205)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:323)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:294)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:268)
	at org.apache.log4j.spi.ThrowableInformation.getThrowableStrRep(ThrowableInformation.java:87)
	at org.apache.log4j.spi.LoggingEvent.getThrowableStrRep(LoggingEvent.java:413)
	at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:313)
	at org.apache.log4j.WriterAppender.append(WriterAppender.java:162)
	at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
	at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
	at org.apache.log4j.Category.callAppenders(Category.java:206)
	at org.apache.log4j.Category.forcedLog(Category.java:391)
	at org.apache.log4j.Category.error(Category.java:322)
	at kafka.utils.Logging$$anonfun$swallowError$1.apply(Logging.scala:105)
	at kafka.utils.Logging$$anonfun$swallowError$1.apply(Logging.scala:105)
	at kafka.utils.Utils$.swallow(Utils.scala:189)
	at kafka.utils.Logging$class.swallowError(Logging.scala:105)
	at kafka.utils.Utils$.swallowError(Utils.scala:46)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:67)
	at kafka.producer.Producer.send(Producer.scala:76)
	at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:96)
	at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
	at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
	at org.apache.log4j.Category.callAppenders(Category.java:206)
	at org.apache.log4j.Category.forcedLog(Category.java:391)
	at org.apache.log4j.Category.info(Category.java:666)
	at kafka.utils.Logging$class.info(Logging.scala:67)
	at kafka.client.ClientUtils$.info(ClientUtils.scala:31)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:51)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.async.DefaultEventHandler$$anonfun$handle$1.apply$mcV$sp(DefaultEventHandler.scala:67)
	at kafka.utils.Utils$.swallow(Utils.scala:187)
	at kafka.utils.Logging$class.swallowError(Logging.scala:105)
	at kafka.utils.Utils$.swallowError(Utils.scala:46)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:67)
	at kafka.producer.Producer.send(Producer.scala:76)
	at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:96)
	at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
	at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
.
.
.
----------------------------------------------------------------------------------------------

I am getting above error continuously if i don`t terminate the program.",ubuntu. eclipse.,babakbehzad,cwimmer,nehanarkhede,sriharsha,style95,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,376077,,,Fri Jun 20 20:24:36 UTC 2014,,,,,,,,,,"0|i1st0n:",376373,,,,,,,,,,,,,,,,,,,,"05/Jun/14 06:17;babakbehzad;Any progress on this? I am having the same issue!;;;","05/Jun/14 13:32;nehanarkhede;[~babakbehzad] Not really so far. We are up for reviewing your patch, if you'd like to take a stab at the fix.;;;","19/Jun/14 13:13;babakbehzad;[~nehanarkhede]: I came up with a patch for this today! I am not sure if it's a general one, but it works for our case. Should I sync up with  [~harsha_ch]?;;;","20/Jun/14 23:38;sriharsha;[~nehanarkhede] [~babakbehzad] It looks like this issue is fixed in the trunk but I am able to reproduce this in 0.8.1.
Do we need to fix this in 0.8.1 branch.
;;;","20/Jun/14 23:50;babakbehzad;Great! I can test this soon. I will let you know about the results.;;;","21/Jun/14 04:19;babakbehzad;Thanks [~sriharsha]. I pulled the trunk and the issue is fixed. I can see that current correct Log4j appender is using KafkaProducer client rather than a Kafka Producer which makes more sense. There's however some lack of features (such as not handling Log4j ConversionPattern, etc.). [~nehanarkhede], should I create a new Jira for this and you want to close this one?;;;","21/Jun/14 04:24;nehanarkhede;bq.  Neha Narkhede, should I create a new Jira for this and you want to close this one?

Sure. That makes sense.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Broker startup, leader election, becoming a leader/follower for intra-cluster replication",KAFKA-45,12514682,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,junrao,,20/Jul/11 05:32,11/Jun/12 04:40,22/Mar/23 15:10,11/Jun/12 04:40,,,,,,,,,,,,,,,,,,0,,,,,,"We need to implement the logic for starting a broker with replicated partitions, the leader election logic and how to become a leader and a follower.",,nehanarkhede,prashanth.menon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-307,KAFKA-306,KAFKA-50,,,,,,,,,,,,KAFKA-44,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,67070,,,Sun Jun 10 20:40:36 UTC 2012,,,,,,,,,,"0|i15yov:",242920,,,,,,,,,,,,,,,,,,,,"13/Feb/12 07:15;prashanth.menon;Hey everyone.  Since the ZK structures are effectively done as part of KAFKA-47, I thought I'd start on this ticket.  Something that came up was the log cleanup functionality within LogManager will need to be tweaked.  My thinking is that Replica's should manage the cleanup of their local logs (moving that functionality from LogManager) and need to be in-sync with the leader with respect to hw, logEndOffset, and also the logMinOffset; essentially, the amount of data available on all ISR for replica R must be the same reglardless of each individual broker's log cleanup configuration.  Not sure how that information should be propagated, whether through the follower's fetch request or somewhere in ZK, that should be left up to discussion.  Regardless, non-leader replica's can use this minOffset to perform local log cleanups, I suppose.  Please do let me know if I'm missing a peice of the puzzle here or if there's a simpler solution.
;;;","16/Feb/12 03:17;nehanarkhede;Prashanth,

Thanks for helping out on replication and getting in the format changes. Before starting on this, we are blocked on KAFKA-49 and KAFKA-44. It seems like it will be most effective to get some help on these JIRAs first. Just a suggestion, comments are welcome!

;;;","16/Feb/12 10:16;prashanth.menon;No worries.  The reason I chose to start here was that I felt it required the creation of some of the base entities required for KAFKA-49 and KAFKA-44.  Since 49 is still semi-blocked by 240 on the produce-side, I didn't want to make too many changes there.  44 on the other hand, makes use of some of algorithms used as part of start up.  Thinking about it, 44 is probably a better place to start in terms of complexity.  Thanks!  ;;;","22/Feb/12 06:27;junrao;Prashanth,

That's a good question. We'd like to make replicas identical with each other. This is easy for size-based log retention, but harder for time-based log retention. What you proposed is to have only the leader delete old log segments and propagate this information to the followers. This seems like a reasonable approach. The question is how should the leader communicate such information to the followers. One possibility is to piggyback on the FetchResponse returned to the followers. This will mean some extra optional fields in FetchResponse.;;;","10/Mar/12 05:56;jkreps;I think we are overthinking this. Currently cleanup is not a precise SLA, it is just a guarantee of the form ""we will never delete anything younger than X OR we will always maintain at least Y bytes of messages"". Trying to maintain this in synchronous form across nodes is overkill I think. It is fine if every node acts independently as long as each of them respects the SLA. I think this should be much simpler and more likely to work.;;;","13/Mar/12 06:40;nehanarkhede;Here is something to think about wrt to leader election and replica failures -

If there are 3 replicas for a partition, and the leader acks the produce request once the request is acked by the 2 followers. The produce request doesn't care about the replication factor. So if one of the followers is slow, the leader will receive less than 2 acks from the followers, and it will go ahead and send a success ACK to the producer. The replicas update their HW only on the next replica fetch response. Since the HW committer thread is running independently. it is possible that the checkpointed HW of one of the 3 replicas is lower than the others. 

If at this point, if leader fails, it will trigger the leader election procedure. According to the current design proposal, any replica in the ISR can become the leader. If the replica with the lower HW becomes the leader, then it will truncate its log upto this last checkpointed HW and start taking produce requests from there. The other 2 replicas, will send ReplicaFetchRequests with an offset that doesn't exist on the leader.

Effectively, it seems that we will end up losing some successfully acknowledged produce requests. Probably, the leader election procedure should check the HW of the participating replicas and give preference to replica with highest HW ?;;;","14/Mar/12 06:33;junrao;If there are 2 followers and leader receives ack from only follow 1, but not follower 2 (within timeout), the leader will kick follower 2 from ISR before it can commit the message and ack the producer. So, follower 2 will never get a chance to become the new leader should the current leader fail.;;;","11/Jun/12 04:40;nehanarkhede;Resolved as part of KAFKA-46;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to access kafka via Tomcat,KAFKA-893,12645684,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,arathim,arathim,02/May/13 03:18,22/May/14 00:34,22/Mar/23 15:10,22/May/14 00:34,,,,,,,,,,,,,,tools,,,,1,,,,,,"Iam using kafka_2.8.0-0.8-SNAPSHOT.jar and Apache Tomcat 7. Upon deploying, the Consumer example (provided at Kafka quickstart) in a Tomcat web app, I get the following error 

java.lang.VerifyError: class scala.Tuple2$mcLL$sp overrides final method _1.()Ljava/lang/Object;
	java.lang.ClassLoader.defineClass1(Native Method)
	java.lang.ClassLoader.defineClass(ClassLoader.java:791)
	java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	org.apache.catalina.loader.WebappClassLoader.findClassInternal(WebappClassLoader.java:2888)
	org.apache.catalina.loader.WebappClassLoader.findClass(WebappClassLoader.java:1172)
	org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1680)
	org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1558)
	kafka.consumer.ConsumerConfig.<init>(ConsumerConfig.scala:75)
	TestServlet.kafkaconsumer(TestServlet.java:44)
	TestServlet.doGet(TestServlet.java:20)
	javax.servlet.http.HttpServlet.service(HttpServlet.java:621)
	javax.servlet.http.HttpServlet.service(HttpServlet.java:728)

Please suggest what should be done to fix this error.

Thanks in advance.
Arathi
",Apache Tomcat 7,arathim,jkreps,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,326045,,,Wed May 21 16:34:15 UTC 2014,,,,,,,,,,"0|i1k8zz:",326390,,,,,,,,,,,,,,,,,,,,"03/Jul/13 11:50;jkreps;I think this happens if you have the wrong version of scala on your classpath.;;;","22/May/14 00:34;arathim;Using Kafka dependency in my maven pom.xml
<dependency>
       <groupId>org.apache.kafka</groupId>
       <artifactId>kafka_2.10</artifactId>
       <version>0.8.0</version>
</dependency>
 fixed the issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE thrown while handling DescribeGroup request for non-existent consumer group,KAFKA-2755,12910832,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,singhashish,singhashish,singhashish,06/Nov/15 04:21,06/Nov/15 05:11,22/Mar/23 15:10,06/Nov/15 05:11,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"NPE thrown while handling DescribeGroup request for non-existent consumer group.

{code}
[2015-11-05 12:02:37,455] ERROR [KafkaApi-0] error when handling request null (kafka.server.KafkaApis)
java.lang.NullPointerException
	at kafka.server.KafkaApis$$anonfun$31.apply(KafkaApis.scala:734)
	at kafka.server.KafkaApis$$anonfun$31.apply(KafkaApis.scala:728)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.server.KafkaApis.handleDescribeGroupRequest(KafkaApis.scala:728)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:82)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
{code}",,githubbot,guozhang,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 05 21:11:33 UTC 2015,,,,,,,,,,"0|i2o0tj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"06/Nov/15 04:30;githubbot;GitHub user SinghAsDev opened a pull request:

    https://github.com/apache/kafka/pull/435

    KAFKA-2755: NPE thrown while handling DescribeGroup request for non-e…

    …xistent consumer group

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/SinghAsDev/kafka KAFKA-2755

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/435.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #435
    
----
commit d5e3e9dbc0dd15ed7e30c1137d185df10060cb6b
Author: Ashish Singh <asingh@cloudera.com>
Date:   2015-11-05T20:29:03Z

    KAFKA-2755: NPE thrown while handling DescribeGroup request for non-existent consumer group

----
;;;","06/Nov/15 04:31;singhashish;[~hachikuji], [~guozhang] mind taking a look?;;;","06/Nov/15 05:11;guozhang;Issue resolved by pull request 435
[https://github.com/apache/kafka/pull/435];;;","06/Nov/15 05:11;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/435
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New producer should emit metrics for buffer exhaustion,KAFKA-2306,12841553,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,lindong,lindong,lindong,30/Jun/15 12:00,08/Jul/15 03:43,22/Mar/23 15:10,08/Jul/15 03:43,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"In the old producer we have droppedMessageRate that allows user to monitor the number of messages dropped when buffer is full and block on buffer full is set to false. This metric is useful in operation. However, in the new producer we don't have this a metric.

The ""errors"" sensor in new-producers measures per-record error that is not limited to those caused by BufferExhaustedException. Thus it is not good enough.
",,guozhang,lindong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/15 12:04;lindong;KAFKA-2306.patch;https://issues.apache.org/jira/secure/attachment/12742703/KAFKA-2306.patch","07/Jul/15 05:54;lindong;KAFKA-2306_2015-07-06_14:54:01.patch;https://issues.apache.org/jira/secure/attachment/12743812/KAFKA-2306_2015-07-06_14%3A54%3A01.patch","07/Jul/15 09:22;lindong;KAFKA-2306_2015-07-06_18:21:43.patch;https://issues.apache.org/jira/secure/attachment/12743862/KAFKA-2306_2015-07-06_18%3A21%3A43.patch","08/Jul/15 01:47;lindong;KAFKA-2306_2015-07-07_10:47:10.patch;https://issues.apache.org/jira/secure/attachment/12744004/KAFKA-2306_2015-07-07_10%3A47%3A10.patch",,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jul 07 19:43:50 UTC 2015,,,,,,,,,,"0|i2gnvr:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"30/Jun/15 12:04;lindong;Created reviewboard https://reviews.apache.org/r/36034/diff/
 against branch origin/trunk;;;","07/Jul/15 05:54;lindong;Updated reviewboard https://reviews.apache.org/r/36034/diff/
 against branch origin/trunk;;;","07/Jul/15 09:22;lindong;Updated reviewboard https://reviews.apache.org/r/36034/diff/
 against branch origin/trunk;;;","08/Jul/15 01:47;lindong;Updated reviewboard https://reviews.apache.org/r/36034/diff/
 against branch origin/trunk;;;","08/Jul/15 03:43;guozhang;Thanks for the patch. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CompressionUtilTest does not run and fails when it does,KAFKA-192,12530476,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,joestein,joestein,joestein,06/Nov/11 14:51,15/Nov/11 05:55,22/Mar/23 15:10,13/Nov/11 07:05,,,,,,,0.8.0,,,,,,,,,,,0,,,,,,"CompressionUtilTest does not run the functions inside of it during ./sbt test

if you change CompressionUtilTest to extend JUnitSuite then the existing functions run (once you adorne them with @Test) but then fail ...

I suspect the TestUtils.checkEquals(messages.iterator, decompressedMessages.iterator) is failing in testSimpleCompressDecompress because all of the messages are serialized into byte arrays and the entire set of messages compressed and that new compressed messages is what is returned as one message instead of the List[Message] and therefor are not interpreted within TestUtil.checkEquals to see this nuance.

e.g.

[error] Test Failed: testSimpleCompressDecompress
junit.framework.AssertionFailedError: expected:<message(magic = 1, attributes = 0, crc = 3819140844, payload = java.nio.HeapByteBuffer[pos=0 lim=8 cap=8])> but was:<MessageAndOffset(message(magic = 1, attributes = 0, crc = 3819140844, payload = java.nio.HeapByteBuffer[pos=0 lim=8 cap=8]),18)>

and

[error] Test Failed: testComplexCompressDecompress
junit.framework.AssertionFailedError: expected:<2> but was:<3>
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-187,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/11 02:58;joestein;kafka-192.patch;https://issues.apache.org/jira/secure/attachment/12502681/kafka-192.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,216214,,,Sun Nov 06 19:07:58 UTC 2011,,,,,,,,,,"0|i09mbr:",54050,,,,,,,,,,,,,,,,,,,,"07/Nov/11 02:58;joestein;made the tests run and fixed them so they succeed (as they should have to compare messages to messages);;;","07/Nov/11 03:07;nehanarkhede;+1. Excellent ! thanks for the patch. Just committed this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kakfa broker not deleting logs after configured retention time properly,KAFKA-2623,12903172,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,superpony25,superpony25,08/Oct/15 07:10,08/Sep/17 03:27,22/Mar/23 15:10,08/Sep/17 03:27,0.8.2.0,,,,,,,,,,,,,log,,,,0,,,,,,"Context:
To get an accurate estimate on how much retention we have for each topic/partition, we have a cron job iterating each topic/partition folder on each node of a cluster, measuring the timestamp difference between the newest and oldest log files. 

Problem:
We notice that it's very common that between leaders and followers, the time differences are vastly different. On the leader the timestamp differences are normally about a week (our retention policy), but on the follower the timestamp differences can sometimes range between just a few hours to 2-3 days.

-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:48 00000000001536840178.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:48 00000000001537497855.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:48 00000000001538155208.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:48 00000000001538811692.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:48 00000000001539468154.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:48 00000000001540122891.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:48 00000000001540775681.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:48 00000000001541430669.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:48 00000000001542088333.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:48 00000000001542746722.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:49 00000000001543405006.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:49 00000000001544062197.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:49 00000000001544718413.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:49 00000000001545374173.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:49 00000000001546029145.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:49 00000000001546686144.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:49 00000000001547344190.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:49 00000000001548001698.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:49 00000000001548657672.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:49 00000000001549312958.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:49 00000000001549969014.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:50 00000000001550623380.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:50 00000000001551279821.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:50 00000000001551937920.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:50 00000000001552597354.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:50 00000000001553256336.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:50 00000000001553914505.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:50 00000000001554571426.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:50 00000000001555228277.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:50 00000000001555882081.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:50 00000000001556538902.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:50 00000000001557196332.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:51 00000000001557852974.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:51 00000000001558510709.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:51 00000000001559166839.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:51 00000000001559823667.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:51 00000000001560478631.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:51 00000000001561136505.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:51 00000000001561792222.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:51 00000000001562450149.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:51 00000000001563107321.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:51 00000000001563763826.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:52 00000000001564420526.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:52 00000000001565076456.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:52 00000000001565735877.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:52 00000000001566394151.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:52 00000000001567051743.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:52 00000000001567709678.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:52 00000000001568366114.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 05:52 00000000001569022963.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 08:09 00000000001569681970.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 10:37 00000000001570340180.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 13:05 00000000001570997358.log
-rw-rw-r-- 1 kloak kloak 256M Oct  4 16:11 00000000001571654289.log
-rw-rw-r-- 1 kloak kloak 256M Oct  5 01:56 00000000001572310787.log
-rw-rw-r-- 1 kloak kloak 256M Oct  5 05:20 00000000001572967484.log
-rw-rw-r-- 1 kloak kloak 256M Oct  5 08:19 00000000001573626503.log
-rw-rw-r-- 1 kloak kloak 256M Oct  5 11:02 00000000001574284909.log
-rw-rw-r-- 1 kloak kloak 256M Oct  5 13:49 00000000001574944379.log
-rw-rw-r-- 1 kloak kloak 256M Oct  5 18:26 00000000001575603057.log
-rw-rw-r-- 1 kloak kloak  28M Oct  5 21:02 00000000001576258146.log

Observation:
We noticed that there are a lot of index files with size 200. The modified timestamp of these index files are pretty much identical.

-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:48 00000000001536840178.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:48 00000000001537497855.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:48 00000000001538155208.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:48 00000000001538811692.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:48 00000000001539468154.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:48 00000000001540122891.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:48 00000000001540775681.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:48 00000000001541430669.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:48 00000000001542088333.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:48 00000000001542746722.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:49 00000000001543405006.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:49 00000000001544062197.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:49 00000000001544718413.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:49 00000000001545374173.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:49 00000000001546029145.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:49 00000000001546686144.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:49 00000000001547344190.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:49 00000000001548001698.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:49 00000000001548657672.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:49 00000000001549312958.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:49 00000000001549969014.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:50 00000000001550623380.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:50 00000000001551279821.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:50 00000000001551937920.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:50 00000000001552597354.index
-rw-rw-r-- 1 kloak kloak  200 Oct  4 05:50 00000000001553256336.index

Theory:
Our guess is that the broker is trying to delete these log and index files, thus the timestamps are all modified at pretty much the same time. However, for some reason the deletion doesn't succeed and thus leave all the log/index files with the same timestamp. But there is no log deletion error in the log whatsoever.","DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=12.04
DISTRIB_CODENAME=precise
DISTRIB_DESCRIPTION=""Ubuntu 12.04.5 LTS""
NAME=""Ubuntu""
VERSION=""12.04.5 LTS, Precise Pangolin""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu precise (12.04.5 LTS)""
VERSION_ID=""12.04""",becket_qin,omkreddy,superpony25,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Sep 07 19:27:46 UTC 2017,,,,,,,,,,"0|i2mpxj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"09/Oct/15 01:16;becket_qin;[~hzhang] Yes, this is a known issue and will be solve by KIP-32. This is because today we do not pass the timestamp from leader to followers. The log retention is based on the file create time/last modification time. That's why the followers can have different timestamp from leader and the retention might not be honored on some replicas.;;;","08/Sep/17 03:27;omkreddy; Time-based log retention is enforced in KIP-33.  Pl reopen if you think the issue still exists
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Should log unexpected exceptions thrown when reading from local log,KAFKA-2899,12916506,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,benstopford,benstopford,benstopford,27/Nov/15 02:52,28/Nov/15 04:15,22/Mar/23 15:10,28/Nov/15 04:14,,,,,,,0.9.0.1,,,,,,,,,,,0,,,,,,,,benstopford,githubbot,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Nov 27 20:14:22 UTC 2015,,,,,,,,,,"0|i2ozlr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"27/Nov/15 02:55;githubbot;GitHub user benstopford opened a pull request:

    https://github.com/apache/kafka/pull/593

    KAFKA-2899: (trivial) Log unexpected exceptions thrown when reading local log

    Currently we don't log exceptions raised when reading from the local log which makes tracking down the cause of problems a bit tricky. 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/benstopford/kafka small-patches

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/593.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #593
    
----
commit c30313871fb539ba4d484145fda7b94e88b89921
Author: Ben Stopford <benstopford@gmail.com>
Date:   2015-11-26T18:52:55Z

    KAFKA-2899: Should log unexpected exceptions thrown when reading from local log

----
;;;","28/Nov/15 04:14;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/593
;;;","28/Nov/15 04:14;guozhang;Issue resolved by pull request 593
[https://github.com/apache/kafka/pull/593];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
selector doesn't close socket connection on non-IOExceptions,KAFKA-2813,12912345,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,junrao,junrao,junrao,12/Nov/15 07:51,12/Nov/15 14:18,22/Mar/23 15:10,12/Nov/15 14:18,,,,,,,0.9.0.0,,,,,,,core,,,,0,,,,,,"When running a system test, we saw lots of entries like the following. The issue is that when the current leader switches to the follower, we will truncate the log in the follower. It's possible there is a concurrent fetch request being served at this moment. If this happens, we throw a KafkaException when trying to send the fetch response (in FileMessageSet). The exception will propagate through Selector.poll(). Selector catches IOException and closes the corresponding socket. However, KafkaException is not an IOException. Since the socket is not closed, Selector.poll() will keep accessing the socket and keep getting the same error.

[2015-11-11 07:25:01,150] ERROR Processor got uncaught exception. (kafka.network.Processor)
kafka.common.KafkaException: Size of FileMessageSet /mnt/kafka-data-logs/test_topic-0/00000000000000000000.log has been truncated during write: old size 16368, new size 0
        at kafka.log.FileMessageSet.writeTo(FileMessageSet.scala:158)
        at kafka.api.PartitionDataSend.writeTo(FetchResponse.scala:77)
        at org.apache.kafka.common.network.MultiSend.writeTo(MultiSend.java:81)
        at kafka.api.TopicDataSend.writeTo(FetchResponse.scala:148)
        at org.apache.kafka.common.network.MultiSend.writeTo(MultiSend.java:81)
        at kafka.api.FetchResponseSend.writeTo(FetchResponse.scala:291)
        at org.apache.kafka.common.network.KafkaChannel.send(KafkaChannel.java:165)
        at org.apache.kafka.common.network.KafkaChannel.write(KafkaChannel.java:152)
        at org.apache.kafka.common.network.Selector.poll(Selector.java:301)
        at kafka.network.Processor.run(SocketServer.scala:413)
        at java.lang.Thread.run(Thread.java:745)
",,githubbot,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 12 06:18:55 UTC 2015,,,,,,,,,,"0|i2oa0n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"12/Nov/15 09:14;githubbot;GitHub user junrao opened a pull request:

    https://github.com/apache/kafka/pull/501

    KAFKA-2813: selector doesn't close socket connection on non-IOExceptions

    Patched Selector.poll() to close the connection on any exception.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/junrao/kafka KAFKA-2813

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/501.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #501
    
----
commit 2a4dfd4d63f3b3383d9ce01fce7c2be151ef9f78
Author: Jun Rao <junrao@gmail.com>
Date:   2015-11-12T01:11:49Z

    KAFKA-2813: selector doesn't close socket connection on non-IOExceptions

----
;;;","12/Nov/15 14:18;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/501
;;;","12/Nov/15 14:18;junrao;Issue resolved by pull request 501
[https://github.com/apache/kafka/pull/501];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
controller logs exceptions during ZK session expiration,KAFKA-1271,12695902,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,19/Feb/14 10:31,04/Apr/14 00:27,22/Mar/23 15:10,21/Feb/14 01:52,0.8.1,,,,,,0.8.1,,,,,,,,,,,0,,,,,,"Saw the following issues when there is ZK session expiration in the controller.

1. 
 ERROR Error handling event ZkEvent[Children of
/admin/delete_topics changed sent to
kafka.controller.PartitionStateMachine$DeleteTopicsListener@39abdac9]
(org.I0Itec.zkclient.ZkEventThread)
java.lang.NullPointerException
at
scala.collection.JavaConversions$JListWrapper.iterator(JavaConversions.scala:524)
at scala.collection.IterableLike$class.foreach(IterableLike.scala:79)
at
scala.collection.JavaConversions$JListWrapper.foreach(JavaConversions.scala:521)
at
scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:176)
at
scala.collection.JavaConversions$JListWrapper.foldLeft(JavaConversions.scala:521)
at
scala.collection.TraversableOnce$class.$div$colon(TraversableOnce.scala:139)
at
scala.collection.JavaConversions$JListWrapper.$div$colon(JavaConversions.scala:521)
at scala.collection.generic.Addable$class.$plus$plus(Addable.scala:54)
at scala.collection.immutable.Set$EmptySet$.$plus$plus(Set.scala:47)
at scala.collection.TraversableOnce$class.toSet(TraversableOnce.scala:436)
at
scala.collection.JavaConversions$JListWrapper.toSet(JavaConversions.scala:521)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener$$anonfun$handleChildChange$2.apply$mcV$sp(PartitionStateMachine.scala:448)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener$$anonfun$handleChildChange$2.apply(PartitionStateMachine.scala:445)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener$$anonfun$handleChildChange$2.apply(PartitionStateMachine.scala:445)
at kafka.utils.Utils$.inLock(Utils.scala:538)
at
kafka.controller.PartitionStateMachine$DeleteTopicsListener.handleChildChange(PartitionStateMachine.scala:445)
at org.I0Itec.zkclient.ZkClient$7.run(ZkClient.java:570)
at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71) 

2. IllegalStateException due to ""Kafka scheduler has not been started"".",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1272,KAFKA-1270,,,,,,,,,,,,,,,"19/Feb/14 23:57;junrao;KAFKA-1271.patch;https://issues.apache.org/jira/secure/attachment/12629794/KAFKA-1271.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,374383,,,Thu Feb 20 17:52:34 UTC 2014,,,,,,,,,,"0|i1silj:",374683,,,,,,,,,,,,,,,,,,,,"19/Feb/14 23:57;junrao;Created reviewboard https://reviews.apache.org/r/18273/
 against branch origin/trunk;;;","21/Feb/14 01:52;junrao;Thanks for the review. Double committed to trunk and 0.8.1.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NullPointerException in TestPurgatoryPerformance,KAFKA-2226,12833140,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,yasuhiro.matsuda,onurkaraman,onurkaraman,28/May/15 02:46,02/Jun/15 05:15,22/Mar/23 15:10,02/Jun/15 05:15,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"A NullPointerException sometimes shows up in TimerTaskList.remove while running TestPurgatoryPerformance. I’m on the HEAD of trunk.
{code}
> ./bin/kafka-run-class.sh kafka.TestPurgatoryPerformance --key-space-size 100000 --keys 3 --num 100000 --pct50 50 --pct75 75 --rate 1000 --size 50 --timeout 20
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/Users/okaraman/code/kafka/core/build/dependant-libs-2.10.5/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/okaraman/code/kafka/core/build/dependant-libs-2.10.5/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[2015-05-27 10:02:14,782] ERROR [completion thread], Error due to  (kafka.TestPurgatoryPerformance$CompletionQueue$$anon$1)
java.lang.NullPointerException
  at kafka.utils.timer.TimerTaskList.remove(TimerTaskList.scala:80)
  at kafka.utils.timer.TimerTaskEntry.remove(TimerTaskList.scala:128)
  at kafka.utils.timer.TimerTask$class.cancel(TimerTask.scala:27)
  at kafka.server.DelayedOperation.cancel(DelayedOperation.scala:50)
  at kafka.server.DelayedOperation.forceComplete(DelayedOperation.scala:71)
  at kafka.TestPurgatoryPerformance$CompletionQueue$$anon$1.doWork(TestPurgatoryPerformance.scala:263)
  at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)
{code}",,junrao,onurkaraman,yasuhiro.matsuda,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/May/15 05:00;yasuhiro.matsuda;KAFKA-2226.patch;https://issues.apache.org/jira/secure/attachment/12735686/KAFKA-2226.patch","29/May/15 08:19;yasuhiro.matsuda;KAFKA-2226_2015-05-28_17:18:55.patch;https://issues.apache.org/jira/secure/attachment/12736006/KAFKA-2226_2015-05-28_17%3A18%3A55.patch","30/May/15 01:50;yasuhiro.matsuda;KAFKA-2226_2015-05-29_10:49:34.patch;https://issues.apache.org/jira/secure/attachment/12736196/KAFKA-2226_2015-05-29_10%3A49%3A34.patch","30/May/15 06:04;yasuhiro.matsuda;KAFKA-2226_2015-05-29_15:04:35.patch;https://issues.apache.org/jira/secure/attachment/12736256/KAFKA-2226_2015-05-29_15%3A04%3A35.patch","30/May/15 06:10;yasuhiro.matsuda;KAFKA-2226_2015-05-29_15:10:24.patch;https://issues.apache.org/jira/secure/attachment/12736259/KAFKA-2226_2015-05-29_15%3A10%3A24.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jun 01 21:15:56 UTC 2015,,,,,,,,,,"0|i2f9sv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"28/May/15 05:01;yasuhiro.matsuda;Created reviewboard https://reviews.apache.org/r/34734/diff/
 against branch origin/trunk;;;","29/May/15 08:19;yasuhiro.matsuda;Updated reviewboard https://reviews.apache.org/r/34734/diff/
 against branch origin/trunk;;;","30/May/15 01:50;yasuhiro.matsuda;Updated reviewboard https://reviews.apache.org/r/34734/diff/
 against branch origin/trunk;;;","30/May/15 06:05;yasuhiro.matsuda;Updated reviewboard https://reviews.apache.org/r/34734/diff/
 against branch origin/trunk;;;","30/May/15 06:10;yasuhiro.matsuda;Updated reviewboard https://reviews.apache.org/r/34734/diff/
 against branch origin/trunk;;;","02/Jun/15 05:15;junrao;Thanks for the latest patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remote producer uses the hostname defined in broker,KAFKA-1138,12680447,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,vacuus,vacuus,21/Nov/13 14:36,01/Sep/17 02:29,22/Mar/23 15:10,01/Sep/17 02:29,0.8.0,,,,,,,,,,,,,producer ,,,,0,,,,,,"When the producer API in the node which is not the broker sends message to a broker, only TopicMetadataRequest is sent, but ProducerRequest is not by observing the log of ""kafka-request.log""
According to my analysis, when the producer api sends ProducerRequest, it seems to use the hostname defined in the broker. So, if the hostname is not the one registered in DNS, the producer cannot send the ProducerRequest. 


I am attaching the log:

[2013-11-21 15:28:49,464] ERROR Failed to collate messages by topic, partition due to: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(id:0,host:111.111.111.111,port:9092)] failed (kafka.producer.async.DefaultEventHandler)
[2013-11-21 15:28:49,465] INFO Back off for 100 ms before retrying send. Remaining retries = 1 (kafka.producer.async.DefaultEventHandler)
[2013-11-21 15:28:49,566] INFO Fetching metadata from broker id:0,host:111.111.111.111,port:9092 with correlation id 6 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2013-11-21 15:28:49,819] ERROR Producer connection to 111.111.111.111:9092 unsuccessful (kafka.producer.SyncProducer)
java.net.ConnectException: 연결이 거부됨
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:639)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.producer.SyncProducer.connect(SyncProducer.scala:146)
	at kafka.producer.SyncProducer.getOrMakeConnection(SyncProducer.scala:161)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:68)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:53)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.async.DefaultEventHandler$$anonfun$handle$2.apply$mcV$sp(DefaultEventHandler.scala:79)
	at kafka.utils.Utils$.swallow(Utils.scala:186)
	at kafka.utils.Logging$class.swallowError(Logging.scala:105)
	at kafka.utils.Utils$.swallowError(Utils.scala:45)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:79)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:104)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:87)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:67)
	at scala.collection.immutable.Stream.foreach(Stream.scala:254)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:66)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)
[2013-11-21 15:28:49,821] WARN Fetching topic metadata with correlation id 6 for topics [Set(test)] from broker [id:0,host:111.111.111.111,port:9092] failed (kafka.client.ClientUtils$)
java.net.ConnectException: 연결이 거부됨
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:639)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.producer.SyncProducer.connect(SyncProducer.scala:146)
	at kafka.producer.SyncProducer.getOrMakeConnection(SyncProducer.scala:161)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:68)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:53)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.async.DefaultEventHandler$$anonfun$handle$2.apply$mcV$sp(DefaultEventHandler.scala:79)
	at kafka.utils.Utils$.swallow(Utils.scala:186)
	at kafka.utils.Logging$class.swallowError(Logging.scala:105)
	at kafka.utils.Utils$.swallowError(Utils.scala:45)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:79)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:104)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:87)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:67)
	at scala.collection.immutable.Stream.foreach(Stream.scala:254)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:66)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)
[2013-11-21 15:28:49,822] ERROR fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(id:0,host:111.111.111.111,port:9092)] failed (kafka.utils.Utils$)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(id:0,host:111.111.111.111,port:9092)] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:67)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.async.DefaultEventHandler$$anonfun$handle$2.apply$mcV$sp(DefaultEventHandler.scala:79)
	at kafka.utils.Utils$.swallow(Utils.scala:186)
	at kafka.utils.Logging$class.swallowError(Logging.scala:105)
	at kafka.utils.Utils$.swallowError(Utils.scala:45)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:79)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:104)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:87)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:67)
	at scala.collection.immutable.Stream.foreach(Stream.scala:254)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:66)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)
Caused by: java.net.ConnectException: 연결이 거부됨
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:639)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.producer.SyncProducer.connect(SyncProducer.scala:146)
	at kafka.producer.SyncProducer.getOrMakeConnection(SyncProducer.scala:161)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:68)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:53)
	... 12 more
[2013-11-21 15:28:49,825] INFO Fetching metadata from broker id:0,host:111.111.111.111,port:9092 with correlation id 7 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2013-11-21 15:28:50,021] ERROR Producer connection to 111.111.111.111:9092 unsuccessful (kafka.producer.SyncProducer)
java.net.ConnectException: 연결이 거부됨
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:639)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.producer.SyncProducer.connect(SyncProducer.scala:146)
	at kafka.producer.SyncProducer.getOrMakeConnection(SyncProducer.scala:161)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:68)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:53)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.BrokerPartitionInfo.getBrokerPartitionInfo(BrokerPartitionInfo.scala:49)
	at kafka.producer.async.DefaultEventHandler.kafka$producer$async$DefaultEventHandler$$getPartitionListForTopic(DefaultEventHandler.scala:187)
	at kafka.producer.async.DefaultEventHandler$$anonfun$partitionAndCollate$1.apply(DefaultEventHandler.scala:151)
	at kafka.producer.async.DefaultEventHandler$$anonfun$partitionAndCollate$1.apply(DefaultEventHandler.scala:150)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
	at kafka.producer.async.DefaultEventHandler.partitionAndCollate(DefaultEventHandler.scala:150)
	at kafka.producer.async.DefaultEventHandler.dispatchSerializedData(DefaultEventHandler.scala:96)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:73)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:104)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:87)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:67)
	at scala.collection.immutable.Stream.foreach(Stream.scala:254)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:66)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)
[2013-11-21 15:28:50,024] WARN Fetching topic metadata with correlation id 7 for topics [Set(test)] from broker [id:0,host:111.111.111.111,port:9092] failed (kafka.client.ClientUtils$)
java.net.ConnectException: 연결이 거부됨
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:639)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.producer.SyncProducer.connect(SyncProducer.scala:146)
	at kafka.producer.SyncProducer.getOrMakeConnection(SyncProducer.scala:161)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:68)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:53)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.BrokerPartitionInfo.getBrokerPartitionInfo(BrokerPartitionInfo.scala:49)
	at kafka.producer.async.DefaultEventHandler.kafka$producer$async$DefaultEventHandler$$getPartitionListForTopic(DefaultEventHandler.scala:187)
	at kafka.producer.async.DefaultEventHandler$$anonfun$partitionAndCollate$1.apply(DefaultEventHandler.scala:151)
	at kafka.producer.async.DefaultEventHandler$$anonfun$partitionAndCollate$1.apply(DefaultEventHandler.scala:150)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
	at kafka.producer.async.DefaultEventHandler.partitionAndCollate(DefaultEventHandler.scala:150)
	at kafka.producer.async.DefaultEventHandler.dispatchSerializedData(DefaultEventHandler.scala:96)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:73)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:104)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:87)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:67)
	at scala.collection.immutable.Stream.foreach(Stream.scala:254)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:66)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)
[2013-11-21 15:28:50,025] ERROR Failed to collate messages by topic, partition due to: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(id:0,host:111.111.111.111,port:9092)] failed (kafka.producer.async.DefaultEventHandler)
[2013-11-21 15:28:50,026] INFO Back off for 100 ms before retrying send. Remaining retries = 0 (kafka.producer.async.DefaultEventHandler)
[2013-11-21 15:28:50,127] INFO Fetching metadata from broker id:0,host:111.111.111.111,port:9092 with correlation id 8 for 1 topic(s) Set(test) (kafka.client.ClientUtils$)
[2013-11-21 15:28:50,324] ERROR Producer connection to 111.111.111.111:9092 unsuccessful (kafka.producer.SyncProducer)
java.net.ConnectException: 연결이 거부됨
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:639)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.producer.SyncProducer.connect(SyncProducer.scala:146)
	at kafka.producer.SyncProducer.getOrMakeConnection(SyncProducer.scala:161)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:68)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:53)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.async.DefaultEventHandler$$anonfun$handle$2.apply$mcV$sp(DefaultEventHandler.scala:79)
	at kafka.utils.Utils$.swallow(Utils.scala:186)
	at kafka.utils.Logging$class.swallowError(Logging.scala:105)
	at kafka.utils.Utils$.swallowError(Utils.scala:45)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:79)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:104)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:87)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:67)
	at scala.collection.immutable.Stream.foreach(Stream.scala:254)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:66)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)
[2013-11-21 15:28:50,326] WARN Fetching topic metadata with correlation id 8 for topics [Set(test)] from broker [id:0,host:111.111.111.111,port:9092] failed (kafka.client.ClientUtils$)
java.net.ConnectException: 연결이 거부됨
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:639)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.producer.SyncProducer.connect(SyncProducer.scala:146)
	at kafka.producer.SyncProducer.getOrMakeConnection(SyncProducer.scala:161)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:68)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:53)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.async.DefaultEventHandler$$anonfun$handle$2.apply$mcV$sp(DefaultEventHandler.scala:79)
	at kafka.utils.Utils$.swallow(Utils.scala:186)
	at kafka.utils.Logging$class.swallowError(Logging.scala:105)
	at kafka.utils.Utils$.swallowError(Utils.scala:45)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:79)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:104)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:87)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:67)
	at scala.collection.immutable.Stream.foreach(Stream.scala:254)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:66)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)
[2013-11-21 15:28:50,328] ERROR fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(id:0,host:111.111.111.111,port:9092)] failed (kafka.utils.Utils$)
kafka.common.KafkaException: fetching topic metadata for topics [Set(test)] from broker [ArrayBuffer(id:0,host:111.111.111.111,port:9092)] failed
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:67)
	at kafka.producer.BrokerPartitionInfo.updateInfo(BrokerPartitionInfo.scala:82)
	at kafka.producer.async.DefaultEventHandler$$anonfun$handle$2.apply$mcV$sp(DefaultEventHandler.scala:79)
	at kafka.utils.Utils$.swallow(Utils.scala:186)
	at kafka.utils.Logging$class.swallowError(Logging.scala:105)
	at kafka.utils.Utils$.swallowError(Utils.scala:45)
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:79)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:104)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:87)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:67)
	at scala.collection.immutable.Stream.foreach(Stream.scala:254)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:66)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)
Caused by: java.net.ConnectException: 연결이 거부됨
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:639)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.producer.SyncProducer.connect(SyncProducer.scala:146)
	at kafka.producer.SyncProducer.getOrMakeConnection(SyncProducer.scala:161)
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:68)
	at kafka.producer.SyncProducer.send(SyncProducer.scala:112)
	at kafka.client.ClientUtils$.fetchTopicMetadata(ClientUtils.scala:53)
	... 12 more
[2013-11-21 15:28:50,332] ERROR Failed to send requests for topics test with correlation ids in [0,8] (kafka.producer.async.DefaultEventHandler)
[2013-11-21 15:28:50,333] ERROR Error in handling batch of 1 events (kafka.producer.async.ProducerSendThread)
kafka.common.FailedToSendMessageException: Failed to send messages after 3 tries.
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:90)
	at kafka.producer.async.ProducerSendThread.tryToHandle(ProducerSendThread.scala:104)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:87)
	at kafka.producer.async.ProducerSendThread$$anonfun$processEvents$3.apply(ProducerSendThread.scala:67)
	at scala.collection.immutable.Stream.foreach(Stream.scala:254)
	at kafka.producer.async.ProducerSendThread.processEvents(ProducerSendThread.scala:66)
	at kafka.producer.async.ProducerSendThread.run(ProducerSendThread.scala:44)
       
",,junrao,vacuus,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,359712,,,Thu Nov 21 16:34:09 UTC 2013,,,,,,,,,,"0|i1q0dr:",360011,,,,,,,,,,,,,,,,,,,,"22/Nov/13 00:34;junrao;Do you think https://issues.apache.org/jira/browse/KAFKA-1092 addresses this issue?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Follower Broker cannot start if offsets are already out of range,KAFKA-3123,12932595,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,mimaison,soumyajitsahu,soumyajitsahu,20/Jan/16 10:16,15/Jun/17 02:42,22/Mar/23 15:10,13/Jun/17 05:37,0.9.0.0,,,,,,0.11.0.0,,,,,,,core,replication,,,0,patch,,,,,"I was trying to upgrade our test Windows cluster from 0.8.1.1 to 0.9.0 one machine at a time. Our logs have just 2 hours of retention. I had re-imaged the test machine under consideration, and got the following error in loop after starting afresh with 0.9.0 broker:

[2016-01-19 13:57:28,809] WARN [ReplicaFetcherThread-1-169595708], Replica 177775588 for partition [EventLogs4,1] reset its fetch offset from 0 to current leader 169595708's start offset 334086 (kafka.server.ReplicaFetcherThread)
[2016-01-19 13:57:28,809] ERROR [ReplicaFetcherThread-1-169595708], Error getting offset for partition [EventLogs4,1] to broker 169595708 (kafka.server.ReplicaFetcherThread)
java.lang.IllegalStateException: Compaction for partition [EXO_EventLogs4,1] cannot be aborted and paused since it is in LogCleaningPaused state.
	at kafka.log.LogCleanerManager$$anonfun$abortAndPauseCleaning$1.apply$mcV$sp(LogCleanerManager.scala:149)
	at kafka.log.LogCleanerManager$$anonfun$abortAndPauseCleaning$1.apply(LogCleanerManager.scala:140)
	at kafka.log.LogCleanerManager$$anonfun$abortAndPauseCleaning$1.apply(LogCleanerManager.scala:140)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.log.LogCleanerManager.abortAndPauseCleaning(LogCleanerManager.scala:140)
	at kafka.log.LogCleaner.abortAndPauseCleaning(LogCleaner.scala:141)
	at kafka.log.LogManager.truncateFullyAndStartAt(LogManager.scala:304)
	at kafka.server.ReplicaFetcherThread.handleOffsetOutOfRange(ReplicaFetcherThread.scala:185)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2$$anonfun$apply$mcV$sp$1$$anonfun$apply$2.apply(AbstractFetcherThread.scala:152)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2$$anonfun$apply$mcV$sp$1$$anonfun$apply$2.apply(AbstractFetcherThread.scala:122)
	at scala.Option.foreach(Option.scala:236)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2$$anonfun$apply$mcV$sp$1.apply(AbstractFetcherThread.scala:122)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2$$anonfun$apply$mcV$sp$1.apply(AbstractFetcherThread.scala:120)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2.apply$mcV$sp(AbstractFetcherThread.scala:120)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2.apply(AbstractFetcherThread.scala:120)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2.apply(AbstractFetcherThread.scala:120)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:118)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:93)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)

I could unblock myself with a code change. I deleted the action for ""case s =>"" in the LogCleanerManager.scala's abortAndPauseCleaning(). I think we should not throw exception if the state is already LogCleaningAborted or LogCleaningPaused in this function, but instead just let it roll.",,aozeritsky,boniek,ecomar,githubbot,ijuma,mimaison,soumyajitsahu,xton,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/16 10:30;soumyajitsahu;0001-Fix-Follower-crashes-when-offset-out-of-range-during.patch;https://issues.apache.org/jira/secure/attachment/12783258/0001-Fix-Follower-crashes-when-offset-out-of-range-during.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,Important,Patch,,,,,,,,9223372036854775807,,,Wed Jun 14 18:42:57 UTC 2017,,,,,,,,,,"0|i2rptb:",9223372036854775807,,nehanarkhede,,,,,,,,,,,,,,,,,,"20/Jan/16 10:28;soumyajitsahu;Submitting a patch for the code change I have mentioned in the Description;;;","20/Jan/16 10:30;soumyajitsahu;Submitting a patch for the code change I have mentioned in the Description;;;","26/Jan/16 06:53;granthenke;[~soumyajitsahu] Would you be willing to submit the patch via the Github Pull request process [here|https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes#ContributingCodeChanges-PullRequest]?;;;","08/Mar/16 15:50;githubbot;GitHub user soumyajit-sahu opened a pull request:

    https://github.com/apache/kafka/pull/1028

    KAFKA-3123: Follower Broker cannot start if offsets are already out of range

    Function abortAndPauseCleaning() doesn't have to throw exception if the state is already LogCleaningAborted or LogCleaningPaused
    @junrao @granthenke 

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/Microsoft/kafka fixFollowerCrashUponExpiredLogs

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1028.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1028
    
----
commit 7809caef9078c4f2985389d22de14f807e140783
Author: Som Sahu <sosahu@microsoft.com>
Date:   2016-03-08T07:15:16Z

    Fix: Follower crashes when offset out of range during startup

----
;;;","10/Aug/16 08:28;soumyajitsahu;I hit another (similar) exception while trying out Kafka from 0.10.0.1.

I think abortAndPauseCleaning() should be a no-op if the state is already LogCleaningPaused. I will create a PR.

java.lang.IllegalStateException: Compaction for partition [simplestress_5,7] cannot be aborted and paused since it is in LogCleaningPaused state.
	at kafka.log.LogCleanerManager$$anonfun$abortAndPauseCleaning$1.apply$mcV$sp(LogCleanerManager.scala:149)
	at kafka.log.LogCleanerManager$$anonfun$abortAndPauseCleaning$1.apply(LogCleanerManager.scala:140)
	at kafka.log.LogCleanerManager$$anonfun$abortAndPauseCleaning$1.apply(LogCleanerManager.scala:140)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.log.LogCleanerManager.abortAndPauseCleaning(LogCleanerManager.scala:140)
	at kafka.log.LogCleaner.abortAndPauseCleaning(LogCleaner.scala:148)
	at kafka.log.LogManager.truncateFullyAndStartAt(LogManager.scala:307)
	at kafka.server.ReplicaFetcherThread.handleOffsetOutOfRange(ReplicaFetcherThread.scala:218)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2$$anonfun$apply$mcV$sp$1$$anonfun$apply$2.apply(AbstractFetcherThread.scala:157)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2$$anonfun$apply$mcV$sp$1$$anonfun$apply$2.apply(AbstractFetcherThread.scala:127)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2$$anonfun$apply$mcV$sp$1.apply(AbstractFetcherThread.scala:127)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2$$anonfun$apply$mcV$sp$1.apply(AbstractFetcherThread.scala:125)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2.apply$mcV$sp(AbstractFetcherThread.scala:125)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2.apply(AbstractFetcherThread.scala:125)
	at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$2.apply(AbstractFetcherThread.scala:125)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:231)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:123)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:98)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63);;;","10/Aug/16 08:52;githubbot;GitHub user soumyajit-sahu opened a pull request:

    https://github.com/apache/kafka/pull/1716

    KAFKA-3123: Make abortAndPauseCleaning() a no-op when state is already LogCleaningPaused

    The function of LogCleanerManager.abortAndPauseCleaning() is to mark a TopicAndPartition as LogCleaningPaused. Hence, it should be a no-op when the TopicAndPartition is already in that state.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/Microsoft/kafka ignoreLogCleaningPauseRequestWhenAlreadyInPausedState

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/1716.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #1716
    
----
commit 3ad294377eee6e6ad3fdb47b7220dcb0913f1fc9
Author: Som Sahu <sosahu@microsoft.com>
Date:   2016-08-10T00:45:55Z

    Make abortAndPauseCleaning a no-op when state is already LogCleaningPaused

----
;;;","30/Nov/16 04:14;githubbot;Github user soumyajit-sahu closed the pull request at:

    https://github.com/apache/kafka/pull/1028
;;;","30/Nov/16 04:17;soumyajitsahu;I am closing this previously opened (and now obsolete) PR.;;;","22/Mar/17 18:26;mimaison;We hit this issue today after reassigning a number of partitions. We had to restart the out of sync brokers to resolve the issue. It would be good to have the fix in the next release;;;","28/Mar/17 20:54;ijuma;[~mimaison], thanks for the comment. Can you share the broker version?;;;","28/Mar/17 21:04;mimaison;We're running 0.10.0.1. I've added a comment in the PR with more details: https://github.com/apache/kafka/pull/1716#discussion_r108386426;;;","02/Jun/17 03:40;ijuma;Moving to 0.11.0.1 as there is no PR ready for review. If we get one during the RC period, we may bring this back into 0.11.0.0.;;;","11/Jun/17 04:43;githubbot;GitHub user mimaison opened a pull request:

    https://github.com/apache/kafka/pull/3296

    KAFKA-3123: Follower Broker cannot start if offsets are already out o…

    …f range
    
    From https://github.com/apache/kafka/pull/1716#discussion_r112000498, ensure the cleaner is restarted if Log.truncateTo throws

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/mimaison/kafka KAFKA-3123

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/3296.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #3296
    
----
commit e12690320d68c7686ecf9ceebe53a4498b8a5f0d
Author: Mickael Maison <mickael.maison@gmail.com>
Date:   2017-06-10T18:49:43Z

    KAFKA-3123: Follower Broker cannot start if offsets are already out of range

----
;;;","13/Jun/17 05:37;ijuma;Issue resolved by pull request 3296
[https://github.com/apache/kafka/pull/3296];;;","13/Jun/17 05:38;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/3296
;;;","15/Jun/17 02:42;githubbot;Github user soumyajit-sahu closed the pull request at:

    https://github.com/apache/kafka/pull/1716
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConsoleProducer does not exit correctly and fix some config properties following KAFKA-648,KAFKA-701,12627454,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,brugidou,brugidou,brugidou,15/Jan/13 00:14,15/Jan/13 01:22,22/Mar/23 15:10,15/Jan/13 01:22,0.8.0,,,,,,0.8.0,,,,,,,config,core,,,0,,,,,,"Just added a proper try/catch around the ConsoleProducer so that when an exception is thrown, the system exits (with error code 1)

In addition, KAFKA-648 broker some configs like request.enqueue.timeout.ms and zk.connection.timeout.ms that I fixed",,brugidou,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/13 00:14;brugidou;KAFKA-701.patch;https://issues.apache.org/jira/secure/attachment/12564729/KAFKA-701.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,304238,,,Mon Jan 14 17:22:44 UTC 2013,,,,,,,,,,"0|i17kgn:",252284,,,,,,,,,,,,,,,,,,,,"15/Jan/13 01:22;junrao;Thanks for the patch. Committed to 0.8 after reverting the change in system_test/ (the consumer property file there is used for an 0.7 consumer).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
incorrect package name in unit tests,KAFKA-2270,12838041,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,proneetv,junrao,junrao,16/Jun/15 12:04,17/Jun/15 06:06,22/Mar/23 15:10,17/Jun/15 06:06,,,,,,,0.9.0.0,,,,,,,core,,,,0,newbie,,,,,"There are a bunch of test files with incorrect package prefix unit.

core/src/test/scala/unit/kafka/common/ConfigTest.scala:package unit.kafka.common
core/src/test/scala/unit/kafka/common/TopicTest.scala:package unit.kafka.common
core/src/test/scala/unit/kafka/consumer/PartitionAssignorTest.scala:package unit.kafka.consumer
core/src/test/scala/unit/kafka/integration/MinIsrConfigTest.scala:package unit.kafka.integration
core/src/test/scala/unit/kafka/KafkaConfigTest.scala:package unit.kafka
core/src/test/scala/unit/kafka/log/LogConfigTest.scala:package unit.kafka.log
core/src/test/scala/unit/kafka/server/KafkaConfigConfigDefTest.scala:package unit.kafka.server
core/src/test/scala/unit/kafka/utils/ByteBoundedBlockingQueueTest.scala:package unit.kafka.utils
core/src/test/scala/unit/kafka/utils/CommandLineUtilsTest.scala:package unit.kafka.utils
core/src/test/scala/unit/kafka/zk/ZKPathTest.scala:package unit.kafka.zk",,junrao,proneetv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jun/15 02:39;proneetv;fix-kafka-2270.patch;https://issues.apache.org/jira/secure/attachment/12739928/fix-kafka-2270.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Jun 16 22:06:55 UTC 2015,,,,,,,,,,"0|i2g2z3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"16/Jun/15 18:26;proneetv;Please let me know if this is a suitable patch (being my very first one here).
Thanks.;;;","16/Jun/15 22:33;junrao;Thanks for the patch. Got a bunch of compilation errors like the following due to unused imports. Could you remove them?

kafka/core/src/test/scala/unit/kafka/KafkaConfigTest.scala:22: imported `Kafka' is permanently hidden by definition of object Kafka in package kafka
import kafka.Kafka
             ^
kafka/core/src/test/scala/unit/kafka/common/ConfigTest.scala:23: imported `InvalidConfigException' is permanently hidden by definition of class InvalidConfigException in package common
import kafka.common.InvalidConfigException
                    ^
kafka/core/src/test/scala/unit/kafka/common/TopicTest.scala:22: imported `Topic' is permanently hidden by definition of object Topic in package common
import kafka.common.{Topic, InvalidTopicException}
                     ^
kafka/core/src/test/scala/unit/kafka/common/TopicTest.scala:22: imported `InvalidTopicException' is permanently hidden by definition of class InvalidTopicException in package common
import kafka.common.{Topic, InvalidTopicException}
;;;","17/Jun/15 00:18;proneetv;I compiled and built the project with the current uploaded patch. My IDE (idea) gave me few deprecation and feature warnings. Let me know, thanks!;;;","17/Jun/15 06:06;junrao;Thanks for the patch. +1. Committed to trunk after removing {} on single class imports.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to start the ZK instance after myid file was missing and had to recreate it.,KAFKA-2028,12782680,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,InduR,InduR,18/Mar/15 04:34,01/Sep/17 02:49,22/Mar/23 15:10,01/Sep/17 02:49,0.8.1.1,,,,,,,,,,,,,admin,,,,0,,,,,,"Created a Dev 3 node cluster environment in Jan and the environment has been up and running without any issues until few days.
 Kafka server stopped running but ZK listener was up .Noticed that the Myid file was missing in all 3 servers.
Recreated the file when ZK was still running did not help.
Stopped all of the ZK /kafka server instances and see the following error when starting ZK.

kafka_2.10-0.8.1.1
OS : RHEL
[root@lablx0025 bin]# ./zookeeper-server-start.sh ../config/zookeeper.properties &
[1] 31053
[***** bin]# [2015-03-17 15:04:33,876] INFO Reading configuration from: ../config/zookeeper.properties (org.apache.zookeeper.                                                                                                       server.quorum.QuorumPeerConfig)
[2015-03-17 15:04:33,885] INFO Defaulting to majority quorums (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2015-03-17 15:04:33,911] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@4891d863, name=log4j:logger=kafka (k                                                                                                       afka)
[2015-03-17 15:04:33,915] INFO Starting quorum peer (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2015-03-17 15:04:33,940] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxn)
[2015-03-17 15:04:33,966] INFO tickTime set to 3000 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2015-03-17 15:04:33,966] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2015-03-17 15:04:33,966] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2015-03-17 15:04:33,966] INFO initLimit set to 5 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2015-03-17 15:04:34,023] ERROR Failed to increment parent cversion for: /consumers/console-consumer-6249/offsets/test (org.apache.zoo                                                                                                       keeper.server.persistence.FileTxnSnapLog)
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /consumers/console-consumer-6249/offsets/test
        at org.apache.zookeeper.server.DataTree.incrementCversion(DataTree.java:1218)
        at org.apache.zookeeper.server.persistence.FileTxnSnapLog.processTransaction(FileTxnSnapLog.java:222)
        at org.apache.zookeeper.server.persistence.FileTxnSnapLog.restore(FileTxnSnapLog.java:150)
        at org.apache.zookeeper.server.ZKDatabase.loadDataBase(ZKDatabase.java:222)
        at org.apache.zookeeper.server.quorum.QuorumPeer.start(QuorumPeer.java:398)
        at org.apache.zookeeper.server.quorum.QuorumPeerMain.runFromConfig(QuorumPeerMain.java:143)
        at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:103)
        at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:76)
[2015-03-17 15:04:34,027] FATAL Unable to load database on disk (org.apache.zookeeper.server.quorum.QuorumPeer)
java.io.IOException: Failed to process transaction type: 2 error: KeeperErrorCode = NoNode for /consumers/console-consumer-6249/offset                                                                                                       s/test
        at org.apache.zookeeper.server.persistence.FileTxnSnapLog.restore(FileTxnSnapLog.java:152)
        at org.apache.zookeeper.server.ZKDatabase.loadDataBase(ZKDatabase.java:222)
        at org.apache.zookeeper.server.quorum.QuorumPeer.start(QuorumPeer.java:398)
        at org.apache.zookeeper.server.quorum.QuorumPeerMain.runFromConfig(QuorumPeerMain.java:143)
        at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:103)
        at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:76)
[2015-03-17 15:04:34,027] FATAL Unexpected exception, exiting abnormally (org.apache.zookeeper.server.quorum.QuorumPeerMain)
java.lang.RuntimeException: Unable to run quorum server
        at org.apache.zookeeper.server.quorum.QuorumPeer.start(QuorumPeer.java:401)
        at org.apache.zookeeper.server.quorum.QuorumPeerMain.runFromConfig(QuorumPeerMain.java:143)
        at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:103)
        at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:76)
Caused by: java.io.IOException: Failed to process transaction type: 2 error: KeeperErrorCode = NoNode for /consumers/console-consumer-                                                                                                       6249/offsets/test
        at org.apache.zookeeper.server.persistence.FileTxnSnapLog.restore(FileTxnSnapLog.java:152)
        at org.apache.zookeeper.server.ZKDatabase.loadDataBase(ZKDatabase.java:222)
        at org.apache.zookeeper.server.quorum.QuorumPeer.start(QuorumPeer.java:398)
        ... 3 more
*****************
Zookeeper properties:

# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the ""License""); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# the directory where the snapshot is stored.
dataDir=/tmp/zookeeper
# the port at which the clients will connect
clientPort=2181
# disable the per-ip limit on the number of connections since this is a non-production config
#maxClientCnxns=0
server.1=lablx0023:2888:3888
server.2=lablx0024:2888:3888
server.3=lablx0025:2888:3888
#add here more servers if you want
initLimit=5
syncLimit=2

",Non Prod,InduR,joestein,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Aug 31 18:49:15 UTC 2017,,,,,,,,,,"0|i26vwv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"18/Mar/15 06:55;joestein;can you post your zookeeper.properties;;;","18/Mar/15 07:57;InduR;Zookeeper properties:
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements. See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to You under the Apache License, Version 2.0
(the ""License""); you may not use this file except in compliance with
the License. You may obtain a copy of the License at
#
http://www.apache.org/licenses/LICENSE-2.0
#
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
the directory where the snapshot is stored.
dataDir=/tmp/zookeeper
the port at which the clients will connect
clientPort=2181
disable the per-ip limit on the number of connections since this is a non-production config
#maxClientCnxns=0
server.1=lablx0023:2888:3888
server.2=lablx0024:2888:3888
server.3=lablx0025:2888:3888
#add here more servers if you want
initLimit=5
syncLimit=2;;;","18/Mar/15 08:03;joestein;the issue is like related to using the /tmp directory 

dataDir=/tmp/zookeeper

you should not be using the /tmp directory for zookeeper nor kafka (check your server.properties log.dirs) data

what could have happened is a reboot which os in that case delete everything in /tmp;;;","18/Mar/15 08:12;InduR;The Data and log files are also mapped to be on tmp;

# A comma seperated list of directories under which to store log files
log.dirs=/tmp/kafka-logs

The server had not been rebooted  in the last two  months since kafka was first installed and started running.
[root@lablx0025 config]# uptime
 19:07:23 up 63 days,  3:19,  1 user,  load average: 0.00, 0.00, 0.00

So to resolve this issue should I re point  server.properties and  ZK.Properties to a new file system and start the instances?

Thanks!;;;","01/Sep/17 02:49;omkreddy;related to config issue.  Pl reopen if you think the issue still exists
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NullPointerException in describe topic,KAFKA-1198,12687012,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,guozhang,junrao,junrao,03/Jan/14 02:17,13/Jan/14 12:38,22/Mar/23 15:10,13/Jan/14 12:38,0.8.1,,,,,,0.8.1,,,,,,,,,,,0,,,,,,"If topic is not specified, we get the following.

bin/kafka-topics.sh --zookeeper localhost:2181 --describe
(Error while executing topic command,java.lang.NullPointerException)

Also, list topic seems to always list all topics even when topics are specified.
",,guozhang,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jan/14 07:10;guozhang;KAFKA-1198.patch;https://issues.apache.org/jira/secure/attachment/12621179/KAFKA-1198.patch","04/Jan/14 02:18;guozhang;KAFKA-1198_2014-01-03_10:17:46.patch;https://issues.apache.org/jira/secure/attachment/12621354/KAFKA-1198_2014-01-03_10%3A17%3A46.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,366007,,,Fri Jan 03 20:19:13 UTC 2014,,,,,,,,,,"0|i1r393:",366314,,,,,,,,,,,,,,,,,,,,"03/Jan/14 03:55;guozhang;1) List option will always get all the topics, only describe option will take the topic specification.

2) the getTopics function does not check if opts.topicOpt is specified, and hence throws the NullPointerException.

Proposed solution: check topicOpt unless it is the list option.;;;","03/Jan/14 05:38;guozhang;I tried the following with the current trunk HEAD and did not hit the Exception:

1. start ZK
2. start one broker
3. bin/kafka-topics.sh --zookeeper localhost:2181 --describe returns empty.
4. create a topic
5. bin/kafka-topics.sh --zookeeper localhost:2181 --list returns the topic
6. bin/kafka-topics.sh --zookeeper localhost:2181 --describe returns the description of the topic.;;;","03/Jan/14 06:49;guozhang;I can re-produce this issue now, was having an older jar before.;;;","03/Jan/14 07:10;guozhang;Created reviewboard https://reviews.apache.org/r/16579/
 against branch origin/trunk;;;","04/Jan/14 02:19;guozhang;Updated reviewboard https://reviews.apache.org/r/16579/
 against branch origin/trunk;;;","04/Jan/14 04:19;junrao;Thanks for the patch. +1 and committed trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Delayed fetch/producer requests should be satisfied on a leader change,KAFKA-1148,12681342,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,jjkoshy,jjkoshy,27/Nov/13 03:29,12/Mar/16 03:22,22/Mar/23 15:10,12/Mar/16 03:22,,,,,,,0.10.0.0,,,,,,,,,,,0,,,,,,"Somewhat related to KAFKA-1016.

This would be an issue only if max.wait is set to a very high value. When a leader change occurs we should remove the delayed request from the purgatory - either satisfy with error/expire - whichever makes more sense.",,githubbot,jjkoshy,peoplebike,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,360607,,,Fri Mar 11 19:22:51 UTC 2016,,,,,,,,,,"0|i1q5vj:",360906,,,,,,,,,,,,,,,,,,,,"05/Dec/15 16:32;peoplebike;Recently, we have lost a set of messages. After checking the log, we think it's very likely caused by this issue.

We have a broker A, when it was the leader, it appended a MessageSet to local log, and waiting for acks, soon it became a follower, and it truncated local log, deleted that message set. But, soon after that, it became leader for that partition again, shrunk ISR and increased its HW, so the previous DelayedProduce be satisfied and the producer client received a successful produce response. But, actually, the messages was lost.

I think Kafka should check leader epoch before sending produce response, to make sure the leader was not changed since it append the produce data to log;;;","06/Dec/15 20:05;githubbot;GitHub user iBuddha opened a pull request:

    https://github.com/apache/kafka/pull/633

    KAFKA-1148 check leader epoch for DelayedProduce

    KAFKA-1148: check leader epoch for DelayedProduce

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/iBuddha/kafka KAFKA-1148

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/633.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #633
    
----
commit 873b555906a773e19bdc3fc54fe9b3f5c3f8a6dd
Author: xhuang <peoplebike@gmail.com>
Date:   2015-12-06T12:02:49Z

    KAFKA-1148 check leader epoch for DelayedProduce

----
;;;","07/Dec/15 20:52;githubbot;Github user iBuddha closed the pull request at:

    https://github.com/apache/kafka/pull/633
;;;","12/Mar/16 03:22;jjkoshy;Issue resolved by pull request 1018
[https://github.com/apache/kafka/pull/1018];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MirrorMaker hides consumer exception - making troubleshooting challenging,KAFKA-1891,12769452,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,gwenshap,gwenshap,gwenshap,23/Jan/15 05:42,23/Jan/15 11:29,22/Mar/23 15:10,23/Jan/15 11:29,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"When MirrorMaker encounters an issue creating a consumer, it gives a generic ""unable to create stream"" error, while hiding the actual issue.

We should print the original exception too, so users can resolve whatever issue prevents MirrorMaker from creating a stream.",,gwenshap,joestein,ywskycn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jan/15 06:57;gwenshap;KAFKA-1891.patch;https://issues.apache.org/jira/secure/attachment/12694030/KAFKA-1891.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jan 23 03:29:50 UTC 2015,,,,,,,,,,"0|i24oyf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"23/Jan/15 06:57;gwenshap;Its a 3 character patch, so I'm not creating an RB :);;;","23/Jan/15 11:29;joestein;committed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ticket Renewal Thread exits prematurely due to inverted comparison,KAFKA-3198,12936410,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,adam.kunicki,adam.kunicki,adam.kunicki,04/Feb/16 02:16,04/Feb/16 15:48,22/Mar/23 15:10,04/Feb/16 15:48,0.9.0.0,,,,,,0.10.0.0,0.9.0.1,,,,,,security,,,,0,,,,,,"Line 152 of Login.java:
{code}
if (isUsingTicketCache && tgt.getRenewTill() != null && tgt.getRenewTill().getTime() >= expiry) {
{code}

This line is used to determine whether to exit the thread and issue an error to the user.

The >= should be < since we are actually able to renew if the renewTill time is later than the current ticket expiration.",,adam.kunicki,githubbot,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Feb 04 07:48:42 UTC 2016,,,,,,,,,,"0|i2sdaf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"04/Feb/16 07:32;githubbot;GitHub user kunickiaj opened a pull request:

    https://github.com/apache/kafka/pull/858

    KAFKA-3198: Ticket Renewal Thread exits prematurely due to inverted c…

    KAFKA-3198: Ticket Renewal Thread exits prematurely due to inverted comparison
    
    The >= should be < since we are actually able to renew if the renewTill time is later than the current ticket expiration.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/kunickiaj/kafka KAFKA-3198

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/858.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #858
    
----
commit 65b10cd2e0bae97833be5459c29953695d8d396a
Author: Adam Kunicki <adam@streamsets.com>
Date:   2016-02-03T18:35:29Z

    KAFKA-3198: Ticket Renewal Thread exits prematurely due to inverted comparison

----
;;;","04/Feb/16 14:26;githubbot;Github user kunickiaj closed the pull request at:

    https://github.com/apache/kafka/pull/858
;;;","04/Feb/16 14:26;githubbot;GitHub user kunickiaj reopened a pull request:

    https://github.com/apache/kafka/pull/858

    KAFKA-3198: Ticket Renewal Thread exits prematurely due to inverted c…

    KAFKA-3198: Ticket Renewal Thread exits prematurely due to inverted comparison
    
    The >= should be < since we are actually able to renew if the renewTill time is later than the current ticket expiration.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/kunickiaj/kafka KAFKA-3198

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/858.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #858
    
----
commit 65b10cd2e0bae97833be5459c29953695d8d396a
Author: Adam Kunicki <adam@streamsets.com>
Date:   2016-02-03T18:35:29Z

    KAFKA-3198: Ticket Renewal Thread exits prematurely due to inverted comparison

----
;;;","04/Feb/16 15:48;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/858
;;;","04/Feb/16 15:48;gwenshap;Issue resolved by pull request 858
[https://github.com/apache/kafka/pull/858];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ReplicaFetcherThread: suspicious log message on reset offset,KAFKA-2164,12826745,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,aozeritsky,aozeritsky,03/May/15 03:18,13/Jun/15 09:51,22/Mar/23 15:10,13/Jun/15 09:51,0.8.2.1,,,,,,0.9.0.0,,,,,,,,,,,4,,,,,,"If log.logEndOffset < leaderStartOffset the follower resets its offset and prints the following:
{code}
[2015-03-25 11:11:08,975] WARN [ReplicaFetcherThread-0-21], Replica 30 for partition [topic,11] reset its fetch offset from 49322124 to current leader 21's start offset 49322124 (kafka.server.ReplicaFetcherThread)
[2015-03-25 11:11:08,976] ERROR [ReplicaFetcherThread-0-21], Current offset 54369274 for partition [topic,11] out of range; reset offset to 49322124 (kafka.server.ReplicaFetcherThread)
{code}
I think the right message should be:
{code}
[2015-03-25 11:11:08,975] WARN [ReplicaFetcherThread-0-21], Replica 30 for partition [topic,11] reset its fetch offset from 54369274 to current leader 21's start offset 49322124 (kafka.server.ReplicaFetcherThread)
[2015-03-25 11:11:08,976] ERROR [ReplicaFetcherThread-0-21], Current offset 54369274 for partition [topic,11] out of range; reset offset to 49322124 (kafka.server.ReplicaFetcherThread)
{code}

This occurs because ReplicaFetcherThread resets the offset and then print log message.
Posible solution:
{code}
diff --git a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala b/core/
index b31b432..181cbc1 100644
--- a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala
+++ b/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala
@@ -111,9 +111,9 @@ class ReplicaFetcherThread(name:String,
        * Roll out a new log at the follower with the start offset equal to the
        */
       val leaderStartOffset = simpleConsumer.earliestOrLatestOffset(topicAndPar
-      replicaMgr.logManager.truncateFullyAndStartAt(topicAndPartition, leaderSt
       warn(""Replica %d for partition %s reset its fetch offset from %d to curre
         .format(brokerConfig.brokerId, topicAndPartition, replica.logEndOffset.
+      replicaMgr.logManager.truncateFullyAndStartAt(topicAndPartition, leaderSt
       leaderStartOffset
     }
   }
{code}

",,aozeritsky,junrao,mazhar.shaikh.in,octo47,ovgolovin,suninside,yuyang08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2165,,,,,,,,"03/May/15 03:41;aozeritsky;KAFKA-2164.patch;https://issues.apache.org/jira/secure/attachment/12729971/KAFKA-2164.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,Patch,,,,,,,,,9223372036854775807,,,Sat Jun 13 01:51:40 UTC 2015,,,,,,,,,,"0|i2e7rj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"13/Jun/15 09:51;junrao;Thanks for the patch. +1 and committed to trunk.

[~aozeritsky], somehow I can't add you to Kafka contributor's list. Not sure why. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
One incorrect bootstrap server will prevent Kafka producer from opening,KAFKA-3112,12931710,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,bondj,bondj,bondj,17/Jan/16 05:39,07/May/16 16:10,22/Mar/23 15:10,07/May/16 16:10,0.8.2.1,,,,,,0.10.0.0,,,,,,,clients,,,,0,,,,,,"If any of the servers specified in bootstrap.servers are not resolvable through DNS the configuration is taken as an error, and the client won't start up. We pass in 30 possible servers, and one had an issue so the client wouldn't start. 

It would be better if the client will attempt to start if there is at least one server available from DNS.",,allenxwang,bondj,githubbot,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2657,,,,,,KAFKA-2657,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat May 07 08:06:25 UTC 2016,,,,,,,,,,"0|i2rkd3:",9223372036854775807,,ijuma,,,,,,,,,,,,,,,,,,"17/Jan/16 05:47;bondj;diff --git a/clients/src/main/java/org/apache/kafka/clients/producer/internals/BufferPoolTest.java b/clients/src/main/java/org/apache/kafka/clients/producer/internals/BufferPoolTest.java
new file mode 100644
index 0000000..a32ff87
--- /dev/null
+++ b/clients/src/main/java/org/apache/kafka/clients/producer/internals/BufferPoolTest.java
@@ -0,0 +1,188 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.kafka.clients.producer.internals;
+
+import java.nio.ByteBuffer;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.Semaphore;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicLong;
+import java.util.concurrent.locks.ReentrantLock;
+
+import org.apache.kafka.clients.producer.BufferExhaustedException;
+import org.apache.kafka.common.metrics.Metrics;
+import org.apache.kafka.common.utils.SystemTime;
+
+public class BufferPoolTest {
+
+    public static void main(String[] args) throws InterruptedException {
+
+        final BufferPool bp = new BufferPool(16 * 1024 * 1024, 16384, false, new Metrics(), new SystemTime(),
+                ""metricGroupName"", Collections.emptyMap());
+        final AtomicLong allocated = new AtomicLong(0);
+        final AtomicLong bufferFull = new AtomicLong(0);
+        final long numberOfMessages = 1000000000;
+        final AtomicLong messages = new AtomicLong(numberOfMessages);
+        final int threadCount = 16;
+        final CountDownLatch latch = new CountDownLatch(threadCount + 1);
+        final Object lock = new Object();
+        final ReentrantLock rl = new ReentrantLock();
+        final LinkedBlockingQueue<ByteBuffer> queue = new LinkedBlockingQueue<ByteBuffer>();
+        final AtomicLong latency = new AtomicLong();
+
+        Thread reaperThread = new Thread(new Runnable() {
+
+            @Override
+            public void run() {
+                List<ByteBuffer> currenlyAllocated = new ArrayList<ByteBuffer>(2048);
+                while (true) {
+
+                    try {
+                        Thread.sleep(100);
+                        queue.drainTo(currenlyAllocated, 2048);
+
+                        for (ByteBuffer byteBuffer : currenlyAllocated) {
+                            bp.deallocate(byteBuffer);
+                        }
+                        // System.out.println(""drained ""+currenlyAllocated.size());
+                        currenlyAllocated.clear();
+                    } catch (Exception x) {
+                        System.out.println(x);
+                    }
+                }
+
+            }
+        });
+        reaperThread.setDaemon(true);
+        reaperThread.start();
+        for (int i = 0; i < threadCount; i++) {
+            Thread th = new Thread(new Runnable() {
+
+                @Override
+                public void run() {
+                    latch.countDown();
+                    try {
+
+                        latch.await();
+                    } catch (InterruptedException e) {
+                        // TODO Auto-generated catch block
+                        e.printStackTrace();
+                    }
+
+                    while (messages.getAndDecrement() > 0) {
+                        try {
+                            // synchronized (lock) {
+                            //
+                            // }
+
+                            // rl.lock();
+                            //
+                            // rl.unlock();
+                            long start = System.nanoTime();
+                            try {
+                                
+                                //ByteBuffer bb = bp.allocate(1000);
+                                // Thread.yield();
+                                ByteBuffer bb = allocate(bp, 1000);
+                                
+                                if (bb != null) {
+                                    queue.offer(bb);
+                                    allocated.incrementAndGet();
+                                } else {
+                                    bufferFull.incrementAndGet();
+                                }
+                            } catch (BufferExhaustedException bee) {
+                                bufferFull.incrementAndGet();
+                            }
+                            
+                            long end = System.nanoTime();
+                            latency.addAndGet((end - start));
+
+                        } catch (Exception e) {
+                            System.out.println(e);
+                        }
+
+                    }
+                }
+            });
+            th.setPriority(Thread.MIN_PRIORITY);
+            th.setDaemon(true);
+            th.start();
+
+        }
+        latch.countDown();
+
+        long time = System.currentTimeMillis();
+        long start = time;
+        long previousF = bufferFull.get();
+        long previousA = allocated.get();
+        long nextSleep = 1000;
+
+        while (true) {
+
+            Thread.sleep(nextSleep);
+            long now = System.currentTimeMillis();
+            long fullV = bufferFull.get();
+            long allocateV = allocated.get();
+            long newVal = fullV + allocateV;
+
+            long latencyMs =latency.get();
+
+            System.out.println(now - start + "","" + (double) (newVal - (previousF + previousA)) / (double) (now - time) * 1000
+                    + "","" + (double) (allocateV) / (double) (newVal) + "","" + fullV + "","" + allocateV + "",""
+                    + theGovernator.availablePermits() + "","" + (fullV+allocateV) + "","" + latencyMs
+                    / (numberOfMessages - messages.get()));
+
+            time = now;
+            previousF = fullV;
+            previousA = allocateV;
+
+//            if (now - start > 120000)
+//                break;
+
+            long diff = System.currentTimeMillis() - now;
+            nextSleep = 1000 - diff;
+        }
+
+    }
+
+    private static final Semaphore theGovernator = new Semaphore(256 * 1000);
+
+    private static ByteBuffer allocate(BufferPool bp, int size) throws InterruptedException {
+        ByteBuffer result;
+
+        final Boolean youMayPass = theGovernator.tryAcquire(size);
+        try {
+            if (youMayPass) {
+                result = bp.allocate(size);
+            } else {
+                result = null;
+            }
+        } finally {
+            if (youMayPass)
+                theGovernator.release(size);
+        }
+
+        return result;
+    }
+
+}
\ No newline at end of file
diff --git a/clients/src/main/java/org/apache/kafka/common/metrics/stats/AvgTest.java b/clients/src/main/java/org/apache/kafka/common/metrics/stats/AvgTest.java
new file mode 100644
index 0000000..ea8efd2
--- /dev/null
+++ b/clients/src/main/java/org/apache/kafka/common/metrics/stats/AvgTest.java
@@ -0,0 +1,26 @@
+package org.apache.kafka.common.metrics.stats;
+
+import org.apache.kafka.common.metrics.MetricConfig;
+
+public class AvgTest {
+    
+    public static void main(String []args) throws Exception
+    {
+        Avg a = new Avg();
+        MetricConfig cfg = new MetricConfig();
+        for(int i=0;i<15;i++)
+        {
+            a.record(cfg, i, System.currentTimeMillis());
+            System.out.println(i+"" ""+a.measure(cfg, System.currentTimeMillis()));
+            Thread.sleep(1000);
+        }
+        
+        for(int i=0;i<150;i++)
+        {
+           
+            System.out.println(Double.isFinite(a.measure(cfg, System.currentTimeMillis())));
+            Thread.sleep(1000);
+        }
+    }
+
+}
diff --git a/clients/src/main/java/org/apache/kafka/common/utils/ClientUtils.java b/clients/src/main/java/org/apache/kafka/common/utils/ClientUtils.java
index d5af354..05143ac 100644
--- a/clients/src/main/java/org/apache/kafka/common/utils/ClientUtils.java
+++ b/clients/src/main/java/org/apache/kafka/common/utils/ClientUtils.java
@@ -39,16 +39,18 @@
                     throw new ConfigException(""Invalid url in "" + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG + "": "" + url);
                 try {
                     InetSocketAddress address = new InetSocketAddress(host, port);
-                    if (address.isUnresolved())
-                        throw new ConfigException(""DNS resolution failed for url in "" + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG + "": "" + url);
-                    addresses.add(address);
+                    if (address.isUnresolved()) {
+                        log.warn(""DNS resolution failed for url in "" + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG + "": "" + url);
+                    } else {
+                        addresses.add(address);
+                    }
                 } catch (NumberFormatException e) {
                     throw new ConfigException(""Invalid port in "" + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG + "": "" + url);
                 }
             }
         }
         if (addresses.size() < 1)
-            throw new ConfigException(""No bootstrap urls given in "" + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG);
+            throw new ConfigException(""No resolvable bootstrap urls given in "" + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG);
         return addresses;
     }
 
;;;","20/Jan/16 02:09;ijuma;Thanks for the contribution. It would make it easier to review if it was submitted via a GitHub pull request as described here:

http://kafka.apache.org/contributing.html;;;","07/May/16 16:06;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/792
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Broker failed to start because of corrupted replication-offset-checkpoint file,KAFKA-1505,12723263,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,nehanarkhede,ttthree,ttthree,24/Jun/14 11:31,04/Sep/17 19:21,22/Mar/23 15:10,04/Sep/17 19:21,0.8.1,,,,,,,,,,,,,replication,,,,0,,,,,,"The replication-offset-checkpoint file seems to have some blank entries where the topic, partition, offset information is expected.

Broker service cannot be started with following error:

[2014-06-18 11:09:51,272] ERROR [KafkaApi-5] error when handling request Name:LeaderAndIsrRequest;Version:0;Controller:2;ControllerEpoch:35;CorrelationId:11;ClientId:id_2-host_10.65.127.89-port_9092;PartitionState:(x,4) -> (LeaderAndIsrInfo:(Leader:14,ISR:14,LeaderEpoch:33,ControllerEpoch:35),ReplicationFactor:3),AllReplicas:14,5,6),(xm,20) -> (LeaderAndIsrInfo:(Leader:11,ISR:11,4,LeaderEpoch:11,ControllerEpoch:32),ReplicationFactor:3),AllReplicas:11,4,5),(xm,0) -> (LeaderAndIsrInfo:(Leader:11,ISR:11,4,LeaderEpoch:28,ControllerEpoch:32),ReplicationFactor:3),AllReplicas:11,4,5),(xm_int,3) -> (LeaderAndIsrInfo:(Leader:17,ISR:17,18,LeaderEpoch:26,ControllerEpoch:30),ReplicationFactor:3),AllReplicas:5,17,18),(x_int,9) -> (LeaderAndIsrInfo:(Leader:11,ISR:11,LeaderEpoch:38,ControllerEpoch:35),ReplicationFactor:3),AllReplicas:11,5,6),(xm_int,11) -> (LeaderAndIsrInfo:(Leader:13,ISR:13,LeaderEpoch:29,ControllerEpoch:35),ReplicationFactor:3),AllReplicas:13,5,6),(x_int,3) -> (LeaderAndIsrInfo:(Leader:19,ISR:19,0,LeaderEpoch:25,ControllerEpoch:32),ReplicationFactor:3),AllReplicas:5,19,0),(xm,1) -> (LeaderAndIsrInfo:(Leader:12,ISR:12,LeaderEpoch:30,ControllerEpoch:35),ReplicationFactor:3),AllReplicas:12,5,6),(x,3) -> (LeaderAndIsrInfo:(Leader:13,ISR:13,4,LeaderEpoch:22,ControllerEpoch:32),ReplicationFactor:3),AllReplicas:13,4,5),(xm,14) -> (LeaderAndIsrInfo:(Leader:18,ISR:18,19,LeaderEpoch:24,ControllerEpoch:31),ReplicationFactor:3),AllReplicas:5,18,19),(xm_int,10) -> (LeaderAndIsrInfo:(Leader:12,ISR:12,4,LeaderEpoch:25,ControllerEpoch:32),ReplicationFactor:3),AllReplicas:12,4,5),(x,15) -> (LeaderAndIsrInfo:(Leader:17,ISR:17,16,LeaderEpoch:24,ControllerEpoch:30),ReplicationFactor:3),AllReplicas:5,16,17),(x_int,8) -> (LeaderAndIsrInfo:(Leader:10,ISR:10,4,LeaderEpoch:26,ControllerEpoch:32),ReplicationFactor:3),AllReplicas:10,4,5),(xm,21) -> (LeaderAndIsrInfo:(Leader:12,ISR:12,LeaderEpoch:8,ControllerEpoch:35),ReplicationFactor:3),AllReplicas:12,5,6);Leaders:id:11,host:25.126.81.157,port:9092,id:14,host:25.126.81.159,port:9092,id:12,host:25.126.81.158,port:9092,id:17,host:10.153.63.196,port:9092,id:18,host:10.153.63.214,port:9092,id:19,host:10.65.127.95,port:9092,id:13,host:10.65.127.93,port:9092,id:10,host:10.65.127.92,port:9092 (kafka.server.KafkaApis)
java.lang.NumberFormatException: For input string: ""                                                                                                                                                                                                                                                        ""
                at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
                at java.lang.Integer.parseInt(Integer.java:481)
                at java.lang.Integer.parseInt(Integer.java:527)
                at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:231)
                at scala.collection.immutable.StringOps.toInt(StringOps.scala:31)
                at kafka.server.OffsetCheckpoint.liftedTree2$1(OffsetCheckpoint.scala:77)
                at kafka.server.OffsetCheckpoint.read(OffsetCheckpoint.scala:73)
                at kafka.cluster.Partition.getOrCreateReplica(Partition.scala:91)
                at kafka.server.ReplicaManager$$anonfun$makeFollowers$5.apply(ReplicaManager.scala:347)
                at kafka.server.ReplicaManager$$anonfun$makeFollowers$5.apply(ReplicaManager.scala:346)
                at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:233)
                at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:233)
                at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
                at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
                at scala.collection.Iterator$class.foreach(Iterator.scala:772)
                at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
                at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
                at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:45)
                at scala.collection.mutable.HashMap.foreach(HashMap.scala:95)
                at scala.collection.TraversableLike$class.map(TraversableLike.scala:233)
                at scala.collection.mutable.HashMap.map(HashMap.scala:45)
                at kafka.server.ReplicaManager.makeFollowers(ReplicaManager.scala:346)
                at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:248)
                at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:93)
                at kafka.server.KafkaApis.handle(KafkaApis.scala:74)
                at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:42)
                at java.lang.Thread.run(Thread.java:724)
","Window Server 2012;JDK1.7.0",hongyu.bi,omkreddy,ttthree,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,401450,,,Mon Sep 04 11:21:31 UTC 2017,,,,,,,,,,"0|i1x3n3:",401523,,,,,,,,,,,,,,,,,,,,"04/Sep/17 19:21;omkreddy;This was fixed in newer versions.  Pl reopen if you think the issue still exists
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use zero loss settings for producer in Kafka Connect,KAFKA-2778,12911448,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,ewencp,ewencp,09/Nov/15 14:23,10/Nov/15 02:38,22/Mar/23 15:10,10/Nov/15 02:38,,,,,,,0.9.0.0,,,,,,,KafkaConnect,,,,0,,,,,,"The settings for the producer in Kafka Connect are not using zero loss settings (and was written before the client timeout patch, so would have been using outdated settings regardless). It should be updated to use settings that, by default, guarantee zero loss but can be overridden. In the case we do see an error, the task already exits.",,ewencp,githubbot,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Nov 09 18:38:23 UTC 2015,,,,,,,,,,"0|i2o4h3:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"10/Nov/15 02:01;gwenshap;https://github.com/apache/kafka/pull/459;;;","10/Nov/15 02:37;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/459
;;;","10/Nov/15 02:38;gwenshap;Issue resolved by pull request 459
[https://github.com/apache/kafka/pull/459];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka.server.ReplicaFetcherThread: java.lang.IndexOutOfBoundsException,KAFKA-529,12608935,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,,jfung,jfung,25/Sep/12 06:04,02/Oct/12 06:47,22/Mar/23 15:10,02/Oct/12 06:47,,,,,,,,,,,,,,,,,,0,,,,,,"1. Attached file system_test_1348521165.tar.gz contains all the associated log files for this test session.

2. The system test output log can be found at: system_test_1348521165/system_test_output.log 

3. The following log message can be found at: system_test_1348521165/logs/broker-2/kafka_server_9092.log

[2012-09-24 14:14:19,601] WARN No previously checkpointed highwatermark value found for topic test_1 partition 1. Returning 0 as the highwatermark (ka
fka.server.HighwaterMarkCheckpoint)
[2012-09-24 14:14:19,604] INFO [Kafka Log on Broker 2], Truncated log segment /tmp/kafka_server_2_logs/test_1-1/00000000000000000000.kafka to target o
ffset 0 (kafka.log.Log)
[2012-09-24 14:14:19,611] INFO [ReplicaFetcherThread-1-0-on-broker-2-], Starting  (kafka.server.ReplicaFetcherThread)
[2012-09-24 14:14:19,611] INFO [ReplicaFetcherManager on broker 2, ], adding fetcher on topic test_1, partion 1, initOffset 0 to broker 1 with fetcherId 0 (kafka.server.ReplicaFetcherManager)
[2012-09-24 14:14:19,973] ERROR [ReplicaFetcherThread-1-0-on-broker-2-], Error due to  (kafka.server.ReplicaFetcherThread)
java.lang.IndexOutOfBoundsException
        at java.nio.Buffer.checkIndex(Buffer.java:512)
        at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:121)
        at kafka.message.Message.magic(Message.scala:119)
        at kafka.message.Message.checksum(Message.scala:132)
        at kafka.message.Message.isValid(Message.scala:144)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNextOuter(ByteBufferMessageSet.scala:118)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:149)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:89)
        at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:61)
        at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:53)
        at kafka.message.ByteBufferMessageSet.verifyMessageSize(ByteBufferMessageSet.scala:79)
        at kafka.log.Log.append(Log.scala:250)
        at kafka.server.ReplicaFetcherThread.processPartitionData(ReplicaFetcherThread.scala:42)
        at kafka.server.AbstractFetcherThread$$anonfun$doWork$5.apply(AbstractFetcherThread.scala:103)
        at kafka.server.AbstractFetcherThread$$anonfun$doWork$5.apply(AbstractFetcherThread.scala:96)
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:105)
        at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:96)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:50)
[2012-09-24 14:14:19,975] INFO [ReplicaFetcherThread-1-0-on-broker-2-], Stopped  (kafka.server.ReplicaFetcherThread)
",,jfung,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Sep/12 06:05;jfung;system_test_1348521165.tar.gz;https://issues.apache.org/jira/secure/attachment/12546391/system_test_1348521165.tar.gz",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,291938,,,Mon Oct 01 22:47:40 UTC 2012,,,,,,,,,,"0|i0rhpz:",158515,,,,,,,,,,,,,,,,,,,,"02/Oct/12 06:47;jfung;This cannot be reproduced any more with the fix from KAFKA-528. So mark this FIXED.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
unit tests sometimes are slow during shutdown,KAFKA-2010,12780358,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Duplicate,junrao,junrao,junrao,09/Mar/15 06:34,13/Mar/15 05:08,22/Mar/23 15:10,13/Mar/15 05:08,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Our unit tests in trunk seem to be slower than before. The slowness seems to be due to a handful of tests.

For example, if you run the following test,  sometimes it can take more than 40
secs, while normally it takes less than 10 secs.

./gradlew -i cleanTest core:test --tests kafka.admin.AddPartitionsTest.testIncrementPartitions
",,guozhang,gwenshap,junrao,sriharsha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Mar 12 21:08:07 UTC 2015,,,,,,,,,,"0|i26hwf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"09/Mar/15 06:45;junrao;The long delay always happens during the shutdown of a multi-node Kafka cluster with the controlled shutdown disabled. The typical pattern is the following. 

1. Broker X, which is the controller, initiates the shutdown process.
2. The socket server of broker X is shut down.

After step 2, two things are happening in parallel.
A. Another broker is still trying to fetch data from broker X since the leaders on broker X haven't been moved. The replica fetcher thread keeps trying to connect to broker X, but keeps failing. Initially, the failing happens immediately. However, after a few seconds, the connecting will block for the socket connection timeout (configured to 1.5 secs in the unit test) and then fail.
B. In broker X,
B1. The shutdown of the controller is initiated. One of the steps is to shut down the RequestSendThread that's responsible for sending requests from the controller to broker X itself.
B2. The RequestSendThread is in the middle of sending a controller request to broker X. Since the socket server of broker X is already shut down. The sending should fail immediately. However, what happens is that the RequestSendThread blocks on connecting to broker X for the socket connect timeout, which has the default value of 30 secs.

Because of this, the shutdown of broker X is delayed by at least 30 secs. This seems to happen more likely after kafka-1971. Before kafka-1971, we de-register a broker's ZK registration before shutting down the socket server in step 2 above. After kafka-1971, broker de-registers itself from ZK in the last step in the shutdown process (so it happens after shutting down the socket server).

The following is the output from a tcpdump. As you can see, starting from 14:29:24.279037, the connecting from both the replica fetcher thread and the RequestSendThread to broker X's port (58693) starts to fail. Initially, a TCP RESET is sent immediately after a TCP SYN (which matches the TCP spec). However, starting from 14:29:25.142164, no RESET is sent after SYN. Therefore the connecting failure is only detected after the timeout.

It's not very clear to me why RESET is not sent after some time. Anyone has a good explanation of this behavior? A few more details.
(1) This happens on my mac. There is no firewall configured.
(2) The unit test open around 20 consecutive ports.
(3) The reconnect in the replica fetch thread has no backoff (it probably should). So, it will try to reconnect immediately after the previous connecting fails.
(4) The reconnect in the RequestSendThread has a 300ms backoff.
(5) There seems to be a gap between 14:29:24.477485 and 14:29:25.142164 in the tcpdump output. It's not clear to me why since in that time window, both the replica fetch thread and
RequestSendThread are still connecting and failing.

tcpdump output:
14:29:24.279037 IP localhost.58973 > localhost.58693: Flags [S], seq 3455869244, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706836 ecr 0,sackOK,eol], length 0
14:29:24.361327 IP localhost.58974 > localhost.58693: Flags [S], seq 3041388581, win 65535, options [mss 16344,nop,wscale 4,nop,nop,TS val 1107706906 ecr 0,sackOK,eol], length 0
14:29:24.361376 IP localhost.58693 > localhost.58974: Flags [R.], seq 0, ack 3041388582, win 0, length 0
14:29:24.405285 IP localhost.58977 > localhost.58693: Flags [S], seq 1164560537, win 65535, options [mss 16344,nop,wscale 4,nop,nop,TS val 1107706945 ecr 0,sackOK,eol], length 0
14:29:24.405384 IP localhost.58693 > localhost.58977: Flags [R.], seq 0, ack 1164560538, win 0, length 0
14:29:24.439743 IP localhost.58973 > localhost.58693: Flags [S], seq 3455869244, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706973 ecr 0,sackOK,eol], length 0
14:29:24.439844 IP localhost.58693 > localhost.58973: Flags [R.], seq 0, ack 3455869245, win 0, length 0
14:29:24.442677 IP localhost.58978 > localhost.58693: Flags [S], seq 1119137787, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706975 ecr 0,sackOK,eol], length 0
14:29:24.442693 IP localhost.58693 > localhost.58978: Flags [R.], seq 0, ack 1119137788, win 0, length 0
14:29:24.443898 IP localhost.58979 > localhost.58693: Flags [S], seq 1843362092, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706977 ecr 0,sackOK,eol], length 0
14:29:24.443912 IP localhost.58693 > localhost.58979: Flags [R.], seq 0, ack 1843362093, win 0, length 0
14:29:24.445085 IP localhost.58980 > localhost.58693: Flags [S], seq 2336267591, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706978 ecr 0,sackOK,eol], length 0
14:29:24.445100 IP localhost.58693 > localhost.58980: Flags [R.], seq 0, ack 2336267592, win 0, length 0
14:29:24.446303 IP localhost.58981 > localhost.58693: Flags [S], seq 3297569415, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706979 ecr 0,sackOK,eol], length 0
14:29:24.446321 IP localhost.58693 > localhost.58981: Flags [R.], seq 0, ack 3297569416, win 0, length 0
14:29:24.447565 IP localhost.58982 > localhost.58693: Flags [S], seq 2742157513, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706980 ecr 0,sackOK,eol], length 0
14:29:24.447575 IP localhost.58693 > localhost.58982: Flags [R.], seq 0, ack 2742157514, win 0, length 0
14:29:24.448901 IP localhost.58983 > localhost.58693: Flags [S], seq 3569996507, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706981 ecr 0,sackOK,eol], length 0
14:29:24.448913 IP localhost.58693 > localhost.58983: Flags [R.], seq 0, ack 3569996508, win 0, length 0
14:29:24.450233 IP localhost.58984 > localhost.58693: Flags [S], seq 2189096629, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706983 ecr 0,sackOK,eol], length 0
14:29:24.450254 IP localhost.58693 > localhost.58984: Flags [R.], seq 0, ack 2189096630, win 0, length 0
14:29:24.451602 IP localhost.58985 > localhost.58693: Flags [S], seq 3668623372, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706984 ecr 0,sackOK,eol], length 0
14:29:24.451616 IP localhost.58693 > localhost.58985: Flags [R.], seq 0, ack 3668623373, win 0, length 0
14:29:24.453369 IP localhost.58986 > localhost.58693: Flags [S], seq 3841327697, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706986 ecr 0,sackOK,eol], length 0
14:29:24.453415 IP localhost.58693 > localhost.58986: Flags [R.], seq 0, ack 3841327698, win 0, length 0
14:29:24.455264 IP localhost.58987 > localhost.58693: Flags [S], seq 1397446064, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706987 ecr 0,sackOK,eol], length 0
14:29:24.455285 IP localhost.58693 > localhost.58987: Flags [R.], seq 0, ack 1397446065, win 0, length 0
14:29:24.456635 IP localhost.58988 > localhost.58693: Flags [S], seq 658704010, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706989 ecr 0,sackOK,eol], length 0
14:29:24.456655 IP localhost.58693 > localhost.58988: Flags [R.], seq 0, ack 658704011, win 0, length 0
14:29:24.457805 IP localhost.58989 > localhost.58693: Flags [S], seq 108288592, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706990 ecr 0,sackOK,eol], length 0
14:29:24.457821 IP localhost.58693 > localhost.58989: Flags [R.], seq 0, ack 108288593, win 0, length 0
14:29:24.458936 IP localhost.58990 > localhost.58693: Flags [S], seq 834439671, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706991 ecr 0,sackOK,eol], length 0
14:29:24.458976 IP localhost.58693 > localhost.58990: Flags [R.], seq 0, ack 834439672, win 0, length 0
14:29:24.460094 IP localhost.58991 > localhost.58693: Flags [S], seq 3341628230, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706992 ecr 0,sackOK,eol], length 0
14:29:24.460108 IP localhost.58693 > localhost.58991: Flags [R.], seq 0, ack 3341628231, win 0, length 0
14:29:24.461227 IP localhost.58992 > localhost.58693: Flags [S], seq 1072784276, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706993 ecr 0,sackOK,eol], length 0
14:29:24.461242 IP localhost.58693 > localhost.58992: Flags [R.], seq 0, ack 1072784277, win 0, length 0
14:29:24.463193 IP localhost.58993 > localhost.58693: Flags [S], seq 3613406588, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706994 ecr 0,sackOK,eol], length 0
14:29:24.463213 IP localhost.58693 > localhost.58993: Flags [R.], seq 0, ack 3613406589, win 0, length 0
14:29:24.464639 IP localhost.58994 > localhost.58693: Flags [S], seq 2569113338, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706995 ecr 0,sackOK,eol], length 0
14:29:24.464658 IP localhost.58693 > localhost.58994: Flags [R.], seq 0, ack 2569113339, win 0, length 0
14:29:24.465911 IP localhost.58995 > localhost.58693: Flags [S], seq 897053363, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706996 ecr 0,sackOK,eol], length 0
14:29:24.465924 IP localhost.58693 > localhost.58995: Flags [R.], seq 0, ack 897053364, win 0, length 0
14:29:24.467197 IP localhost.58996 > localhost.58693: Flags [S], seq 1556778022, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706997 ecr 0,sackOK,eol], length 0
14:29:24.467210 IP localhost.58693 > localhost.58996: Flags [R.], seq 0, ack 1556778023, win 0, length 0
14:29:24.468455 IP localhost.58997 > localhost.58693: Flags [S], seq 522890491, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706998 ecr 0,sackOK,eol], length 0
14:29:24.468469 IP localhost.58693 > localhost.58997: Flags [R.], seq 0, ack 522890492, win 0, length 0
14:29:24.469650 IP localhost.58998 > localhost.58693: Flags [S], seq 3272035680, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107706999 ecr 0,sackOK,eol], length 0
14:29:24.469661 IP localhost.58693 > localhost.58998: Flags [R.], seq 0, ack 3272035681, win 0, length 0
14:29:24.470846 IP localhost.58999 > localhost.58693: Flags [S], seq 1810034270, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107707000 ecr 0,sackOK,eol], length 0
14:29:24.470861 IP localhost.58693 > localhost.58999: Flags [R.], seq 0, ack 1810034271, win 0, length 0
14:29:24.472034 IP localhost.59000 > localhost.58693: Flags [S], seq 2410840076, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107707001 ecr 0,sackOK,eol], length 0
14:29:24.472046 IP localhost.58693 > localhost.59000: Flags [R.], seq 0, ack 2410840077, win 0, length 0
14:29:24.473404 IP localhost.59001 > localhost.58693: Flags [S], seq 1786606508, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107707002 ecr 0,sackOK,eol], length 0
14:29:24.473468 IP localhost.58693 > localhost.59001: Flags [R.], seq 0, ack 1786606509, win 0, length 0
14:29:24.476083 IP localhost.59002 > localhost.58693: Flags [S], seq 2237271129, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107707004 ecr 0,sackOK,eol], length 0
14:29:24.476098 IP localhost.58693 > localhost.59002: Flags [R.], seq 0, ack 2237271130, win 0, length 0
14:29:24.477475 IP localhost.59003 > localhost.58693: Flags [S], seq 1523915848, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107707006 ecr 0,sackOK,eol], length 0
14:29:24.477485 IP localhost.58693 > localhost.59003: Flags [R.], seq 0, ack 1523915849, win 0, length 0
14:29:25.142164 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,nop,wscale 4,nop,nop,TS val 1107707572 ecr 0,sackOK,eol], length 0
14:29:25.142176 IP localhost.59223 > localhost.58693: Flags [S], seq 4039966681, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107707572 ecr 0,sackOK,eol], length 0
14:29:25.342565 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,nop,wscale 4,nop,nop,TS val 1107707748 ecr 0,sackOK,eol], length 0
14:29:25.342578 IP localhost.59223 > localhost.58693: Flags [S], seq 4039966681, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107707748 ecr 0,sackOK,eol], length 0
14:29:25.443273 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,nop,wscale 4,nop,nop,TS val 1107707848 ecr 0,sackOK,eol], length 0
14:29:25.443319 IP localhost.59223 > localhost.58693: Flags [S], seq 4039966681, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107707848 ecr 0,sackOK,eol], length 0
14:29:25.644115 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,nop,wscale 4,nop,nop,TS val 1107708047 ecr 0,sackOK,eol], length 0
14:29:25.644126 IP localhost.59223 > localhost.58693: Flags [S], seq 4039966681, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107708047 ecr 0,sackOK,eol], length 0
14:29:25.745269 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,nop,wscale 4,nop,nop,TS val 1107708148 ecr 0,sackOK,eol], length 0
14:29:25.846262 IP localhost.59223 > localhost.58693: Flags [S], seq 4039966681, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107708248 ecr 0,sackOK,eol], length 0
14:29:25.946931 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,nop,wscale 4,nop,nop,TS val 1107708348 ecr 0,sackOK,eol], length 0
14:29:26.249474 IP localhost.59223 > localhost.58693: Flags [S], seq 4039966681, win 65535, options [mss 16344,nop,wscale 3,nop,nop,TS val 1107708650 ecr 0,sackOK,eol], length 0
14:29:26.350322 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,nop,wscale 4,nop,nop,TS val 1107708750 ecr 0,sackOK,eol], length 0
14:29:27.255626 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,nop,wscale 4,nop,nop,TS val 1107709606 ecr 0,sackOK,eol], length 0
14:29:28.967861 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,nop,wscale 4,nop,nop,TS val 1107711260 ecr 0,sackOK,eol], length 0
14:29:32.293864 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,sackOK,eol], length 0
14:29:38.938614 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,sackOK,eol], length 0
14:29:45.481879 IP localhost.59224 > localhost.58693: Flags [S], seq 2276013461, win 65535, options [mss 16344,sackOK,eol], length 0
;;;","09/Mar/15 07:04;sriharsha;[~junrao] It might be due to this https://issues.apache.org/jira/browse/KAFKA-1887?focusedCommentId=14330093&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14330093 . 

KAFKA-1971 removed healthCheck.shutdown() which doesn't remove the brokerId causing controllerChannelManager.shutdown() throw an exception as noted in my comment in KAFKA-1887.;;;","09/Mar/15 12:12;gwenshap;[~junrao]: Out of curiosity, what's the value of net.inet.tcp.blackhole on your machine?;;;","09/Mar/15 13:40;gwenshap;[~junrao] can you also check dmesg (sudo dmesg) to see if you see something like ""Limiting closed port RST""?
Its possible that we reached icmplim threshold.;;;","10/Mar/15 00:48;junrao;[~gwenshap], thanks for the info. Steve Miller also pointed me to the same direction. It is indeed due to kernel rate-limit on the number of RST segments it'll send. From /var/log/system.log, I do see the following entries.

Mar  6 14:29:24 kernel[0]: Limiting closed port RST response from 259 to 250 packets per second
Mar  6 14:29:26 kernel[0]: Limiting closed port RST response from 273 to 250 packets per second
Mar  6 14:29:28 kernel[0]: Limiting closed port RST response from 260 to 250 packets per second

Not sure exactly when rate limit is triggered though. I tried to reproduce this issue by keeping connecting to a non-existing port. However, the connecting still fails quickly after hundreds of tries.


;;;","10/Mar/15 08:26;guozhang;Jun, how frequently will this happen on your Mac?

Aside from the TCP issue (would be interesting to learn what is the triggering threshold), I'm wondering if we should 

1) Add backoff for the replica fetcher threads ""HandleError"", there is already a ticket open and in progress for this; 
2) Use a different timeout for Socket.connect().

Today the controllerSocketTimeoutMs is actually used in two places, Socket.setSoTime() and Socket.connect(). Arguably for setting the socket timeout we can use a large value of 30 sec, but we may probably want much smaller values for timeout in connect calls.;;;","10/Mar/15 09:36;junrao;[~guozhang], this seems to happen frequently to me on Mac.

I agree that the proper fix is to add the fetcher backoff. Commented on KAFKA-1461.;;;","13/Mar/15 05:08;junrao;This is fixed in KAFKA-1461. The unit tests time went down from 12 mins to 8.5 mins on my mac.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Offset commit API, does it work?",KAFKA-1306,12701792,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,korebantic2,korebantic2,17/Mar/14 11:25,20/Mar/14 03:33,22/Mar/23 15:10,20/Mar/14 03:33,0.8.1,,,,,,,,,,,,,,,,,0,,,,,,"I followed this guide very carefully https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol and patched the ruby client Poseidon. Whenever I submit an OffsetCommitRequest, I receive the following error in the kafka logs:

{noformat}
23:07:33 kafka-b0.1  | java.nio.BufferUnderflowException
23:07:33 kafka-b0.1  | 	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:145)
23:07:33 kafka-b0.1  | 	at java.nio.ByteBuffer.get(ByteBuffer.java:694)
23:07:33 kafka-b0.1  | 	at kafka.api.ApiUtils$.readShortString(ApiUtils.scala:38)
23:07:33 kafka-b0.1  | 	at kafka.api.UpdateMetadataRequest$$anonfun$readFrom$1.apply(UpdateMetadataRequest.scala:43)
23:07:33 kafka-b0.1  | 	at kafka.api.UpdateMetadataRequest$$anonfun$readFrom$1.apply(UpdateMetadataRequest.scala:42)
23:07:33 kafka-b0.1  | 	at scala.collection.immutable.Range.foreach(Range.scala:78)
23:07:33 kafka-b0.1  | 	at kafka.api.UpdateMetadataRequest$.readFrom(UpdateMetadataRequest.scala:42)
23:07:33 kafka-b0.1  | 	at kafka.api.RequestKeys$$anonfun$7.apply(RequestKeys.scala:42)
23:07:33 kafka-b0.1  | 	at kafka.api.RequestKeys$$anonfun$7.apply(RequestKeys.scala:42)
23:07:33 kafka-b0.1  | 	at kafka.network.RequestChannel$Request.<init>(RequestChannel.scala:50)
23:07:33 kafka-b0.1  | 	at kafka.network.Processor.read(SocketServer.scala:353)
23:07:33 kafka-b0.1  | 	at kafka.network.Processor.run(SocketServer.scala:245)
23:07:33 kafka-b0.1  | 	at java.lang.Thread.run(Thread.java:724)
{/noformat}

The binary data for the request looks as follows:

{noformat}
\x00\x06\x00\x00\x00\x00\x00\x02\x00\x02p1\x00\x03cg1\x00\x00\x00\x01\x00\x05repl5\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x04meta
{/noformat}

Thinking that I failed to understand how to formulate the binary request correctly, I downloaded sarama, the go kafka library. Using its API to make the request, I also received the same error. Here's an example:

https://github.com/talbright/saramit


",,junrao,korebantic2,zhangzs,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,380137,,,Wed Mar 19 19:32:07 UTC 2014,,,,,,,,,,"0|i1thxr:",380421,,,,,,,,,,,,,,,,,,,,"19/Mar/14 12:11;junrao;It seems that you put in the wrong request id. The id for OffsetCommit is 8, instead of 6.;;;","19/Mar/14 12:21;junrao;Actually, just realized that the request id for OffsetCommit is documented incorrectly in the wiki. Updated the wiki.;;;","20/Mar/14 00:31;korebantic2;Man Jimi had it all wrong, it should have been if a 6 was an 8.

http://www.youtube.com/watch?v=VNXWMHu9An0

Thanks for the update, I'll work on testing it out on my end and update the issue once I verify. ;;;","20/Mar/14 03:32;korebantic2;Yup. As you said, it wasn't documented correctly. I change the ID to the request as you indicated above, and I was able to submit an OffsetCommit request. I also confirmed the data was stored in zookeeper. So it looks good.

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"PatternSyntaxException thrown in MM, causes MM to hang",KAFKA-3140,12933510,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,singhashish,singhashish,singhashish,23/Jan/16 06:20,23/Jan/16 08:25,22/Mar/23 15:10,23/Jan/16 08:25,,,,,,,0.10.0.0,,,,,,,tools,,,,0,,,,,,"On passing an invalid java regex string as whitelist to MM, PatternSyntaxException is thrown and MM hangs. Below is relevant ST.

{code}
java.util.regex.PatternSyntaxException: Dangling meta character '*' near index 0
*
^
	at java.util.regex.Pattern.error(Pattern.java:1955)
	at java.util.regex.Pattern.sequence(Pattern.java:2123)
	at java.util.regex.Pattern.expr(Pattern.java:1996)
	at java.util.regex.Pattern.compile(Pattern.java:1696)
	at java.util.regex.Pattern.<init>(Pattern.java:1351)
	at java.util.regex.Pattern.compile(Pattern.java:1028)
	at kafka.tools.MirrorMaker$MirrorMakerNewConsumer.init(MirrorMaker.scala:521)
	at kafka.tools.MirrorMaker$MirrorMakerThread.run(MirrorMaker.scala:389)
{code}",,githubbot,gwenshap,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Jan 23 00:25:07 UTC 2016,,,,,,,,,,"0|i2rvfz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"23/Jan/16 06:23;githubbot;GitHub user SinghAsDev opened a pull request:

    https://github.com/apache/kafka/pull/805

    KAFKA-3140: Fix PatternSyntaxException and hand caused by it in Mirro…

    Fix PatternSyntaxException and hand caused by it in MirrorMaker on passing invalid java regex string as whitelist

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/SinghAsDev/kafka KAFKA-3140

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/805.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #805
    
----
commit 0f120f976ce66e37cb5180df2b024def1cfcd6bb
Author: Ashish Singh <asingh@cloudera.com>
Date:   2016-01-22T22:22:05Z

    KAFKA-3140: Fix PatternSyntaxException and hand caused by it in MirrorMaker on passing invalid java regex string as whitelist.

----
;;;","23/Jan/16 08:25;gwenshap;Issue resolved by pull request 805
[https://github.com/apache/kafka/pull/805];;;","23/Jan/16 08:25;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/805
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
quick cleanup of producer performance scripts,KAFKA-2080,12787147,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,gwenshap,gwenshap,gwenshap,01/Apr/15 04:31,02/Nov/15 08:34,22/Mar/23 15:10,02/Nov/15 08:33,,,,,,,,,,,,,,tools,,,,0,newbie,,,,,"We have two producer performance tools at the moment: one at o.a.k.client.tools and one at kafka.tools

bin/kafka-producer-perf-test.sh is calling the kafka.tools one.

org.apache.kafka.clients.tools.ProducerPerformance has --messages listed as optional (with default) while leaving the parameter out results in an error.

Cleanup will include:
* Removing the kafka.tools performance tool
* Changing the shellscript to use new tool
* Fix the misleading documentation for --messages
* Adding both performance tools to the kafka docs


",,gwenshap,varvind,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Nov 02 00:34:04 UTC 2015,,,,,,,,,,"0|i27m1b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"02/Nov/15 03:13;varvind;Looks like this has been fixed in https://issues.apache.org/jira/browse/KAFKA-2562;;;","02/Nov/15 08:34;gwenshap;Thanks for the reminder [~varvind];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka-acls.sh throws ArrayIndexOutOfBoundsException for an invalid authorizer-property,KAFKA-3141,12933547,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,singhashish,singhashish,singhashish,23/Jan/16 08:22,10/Feb/16 12:49,22/Mar/23 15:10,10/Feb/16 12:49,0.9.0.0,,,,,,0.10.0.0,0.9.0.1,,,,,,,,,,0,,,,,,"kafka-acls.sh throws ArrayIndexOutOfBoundsException for an invalid authorizer-property. ST below.

{code}
Error while executing topic Acl command 1
java.lang.ArrayIndexOutOfBoundsException: 1
	at kafka.admin.AclCommand$$anonfun$withAuthorizer$2.apply(AclCommand.scala:65)
	at kafka.admin.AclCommand$$anonfun$withAuthorizer$2.apply(AclCommand.scala:65)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at kafka.admin.AclCommand$.withAuthorizer(AclCommand.scala:65)
	at kafka.admin.AclCommand$.addAcl(AclCommand.scala:78)
	at kafka.admin.AclCommand$.main(AclCommand.scala:48)
	at kafka.admin.AclCommand.main(AclCommand.scala)
{code}",,githubbot,gwenshap,singhashish,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Feb 10 04:49:22 UTC 2016,,,,,,,,,,"0|i2rvnz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"23/Jan/16 08:26;githubbot;GitHub user SinghAsDev opened a pull request:

    https://github.com/apache/kafka/pull/806

    KAFKA-3141: Skip misformed properties instead of throwing ArrayIndexO…

    Skip misformed properties instead of throwing ArrayIndexOutOfBoundsException

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/SinghAsDev/kafka KAFKA-3141

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/806.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #806
    
----
commit c7ff10bdde3482db2d594faaa6760ea5c0137c0b
Author: Ashish Singh <asingh@cloudera.com>
Date:   2016-01-23T00:24:15Z

    KAFKA-3141: Skip misformed properties instead of throwing ArrayIndexOutOfBoundsException

----
;;;","09/Feb/16 01:59;singhashish;[~gwenshap] mind taking a look at this. It will be nice to have this in 0.9.0.1.;;;","10/Feb/16 12:49;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/806
;;;","10/Feb/16 12:49;gwenshap;Issue resolved by pull request 806
[https://github.com/apache/kafka/pull/806];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Build fails for scala 2.9.2,KAFKA-1813,12760463,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,fanatoly,fanatoly,fanatoly,09/Dec/14 23:28,13/Dec/14 10:22,22/Mar/23 15:10,13/Dec/14 03:54,,,,,,,0.9.0.0,,,,,,,build,,,,0,,,,,,"Currently, in trunk, the 2.9.2 build fails with the following error:

MirrorMaker.scala:507 overloaded method value commitOffsets with alternatives:
  (isAutoCommit: Boolean,topicPartitionOffsets: scala.collection.immutable.Map[kafka.common.TopicAndPartition,kafka.common.OffsetAndMetadata])Unit <and>
  (isAutoCommit: Boolean)Unit <and>
  => Unit
 cannot be applied to (isAutoCommit: Boolean, scala.collection.immutable.Map[kafka.common.TopicAndPartition,kafka.common.OffsetAndMetadata])
        connector.commitOffsets(isAutoCommit = false, offsetsToCommit)

It looks like the 2.9.2 compiler cannot resolve an overloaded method when mixing named and ordered parameters.

I ran into this when I cloned the repo and ran ./gradlew test.",,fanatoly,guozhang,joestein,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Dec/14 23:31;fanatoly;fix_2_9_2_build.patch;https://issues.apache.org/jira/secure/attachment/12686025/fix_2_9_2_build.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sat Dec 13 02:22:44 UTC 2014,,,,,,,,,,"0|i238bj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"09/Dec/14 23:31;fanatoly;patch fixing scala 2.9.2 build;;;","09/Dec/14 23:53;joestein;Did you run the new bootstrap we added to the README?;;;","10/Dec/14 00:37;fanatoly;Yes. The project was bootstrapped. I was wrong about running into this when I ran test. I must have run test_core_2_9_2 directly.;;;","13/Dec/14 03:54;junrao;Thanks for the patch. The issue was introduced by KAFKA-1650. +1 and committed to trunk.;;;","13/Dec/14 10:22;guozhang;Thanks Anatoly.

When I ran the tests / builds before checking in KAFKA-1650 I did not see either this issue or KAFKA-1815, which is a bit wired. Will do some local testing again.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SocketServer.shutdown() doesn't close open connections,KAFKA-1279,12696986,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jkreps,jkreps,jkreps,25/Feb/14 03:08,25/Feb/14 11:31,22/Mar/23 15:10,25/Feb/14 11:31,,,,,,,,,,,,,,,,,,0,,,,,,"SocketServer.shutdown() stops the selector thread but doesn't actually close all the existing connections.

In normal operations this doesn't matter much because right after shutting down the socket server the process exits which closes all the connections. However we found this issue during unit testing--essentially we are leaking all the connections so shutdown() doesn't actually cause any error at all on the client which is still able to write to the socket and just never receives a response.",,jkreps,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Feb/14 06:47;jkreps;KAFKA-1279.patch;https://issues.apache.org/jira/secure/attachment/12630820/KAFKA-1279.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,375461,,,Mon Feb 24 22:47:52 UTC 2014,,,,,,,,,,"0|i1sp87:",375757,,,,,,,,,,,,,,,,,,,,"25/Feb/14 06:47;jkreps;Created reviewboard https://reviews.apache.org/r/18441/
 against branch trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Coordinator should return illegal generation for commits from unknown groups with non-negative generation,KAFKA-2596,12901185,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,hachikuji,hachikuji,hachikuji,29/Sep/15 07:49,09/Oct/15 14:35,22/Mar/23 15:10,09/Oct/15 14:35,0.9.0.0,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Currently the consumer coordinator accepts offset commits blindly if it has no state stored for the associated groupId. This means that upon coordinator failover, offset commits from any member of a group will be accepted, even if that member is from an older generation. A better way of handling this case would be to return an ILLEGAL_GENERATION error when the generation in the commit request is greater than or equal to 0. Consumers that are not using group management will always send a generation of -1, so their commits will still be accepted as valid. ",,githubbot,guozhang,hachikuji,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Oct 09 06:35:30 UTC 2015,,,,,,,,,,"0|i2mdv3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"01/Oct/15 08:17;githubbot;GitHub user hachikuji opened a pull request:

    https://github.com/apache/kafka/pull/267

    KAFKA-2596: reject commits from unknown groups with positive generations

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/hachikuji/kafka KAFKA-2596

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/267.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #267
    
----
commit 4dd1fa1705d5d6d77325db43049e1bb433817209
Author: Jason Gustafson <jason@confluent.io>
Date:   2015-10-01T00:11:04Z

    KAFKA-2596: reject commits from unknown groups with positive generations

----
;;;","09/Oct/15 14:35;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/267
;;;","09/Oct/15 14:35;guozhang;Issue resolved by pull request 267
[https://github.com/apache/kafka/pull/267];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Metadata#getClusterForCurrentTopics can throw NPE even with null checking,KAFKA-2599,12901421,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,eribeiro,eribeiro,eribeiro,30/Sep/15 04:46,07/Oct/15 04:35,22/Mar/23 15:10,07/Oct/15 04:35,0.8.2.1,,,,,,0.9.0.0,,,,,,,clients,,,,0,,,,,,"While working on another issue I have just seen the following:

{code}
    private Cluster getClusterForCurrentTopics(Cluster cluster) {
        Collection<PartitionInfo> partitionInfos = new ArrayList<>();
        if (cluster != null) {
            for (String topic : this.topics) {
                partitionInfos.addAll(cluster.partitionsForTopic(topic));
            }
        }
        return new Cluster(cluster.nodes(), partitionInfos);
    }
{code}

Well, there's a null check for cluster, but if cluster is null it will throw NPE at the return line by calling {{cluster.nodes()}}! So, I put together a quick fix and changed {{MetadataTest}} to reproduce this error.",,eribeiro,githubbot,guozhang,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Oct 06 20:35:57 UTC 2015,,,,,,,,,,"0|i2mfdr:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"30/Sep/15 04:48;githubbot;GitHub user eribeiro opened a pull request:

    https://github.com/apache/kafka/pull/262

    KAFKA-2599 Metadata#getClusterForCurrentTopics can throw NPE even wit…

    …h null checking

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/eribeiro/kafka KAFKA-2599

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/262.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #262
    
----
commit 960107edf131a710e1af808fe93a6ad8566098a5
Author: Edward Ribeiro <edward.ribeiro@gmail.com>
Date:   2015-09-29T20:42:31Z

    KAFKA-2599 Metadata#getClusterForCurrentTopics can throw NPE even with null checking

----
;;;","06/Oct/15 15:39;ijuma;Trivial fix for NPE.;;;","07/Oct/15 04:35;guozhang;Issue resolved by pull request 262
[https://github.com/apache/kafka/pull/262];;;","07/Oct/15 04:35;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/262
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BoundedByteBufferReceive hides OutOfMemoryError,KAFKA-204,12531486,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Critical,Fixed,cburroughs,cburroughs,cburroughs,16/Nov/11 00:31,24/Nov/11 07:46,22/Mar/23 15:10,24/Nov/11 07:46,0.7,,,,,,0.7.1,,,,,,,,,,,0,,,,,,"  private def byteBufferAllocate(size: Int): ByteBuffer = {
    var buffer: ByteBuffer = null
    try {
      buffer = ByteBuffer.allocate(size)
    }
    catch {
      case e: OutOfMemoryError =>
        throw new RuntimeException(""OOME with size "" + size, e)
      case e2 =>
        throw e2
    }
    buffer
  }

This hides the fact that an Error occurred, and will likely result in some log handler printing a message, instead of exiting with non-zero status.  Knowing how large the allocation was that caused an OOM is really nice, so I'd suggest logging in byteBufferAllocate and then re-throwing OutOfMemoryError",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Nov/11 22:12;cburroughs;k204-v1.txt;https://issues.apache.org/jira/secure/attachment/12503888/k204-v1.txt",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,217222,,,Wed Nov 23 23:46:49 UTC 2011,,,,,,,,,,"0|i0l4g7:",121371,,,,,,,,,,,,,,,,,,,,"16/Nov/11 00:37;jkreps;Uh...does anyone know what the motivation of this was originally? Catching OutOfMemoryError is a bit unorthodox...;;;","16/Nov/11 01:13;tgautier;Agree with Jay - if you get an OOME all bets are off.  Best to just exit.;;;","16/Nov/11 22:16;cburroughs;Tiny patch for this one case, created KAFKA-205 to follow up.;;;","17/Nov/11 00:22;junrao;The main reason this was added is to show the requested size and the caller that triggered such a request. It would be nice if both pieces are logged together. With the new patch, those two pieces are logged separately (although should be close) and someone has to link them together manually.;;;","17/Nov/11 00:24;junrao;Another possibility is to rethrow a new RuntimeException with OOME wrapped as the cause.;;;","19/Nov/11 21:23;erikvanoosten;If you rethrow, then rethrow a new OOME with the original OOME wrapped.;;;","21/Nov/11 08:16;junrao;Hmm, it doesn't look like OutOfMemoryError allow one to specify a cause during initialization.;;;","23/Nov/11 15:51;jkreps;I understand the intent, but the important thing here is not to swallow the OOM exception, right? I mean once you hit that all bets are off, you need to restart your process...basically I think we shouldn't be messing with that.;;;","23/Nov/11 15:52;jkreps;We have request limits in the server and consumer that should provide protection against this so i think that is the appropriate way to handle it. If it does happen I think we should just break everything and then the person running things should set the configs correctly to limit the max request size the server will accept and the max fetch size for the client.;;;","23/Nov/11 21:18;cburroughs;> I mean once you hit that all bets are off, you need to restart your process...basically I think we shouldn't be messing with that. 

Yeah, the most important thing to do is get out of the way and let the process exit with a non-zero status code.

So the options as I see it are:
 (1) Do something ugly (like pass the original fetch request to byteBufferAllocate) for the purposes of a valiant but possible futile logging attempt (there is no guarantee we will be able to allocate the logging Strings we are already asking for, everything we ad makes that less likely).
 (2)  Just rethrow e after a logging attempt in byteBufferAllocate.

My preference is (2), but if someone prefers (1) that's a reasonable trade off.;;;","24/Nov/11 02:47;junrao;Ok, I am fine with the patch then. Any objection to commit it?;;;","24/Nov/11 02:50;nehanarkhede;+1;;;","24/Nov/11 07:46;junrao;Just committed this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NullPointerException in client on MetadataRequest,KAFKA-2105,12819182,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,omkreddy,theduderog,theduderog,08/Apr/15 12:42,31/Aug/17 23:45,22/Mar/23 15:10,31/Aug/17 23:45,0.8.2.1,,,,,,0.11.0.1,1.0.0,,,,,,clients,,,,0,,,,,,"With the new producer, if you accidentally pass null to KafkaProducer.partitionsFor(null), it will cause the IO thread to throw NPE.

Uncaught error in kafka producer I/O thread: 
java.lang.NullPointerException
	at org.apache.kafka.common.utils.Utils.utf8Length(Utils.java:174)
	at org.apache.kafka.common.protocol.types.Type$5.sizeOf(Type.java:176)
	at org.apache.kafka.common.protocol.types.ArrayOf.sizeOf(ArrayOf.java:55)
	at org.apache.kafka.common.protocol.types.Schema.sizeOf(Schema.java:81)
	at org.apache.kafka.common.protocol.types.Struct.sizeOf(Struct.java:218)
	at org.apache.kafka.common.requests.RequestSend.serialize(RequestSend.java:35)
	at org.apache.kafka.common.requests.RequestSend.<init>(RequestSend.java:29)
	at org.apache.kafka.clients.NetworkClient.metadataRequest(NetworkClient.java:369)
	at org.apache.kafka.clients.NetworkClient.maybeUpdateMetadata(NetworkClient.java:391)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:188)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:191)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:122)
	at java.lang.Thread.run(Thread.java:745)",,githubbot,gwenshap,theduderog,yaitskov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Apr/15 01:26;yaitskov;guard-from-null.patch;https://issues.apache.org/jira/secure/attachment/12727960/guard-from-null.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Aug 31 15:33:18 UTC 2017,,,,,,,,,,"0|i2cy7z:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"24/Apr/15 16:55;yaitskov;The patch checks that the argument of partitionsFor is not null.;;;","25/Apr/15 00:41;gwenshap;I'm having trouble applying this patch format.

Can you generate one using ""git diff""? Better yet, try our patch review tool: https://cwiki.apache.org/confluence/display/KAFKA/Patch+submission+and+review;;;","25/Apr/15 01:26;yaitskov;Sorry, First time I did patch with --color option.
As for me patch files are legacy technique, a github reference for a pull request looks much much better, but I didn't find any ticket resolution in a such way. ;;;","19/Aug/17 22:54;githubbot;GitHub user omkreddy opened a pull request:

    https://github.com/apache/kafka/pull/3697

    KAFKA-2105: add topic null check to KafkaProducer.partitionsFor method

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/omkreddy/kafka KAFKA-2105

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/3697.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #3697
    
----
commit 7a67d783571165cfc4fa5a301aeaaa3a139273af
Author: Manikumar Reddy <manikumar.reddy@gmail.com>
Date:   2017-08-19T14:46:35Z

    KAFKA-2105: add null check to KafkaProducer.partitionsFor method

----
;;;","31/Aug/17 23:33;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/3697
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NullPointerException in RequestSendThread,KAFKA-1883,12768588,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,jaikiran,jaikiran,jaikiran,20/Jan/15 11:35,03/Sep/15 08:04,22/Mar/23 15:10,26/Jan/15 10:55,,,,,,,0.9.0.0,,,,,,,core,,,,0,,,,,,"I often see the following exception while running some tests
(ProducerFailureHandlingTest.testNoResponse is one such instance):

{code}
[2015-01-19 22:30:24,257] ERROR [Controller-0-to-broker-1-send-thread],
Controller 0 fails to send a request to broker
id:1,host:localhost,port:56729 (kafka.controller.RequestSendThread:103)
java.lang.NullPointerException
    at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.
scala:150)
    at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:60)

{code}

Looking at that code in question, I can see that the NPE can be triggered
when the ""receive"" is null which can happen if the ""isRunning"" is false
(i.e a shutdown has been requested).",,jaikiran,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/15 11:40;jaikiran;KAFKA-1883.patch;https://issues.apache.org/jira/secure/attachment/12693211/KAFKA-1883.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Mon Jan 26 02:55:21 UTC 2015,,,,,,,,,,"0|i24jqf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"20/Jan/15 11:40;jaikiran;Created reviewboard https://reviews.apache.org/r/30062/diff/
 against branch origin/trunk;;;","26/Jan/15 10:55;nehanarkhede;Thanks for the patch. Pushed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Can't set SSL as inter-broker-protocol by rolling restart of brokers,KAFKA-2738,12910207,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,benstopford,gwenshap,gwenshap,04/Nov/15 08:48,06/Nov/15 01:05,22/Mar/23 15:10,06/Nov/15 01:05,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Scenario (as carefully documented by [~benstopford]:

1. Start 2 or more brokers with listeners on both PLAINTEXT and SSL protocols, and PLAINTEXT as security.inter.broker.protocol:

inter.broker.protocol.version = 0.9.0.X
security.inter.broker.protocol = PLAINTEXT
listeners = PLAINTEXT://:9092,SSL://:9093

2. Stop one of the brokers and change security.inter.broker.protocol to SSL

inter.broker.protocol.version = 0.9.0.X
security.inter.broker.protocol = SSL
listeners = PLAINTEXT://:9092,SSL://:9093

3. Start that broker again.

You will get replication errors as it will attempt to use SSL on a PLAINTEXT port:

{code}
WARN ReplicaFetcherThread-0-3, Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@78ca3ba1. Possible cause: java.io.IOException: Connection to Node(3, worker4, 9092) failed (kafka.server.ReplicaFetcherThread)
WARN Failed to send SSL Close message (org.apache.kafka.common.network.SslTransportLayer)
java.io.IOException: Broken pipe
at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
at sun.nio.ch.IOUtil.write(IOUtil.java:65)
at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:492)
at org.apache.kafka.common.network.SslTransportLayer.flush(SslTransportLayer.java:188)
at org.apache.kafka.common.network.SslTransportLayer.close(SslTransportLayer.java:161)
at org.apache.kafka.common.network.KafkaChannel.close(KafkaChannel.java:50)
at org.apache.kafka.common.network.Selector.close(Selector.java:448)
at org.apache.kafka.common.network.Selector.poll(Selector.java:316)
at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:270)
at kafka.utils.NetworkClientBlockingOps$.recurse$1(NetworkClientBlockingOps.scala:128)
at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollUntilFound$extension(NetworkClientBlockingOps.scala:139)
at kafka.utils.NetworkClientBlockingOps$.kafka$utils$NetworkClientBlockingOps$$pollUntil$extension(NetworkClientBlockingOps.scala:105)
at kafka.utils.NetworkClientBlockingOps$.blockingReady$extension(NetworkClientBlockingOps.scala:58)
at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:202)
at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:192)
at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)
at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:102)
at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:93)
at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
{code}",,githubbot,guozhang,gwenshap,junrao,Ormod,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 05 17:05:58 UTC 2015,,,,,,,,,,"0|i2nwzj:",9223372036854775807,,junrao,,,,,,,,,,,,,,,,,,"04/Nov/15 10:49;junrao;Good find. In ReplicaManager.makeFollowers(), we have the following code.
val partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map(partition =>
new TopicAndPartition(partition) -> BrokerAndInitialOffset(
leaders.find(_.id == partition.leaderReplicaIdOpt.get).get,
partition.getReplica().get.logEndOffset.messageOffset)).toMap
replicaFetcherManager.addFetcherForPartitions(partitionsToMakeFollowerWithLeaderAndOffset)
It seems that instead of passing in the BrokerEndpoint in the LeaderAndIsrRequest to replicaFetcherManager.addFetcherForPartitions, we should pick the endpoint from MetadataCache.brokers based on the security.inter.broker.protocol.;;;","05/Nov/15 14:31;githubbot;GitHub user gwenshap opened a pull request:

    https://github.com/apache/kafka/pull/428

    KAFKA-2738: Replica FetcherThread should connect to leader endpoint m…

    …atching its inter-broker security protocol

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/gwenshap/kafka KAFKA-2738

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/428.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #428
    
----
commit 994fa156a0f6e818184182e7e5c852ece58191ce
Author: Gwen Shapira <cshapi@gmail.com>
Date:   2015-11-05T06:30:13Z

    KAFKA-2738: Replica FetcherThread should connect to leader endpoint matching its inter-broker security protocol

----
;;;","05/Nov/15 14:34;gwenshap;The PR above fixes the issue we saw.

Two notes:
1. We keep passing metadata cache references around ReplicaManager. It will be nice to refactor a bit and initialize ReplicaManager with MetadataCache as a member, so we can avoid passing references around. I avoided this in this PR to keep it focused.

2. I kept running into timeouts with controlled shutdown while testing this. It doesn't seem like the same issue (i.e. they reproduced very inconsistently on both SSL and PLAINTEXT brokers), but worth keeping in mind.;;;","06/Nov/15 01:05;guozhang;Issue resolved by pull request 428
[https://github.com/apache/kafka/pull/428];;;","06/Nov/15 01:05;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/428
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestPurgatoryPerformance does not compile using IBM JDK,KAFKA-2113,12819975,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,rsivaram,rsivaram,rsivaram,10/Apr/15 16:35,17/Apr/15 01:27,22/Mar/23 15:10,17/Apr/15 01:27,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"TestPurgatoryPerformance uses a class from the com.sun package that is not available in the IBM JDK.

The code does handle the class not found exception at runtime if run with an IBM JRE (and prints out -1 as CPU time). But as a result of the direct reference to the com.sun.management.OperatingSystemMXBean class, Kafka core project no longer compiles with an IBM JDK. 

{quote}
:core:compileTestScala/kafka/core/src/test/scala/other/kafka/TestPurgatoryPerformance.scala:88: type OperatingSystemMXBean is not a member of package com.sun.management
      Some(ManagementFactory.getOperatingSystemMXBean().asInstanceOf[com.sun.management.OperatingSystemMXBean])
                                                                                        ^
one error found
 FAILED
{quote}

The JRE-specific class should be dynamically loaded to enable the class to be compiled as well as run with any JDK.
",,junrao,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Apr/15 16:45;rsivaram;KAFKA-2113.patch;https://issues.apache.org/jira/secure/attachment/12724498/KAFKA-2113.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Apr 16 17:27:19 UTC 2015,,,,,,,,,,"0|i2d33r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"10/Apr/15 16:45;rsivaram;Created reviewboard https://reviews.apache.org/r/33071/diff/
 against branch origin/trunk;;;","10/Apr/15 16:58;rsivaram;The attached patch dynamically loads the JRE-specific class for obtaining process CPU time. It could be made more efficient by caching the getProcessCpuTime method, but since it is only invoked twice, it seemed neater to keep all the code in a single method. Have also added code to get process CPU time for IBM JRE.

Compiled and ran code with OpenJDK which uses the class from com.sun package and with IBM JDK. Both compiled and printed out process CPU time.;;;","17/Apr/15 01:27;junrao;Thanks for the patch. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
java.lang.ArithmeticException: / by zero in ConsumerPerformance,KAFKA-3111,12931559,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,vahid,junrao,junrao,16/Jan/16 03:52,09/Jul/16 07:18,22/Mar/23 15:10,09/Jul/16 07:18,0.9.0.0,,,,,,0.10.1.0,,,,,,,core,,,,0,newbie,,,,,"Saw the following error. If there are lots of unconsumed messages, between two iterations of the consumption, the timestamp may not have changed.

kafka-consumer-perf-test --zookeeper localhost:2181 --topic test --group test-group --threads 1 --show-detailed-stats --reporting-interval 5000
2016-01-13 09:12:43:905, 0, 1048576, 35.2856, 238.4186, 370000, 2500000.0000
2016-01-13 09:12:43:916, 0, 1048576, 35.7624, 47.6837, 375000, 500000.0000
java.lang.ArithmeticException: / by zero
        at kafka.tools.ConsumerPerformance$ConsumerPerfThread.printMessage(ConsumerPerformance.scala:189)
        at kafka.tools.ConsumerPerformance$ConsumerPerfThread.run(ConsumerPerformance.scala:164)
2016-01-13 09:12:43:918, 0, 1048576, 36.2393, 0.7117, 380000, 7000.0000
",,githubbot,junrao,vahid,wushujames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jul 08 23:18:58 UTC 2016,,,,,,,,,,"0|i2rjfj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"16/Jan/16 06:46;vahid;In the example above the timestamps are not the same (they all have different milliseconds). So the timestamp difference is not zero. Wondering what becomes zero there to cause the / by zero exception.;;;","16/Jan/16 07:05;junrao;The log line when the exception happens won't be printed since we hit the exception.;;;","16/Jan/16 07:38;vahid;I see, thanks. I'm trying to reproduce the issue but have not had any luck yet. I've even had log lines with the same timestamp and no exception was raised. 

Example:

bin/kafka-consumer-perf-test.sh --zookeeper localhost:2181 --topic topic1 --threads 1 --show-detailed-stats --reporting-interval 5000 --messages 10001
time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec
2016-01-15 15:06:04:909, 0, 0.0143, 0.2744, 5000, 96153.8462
2016-01-15 15:06:04:914, 0, 0.0286, 3.5763, 10000, 1250000.0000
2016-01-15 15:06:04:914, 0, 0.0286, 0.0001, 10001, 17.5439

Also, this one with smaller number of messages to process:

bin/kafka-consumer-perf-test.sh --zookeeper localhost:2181 --topic topic1 --threads 1 --show-detailed-stats --reporting-interval 1 --messages 10
time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec
2016-01-15 15:36:48:262, 0, 0.0000, 0.0003, 1, 333.3333
2016-01-15 15:36:48:264, 0, 0.0000, Infinity, 2, Infinity
2016-01-15 15:36:48:264, 0, 0.0000, NaN, 3, Infinity
2016-01-15 15:36:48:265, 0, 0.0000, Infinity, 4, Infinity
2016-01-15 15:36:48:265, 0, 0.0000, Infinity, 5, Infinity
2016-01-15 15:36:48:265, 0, 0.0000, Infinity, 6, Infinity
2016-01-15 15:36:48:271, 0, 0.0000, Infinity, 7, Infinity
2016-01-15 15:36:48:271, 0, 0.0000, Infinity, 8, Infinity
2016-01-15 15:36:48:271, 0, 0.0000, Infinity, 9, Infinity
2016-01-15 15:36:48:271, 0, 0.0000, Infinity, 10, Infinity
2016-01-15 15:36:48:272, 0, 0.0000, 0.0000, 10, 0.0000
;;;","16/Jan/16 08:17;junrao;Interesting, this article (http://voidexception.weebly.com/arithmeticexception---causes--fixes.html) explains this. What's in the description happened in 0.8.2 where we define elapsedTime as long. In this case, we hit ArithmeticException if elapsedTime is 0. In 0.9.0, we changed elapsedTime to double. Then, if elapsedTime is 0, we get Infinity.

If there is no data between two iterations and elapsedTime is 0, we should report 0, instead of Infinity. If there is data and elapsedTime is 0, we probably have no other choice but to report Infinity.;;;","19/Jan/16 05:59;githubbot;GitHub user vahidhashemian opened a pull request:

    https://github.com/apache/kafka/pull/788

    KAFKA-3111: Fix ConsumerPerformance output for zero interval lengths

    Interval lengths for ConsumerPerformance could sometime be calculated as zero. In such cases, when the bytes read or messages read are also zero a NaN output is returned for mbRead per second or for nMsg per second, whereas zero would be a more appropriate output.
    
    In cases where interval length is zero but there have been data and messages to read, an output of Infinity is returned, as expected.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/vahidhashemian/kafka KAFKA-3111

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/788.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #788
    
----
commit 34c54e98c5e641986d74506edfd17b0c0ba105c2
Author: Vahid Hashemian <vahidhashemian@us.ibm.com>
Date:   2016-01-18T21:50:02Z

    KAFKA-3111: Fix ConsumerPerformance output for zero interval lengths

----
;;;","19/Jan/16 07:23;githubbot;Github user vahidhashemian closed the pull request at:

    https://github.com/apache/kafka/pull/788
;;;","19/Jan/16 07:23;githubbot;GitHub user vahidhashemian reopened a pull request:

    https://github.com/apache/kafka/pull/788

    KAFKA-3111: Fix ConsumerPerformance output for zero interval lengths

    Interval lengths for ConsumerPerformance could sometime be calculated as zero. In such cases, when the bytes read or messages read are also zero a NaN output is returned for mbRead per second or for nMsg per second, whereas zero would be a more appropriate output.
    
    In cases where interval length is zero but there have been data and messages to read, an output of Infinity is returned, as expected.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/vahidhashemian/kafka KAFKA-3111

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/788.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #788
    
----
commit 34c54e98c5e641986d74506edfd17b0c0ba105c2
Author: Vahid Hashemian <vahidhashemian@us.ibm.com>
Date:   2016-01-18T21:50:02Z

    KAFKA-3111: Fix ConsumerPerformance output for zero interval lengths

----
;;;","01/Jun/16 04:17;vahid;[~junrao] Could you please take a look at the PR for this JIRA if you still think the JIRA is worth a fix? After running some tests I believe the fix provided still improves the consumer performance test output. Thanks for your feedback in advance.;;;","09/Jul/16 07:18;junrao;Issue resolved by pull request 788
[https://github.com/apache/kafka/pull/788];;;","09/Jul/16 07:18;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/788
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
kafka-merge-pr tool fails to update JIRA with fix version 0.9.0.0,KAFKA-2548,12864012,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ijuma,gwenshap,gwenshap,15/Sep/15 04:18,25/Sep/15 01:32,22/Mar/23 15:10,25/Sep/15 01:32,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Trying to update JIRA where the fix version is set to '0.9.0.0', I get the following error:

{code}
Traceback (most recent call last):
  File ""kafka-merge-pr.py"", line 474, in <module>
    main()
  File ""kafka-merge-pr.py"", line 460, in main
    resolve_jira_issues(commit_title, merged_refs, jira_comment)
  File ""kafka-merge-pr.py"", line 317, in resolve_jira_issues
    resolve_jira_issue(merge_branches, comment, jira_id)
  File ""kafka-merge-pr.py"", line 285, in resolve_jira_issue
    (major, minor, patch) = v.split(""."")
ValueError: too many values to unpack
{code}

We need to handle 3 and 4 part versions (x.y.z and x.y.z.w)",,githubbot,gwenshap,ijuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2563,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Sep 24 17:31:41 UTC 2015,,,,,,,,,,"0|i2k5rz:",9223372036854775807,,guozhang,,,,,,,,,,,,,,,,,,"25/Sep/15 00:47;ijuma;Issue resolved by pull request 6
[https://github.com/ijuma/kafka/pull/6];;;","25/Sep/15 00:47;ijuma;I was just testing the fix to the script.;;;","25/Sep/15 00:55;githubbot;GitHub user ijuma opened a pull request:

    https://github.com/apache/kafka/pull/238

    KAFKA-2548; kafka-merge-pr tool fails to update JIRA with fix version 0.9.0.0

    Simplified the logic to choose the default fix version. We just hardcode
    it for `trunk` and try to compute it based on the branch name for the
    rest.
    
    Removed logic that tries to handle forked release branches as it
    seems to be specific to how the Spark project handles their JIRA.

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ijuma/kafka kafka-2548-merge-pr-tool-4-segment-fix-version

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/238.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #238
    
----
commit a2e6787f923fffb092d7f4c880923c501d2a9b9f
Author: Ismael Juma <ismael@juma.me.uk>
Date:   2015-09-24T16:43:14Z

    Don't fail on fix versions with 4 segments
    
    Simplified the logic to choose the default fix version. We just hardcode
    it for `trunk` and try to compute it based on the branch name for the
    rest.
    
    Removed logic that tries to handle forked release branches as it
    seems to be specific to how the Spark project handles their JIRA.

----
;;;","25/Sep/15 01:31;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/238
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cleanup logging in new producer,KAFKA-1302,12701011,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,junrao,junrao,13/Mar/14 00:29,04/Apr/14 00:15,22/Mar/23 15:10,14/Mar/14 05:27,0.8.2.0,,,,,,0.8.2.0,,,,,,,core,,,,0,,,,,,"1. When we hit an error in producer, we call the callback with a null RecordMetadata. If the callback tries to get the topic/partition, it will hit a NullPointerException. It's probably better to create a RecordMetadata with -1 as the offset.
2. When printing out a Struct, we don't print out the content wrapped in an array properly. So, we will see sth like the following.
[2014-03-09 11:56:24,364] INFO Created 1 requests: [InFlightRequest(expectResponse=true, batches={test-0=RecordBatch(topicPartition=test-0, recordCount=1)}, request=RequestSend(header={api_key=0,api_version=0,correlation_id=1,client_id=perf-test}, body={acks=-1,timeout=3000,topic_data=[Ljava.lang.Object;@700a4488}))] (org.apache.kafka.clients.producer.internals.Sender)
3. Need to override the toString() in ProduceResponse.
4. Sender.run(now): It would be good to log metadata request too.
5. Sender.handleDisconnects(): It would be useful to log the correlation id of cancelled inflight requests
",,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1296,,,,,,,,,,,,,,,,"13/Mar/14 00:31;junrao;KAFKA-1302.patch;https://issues.apache.org/jira/secure/attachment/12634199/KAFKA-1302.patch","14/Mar/14 02:00;junrao;KAFKA-1302_2014-03-13_11:00:33.patch;https://issues.apache.org/jira/secure/attachment/12634497/KAFKA-1302_2014-03-13_11%3A00%3A33.patch",,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,379357,,,Thu Mar 13 21:27:16 UTC 2014,,,,,,,,,,"0|i1td6f:",379648,,,,,,,,,,,,,,,,,,,,"13/Mar/14 00:31;junrao;Created reviewboard https://reviews.apache.org/r/19132/
 against branch origin/trunk;;;","14/Mar/14 02:00;junrao;Updated reviewboard https://reviews.apache.org/r/19132/
 against branch origin/trunk;;;","14/Mar/14 05:27;junrao;Thanks for the reviews. Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Messages is a required argument to Producer Performance Test,KAFKA-1517,12725168,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Trivial,Fixed,danielcompton,danielcompton,danielcompton,03/Jul/14 11:22,08/Apr/15 13:20,22/Mar/23 15:10,08/Apr/15 13:20,0.8.1.1,,,,,,0.9.0.0,,,,,,,,,,,0,newbie,,,,,"When running the producer performance test without providing a messages argument, you get an error:

{noformat}
$bin/kafka-producer-perf-test.sh --topics mirrormirror --broker-list kafka-dc21:9092
Missing required argument ""[messages]""

Option                                  Description
------                                  -----------
......
--messages <Long: count>                The number of messages to send or
                                          consume (default:
                                          9223372036854775807)
{noformat}

However the [shell command documentation|https://github.com/apache/kafka/blob/c66e408b244de52f1c5c5bbd7627aa1f028f9a87/perf/src/main/scala/kafka/perf/PerfConfig.scala#L25] doesn't say that this is required and implies that [2^63-1|http://en.wikipedia.org/wiki/9223372036854775807] (Long.MaxValue) messages will be sent. It should probably look like the [ConsoleProducer|https://github.com/apache/kafka/blob/c66e408b244de52f1c5c5bbd7627aa1f028f9a87/core/src/main/scala/kafka/producer/ConsoleProducer.scala#L32] and prefix the documentation with REQUIRED. Or should we make this a non-required argument and set the default value to something sane like 100,000 messages.

Which option is preferable for this?",,danielcompton,junrao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jul/14 09:14;danielcompton;0001-KAFKA-1517-Make-messages-a-required-argument.patch;https://issues.apache.org/jira/secure/attachment/12657021/0001-KAFKA-1517-Make-messages-a-required-argument.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,403351,,,Wed Apr 08 05:20:21 UTC 2015,,,,,,,,,,"0|i1xf7b:",403402,,,,,,,,,,,,,,,,,,,,"06/Jul/14 23:52;junrao;Yes, I think it would be better if we document it as required and get rid of the default.;;;","07/Jul/14 07:20;danielcompton;Great, I'll prepare a patch, documenting it as mandatory and removing the default value.;;;","22/Jul/14 09:15;danielcompton;I've attached a patch for this. Let me know if the patch isn't correct, I wasn't sure I was doing it correctly.;;;","08/Apr/15 13:20;junrao;Sorry for the late review. +1 and committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
scheduler exception on non-controller node when shutdown,KAFKA-2283,12838488,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,nehanarkhede,allenlz,allenlz,17/Jun/15 22:42,16/Aug/17 02:36,22/Mar/23 15:10,16/Aug/17 02:36,0.8.2.1,,,,,,,,,,,,,controller,,,,1,,,,,,"When broker shutdown, there is an error log about 'Kafka scheduler has not been started'.
It only appears on non-controller node. If this broker is the controller, it shutdown without warning log.

IMHO, *autoRebalanceScheduler.shutdown()* should only valid for controller, right?

{quote}
[2015-06-17 22:32:51,814] INFO Shutdown complete. (kafka.log.LogManager)
[2015-06-17 22:32:51,815] WARN Kafka scheduler has not been started (kafka.utils.Utils$)
java.lang.IllegalStateException: Kafka scheduler has not been started
        at kafka.utils.KafkaScheduler.ensureStarted(KafkaScheduler.scala:114)
        at kafka.utils.KafkaScheduler.shutdown(KafkaScheduler.scala:86)
        at kafka.controller.KafkaController.onControllerResignation(KafkaController.scala:350)
        at kafka.controller.KafkaController.shutdown(KafkaController.scala:664)
        at kafka.server.KafkaServer$$anonfun$shutdown$8.apply$mcV$sp(KafkaServer.scala:285)
        at kafka.utils.Utils$.swallow(Utils.scala:172)
        at kafka.utils.Logging$class.swallowWarn(Logging.scala:92)
        at kafka.utils.Utils$.swallowWarn(Utils.scala:45)
        at kafka.utils.Logging$class.swallow(Logging.scala:94)
        at kafka.utils.Utils$.swallow(Utils.scala:45)
        at kafka.server.KafkaServer.shutdown(KafkaServer.scala:285)
        at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:42)
        at kafka.Kafka$$anon$1.run(Kafka.scala:42)
[2015-06-17 22:32:51,818] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
{quote}
",linux debian,allenlz,bobrik,omkreddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jun 19 07:52:21 UTC 2015,,,,,,,,,,"0|i2g5p3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"19/Jun/15 15:52;omkreddy;looks like this got fixed in trunk  build.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Space in the value for ""host.name"" causes ""Unresolved address""",KAFKA-3050,12924936,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,nmarkandeya,nmarkandeya,31/Dec/15 03:23,26/Feb/18 05:35,22/Mar/23 15:10,18/Apr/16 14:52,0.8.2.1,,,,,,0.9.0.0,,,,,,,,,,,1,newbie,,,,,"In {{<KAFKA_HOME>/config/server.properties}},  after updating the {{host.name}}  to a value with a space after ""localhost"", received

{code}
[2015-12-30 11:13:43,014] FATAL Fatal error during KafkaServerStartable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
kafka.common.KafkaException: Socket server failed to bind to localhost :9092: Unresolved address.
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:260)
	at kafka.network.Acceptor.<init>(SocketServer.scala:205)
	at kafka.network.SocketServer.startup(SocketServer.scala:86)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:99)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:46)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.net.SocketException: Unresolved address
	at sun.nio.ch.Net.translateToSocketException(Net.java:131)
	at sun.nio.ch.Net.translateException(Net.java:157)
	at sun.nio.ch.Net.translateException(Net.java:163)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:76)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:256)
	... 6 more
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:218)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	... 8 more
{code}

 I am running {{kafka_2.9.1-0.8.2.2}} on Centos6.5 with Java8
{code}
java version ""1.8.0_60""
Java(TM) SE Runtime Environment (build 1.8.0_60-b27)
Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode)
{code}
",,alwindoss,githubbot,ijuma,nmarkandeya,omkreddy,Zixxy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Sun Feb 25 21:35:31 UTC 2018,,,,,,,,,,"0|i2qez3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"04/Jan/16 22:53;ijuma;Thanks for the report. To be clear, are you requesting that we trim empty spaces after the config value before using it?;;;","05/Jan/16 23:07;nmarkandeya;[~ijuma] Yes.;;;","15/Jan/16 05:19;githubbot;GitHub user Zixxy opened a pull request:

    https://github.com/apache/kafka/pull/777

    KAFKA-3050: Acceptor allows hostnames surrounded by whitespaces

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/Zixxy/kafka trunk

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/777.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #777
    
----
commit 48321d4bb9d0490c3cbb993069b7349013fd42e5
Author: Zixxy <sylwekklocek@gmail.com>
Date:   2016-01-14T21:13:27Z

    KAFKA-3050: Acceptor allows hostnames surrounded by whitespaces

----
;;;","15/Jan/16 21:11;Zixxy;Does this issue have sense? Master currently trims host.name. ;;;","18/Apr/16 14:52;omkreddy;This got fixed in 0.9.0.0 release;;;","26/Feb/18 05:35;githubbot;hachikuji closed pull request #777: KAFKA-3050: Acceptor allows hostnames surrounded by whitespaces
URL: https://github.com/apache/kafka/pull/777
 
 
   

This is a PR merged from a forked repository.
As GitHub hides the original diff on merge, it is displayed below for
the sake of provenance:

As this is a foreign pull request (from a fork), the diff is supplied
below (as it won't show otherwise due to GitHub magic):

diff --git a/core/src/main/scala/kafka/network/SocketServer.scala b/core/src/main/scala/kafka/network/SocketServer.scala
index c3ecd750c21..3f876441744 100644
--- a/core/src/main/scala/kafka/network/SocketServer.scala
+++ b/core/src/main/scala/kafka/network/SocketServer.scala
@@ -297,7 +297,7 @@ private[kafka] class Acceptor(val endPoint: EndPoint,
       if(host == null || host.trim.isEmpty)
         new InetSocketAddress(port)
       else
-        new InetSocketAddress(host, port)
+        new InetSocketAddress(host.trim, port)
     val serverChannel = ServerSocketChannel.open()
     serverChannel.configureBlocking(false)
     serverChannel.socket().setReceiveBufferSize(recvBufferSize)


 

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Processor thread dies due to an uncaught NoSuchElementException,KAFKA-2595,12901130,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,shaun.senecal@lithium.com,shaun.senecal@lithium.com,29/Sep/15 04:14,08/Sep/17 03:32,22/Mar/23 15:10,08/Sep/17 03:32,0.8.2.0,,,,,,,,,,,,,,,,,0,,,,,,"We are getting uncaught exceptions which seem to kill the processor threads.  The end result is that we end up with a bunch of connections in CLOSE_WAIT and eventually the broker is unable to respond or hits the max open files ulimit.

{noformat}
[2015-09-23 09:54:33,687] ERROR Uncaught exception in thread 'kafka-network-thread-9092-2': (kafka.utils.Utils$)
java.util.NoSuchElementException: None.get
        at scala.None$.get(Option.scala:347)
        at scala.None$.get(Option.scala:345)
        at kafka.network.ConnectionQuotas.dec(SocketServer.scala:524)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:165)
        at kafka.network.AbstractServerThread.close(SocketServer.scala:157)
        at kafka.network.Processor.close(SocketServer.scala:374)
        at kafka.network.Processor.processNewResponses(SocketServer.scala:406)
        at kafka.network.Processor.run(SocketServer.scala:318)
        at java.lang.Thread.run(Thread.java:745)
{noformat}

The issue appears to be the same as KAFKA-1577, except that its not happening during shutdown.  We haven't been able to isolate when this happens, so we dont have a good way to reproduce the issue.

It also looks like KAFKA-2353 would work around the issue if it could be back-ported, but the root cause should probably be fixed as well.

- java version: 1.7.0_65
- kafka version: 0.8.2.0
- topics: 366
- partitions: ~550 (a few 20 partition topics, and a bunch of 1 partition topics)
",,omkreddy,shaun.senecal@lithium.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-1804,,,,,,,,,,,,,,,,,,"29/Sep/15 04:15;shaun.senecal@lithium.com;server.log.2015-09-23-09.gz;https://issues.apache.org/jira/secure/attachment/12764087/server.log.2015-09-23-09.gz",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Sep 07 19:32:28 UTC 2017,,,,,,,,,,"0|i2mdiv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"29/Sep/15 04:15;shaun.senecal@lithium.com;Server logs for the day which appears to have caused the processor thread to die;;;","08/Sep/17 03:32;omkreddy;See the discussion in KAFKA-1804;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
System tests: update benchmark tests to run with new and old consumer,KAFKA-2489,12860351,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,granders,granders,granders,29/Aug/15 01:59,09/Sep/15 09:00,22/Mar/23 15:10,09/Sep/15 09:00,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"Update benchmark tests to run w/new consumer to help catch performance regressions

For context:

https://www.mail-archive.com/dev@kafka.apache.org/msg33633.html
The new consumer was previously reaching getting good performance. However, a 
recent report on the mailing list indicates it's dropped significantly. After 
evaluation, even with a local broker it seems to only be reaching a 2-10MB/s, 
compared to 600+MB/s previously. Before release, we should get the performance 
back on par.

Some details about where the regression occurred from the mailing list 
http://mail-archives.apache.org/mod_mbox/kafka-dev/201508.mbox/%3CCAAdKFaE8bPSeWZf%2BF9RuA-xZazRpBrZG6vo454QLVHBAk_VOJg%40mail.gmail.com%3E
 :

bq. At 49026f11781181c38e9d5edb634be9d27245c961 (May 14th), we went from good 
performance -> an error due to broker apparently not accepting the partition 
assignment strategy. Since this commit seems to add heartbeats and the server 
side code for partition assignment strategies, I assume we were missing 
something on the client side and by filling in the server side, things stopped 
working.
bq. On either 84636272422b6379d57d4c5ef68b156edc1c67f8 or 
a5b11886df8c7aad0548efd2c7c3dbc579232f03 (July 17th), I am able to run the perf 
test again, but it's slow -- ~10MB/s for me vs the 2MB/s Jay was seeing, but 
that's still far less than the 600MB/s I saw on the earlier commits.

Ideally we would also at least have a system test in place for the new 
consumer, even if regressions weren't automatically detected. It would at least 
allow for manually checking for regressions. This should not be difficult since 
there are already old consumer performance tests.
",,githubbot,granders,gwenshap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Sep 09 01:00:56 UTC 2015,,,,,,,,,,"0|i2jjlj:",9223372036854775807,,gwenshap,,,,,,,,,,,,,,,,,,"30/Aug/15 00:50;githubbot;GitHub user granders opened a pull request:

    https://github.com/apache/kafka/pull/179

    KAFKA-2489: add benchmark for new consumer

    @ewencp 
    The changes here are smaller than they look - mostly refactoring/cleanup.
    
    - ConsumerPerformance.scala - corrected timeout inequality which had prevented this from working with new consumer
    - ConsumerPerformanceService: added new_consumer flag, and exposed more command-line settings
    - benchmark.py: refactored to use `@parametrize` and `@matrix` - this reduced some amount of repeated code
    - benchmark.py: added consumer performance tests with new consumer (using `@parametrize`)
    - benchmark.py: added more detailed test descriptions
    - performance.py: broke into separate files 
    


You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/confluentinc/kafka KAFKA-2489-benchmark-new-consumer

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/179.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #179
    
----
commit 6525594e2c4803f85403f260ddcb18ff5ae6c0a0
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-08-29T05:24:29Z

    Fixed typo in ProducerPerformance.java

commit fa5f81094215a69f00076cc2a07c2e3d19f9a34f
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-08-29T05:25:53Z

    Fixed ConsumerPerformance.scala with new consumer: incorrect inequality previously caused this to time out without consuming any messages with new consumer.

commit 45b31f3d5f7a2ae6d4d27737012495cc8ad1c70d
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-08-29T05:28:57Z

    Updated consumer throughput tests to run with new and old consumer. Refactored with @parametrize and @matrix to reduce duplicated code.

commit f4d837330fdda2bc7918b97e740ba91a9d456462
Author: Geoff Anderson <geoff@confluent.io>
Date:   2015-08-29T05:30:37Z

    Refactored performance.py - broke services into individual files. This does not change the way external users would import and use the performance services however.

----
;;;","09/Sep/15 09:00;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/179
;;;","09/Sep/15 09:00;gwenshap;Issue resolved by pull request 179
[https://github.com/apache/kafka/pull/179];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Producer perf test fails against localhost with > 10 threads,KAFKA-88,12518225,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,jkreps,jkreps,jkreps,09/Aug/11 01:36,09/Aug/11 03:09,22/Mar/23 15:10,09/Aug/11 02:44,0.6,,,,,,0.7,,,,,,,config,,,,0,,,,,,"The perf test starts producing errors when it is run with --threads 11 (or higher). The cause is that we create a zookeeper connection per thread, and zookeeper recently added a feature which limits the number of connections per ip in ZOOKEEPER-336. This setting is set to 10 by default. I recommend we bump this up in our packaged zk config, since it is hard to figure this out and makes it look like the client itself is having issues.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Aug/11 01:37;jkreps;zk-config.diff;https://issues.apache.org/jira/secure/attachment/12489715/zk-config.diff",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,65727,,,Mon Aug 08 19:09:58 UTC 2011,,,,,,,,,,"0|i15yvj:",242950,,,,,,,,,,,,,,,,,,,,"09/Aug/11 01:37;jkreps;Change zk config to allow unlimited connections.;;;","09/Aug/11 02:28;junrao;Thanks, Jay. Looks good. Just committed this.;;;","09/Aug/11 03:06;cburroughs;Is this a zk conn per thead only for perf code,  Or do the producers/consumers do this?;;;","09/Aug/11 03:09;jkreps;There is effectively one producer per test thread, this is good as it is more realistic i think.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ClosedByInterruptException when high-level consumer shutdown normally,KAFKA-900,12646752,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,jbrosenberg,jbrosenberg,09/May/13 13:21,30/May/13 00:56,22/Mar/23 15:10,30/May/13 00:56,0.8.0,,,,,,0.8.0,,,,,,,consumer,,,,0,,,,,,"I'm porting some unit tests from 0.7.2 to 0.8.0. The test does the following, all embedded in the same java process: 

-- spins up a zk instance 
-- spins up a kafka server using a fresh log directory 
-- creates a producer and sends a message 
-- creates a high-level consumer and verifies that it can consume the message 
-- shuts down the consumer 
-- stops the kafka server 
-- stops zk 

The test seems to be working fine now, however, I consistently see the following exception, when the consumer connector is shutdown:

1699 [ConsumerFetcherThread-group1_square-1a7ac0.local-1368076598439-d66bb2eb-0-1946108683] WARN kafka.consumer.ConsumerFetcherThread  - [ConsumerFetcherThread-group1_square-1a7ac0.local-1368076598439-d66bb2eb-0-1946108683], Error in fetch Name: FetchRequest; Version: 0; CorrelationId: 1; ClientId: group1-ConsumerFetcherThread-group1_square-1a7ac0.local-1368076598439-d66bb2eb-0-1946108683; ReplicaId: -1; MaxWait: 100 ms; MinBytes: 1 bytes; RequestInfo: [test-topic,0] -> PartitionFetchInfo(1,1048576)
java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:543)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.consumer.SimpleConsumer.connect(SimpleConsumer.scala:47)
	at kafka.consumer.SimpleConsumer.reconnect(SimpleConsumer.scala:60)
	at kafka.consumer.SimpleConsumer.liftedTree1$1(SimpleConsumer.scala:81)
	at kafka.consumer.SimpleConsumer.kafka$consumer$SimpleConsumer$$sendRequest(SimpleConsumer.scala:73)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(SimpleConsumer.scala:112)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:112)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:112)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply$mcV$sp(SimpleConsumer.scala:111)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:111)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:111)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.consumer.SimpleConsumer.fetch(SimpleConsumer.scala:110)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:96)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:88)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)
1721 [Thread-12] INFO com.squareup.kafka.server.KafkaServer  - Shutting down KafkaServer
2030 [main] INFO com.squareup.kafka.server.KafkaServer  - Shut down complete for KafkaServer
Disconnected from the target VM, address: '127.0.0.1:49243', transport: 'socket'


It would be great if instead, something meaningful was logged, like:

""Consumer connector has been shutdown""",,jbrosenberg,jbrosenberg@gmail.com,junrao,nehanarkhede,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/May/13 00:35;junrao;kafka-900.patch;https://issues.apache.org/jira/secure/attachment/12582491/kafka-900.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,327110,,,Wed May 29 16:56:58 UTC 2013,,,,,,,,,,"0|i1kfu7:",327454,,,,,,,,,,,,,,,,,,,,"10/May/13 00:35;junrao;Attach a patch. Jason, could you give it a try?;;;","30/May/13 00:39;nehanarkhede;+1, thanks for the patch!;;;","30/May/13 00:56;junrao;Thanks for the review. Committed to 0.8.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Round robin consumer balance throws an NPE when there are no topics,KAFKA-1648,12743567,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,mgharat,toddpalino,toddpalino,24/Sep/14 02:11,15/Nov/14 03:15,22/Mar/23 15:10,10/Oct/14 07:36,,,,,,,0.9.0.0,,,,,,,consumer,,,,0,newbie,,,,,"If you use the roundrobin rebalance method with a wildcard consumer, and there are no topics in the cluster, rebalance throws a NullPointerException in the consumer and fails. It retries the rebalance, but will continue to throw the NPE.

2014/09/23 17:51:16.147 [ZookeeperConsumerConnector] [kafka-audit_lva1-app0007.corp-1411494404908-4e620544], Cleared all relevant queues for this fetcher
2014/09/23 17:51:16.147 [ZookeeperConsumerConnector] [kafka-audit_lva1-app0007.corp-1411494404908-4e620544], Cleared the data chunks in all the consumer message iterators
2014/09/23 17:51:16.148 [ZookeeperConsumerConnector] [kafka-audit_lva1-app0007.corp-1411494404908-4e620544], Committing all offsets after clearing the fetcher queues
2014/09/23 17:51:46.148 [ZookeeperConsumerConnector] [kafka-audit_lva1-app0007.corp-1411494404908-4e620544], begin rebalancing consumer kafka-audit_lva1-app0007.corp-1411494404908-4e620544 try #0
2014/09/23 17:51:46.148 ERROR [OffspringServletRuntime] [main] [kafka-console-audit] [] Boot listener com.linkedin.kafkaconsoleaudit.KafkaConsoleAuditBootListener failed
kafka.common.ConsumerRebalanceFailedException: kafka-audit_lva1-app0007.corp-1411494404908-4e620544 can't rebalance after 10 retries
	at kafka.consumer.ZookeeperConsumerConnector$ZKRebalancerListener.syncedRebalance(ZookeeperConsumerConnector.scala:630)
	at kafka.consumer.ZookeeperConsumerConnector.kafka$consumer$ZookeeperConsumerConnector$$reinitializeConsumer(ZookeeperConsumerConnector.scala:897)
	at kafka.consumer.ZookeeperConsumerConnector$WildcardStreamsHandler.<init>(ZookeeperConsumerConnector.scala:931)
	at kafka.consumer.ZookeeperConsumerConnector.createMessageStreamsByFilter(ZookeeperConsumerConnector.scala:159)
	at kafka.javaapi.consumer.ZookeeperConsumerConnector.createMessageStreamsByFilter(ZookeeperConsumerConnector.scala:101)
	at com.linkedin.tracker.consumer.TrackingConsumerImpl.initWildcardIterators(TrackingConsumerImpl.java:88)
	at com.linkedin.tracker.consumer.TrackingConsumerImpl.getWildcardIterators(TrackingConsumerImpl.java:116)
	at com.linkedin.kafkaconsoleaudit.KafkaConsoleAudit.createAuditThreads(KafkaConsoleAudit.java:59)
	at com.linkedin.kafkaconsoleaudit.KafkaConsoleAudit.initializeAudit(KafkaConsoleAudit.java:50)
	at com.linkedin.kafkaconsoleaudit.KafkaConsoleAuditFactory.createInstance(KafkaConsoleAuditFactory.java:125)
	at com.linkedin.kafkaconsoleaudit.KafkaConsoleAuditFactory.createInstance(KafkaConsoleAuditFactory.java:20)
	at com.linkedin.util.factory.SimpleSingletonFactory.createInstance(SimpleSingletonFactory.java:20)
	at com.linkedin.util.factory.SimpleSingletonFactory.createInstance(SimpleSingletonFactory.java:14)
	at com.linkedin.util.factory.Generator.doGetBean(Generator.java:337)
	at com.linkedin.util.factory.Generator.getBean(Generator.java:270)
	at com.linkedin.kafkaconsoleaudit.KafkaConsoleAuditBootListener.onBoot(KafkaConsoleAuditBootListener.java:16)
	at com.linkedin.offspring.servlet.OffspringServletRuntime.startGenerator(OffspringServletRuntime.java:147)
	at com.linkedin.offspring.servlet.OffspringServletRuntime.start(OffspringServletRuntime.java:73)
	at com.linkedin.offspring.servlet.OffspringServletContextListener.contextInitialized(OffspringServletContextListener.java:28)
	at org.eclipse.jetty.server.handler.ContextHandler.callContextInitialized(ContextHandler.java:771)
	at org.eclipse.jetty.servlet.ServletContextHandler.callContextInitialized(ServletContextHandler.java:424)
	at org.eclipse.jetty.server.handler.ContextHandler.startContext(ContextHandler.java:763)
	at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:249)
	at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1250)
	at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:706)
	at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:492)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at com.linkedin.emweb.ContextBasedHandlerImpl.doStart(ContextBasedHandlerImpl.java:105)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at com.linkedin.emweb.WebappDeployerImpl.start(WebappDeployerImpl.java:333)
	at com.linkedin.emweb.WebappDeployerImpl.deploy(WebappDeployerImpl.java:187)
	at com.linkedin.emweb.StateKeeperWebappDeployer.deploy(StateKeeperWebappDeployer.java:75)
	at com.linkedin.emweb.StateKeeperWebappDeployer.restore(StateKeeperWebappDeployer.java:62)
	at com.linkedin.emweb.WebappRunner.restoreServerState(WebappRunner.java:171)
	at com.linkedin.emweb.BaseRunner.start(BaseRunner.java:96)
	at com.linkedin.spring.cmdline.ServerCmdLineApp.start(ServerCmdLineApp.java:86)
	at com.linkedin.spring.cmdline.ServerCmdLineApp.doRun(ServerCmdLineApp.java:102)
	at com.linkedin.spring.cmdline.CmdLineAppRunner.run(CmdLineAppRunner.java:246)
	at com.linkedin.spring.cmdline.CmdLineAppRunner.main(CmdLineAppRunner.java:480)

(note - the com.linkedin stuff in the stack trace is from the container we run our applications in and does not affect the operation of the rebalance)",,jjkoshy,mgharat,nehanarkhede,toddpalino,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Oct/14 06:43;mgharat;KAFKA-1648.patch;https://issues.apache.org/jira/secure/attachment/12672671/KAFKA-1648.patch","05/Oct/14 08:40;mgharat;KAFKA-1648_2014-10-04_17:40:47.patch;https://issues.apache.org/jira/secure/attachment/12672963/KAFKA-1648_2014-10-04_17%3A40%3A47.patch","09/Oct/14 08:29;mgharat;KAFKA-1648_2014-10-08_17:29:14.patch;https://issues.apache.org/jira/secure/attachment/12673782/KAFKA-1648_2014-10-08_17%3A29%3A14.patch","09/Oct/14 08:46;mgharat;KAFKA-1648_2014-10-08_17:46:45.patch;https://issues.apache.org/jira/secure/attachment/12673788/KAFKA-1648_2014-10-08_17%3A46%3A45.patch","10/Oct/14 02:56;mgharat;KAFKA-1648_2014-10-09_11:56:44.patch;https://issues.apache.org/jira/secure/attachment/12673960/KAFKA-1648_2014-10-09_11%3A56%3A44.patch",,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Oct 09 23:36:50 UTC 2014,,,,,,,,,,"0|i20egn:",9223372036854775807,,jjkoshy,,,,,,,,,,,,,,,,,,"25/Sep/14 13:02;nehanarkhede;Assigning this to Joel for review as he probably has the most context on this feature;;;","03/Oct/14 06:43;mgharat;Created reviewboard https://reviews.apache.org/r/26291/diff/
 against branch origin/trunk;;;","05/Oct/14 08:41;mgharat;Updated reviewboard https://reviews.apache.org/r/26291/diff/
 against branch origin/trunk;;;","09/Oct/14 08:29;mgharat;Updated reviewboard https://reviews.apache.org/r/26291/diff/
 against branch origin/trunk;;;","09/Oct/14 08:46;mgharat;Updated reviewboard https://reviews.apache.org/r/26291/diff/
 against branch origin/trunk;;;","10/Oct/14 02:56;mgharat;Updated reviewboard https://reviews.apache.org/r/26291/diff/
 against branch origin/trunk;;;","10/Oct/14 07:36;jjkoshy;Committed to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Forwarding task reconfigurations in Copycat can deadlock with rebalances and has no backoff,KAFKA-2743,12910449,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,ewencp,ewencp,ewencp,05/Nov/15 03:24,06/Nov/15 00:44,22/Mar/23 15:10,06/Nov/15 00:44,,,,,,,0.9.0.0,,,,,,,KafkaConnect,,,,0,,,,,,"There are two issues with the way we're currently forwarding task reconfigurations. First, the forwarding is performed synchronously in the DistributedHerder's main processing loop. If node A forwards a task reconfiguration and node B has started a rebalance process, we can end up with distributed deadlock because node A will be blocking on the HTTP request in the thread that would otherwise handle heartbeating and rebalancing.

Second, currently we just retry aggressively with no backoff. In some cases the node that is currently thought to be the leader will legitimately be down (it shutdown and the node sending the request didn't rebalance yet), so we need some backoff to avoid unnecessarily hammering the network and the huge log files that result from constant errors.",,ewencp,githubbot,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Thu Nov 05 16:44:27 UTC 2015,,,,,,,,,,"0|i2nygv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"05/Nov/15 03:33;githubbot;GitHub user ewencp opened a pull request:

    https://github.com/apache/kafka/pull/422

    KAFKA-2743: Make forwarded task reconfiguration requests asynchronous, run on a separate thread, and backoff before retrying when they fail.

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/ewencp/kafka task-reconfiguration-async-with-backoff

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/422.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #422
    
----
commit 8a30a78b9222ed8fec5143a41db5cf8e6e9efbc7
Author: Ewen Cheslack-Postava <me@ewencp.org>
Date:   2015-11-03T05:30:32Z

    KAFKA-2743: Make forwarded task reconfiguration requests asynchronous, run on a separate thread, and backoff before retrying when they fail.

----
;;;","06/Nov/15 00:44;guozhang;Issue resolved by pull request 422
[https://github.com/apache/kafka/pull/422];;;","06/Nov/15 00:44;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/422
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade LZ4 to version 1.3 to avoid crashing with IBM Java 7,KAFKA-2421,12854175,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,granthenke,rsivaram,rsivaram,11/Aug/15 22:51,02/Dec/15 03:59,22/Mar/23 15:10,02/Dec/15 03:59,0.8.2.1,,,,,,0.10.0.0,,,,,,,,,,,1,,,,,,"Upgrade LZ4 to version 1.3 to avoid crashing with IBM Java 7.

LZ4 version 1.2 crashes with 64-bit IBM Java 7. This has been fixed in LZ4 version 1.3 (https://github.com/jpountz/lz4-java/blob/master/CHANGES.md, https://github.com/jpountz/lz4-java/pull/46).


The unit test org.apache.kafka.common.record.MemoryRecordsTest crashes when run with 64-bit IBM Java7 with the error:

{quote}
00000000023EB900: Native Method 000000000263CE10 (net/jpountz/lz4/LZ4JNI.LZ4_compress_limitedOutput([BII[BII)I)
00000000023EB900: Invalid JNI call of function void ReleasePrimitiveArrayCritical(JNIEnv *env, jarray array, void *carray, jint mode): For array 00000000FFF7EAB8 parameter carray passed 00000000FFF85998, expected to be 00000000FFF7EAC0
14:08:42.763 0x23eb900    j9mm.632    *   ** ASSERTION FAILED ** at StandardAccessBarrier.cpp:335: ((false))
JVMDUMP039I Processing dump event ""traceassert"", detail """" at 2015/08/11 15:08:42 - please wait.
{quote}

Stack trace from javacore:

3XMTHREADINFO3           Java callstack:
4XESTACKTRACE                at net/jpountz/lz4/LZ4JNI.LZ4_compress_limitedOutput(Native Method)
4XESTACKTRACE                at net/jpountz/lz4/LZ4JNICompressor.compress(LZ4JNICompressor.java:31)
4XESTACKTRACE                at net/jpountz/lz4/LZ4Factory.<init>(LZ4Factory.java:163)
4XESTACKTRACE                at net/jpountz/lz4/LZ4Factory.instance(LZ4Factory.java:46)
4XESTACKTRACE                at net/jpountz/lz4/LZ4Factory.nativeInstance(LZ4Factory.java:76)
5XESTACKTRACE                   (entered lock: net/jpountz/lz4/LZ4Factory@0x00000000E02F0BE8, entry count: 1)
4XESTACKTRACE                at net/jpountz/lz4/LZ4Factory.fastestInstance(LZ4Factory.java:129)
4XESTACKTRACE                at org/apache/kafka/common/record/KafkaLZ4BlockOutputStream.<init>(KafkaLZ4BlockOutputStream.java:72)
4XESTACKTRACE                at org/apache/kafka/common/record/KafkaLZ4BlockOutputStream.<init>(KafkaLZ4BlockOutputStream.java:93)
4XESTACKTRACE                at org/apache/kafka/common/record/KafkaLZ4BlockOutputStream.<init>(KafkaLZ4BlockOutputStream.java:103)
4XESTACKTRACE                at sun/reflect/NativeConstructorAccessorImpl.newInstance0(Native Method)
4XESTACKTRACE                at sun/reflect/NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:86)
4XESTACKTRACE                at sun/reflect/DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:58)
4XESTACKTRACE                at java/lang/reflect/Constructor.newInstance(Constructor.java:542)
4XESTACKTRACE                at org/apache/kafka/common/record/Compressor.wrapForOutput(Compressor.java:222)
4XESTACKTRACE                at org/apache/kafka/common/record/Compressor.<init>(Compressor.java:72)
4XESTACKTRACE                at org/apache/kafka/common/record/Compressor.<init>(Compressor.java:76)
4XESTACKTRACE                at org/apache/kafka/common/record/MemoryRecords.<init>(MemoryRecords.java:43)
4XESTACKTRACE                at org/apache/kafka/common/record/MemoryRecords.emptyRecords(MemoryRecords.java:51)
4XESTACKTRACE                at org/apache/kafka/common/record/MemoryRecords.emptyRecords(MemoryRecords.java:55)
4XESTACKTRACE                at org/apache/kafka/common/record/MemoryRecordsTest.testIterator(MemoryRecordsTest.java:42)

java -version
java version ""1.7.0""
Java(TM) SE Runtime Environment (build pxa6470_27sr3fp1-20150605_01(SR3 FP1))
IBM J9 VM (build 2.7, JRE 1.7.0 Linux amd64-64 Compressed References 20150407_243189 (JIT enabled, AOT enabled)
J9VM - R27_Java727_SR3_20150407_1831_B243189
JIT  - tr.r13.java_20150406_89182
GC   - R27_Java727_SR3_20150407_1831_B243189_CMPRSS
J9CL - 20150407_243189)
JCL - 20150601_01 based on Oracle 7u79-b14",IBM Java 7,githubbot,junrao,rsivaram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Aug/15 23:17;rsivaram;KAFKA-2421.patch;https://issues.apache.org/jira/secure/attachment/12749873/KAFKA-2421.patch","12/Aug/15 02:56;rsivaram;KAFKA-2421_2015-08-11_18:54:26.patch;https://issues.apache.org/jira/secure/attachment/12749909/KAFKA-2421_2015-08-11_18%3A54%3A26.patch","08/Sep/15 19:38;rsivaram;kafka-2421_2015-09-08_11:38:03.patch;https://issues.apache.org/jira/secure/attachment/12754622/kafka-2421_2015-09-08_11%3A38%3A03.patch",,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Tue Dec 01 19:57:54 UTC 2015,,,,,,,,,,"0|i2il9z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"11/Aug/15 23:18;rsivaram;Created reviewboard https://reviews.apache.org/r/37357/diff/
 against branch origin/trunk;;;","11/Aug/15 23:27;rsivaram;Attached patch upgrades LZ4 to version 1.3 and fixes the reference to a method that was moved to a different class. Have tested that all unit tests work with IBM Java 7 with the changes.;;;","12/Aug/15 02:56;rsivaram;Updated reviewboard https://reviews.apache.org/r/37357/diff/
 against branch origin/trunk;;;","02/Sep/15 07:04;junrao;The patch no longer applies. Could you rebase?;;;","08/Sep/15 19:38;rsivaram;Updated reviewboard https://reviews.apache.org/r/37357/diff/
 against branch origin/trunk;;;","08/Sep/15 19:44;rsivaram;[~junrao] Sorry I was away for the last couple of weeks. The patch has been updated.;;;","19/Nov/15 00:01;granthenke;[~rsivaram] Do you mind if I finish this up? I would like to add a few unit tests related to compression size and get this merged. Its related to KAFKA-2800 which I have been working on.;;;","19/Nov/15 01:54;granthenke;[~rsivaram] I am going to send a PR for this today. I hope thats okay.;;;","19/Nov/15 01:59;githubbot;GitHub user granthenke opened a pull request:

    https://github.com/apache/kafka/pull/552

    KAFKA-2421: Upgrade LZ4 to version 1.3

    A few notes on the added test:
     * I verified this test fails when changing between snappy 1.1.1.2 and 1.1.1.7 (per KAFKA-2189)
     * The hard coded numbers are passing before and after lzo change

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/granthenke/kafka lz4

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/552.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #552
    
----
commit 0d6eb9948c18cdabdadcb7baa67c59fe0c8c51e2
Author: Grant Henke <granthenke@gmail.com>
Date:   2015-11-18T17:58:09Z

    KAFKA-2421: Upgrade LZ4 to version 1.3
    
    A few notes on the added test:
     * I verified this test fails when changing between snappy 1.1.1.2 and 1.1.1.7 (per KAFKA-2189)
     * The hard coded numbers are passing before and after lzo change

----
;;;","19/Nov/15 03:38;rsivaram;[~granthenke] Thank you for picking this up.;;;","02/Dec/15 03:57;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/552
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Zookeeper disconnects with ""can't find default realm"" message",KAFKA-3090,12929585,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,,mohitanchlia,mohitanchlia,13/Jan/16 04:10,15/Jul/16 18:09,22/Mar/23 15:10,14/Jan/16 04:08,,,,,,,,,,,,,,security,,,,0,,,,,,"Server disconnects from the zookeeper with the following log. It appears that it can't determine the realm even though the setup I performed looks ok.

In here find the list of principals, logs and Jaas file:

1) Jaas file 
KafkaServer {
    com.sun.security.auth.module.Krb5LoginModule required

    useKeyTab=true
    storeKey=true
    keyTab=""/mnt/kafka/kafka/kafka.keytab""
    principal=""kafka/10.24.251.175@EXAMPLE.COM"";
};

Client {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    storeKey=true
    keyTab=""/mnt/kafka/kafka/kafka.keytab""
    principal=""kafka/10.24.251.175@EXAMPLE.COM"";
};


2) Principles from krb admin

kadmin.local:  list_principals
K/M@EXAMPLE.COM
kadmin/admin@EXAMPLE.COM
kadmin/changepw@EXAMPLE.COM
kadmin/ip-10-24-251-175.us-west-2.compute.internal@EXAMPLE.COM
kafka/10.24.251.175@EXAMPLE.COM
krbtgt/EXAMPLE.COM@EXAMPLE.COM

3) [2016-01-12 14:53:13,132] WARN SASL configuration failed: javax.security.auth.login.LoginException: Cannot locate default realm Will continue connection to Zookeeper server without SASL authentication, if Zookeeper server allows it. (org.apache.zookeeper.ClientCnxn)
[2016-01-12 14:53:13,134] INFO Opening socket connection to server localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2016-01-12 14:53:13,134] INFO zookeeper state changed (AuthFailed) (org.I0Itec.zkclient.ZkClient)
[2016-01-12 14:53:13,139] INFO Accepted socket connection from /127.0.0.1:53028 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2016-01-12 14:53:13,139] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2016-01-12 14:53:13,142] INFO Client attempting to establish new session at /127.0.0.1:53028 (org.apache.zookeeper.server.ZooKeeperServer)
[2016-01-12 14:53:13,144] INFO Established session 0x152376012690001 with negotiated timeout 6000 for client /127.0.0.1:53028 (org.apache.zookeeper.server.ZooKeeperServer)
[2016-01-12 14:53:13,146] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x152376012690001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2016-01-12 14:53:13,146] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2016-01-12 14:53:19,087] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[2016-01-12 14:53:19,088] INFO Processed session termination for sessionid: 0x152376012690001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2016-01-12 14:53:19,089] INFO Session: 0x152376012690001 closed (org.apache.zookeeper.ZooKeeper)
[2016-01-12 14:53:19,089] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[2016-01-12 14:53:19,089] INFO Closed socket connection for client /127.0.0.1:53028 which had sessionid 0x152376012690001 (org.apache.zookeeper.server.NIOServerCnxn)
[2016-01-12 14:53:19,090] FATAL Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 6000
        at org.I0Itec.zkclient.ZkClient.connect(ZkClient.java:1223)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:155)
        at org.I0Itec.zkclient.ZkClient.<init>(ZkClient.java:129)
        at kafka.utils.ZkUtils$.createZkClientAndConnection(ZkUtils.scala:89)
        at kafka.utils.ZkUtils$.apply(ZkUtils.scala:71)
        at kafka.server.KafkaServer.initZk(KafkaServer.scala:278)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:168)
        at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
        at kafka.Kafka$.main(Kafka.scala:67)
        at kafka.Kafka.main(Kafka.scala)
",RHEL 6,ijuma,liuxinjian,mohitanchlia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-3102,,,,,,,,,,,,,,KAFKA-3102,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Fri Jul 15 10:00:03 UTC 2016,,,,,,,,,,"0|i2r793:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"14/Jan/16 02:00;mohitanchlia;I am following the documentation here:

http://docs.confluent.io/2.0.0/kafka/sasl.html
;;;","14/Jan/16 04:08;mohitanchlia;Fixed the krb5.conf file;;;","14/Jan/16 04:12;ijuma;Thanks for updating this Mohit. What was the issue with the krb5.conf file? It may help others facing similar issues.;;;","15/Jul/16 18:00;liuxinjian;Hi Mohit,
 what was the issue with the krb5.conf file?I am facing a similar issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Consumer Code documentation,KAFKA-52,12514689,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,,,,20/Jul/11 05:32,20/Jul/11 05:32,22/Mar/23 15:10,20/Jul/11 05:32,,,,,,,0.6,,,,,,,,,,,0,,,,,,"The example code for the ""Consumer Code"" section on http://sna-projects.com/kafka/quickstart.php seems to contain a couple of errors. 

Here's the working code: 

{code} 
// specify some consumer properties 
Properties props = new Properties(); 
props.put(""zk.connect"", ""localhost:2181""); 
props.put(""zk.connectiontimeout.ms"", ""1000000""); 
props.put(""groupid"", ""test_group""); 

// Create the connection to the cluster 
ConsumerConfig consumerConfig = new ConsumerConfig(props); 
ConsumerConnector consumerConnector = Consumer.create(consumerConfig); 

// create 4 partitions of the stream for topic ""test"", to allow 4 threads to consume 
Map<String, List<KafkaMessageStream>> topicMessageStreams = 
consumerConnector.createMessageStreams(ImmutableMap.of(""test"", 4)); 
// create list of 4 threads to consume from each of the partitions 
List<KafkaMessageStream> streams = topicMessageStreams.get(""test""); 
ExecutorService executor = Executors.newFixedThreadPool(4); 

// consume the messages in the threads 
for (final KafkaMessageStream stream : streams) { 
executor.submit(new Runnable() { 
//final KafkaMessageStream stream = topicStream.getValue(); 
public void run() { 
for (Message message : stream) { 
// process message 
} 
} 
}); 
} 
{code} 

It might also be worth specifying the imports: 

{code} 
import kafka.consumer.*; 
import kafka.message.Message; 

import java.util.Properties; 
import java.util.Map; 
import java.util.List; 
import java.util.concurrent.ExecutorService; 
import java.util.concurrent.Executors; 

import com.google.common.collect.ImmutableMap; 
{code}",web,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,300,300,,0%,300,300,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,67477,,,2011-07-19 21:32:23.0,,,,,,,,,,"0|i15ypb:",242922,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tooBigRequestIsRejected fails with unexpected Exceptoin,KAFKA-125,12520945,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Minor,Fixed,jkreps,cburroughs,cburroughs,01/Sep/11 01:04,04/Oct/11 04:12,22/Mar/23 15:10,04/Oct/11 04:12,0.7,,,,,,0.7,,,,,,,,,,,0,,,,,,"Commit: http://svn.apache.org/viewvc?view=revision&revision=1159837

[info] Test Starting: tooBigRequestIsRejected
[error] Test Failed: tooBigRequestIsRejected
java.lang.Exception: Unexpected exception, expected<java.io.EOFException> but was<java.net.SocketException>
	at org.junit.internal.runners.TestMethodRunner.runUnprotected(TestMethodRunner.java:91)
	at org.junit.internal.runners.BeforeAndAfterRunner.runProtected(BeforeAndAfterRunner.java:34)
	at org.junit.internal.runners.TestMethodRunner.runMethod(TestMethodRunner.java:75)
	at org.junit.internal.runners.TestMethodRunner.run(TestMethodRunner.java:45)
	at org.junit.internal.runners.TestClassMethodsRunner.invokeTestMethod(TestClassMethodsRunner.java:71)
	at org.junit.internal.runners.TestClassMethodsRunner.run(TestClassMethodsRunner.java:35)
	at org.junit.internal.runners.TestClassRunner$1.runUnprotected(TestClassRunner.java:42)
	at org.junit.internal.runners.BeforeAndAfterRunner.runProtected(BeforeAndAfterRunner.java:34)
	at org.junit.internal.runners.TestClassRunner.run(TestClassRunner.java:52)
	at org.junit.internal.runners.CompositeRunner.run(CompositeRunner.java:29)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:121)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:100)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:91)
	at org.scalatest.junit.JUnitSuite$class.run(JUnitSuite.scala:261)
	at kafka.network.SocketServerTest.run(SocketServerTest.scala:32)
	at org.scalatest.tools.ScalaTestFramework$ScalaTestRunner.run(ScalaTestFramework.scala:40)
	at sbt.TestRunner.run(TestFramework.scala:53)
	at sbt.TestRunner.runTest$1(TestFramework.scala:67)
	at sbt.TestRunner.run(TestFramework.scala:76)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11.runTest$2(TestFramework.scala:194)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)
	at sbt.NamedTestTask.run(TestFramework.scala:92)
	at sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)
	at sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)
	at sbt.TaskManager$Task.invoke(TaskManager.scala:62)
	at sbt.impl.RunTask.doRun$1(RunTask.scala:77)
	at sbt.impl.RunTask.runTask(RunTask.scala:85)
	at sbt.impl.RunTask.sbt$impl$RunTask$$runIfNotRoot(RunTask.scala:60)
	at sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)
	at sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)
	at sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)
	at sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)
	at sbt.Control$.trapUnit(Control.scala:19)
	at sbt.Distributor$Run$Worker.run(ParallelRunner.scala:131)
Caused by: java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:168)
	at java.net.SocketInputStream.read(SocketInputStream.java:182)
	at java.io.DataInputStream.readInt(DataInputStream.java:370)
	at kafka.network.SocketServerTest.sendRequest(SocketServerTest.scala:56)
	at kafka.network.SocketServerTest.tooBigRequestIsRejected(SocketServerTest.scala:78)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.internal.runners.TestMethodRunner.executeMethodBody(TestMethodRunner.java:99)
	at org.junit.internal.runners.TestMethodRunner.runUnprotected(TestMethodRunner.java:81)
	at org.junit.internal.runners.BeforeAndAfterRunner.runProtected(BeforeAndAfterRunner.java:34)
	at org.junit.internal.runners.TestMethodRunner.runMethod(TestMethodRunner.java:75)
	at org.junit.internal.runners.TestMethodRunner.run(TestMethodRunner.java:45)
	at org.junit.internal.runners.TestClassMethodsRunner.invokeTestMethod(TestClassMethodsRunner.java:71)
	at org.junit.internal.runners.TestClassMethodsRunner.run(TestClassMethodsRunner.java:35)
	at org.junit.internal.runners.TestClassRunner$1.runUnprotected(TestClassRunner.java:42)
	at org.junit.internal.runners.BeforeAndAfterRunner.runProtected(BeforeAndAfterRunner.java:34)
	at org.junit.internal.runners.TestClassRunner.run(TestClassRunner.java:52)
	at org.junit.internal.runners.CompositeRunner.run(CompositeRunner.java:29)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:121)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:100)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:91)
	at org.scalatest.junit.JUnitSuite$class.run(JUnitSuite.scala:261)
	at kafka.network.SocketServerTest.run(SocketServerTest.scala:32)
	at org.scalatest.tools.ScalaTestFramework$ScalaTestRunner.run(ScalaTestFramework.scala:40)
	at sbt.TestRunner.run(TestFramework.scala:53)
	at sbt.TestRunner.runTest$1(TestFramework.scala:67)
	at sbt.TestRunner.run(TestFramework.scala:76)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11.runTest$2(TestFramework.scala:194)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)
	at sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)
	at sbt.NamedTestTask.run(TestFramework.scala:92)
	at sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)
	at sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)
	at sbt.TaskManager$Task.invoke(TaskManager.scala:62)
	at sbt.impl.RunTask.doRun$1(RunTask.scala:77)
	at sbt.impl.RunTask.runTask(RunTask.scala:85)
	at sbt.impl.RunTask.sbt$impl$RunTask$$runIfNotRoot(RunTask.scala:60)
	at sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)
	at sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)
	at sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)
	at sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)
	at sbt.Control$.trapUnit(Control.scala:19)
	at sbt.Distributor$Run$Worker.run(ParallelRunner.scala:131)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Oct/11 12:34;jkreps;kafka-125.patch;https://issues.apache.org/jira/secure/attachment/12497423/kafka-125.patch",,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,41678,,,Mon Oct 03 04:51:29 UTC 2011,,,,,,,,,,"0|i15z1r:",242978,,,,,,,,,,,,,,,,,,,,"01/Oct/11 06:31;nehanarkhede;Jay,

We are getting ready to cut the first RC early next week. It would be good to fix this before the RC is published. Do you think that can happen ?

;;;","03/Oct/11 12:51;junrao;+1 for the patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Race condition causes Mirror Maker to hang during shutdown (new consumer),KAFKA-2770,12911259,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Blocker,Fixed,guozhang,granders,granders,07/Nov/15 09:19,11/Nov/15 11:18,22/Mar/23 15:10,11/Nov/15 11:18,,,,,,,0.9.0.0,,,,,,,,,,,0,,,,,,"I recently added clean bounce with new consumer to the mirror maker tests (https://github.com/apache/kafka/pull/427), and noticed that in this case the mirror maker process (with new consumer) sometimes hangs and fails to stop when stopped with kill -15

{code:title=mirror_maker.log|borderStyle=solid}
[2015-11-06 22:06:04,213] INFO Start clean shutdown. (kafka.tools.MirrorMaker$)
[2015-11-06 22:06:04,221] INFO Shutting down consumer threads. (kafka.tools.MirrorMaker$)
[2015-11-06 22:06:04,239] INFO [mirrormaker-thread-0] mirrormaker-thread-0 shutting down (kafka.tools.MirrorMaker$MirrorMakerThread)
[2015-11-06 22:06:04,253] INFO [mirrormaker-thread-0] Flushing producer. (kafka.tools.MirrorMaker$MirrorMakerThread)
[2015-11-06 22:06:04,254] INFO [mirrormaker-thread-0] Committing consumer offsets. (kafka.tools.MirrorMaker$MirrorMakerThread)
Exception in thread ""mirrormaker-thread-0"" org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:304)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:194)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:184)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:154)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:347)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:895)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:869)
	at kafka.tools.MirrorMaker$MirrorMakerNewConsumer.commit(MirrorMaker.scala:522)
	at kafka.tools.MirrorMaker$.commitOffsets(MirrorMaker.scala:338)
	at kafka.tools.MirrorMaker$MirrorMakerThread.run(MirrorMaker.scala:406)
[2015-11-06 22:06:29,448] DEBUG Connection with worker4/192.168.50.104 disconnected (org.apache.kafka.common.network.Selector)
java.io.EOFException
	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:83)
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:71)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:160)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:141)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:288)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:270)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:216)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:128)
	at java.lang.Thread.run(Thread.java:745)
{code}

The current working hypothesis is this:

a WakeupException is being triggered during the finally block in mirror maker by the call to commitOffsets, and the mirror maker thread dies before the call to shutdownLatch.countDown(). Therefore the shutdownLatch.await() call in awaitShutdown() blocks forever and the process never exits.

Why can commitOffsets trigger a wakeup exception?
The shutdown hook is triggered in another thread, and does this:
        shuttingDown = true
        mirrorMakerConsumer.stop()  # Calls consumer.wakeup()

If the timing is right (wrong), the wakeup flag is set, but the mirrormaker produce/consume loop exits without triggering the WakeupException, and the WakeupException isn't thrown until commitOffsets() is called in the finally block.


",,becket_qin,githubbot,granders,guozhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,KAFKA-2747,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,9223372036854775807,,,Wed Nov 11 03:18:38 UTC 2015,,,,,,,,,,"0|i2o3bb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,"09/Nov/15 04:30;guozhang;Thanks [~geoffra] for reporting, after reading the code I agree with the root cause: basically the new consumer's closing pattern should be based on the wakeup exception not on the shutting down flag. I am working on this now.;;;","10/Nov/15 04:22;githubbot;GitHub user guozhangwang opened a pull request:

    https://github.com/apache/kafka/pull/470

    KAFKA-2770: Catch and ignore WakeupException for commit upon closing

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/guozhangwang/kafka K2770

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/kafka/pull/470.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #470
    
----

----
;;;","10/Nov/15 05:50;becket_qin;[~guozhang] I think in addition to the changes in consumer, Mirror Maker should probably swallow any exception to make sure the countdown latch is pulled. I will submit a patch for that.;;;","11/Nov/15 11:18;githubbot;Github user asfgit closed the pull request at:

    https://github.com/apache/kafka/pull/470
;;;","11/Nov/15 11:18;guozhang;Issue resolved by pull request 470
[https://github.com/apache/kafka/pull/470];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
StackOverFlowError,KAFKA-848,12640652,Bug,Resolved,KAFKA,Kafka,software,junrao,Apache Kafka is a distributed streaming platform.,http://kafka.apache.org/,Major,Fixed,junrao,siningma,siningma,04/Apr/13 07:13,08/Feb/15 07:43,22/Mar/23 15:10,08/Feb/15 07:43,0.7.1,,,,,,,,,,,,,producer ,,,,0,,,,,,"
I am using kafka 0.7.1 right now.
I am using the following log4j properties file and trying to send some log 
information to kafka server.



log4j.rootLogger=INFO,file,stdout

log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=[%d] %p %t %m (%c)%n

log4j.appender.file=org.apache.log4j.RollingFileAppender
#log4j.appender.file.FileNamePattern=c:\\development\\producer-agent_%d{yyyy-MM-dd}.log
log4j.appender.file.File=${AC_DATA_HOME}\\lmservice\\tailer-aggregator.log
log4j.appender.file.MaxFileSize=100MB
log4j.appender.file.MaxBackupIndex=1
log4j.appender.file.layout=org.apache.log4j.PatternLayout
#log4j.appender.file.layout.ConversionPattern= %-4r [%t] %-5p %c %x - %m%n
log4j.appender.file.layout.ConversionPattern=[%d] %p %t %m (%c)%n

log4j.appender.KAFKA=kafka.producer.KafkaLog4jAppender
log4j.appender.KAFKA.layout=org.apache.log4j.PatternLayout
log4j.appender.KAFKA.layout.ConversionPattern=[%d] %p %t %m (%c)%n
log4j.appender.KAFKA.BrokerList=0:localhost:9092
log4j.appender.KAFKA.SerializerClass=kafka.serializer.StringEncoder
log4j.appender.KAFKA.Topic=test.topic


# Turn on all our debugging info
log4j.logger.kafka=INFO, KAFKA
log4j.logger.org=INFO, KAFKA
log4j.logger.com=INFO, KAFKA

When I run the program without KafkaLog4jAppender, everything is fine. Then I add KafkaLog4jAppender.
The producer can send messages through KafkaLog4jAppender to Kafka server.
However, after the producer send messages for a while. I see StackOverflowError. It seems that the producer or something else is recursively calling some functions.
This error will come out from many threads. I only copy 3 threads call stack below.

CallStack:
Exception in thread ""Process_Manager"" java.lang.StackOverflowError
        at java.util.regex.Pattern$1.isSatisfiedBy(Unknown Source)
        at java.util.regex.Pattern$5.isSatisfiedBy(Unknown Source)
        at java.util.regex.Pattern$5.isSatisfiedBy(Unknown Source)
        at java.util.regex.Pattern$CharProperty.match(Unknown Source)
        at java.util.regex.Pattern$GroupHead.match(Unknown Source)
        at java.util.regex.Pattern$Branch.match(Unknown Source)
        at java.util.regex.Pattern$Branch.match(Unknown Source)
        at java.util.regex.Pattern$Branch.match(Unknown Source)
        at java.util.regex.Pattern$BranchConn.match(Unknown Source)
        at java.util.regex.Pattern$GroupTail.match(Unknown Source)
        at java.util.regex.Pattern$Curly.match0(Unknown Source)
        at java.util.regex.Pattern$Curly.match(Unknown Source)
        at java.util.regex.Pattern$GroupHead.match(Unknown Source)
        at java.util.regex.Pattern$Branch.match(Unknown Source)
        at java.util.regex.Pattern$Branch.match(Unknown Source)
        at java.util.regex.Pattern$BmpCharProperty.match(Unknown Source)
        at java.util.regex.Pattern$Start.match(Unknown Source)
        at java.util.regex.Matcher.search(Unknown Source)
        at java.util.regex.Matcher.find(Unknown Source)
        at java.util.Formatter.parse(Unknown Source)
        at java.util.Formatter.format(Unknown Source)
        at java.util.Formatter.format(Unknown Source)
        at java.lang.String.format(Unknown Source)
        at scala.collection.immutable.StringLike$class.format(StringLike.scala:251)
        at scala.collection.immutable.StringOps.format(StringOps.scala:31)
        at kafka.utils.Logging$class.msgWithLogIdent(Logging.scala:28)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:108)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)

Exception in thread ""Thread-3"" java.lang.StackOverflowError
        at sun.nio.ch.SocketDispatcher.writev0(Native Method)
        at sun.nio.ch.SocketDispatcher.writev(Unknown Source)
        at sun.nio.ch.IOUtil.write(Unknown Source)
        at sun.nio.ch.SocketChannelImpl.write(Unknown Source)
        at java.nio.channels.SocketChannel.write(Unknown Source)
        at kafka.network.BoundedByteBufferSend.writeTo(BoundedByteBufferSend.scala:49)
        at kafka.network.Send$class.writeCompletely(Transmission.scala:73)
        at kafka.network.BoundedByteBufferSend.writeCompletely(BoundedByteBufferSend.scala:25)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:95)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.info(Category.java:666)
        at kafka.utils.Logging$class.info(Logging.scala:58)
        at kafka.producer.SyncProducer.info(SyncProducer.scala:39)
        at kafka.producer.SyncProducer.disconnect(SyncProducer.scala:153)
        at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:99)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:94)
        at kafka.producer.SyncProducer.send(SyncProducer.scala:125)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply$mcVI$sp(ProducerPool.scala:114)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at kafka.producer.ProducerPool$$anonfun$send$1.apply(ProducerPool.scala:100)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)
        at kafka.producer.ProducerPool.send(ProducerPool.scala:100)
        at kafka.producer.Producer.configSend(Producer.scala:159)
        at kafka.producer.Producer.send(Producer.scala:100)
        at kafka.producer.KafkaLog4jAppender.append(KafkaLog4jAppender.scala:83)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)

",Win7 64 bit,siningma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,,321111,,,2013-04-03 23:13:01.0,,,,,,,,,,"0|i1jel3:",321456,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
